original_idx,chunk_idx,command,chunk_text
0,0,abilint,nan
1,0,ac,"ac
prints out a report of connect time (in hours) based on the loâ
       gins/logouts  in  the  current
wtmp
file. A total is also printed
       out. The accounting file
wtmp
is maintained by
init
(8)  and
login(1)
."
1,1,ac,"The accounting file
wtmp
is maintained by
init
(8)  and
login(1)
. Neither
ac
nor
login
creates the
wtmp
if it doesn't exist, no acâ
       counting is done. To begin accounting, create  the  file  with  a
       length of zero."
1,2,ac,"To begin accounting, create  the  file  with  a
       length of zero. NOTE:   The
wtmp
file can get really big, really fast. You might
       want to trim it every once and a while."
1,3,ac,"You might
       want to trim it every once and a while. GNU
ac
works nearly the same UNIX
ac
, though it's a little smarter
       in several ways. You should therefore expect differences  in  the
       output of GNU
ac
and the output of
ac
's on other systems."
1,4,ac,"GNU
ac
works nearly the same UNIX
ac
, though it's a little smarter
       in several ways. You should therefore expect differences  in  the
       output of GNU
ac
and the output of
ac
's on other systems. Use the
       command
info
accounting
to get additional information."
2,0,abidb,nan
3,0,abicompat,nan
4,0,abipkgdiff,nan
5,0,Linux man pages online,nan
6,0,abidw,nan
7,0,Linux man pages online,nan
8,0,abidiff,nan
9,0,addftinfo,nan
10,0,addr2line,"addr2line
translates addresses or symbol+offset into file names
       and line numbers. Given an address or symbol+offset in an
       executable or an offset in a section of a relocatable object, it
       uses the debugging information to figure out which file name and
       line number are associated with it. The executable or relocatable object to use is specified with the
-e
option."
10,1,addr2line,"The executable or relocatable object to use is specified with the
-e
option. The default is the file
a.out
. The section in the
       relocatable object to use is specified with the
-j
option."
10,2,addr2line,"The section in the
       relocatable object to use is specified with the
-j
option. addr2line
has two modes of operation. In the first, hexadecimal addresses or symbol+offset are specified
       on the command line, and
addr2line
displays the file name and line
       number for each address."
10,3,addr2line,"In the first, hexadecimal addresses or symbol+offset are specified
       on the command line, and
addr2line
displays the file name and line
       number for each address. In the second,
addr2line
reads hexadecimal addresses or
       symbol+offset from standard input, and prints the file name and
       line number for each address on standard output. In this mode,
addr2line
may be used in a pipe to convert dynamically chosen
       addresses."
10,4,addr2line,"In this mode,
addr2line
may be used in a pipe to convert dynamically chosen
       addresses. The format of the output is
FILENAME:LINENO
. By default each
       input address generates one line of output."
10,5,addr2line,"By default each
       input address generates one line of output. Two options can generate additional lines before each
FILENAME:LINENO
line (in that order). If the
-a
option is used then a line with the input address is
       displayed."
10,6,addr2line,"If the
-a
option is used then a line with the input address is
       displayed. If the
-f
option is used, then a line with the
FUNCTIONNAME
is
       displayed. This is the name of the function containing the
       address."
10,7,addr2line,"This is the name of the function containing the
       address. One option can generate additional lines after the
FILENAME:LINENO
line. If the
-i
option is used and the code at the given address is
       present there because of inlining by the compiler then additional
       lines are displayed afterwards."
10,8,addr2line,"If the
-i
option is used and the code at the given address is
       present there because of inlining by the compiler then additional
       lines are displayed afterwards. One or two extra lines (if the
-f
option is used) are displayed for each inlined function. Alternatively if the
-p
option is used then each input address
       generates a single, long, output line containing the address, the
       function name, the file name and the line number."
10,9,addr2line,"Alternatively if the
-p
option is used then each input address
       generates a single, long, output line containing the address, the
       function name, the file name and the line number. If the
-i
option has also been used then any inlined functions will be
       displayed in the same manner, but on separate lines, and prefixed
       by the text
(inlined by)
. If the file name or function name can not be determined,
addr2line
will print two question marks in their place."
10,10,addr2line,"If the file name or function name can not be determined,
addr2line
will print two question marks in their place. If the line number
       can not be determined,
addr2line
will print 0. When symbol+offset is used, +offset is optional, except when the
       symbol is ambigious with a hex number."
10,11,addr2line,"If the line number
       can not be determined,
addr2line
will print 0. When symbol+offset is used, +offset is optional, except when the
       symbol is ambigious with a hex number. The resolved symbols can be
       mangled or unmangled, except unmangled symbols with + are not
       allowed."
11,0,arch,"Print machine architecture.
--help
display this help and exit
--version
output version information and exit"
12,0,ar,"The GNU
ar
program creates, modifies, and extracts from archives. An
archive
is a single file holding a collection of other files in
       a structure that makes it possible to retrieve the original
       individual files (called
members
of the archive). The original files' contents, mode (permissions), timestamp,
       owner, and group are preserved in the archive, and can be restored
       on extraction."
12,1,ar,"The original files' contents, mode (permissions), timestamp,
       owner, and group are preserved in the archive, and can be restored
       on extraction. GNU
ar
can maintain archives whose members have names of any
       length; however, depending on how
ar
is configured on your system,
       a limit on member-name length may be imposed for compatibility
       with archive formats maintained with other tools. If it exists,
       the limit is often 15 characters (typical of formats related to
       a.out) or 16 characters (typical of formats related to coff)."
12,2,ar,"If it exists,
       the limit is often 15 characters (typical of formats related to
       a.out) or 16 characters (typical of formats related to coff). ar
is considered a binary utility because archives of this sort
       are most often used as
libraries
holding commonly needed
       subroutines. Since libraries often will depend on other
       libraries,
ar
can also record the dependencies of a library when
       the
--record-libdeps
option is specified."
12,3,ar,"Since libraries often will depend on other
       libraries,
ar
can also record the dependencies of a library when
       the
--record-libdeps
option is specified. ar
creates an index to the symbols defined in relocatable object
       modules in the archive when you specify the modifier
s
. Once
       created, this index is updated in the archive whenever
ar
makes a
       change to its contents (save for the
q
update operation)."
12,4,ar,"Once
       created, this index is updated in the archive whenever
ar
makes a
       change to its contents (save for the
q
update operation). An
       archive with such an index speeds up linking to the library, and
       allows routines in the library to call each other without regard
       to their placement in the archive. You may use
nm -s
or
nm --print-armap
to list this index table."
12,5,ar,"You may use
nm -s
or
nm --print-armap
to list this index table. If an archive lacks the table, another form of
ar
called
ranlib
can be used to add just the table. GNU
ar
can optionally create a
thin
archive, which contains a
       symbol index and references to the original copies of the member
       files of the archive."
12,6,ar,"GNU
ar
can optionally create a
thin
archive, which contains a
       symbol index and references to the original copies of the member
       files of the archive. This is useful for building libraries for
       use within a local build tree, where the relocatable objects are
       expected to remain available, and copying the contents of each
       object would only waste time and space. An archive can either be
thin
or it can be normal."
12,7,ar,"An archive can either be
thin
or it can be normal. It cannot be
       both at the same time. Once an archive is created its format
       cannot be changed without first deleting it and then creating a
       new archive in its place."
12,8,ar,"Once an archive is created its format
       cannot be changed without first deleting it and then creating a
       new archive in its place. Thin archives are also
flattened
, so that adding one thin archive
       to another thin archive does not nest it, as would happen with a
       normal archive. Instead the elements of the first archive are
       added individually to the second archive."
12,9,ar,"Instead the elements of the first archive are
       added individually to the second archive. The paths to the elements of the archive are stored relative to
       the archive itself. GNU
ar
is designed to be compatible with two different facilities."
12,10,ar,"The paths to the elements of the archive are stored relative to
       the archive itself. GNU
ar
is designed to be compatible with two different facilities. You can control its activity using command-line options, like the
       different varieties of
ar
on Unix systems; or, if you specify the
       single command-line option
-M
, you can control it with a script
       supplied via standard input, like the MRI ""librarian"" program."
13,0,afmtodit,nan
14,0,apropos,"Each manual page has a short description available within it. apropos
searches the descriptions for instances of
keyword
. keyword
is usually a regular expression, as if (
-r
) was used, or
       may contain wildcards (
-w
), or match the exact keyword (
-e
)."
14,1,apropos,"keyword
is usually a regular expression, as if (
-r
) was used, or
       may contain wildcards (
-w
), or match the exact keyword (
-e
). Using these options, it may be necessary to quote the
keyword
or
       escape (\) the special characters to stop the shell from
       interpreting them. The standard matching rules allow matches to be made against the
       page name and word boundaries in the description."
14,2,apropos,"The standard matching rules allow matches to be made against the
       page name and word boundaries in the description. The database searched by
apropos
is updated by the
mandb
program. Depending on your installation, this may be run by a periodic cron
       job, or may need to be run manually after new manual pages have
       been installed."
15,0,ar,"The
ar
utility is part of the Software Development Utilities
       option. The
ar
utility can be used to create and maintain groups of files
       combined into an archive. Once an archive has been created, new
       files can be added, and existing files in an archive can be
       extracted, deleted, or replaced."
15,1,ar,"Once an archive has been created, new
       files can be added, and existing files in an archive can be
       extracted, deleted, or replaced. When an archive consists entirely
       of valid object files, the implementation shall format the archive
       so that it is usable as a library for link editing (see
c99
and
fort77
). When some of the archived files are not valid object
       files, the suitability of the archive for library use is
       undefined."
15,2,ar,"When some of the archived files are not valid object
       files, the suitability of the archive for library use is
       undefined. If an archive consists entirely of printable files,
       the entire archive shall be printable. When
ar
creates an archive, it creates administrative information
       indicating whether a symbol table is present in the archive."
15,3,ar,"When
ar
creates an archive, it creates administrative information
       indicating whether a symbol table is present in the archive. When
       there is at least one object file that
ar
recognizes as such in
       the archive, an archive symbol table shall be created in the
       archive and maintained by
ar
; it is used by the link editor to
       search the archive. Whenever the
ar
utility is used to create or
       update the contents of such an archive, the symbol table shall be
       rebuilt."
15,4,ar,"Whenever the
ar
utility is used to create or
       update the contents of such an archive, the symbol table shall be
       rebuilt. The
-s
option shall force the symbol table to be rebuilt. All
file
operands can be pathnames."
15,5,ar,"All
file
operands can be pathnames. However, files within archives
       shall be named by a filename, which is the last component of the
       pathname used when the file was entered into the archive. The
       comparison of
file
operands to the names of files in archives
       shall be performed by comparing the last component of the operand
       to the name of the file in the archive."
15,6,ar,"The
       comparison of
file
operands to the names of files in archives
       shall be performed by comparing the last component of the operand
       to the name of the file in the archive. It is unspecified whether multiple files in the archive may be
       identically named. In the case of such files, however, each
file
and
posname
operand shall match only the first file in the archive
       having a name that is the same as the last component of the
       operand."
16,0,alias,"The
alias
utility shall create or redefine alias definitions or
       write the values of existing alias definitions to standard output. An alias definition provides a string value that shall replace a
       command name when it is encountered; see
Section 2.3.1
,
Alias
Substitution
. An alias definition shall affect the current shell execution
       environment and the execution environments of the subshells of the
       current shell."
16,1,alias,"An alias definition provides a string value that shall replace a
       command name when it is encountered; see
Section 2.3.1
,
Alias
Substitution
. An alias definition shall affect the current shell execution
       environment and the execution environments of the subshells of the
       current shell. When used as specified by this volume of
       POSIX.1â2017, the alias definition shall not affect the parent
       process of the current shell nor any utility environment invoked
       by the shell; see
Section 2.12
,
Shell Execution Environment
."
17,0,aria_chk,"Describe, check and repair of Aria tables. Used without options
       all tables on the command will be checked for errors
Global options
-#
,
--debug=
... Output debug log."
17,1,aria_chk,"Output debug log. Often this is 'd:t:o,filename'. -H
,
--HELP
Print all argument options sorted alphabetically."
17,2,aria_chk,"-H
,
--HELP
Print all argument options sorted alphabetically. -? ,
--help
Print all options by groups
--datadir
=
path
Path for control file (and logs if
--logdir
not used)
--logdir
=
path
Path for log files
--ignore-control-file
Don't open the control file."
17,3,aria_chk,",
--help
Print all options by groups
--datadir
=
path
Path for control file (and logs if
--logdir
not used)
--logdir
=
path
Path for log files
--ignore-control-file
Don't open the control file. Only use this if you are sure
              the tables are not in use by another program! --require-control-file
Abort if we can't find/read the maria_log_control file
-s
,
--silent
Only print errors."
17,4,aria_chk,"--require-control-file
Abort if we can't find/read the maria_log_control file
-s
,
--silent
Only print errors. One can use two
-s
to make maria_chk
              very silent. -t
,
--tmpdir
=
path
Path for temporary files."
17,5,aria_chk,"-t
,
--tmpdir
=
path
Path for temporary files. Multiple paths can be specified,
              separated by colon (:), they will be used in a round-robin
              fashion. -v
,
--verbose
Print more information."
17,6,aria_chk,"-v
,
--verbose
Print more information. This can be used with
--description
and
--check
. Use many
-v
for more verbosity."
17,7,aria_chk,"Use many
-v
for more verbosity. -V
,
--version
Print version and exit. -w
,
--wait
Wait if table is locked."
17,8,aria_chk,"-w
,
--wait
Wait if table is locked. Check options (check is the default action for aria_chk)
-c
,
--check
Check table for errors. -e
,
--extend-check
Check the table VERY thoroughly."
17,9,aria_chk,"-e
,
--extend-check
Check the table VERY thoroughly. Only use this in extreme
              cases as aria_chk should normally be able to find out if
              the table is ok even without this switch. -F
,
--fast
Check only tables that haven't been closed properly."
17,10,aria_chk,"-F
,
--fast
Check only tables that haven't been closed properly. -C
,
--check-only-changed
Check only tables that have changed since last check. -f
,
--force
Restart with '-r' if there are any errors in the table."
17,11,aria_chk,"-f
,
--force
Restart with '-r' if there are any errors in the table. States will be updated as with '--update-state'. -i
,
--information
Print statistics information about table that is checked."
17,12,aria_chk,"-i
,
--information
Print statistics information about table that is checked. -m
,
--medium-check
Faster than extend-check, but only finds 99.99% of all
              errors. Should be good enough for most cases."
17,13,aria_chk,"Should be good enough for most cases. -T
,
--read-only
Don't mark table as checked. -U
,
--update-state
Mark tables as crashed if any errors were found and clean
              if check didn't find any errors but table was marked as
              'not clean' before."
17,14,aria_chk,"-U
,
--update-state
Mark tables as crashed if any errors were found and clean
              if check didn't find any errors but table was marked as
              'not clean' before. This allows one to get rid of warnings
              like 'table not properly closed'. If table was updated,
              update also the timestamp for when the check was made."
17,15,aria_chk,"If table was updated,
              update also the timestamp for when the check was made. This
              option is on by default! Use
--skip-update-state
to
              disable."
17,16,aria_chk,"Use
--skip-update-state
to
              disable. --warning-for-wrong-transaction-id
Give a warning if we find a transaction id in the table
              that is bigger than what exists in the control file. Use
--skip-
..."
17,17,aria_chk,"Use
--skip-
... to disable warning
Recover (repair)/ options (When using '--recover' or '--safe-recover')
-B
,
--backup
Make a backup of the .MAD file as 'filename-time.BAK'. --correct-checksum
Correct checksum information for table."
17,18,aria_chk,"--correct-checksum
Correct checksum information for table. -D
,
--data-file-length=
#
              Max length of data file (when recreating data file when
              it's full). -e
,
--extend-check
Try to recover every possible row from the data file
              Normally this will also find a lot of garbage rows; Don't
              use this option if you are not totally desperate."
17,19,aria_chk,"-e
,
--extend-check
Try to recover every possible row from the data file
              Normally this will also find a lot of garbage rows; Don't
              use this option if you are not totally desperate. -f
,
--force
Overwrite old temporary files. -k
,
--keys-used=
#
              Tell Aria to update only some specific keys."
17,20,aria_chk,"-k
,
--keys-used=
#
              Tell Aria to update only some specific keys. # is a bit
              mask of which keys to use. This can be used to get faster
              inserts."
17,21,aria_chk,"This can be used to get faster
              inserts. --max-record-length=
#
              Skip rows bigger than this if aria_chk can't allocate
              memory to hold it. -r
,
--recover
Can fix almost anything except unique keys that aren't
              unique."
17,22,aria_chk,"-r
,
--recover
Can fix almost anything except unique keys that aren't
              unique. -n
,
--sort-recover
Forces recovering with sorting even if the temporary file
              would be very big. -p
,
--parallel-recover
Uses the same technique as '-r' and '-n', but creates all
              the keys in parallel, in different threads."
17,23,aria_chk,"-p
,
--parallel-recover
Uses the same technique as '-r' and '-n', but creates all
              the keys in parallel, in different threads. -o
,
--safe-recover
Uses old recovery method; Slower than '-r' but can handle a
              couple of cases where '-r' reports that it can't fix the
              data file. --transaction-log
Log repair command to transaction log."
17,24,aria_chk,"--transaction-log
Log repair command to transaction log. This is needed if
              one wants to use the aria_read_log to repeat the repair
--character-sets-dir=
... Directory where character sets are."
17,25,aria_chk,"Directory where character sets are. --set-collation
=
name
Change the collation used by the index. -q
,
--quick
Faster repair by not modifying the data file."
17,26,aria_chk,"-q
,
--quick
Faster repair by not modifying the data file. One can give
              a second '-q' to force aria_chk to modify the original
              datafile in case of duplicate keys. NOTE: Tables where the
              data file is corrupted can't be fixed with this option."
17,27,aria_chk,"NOTE: Tables where the
              data file is corrupted can't be fixed with this option. -u
,
--unpack
Unpack file packed with ariapack. Other actions
-a
,
--analyze
Analyze distribution of keys."
17,28,aria_chk,"Other actions
-a
,
--analyze
Analyze distribution of keys. Will make some joins in
              MariaDB faster. You can check the calculated distribution
              by using '--description
--verbose
table_name'."
17,29,aria_chk,"You can check the calculated distribution
              by using '--description
--verbose
table_name'. --stats_method
=
name
Specifies how index statistics collection code should treat
              NULLs. Possible values of name are ""nulls_unequal"" (default
              for 4.1/5.0), ""nulls_equal"" (emulate 4.0), and
              ""nulls_ignored""."
17,30,aria_chk,"Possible values of name are ""nulls_unequal"" (default
              for 4.1/5.0), ""nulls_equal"" (emulate 4.0), and
              ""nulls_ignored"". -d
,
--description
Prints some information about table. -A
,
--set-auto-increment
[=
value
]
              Force auto_increment to start at this or higher value If no
              value is given, then sets the next auto_increment value to
              the highest used value for the auto key + 1."
17,31,aria_chk,"-A
,
--set-auto-increment
[=
value
]
              Force auto_increment to start at this or higher value If no
              value is given, then sets the next auto_increment value to
              the highest used value for the auto key + 1. -S
,
--sort-index
Sort index blocks. This speeds up 'read-next' in
              applications."
17,32,aria_chk,"This speeds up 'read-next' in
              applications. -R
,
--sort-records=
#
              Sort records according to an index. This makes your data
              much more localized and may speed up things (It may be VERY
              slow to do a sort the first time!)."
17,33,aria_chk,"This makes your data
              much more localized and may speed up things (It may be VERY
              slow to do a sort the first time!). -b
,
--block-search=
#
              Find a record, a block at given offset belongs to. -z
,
--zerofill
Fill empty space in data and index files with zeroes."
17,34,aria_chk,"-z
,
--zerofill
Fill empty space in data and index files with zeroes. This
              makes the data file movable between different servers. --zerofill-keep-lsn
Like
--zerofill
but does not zero out LSN of data/index
              pages."
17,35,aria_chk,"--zerofill-keep-lsn
Like
--zerofill
but does not zero out LSN of data/index
              pages. Variables
--page_buffer_size=
#
              Size of page buffer. Used by
--safe-repair
--read_buffer_size=
#
              Read buffer size for sequential reads during scanning
--sort_buffer_size=
#
              Size of sort buffer."
17,36,aria_chk,"Used by
--safe-repair
--read_buffer_size=
#
              Read buffer size for sequential reads during scanning
--sort_buffer_size=
#
              Size of sort buffer. Used by
--recover
--sort_key_blocks=
#
              Internal buffer for sorting keys; Don't touch. --write_buffer_size=
#
              Write buffer size for sequential writes during repair

       Default options are read from the following files in the given
       order:
/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf
The following groups are read:
aria_chk
The following options may be given as the first argument:
--print-defaults
Print the program argument list and exit."
17,37,aria_chk,"--write_buffer_size=
#
              Write buffer size for sequential writes during repair

       Default options are read from the following files in the given
       order:
/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf
The following groups are read:
aria_chk
The following options may be given as the first argument:
--print-defaults
Print the program argument list and exit. --no-defaults
Don't read default options from any option file. --defaults-file=
#
              Only read default options from the given file #."
17,38,aria_chk,"--no-defaults
Don't read default options from any option file. --defaults-file=
#
              Only read default options from the given file #. --defaults-extra-file=
#
              Read this file after the global files are read."
18,0,admin,"The
admin
utility shall create new SCCS files or change parameters
       of existing ones. If a named file does not exist, it shall be
       created, and its parameters shall be initialized according to the
       specified options. Parameters not initialized by an option shall
       be assigned a default value."
18,1,admin,"Parameters not initialized by an option shall
       be assigned a default value. If a named file does exist,
       parameters corresponding to specified options shall be changed,
       and other parameters shall be left as is. All SCCS filenames supplied by the application shall be of the
       form s."
18,2,admin,"All SCCS filenames supplied by the application shall be of the
       form s. filename
. New SCCS files shall be given read-only
       permission mode."
18,3,admin,"New SCCS files shall be given read-only
       permission mode. Write permission in the parent directory is
       required to create a file. All writing done by
admin
shall be to a
       temporary
x-file
, named x."
18,4,admin,"All writing done by
admin
shall be to a
       temporary
x-file
, named x. filename
(see
get(1p)
) created with
       read-only mode if
admin
is creating a new SCCS file, or created
       with the same mode as that of the SCCS file if the file already
       exists. After successful execution of
admin
, the SCCS file shall
       be removed (if it exists), and the
x-file
shall be renamed with
       the name of the SCCS file."
18,5,admin,"After successful execution of
admin
, the SCCS file shall
       be removed (if it exists), and the
x-file
shall be renamed with
       the name of the SCCS file. This ensures that changes are made to
       the SCCS file only if no errors occur. The
admin
utility shall also use a transient lock file (named
       z."
18,6,admin,"This ensures that changes are made to
       the SCCS file only if no errors occur. The
admin
utility shall also use a transient lock file (named
       z. filename
), which is used to prevent simultaneous updates to the
       SCCS file; see
get(1p)
."
19,0,aria_dump_log,"Dump content of Aria log pages. -#
,
--debug
[=
name
]
              Output debug log. Often the argument is 'd:t:o,filename'."
19,1,aria_dump_log,"Often the argument is 'd:t:o,filename'. -f
,
--file
=
name
Path to file which will be read
-? ,
--help
Display this help and exit."
19,2,aria_dump_log,",
--help
Display this help and exit. -o
,
--offset=
#
              Start reading log from this offset
-n
,
--pages=
#
              Number of pages to read
-U
,
--unit-test
Use unit test record table (for logs created by unittests
-V
,
--version
Print version and exit. Default options are read from the following files in the given
       order:
/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf
The following groups are read:
aria_dump_log
The following options may be given as the first argument:
--print-defaults
Print the program argument list and exit."
19,3,aria_dump_log,"Default options are read from the following files in the given
       order:
/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf
The following groups are read:
aria_dump_log
The following options may be given as the first argument:
--print-defaults
Print the program argument list and exit. --no-defaults
Don't read default options from any option file. --defaults-file=
#
              Only read default options from the given file #."
19,4,aria_dump_log,"--no-defaults
Don't read default options from any option file. --defaults-file=
#
              Only read default options from the given file #. --defaults-extra-file=
#
              Read this file after the global files are read."
20,0,aria_ftdump,"Use: aria_ft_dump <table_name> <index_num>
-? ,
-h
,
--help
Display help and exit. -c
,
--count
Calculate per-word stats (counts and global weights)."
20,1,aria_ftdump,"-c
,
--count
Calculate per-word stats (counts and global weights). -d
,
--dump
Dump index (incl. data offsets and word weights)."
20,2,aria_ftdump,"data offsets and word weights). -l
,
--length
Report length distribution. -s
,
--stats
Report global stats."
20,3,aria_ftdump,"-l
,
--length
Report length distribution. -s
,
--stats
Report global stats. -v
,
--verbose
Be verbose."
21,0,aria_pack,"Pack a Aria-table to take much less space. Keys are not updated,
       you must run
aria_chk -rq
on the index (.MAI) file afterwards to
       update the keys. You should give the .MAI file as the filename
       argument."
21,1,aria_pack,"You should give the .MAI file as the filename
       argument. To unpack a packed table, run
aria_chk -u
on the table
-b
,
--backup
Make a backup of the table as table_name.OLD. --character-sets-dir
=
name
Directory where character sets are."
21,2,aria_pack,"--character-sets-dir
=
name
Directory where character sets are. -#
,
--debug
[=
name
]
              Output debug log. Often this is 'd:t:o,filename'."
21,3,aria_pack,"Often this is 'd:t:o,filename'. -f
,
--force
Force packing of table even if it gets bigger or if
              tempfile exists. -j
,
--join
=
name
Join all given tables into 'new_table_name'."
21,4,aria_pack,"-j
,
--join
=
name
Join all given tables into 'new_table_name'. All tables
              MUST have identical layouts. -?"
21,5,aria_pack,"-? ,
--help
Display this help and exit. -s
,
--silent
Be more silent."
21,6,aria_pack,"-s
,
--silent
Be more silent. -T
,
--tmpdir
=
name
Use temporary directory to store temporary table. -t
,
--test
Don't pack table, only test packing it."
21,7,aria_pack,"-t
,
--test
Don't pack table, only test packing it. -v
,
--verbose
Write info about progress and packing result. Use many
-v
for more verbosity!"
21,8,aria_pack,"Use many
-v
for more verbosity! -V
,
--version
Output version information and exit. -w
,
--wait
Wait and retry if table is in use."
21,9,aria_pack,"-w
,
--wait
Wait and retry if table is in use. Default options are read from the following files in the given
       order:
/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf
The following groups are read:
ariapack
The following options may be given as the first argument:
--print-defaults
Print the program argument list and exit. --no-defaults
Don't read default options from any option file."
21,10,aria_pack,"--no-defaults
Don't read default options from any option file. --defaults-file=
#
              Only read default options from the given file #. --defaults-extra-file=
#
              Read this file after the global files are read."
22,0,aria_read_log,"Display and apply log records from a Aria transaction log found in
       the current directory (for now)

       Note: Aria is compiled without
-DIDENTICAL_PAGES_AFTER_RECOVERY
which means that the table files are not byte-to-byte identical to
       files created during normal execution. This should be ok, except
       for test scripts that tries to compare files before and after
       recovery. You need to use one of
-d
or
-a
-a
,
--apply
Apply log to tables: modifies tables!"
22,1,aria_read_log,"You need to use one of
-d
or
-a
-a
,
--apply
Apply log to tables: modifies tables! you should make a
              backup first! Displays a lot of information if not run
              with
--silent
--character-sets-dir
=
name
Directory where character sets are."
22,2,aria_read_log,"Displays a lot of information if not run
              with
--silent
--character-sets-dir
=
name
Directory where character sets are. -c
,
--check
if
--display-only
, check if record is fully readable (for
              debugging)
-#
,
--debug
[=
name
]
              Output debug log. Often the argument is 'd:t:o,filename'."
22,3,aria_read_log,"Often the argument is 'd:t:o,filename'. --force-crash=
#
              Force crash after # recovery events
-? ,
--help
Display this help and exit."
22,4,aria_read_log,",
--help
Display this help and exit. -d
,
--display-only
display brief info read from records' header
-e
,
--end-lsn=
#
              Stop applying at this lsn. If end-lsn is used, UNDO:s will
              not be applied
-h
,
--aria-log-dir-path
=
name
Path to the directory where to store transactional log
-P
,
--page-buffer-size=
#
              The size of the buffer used for index blocks for Aria
              tables
-o
,
--start-from-lsn=
#
              Start reading log from this lsn
-C
,
--start-from-checkpoint
Start applying from last checkpoint
-s
,
--silent
Print less information during apply/undo phase
-T
,
--tables-to-redo
=
name
List of tables separated with , that we should apply REDO
              on."
22,5,aria_read_log,"If end-lsn is used, UNDO:s will
              not be applied
-h
,
--aria-log-dir-path
=
name
Path to the directory where to store transactional log
-P
,
--page-buffer-size=
#
              The size of the buffer used for index blocks for Aria
              tables
-o
,
--start-from-lsn=
#
              Start reading log from this lsn
-C
,
--start-from-checkpoint
Start applying from last checkpoint
-s
,
--silent
Print less information during apply/undo phase
-T
,
--tables-to-redo
=
name
List of tables separated with , that we should apply REDO
              on. Use this if you only want to recover some tables
-t
,
--tmpdir
=
name
Path for temporary files. Multiple paths can be specified,
              separated by colon (:)
--translog-buffer-size=
#
              The size of the buffer used for transaction log for Aria
              tables
-u
,
--undo
Apply UNDO records to tables."
22,6,aria_read_log,"Multiple paths can be specified,
              separated by colon (:)
--translog-buffer-size=
#
              The size of the buffer used for transaction log for Aria
              tables
-u
,
--undo
Apply UNDO records to tables. (disable with
--disable-undo
)
              (Defaults to on; use
--skip-undo
to disable.)
-v
,
--verbose
Print more information during apply/undo phase
-V
,
--version
Print version and exit. Default options are read from the following files in the given
       order:
/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf
The following groups are read:
aria_read_log
The following options may be given as the first argument:
--print-defaults
Print the program argument list and exit."
22,7,aria_read_log,"Default options are read from the following files in the given
       order:
/etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf
The following groups are read:
aria_read_log
The following options may be given as the first argument:
--print-defaults
Print the program argument list and exit. --no-defaults
Don't read default options from any option file. --defaults-file=
#
              Only read default options from the given file #."
22,8,aria_read_log,"--no-defaults
Don't read default options from any option file. --defaults-file=
#
              Only read default options from the given file #. --defaults-extra-file=
#
              Read this file after the global files are read."
23,0,asa,"The
asa
utility shall write its input files to standard output,
       mapping carriage-control characters from the text files to line-
       printer control sequences in an implementation-defined manner. The first character of every line shall be removed from the input,
       and the following actions are performed. If the character removed is:

       <space>   The rest of the line is output without change."
23,1,asa,"If the character removed is:

       <space>   The rest of the line is output without change. 0         A <newline> is output, then the rest of the input line. 1         One or more implementation-defined characters that
                 causes an advance to the next page shall be output,
                 followed by the rest of the input line."
23,2,asa,"1         One or more implementation-defined characters that
                 causes an advance to the next page shall be output,
                 followed by the rest of the input line. +         The <newline> of the previous line shall be replaced
                 with one or more implementation-defined characters that
                 causes printing to return to column position 1, followed
                 by the rest of the input line. If the
'+'
is the first
                 character in the input, it shall be equivalent to
                 <space>."
23,3,asa,"+         The <newline> of the previous line shall be replaced
                 with one or more implementation-defined characters that
                 causes printing to return to column position 1, followed
                 by the rest of the input line. If the
'+'
is the first
                 character in the input, it shall be equivalent to
                 <space>. The action of the
asa
utility is unspecified upon encountering any
       character other than those listed above as the first character in
       a line."
24,0,ascii-xfr,"Ascii-xfr
Transfers files in ASCII mode. This means no flow
       control, no checksumming and no file-name negotiation. It should
only
be used if the remote system doesn't understand anything
       else."
24,1,ascii-xfr,"It should
only
be used if the remote system doesn't understand anything
       else. The ASCII protocol transfers files line-by-line. The EOL (End-Of-
       Line) character is transmitted as CRLF."
24,2,ascii-xfr,"The EOL (End-Of-
       Line) character is transmitted as CRLF. When receiving, the CR
       character is stripped from the incoming file. The Control-Z
       (ASCII 26) character signals End-Of-File, if option -e is
       specified (unless you change it to Control-D (ASCII 4) with -d)."
24,3,ascii-xfr,"The Control-Z
       (ASCII 26) character signals End-Of-File, if option -e is
       specified (unless you change it to Control-D (ASCII 4) with -d). Ascii-xfr
reads from
stdin
when receiving, and sends data on
stdout
when sending. Some form of input or output redirection to
       the modem device is thus needed when downloading or uploading,
       respectively."
25,0,attr,"The
attr
utility allows the manipulation of extended attributes
       associated with filesystem objects from within shell scripts. There are four main operations that
attr
can perform:
GET
The
-g attrname
option tells
attr
to search the named
              object and print (to
stdout
) the value associated with that
              attribute name. With the
-q
flag,
stdout
will be exactly
              and only the value of the attribute, suitable for storage
              directly into a file or processing via a piped command."
25,1,attr,"With the
-q
flag,
stdout
will be exactly
              and only the value of the attribute, suitable for storage
              directly into a file or processing via a piped command. LIST
The
-l
option tells
attr
to list the names of all the
              attributes that are associated with the object, and the
              number of bytes in the value of each of those attributes. With the
-q
flag,
stdout
will be a simple list of only the
              attribute names, one per line, suitable for input into a
              script."
25,2,attr,"With the
-q
flag,
stdout
will be a simple list of only the
              attribute names, one per line, suitable for input into a
              script. REMOVE
The
-r attrname
option tells
attr
to remove an attribute
              with the given name from the object if the attribute
              exists. There is no output on successful completion."
25,3,attr,"There is no output on successful completion. SET/CREATE
The
-s attrname
option tells
attr
to set the named
              attribute of the object to the value read from
stdin
. If
              an attribute with that name already exists, its value will
              be replaced with this one."
25,4,attr,"If
              an attribute with that name already exists, its value will
              be replaced with this one. If an attribute with that name
              does not already exist, one will be created with this
              value. With the
-V attrvalue
flag, the attribute will be
              set to have a value of
attrvalue
and
stdin
will not be
              read."
25,5,attr,"With the
-V attrvalue
flag, the attribute will be
              set to have a value of
attrvalue
and
stdin
will not be
              read. With the
-q
flag,
stdout
will not be used. Without
              the
-q
flag, a message showing the attribute name and the
              entire value will be printed."
25,6,attr,"Without
              the
-q
flag, a message showing the attribute name and the
              entire value will be printed. When the
-L
option is given and the named object is a symbolic
       link, operate on the attributes of the object referenced by the
       symbolic link. Without this option, operate on the attributes of
       the symbolic link itself."
25,7,attr,"Without this option, operate on the attributes of
       the symbolic link itself. When the
-R
option is given and the process has appropriate
       privileges, operate in the
root
attribute namespace rather that
       the
USER
attribute namespace. The
-S
option is similar, except it specifies use of the
security
attribute namespace."
25,8,attr,"The
-S
option is similar, except it specifies use of the
security
attribute namespace. When the
-q
option is given
attr
will try to keep quiet. It will
       output error messages (to
stderr
) but will not print status
       messages (to
stdout
)."
26,0,at,"The
at
utility shall read commands from standard input and group
       them together as an
at-job
, to be executed at a later time. The at-job shall be executed in a separate invocation of the
       shell, running in a separate process group with no controlling
       terminal, except that the environment variables, current working
       directory, file creation mask, and other implementation-defined
       execution-time attributes in effect when the
at
utility is
       executed shall be retained and used when the at-job is executed. When the at-job is submitted, the
at_job_id
and scheduled time
       shall be written to standard error."
26,1,at,"When the at-job is submitted, the
at_job_id
and scheduled time
       shall be written to standard error. The
at_job_id
is an identifier
       that shall be a string consisting solely of alphanumeric
       characters and the <period> character. The
at_job_id
shall be
       assigned by the system when the job is scheduled such that it
       uniquely identifies a particular job."
26,2,at,"The
at_job_id
shall be
       assigned by the system when the job is scheduled such that it
       uniquely identifies a particular job. User notification and the processing of the job's standard output
       and standard error are described under the
-m
option. Users shall be permitted to use
at
if their name appears in the
       file
at.allow
which is located in an implementation-defined
       directory."
26,3,at,"Users shall be permitted to use
at
if their name appears in the
       file
at.allow
which is located in an implementation-defined
       directory. If that file does not exist, the file
at.deny
, which
       is located in an implementation-defined directory, shall be
       checked to determine whether the user shall be denied access to
at
. If neither file exists, only a process with appropriate
       privileges shall be allowed to submit a job."
26,4,at,"If neither file exists, only a process with appropriate
       privileges shall be allowed to submit a job. If only
at.deny
exists and is empty, global usage shall be permitted. The
at.allow
and
at.deny
files shall consist of one user name per line."
27,0,audit2allow,"This utility scans the logs for messages logged when the system
       denied permission for operations, and generates a snippet of
       policy rules which, if loaded into policy, might have allowed
       those operations to succeed. However, this utility only generates
       Type Enforcement (TE) allow rules. Certain permission denials may
       require other kinds of policy changes, e.g."
27,1,audit2allow,"Certain permission denials may
       require other kinds of policy changes, e.g. adding an attribute to
       a type declaration to satisfy an existing constraint, adding a
       role allow rule, or modifying a constraint. The
audit2why
(8)
       utility may be used to diagnose the reason when it is unclear."
27,2,audit2allow,"The
audit2why
(8)
       utility may be used to diagnose the reason when it is unclear. Care must be exercised while acting on the output of this utility
       to ensure that the operations being permitted do not pose a
       security threat. Often it is better to define new domains and/or
       types, or make other structural changes to narrowly allow an
       optimal set of operations to succeed, as opposed to blindly
       implementing the sometimes broad changes recommended by this
       utility."
27,3,audit2allow,"Care must be exercised while acting on the output of this utility
       to ensure that the operations being permitted do not pose a
       security threat. Often it is better to define new domains and/or
       types, or make other structural changes to narrowly allow an
       optimal set of operations to succeed, as opposed to blindly
       implementing the sometimes broad changes recommended by this
       utility. Certain permission denials are not fatal to the
       application, in which case it may be preferable to simply suppress
       logging of the denial via a 'dontaudit' rule rather than an
       'allow' rule."
28,0,as,"GNU
as
is really a family of assemblers. If you use (or have
       used) the GNU assembler on one architecture, you should find a
       fairly similar environment when you use it on another
       architecture. Each version has much in common with the others,
       including object file formats, most assembler directives (often
       called
pseudo-ops
) and assembler syntax."
28,1,as,"Each version has much in common with the others,
       including object file formats, most assembler directives (often
       called
pseudo-ops
) and assembler syntax. as
is primarily intended to assemble the output of the GNU C
       compiler ""gcc"" for use by the linker ""ld"". Nevertheless, we've
       tried to make
as
assemble correctly everything that other
       assemblers for the same machine would assemble."
28,2,as,"Nevertheless, we've
       tried to make
as
assemble correctly everything that other
       assemblers for the same machine would assemble. Any exceptions
       are documented explicitly. This doesn't mean
as
always uses the
       same syntax as another assembler for the same architecture; for
       example, we know of several incompatible versions of 680x0
       assembly language syntax."
28,3,as,"This doesn't mean
as
always uses the
       same syntax as another assembler for the same architecture; for
       example, we know of several incompatible versions of 680x0
       assembly language syntax. Each time you run
as
it assembles exactly one source program. The
       source program is made up of one or more files."
28,4,as,"The
       source program is made up of one or more files. (The standard
       input is also a file.)

       You give
as
a command line that has zero or more input file names. The input files are read (from left file name to right)."
28,5,as,"The input files are read (from left file name to right). A
       command-line argument (in any position) that has no special
       meaning is taken to be an input file name. If you give
as
no file names it attempts to read one input file
       from the
as
standard input, which is normally your terminal."
28,6,as,"If you give
as
no file names it attempts to read one input file
       from the
as
standard input, which is normally your terminal. You
       may have to type
ctl-D
to tell
as
there is no more program to
       assemble. Use
--
if you need to explicitly name the standard input file in
       your command line."
28,7,as,"Use
--
if you need to explicitly name the standard input file in
       your command line. If the source is empty,
as
produces a small, empty object file. as
may write warnings and error messages to the standard error
       file (usually your terminal)."
28,8,as,"as
may write warnings and error messages to the standard error
       file (usually your terminal). This should not happen when  a
       compiler runs
as
automatically. Warnings report an assumption
       made so that
as
could keep assembling a flawed program; errors
       report a grave problem that stops the assembly."
28,9,as,"Warnings report an assumption
       made so that
as
could keep assembling a flawed program; errors
       report a grave problem that stops the assembly. If you are invoking
as
via the GNU C compiler, you can use the
-Wa
option to pass arguments through to the assembler. The assembler
       arguments must be separated from each other (and the
-Wa
) by
       commas."
28,10,as,"The assembler
       arguments must be separated from each other (and the
-Wa
) by
       commas. For example:

               gcc -c -g -O -Wa,-alh,-L file.c

       This passes two options to the assembler:
-alh
(emit a listing to
       standard output with high-level and assembly source) and
-L
(retain local symbols in the symbol table). Usually you do not need to use this
-Wa
mechanism, since many
       compiler command-line options are automatically passed to the
       assembler by the compiler."
28,11,as,"For example:

               gcc -c -g -O -Wa,-alh,-L file.c

       This passes two options to the assembler:
-alh
(emit a listing to
       standard output with high-level and assembly source) and
-L
(retain local symbols in the symbol table). Usually you do not need to use this
-Wa
mechanism, since many
       compiler command-line options are automatically passed to the
       assembler by the compiler. (You can call the GNU compiler driver
       with the
-v
option to see precisely what options it passes to each
       compilation pass, including the assembler.)"
29,0,audit2allow,"This utility scans the logs for messages logged when the system
       denied permission for operations, and generates a snippet of
       policy rules which, if loaded into policy, might have allowed
       those operations to succeed. However, this utility only generates
       Type Enforcement (TE) allow rules. Certain permission denials may
       require other kinds of policy changes, e.g."
29,1,audit2allow,"Certain permission denials may
       require other kinds of policy changes, e.g. adding an attribute to
       a type declaration to satisfy an existing constraint, adding a
       role allow rule, or modifying a constraint. The
audit2why
(8)
       utility may be used to diagnose the reason when it is unclear."
29,2,audit2allow,"The
audit2why
(8)
       utility may be used to diagnose the reason when it is unclear. Care must be exercised while acting on the output of this utility
       to ensure that the operations being permitted do not pose a
       security threat. Often it is better to define new domains and/or
       types, or make other structural changes to narrowly allow an
       optimal set of operations to succeed, as opposed to blindly
       implementing the sometimes broad changes recommended by this
       utility."
29,3,audit2allow,"Care must be exercised while acting on the output of this utility
       to ensure that the operations being permitted do not pose a
       security threat. Often it is better to define new domains and/or
       types, or make other structural changes to narrowly allow an
       optimal set of operations to succeed, as opposed to blindly
       implementing the sometimes broad changes recommended by this
       utility. Certain permission denials are not fatal to the
       application, in which case it may be preferable to simply suppress
       logging of the denial via a 'dontaudit' rule rather than an
       'allow' rule."
30,0,as,"GNU
as
is really a family of assemblers. If you use (or have
       used) the GNU assembler on one architecture, you should find a
       fairly similar environment when you use it on another
       architecture. Each version has much in common with the others,
       including object file formats, most assembler directives (often
       called
pseudo-ops
) and assembler syntax."
30,1,as,"Each version has much in common with the others,
       including object file formats, most assembler directives (often
       called
pseudo-ops
) and assembler syntax. as
is primarily intended to assemble the output of the GNU C
       compiler ""gcc"" for use by the linker ""ld"". Nevertheless, we've
       tried to make
as
assemble correctly everything that other
       assemblers for the same machine would assemble."
30,2,as,"Nevertheless, we've
       tried to make
as
assemble correctly everything that other
       assemblers for the same machine would assemble. Any exceptions
       are documented explicitly. This doesn't mean
as
always uses the
       same syntax as another assembler for the same architecture; for
       example, we know of several incompatible versions of 680x0
       assembly language syntax."
30,3,as,"This doesn't mean
as
always uses the
       same syntax as another assembler for the same architecture; for
       example, we know of several incompatible versions of 680x0
       assembly language syntax. Each time you run
as
it assembles exactly one source program. The
       source program is made up of one or more files."
30,4,as,"The
       source program is made up of one or more files. (The standard
       input is also a file.)

       You give
as
a command line that has zero or more input file names. The input files are read (from left file name to right)."
30,5,as,"The input files are read (from left file name to right). A
       command-line argument (in any position) that has no special
       meaning is taken to be an input file name. If you give
as
no file names it attempts to read one input file
       from the
as
standard input, which is normally your terminal."
30,6,as,"If you give
as
no file names it attempts to read one input file
       from the
as
standard input, which is normally your terminal. You
       may have to type
ctl-D
to tell
as
there is no more program to
       assemble. Use
--
if you need to explicitly name the standard input file in
       your command line."
30,7,as,"Use
--
if you need to explicitly name the standard input file in
       your command line. If the source is empty,
as
produces a small, empty object file. as
may write warnings and error messages to the standard error
       file (usually your terminal)."
30,8,as,"as
may write warnings and error messages to the standard error
       file (usually your terminal). This should not happen when  a
       compiler runs
as
automatically. Warnings report an assumption
       made so that
as
could keep assembling a flawed program; errors
       report a grave problem that stops the assembly."
30,9,as,"Warnings report an assumption
       made so that
as
could keep assembling a flawed program; errors
       report a grave problem that stops the assembly. If you are invoking
as
via the GNU C compiler, you can use the
-Wa
option to pass arguments through to the assembler. The assembler
       arguments must be separated from each other (and the
-Wa
) by
       commas."
30,10,as,"The assembler
       arguments must be separated from each other (and the
-Wa
) by
       commas. For example:

               gcc -c -g -O -Wa,-alh,-L file.c

       This passes two options to the assembler:
-alh
(emit a listing to
       standard output with high-level and assembly source) and
-L
(retain local symbols in the symbol table). Usually you do not need to use this
-Wa
mechanism, since many
       compiler command-line options are automatically passed to the
       assembler by the compiler."
30,11,as,"For example:

               gcc -c -g -O -Wa,-alh,-L file.c

       This passes two options to the assembler:
-alh
(emit a listing to
       standard output with high-level and assembly source) and
-L
(retain local symbols in the symbol table). Usually you do not need to use this
-Wa
mechanism, since many
       compiler command-line options are automatically passed to the
       assembler by the compiler. (You can call the GNU compiler driver
       with the
-v
option to see precisely what options it passes to each
       compilation pass, including the assembler.)"
31,0,autofsd-probe,"autofsd-probe
will check the status of the
autofsd
(1) daemon on
       the specified
host
. Unless directed to another
host
by the
-h
option,
autofsd-probe
will contact the
AutoFS
daemon on the local host. The
AutoFS
file system is built on the Remote Procedure Call
       (
RPC(3)
) library routines."
31,1,autofsd-probe,"The
AutoFS
file system is built on the Remote Procedure Call
       (
RPC(3)
) library routines. The
-t
option allows the total timeout
       and retry timeout intervals to be set for all remote procedure
       call operations used with
autofsd-probe
. This option accepts an
       interval argument in the form described in the
PCPIntro(1)
manual
       page."
31,2,autofsd-probe,"This option accepts an
       interval argument in the form described in the
PCPIntro(1)
manual
       page. autofsd-probe
is typically used in an automated fashion from
       within
pmdashping(1)
and in conjunction with
pmie(1)
, for
       monitoring response time and service failure. By default
autofsd-probe
will not produce any output, unless there
       is an error in which case a diagnostic message will be displayed
       and the exit status will indicate the reason for failure."
32,0,autopoint,"Copies standard gettext infrastructure files into a source
       package."
33,0,b2sum,"Print or check BLAKE2b (512-bit) checksums. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
33,1,b2sum,"Mandatory arguments to long options are mandatory for short
       options too. -b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
-l
,
--length
=
BITS
digest length in bits; must not exceed the max for the
              blake2 algorithm and must be a multiple of 8
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in RFC 7693. When checking,
       the input should be a former output of this program."
33,2,b2sum,"When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE. There is no difference between binary mode and text mode on GNU
       systems."
34,0,babeltrace2-help,"The
help
command prints the details and help text of either the
       Babeltrace 2 plugin named
PLUGIN-NAME
or the specific component
       class of type
COMP-CLS-TYPE
named
COMP-CLS-NAME
found in the
       plugin named
PLUGIN-NAME
. See
babeltrace2-intro(7)
to learn more about the Babeltrace 2
       project and its core concepts. The available values for
COMP-CLS-TYPE
are:
source
,
src
Source component class."
34,1,babeltrace2-help,"The available values for
COMP-CLS-TYPE
are:
source
,
src
Source component class. filter
,
flt
Filter component class. sink
Sink component class."
34,2,babeltrace2-help,"filter
,
flt
Filter component class. sink
Sink component class. See âEXAMPLESâ for usage examples."
35,0,babeltrace2-list-plugins,"The
list-plugins
command prints a list of available Babeltrace 2
       plugins along with their component classes and their properties.

       See
babeltrace2-intro(7)
to learn more about the Babeltrace 2
       project and its core concepts."
36,0,babeltrace2-convert,"The
convert
command converts one or more traces to a given format,
       possibly with filters in the conversion path. See
babeltrace2-intro(7)
to learn more about the Babeltrace 2
       project and its core concepts. Note
convert
is the default
babeltrace2(1)
command: you generally
           donât need to specify its name."
36,1,babeltrace2-convert,"Note
convert
is the default
babeltrace2(1)
command: you generally
           donât need to specify its name. The following commands are
           equivalent if the
... part doesnât start with the name of
           another
babeltrace2(1)
command, like
run
or
list-plugins
:

               $ babeltrace2 convert ..."
36,2,babeltrace2-convert,"part doesnât start with the name of
           another
babeltrace2(1)
command, like
run
or
list-plugins
:

               $ babeltrace2 convert ... $ babeltrace2 ... If you need to make sure that you are executing the
convert
command, then use
babeltrace2 convert
explicitly."
36,3,babeltrace2-convert,"If you need to make sure that you are executing the
convert
command, then use
babeltrace2 convert
explicitly. More specifically, the
convert
command creates a conversion graph. A conversion graph is a specialized trace processing graph focused
       on the conversion of one or more traces to another format,
       possibly filtering or modifying their events and other messages in
       the process."
36,4,babeltrace2-convert,"A conversion graph is a specialized trace processing graph focused
       on the conversion of one or more traces to another format,
       possibly filtering or modifying their events and other messages in
       the process. A conversion graph is a linear chain of components
       once the source streams are merged:

           +----------+
           | source 1 @-. +----------+ |
                        |  +-------+
           +----------+ '->@       |    +---------+    +------------+
           | source 2 @--->@ muxer @--->@ trimmer @--->@ debug-info @-."
36,5,babeltrace2-convert,"+----------+ |
                        |  +-------+
           +----------+ '->@       |    +---------+    +------------+
           | source 2 @--->@ muxer @--->@ trimmer @--->@ debug-info @-. +----------+ .->@       |    +---------+    +------------+ |
                        |  +-------+                                  |
           +----------+ |    .----------------------------------------'
           |   ... @-'    |  +---------------+    +------+
           +----------+      '->@ other filters |--->@ sink |
                                +---------------+    +------+

       Note that the trimmer, debugging information, and other filters
       are optional."
36,6,babeltrace2-convert,"@-'    |  +---------------+    +------+
           +----------+      '->@ other filters |--->@ sink |
                                +---------------+    +------+

       Note that the trimmer, debugging information, and other filters
       are optional. See âCreate implicit components from optionsâ to
       learn how to enable them. If you need another trace processing graph layout, then use the
       more flexible
babeltrace2-run(1)
command."
36,7,babeltrace2-convert,"If you need another trace processing graph layout, then use the
       more flexible
babeltrace2-run(1)
command. Like with the
babeltrace2-run(1)
command, you can create
       components explicitly with the
--component
option (see âCreate
       explicit componentsâ). You can also use one of the many specific
convert
command options (see âCreate implicit components from
       optionsâ) and non-option arguments (see âCreate implicit
       components from non-option argumentsâ) to create implicit
       components."
36,8,babeltrace2-convert,"You can also use one of the many specific
convert
command options (see âCreate implicit components from
       optionsâ) and non-option arguments (see âCreate implicit
       components from non-option argumentsâ) to create implicit
       components. An
implicit component
is a component which is created and added to
       the conversion graph without an explicit instantiation through the
--component
option. An implicit component is easier to create than
       an explicit component: this is why the
convert
command exists, as
       you can also create and run a conversion graph with the generic
babeltrace2-run(1)
command."
36,9,babeltrace2-convert,"An implicit component is easier to create than
       an explicit component: this is why the
convert
command exists, as
       you can also create and run a conversion graph with the generic
babeltrace2-run(1)
command. For example, you can specify one or more CTF trace path as
       non-option arguments to pretty-print the merged events to the
       standard output:

           $ babeltrace2 /path/to/trace /path/to/other/trace

       This is the equivalent of creating and connecting together:

       â¢   One
source.ctf.fs
components with its
inputs
initialization
           parameter set to
/path/to/trace
. â¢   One
source.ctf.fs
components with its
inputs
initialization
           parameter set to
/path/to/other/trace
."
36,10,babeltrace2-convert,"â¢   One
source.ctf.fs
components with its
inputs
initialization
           parameter set to
/path/to/other/trace
. â¢   A
filter.utils.muxer
component. â¢   A
sink.text.pretty
component."
36,11,babeltrace2-convert,"â¢   A
sink.text.pretty
component. This creates the following conversion graph:

           +------------+    +-----------------+    +------------------+
           | src.ctf.fs |    | flt.utils.muxer |    | sink.text.pretty |
           |  [ctf-fs]  |    |     [muxer]     |    |     [pretty]     |
           |            |    |                 |    |                  |
           |    stream0 @--->@ in0         out @--->@ in               |
           |    stream1 @--->@ in1             |    +------------------+
           |    stream2 @--->@ in2             |
           |    stream3 @--->@ in3             |
           +------------+    |                 |
                             |                 |
           +------------+    |                 |
           | src.ctf.fs |    |                 |
           | [ctf-fs-2] |    |                 |
           |            |    |                 |
           |    stream0 @--->@ in4             |
           |    stream1 @--->@ in5             |
           +------------+    @ in6             |
                             +-----------------+

       Itâs equivalent to the following
babeltrace2-run(1)
command line:

           $ babeltrace2 run --component=ctf-fs:src.ctf.fs \
                             --params='inputs=[""/path/to/trace""] \
                             --component=ctf-fs-2:src.ctf.fs \
                             --params='inputs=[""/path/to/other/trace""] \
                             --component=muxer:filter.utils.muxer \
                             --component=pretty:sink.text.pretty \
                             --connect=ctf*:muxer --connect=muxer:pretty

       You can use the
--run-args
option to make the
convert
command
       print its equivalent
run
command arguments instead of creating and
       running the conversion graph. The printed arguments are escaped
       for shells, which means you can use them as is on the command line
       and possibly add more options to the
run
command:

           $ babeltrace2 run $(babeltrace2 --run-args /path/to/trace) ..."
36,12,babeltrace2-convert,"The printed arguments are escaped
       for shells, which means you can use them as is on the command line
       and possibly add more options to the
run
command:

           $ babeltrace2 run $(babeltrace2 --run-args /path/to/trace) ... The
--run-args-0
option is like the
--run-args
option, but the
       printed arguments are NOT escaped and theyâre separated by a null
       character instead of a space. This is useful if the resulting
       arguments arenât the direct input of a shell, for example if
       passed to
xargs -0
."
36,13,babeltrace2-convert,"This is useful if the resulting
       arguments arenât the direct input of a shell, for example if
       passed to
xargs -0
. See âEXAMPLESâ for usage examples. Create explicit components
To explicitly create a component, use the
--component
option."
36,14,babeltrace2-convert,"Create explicit components
To explicitly create a component, use the
--component
option. This
       option specifies:

       â¢
Optional
: The name of the component. â¢   The type of the component class to instantiate: source,
           filter, or sink."
36,15,babeltrace2-convert,"â¢   The type of the component class to instantiate: source,
           filter, or sink. â¢   The name of the plugin in which to find the component class to
           instantiate. â¢   The name of the component class to instantiate."
36,16,babeltrace2-convert,"â¢   The name of the component class to instantiate. You can use the
--component
option multiple times to create
       multiple components. You can instantiate the same component class
       multiple times as different component instances."
36,17,babeltrace2-convert,"You can instantiate the same component class
       multiple times as different component instances. Immediately following a
--component
option on the command line,
       the created component is known as the
current component
(until the
       next
--component
option or non-option argument). The following command-line options apply to the current component:
--log-level
=
LVL
Set the log level of the current component to
LVL
."
36,18,babeltrace2-convert,"The following command-line options apply to the current component:
--log-level
=
LVL
Set the log level of the current component to
LVL
. --params
=
PARAMS
Add
PARAMS
to the initialization parameters of the current
           component. If
PARAMS
contains a key which exists in the initialization
           parameters of the current component, then replace the
           parameter."
36,19,babeltrace2-convert,"If
PARAMS
contains a key which exists in the initialization
           parameters of the current component, then replace the
           parameter. See âEXAMPLESâ for usage examples. Create implicit components from non-option arguments
When you specify a non-option argument to the
convert
command, it
       tries to find one or more components which can handle this
       argument."
36,20,babeltrace2-convert,"Create implicit components from non-option arguments
When you specify a non-option argument to the
convert
command, it
       tries to find one or more components which can handle this
       argument. For example, with this command line:

           $ babeltrace2 /path/to/trace

       If
/path/to/trace
is a CTF trace directory, then the
convert
command creates a
source.ctf.fs
component to handle this specific
       trace. This automatic source component discovery mechanism is possible
       thanks to component classes which support the
babeltrace.support-
info
query object (see
babeltrace2-query-babeltrace.support-info(7)
)."
36,21,babeltrace2-convert,"This automatic source component discovery mechanism is possible
       thanks to component classes which support the
babeltrace.support-
info
query object (see
babeltrace2-query-babeltrace.support-info(7)
). The non-option argument can be a directory. If no component can
       handle that specific directory, then the
convert
command traverses
       that directory and recursively tries to find compatible components
       for each file and subdirectory."
36,22,babeltrace2-convert,"If no component can
       handle that specific directory, then the
convert
command traverses
       that directory and recursively tries to find compatible components
       for each file and subdirectory. This means that a single
       non-option argument can lead to the creation of many implicit
       components. The following command-line options apply to ALL the implicit
       components created from the last non-option argument:
--log-level
=
LVL
Set the log level of those implicit components to
LVL
."
36,23,babeltrace2-convert,"The following command-line options apply to ALL the implicit
       components created from the last non-option argument:
--log-level
=
LVL
Set the log level of those implicit components to
LVL
. --params
=
PARAMS
Add
PARAMS
to the initialization parameters of those implicit
           components. For a given implicit component, if
PARAMS
contains a key which
           exists in the initialization parameters of this component,
           then replace the parameter."
36,24,babeltrace2-convert,"For a given implicit component, if
PARAMS
contains a key which
           exists in the initialization parameters of this component,
           then replace the parameter. Note that itâs also possible for two non-option arguments to cause
       the creation of a single implicit component. For example, if you
       specify:

           $ babeltrace2 /path/to/chunk1 /path/to/chunk2

       where
/path/to/chunk1
and
/path/to/chunk2
are paths to chunks of
       the same logical CTF trace, then the
convert
command creates a
       single
source.ctf.fs
component which receives both paths at
       initialization time."
36,25,babeltrace2-convert,"For example, if you
       specify:

           $ babeltrace2 /path/to/chunk1 /path/to/chunk2

       where
/path/to/chunk1
and
/path/to/chunk2
are paths to chunks of
       the same logical CTF trace, then the
convert
command creates a
       single
source.ctf.fs
component which receives both paths at
       initialization time. When this happens, any
--log-level
or
--params
option that you specify to one of them applies to the
       single implicit component. For example:

           $ babeltrace2 /path/to/chunk1 --params=clock-class-offset-s=450 \
                         /path/to/chunk2 --params=clock-class-offset-ns=98 \
                         --log-level=INFO

       Here, the single implicit component gets both
clock-class-offset-s
and
clock-class-offset-ns
initialization parameters, as well as
       the INFO log level."
36,26,babeltrace2-convert,"For example:

           $ babeltrace2 /path/to/chunk1 --params=clock-class-offset-s=450 \
                         /path/to/chunk2 --params=clock-class-offset-ns=98 \
                         --log-level=INFO

       Here, the single implicit component gets both
clock-class-offset-s
and
clock-class-offset-ns
initialization parameters, as well as
       the INFO log level. For backward compatibility with the
babeltrace
(1) program, the
convert
command ignores any non-option argument which does not
       cause the creation of any component. In that case, it emits a
       warning log statement and continues."
36,27,babeltrace2-convert,"In that case, it emits a
       warning log statement and continues. Create implicit components from options
There are many ways to create implicit components from options
       with the
convert
command:

       â¢   To create an implicit
filter.utils.trimmer
component (stream
           trimmer), specify the
--begin
,
--end
, or
--timerange
option. Examples:

               $ babeltrace2 /path/to/trace --begin=22:14:38 --end=22:15:07

               $ babeltrace2 /path/to/trace --timerange=22:14:38,22:15:07

               $ babeltrace2 /path/to/trace --end=12:31:04.882928015

       â¢   To create an implicit
filter.lttng-utils.debug-info
(add
           debugging information to compatible LTTng events), specify any
           of the
--debug-info
,
--debug-info-dir
,
--debug-info-full-path
,
           or
--debug-info-target-prefix
options."
36,28,babeltrace2-convert,"Examples:

               $ babeltrace2 /path/to/trace --begin=22:14:38 --end=22:15:07

               $ babeltrace2 /path/to/trace --timerange=22:14:38,22:15:07

               $ babeltrace2 /path/to/trace --end=12:31:04.882928015

       â¢   To create an implicit
filter.lttng-utils.debug-info
(add
           debugging information to compatible LTTng events), specify any
           of the
--debug-info
,
--debug-info-dir
,
--debug-info-full-path
,
           or
--debug-info-target-prefix
options. Examples:

               $ babeltrace2 /path/to/trace --debug-info

               $ babeltrace2 /path/to/trace \
                             --debug-info-target-prefix=/tmp/tgt-root

               $ babeltrace2 /path/to/trace --debug-info-full-path

       â¢   To create an implicit
sink.text.pretty
component
           (pretty-printing text output to the standard output or to a
           file), specify no other sink components, explicit or implicit. The implicit
sink.text.pretty
component exists by default."
36,29,babeltrace2-convert,"The implicit
sink.text.pretty
component exists by default. If
           any other explicit or implicit sink component exists, then the
convert
command doesnât automatically create the implicit
sink.text.pretty
component. The
--clock-cycles
,
--clock-date
,
--clock-gmt
,
--clock-
seconds
,
--color
,
--fields
,
--names
, and
--no-delta
options
           all apply to the implicit
sink.text.pretty
component."
36,30,babeltrace2-convert,"The
--clock-cycles
,
--clock-date
,
--clock-gmt
,
--clock-
seconds
,
--color
,
--fields
,
--names
, and
--no-delta
options
           all apply to the implicit
sink.text.pretty
component. The
--output
option without
--output-format
=
ctf
makes the
           implicit
sink.text.pretty
component write its content to a
           file, except the warnings for backward compatibility with the
babeltrace
(1) program. Examples:

               $ babeltrace2 /path/to/trace

               $ babeltrace2 /path/to/trace --no-delta

               $ babeltrace2 /path/to/trace --output=/tmp/pretty-out

       â¢   To create an implicit
sink.utils.dummy
component (no output),
           specify the
--output-format
=
dummy
option."
36,31,babeltrace2-convert,"Examples:

               $ babeltrace2 /path/to/trace

               $ babeltrace2 /path/to/trace --no-delta

               $ babeltrace2 /path/to/trace --output=/tmp/pretty-out

       â¢   To create an implicit
sink.utils.dummy
component (no output),
           specify the
--output-format
=
dummy
option. Example:

               $ babeltrace2 /path/to/trace --output-format=dummy

       â¢   To create an implicit
sink.ctf.fs
component (CTF traces
           written to the file system), specify the
--output-format
=
ctf
and the
--output
=
DIR
(base output directory) options. Example:

               $ babeltrace2 /path/to/input/trace --output-format=ctf \
                             --output=my-traces

           As of this version, a
sink.ctf.fs
component generates CTF 2
           (see <
https://diamon.org/ctf/
>) traces by default."
36,32,babeltrace2-convert,"Example:

               $ babeltrace2 /path/to/input/trace --output-format=ctf \
                             --output=my-traces

           As of this version, a
sink.ctf.fs
component generates CTF 2
           (see <
https://diamon.org/ctf/
>) traces by default. To write
           CTF 1.8 (see <
https://diamon.org/ctf/v1.8.3/
>) traces, create
           an explicit
sink.ctf.fs
component (see âCreate explicit
           componentsâ) and use the
ctf-version=""1""
initialization
           parameter:

               $ babeltrace2 /path/to/input/trace --component=sink.ctf.fs \
                             --params='path=""my-traces"",ctf-version=""1""'

       You can combine multiple methods to create multiple implicit
       components. For example, you can trim an LTTng (CTF) trace, add
       debugging information to it, and write it as another CTF trace:

           $ babeltrace2 /path/to/input/trace --timerange=22:14:38,22:15:07 \
                         --debug-info --output-format=ctf --output=out-dir

       The equivalent
babeltrace2-run(1)
command of this
convert
command
       is:

           $ babeltrace2 run --component=auto-disc-source-ctf-fs:source.ctf.fs \
                             --params='inputs=[""/path/to/input/trace""]' \
                             --component=sink-ctf-fs:sink.ctf.fs \
                             --params='path=""out-dir""' \
                             --component=muxer:filter.utils.muxer \
                             --component=trimmer:filter.utils.trimmer \
                             --params='begin=""22:14:38""' \
                             --params='end=""22:15:07""' \
                             --component=debug-info:filter.lttng-utils.debug-info \
                             --connect=auto-disc-source-ctf-fs:muxer \
                             --connect=muxer:trimmer \
                             --connect=trimmer:debug-info \
                             --connect=debug-info:sink-ctf-fs

       The order of the implicit component options documented in this
       subsection isnât significant."
36,33,babeltrace2-convert,"To write
           CTF 1.8 (see <
https://diamon.org/ctf/v1.8.3/
>) traces, create
           an explicit
sink.ctf.fs
component (see âCreate explicit
           componentsâ) and use the
ctf-version=""1""
initialization
           parameter:

               $ babeltrace2 /path/to/input/trace --component=sink.ctf.fs \
                             --params='path=""my-traces"",ctf-version=""1""'

       You can combine multiple methods to create multiple implicit
       components. For example, you can trim an LTTng (CTF) trace, add
       debugging information to it, and write it as another CTF trace:

           $ babeltrace2 /path/to/input/trace --timerange=22:14:38,22:15:07 \
                         --debug-info --output-format=ctf --output=out-dir

       The equivalent
babeltrace2-run(1)
command of this
convert
command
       is:

           $ babeltrace2 run --component=auto-disc-source-ctf-fs:source.ctf.fs \
                             --params='inputs=[""/path/to/input/trace""]' \
                             --component=sink-ctf-fs:sink.ctf.fs \
                             --params='path=""out-dir""' \
                             --component=muxer:filter.utils.muxer \
                             --component=trimmer:filter.utils.trimmer \
                             --params='begin=""22:14:38""' \
                             --params='end=""22:15:07""' \
                             --component=debug-info:filter.lttng-utils.debug-info \
                             --connect=auto-disc-source-ctf-fs:muxer \
                             --connect=muxer:trimmer \
                             --connect=trimmer:debug-info \
                             --connect=debug-info:sink-ctf-fs

       The order of the implicit component options documented in this
       subsection isnât significant. See âEXAMPLESâ for more examples."
37,0,babeltrace2-query,"The
query
command queries the object named
OBJECT
from the
       component class named
COMP-CLS-NAME
of the type
COMP-CLS-TYPE
found in the Babeltrace 2 plugin named
PLUGIN-NAME
and prints the
       results. See
babeltrace2-intro(7)
to learn more about the Babeltrace 2
       project and its core concepts. The available values for
COMP-CLS-TYPE
are:
source
,
src
Source component class."
37,1,babeltrace2-query,"The available values for
COMP-CLS-TYPE
are:
source
,
src
Source component class. filter
,
flt
Filter component class. sink
Sink component class."
37,2,babeltrace2-query,"sink
Sink component class. The exact object names and the parameters that a given component
       class expects are described in its own documentation. babeltrace2-help(1)
can generally provide this information."
37,3,babeltrace2-query,"babeltrace2-help(1)
can generally provide this information. You can use the
--params
option to pass parameters to the query
       operation of the component class. The output of the
query
command can look like YAML (see
       <
https://yaml.org/
>), but itâs not guaranteed to be
       YAML-compliant."
37,4,babeltrace2-query,"You can use the
--params
option to pass parameters to the query
       operation of the component class. The output of the
query
command can look like YAML (see
       <
https://yaml.org/
>), but itâs not guaranteed to be
       YAML-compliant. See âEXAMPLESâ for usage examples."
38,0,base32,"Base32 encode or decode FILE, or standard input, to standard
       output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
38,1,base32,"Mandatory arguments to long options are mandatory for short
       options too. -d
,
--decode
decode data
-i
,
--ignore-garbage
when decoding, ignore non-alphabet characters
-w
,
--wrap
=
COLS
wrap encoded lines after COLS character (default 76). Use
              0 to disable line wrapping
--help
display this help and exit
--version
output version information and exit

       The data are encoded as described for the base32 alphabet in RFC
       4648."
38,2,base32,"Use
              0 to disable line wrapping
--help
display this help and exit
--version
output version information and exit

       The data are encoded as described for the base32 alphabet in RFC
       4648. When decoding, the input may contain newlines in addition
       to the bytes of the formal base32 alphabet. Use
--ignore-garbage
to attempt to recover from any other non-alphabet bytes in the
       encoded stream."
39,0,awk,"The
awk
utility shall execute programs written in the
awk
programming language, which is specialized for textual data
       manipulation. An
awk
program is a sequence of patterns and
       corresponding actions. When input is read that matches a pattern,
       the action associated with that pattern is carried out."
39,1,awk,"When input is read that matches a pattern,
       the action associated with that pattern is carried out. Input shall be interpreted as a sequence of records. By default, a
       record is a line, less its terminating <newline>, but this can be
       changed by using the
RS
built-in variable."
39,2,awk,"By default, a
       record is a line, less its terminating <newline>, but this can be
       changed by using the
RS
built-in variable. Each record of input
       shall be matched in turn against each pattern in the program. For
       each pattern matched, the associated action shall be executed."
39,3,awk,"For
       each pattern matched, the associated action shall be executed. The
awk
utility shall interpret each input record as a sequence of
       fields where, by default, a field is a string of non-<blank>
       non-<newline> characters. This default <blank> and <newline> field
       delimiter can be changed by using the
FS
built-in variable or the
-F
sepstring
option."
39,4,awk,"This default <blank> and <newline> field
       delimiter can be changed by using the
FS
built-in variable or the
-F
sepstring
option. The
awk
utility shall denote the first field
       in a record $1, the second $2, and so on. The symbol $0 shall
       refer to the entire record; setting any other field causes the re-
       evaluation of $0."
39,5,awk,"The
awk
utility shall denote the first field
       in a record $1, the second $2, and so on. The symbol $0 shall
       refer to the entire record; setting any other field causes the re-
       evaluation of $0. Assigning to $0 shall reset the values of all
       other fields and the
NF
built-in variable."
40,0,base64,"Base64 encode or decode FILE, or standard input, to standard
       output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
40,1,base64,"Mandatory arguments to long options are mandatory for short
       options too. -d
,
--decode
decode data
-i
,
--ignore-garbage
when decoding, ignore non-alphabet characters
-w
,
--wrap
=
COLS
wrap encoded lines after COLS character (default 76). Use
              0 to disable line wrapping
--help
display this help and exit
--version
output version information and exit

       The data are encoded as described for the base64 alphabet in RFC
       4648."
40,2,base64,"Use
              0 to disable line wrapping
--help
display this help and exit
--version
output version information and exit

       The data are encoded as described for the base64 alphabet in RFC
       4648. When decoding, the input may contain newlines in addition
       to the bytes of the formal base64 alphabet. Use
--ignore-garbage
to attempt to recover from any other non-alphabet bytes in the
       encoded stream."
41,0,babeltrace2-run,"The
run
command creates a Babeltrace 2 trace processing graph and
       runs it. See
babeltrace2-intro(7)
to learn more about the Babeltrace 2
       project and its core concepts. The
run
command dynamically loads Babeltrace 2 plugins which
       supply component classes."
41,1,babeltrace2-run,"The
run
command dynamically loads Babeltrace 2 plugins which
       supply component classes. With the
run
command, you specify which
       component classes to instantiate as components and how to connect
       them. The steps to write a
babeltrace2 run
command line are:

        1."
41,2,babeltrace2-run,"The steps to write a
babeltrace2 run
command line are:

        1. Specify which component classes to instantiate as components
           with many
--component
options and how to configure them. This is the
COMPONENTS
part of the synopsis."
41,3,babeltrace2-run,"This is the
COMPONENTS
part of the synopsis. See âCreate
           componentsâ to learn more. 2."
41,4,babeltrace2-run,"2. Specify how to connect components together with one or more
--connect
options. See âConnect componentsâ to learn more."
41,5,babeltrace2-run,"See âConnect componentsâ to learn more. Note
The
babeltrace2-convert(1)
command is a specialization of the
run
command for the very common case of converting one or more
           traces: it generates a
run
command line and executes it. You
           can use its
--run-args
or
--run-args-0
option to make it print
           the equivalent
run
command line instead."
41,6,babeltrace2-run,"You
           can use its
--run-args
or
--run-args-0
option to make it print
           the equivalent
run
command line instead. Create components
To create a component, use the
--component
option. This option
       specifies:

       â¢   The name of the component, unique amongst all the component
           names of the trace processing graph."
41,7,babeltrace2-run,"This option
       specifies:

       â¢   The name of the component, unique amongst all the component
           names of the trace processing graph. â¢   The type of the component class to instantiate: source,
           filter, or sink. â¢   The name of the plugin in which to find the component class to
           instantiate."
41,8,babeltrace2-run,"â¢   The name of the plugin in which to find the component class to
           instantiate. â¢   The name of the component class to instantiate. Use the
--component
option multiple times to create multiple
       components."
41,9,babeltrace2-run,"Use the
--component
option multiple times to create multiple
       components. You can instantiate the same component class multiple
       times as different components. At any point in the command line, the
--base-params
sets the
       current base initialization parameters and the
--reset-base-params
resets them."
41,10,babeltrace2-run,"At any point in the command line, the
--base-params
sets the
       current base initialization parameters and the
--reset-base-params
resets them. When you specify a
--component
option, its initial
       initialization parameters are a copy of the current base
       initialization parameters. Immediately following a
--component
option on the command line,
       the created component is known as the
current component
(until the
       next
--component
option)."
41,11,babeltrace2-run,"Immediately following a
--component
option on the command line,
       the created component is known as the
current component
(until the
       next
--component
option). The
--params
=
PARAMS
option adds parameters to the initialization
       parameters of the current component. If
PARAMS
contains a key
       which exists in the initialization parameters of the current
       component, then this parameter is replaced."
41,12,babeltrace2-run,"If
PARAMS
contains a key
       which exists in the initialization parameters of the current
       component, then this parameter is replaced. Connect components
The components which you create from component classes with the
--component
option (see âCreate componentsâ) add input and output
ports
depending on their type. An output port is from where
       messages, like trace events, are sent."
41,13,babeltrace2-run,"An output port is from where
       messages, like trace events, are sent. An input port is where
       messages are received. For a given component, each port has a
       unique name."
41,14,babeltrace2-run,"For a given component, each port has a
       unique name. The purpose of the
run
command is to create a trace processing
       graph, that is, to know which component ports to connect together. The command achieves this with the help of the connection rules
       that you provide with one or more
--connect
=
CONN-RULE
options."
41,15,babeltrace2-run,"The command achieves this with the help of the connection rules
       that you provide with one or more
--connect
=
CONN-RULE
options. The format of
CONN-RULE
is:
UP-COMP-PAT
[. UP-PORT-PAT
]:
DOWN-COMP-PAT
[."
41,16,babeltrace2-run,"UP-PORT-PAT
]:
DOWN-COMP-PAT
[. DOWN-PORT-PAT
]
UP-COMP-PAT
Upstream component name pattern. UP-PORT-PAT
Upstream (output) port name pattern."
41,17,babeltrace2-run,"UP-PORT-PAT
Upstream (output) port name pattern. DOWN-COMP-PAT
Downstream component name pattern. DOWN-PORT-PAT
Downstream (input) port name pattern."
41,18,babeltrace2-run,"DOWN-PORT-PAT
Downstream (input) port name pattern. When a source or filter component adds a new output port within
       the processing graph, the
run
command does the following to find
       an input port to connect it to:

           For each connection rule (--connect options, in order):
             If the component name of the output port matches UP-COMP-PAT and the
             output port name matches UP-PORT-PAT:
               For each component COMP in the trace processing graph:
                 If the name of COMP matches DOWN-COMP-PAT:
                   Select the first input port of COMP of which the name matches
                   DOWN-PORT-PAT, or fail with no match. No possible connection: fail with no match."
41,19,babeltrace2-run,"No possible connection: fail with no match. UP-COMP-PAT
,
UP-PORT-PAT
,
DOWN-COMP-PAT
, and
DOWN-PORT-PAT
are
       globbing patterns where only the wildcard character,
*
, is
       special: it matches zero or more characters. You must escape the
*
,
?"
41,20,babeltrace2-run,"You must escape the
*
,
? ,
[
,
. ,
:
, and
\
characters with
\
."
41,21,babeltrace2-run,",
:
, and
\
characters with
\
. When you donât specify
UP-PORT-PAT
or
DOWN-PORT-PAT
, theyâre
       equivalent to
*
. You can leverage this connection mechanism to specify fallbacks
       with a careful use of wildcards, as the order of the
--connect
options on the command line is significant."
41,22,babeltrace2-run,"You can leverage this connection mechanism to specify fallbacks
       with a careful use of wildcards, as the order of the
--connect
options on the command line is significant. For example:

           --connect='A.out*:B.in*' --connect=A:B --connect='*:C'

       With those connection rules, the
run
command connects:

       â¢   Any output port of which the name starts with
out
of component
A
to the first input port of which the name starts with
in
of
           component
B
. â¢   Any other output port of component
A
to the first available
           input port of component
B
."
41,23,babeltrace2-run,"â¢   Any other output port of component
A
to the first available
           input port of component
B
. â¢   Any other output port (of any component except
A
) to the first
           available input port of component
C
. The
run
command fails when it cannot find an input port to which
       to connect a given output port using the provided connection
       rules."
41,24,babeltrace2-run,"â¢   Any other output port (of any component except
A
) to the first
           available input port of component
C
. The
run
command fails when it cannot find an input port to which
       to connect a given output port using the provided connection
       rules. See âEXAMPLESâ for more examples."
42,0,babeltrace2,"babeltrace2
is an open-source trace converter and processor
       command-line program. The tool can open one or more traces and
       convert between multiple formats, possibly with one or more
       filters in the conversion path, and perform other operations
       depending on the command
CMD
(see âCOMMANDSâ). Note
You might be looking for the manual page of the
babeltrace2-convert(1)
; the
convert
command is the default
           command of
babeltrace2
and is backward compatible with
babeltrace
(1)."
42,1,babeltrace2,"Note
You might be looking for the manual page of the
babeltrace2-convert(1)
; the
convert
command is the default
           command of
babeltrace2
and is backward compatible with
babeltrace
(1). See âEXAMPLESâ for
convert
command examples. See
babeltrace2-intro(7)
to learn more about the Babeltrace 2
       project and its core concepts."
42,2,babeltrace2,"See
babeltrace2-intro(7)
to learn more about the Babeltrace 2
       project and its core concepts. Most of the
babeltrace2
commands load Babeltrace 2 plugins to
       perform their operation. The search path for Babeltrace 2 plugins
       is, in this order:

        1."
42,3,babeltrace2,"The search path for Babeltrace 2 plugins
       is, in this order:

        1. The colon-separated (or semicolon, on Windows) list of
           directories in the
BABELTRACE_PLUGIN_PATH
environment
           variable. 2."
42,4,babeltrace2,"2. The colon-separated (or semicolon, on Windows) list of
           directories in the
--plugin-path
option. 3."
42,5,babeltrace2,"3. $HOME/.local/lib/babeltrace2/plugins
4. /usr/local/lib/babeltrace2/plugins
You can use the
babeltrace2-list-plugins(1)
command to dynamically
       list the available plugins and what they offer."
42,6,babeltrace2,"$HOME/.local/lib/babeltrace2/plugins
4. /usr/local/lib/babeltrace2/plugins
You can use the
babeltrace2-list-plugins(1)
command to dynamically
       list the available plugins and what they offer. See âPROJECTâS
       PLUGINSâ for a list of plugins shipped with Babeltrace 2."
43,0,basename,"The
string
operand shall be treated as a pathname, as defined in
       the Base Definitions volume of POSIX.1â2017,
Section 3.271
,
Pathname
. The string
string
shall be converted to the filename
       corresponding to the last pathname component in
string
and then
       the suffix string
suffix
, if present, shall be removed. This shall
       be done by performing actions equivalent to the following steps in
       order:

        1."
43,1,basename,"This shall
       be done by performing actions equivalent to the following steps in
       order:

        1. If
string
is a null string, it is unspecified whether the
           resulting string is
'.'
or a null string. In either case,
           skip steps 2 through 6."
43,2,basename,"In either case,
           skip steps 2 through 6. 2. If
string
is
""//""
, it is implementation-defined whether steps
           3 to 6 are skipped or processed."
43,3,basename,"If
string
is
""//""
, it is implementation-defined whether steps
           3 to 6 are skipped or processed. 3. If
string
consists entirely of <slash> characters,
string
shall be set to a single <slash> character."
43,4,basename,"If
string
consists entirely of <slash> characters,
string
shall be set to a single <slash> character. In this case, skip
           steps 4 to 6. 4."
43,5,basename,"4. If there are any trailing <slash> characters in
string
, they
           shall be removed. 5."
43,6,basename,"5. If there are any <slash> characters remaining in
string
, the
           prefix of
string
up to and including the last <slash>
           character in
string
shall be removed. 6."
43,7,basename,"6. If the
suffix
operand is present, is not identical to the
           characters remaining in
string
, and is identical to a suffix
           of the characters remaining in
string
, the suffix
suffix
shall
           be removed from
string
. Otherwise,
string
is not modified by
           this step."
43,8,basename,"Otherwise,
string
is not modified by
           this step. It shall not be considered an error if
suffix
is
           not found in
string
. The resulting string shall be written to standard output."
44,0,basename,"Print NAME with any leading directory components removed. If
       specified, also remove a trailing SUFFIX. Mandatory arguments to long options are mandatory for short
       options too."
44,1,basename,"If
       specified, also remove a trailing SUFFIX. Mandatory arguments to long options are mandatory for short
       options too. -a
,
--multiple
support multiple arguments and treat each as a NAME
-s
,
--suffix
=
SUFFIX
remove a trailing SUFFIX; implies
-a
-z
,
--zero
end each output line with NUL, not newline
--help
display this help and exit
--version
output version information and exit"
45,0,basenc,"basenc encode or decode FILE, or standard input, to standard
       output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
45,1,basenc,"Mandatory arguments to long options are mandatory for short
       options too. --base64
same as 'base64' program (RFC4648 section 4)
--base64url
file- and url-safe base64 (RFC4648 section 5)
--base32
same as 'base32' program (RFC4648 section 6)
--base32hex
extended hex alphabet base32 (RFC4648 section 7)
--base16
hex encoding (RFC4648 section 8)
--base2msbf
bit string with most significant bit (msb) first
--base2lsbf
bit string with least significant bit (lsb) first
-d
,
--decode
decode data
-i
,
--ignore-garbage
when decoding, ignore non-alphabet characters
-w
,
--wrap
=
COLS
wrap encoded lines after COLS character (default 76). Use
              0 to disable line wrapping
--z85
ascii85-like encoding (ZeroMQ spec:32/Z85); when encoding,
              input length must be a multiple of 4; when decoding, input
              length must be a multiple of 5
--help
display this help and exit
--version
output version information and exit

       When decoding, the input may contain newlines in addition to the
       bytes of the formal alphabet."
45,2,basenc,"--base64
same as 'base64' program (RFC4648 section 4)
--base64url
file- and url-safe base64 (RFC4648 section 5)
--base32
same as 'base32' program (RFC4648 section 6)
--base32hex
extended hex alphabet base32 (RFC4648 section 7)
--base16
hex encoding (RFC4648 section 8)
--base2msbf
bit string with most significant bit (msb) first
--base2lsbf
bit string with least significant bit (lsb) first
-d
,
--decode
decode data
-i
,
--ignore-garbage
when decoding, ignore non-alphabet characters
-w
,
--wrap
=
COLS
wrap encoded lines after COLS character (default 76). Use
              0 to disable line wrapping
--z85
ascii85-like encoding (ZeroMQ spec:32/Z85); when encoding,
              input length must be a multiple of 4; when decoding, input
              length must be a multiple of 5
--help
display this help and exit
--version
output version information and exit

       When decoding, the input may contain newlines in addition to the
       bytes of the formal alphabet. Use
--ignore-garbage
to attempt to
       recover from any other non-alphabet bytes in the encoded stream."
46,0,batch,"The
batch
utility shall read commands from standard input and
       schedule them for execution in a batch queue. It shall be the
       equivalent of the command:

           at -q b -m now

       where queue
b
is a special
at
queue, specifically for batch jobs. Batch jobs shall be submitted to the batch queue with no time
       constraints and shall be run by the system using algorithms, based
       on unspecified factors, that may vary with each invocation of
batch
."
46,1,batch,"Batch jobs shall be submitted to the batch queue with no time
       constraints and shall be run by the system using algorithms, based
       on unspecified factors, that may vary with each invocation of
batch
. Users shall be permitted to use
batch
if their name appears in the
       file
at.allow
which is located in an implementation-defined
       directory. If that file does not exist, the file
at.deny
, which
       is located in an implementation-defined directory, shall be
       checked to determine whether the user shall be denied access to
batch
."
46,2,batch,"If that file does not exist, the file
at.deny
, which
       is located in an implementation-defined directory, shall be
       checked to determine whether the user shall be denied access to
batch
. If neither file exists, only a process with appropriate
       privileges shall be allowed to submit a job. If only
at.deny
exists and is empty, global usage shall be permitted."
46,3,batch,"If neither file exists, only a process with appropriate
       privileges shall be allowed to submit a job. If only
at.deny
exists and is empty, global usage shall be permitted. The
at.allow
and
at.deny
files shall consist of one user name per line."
47,0,bg,"If job control is enabled (see the description of
set
-m
), the
bg
utility shall resume suspended jobs from the current environment
       (see
Section 2.12
,
Shell Execution Environment
) by running them as
       background jobs. If the job specified by
job_id
is already a
       running background job, the
bg
utility shall have no effect and
       shall exit successfully.

       Using
bg
to place a job into the background shall cause its
       process ID to become ``known in the current shell execution
       environment'', as if it had been started as an asynchronous list;
       see
Section 2.9.3.1
,
Examples
."
48,0,bits,"The
bits
utility converts bit masks into various formats. It
       supports combining multiple masks together using bitwise
       operations."
49,0,bno_plot,"bno_plot is a visualization tool for the block layer IO tracing
       tool called blktrace(8). As noted in its documentation, blktrace
       is a block layer IO tracing mechanism which provides detailed
       information about request queue operations up to user space. bno_plot utilizes gnuplot to generate a 3D plot of the block
       number output from btt."
49,1,bno_plot,"bno_plot utilizes gnuplot to generate a 3D plot of the block
       number output from btt. If no
<files>
are specified, it will
       utilize all files generated after btt was run with
-B blknos
(meaning: all files of the form
blknos*[rw].dat
). The
-K
option forces bno_plot to put the keys below the graph."
49,2,bno_plot,"The
-K
option forces bno_plot to put the keys below the graph. If
       it is not specified, all keys for input files are put in the upper
       right corner of the graph. If the number of devices exceed 10,
       then bno_plot will automatically push the keys under the graph."
49,3,bno_plot,"If the number of devices exceed 10,
       then bno_plot will automatically push the keys under the graph. To use this utility, the gnuplot package needs to be installed. To exit the plotter, enter 'quit' or ^D at the 'gnuplot> ' prompt."
50,0,blkrawverify,"The
blkrawverify
utility can be used to verify data retrieved via
blktrace
. It will check for valid event formats, forward
       progressing sequence numbers and time stamps, also does reasonable
       checks for other potential issues within individual events.

       Errors found will be tracked in <
dev
>.verify.out."
51,0,bootctl,"bootctl
can check the EFI firmware and boot loader status, list
       and manage available boot loaders and boot loader entries, and
       install, update, or remove the
systemd-boot(7)
boot loader on the
       current system."
52,0,bc,"The
bc
utility shall implement an arbitrary precision calculator.
       It shall take input from any files given, then read from the
       standard input. If the standard input and standard output to
bc
are attached to a terminal, the invocation of
bc
shall be
       considered to be
interactive
, causing behavioral constraints
       described in the following sections."
53,0,blkparse,"The
blkparse
utility will attempt to combine streams of events for
       various devices on various CPUs, and produce a formatted output of
       the event information. Specifically, it will take the (machine-
       readable) output of the
blktrace
utility and convert it to a
       nicely formatted and human-readable form. As with
blktrace
, some details concerning
blkparse
will help in
       understanding the command line options presented below."
53,1,blkparse,"As with
blktrace
, some details concerning
blkparse
will help in
       understanding the command line options presented below. - By default,
blkparse
expects to run in a post-processing mode;
         one where the trace events have been saved by a previous run of
         blktrace, and blkparse is combining event streams and dumping
         formatted data. blkparse may be run in a live manner concurrently with blktrace
         by specifying
-i -
to blkparse, and combining it with the live
         option for blktrace."
53,2,blkparse,"blkparse may be run in a live manner concurrently with blktrace
         by specifying
-i -
to blkparse, and combining it with the live
         option for blktrace. An example would be:

            % blktrace -d /dev/sda -o - | blkparse -i -

       - You can set how many blkparse batches event reads via the
-b
option, the default is to handle events in batches of 512. - If you have saved event traces in blktrace with different output
         names (via the
-o
option to blktrace), you must specify the same
         input name via the
-i
option."
53,3,blkparse,"- If you have saved event traces in blktrace with different output
         names (via the
-o
option to blktrace), you must specify the same
         input name via the
-i
option. - The format of the output data can be controlled via the
-f
or
-F
options -- see OUTPUT DESCRIPTION AND FORMATTING for details. By default, blkparse sends formatted data to standard output."
53,4,blkparse,"By default, blkparse sends formatted data to standard output. This
       may be changed via the
-o
option, or text output can be disabled
       via the
-O
option. A merged binary stream can be produced using
       the
-d
option."
54,0,break,"If
n
is specified, the
break
utility shall exit from the
n
th
       enclosing
for
,
while
, or
until
loop. If
n
is not specified,
break
shall behave as if
n
was specified as 1. Execution shall continue
       with the command immediately following the exited loop."
54,1,break,"Execution shall continue
       with the command immediately following the exited loop. The value
       of
n
is a positive decimal integer. If
n
is greater than the
       number of enclosing loops, the outermost enclosing loop shall be
       exited."
54,2,break,"If
n
is greater than the
       number of enclosing loops, the outermost enclosing loop shall be
       exited. If there is no enclosing loop, the behavior is
       unspecified. A loop shall enclose a
break
or
continue
command if the loop
       lexically encloses the command."
54,3,break,"A loop shall enclose a
break
or
continue
command if the loop
       lexically encloses the command. A loop lexically encloses a
break
or
continue
command if the command is:

        *  Executing in the same execution environment (see
Section 2.12
,
Shell Execution Environment
) as the compound-list of the
           loop's do-group (see
Section 2.10.2
,
Shell Grammar Rules
), and

        *  Contained in a compound-list associated with the loop (either
           in the compound-list of the loop's do-group or, if the loop is
           a
while
or
until
loop, in the compound-list following the
while
or
until
reserved word), and

        *  Not in the body of a function whose function definition
           command (see
Section 2.9.5
,
Function Definition Command
) is
           contained in a compound-list associated with the loop. If
n
is greater than the number of lexically enclosing loops and
       there is a non-lexically enclosing loop in progress in the same
       execution environment as the
break
or
continue
command, it is
       unspecified whether that loop encloses the command."
55,0,btt,"btt is a post-processing tool for the block layer IO tracing tool
       called blktrace(8). As noted in its documentation, blktrace is a
       block layer IO tracing mechanism which provides detailed
       information about request queue operations up to user space. btt will take in binary dump data from blkparse, and analyse the
       events, producing a series of output from the analysis."
55,1,btt,"btt will take in binary dump data from blkparse, and analyse the
       events, producing a series of output from the analysis. It will
       also build .dat files containing ""range data"" -- showing things
       like Q activity (periods of time while Q events are being
       produced), C activity (likewise for command completions), and etc. Included with the distribution is a simple 3D plotting utility,
bno_plot
, which can plot the block numbers btt outputs if the
-B
option is specified."
55,2,btt,"It will
       also build .dat files containing ""range data"" -- showing things
       like Q activity (periods of time while Q events are being
       produced), C activity (likewise for command completions), and etc. Included with the distribution is a simple 3D plotting utility,
bno_plot
, which can plot the block numbers btt outputs if the
-B
option is specified. The display will display each IO generated,
       with the time (seconds) along the X-axis, the block number (start)
       along the Y-axis and the number of blocks transferred in the IO
       represented along the Z-axis."
56,0,busctl,"busctl
may be used to introspect and monitor the D-Bus bus."
57,0,cal,"cal
displays a simple calendar. If no arguments are specified, the
       current month is displayed. The
month
may be specified as a number (1-12), as a month name or
       as an abbreviated month name according to the current locales."
57,1,cal,"The
month
may be specified as a number (1-12), as a month name or
       as an abbreviated month name according to the current locales. Two different calendar systems are used, Gregorian and Julian. These are nearly identical systems with Gregorian making a small
       adjustment to the frequency of leap years; this facilitates
       improved synchronization with solar events like the equinoxes."
57,2,cal,"These are nearly identical systems with Gregorian making a small
       adjustment to the frequency of leap years; this facilitates
       improved synchronization with solar events like the equinoxes. The
       Gregorian calendar reform was introduced in 1582, but its adoption
       continued up to 1923. By default
cal
uses the adoption date of 3
       Sept 1752."
57,3,cal,"By default
cal
uses the adoption date of 3
       Sept 1752. From that date forward the Gregorian calendar is
       displayed; previous dates use the Julian calendar system. 11 days
       were removed at the time of adoption to bring the calendar in sync
       with solar events."
57,4,cal,"11 days
       were removed at the time of adoption to bring the calendar in sync
       with solar events. So Sept 1752 has a mix of Julian and Gregorian
       dates by which the 2nd is followed by the 14th (the 3rd through
       the 13th are absent). Optionally, either the proleptic Gregorian calendar or the Julian
       calendar may be used exclusively."
57,5,cal,"So Sept 1752 has a mix of Julian and Gregorian
       dates by which the 2nd is followed by the 14th (the 3rd through
       the 13th are absent). Optionally, either the proleptic Gregorian calendar or the Julian
       calendar may be used exclusively. See
--reform
below."
58,0,c++filt,"The C++ and Java languages provide function overloading, which
       means that you can write many functions with the same name,
       providing that each function takes parameters of different types. In order to be able to distinguish these similarly named functions
       C++ and Java encode them into a low-level assembler name which
       uniquely identifies each different version. This process is known
       as
mangling
."
58,1,c++filt,"This process is known
       as
mangling
. The
c++filt
[1] program does the inverse mapping: it
       decodes (
demangles
) low-level names into user-level names so that
       they can be read. Every alphanumeric word (consisting of letters, digits,
       underscores, dollars, or periods) seen in the input is a potential
       mangled name."
58,2,c++filt,"Every alphanumeric word (consisting of letters, digits,
       underscores, dollars, or periods) seen in the input is a potential
       mangled name. If the name decodes into a C++ name, the C++ name
       replaces the low-level name in the output, otherwise the original
       word is output. In this way you can pass an entire assembler
       source file, containing mangled names, through
c++filt
and see the
       same source file containing demangled names."
58,3,c++filt,"In this way you can pass an entire assembler
       source file, containing mangled names, through
c++filt
and see the
       same source file containing demangled names. You can also use
c++filt
to decipher individual symbols by passing
       them on the command line:

               c++filt <symbol>

       If no
symbol
arguments are given,
c++filt
reads symbol names from
       the standard input instead. All the results are printed on the
       standard output."
58,4,c++filt,"All the results are printed on the
       standard output. The difference between reading names from the
       command line versus reading names from the standard input is that
       command-line arguments are expected to be just mangled names and
       no checking is performed to separate them from surrounding text. Thus for example:

               c++filt -n _Z1fv

       will work and demangle the name to ""f()"" whereas:

               c++filt -n _Z1fv,

       will not work."
58,5,c++filt,"Thus for example:

               c++filt -n _Z1fv

       will work and demangle the name to ""f()"" whereas:

               c++filt -n _Z1fv,

       will not work. (Note the extra comma at the end of the mangled
       name which makes it invalid). This command however will work:

               echo _Z1fv, | c++filt -n

       and will display ""f(),"", i.e., the demangled name followed by a
       trailing comma."
58,6,c++filt,"This command however will work:

               echo _Z1fv, | c++filt -n

       and will display ""f(),"", i.e., the demangled name followed by a
       trailing comma. This behaviour is because when the names are read
       from the standard input it is expected that they might be part of
       an assembler source file where there might be extra, extraneous
       characters trailing after a mangled name. For example:

                   .type   _Z1fv, @function"
59,0,bash,"Bash
is an
sh
-compatible command language interpreter that
       executes commands read from the standard input or from a file. Bash
also incorporates useful features from the
Korn
and
C
shells
       (
ksh
and
csh
). Bash
is intended to be a conformant implementation of the Shell
       and Utilities portion of the IEEE POSIX specification (IEEE
       Standard 1003.1)."
59,1,bash,"Bash
also incorporates useful features from the
Korn
and
C
shells
       (
ksh
and
csh
). Bash
is intended to be a conformant implementation of the Shell
       and Utilities portion of the IEEE POSIX specification (IEEE
       Standard 1003.1). Bash
can be configured to be POSIX-conformant
       by default."
60,0,cal,"The
cal
utility shall write a calendar to standard output using
       the Julian calendar for dates from January 1, 1 through September
       2, 1752 and the Gregorian calendar for dates from September 14,
       1752 through December 31, 9999 as though the Gregorian calendar
       had been adopted on September 14, 1752. If no operands are given,
cal
shall produce a one-month calendar
       for the current month in the current year. If only the
year
operand is given,
cal
shall produce a calendar for all twelve
       months in the given calendar year."
60,1,cal,"If no operands are given,
cal
shall produce a one-month calendar
       for the current month in the current year. If only the
year
operand is given,
cal
shall produce a calendar for all twelve
       months in the given calendar year. If both
month
and
year
operands
       are given,
cal
shall produce a one-month calendar for the given
       month in the given year."
61,0,callgrind_control,"callgrind_control
controls programs being run by the Valgrind tool
       Callgrind. When a
pid/program name
argument is not specified, all
       applications currently being run by Callgrind on this system will
       be used for actions given by the specified option(s). The default
       action is to give some brief information about the applications
       being run by Callgrind."
62,0,callgrind_annotate,"callgrind_annotate
takes an output file produced by the Valgrind
       tool Callgrind and prints the information in an easy-to-read form."
63,0,cancel,"The
cancel
command cancels print jobs.  If no
destination
or
id
is
       specified, the currently printing job on the default destination
       is canceled."
64,0,c99,"The
c99
utility is an interface to the standard C compilation
       system; it shall accept source code conforming to the ISO C
       standard. The system conceptually consists of a compiler and link
       editor. The input files referenced by
pathname
operands and
-l
option-arguments shall be compiled and linked to produce an
       executable file."
64,1,c99,"The input files referenced by
pathname
operands and
-l
option-arguments shall be compiled and linked to produce an
       executable file. (It is unspecified whether the linking occurs
       entirely within the operation of
c99
; some implementations may
       produce objects that are not fully resolved until the file is
       executed.)

       If the
-c
option is specified, for all pathname operands of the
       form
file
.c
, the files:

           $(basename
pathname
.c).o

       shall be created as the result of successful compilation. If the
-c
option is not specified, it is unspecified whether such
.o
files are created or deleted for the
file
.c
operands."
64,2,c99,"If the
-c
option is not specified, it is unspecified whether such
.o
files are created or deleted for the
file
.c
operands. If there are no options that prevent link editing (such as
-c
or
-E
), and all input files compile and link without error, the
       resulting executable file shall be written according to the
-o
outfile
option (if present) or to the file
a.out
. The executable file shall be created as specified in
Section
1.1.1.4
,
File Read
,
Write
,
and Creation
, except that the file
       permission bits shall be set to: S_IRWXO | S_IRWXG | S_IRWXU

       and the bits specified by the
umask
of the process shall be
       cleared."
65,0,capsh,"Linux capability support and use can be explored and constrained
       with this tool. This tool provides a handy wrapper for certain
       types of capability testing and environment creation. It also
       provides some debugging features useful for summarizing capability
       state."
66,0,cat,"Concatenate FILE(s) to standard output.

       With no FILE, or when FILE is -, read standard input.
-A
,
--show-all
equivalent to
-vET
-b
,
--number-nonblank
number nonempty output lines, overrides
-n
-e
equivalent to
-vE
-E
,
--show-ends
display $ at end of each line
-n
,
--number
number all output lines
-s
,
--squeeze-blank
suppress repeated empty output lines
-t
equivalent to
-vT
-T
,
--show-tabs
display TAB characters as ^I
-u
(ignored)
-v
,
--show-nonprinting
use ^ and M- notation, except for LFD and TAB
--help
display this help and exit
--version
output version information and exit"
67,0,cat,"The
cat
utility shall read files in sequence and shall write their
       contents to the standard output in the same sequence."
68,0,cg_annotate,"cg_annotate
takes one or more Cachegrind output files and prints
       data about the profiled program in an easy-to-read form."
69,0,cd,"The
cd
utility shall change the working directory of the current
       shell execution environment (see
Section 2.12
,
Shell Execution
Environment
) by executing the following steps in sequence. (In the
       following steps, the symbol
curpath
represents an intermediate
       value used to simplify the description of the algorithm used by
cd
. There is no requirement that
curpath
be made visible to the
       application.)

        1."
69,1,cd,"There is no requirement that
curpath
be made visible to the
       application.)

        1. If no
directory
operand is given and the
HOME
environment
           variable is empty or undefined, the default behavior is
           implementation-defined and no further steps shall be taken. 2."
69,2,cd,"2. If no
directory
operand is given and the
HOME
environment
           variable is set to a non-empty value, the
cd
utility shall
           behave as if the directory named in the
HOME
environment
           variable was specified as the
directory
operand. 3."
69,3,cd,"3. If the
directory
operand begins with a <slash> character, set
curpath
to the operand and proceed to step 7. 4."
69,4,cd,"4. If the first component of the
directory
operand is dot or dot-
           dot, proceed to step 6. 5."
69,5,cd,"5. Starting with the first pathname in the <colon>-separated
           pathnames of
CDPATH
(see the ENVIRONMENT VARIABLES section) if
           the pathname is non-null, test if the concatenation of that
           pathname, a <slash> character if that pathname did not end
           with a <slash> character, and the
directory
operand names a
           directory. If the pathname is null, test if the concatenation
           of dot, a <slash> character, and the operand names a
           directory."
69,6,cd,"If the pathname is null, test if the concatenation
           of dot, a <slash> character, and the operand names a
           directory. In either case, if the resulting string names an
           existing directory, set
curpath
to that string and proceed to
           step 7. Otherwise, repeat this step with the next pathname in
CDPATH
until all pathnames have been tested."
69,7,cd,"Otherwise, repeat this step with the next pathname in
CDPATH
until all pathnames have been tested. 6. Set
curpath
to the
directory
operand."
69,8,cd,"Set
curpath
to the
directory
operand. 7. If the
-P
option is in effect, proceed to step 10."
69,9,cd,"If the
-P
option is in effect, proceed to step 10. If
curpath
does not begin with a <slash> character, set
curpath
to the
           string formed by the concatenation of the value of
PWD
, a
           <slash> character if the value of
PWD
did not end with a
           <slash> character, and
curpath
. 8."
69,10,cd,"8. The
curpath
value shall then be converted to canonical form as
           follows, considering each component from beginning to end, in
           sequence:

            a. Dot components and any <slash> characters that separate
               them from the next component shall be deleted."
69,11,cd,"Dot components and any <slash> characters that separate
               them from the next component shall be deleted. b. For each dot-dot component, if there is a preceding
               component and it is neither root nor dot-dot, then:

                i."
69,12,cd,"For each dot-dot component, if there is a preceding
               component and it is neither root nor dot-dot, then:

                i. If the preceding component does not refer (in the
                    context of pathname resolution with symbolic links
                    followed) to a directory, then the
cd
utility shall
                    display an appropriate error message and no further
                    steps shall be taken. ii."
69,13,cd,"ii. The preceding component, all <slash> characters
                    separating the preceding component from dot-dot, dot-
                    dot, and all <slash> characters separating dot-dot
                    from the following component (if any) shall be
                    deleted. c."
69,14,cd,"c. An implementation may further simplify
curpath
by removing
               any trailing <slash> characters that are not also leading
               <slash> characters, replacing multiple non-leading
               consecutive <slash> characters with a single <slash>, and
               replacing three or more leading <slash> characters with a
               single <slash>. If, as a result of this canonicalization,
               the
curpath
variable is null, no further steps shall be
               taken."
69,15,cd,"If, as a result of this canonicalization,
               the
curpath
variable is null, no further steps shall be
               taken. 9. If
curpath
is longer than {PATH_MAX} bytes (including the
           terminating null) and the
directory
operand was not longer
           than {PATH_MAX} bytes (including the terminating null), then
curpath
shall be converted from an absolute pathname to an
           equivalent relative pathname if possible."
69,16,cd,"If
curpath
is longer than {PATH_MAX} bytes (including the
           terminating null) and the
directory
operand was not longer
           than {PATH_MAX} bytes (including the terminating null), then
curpath
shall be converted from an absolute pathname to an
           equivalent relative pathname if possible. This conversion
           shall always be considered possible if the value of
PWD
, with
           a trailing <slash> added if it does not already have one, is
           an initial substring of
curpath
. Whether or not it is
           considered possible under other circumstances is unspecified."
69,17,cd,"Whether or not it is
           considered possible under other circumstances is unspecified. Implementations may also apply this conversion if
curpath
is
           not longer than {PATH_MAX} bytes or the
directory
operand was
           longer than {PATH_MAX} bytes. 10."
69,18,cd,"10. The
cd
utility shall then perform actions equivalent to the
chdir
() function called with
curpath
as the
path
argument. If
           these actions fail for any reason, the
cd
utility shall
           display an appropriate error message and the remainder of this
           step shall not be executed."
69,19,cd,"If
           these actions fail for any reason, the
cd
utility shall
           display an appropriate error message and the remainder of this
           step shall not be executed. If the
-P
option is not in effect,
           the
PWD
environment variable shall be set to the value that
curpath
had on entry to step 9 (i.e., before conversion to a
           relative pathname). If the
-P
option is in effect, the
PWD
environment variable shall be set to the string that would be
           output by
pwd
-P
."
69,20,cd,"If the
-P
option is in effect, the
PWD
environment variable shall be set to the string that would be
           output by
pwd
-P
. If there is insufficient permission on the
           new directory, or on any parent of that directory, to
           determine the current working directory, the value of the
PWD
environment variable is unspecified. If, during the execution of the above steps, the
PWD
environment
       variable is set, the
OLDPWD
environment variable shall also be set
       to the value of the old working directory (that is the current
       working directory immediately prior to the call to
cd
)."
70,0,cdrwtool,"The
cdwrtool
command can perform certain actions on a CD-R, CD-RW,
       or DVD-R device. Mainly these are blanking the media, formatting
       it for use with the packet-cd device,  and applying an UDF
       filesystem. The most common usage is probably the `quick setup' option:
cdrwtool -d
device
-q
which will blank the disc, format it as one large track, and write
       the UDF filesystem structures."
70,1,cdrwtool,"The most common usage is probably the `quick setup' option:
cdrwtool -d
device
-q
which will blank the disc, format it as one large track, and write
       the UDF filesystem structures. Other options get and set various parameters of how the device is
       set up, and provide for different offsets, modes and settings from
       the defaults. The usefulness of most of the options is not explained."
71,0,cg_diff,"cg_diff
diffs two Cachegrind output files into a single Cachegrind
       output file. It is deprecated because
cg_annotate
can now do much
       the same thing, but better."
72,0,cgcc,"cgcc
provides a wrapper around a C compiler (
cc
by default) which
       also invokes the Sparse static analysis tool. cgcc
accepts all Sparse command-line options, such as warning
       options, and passes all other options through to the compiler. By providing the same interface as the C compiler,
cgcc
allows
       projects to run Sparse as part of their build without modifying
       their build system, by using
cgcc
as the compiler."
72,1,cgcc,"cgcc
accepts all Sparse command-line options, such as warning
       options, and passes all other options through to the compiler. By providing the same interface as the C compiler,
cgcc
allows
       projects to run Sparse as part of their build without modifying
       their build system, by using
cgcc
as the compiler. For many
       projects, setting
CC=cgcc
on the
make
command-line will work."
73,0,cflow,"The
cflow
utility shall analyze a collection of object files or
       assembler, C-language,
lex
, or
yacc
source files, and attempt to
       build a graph, written to standard output, charting the external
       references."
74,0,certtool,"Tool to parse and generate X.509 certificates, requests and
       private keys. It can be used interactively or non interactively
       by specifying the template command line option. The tool accepts files or supported URIs via the --infile option."
74,1,certtool,"It can be used interactively or non interactively
       by specifying the template command line option. The tool accepts files or supported URIs via the --infile option. In case PIN is required for URI access you can provide it using
       the environment variables GNUTLS_PIN and GNUTLS_SO_PIN."
75,0,cg_merge,"cg_merge
sums together multiple Cachegrind output files into a
       single Cachegrind output file. It is deprecated because
cg_annotate
can now do much the same thing, but better."
76,0,chacl,"chacl
is an IRIX-compatibility command, and is maintained for
       those users who are familiar with its use from either XFS or IRIX. Refer to the
SEE ALSO
section below for a description of tools
       which conform more closely to the (withdrawn draft) POSIX 1003.1e
       standard which describes Access Control Lists (ACLs). chacl
changes the ACL(s) for a file or directory."
76,1,chacl,"chacl
changes the ACL(s) for a file or directory. The ACL(s)
       specified are applied to each file in the
pathname
arguments. Each ACL is a string which is interpreted using the
acl_from_text(3)
routine."
76,2,chacl,"Each ACL is a string which is interpreted using the
acl_from_text(3)
routine. These strings are made up of comma
       separated clauses each of which is of the form, tag:name:perm. Where
tag
can be:

       ""user"" (or ""u"")
              indicating that the entry is a ""user"" ACL entry."
76,3,chacl,"Where
tag
can be:

       ""user"" (or ""u"")
              indicating that the entry is a ""user"" ACL entry. ""group"" (or ""g"")
              indicating that the entry is a ""group"" ACL entry. ""other"" (or ""o"")
              indicating that the entry is an ""other"" ACL entry."
76,4,chacl,"""other"" (or ""o"")
              indicating that the entry is an ""other"" ACL entry. ""mask"" (or ""m"")
              indicating that the entry is a ""mask"" ACL entry. name
is a string which is the user or group name for the ACL
       entry."
76,5,chacl,"name
is a string which is the user or group name for the ACL
       entry. A null
name
in a user or group ACL entry indicates the
       file's owner or file's group. perm
is the string ""rwx"" where each
       of the entries may be replaced by a ""-"" indicating no access of
       that type, e.g."
76,6,chacl,"A null
name
in a user or group ACL entry indicates the
       file's owner or file's group. perm
is the string ""rwx"" where each
       of the entries may be replaced by a ""-"" indicating no access of
       that type, e.g. ""r-x"", ""--x"", ""---""."
77,0,chage,"The
chage
command changes the number of days between password
       changes and the date of the last password change. This information
       is used by the system to determine when a user must change their
       password."
78,0,chfn,"chfn
is used to change your finger information. This information
       is stored in the
/etc/passwd
file, and is displayed by the
finger
program. The Linux
finger
command will display four pieces of
       information that can be changed by
chfn
: your real name, your work
       room and phone, and your home phone."
78,1,chfn,"The Linux
finger
command will display four pieces of
       information that can be changed by
chfn
: your real name, your work
       room and phone, and your home phone. Any of the four pieces of information can be specified on the
       command line. If no information is given on the command line,
chfn
enters interactive mode."
78,2,chfn,"If no information is given on the command line,
chfn
enters interactive mode. In interactive mode,
chfn
will prompt for each field. At a prompt,
       you can enter the new information, or just press return to leave
       the field unchanged."
78,3,chfn,"At a prompt,
       you can enter the new information, or just press return to leave
       the field unchanged. Enter the keyword ""none"" to make the field
       blank. chfn
supports non-local entries (kerberos, LDAP, etc.) if linked
       with libuser, otherwise use
ypchfn
(1),
lchfn
(1) or any other
       implementation for non-local entries."
79,0,chcon,"Change the SELinux security context of each FILE to CONTEXT. With
--reference
, change the security context of each FILE to that of
       RFILE. Mandatory arguments to long options are mandatory for short
       options too."
79,1,chcon,"Mandatory arguments to long options are mandatory for short
       options too. --dereference
affect the referent of each symbolic link (this is the
              default), rather than the symbolic link itself
-h
,
--no-dereference
affect symbolic links instead of any referenced file
-u
,
--user
=
USER
set user USER in the target security context
-r
,
--role
=
ROLE
set role ROLE in the target security context
-t
,
--type
=
TYPE
set type TYPE in the target security context
-l
,
--range
=
RANGE
set range RANGE in the target security context
--no-preserve-root
do not treat '/' specially (the default)
--preserve-root
fail to operate recursively on '/'
--reference
=
RFILE
use RFILE's security context rather than specifying a
              CONTEXT value
-R
,
--recursive
operate on files and directories recursively
-v
,
--verbose
output a diagnostic for every file processed

       The following options modify how a hierarchy is traversed when the
-R
option is also specified. If more than one is specified, only
       the final one takes effect."
79,2,chcon,"--dereference
affect the referent of each symbolic link (this is the
              default), rather than the symbolic link itself
-h
,
--no-dereference
affect symbolic links instead of any referenced file
-u
,
--user
=
USER
set user USER in the target security context
-r
,
--role
=
ROLE
set role ROLE in the target security context
-t
,
--type
=
TYPE
set type TYPE in the target security context
-l
,
--range
=
RANGE
set range RANGE in the target security context
--no-preserve-root
do not treat '/' specially (the default)
--preserve-root
fail to operate recursively on '/'
--reference
=
RFILE
use RFILE's security context rather than specifying a
              CONTEXT value
-R
,
--recursive
operate on files and directories recursively
-v
,
--verbose
output a diagnostic for every file processed

       The following options modify how a hierarchy is traversed when the
-R
option is also specified. If more than one is specified, only
       the final one takes effect. -H
if a command line argument is a symbolic link to a
              directory, traverse it
-L
traverse every symbolic link to a directory encountered
-P
do not traverse any symbolic links (default)
--help
display this help and exit
--version
output version information and exit"
80,0,chgrp,"Change the group of each FILE to GROUP. With
--reference
, change
       the group of each FILE to that of RFILE. -c
,
--changes
like verbose but report only when a change is made
-f
,
--silent
,
--quiet
suppress most error messages
-v
,
--verbose
output a diagnostic for every file processed
--dereference
affect the referent of each symbolic link (this is the
              default), rather than the symbolic link itself
-h
,
--no-dereference
affect symbolic links instead of any referenced file
              (useful only on systems that can change the ownership of a
              symlink)
--from
=
CURRENT_OWNER
:CURRENT_GROUP
              change the ownership of each file only if its current owner
              and/or group match those specified here."
80,1,chgrp,"-c
,
--changes
like verbose but report only when a change is made
-f
,
--silent
,
--quiet
suppress most error messages
-v
,
--verbose
output a diagnostic for every file processed
--dereference
affect the referent of each symbolic link (this is the
              default), rather than the symbolic link itself
-h
,
--no-dereference
affect symbolic links instead of any referenced file
              (useful only on systems that can change the ownership of a
              symlink)
--from
=
CURRENT_OWNER
:CURRENT_GROUP
              change the ownership of each file only if its current owner
              and/or group match those specified here. Either may be
              omitted, in which case a match is not required for the
              omitted attribute
--no-preserve-root
do not treat '/' specially (the default)
--preserve-root
fail to operate recursively on '/'
--reference
=
RFILE
use RFILE's ownership rather than specifying values. RFILE
              is always dereferenced if a symbolic link."
80,2,chgrp,"RFILE
              is always dereferenced if a symbolic link. -R
,
--recursive
operate on files and directories recursively

       The following options modify how a hierarchy is traversed when the
-R
option is also specified. If more than one is specified, only
       the final one takes effect."
80,3,chgrp,"If more than one is specified, only
       the final one takes effect. -P
is the default. -H
if a command line argument is a symbolic link to a
              directory, traverse it
-L
traverse every symbolic link to a directory encountered
-P
do not traverse any symbolic links
--help
display this help and exit
--version
output version information and exit"
81,0,chem,nan
82,0,chkhelp,"chkhelp
checks the consistency of Performance Co-Pilot help text
       files generated by
newhelp(1)
and used by Performance Metric
       Domain Agents (PMDAs). The checking involves scanning the files,
       and optionally displaying selected entries. The files
helpfile
.dir
and
helpfile
.pag
are created by
newhelp(1)
,
       and are assumed to already exist."
82,1,chkhelp,"The files
helpfile
.dir
and
helpfile
.pag
are created by
newhelp(1)
,
       and are assumed to already exist. Without any options or
metricname
arguments,
chkhelp
silently
       verifies the structural integrity of the help files. If any
metricname
arguments are specified, then the help entries
       for only the corresponding metrics will be processed."
82,2,chkhelp,"If any
metricname
arguments are specified, then the help entries
       for only the corresponding metrics will be processed. If no
metricname
arguments are specified, then at least one of the
       options
-i
or
-p
must be given. The
-i
option causes entries for
       all instance domains to be processed (ignoring entries for
       performance metrics)."
82,3,chkhelp,"The
-i
option causes entries for
       all instance domains to be processed (ignoring entries for
       performance metrics). The
-p
option causes entries for all
       metrics to be displayed (ignoring entries for instance domains). When metric entries are to be processed (via either the
metricname
arguments or the
-p
option or the
-i
option), the
-O
and
-H
options request the display of the one-line and verbose help text
       respectively."
82,4,chkhelp,"When metric entries are to be processed (via either the
metricname
arguments or the
-p
option or the
-i
option), the
-O
and
-H
options request the display of the one-line and verbose help text
       respectively. The default is
-O
. Normally
chkhelp
operates on the default Performance Metrics Name
       Space (PMNS), however if the
-n
option is specified an alternative
       namespace is loaded from the file
pmnsfile
."
82,5,chkhelp,"Normally
chkhelp
operates on the default Performance Metrics Name
       Space (PMNS), however if the
-n
option is specified an alternative
       namespace is loaded from the file
pmnsfile
. The
-e
option provides an existence check where all of the
       specified metrics from the PMNS (note, not from
helpfile
) are
       scanned, and only the names of the metrics for which
no
help text
       exists are reported. The
-e
option is mutually exclusive with the
-i
and/or
-p
options."
83,0,chgrp,"The
chgrp
utility shall set the group ID of the file named by each
file
operand to the group ID specified by the
group
operand. For each
file
operand, or, if the
-R
option is used, each file
       encountered while walking the directory trees specified by the
file
operands, the
chgrp
utility shall perform actions equivalent
       to the
chown
() function defined in the System Interfaces volume of
       POSIX.1â2017, called with the following arguments:

        *  The
file
operand shall be used as the
path
argument. *  The user ID of the file shall be used as the
owner
argument."
83,1,chgrp,"*  The user ID of the file shall be used as the
owner
argument. *  The specified group ID shall be used as the
group
argument. Unless
chgrp
is invoked by a process with appropriate privileges,
       the set-user-ID and set-group-ID bits of a regular file shall be
       cleared upon successful completion; the set-user-ID and set-group-
       ID bits of other file types may be cleared."
84,0,chattr,"chattr
changes the file attributes on a Linux file system. The format of a symbolic
mode
is
+-=
[
aAcCdDeFijmPsStTux
]. The operator '
+
' causes the selected attributes to be added to the
       existing attributes of the files; '
-
' causes them to be removed;
       and '
=
' causes them to be the only attributes that the files have."
84,1,chattr,"The operator '
+
' causes the selected attributes to be added to the
       existing attributes of the files; '
-
' causes them to be removed;
       and '
=
' causes them to be the only attributes that the files have. The letters '
aAcCdDeFijmPsStTux
' select the new attributes for the
       files: append only (
a
), no atime updates (
A
), compressed (
c
), no
       copy on write (
C
), no dump (
d
), synchronous directory updates (
D
),
       extent format (
e
), case-insensitive directory lookups (
F
),
       immutable (
i
), data journaling (
j
), don't compress (
m
), project
       hierarchy (
P
), secure deletion (
s
), synchronous updates (
S
), no
       tail-merging (
t
), top of directory hierarchy (
T
), undeletable (
u
),
       and direct access for files (
x
). The following attributes are read-only, and may be listed by
lsattr(1)
but not modified by chattr: encrypted (
E
), indexed
       directory (
I
), inline data (
N
), and verity (
V
)."
84,2,chattr,"The letters '
aAcCdDeFijmPsStTux
' select the new attributes for the
       files: append only (
a
), no atime updates (
A
), compressed (
c
), no
       copy on write (
C
), no dump (
d
), synchronous directory updates (
D
),
       extent format (
e
), case-insensitive directory lookups (
F
),
       immutable (
i
), data journaling (
j
), don't compress (
m
), project
       hierarchy (
P
), secure deletion (
s
), synchronous updates (
S
), no
       tail-merging (
t
), top of directory hierarchy (
T
), undeletable (
u
),
       and direct access for files (
x
). The following attributes are read-only, and may be listed by
lsattr(1)
but not modified by chattr: encrypted (
E
), indexed
       directory (
I
), inline data (
N
), and verity (
V
). Not all flags are supported or utilized by all file systems; refer
       to file system-specific man pages such as
btrfs
(5),
ext4(5)
,
mkfs.f2fs
(8), and
xfs(5)
for more file system-specific details."
85,0,chmod,"This manual page documents the GNU version of
chmod
. chmod
changes the file mode bits of each given file according to
mode
,
       which can be either a symbolic representation of changes to make,
       or an octal number representing the bit pattern for the new mode
       bits. The format of a symbolic mode is [
ugoa
...][[
-+=
][
perms
...]...],
       where
perms
is either zero or more letters from the set
rwxXst
, or
       a single letter from the set
ugo
."
85,1,chmod,"The format of a symbolic mode is [
ugoa
...][[
-+=
][
perms
...]...],
       where
perms
is either zero or more letters from the set
rwxXst
, or
       a single letter from the set
ugo
. Multiple symbolic modes can be
       given, separated by commas. A combination of the letters
ugoa
controls which users' access to
       the file will be changed: the user who owns it (
u
), other users in
       the file's group (
g
), other users not in the file's group (
o
), or
       all users (
a
)."
85,2,chmod,"A combination of the letters
ugoa
controls which users' access to
       the file will be changed: the user who owns it (
u
), other users in
       the file's group (
g
), other users not in the file's group (
o
), or
       all users (
a
). If none of these are given, the effect is as if
       (
a
) were given, but bits that are set in the umask are not
       affected. The operator
+
causes the selected file mode bits to be added to
       the existing file mode bits of each file;
-
causes them to be
       removed; and
=
causes them to be added and causes unmentioned bits
       to be removed except that a directory's unmentioned set user and
       group ID bits are not affected."
85,3,chmod,"The operator
+
causes the selected file mode bits to be added to
       the existing file mode bits of each file;
-
causes them to be
       removed; and
=
causes them to be added and causes unmentioned bits
       to be removed except that a directory's unmentioned set user and
       group ID bits are not affected. The letters
rwxXst
select file mode bits for the affected users:
       read (
r
), write (
w
), execute (or search for directories) (
x
),
       execute/search only if the file is a directory or already has
       execute permission for some user (
X
), set user or group ID on
       execution (
s
), restricted deletion flag or sticky bit (
t
). Instead of one or more of these letters, you can specify exactly
       one of the letters
ugo
: the permissions granted to the user who
       owns the file (
u
), the permissions granted to other users who are
       members of the file's group (
g
), and the permissions granted to
       users that are in neither of the two preceding categories (
o
)."
85,4,chmod,"Instead of one or more of these letters, you can specify exactly
       one of the letters
ugo
: the permissions granted to the user who
       owns the file (
u
), the permissions granted to other users who are
       members of the file's group (
g
), and the permissions granted to
       users that are in neither of the two preceding categories (
o
). A numeric mode is from one to four octal digits (0-7), derived by
       adding up the bits with values 4, 2, and 1. Omitted digits are
       assumed to be leading zeros."
85,5,chmod,"Omitted digits are
       assumed to be leading zeros. The first digit selects the set user
       ID (4) and set group ID (2) and restricted deletion or sticky (1)
       attributes. The second digit selects permissions for the user who
       owns the file: read (4), write (2), and execute (1); the third
       selects permissions for other users in the file's group, with the
       same values; and the fourth for other users not in the file's
       group, with the same values."
85,6,chmod,"The second digit selects permissions for the user who
       owns the file: read (4), write (2), and execute (1); the third
       selects permissions for other users in the file's group, with the
       same values; and the fourth for other users not in the file's
       group, with the same values. chmod
doesn't change the permissions of symbolic links; the
chmod
system call cannot change their permissions on most systems, and
       most systems ignore permissions of symbolic links. However, for
       each symbolic link listed on the command line,
chmod
changes the
       permissions of the pointed-to file."
85,7,chmod,"However, for
       each symbolic link listed on the command line,
chmod
changes the
       permissions of the pointed-to file. In contrast,
chmod
ignores
       symbolic links encountered during recursive directory traversals. Options that modify this behavior are described in the
OPTIONS
section."
86,0,chmod,"The
chmod
utility shall change any or all of the file mode bits of
       the file named by each
file
operand in the way specified by the
mode
operand. It is implementation-defined whether and how the
chmod
utility
       affects any alternate or additional file access control mechanism
       (see the Base Definitions volume of POSIX.1â2017,
Section 4.5
,
File Access Permissions
) being used for the specified file. Only a process whose effective user ID matches the user ID of the
       file, or a process with appropriate privileges, shall be permitted
       to change the file mode bits of a file."
86,1,chmod,"It is implementation-defined whether and how the
chmod
utility
       affects any alternate or additional file access control mechanism
       (see the Base Definitions volume of POSIX.1â2017,
Section 4.5
,
File Access Permissions
) being used for the specified file. Only a process whose effective user ID matches the user ID of the
       file, or a process with appropriate privileges, shall be permitted
       to change the file mode bits of a file. Upon successfully changing the file mode bits of a file, the
chmod
utility shall mark for update the last file status change
       timestamp of the file."
87,0,choom,"The
choom
command displays and adjusts Out-Of-Memory killer score
       setting."
88,0,chown,"This manual page documents the GNU version of
chown
. chown
changes the user and/or group ownership of each given file. If
       only an owner (a user name or numeric user ID) is given, that user
       is made the owner of each given file, and the files' group is not
       changed."
88,1,chown,"If
       only an owner (a user name or numeric user ID) is given, that user
       is made the owner of each given file, and the files' group is not
       changed. If the owner is followed by a colon and a group name (or
       numeric group ID), with no spaces between them, the group
       ownership of the files is changed as well. If a colon but no
       group name follows the user name, that user is made the owner of
       the files and the group of the files is changed to that user's
       login group."
88,2,chown,"If a colon but no
       group name follows the user name, that user is made the owner of
       the files and the group of the files is changed to that user's
       login group. If the colon and group are given, but the owner is
       omitted, only the group of the files is changed; in this case,
chown
performs the same function as
chgrp
. If only a colon is
       given, or if the entire operand is empty, neither the owner nor
       the group is changed."
89,0,chsh,"chsh
is used to change your login shell. If a shell is not given
       on the command line,
chsh
prompts for one.
chsh
supports non-local entries (kerberos, LDAP, etc.) if linked
       with libuser, otherwise use
ypchsh
(1),
lchsh
(1) or any other
       implementation for non-local entries."
90,0,chvt,"The command
chvt
N
makes
/dev/ttyN
the foreground terminal.  (The
       corresponding screen is created if it did not exist yet.  To get
       rid of unused VTs, use
deallocvt(1)
.)  The key combination
       (Ctrl-)LeftAlt-F
N
(with
N
in the range 1-12) usually has a similar
       effect."
91,0,chown,"The
chown
utility shall set the user ID of the file named by each
file
operand to the user ID specified by the
owner
operand. For each
file
operand, or, if the
-R
option is used, each file
       encountered while walking the directory trees specified by the
file
operands, the
chown
utility shall perform actions equivalent
       to the
chown
() function defined in the System Interfaces volume of
       POSIX.1â2017, called with the following arguments:

        1. The
file
operand shall be used as the
path
argument."
91,1,chown,"The
file
operand shall be used as the
path
argument. 2. The user ID indicated by the
owner
portion of the first
           operand shall be used as the
owner
argument."
91,2,chown,"The user ID indicated by the
owner
portion of the first
           operand shall be used as the
owner
argument. 3. If the
group
portion of the first operand is given, the group
           ID indicated by it shall be used as the
group
argument;
           otherwise, the group ownership shall not be changed."
91,3,chown,"3. If the
group
portion of the first operand is given, the group
           ID indicated by it shall be used as the
group
argument;
           otherwise, the group ownership shall not be changed. Unless
chown
is invoked by a process with appropriate privileges,
       the set-user-ID and set-group-ID bits of a regular file shall be
       cleared upon successful completion; the set-user-ID and set-group-
       ID bits of other file types may be cleared."
92,0,chrt,"chrt
sets or retrieves the real-time scheduling attributes of an
       existing
PID
, or runs
command
with the given attributes."
93,0,chroot,"Run COMMAND with root directory set to NEWROOT.
--groups
=
G_LIST
specify supplementary groups as g1,g2,..,gN
--userspec
=
USER
:GROUP
              specify user and group (ID or name) to use
--skip-chdir
do not change working directory to '/'
--help
display this help and exit
--version
output version information and exit

       If no command is given, run '""$SHELL""
-i
' (default: '/bin/sh
-i
').
Exit status:
125    if the chroot command itself fails

       126    if COMMAND is found but cannot be invoked

       127    if COMMAND cannot be found

       -      the exit status of COMMAND otherwise"
94,0,cksum,"Print or verify checksums. By default use the 32 bit CRC
       algorithm. With no FILE, or when FILE is -, read standard input."
94,1,cksum,"With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too. -a
,
--algorithm
=
TYPE
select the digest type to use."
94,2,cksum,"Mandatory arguments to long options are mandatory for short
       options too. -a
,
--algorithm
=
TYPE
select the digest type to use. See DIGEST below
--base64
emit base64-encoded digests, not hexadecimal
-c
,
--check
read checksums from the FILEs and check them
-l
,
--length
=
BITS
digest length in bits; must not exceed the max for the
              blake2 algorithm and must be a multiple of 8
--raw
emit a raw binary digest, not hexadecimal
--tag
create a BSD-style checksum (the default)
--untagged
create a reversed style checksum, without digest type
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--debug
indicate which implementation used
--help
display this help and exit
--version
output version information and exit
DIGEST determines the digest algorithm and default output format:
sysv   (equivalent to sum
-s
)

       bsd    (equivalent to sum
-r
)

       crc    (equivalent to cksum)

       crc32b (only available through cksum)

       md5    (equivalent to md5sum)

       sha1   (equivalent to sha1sum)

       sha224 (equivalent to sha224sum)

       sha256 (equivalent to sha256sum)

       sha384 (equivalent to sha384sum)

       sha512 (equivalent to sha512sum)

       blake2b
              (equivalent to b2sum)

       sm3    (only available through cksum)

       When checking, the input should be a former output of this
       program, or equivalent standalone program."
95,0,cifsiostat,"The
cifsiostat
command displays statistics about read and write
       operations on CIFS filesystems. The
interval
parameter specifies the amount of time in seconds
       between each report. The first report contains statistics for the
       time since system startup (boot), unless the
-y
option is used (in
       this case, the first report is omitted)."
95,1,cifsiostat,"The first report contains statistics for the
       time since system startup (boot), unless the
-y
option is used (in
       this case, the first report is omitted). Each subsequent report
       contains statistics collected during the interval since the
       previous report. A report consists of a CIFS header row followed
       by a line of statistics for each CIFS filesystem that is mounted."
95,2,cifsiostat,"A report consists of a CIFS header row followed
       by a line of statistics for each CIFS filesystem that is mounted. The
count
parameter can be specified in conjunction with the
interval
parameter. If the
count
parameter is specified, the value
       of
count
determines the number of reports generated at
interval
seconds apart."
95,3,cifsiostat,"The
count
parameter can be specified in conjunction with the
interval
parameter. If the
count
parameter is specified, the value
       of
count
determines the number of reports generated at
interval
seconds apart. If the
interval
parameter is specified without the
count
parameter, the
cifsiostat
command generates reports
       continuously."
96,0,cksum,"The
cksum
utility shall calculate and write to standard output a
       cyclic redundancy check (CRC) for each input file, and also write
       to standard output the number of octets in each file. The CRC used
       is based on the polynomial used for CRC error checking in the
       ISO/IEC 8802â3:1996 standard (Ethernet). The encoding for the CRC checksum is defined by the generating
       polynomial:
G
(
x
)=
x
32+
x
26+
x
23+
x
22+
x
16+
x
12+
x
11+
x
10+
x
8+
x
7+
x
5+
x
4+
x
2+
x
+1

       Mathematically, the CRC value corresponding to a given file shall
       be defined by the following procedure:

        1."
96,1,cksum,"The encoding for the CRC checksum is defined by the generating
       polynomial:
G
(
x
)=
x
32+
x
26+
x
23+
x
22+
x
16+
x
12+
x
11+
x
10+
x
8+
x
7+
x
5+
x
4+
x
2+
x
+1

       Mathematically, the CRC value corresponding to a given file shall
       be defined by the following procedure:

        1. The
n
bits to be evaluated are considered to be the
           coefficients of a mod 2 polynomial
M
(
x
) of degree
n
-1. These
n
bits are the bits from the file, with the most significant
           bit being the most significant bit of the first octet of the
           file and the last bit being the least significant bit of the
           last octet, padded with zero bits (if necessary) to achieve an
           integral number of octets, followed by one or more octets
           representing the length of the file as a binary value, least
           significant octet first."
96,2,cksum,"These
n
bits are the bits from the file, with the most significant
           bit being the most significant bit of the first octet of the
           file and the last bit being the least significant bit of the
           last octet, padded with zero bits (if necessary) to achieve an
           integral number of octets, followed by one or more octets
           representing the length of the file as a binary value, least
           significant octet first. The smallest number of octets capable
           of representing this integer shall be used. 2."
96,3,cksum,"2. M
(
x
) is multiplied by
x
32 (that is, shifted left 32 bits) and
           divided by
G
(
x
) using mod 2 division, producing a remainder
R
(
x
) of degree â¤ 31. 3."
96,4,cksum,"3. The coefficients of
R
(
x
) are considered to be a 32-bit
           sequence. 4."
96,5,cksum,"The coefficients of
R
(
x
) are considered to be a 32-bit
           sequence. 4. The bit sequence is complemented and the result is the CRC."
97,0,clear,"@CLEAR@
clears your terminal's screen if this is possible,
       including the terminal's scrollback buffer (if the extended âE3â
       capability is defined). @CLEAR@
looks in the environment for the
       terminal type given by the environment variable
TERM
, and then in
       the
terminfo
database to determine how to clear the screen. @CLEAR@
writes to the standard output."
97,1,clear,"@CLEAR@
looks in the environment for the
       terminal type given by the environment variable
TERM
, and then in
       the
terminfo
database to determine how to clear the screen. @CLEAR@
writes to the standard output. You can redirect the
       standard output to a file (which prevents
@CLEAR@
from actually
       clearing the screen), and later
cat
the file to the screen,
       clearing it at that point."
98,0,clear,"@CLEAR@
clears your terminal's screen if this is possible,
       including the terminal's scrollback buffer (if the extended âE3â
       capability is defined). @CLEAR@
looks in the environment for the
       terminal type given by the environment variable
TERM
, and then in
       the
terminfo
database to determine how to clear the screen. @CLEAR@
writes to the standard output."
98,1,clear,"@CLEAR@
looks in the environment for the
       terminal type given by the environment variable
TERM
, and then in
       the
terminfo
database to determine how to clear the screen. @CLEAR@
writes to the standard output. You can redirect the
       standard output to a file (which prevents
@CLEAR@
from actually
       clearing the screen), and later
cat
the file to the screen,
       clearing it at that point."
99,0,clustervis,"clustervis
displays three dimensional bar charts of CPU
       utilization and network traffic for one or most hosts in a
       cluster. An alternative two dimensional cluster performance
       monitoring tool is
pmgcluster
(1). clustervis
is designed to
       provide a scalable overview of the performance of large clusters."
99,1,clustervis,"clustervis
is designed to
       provide a scalable overview of the performance of large clusters. Other tools such as
pmchart(1)
and
pmgsys
(1) provide drill-down
       details on a per-host basis. These tools may be launched by
       clicking on the purple base plane for a particular host and then
       selecting a tool from the
launch
menu in
clustervis
."
99,2,clustervis,"These tools may be launched by
       clicking on the purple base plane for a particular host and then
       selecting a tool from the
launch
menu in
clustervis
. The
-H
,
-h
and
-a
arguments are all mutually exclusive and have
       the following semantics; if none of
-H
,
-h
or
-a
is given, and
       either the file
/etc/nodes
or
/etc/ace/nodes
exists, or the
$PCP_CLUSTER_CONFIG
environment variable is set, then use the
       named file as the set of hosts for live monitoring. If the
       default nodes file does not exist, the environment variable is not
       set and none of the three flags were given, an error is reported."
99,3,clustervis,"If the
       default nodes file does not exist, the environment variable is not
       set and none of the three flags were given, an error is reported. Otherwise, if
-H
is given, then the set of hosts is given in
nodesfile
. The
-h
flag specifies one or more (comma separated with no spaces)
       hosts for live monitoring and the
-a
flag specifies one or more
       archives for archive replay (comma separated)."
99,4,clustervis,"The
-h
flag specifies one or more (comma separated with no spaces)
       hosts for live monitoring and the
-a
flag specifies one or more
       archives for archive replay (comma separated). The height of the CPU stack is proportional to the CPU utilization
       in each of the modes
sys
(red, executing in the kernel) and
user
(blue, executing user code). The network traffic stack is shown
       for each network interface as the packet rate
in
(light blue),
out
(orange) and
errors
(red)."
99,5,clustervis,"The network traffic stack is shown
       for each network interface as the packet rate
in
(light blue),
out
(orange) and
errors
(red). The hight of the network stack is
       modulated by the
-m
argument, with a default of
750
packets/second
       representing saturated network traffic. clustervis
generates a
pmview(1)
configuration file, and passes
       most command line options to
pmview(1)
."
99,6,clustervis,"The hight of the network stack is
       modulated by the
-m
argument, with a default of
750
packets/second
       representing saturated network traffic. clustervis
generates a
pmview(1)
configuration file, and passes
       most command line options to
pmview(1)
. Therefore, the command
       line options
-A
,
-a
,
-C
,
-h
,
-n
,
-O
,
-p
,
-S
,
-t
,
-T
,
-Z
and
-z
,
       and the user interface are described in the
pmview(1)
man page."
100,0,cmp,"Compare two files byte by byte. The optional SKIP1 and SKIP2 specify the number of bytes to skip
       at the beginning of each file (zero by default). Mandatory arguments to long options are mandatory for short
       options too."
100,1,cmp,"Mandatory arguments to long options are mandatory for short
       options too. -b
,
--print-bytes
print differing bytes
-i
,
--ignore-initial
=
SKIP
skip first SKIP bytes of both inputs
-i
,
--ignore-initial
=
SKIP1
:SKIP2
              skip first SKIP1 bytes of FILE1 and first SKIP2 bytes of
              FILE2
-l
,
--verbose
output byte numbers and differing byte values
-n
,
--bytes
=
LIMIT
compare at most LIMIT bytes
-s
,
--quiet
,
--silent
suppress all normal output
--help
display this help and exit
-v
,
--version
output version information and exit

       SKIP values may be followed by the following multiplicative
       suffixes: kB 1000, K 1024, MB 1,000,000, M 1,048,576, GB
       1,000,000,000, G 1,073,741,824, and so on for T, P, E, Z, Y. If a FILE is '-' or missing, read standard input."
100,2,cmp,"-b
,
--print-bytes
print differing bytes
-i
,
--ignore-initial
=
SKIP
skip first SKIP bytes of both inputs
-i
,
--ignore-initial
=
SKIP1
:SKIP2
              skip first SKIP1 bytes of FILE1 and first SKIP2 bytes of
              FILE2
-l
,
--verbose
output byte numbers and differing byte values
-n
,
--bytes
=
LIMIT
compare at most LIMIT bytes
-s
,
--quiet
,
--silent
suppress all normal output
--help
display this help and exit
-v
,
--version
output version information and exit

       SKIP values may be followed by the following multiplicative
       suffixes: kB 1000, K 1024, MB 1,000,000, M 1,048,576, GB
       1,000,000,000, G 1,073,741,824, and so on for T, P, E, Z, Y. If a FILE is '-' or missing, read standard input. Exit status is
       0 if inputs are the same, 1 if different, 2 if trouble."
101,0,cmp,"The
cmp
utility shall compare two files. The
cmp
utility shall
       write no output if the files are the same. Under default options,
       if they differ, it shall write to standard output the byte and
       line number at which the first difference occurred."
101,1,cmp,"The
cmp
utility shall
       write no output if the files are the same. Under default options,
       if they differ, it shall write to standard output the byte and
       line number at which the first difference occurred. Bytes and
       lines shall be numbered beginning with 1."
102,0,cmtime,"Determines min, max, and average times for various ""steps"" in RDMA
       CM connection setup and teardown between a client and server
       application. ""Steps"" that are timed are: create ID, bind address, resolve
       address, resolve route, create QP, modify QP to INIT, modify QP to
       RTR, modify QP to RTS, CM connect, client establish, disconnect,
       destroy QP, and destroy ID. Many operations are asynchronous, allowing progress on multiple
       connections simultanesously."
102,1,cmtime,"Many operations are asynchronous, allowing progress on multiple
       connections simultanesously. The 'sum' output adds the time that
       all connections took for a given step. The average 'us/conn' is
       the sum divided by the number of connections."
102,2,cmtime,"The average 'us/conn' is
       the sum divided by the number of connections. This is useful to
       identify steps which take a significant amount of time. The min
       and max values are the smallest and largest times that any single
       connection took to complete a given step."
102,3,cmtime,"The min
       and max values are the smallest and largest times that any single
       connection took to complete a given step. The 'total' and 'avg/iter' times measure the time to complete a
       given step for all connections. These two values take into
       account asynchronous operations."
102,4,cmtime,"These two values take into
       account asynchronous operations. For steps which are serial, the
       total and sum values will be roughly the same. For asynchronous
       steps, the total may be significantly lower than the sum, as
       multiple connections will be in progress simultanesously."
102,5,cmtime,"For asynchronous
       steps, the total may be significantly lower than the sum, as
       multiple connections will be in progress simultanesously. The
       avg/iter is the total time divided by the number of connections. In many cases, times may not be available or only available on the
       client."
102,6,cmtime,"The
       avg/iter is the total time divided by the number of connections. In many cases, times may not be available or only available on the
       client. Is such situations, the output will show 0."
103,0,collectl2pcp,"collectl2pcp
reads raw
collectl
(1) data from each
file
and creates
       a new PCP archive with basename
archive
.  Each input
file
may be
       gzipped (with
.gz
suffix).  The PCP
archive
and at least one input
file
are required arguments."
104,0,col,"col
filters out reverse (and half-reverse) line feeds so the
       output is in the correct order, with only forward and half-forward
       line feeds. It also replaces any whitespace characters with tabs
       where possible. This can be useful in processing the output of
nroff(1)
and
tbl(1)
."
104,1,col,"It also replaces any whitespace characters with tabs
       where possible. This can be useful in processing the output of
nroff(1)
and
tbl(1)
. col
reads from standard input and writes to standard output."
105,0,colcrt,"colcrt
provides virtual half-line and reverse line feed sequences
       for terminals without such capability, and on which overstriking
       is destructive. Half-line characters and underlining (changed to
       dashing `-') are placed on new lines in between the normal output
       lines."
106,0,colon,"This utility shall only expand command
argument
s.  It is used when
       a command is needed, as in the
then
condition of an
if
command,
       but nothing is to be done by the command."
107,0,colrm,"colrm
removes selected columns from a file. Input is taken from
       standard input. Output is sent to standard output."
107,1,colrm,"Output is sent to standard output. If called with one parameter the columns of each line will be
       removed starting with the specified
first
column. If called with
       two parameters the columns from the
first
column to the
last
column will be removed."
107,2,colrm,"If called with one parameter the columns of each line will be
       removed starting with the specified
first
column. If called with
       two parameters the columns from the
first
column to the
last
column will be removed. Column numbering starts with column 1."
108,0,column,"The
column
utility formats its input into multiple columns. It
       supports three modes:
fill columns before rows
This is the default mode (required for backwards
           compatibility). fill rows before columns
This mode is enabled with the
-x, --fillrows
option."
108,1,column,"fill rows before columns
This mode is enabled with the
-x, --fillrows
option. create a table
Determine the number of columns the input contains and create
           a table. This mode is enabled with the
-t, --table
option."
108,2,column,"This mode is enabled with the
-t, --table
option. Output is aligned to the terminal width in interactive mode
           and 80 columns in non-interactive mode (see
--output-width
for
           more details). Custom formatting can be applied by using
           various
--table-\
* options."
108,3,column,"Custom formatting can be applied by using
           various
--table-\
* options. Input is taken from
file
, or otherwise from standard input. Empty
       lines are ignored and all invalid multibyte sequences are encoded
       with the x<hex> convention."
109,0,comm,"Compare sorted files FILE1 and FILE2 line by line. When FILE1 or FILE2 (not both) is -, read standard input. With no options, produce three-column output."
109,1,comm,"With no options, produce three-column output. Column one contains
       lines unique to FILE1, column two contains lines unique to FILE2,
       and column three contains lines common to both files. -1
suppress column 1 (lines unique to FILE1)
-2
suppress column 2 (lines unique to FILE2)
-3
suppress column 3 (lines that appear in both files)
--check-order
check that the input is correctly sorted, even if all input
              lines are pairable
--nocheck-order
do not check that the input is correctly sorted
--output-delimiter
=
STR
separate columns with STR
--total
output a summary
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit

       Comparisons honor the rules specified by 'LC_COLLATE'."
110,0,comm,"The
comm
utility shall read
file1
and
file2
, which should be
       ordered in the current collating sequence, and produce three text
       columns as output: lines only in
file1
, lines only in
file2
, and
       lines in both files. If the lines in both files are not ordered according to the
       collating sequence of the current locale, the results are
       unspecified. If the collating sequence of the current locale does not have a
       total ordering of all characters (see the Base Definitions volume
       of POSIX.1â2017,
Section 7.3.2
,
LC_COLLATE
) and any lines from the
       input files collate equally but are not identical,
comm
should
       treat them as different lines but may treat them as being the
       same."
110,1,comm,"If the lines in both files are not ordered according to the
       collating sequence of the current locale, the results are
       unspecified. If the collating sequence of the current locale does not have a
       total ordering of all characters (see the Base Definitions volume
       of POSIX.1â2017,
Section 7.3.2
,
LC_COLLATE
) and any lines from the
       input files collate equally but are not identical,
comm
should
       treat them as different lines but may treat them as being the
       same. If it treats them as different,
comm
should expect them to
       be ordered according to a further byte-by-byte comparison using
       the collating sequence for the POSIX locale and if they are not
       ordered in this way, the output of
comm
can identify such lines as
       being both unique to
file1
and unique to
file2
instead of being in
       both files."
111,0,comp_err,"comp_err
creates the errmsg.sys file that is used by
mariadbd
to
       determine the error messages to display for different error codes. comp_err
normally is run automatically when MariaDB is built. It
       compiles the errmsg.sys file from the plaintext file located at
       sql/share/errmsg.txt in MariaDB source distributions."
111,1,comp_err,"It
       compiles the errmsg.sys file from the plaintext file located at
       sql/share/errmsg.txt in MariaDB source distributions. comp_err
also generates mysqld_error.h, mysqld_ername.h, and
       sql_state.h header files. For more information about how error messages are defined, see the
       MariaDB Manual."
111,2,comp_err,"For more information about how error messages are defined, see the
       MariaDB Manual. Invoke
comp_err
like this:

           shell>
comp_err [
options
]
comp_err
supports the following options. â¢
--help
,
-?"
111,3,comp_err,"â¢
--help
,
-? Display a help message and exit. â¢
--charset=
path
,
-C
path
The character set directory."
111,4,comp_err,"â¢
--charset=
path
,
-C
path
The character set directory. The default is
           ../sql/share/charsets. â¢
--debug=
debug_options
,
-#
debug_options
Write a debugging log."
111,5,comp_err,"â¢
--debug=
debug_options
,
-#
debug_options
Write a debugging log. A typical
debug_options
string is
           Â´d:t:O,
file_name
Â´. The default is Â´d:t:O,/tmp/comp_err.traceÂ´."
111,6,comp_err,"The default is Â´d:t:O,/tmp/comp_err.traceÂ´. â¢
--debug-info
,
-T
Print some debugging information when the program exits. â¢
--header_file=
file_name
,
-H
file_name
The name of the error header file."
111,7,comp_err,"â¢
--header_file=
file_name
,
-H
file_name
The name of the error header file. The default is
           mariadbd_error.h. â¢
--in_file=
file_name
,
-F
file_name
The name of the input file."
111,8,comp_err,"â¢
--in_file=
file_name
,
-F
file_name
The name of the input file. The default is
           ../sql/share/errmsg.txt. â¢
--name_file=
file_name
,
-N
file_name
The name of the error name file."
111,9,comp_err,"â¢
--name_file=
file_name
,
-N
file_name
The name of the error name file. The default is
           mysqld_ername.h. â¢
--out_dir=
path
,
-D
path
The name of the output base directory."
111,10,comp_err,"â¢
--out_dir=
path
,
-D
path
The name of the output base directory. The default is
           ../sql/share/. â¢
--out_file=
file_name
,
-O
file_name
The name of the output file."
111,11,comp_err,"â¢
--out_file=
file_name
,
-O
file_name
The name of the output file. The default is errmsg.sys. â¢
--statefile=
file_name
,
-S
file_name
The name for the SQLSTATE header file."
111,12,comp_err,"â¢
--statefile=
file_name
,
-S
file_name
The name for the SQLSTATE header file. The default is
           sql_state.h. â¢
--version
,
-V
Display version information and exit."
112,0,coredumpctl,"coredumpctl
is a tool that can be used to retrieve and process
       core dumps and metadata which were saved by
systemd-coredump(8)
."
113,0,compress,"The
compress
utility shall attempt to reduce the size of the named
       files by using adaptive Lempel-Ziv coding algorithm. Note:
Lempel-Ziv is US Patent 4464650, issued to William Eastman,
              Abraham Lempel, Jacob Ziv, Martin Cohn on August 7th, 1984,
              and assigned to Sperry Corporation. Lempel-Ziv-Welch compression is covered by US Patent
                 4558302, issued to Terry A."
113,1,compress,"Lempel-Ziv-Welch compression is covered by US Patent
                 4558302, issued to Terry A. Welch on December 10th,
                 1985, and assigned to Sperry Corporation. On systems not supporting adaptive Lempel-Ziv coding algorithm,
       the input files shall not be changed and an error value greater
       than two shall be returned."
113,2,compress,"On systems not supporting adaptive Lempel-Ziv coding algorithm,
       the input files shall not be changed and an error value greater
       than two shall be returned. Except when the output is to the
       standard output, each file shall be replaced by one with the
       extension
.Z
. If the invoking process has appropriate privileges,
       the ownership, modes, access time, and modification time of the
       original file are preserved."
113,3,compress,"If the invoking process has appropriate privileges,
       the ownership, modes, access time, and modification time of the
       original file are preserved. If appending the
.Z
to the filename
       would make the name exceed {NAME_MAX} bytes, the command shall
       fail. If no files are specified, the standard input shall be
       compressed to the standard output."
114,0,continue,"If
n
is specified, the
continue
utility shall return to the top of
       the
n
th enclosing
for
,
while
, or
until
loop. If
n
is not
       specified,
continue
shall behave as if
n
was specified as 1. Returning to the top of the loop involves repeating the condition
       list of a
while
or
until
loop or performing the next assignment of
       a
for
loop, and re-executing the loop if appropriate."
114,1,continue,"Returning to the top of the loop involves repeating the condition
       list of a
while
or
until
loop or performing the next assignment of
       a
for
loop, and re-executing the loop if appropriate. The value of
n
is a positive decimal integer. If
n
is greater than
       the number of enclosing loops, the outermost enclosing loop shall
       be used."
114,2,continue,"If
n
is greater than
       the number of enclosing loops, the outermost enclosing loop shall
       be used. If there is no enclosing loop, the behavior is
       unspecified. The meaning of ``enclosing'' shall be as specified in the
       description of the
break
utility."
115,0,coresched,"The
coresched
command is used to retrieve or modify the core
       scheduling cookies of a running process given its
pid
, or to spawn
       a new
command
with core scheduling cookies. Core scheduling permits the definition of groups of tasks that are
       allowed to share a physical core. This is done by assigning a
       cookie to each task."
115,1,coresched,"This is done by assigning a
       cookie to each task. Only tasks have the same cookie are allowed
       to be scheduled on the same physical core. It is possible to either assign a new random cookie to a task, or
       copy a cookie from another task."
115,2,coresched,"Only tasks have the same cookie are allowed
       to be scheduled on the same physical core. It is possible to either assign a new random cookie to a task, or
       copy a cookie from another task. It is not possible to choose the
       value of the cookie."
116,0,command,"The
command
utility shall cause the shell to treat the arguments
       as a simple command, suppressing the shell function lookup that is
       described in
Section 2.9.1.1
,
Command Search and Execution
, item
       1b. If the
command_name
is the same as the name of one of the special
       built-in utilities, the special properties in the enumerated list
       at the beginning of
Section 2.14
,
Special Built-In Utilities
shall
       not occur. In every other respect, if
command_name
is not the name
       of a function, the effect of
command
(with no options) shall be
       the same as omitting
command
."
116,1,command,"If the
command_name
is the same as the name of one of the special
       built-in utilities, the special properties in the enumerated list
       at the beginning of
Section 2.14
,
Special Built-In Utilities
shall
       not occur. In every other respect, if
command_name
is not the name
       of a function, the effect of
command
(with no options) shall be
       the same as omitting
command
. When the
-v
or
-V
option is used, the
command
utility shall
       provide information concerning how a command name is interpreted
       by the shell."
117,0,coreutils,"Execute the PROGRAM_NAME built-in program with the given
       PARAMETERS.
--help
display this help and exit
--version
output version information and exit

       Use: 'coreutils
--coreutils-prog
=
PROGRAM_NAME
--help
' for
       individual program help."
118,0,cp,"Copy SOURCE to DEST, or multiple SOURCE(s) to DIRECTORY. Mandatory arguments to long options are mandatory for short
       options too. -a
,
--archive
same as
-dR --preserve
=
all
--attributes-only
don't copy the file data, just the attributes
--backup
[=
CONTROL
]
              make a backup of each existing destination file
-b
like
--backup
but does not accept an argument
--copy-contents
copy contents of special files when recursive
-d
same as
--no-dereference --preserve
=
links
--debug
explain how a file is copied."
118,1,cp,"-a
,
--archive
same as
-dR --preserve
=
all
--attributes-only
don't copy the file data, just the attributes
--backup
[=
CONTROL
]
              make a backup of each existing destination file
-b
like
--backup
but does not accept an argument
--copy-contents
copy contents of special files when recursive
-d
same as
--no-dereference --preserve
=
links
--debug
explain how a file is copied. Implies
-v
-f
,
--force
if an existing destination file cannot be opened, remove it
              and try again (this option is ignored when the
-n
option is
              also used)
-i
,
--interactive
prompt before overwrite (overrides a previous
-n
option)
-H
follow command-line symbolic links in SOURCE
-l
,
--link
hard link files instead of copying
-L
,
--dereference
always follow symbolic links in SOURCE
-n
,
--no-clobber
(deprecated) silently skip existing files. See also
--update
-P
,
--no-dereference
never follow symbolic links in SOURCE
-p
same as
--preserve
=
mode
,ownership,timestamps
--preserve
[=
ATTR_LIST
]
              preserve the specified attributes
--no-preserve
=
ATTR_LIST
don't preserve the specified attributes
--parents
use full source file name under DIRECTORY
-R
,
-r
,
--recursive
copy directories recursively
--reflink
[=
WHEN
]
              control clone/CoW copies."
118,2,cp,"See also
--update
-P
,
--no-dereference
never follow symbolic links in SOURCE
-p
same as
--preserve
=
mode
,ownership,timestamps
--preserve
[=
ATTR_LIST
]
              preserve the specified attributes
--no-preserve
=
ATTR_LIST
don't preserve the specified attributes
--parents
use full source file name under DIRECTORY
-R
,
-r
,
--recursive
copy directories recursively
--reflink
[=
WHEN
]
              control clone/CoW copies. See below
--remove-destination
remove each existing destination file before attempting to
              open it (contrast with
--force
)
--sparse
=
WHEN
control creation of sparse files. See below
--strip-trailing-slashes
remove any trailing slashes from each SOURCE argument
-s
,
--symbolic-link
make symbolic links instead of copying
-S
,
--suffix
=
SUFFIX
override the usual backup suffix
-t
,
--target-directory
=
DIRECTORY
copy all SOURCE arguments into DIRECTORY
-T
,
--no-target-directory
treat DEST as a normal file
--update
[=
UPDATE
]
              control which existing files are updated;
              UPDATE={all,none,none-fail,older(default)}
-u
equivalent to
--update
[=
older
]."
118,3,cp,"See below
--strip-trailing-slashes
remove any trailing slashes from each SOURCE argument
-s
,
--symbolic-link
make symbolic links instead of copying
-S
,
--suffix
=
SUFFIX
override the usual backup suffix
-t
,
--target-directory
=
DIRECTORY
copy all SOURCE arguments into DIRECTORY
-T
,
--no-target-directory
treat DEST as a normal file
--update
[=
UPDATE
]
              control which existing files are updated;
              UPDATE={all,none,none-fail,older(default)}
-u
equivalent to
--update
[=
older
]. See below
-v
,
--verbose
explain what is being done
--keep-directory-symlink
follow existing symlinks to directories
-x
,
--one-file-system
stay on this file system
-Z
set SELinux security context of destination file to default
              type
--context
[=
CTX
]
              like
-Z
, or if CTX is specified then set the SELinux or
              SMACK security context to CTX
--help
display this help and exit
--version
output version information and exit

       ATTR_LIST is a comma-separated list of attributes. Attributes are
       'mode' for permissions (including any ACL and xattr permissions),
       'ownership' for user and group, 'timestamps' for file timestamps,
       'links' for hard links, 'context' for security context, 'xattr'
       for extended attributes, and 'all' for all attributes."
118,4,cp,"Attributes are
       'mode' for permissions (including any ACL and xattr permissions),
       'ownership' for user and group, 'timestamps' for file timestamps,
       'links' for hard links, 'context' for security context, 'xattr'
       for extended attributes, and 'all' for all attributes. By default, sparse SOURCE files are detected by a crude heuristic
       and the corresponding DEST file is made sparse as well. That is
       the behavior selected by
--sparse
=
auto
."
118,5,cp,"That is
       the behavior selected by
--sparse
=
auto
. Specify
--sparse
=
always
to create a sparse DEST file whenever the SOURCE file contains a
       long enough sequence of zero bytes. Use
--sparse
=
never
to inhibit
       creation of sparse files."
118,6,cp,"Use
--sparse
=
never
to inhibit
       creation of sparse files. UPDATE controls which existing files in the destination are
       replaced. 'all' is the default operation when an
--update
option
       is not specified, and results in all existing files in the
       destination being replaced."
118,7,cp,"'all' is the default operation when an
--update
option
       is not specified, and results in all existing files in the
       destination being replaced. 'none' is like the
--no-clobber
option, in that no files in the destination are replaced, and
       skipped files do not induce a failure. 'none-fail' also ensures
       no files are replaced in the destination, but any skipped files
       are diagnosed and induce a failure."
118,8,cp,"'none-fail' also ensures
       no files are replaced in the destination, but any skipped files
       are diagnosed and induce a failure. 'older' is the default
       operation when
--update
is specified, and results in files being
       replaced if they're older than the corresponding source file. When
--reflink
[=
always
] is specified, perform a lightweight copy,
       where the data blocks are copied only when modified."
118,9,cp,"When
--reflink
[=
always
] is specified, perform a lightweight copy,
       where the data blocks are copied only when modified. If this is
       not possible the copy fails, or if
--reflink
=
auto
is specified,
       fall back to a standard copy. Use
--reflink
=
never
to ensure a
       standard copy is performed."
118,10,cp,"Use
--reflink
=
never
to ensure a
       standard copy is performed. The backup suffix is '~', unless set with
--suffix
or
       SIMPLE_BACKUP_SUFFIX. The version control method may be selected
       via the
--backup
option or through the VERSION_CONTROL environment
       variable."
118,11,cp,"The backup suffix is '~', unless set with
--suffix
or
       SIMPLE_BACKUP_SUFFIX. The version control method may be selected
       via the
--backup
option or through the VERSION_CONTROL environment
       variable. Here are the values:

       none, off
              never make backups (even if
--backup
is given)

       numbered, t
              make numbered backups

       existing, nil
              numbered if numbered backups exist, simple otherwise

       simple, never
              always make simple backups

       As a special case, cp makes a backup of SOURCE when the force and
       backup options are given and SOURCE and DEST are the same name for
       an existing, regular file."
119,0,cp,"The first synopsis form is denoted by two operands, neither of
       which are existing files of type directory. The
cp
utility shall
       copy the contents of
source_file
(or, if
source_file
is a file of
       type symbolic link, the contents of the file referenced by
source_file
) to the destination path named by
target_file. The second synopsis form is denoted by two or more operands where
       the
-R
option is not specified and the first synopsis form is not
       applicable."
119,1,cp,"The second synopsis form is denoted by two or more operands where
       the
-R
option is not specified and the first synopsis form is not
       applicable. It shall be an error if any
source_file
is a file of
       type directory, if
target
does not exist, or if
target
does not
       name a directory. The
cp
utility shall copy the contents of each
source_file
(or, if
source_file
is a file of type symbolic link,
       the contents of the file referenced by
source_file
) to the
       destination path named by the concatenation of
target
, a single
       <slash> character if
target
did not end in a <slash>, and the last
       component of
source_file
."
119,2,cp,"The
cp
utility shall copy the contents of each
source_file
(or, if
source_file
is a file of type symbolic link,
       the contents of the file referenced by
source_file
) to the
       destination path named by the concatenation of
target
, a single
       <slash> character if
target
did not end in a <slash>, and the last
       component of
source_file
. The third synopsis form is denoted by two or more operands where
       the
-R
option is specified. The
cp
utility shall copy each file in
       the file hierarchy rooted in each
source_file
to a destination
       path named as follows:

        *  If
target
exists and names an existing directory, the name of
           the corresponding destination path for each file in the file
           hierarchy shall be the concatenation of
target
, a single
           <slash> character if
target
did not end in a <slash>, and the
           pathname of the file relative to the directory containing
source_file
."
119,3,cp,"The
cp
utility shall copy each file in
       the file hierarchy rooted in each
source_file
to a destination
       path named as follows:

        *  If
target
exists and names an existing directory, the name of
           the corresponding destination path for each file in the file
           hierarchy shall be the concatenation of
target
, a single
           <slash> character if
target
did not end in a <slash>, and the
           pathname of the file relative to the directory containing
source_file
. *  If
target
does not exist and two operands are specified, the
           name of the corresponding destination path for
source_file
shall be
target
; the name of the corresponding destination
           path for all other files in the file hierarchy shall be the
           concatenation of
target
, a <slash> character, and the pathname
           of the file relative to
source_file
. It shall be an error if
target
does not exist and more than two
       operands are specified, or if
target
exists and does not name a
       directory."
119,4,cp,"It shall be an error if
target
does not exist and more than two
       operands are specified, or if
target
exists and does not name a
       directory. In the following description, the term
dest_file
refers to the
       file named by the destination path. The term
source_file
refers to
       the file that is being copied, whether specified as an operand or
       a file in a file hierarchy rooted in a
source_file
operand."
119,5,cp,"The term
source_file
refers to
       the file that is being copied, whether specified as an operand or
       a file in a file hierarchy rooted in a
source_file
operand. If
source_file
is a file of type symbolic link:

        *  If the
-R
option was not specified,
cp
shall take actions
           based on the type and contents of the file referenced by the
           symbolic link, and not by the symbolic link itself, unless the
-P
option was specified. *  If the
-R
option was specified:

           --  If none of the options
-H
,
-L
, nor
-P
were specified, it
               is unspecified which of
-H
,
-L
, or
-P
will be used as a
               default."
119,6,cp,"*  If the
-R
option was specified:

           --  If none of the options
-H
,
-L
, nor
-P
were specified, it
               is unspecified which of
-H
,
-L
, or
-P
will be used as a
               default. --  If the
-H
option was specified,
cp
shall take actions
               based on the type and contents of the file referenced by
               any symbolic link specified as a
source_file
operand. --  If the
-L
option was specified,
cp
shall take actions
               based on the type and contents of the file referenced by
               any symbolic link specified as a
source_file
operand or
               any symbolic links encountered during traversal of a file
               hierarchy."
119,7,cp,"--  If the
-L
option was specified,
cp
shall take actions
               based on the type and contents of the file referenced by
               any symbolic link specified as a
source_file
operand or
               any symbolic links encountered during traversal of a file
               hierarchy. --  If the
-P
option was specified,
cp
shall copy any symbolic
               link specified as a
source_file
operand and any symbolic
               links encountered during traversal of a file hierarchy,
               and shall not follow any symbolic links. For each
source_file
, the following steps shall be taken:

        1."
119,8,cp,"For each
source_file
, the following steps shall be taken:

        1. If
source_file
references the same file as
dest_file
,
cp
may
           write a diagnostic message to standard error; it shall do
           nothing more with
source_file
and shall go on to any remaining
           files. 2."
119,9,cp,"2. If
source_file
is of type directory, the following steps shall
           be taken:

            a. If the
-R
option was not specified,
cp
shall write a
               diagnostic message to standard error, do nothing more with
source_file
, and go on to any remaining files."
119,10,cp,"If the
-R
option was not specified,
cp
shall write a
               diagnostic message to standard error, do nothing more with
source_file
, and go on to any remaining files. b. If
source_file
was not specified as an operand and
source_file
is dot or dot-dot,
cp
shall do nothing more
               with
source_file
and go on to any remaining files."
119,11,cp,"If
source_file
was not specified as an operand and
source_file
is dot or dot-dot,
cp
shall do nothing more
               with
source_file
and go on to any remaining files. c. If
dest_file
exists and it is a file type not specified by
               the System Interfaces volume of POSIX.1â2017, the behavior
               is implementation-defined."
119,12,cp,"If
dest_file
exists and it is a file type not specified by
               the System Interfaces volume of POSIX.1â2017, the behavior
               is implementation-defined. d. If
dest_file
exists and it is not of type directory,
cp
shall write a diagnostic message to standard error, do
               nothing more with
source_file
or any files below
source_file
in the file hierarchy, and go on to any
               remaining files."
119,13,cp,"If
dest_file
exists and it is not of type directory,
cp
shall write a diagnostic message to standard error, do
               nothing more with
source_file
or any files below
source_file
in the file hierarchy, and go on to any
               remaining files. e. If the directory
dest_file
does not exist, it shall be
               created with file permission bits set to the same value as
               those of
source_file
, modified by the file creation mask
               of the user if the
-p
option was not specified, and then
               bitwise-inclusively OR'ed with S_IRWXU."
119,14,cp,"If the directory
dest_file
does not exist, it shall be
               created with file permission bits set to the same value as
               those of
source_file
, modified by the file creation mask
               of the user if the
-p
option was not specified, and then
               bitwise-inclusively OR'ed with S_IRWXU. If
dest_file
cannot be created,
cp
shall write a diagnostic message to
               standard error, do nothing more with
source_file
, and go
               on to any remaining files. It is unspecified if
cp
attempts to copy files in the file hierarchy rooted in
source_file
."
119,15,cp,"It is unspecified if
cp
attempts to copy files in the file hierarchy rooted in
source_file
. f. The files in the directory
source_file
shall be copied to
               the directory
dest_file
, taking the four steps (1 to 4)
               listed here with the files as
source_file
s."
119,16,cp,"The files in the directory
source_file
shall be copied to
               the directory
dest_file
, taking the four steps (1 to 4)
               listed here with the files as
source_file
s. g. If
dest_file
was created, its file permission bits shall
               be changed (if necessary) to be the same as those of
source_file
, modified by the file creation mask of the
               user if the
-p
option was not specified."
119,17,cp,"If
dest_file
was created, its file permission bits shall
               be changed (if necessary) to be the same as those of
source_file
, modified by the file creation mask of the
               user if the
-p
option was not specified. h. The
cp
utility shall do nothing more with
source_file
and
               go on to any remaining files."
119,18,cp,"The
cp
utility shall do nothing more with
source_file
and
               go on to any remaining files. 3. If
source_file
is of type regular file, the following steps
           shall be taken:

            a."
119,19,cp,"If
source_file
is of type regular file, the following steps
           shall be taken:

            a. The behavior is unspecified if
dest_file
exists and was
               written by a previous step. Otherwise, if
dest_file
exists, the following steps shall be taken:

                i."
119,20,cp,"Otherwise, if
dest_file
exists, the following steps shall be taken:

                i. If the
-i
option is in effect, the
cp
utility shall
                    write a prompt to the standard error and read a line
                    from the standard input. If the response is not
                    affirmative,
cp
shall do nothing more with
source_file
and go on to any remaining files."
119,21,cp,"If the response is not
                    affirmative,
cp
shall do nothing more with
source_file
and go on to any remaining files. ii. A file descriptor for
dest_file
shall be obtained by
                    performing actions equivalent to the
open
() function
                    defined in the System Interfaces volume of
                    POSIX.1â2017 called using
dest_file
as the
path
argument, and the bitwise-inclusive OR of O_WRONLY
                    and O_TRUNC as the
oflag
argument."
119,22,cp,"A file descriptor for
dest_file
shall be obtained by
                    performing actions equivalent to the
open
() function
                    defined in the System Interfaces volume of
                    POSIX.1â2017 called using
dest_file
as the
path
argument, and the bitwise-inclusive OR of O_WRONLY
                    and O_TRUNC as the
oflag
argument. iii. If the attempt to obtain a file descriptor fails and
                    the
-f
option is in effect,
cp
shall attempt to
                    remove the file by performing actions equivalent to
                    the
unlink
() function defined in the System
                    Interfaces volume of POSIX.1â2017 called using
dest_file
as the
path
argument."
119,23,cp,"If the attempt to obtain a file descriptor fails and
                    the
-f
option is in effect,
cp
shall attempt to
                    remove the file by performing actions equivalent to
                    the
unlink
() function defined in the System
                    Interfaces volume of POSIX.1â2017 called using
dest_file
as the
path
argument. If this attempt
                    succeeds,
cp
shall continue with step 3b. b."
119,24,cp,"b. If
dest_file
does not exist, a file descriptor shall be
               obtained by performing actions equivalent to the
open
()
               function defined in the System Interfaces volume of
               POSIX.1â2017 called using
dest_file
as the
path
argument,
               and the bitwise-inclusive OR of O_WRONLY and O_CREAT as
               the
oflag
argument. The file permission bits of
source_file
shall be the
mode
argument."
119,25,cp,"The file permission bits of
source_file
shall be the
mode
argument. c. If the attempt to obtain a file descriptor fails,
cp
shall
               write a diagnostic message to standard error, do nothing
               more with
source_file
, and go on to any remaining files."
119,26,cp,"If the attempt to obtain a file descriptor fails,
cp
shall
               write a diagnostic message to standard error, do nothing
               more with
source_file
, and go on to any remaining files. d. The contents of
source_file
shall be written to the file
               descriptor."
119,27,cp,"The contents of
source_file
shall be written to the file
               descriptor. Any write errors shall cause
cp
to write a
               diagnostic message to standard error and continue to step
               3e. e."
119,28,cp,e. The file descriptor shall be closed. f.
119,29,cp,"f. The
cp
utility shall do nothing more with
source_file
. If
               a write error occurred in step 3d, it is unspecified if
cp
continues with any remaining files."
119,30,cp,"If
               a write error occurred in step 3d, it is unspecified if
cp
continues with any remaining files. If no write error
               occurred in step 3d,
cp
shall go on to any remaining
               files. 4."
119,31,cp,"4. Otherwise, the
-R
option was specified, and the following
           steps shall be taken:

            a. The
dest_file
shall be created with the same file type as
source_file
."
119,32,cp,"The
dest_file
shall be created with the same file type as
source_file
. b. If
source_file
is a file of type FIFO, the file permission
               bits shall be the same as those of
source_file,
modified
               by the file creation mask of the user if the
-p
option was
               not specified."
119,33,cp,"If
source_file
is a file of type FIFO, the file permission
               bits shall be the same as those of
source_file,
modified
               by the file creation mask of the user if the
-p
option was
               not specified. Otherwise, the permissions, owner ID, and
               group ID of
dest_file
are implementation-defined. If this creation fails for any reason,
cp
shall write a
               diagnostic message to standard error, do nothing more with
source_file
, and go on to any remaining files."
119,34,cp,"If this creation fails for any reason,
cp
shall write a
               diagnostic message to standard error, do nothing more with
source_file
, and go on to any remaining files. c. If
source_file
is a file of type symbolic link, and the
               options require the symbolic link itself to be acted upon,
               the pathname contained in
dest_file
shall be the same as
               the pathname contained in
source_file
."
119,35,cp,"If
source_file
is a file of type symbolic link, and the
               options require the symbolic link itself to be acted upon,
               the pathname contained in
dest_file
shall be the same as
               the pathname contained in
source_file
. If this fails for any reason,
cp
shall write a diagnostic
               message to standard error, do nothing more with
source_file
, and go on to any remaining files. If the implementation provides additional or alternate access
       control mechanisms (see the Base Definitions volume of
       POSIX.1â2017,
Section 4.5
,
File Access Permissions
), their effect
       on copies of files is implementation-defined."
120,0,csplit,"Output pieces of FILE separated by PATTERN(s) to files 'xx00',
       'xx01', ..., and output byte counts of each piece to standard
       output.

       Read standard input if FILE is -

       Mandatory arguments to long options are mandatory for short
       options too.
-b
,
--suffix-format
=
FORMAT
use sprintf FORMAT instead of %02d
-f
,
--prefix
=
PREFIX
use PREFIX instead of 'xx'
-k
,
--keep-files
do not remove output files on errors
--suppress-matched
suppress the lines matching PATTERN
-n
,
--digits
=
DIGITS
use specified number of digits instead of 2
-s
,
--quiet
,
--silent
do not print counts of output file sizes
-z
,
--elide-empty-files
suppress empty output files
--help
display this help and exit
--version
output version information and exit
Each PATTERN may be:
INTEGER
              copy up to but not including specified line number

       /REGEXP/[OFFSET]
              copy up to but not including a matching line

       %REGEXP%[OFFSET]
              skip to, but not including a matching line

       {INTEGER}
              repeat the previous pattern specified number of times

       {*}    repeat the previous pattern as many times as possible

       A line OFFSET is an integer optionally preceded by '+' or '-'"
121,0,crontab,"The
crontab
utility shall create, replace, or edit a user's
       crontab entry; a crontab entry is a list of commands and the times
       at which they shall be executed. The new crontab entry can be
       input by specifying
file
or input from standard input if no
file
operand is specified, or by using an editor, if
-e
is specified. Upon execution of a command from a crontab entry, the
       implementation shall supply a default environment, defining at
       least the following environment variables:
HOME
A pathname of the user's home directory."
121,1,crontab,"Upon execution of a command from a crontab entry, the
       implementation shall supply a default environment, defining at
       least the following environment variables:
HOME
A pathname of the user's home directory. LOGNAME
The user's login name. PATH
A string representing a search path guaranteed to find
                 all of the standard utilities."
121,2,crontab,"PATH
A string representing a search path guaranteed to find
                 all of the standard utilities. SHELL
A pathname of the command interpreter. When
crontab
is
                 invoked as specified by this volume of POSIX.1â2017, the
                 value shall be a pathname for
sh
."
121,3,crontab,"When
crontab
is
                 invoked as specified by this volume of POSIX.1â2017, the
                 value shall be a pathname for
sh
. The values of these variables when
crontab
is invoked as specified
       by this volume of POSIX.1â2017 shall not affect the default values
       provided when the scheduled command is run. If standard output and standard error are not redirected by
       commands executed from the crontab entry, any generated output or
       errors shall be mailed, via an implementation-defined method, to
       the user."
121,4,crontab,"If standard output and standard error are not redirected by
       commands executed from the crontab entry, any generated output or
       errors shall be mailed, via an implementation-defined method, to
       the user. Users shall be permitted to use
crontab
if their names appear in
       the file
cron.allow
which is located in an implementation-defined
       directory. If that file does not exist, the file
cron.deny
, which
       is located in an implementation-defined directory, shall be
       checked to determine whether the user shall be denied access to
crontab
."
121,5,crontab,"If that file does not exist, the file
cron.deny
, which
       is located in an implementation-defined directory, shall be
       checked to determine whether the user shall be denied access to
crontab
. If neither file exists, only a process with appropriate
       privileges shall be allowed to submit a job. If only
cron.deny
exists and is empty, global usage shall be permitted."
121,6,crontab,"If neither file exists, only a process with appropriate
       privileges shall be allowed to submit a job. If only
cron.deny
exists and is empty, global usage shall be permitted. The
cron.allow
and
cron.deny
files shall consist of one user name per
       line."
122,0,cronnext,"Determine the time cron will execute the next job. Without
       arguments, it prints that time considering all crontabs, in number
       of seconds since the Epoch, rounded to the minute. This number can
       be converted into other formats using
date(1)
, like
date --date
@43243254
The file arguments are optional."
122,1,cronnext,"Without
       arguments, it prints that time considering all crontabs, in number
       of seconds since the Epoch, rounded to the minute. This number can
       be converted into other formats using
date(1)
, like
date --date
@43243254
The file arguments are optional. If provided,
cronnext
uses them
       as crontabs instead of the ones installed in the system."
123,0,crontab,"Crontab
is the program used to install a crontab table
file
,
       remove or list the existing tables used to serve the
cron(8)
daemon. Each user can have their own crontab, and though these
       are files in
/var/spool/
, they are not intended to be edited
       directly. For SELinux in MLS mode, you can define more crontabs
       for each range."
123,1,crontab,"For SELinux in MLS mode, you can define more crontabs
       for each range. For more information, see
selinux(8)
. In this version of
Cron
it is possible to use a network-mounted
       shared
/var/spool/cron
across a cluster of hosts and specify that
       only one of the hosts should run the crontab jobs in the
       particular directory at any one time."
123,2,crontab,"In this version of
Cron
it is possible to use a network-mounted
       shared
/var/spool/cron
across a cluster of hosts and specify that
       only one of the hosts should run the crontab jobs in the
       particular directory at any one time. You may also use
crontab
from any of these hosts to edit the same shared set of crontab
       files, and to set and query which host should run the crontab
       jobs. Scheduling cron jobs with
crontab
can be allowed or disallowed for
       different users."
123,3,crontab,"Scheduling cron jobs with
crontab
can be allowed or disallowed for
       different users. For this purpose, use the
cron.allow
and
cron.deny
files. If the
cron.allow
file exists, a user must be
       listed in it to be allowed to use
crontab
."
123,4,crontab,"If the
cron.allow
file exists, a user must be
       listed in it to be allowed to use
crontab
. If the
cron.allow
file
       does not exist but the
cron.deny
file does exist, then a user must
not
be listed in the
cron.deny
file in order to use
crontab. If
       neither of these files exist, then only the super user is allowed
       to use
crontab
."
123,5,crontab,"If
       neither of these files exist, then only the super user is allowed
       to use
crontab
. Another way to restrict the scheduling of cron jobs beyond
crontab
is to use PAM authentication in
/etc/security/access.conf
to set
       up users, which are allowed or disallowed to use
crontab
or modify
       system cron jobs in the
/etc/cron.d/
directory. The temporary directory can be set in an environment variable."
123,6,crontab,"The temporary directory can be set in an environment variable. If
       it is not set by the user, the
/tmp
directory is used. When listing a crontab on a terminal the output will be colorized
       unless an environment variable
NO_COLOR
is set."
123,7,crontab,"When listing a crontab on a terminal the output will be colorized
       unless an environment variable
NO_COLOR
is set. On edition or deletion of the crontab, a backup of the last
       crontab will be saved to
$XDG_CACHE_HOME/crontab/crontab.bak
or
$XDG_CACHE_HOME/crontab/crontab.<user>.bak
if
-u
is used. If the
XDG_CACHE_HOME
environment variable is not set,
$HOME/.cache
will
       be used instead."
124,0,csplit,"The
csplit
utility shall read the file named by the
file
operand,
       write all or part of that file into other files as directed by the
arg
operands, and write the sizes of the files."
125,0,ctags,"The
ctags
utility shall be provided on systems that support the
       the Software Development Utilities option, and either or both of
       the C-Language Development Utilities option and FORTRAN
       Development Utilities option. On other systems, it is optional. The
ctags
utility shall write a
tagsfile
or an index of objects
       from C-language or FORTRAN source files specified by the
pathname
operands."
125,1,ctags,"The
ctags
utility shall write a
tagsfile
or an index of objects
       from C-language or FORTRAN source files specified by the
pathname
operands. The
tagsfile
shall list the locators of language-
       specific objects within the source files. A locator consists of a
       name, pathname, and either a search pattern or a line number that
       can be used in searching for the object definition."
125,2,ctags,"The
tagsfile
shall list the locators of language-
       specific objects within the source files. A locator consists of a
       name, pathname, and either a search pattern or a line number that
       can be used in searching for the object definition. The objects
       that shall be recognized are specified in the EXTENDED DESCRIPTION
       section."
126,0,cpp,"The C preprocessor, often known as
cpp
, is a
macro processor
that
       is used automatically by the C compiler to transform your program
       before compilation. It is called a macro processor because it
       allows you to define
macros
, which are brief abbreviations for
       longer constructs. The C preprocessor is intended to be used only with C, C++, and
       Objective-C source code."
126,1,cpp,"The C preprocessor is intended to be used only with C, C++, and
       Objective-C source code. In the past, it has been abused as a
       general text processor. It will choke on input which does not
       obey C's lexical rules."
126,2,cpp,"It will choke on input which does not
       obey C's lexical rules. For example, apostrophes will be
       interpreted as the beginning of character constants, and cause
       errors. Also, you cannot rely on it preserving characteristics of
       the input which are not significant to C-family languages."
126,3,cpp,"Also, you cannot rely on it preserving characteristics of
       the input which are not significant to C-family languages. If a
       Makefile is preprocessed, all the hard tabs will be removed, and
       the Makefile will not work. Having said that, you can often get away with using cpp on things
       which are not C."
126,4,cpp,"Having said that, you can often get away with using cpp on things
       which are not C. Other Algol-ish programming languages are often
       safe (Ada, etc.) So is assembly, with caution. -traditional-cpp
mode preserves more white space, and is otherwise more permissive."
126,5,cpp,"-traditional-cpp
mode preserves more white space, and is otherwise more permissive. Many of the problems can be avoided by writing C or C++ style
       comments instead of native language comments, and keeping macros
       simple. Wherever possible, you should use a preprocessor geared to the
       language you are writing in."
126,6,cpp,"Wherever possible, you should use a preprocessor geared to the
       language you are writing in. Modern versions of the GNU assembler
       have macro facilities. Most high level programming languages have
       their own conditional compilation and inclusion mechanism."
126,7,cpp,"Most high level programming languages have
       their own conditional compilation and inclusion mechanism. If all
       else fails, try a true general text processor, such as GNU M4. C preprocessors vary in some details."
126,8,cpp,"C preprocessors vary in some details. This manual discusses the
       GNU C preprocessor, which provides a small superset of the
       features of ISO Standard C. In its default mode, the GNU C
       preprocessor does not do a few things required by the standard."
126,9,cpp,"In its default mode, the GNU C
       preprocessor does not do a few things required by the standard. These are features which are rarely, if ever, used, and may cause
       surprising changes to the meaning of a program which does not
       expect them. To get strict ISO Standard C, you should use the
-std=c90
,
-std=c99
,
-std=c11
or
-std=c17
options, depending on
       which version of the standard you want."
126,10,cpp,"To get strict ISO Standard C, you should use the
-std=c90
,
-std=c99
,
-std=c11
or
-std=c17
options, depending on
       which version of the standard you want. To get all the mandatory
       diagnostics, you must also use
-pedantic
. This manual describes the behavior of the ISO preprocessor."
126,11,cpp,"This manual describes the behavior of the ISO preprocessor. To
       minimize gratuitous differences, where the ISO preprocessor's
       behavior does not conflict with traditional semantics, the
       traditional preprocessor should behave the same way. The various
       differences that do exist are detailed in the section
Traditional
Mode
."
126,12,cpp,"To
       minimize gratuitous differences, where the ISO preprocessor's
       behavior does not conflict with traditional semantics, the
       traditional preprocessor should behave the same way. The various
       differences that do exist are detailed in the section
Traditional
Mode
. For clarity, unless noted otherwise, references to
CPP
in this
       manual refer to GNU CPP."
127,0,cupstestppd,"cupstestppd
tests the conformance of PPD files to the Adobe
       PostScript Printer Description file format specification version
       4.3. It can also be used to list the supported options and
       available fonts in a PPD file. The results of testing and any
       other output are sent to the standard output."
127,1,cupstestppd,"The results of testing and any
       other output are sent to the standard output. The first form of
cupstestppd
tests one or more PPD files on the
       command-line. The second form tests the PPD file provided on the
       standard input."
128,0,cups-config,"The
cups-config
command allows application developers to determine
       the necessary command-line options for the compiler and linker, as
       well as the installation directories for filters, configuration
       files, and drivers. All values are reported to the standard
       output. Note:
This command is deprecated and will be removed in a
       future version of CUPS."
128,1,cups-config,"All values are reported to the standard
       output. Note:
This command is deprecated and will be removed in a
       future version of CUPS. The
pkg-config
(1) command should be used
       instead."
129,0,cups,"CUPS
is the software you use to print from applications like word
       processors, email readers, photo editors, and web browsers. It
       converts the page descriptions produced by your application (put a
       paragraph here, draw a line there, and so forth) into something
       your printer can understand and then sends the information to the
       printer for printing. Now, since every printer manufacturer does things differently,
       printing can be very complicated."
129,1,cups,"Now, since every printer manufacturer does things differently,
       printing can be very complicated. CUPS
does its best to hide this
       from you and your application so that you can concentrate on
       printing and less on how to print. Generally, the only time you
       need to know anything about your printer is when you use it for
       the first time, and even then
CUPS
can often figure things out on
       its own."
129,2,cups,"Generally, the only time you
       need to know anything about your printer is when you use it for
       the first time, and even then
CUPS
can often figure things out on
       its own. HOW DOES IT WORK? The first time you print to a printer,
CUPS
creates a queue to
       keep track of the current status of the printer (everything OK,
       out of paper, etc.) and any pages you have printed."
129,3,cups,"The first time you print to a printer,
CUPS
creates a queue to
       keep track of the current status of the printer (everything OK,
       out of paper, etc.) and any pages you have printed. Most of the
       time the queue points to a printer connected directly to your
       computer via a USB port, however it can also point to a printer on
       your network, a printer on the Internet, or multiple printers
       depending on the configuration. Regardless of where the queue
       points, it will look like any other printer to you and your
       applications."
129,4,cups,"Regardless of where the queue
       points, it will look like any other printer to you and your
       applications. Every time you print something,
CUPS
creates a job which contains
       the queue you are sending the print to, the name of the document
       you are printing, and the page descriptions. Job are numbered
       (queue-1, queue-2, and so forth) so you can monitor the job as it
       is printed or cancel it if you see a mistake."
129,5,cups,"Job are numbered
       (queue-1, queue-2, and so forth) so you can monitor the job as it
       is printed or cancel it if you see a mistake. When
CUPS
gets a job
       for printing, it determines the best programs (filters, printer
       drivers, port monitors, and backends) to convert the pages into a
       printable format and then runs them to actually print the job. When the print job is completely printed,
CUPS
removes the job
       from the queue and moves on to any other jobs you have submitted."
129,6,cups,"When the print job is completely printed,
CUPS
removes the job
       from the queue and moves on to any other jobs you have submitted. You can also be notified when the job is finished, or if there are
       any errors during printing, in several different ways. WHERE DO I BEGIN?"
129,7,cups,"WHERE DO I BEGIN? The easiest way to start is by using the web interface to
       configure your printer. Go to ""http://localhost:631"" and choose
       the Administration tab at the top of the page."
129,8,cups,"Go to ""http://localhost:631"" and choose
       the Administration tab at the top of the page. Click/press on the
       Add Printer button and follow the prompts. When you are asked for a username and password, enter your login
       username and password or the ""root"" username and password."
129,9,cups,"When you are asked for a username and password, enter your login
       username and password or the ""root"" username and password. After the printer is added you will be asked to set the default
       printer options (paper size, output mode, etc.) for the printer. Make any changes as needed and then click/press on the Set Default
       Options button to save them."
129,10,cups,"Make any changes as needed and then click/press on the Set Default
       Options button to save them. Some printers also support auto-
       configuration - click/press on the Query Printer for Default
       Options button to update the options automatically. Once you have added the printer, you can print to it from any
       application."
129,11,cups,"Once you have added the printer, you can print to it from any
       application. You can also choose Print Test Page from the
       maintenance menu to print a simple test page and verify that
       everything is working properly. You can also use the
lpadmin(8)
and
lpinfo(8)
commands to add
       printers to
CUPS
."
129,12,cups,"You can also use the
lpadmin(8)
and
lpinfo(8)
commands to add
       printers to
CUPS
. Additionally, your operating system may include
       graphical user interfaces or automatically create printer queues
       when you connect a printer to your computer. HOW DO I GET HELP?"
129,13,cups,"HOW DO I GET HELP? The
OpenPrinting CUPS
website
       (
https://openprinting.github.io/cups
) provides access to the
cups
and
cups-devel
mailing lists, additional documentation and
       resources, and a bug report database. Most vendors also provide
       online discussion forums to ask printing questions for your
       operating system of choice."
130,0,curl-config,"curl-config
displays information about the curl and libcurl
       installation."
131,0,cut,"Print selected parts of lines from each FILE to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
131,1,cut,"Mandatory arguments to long options are mandatory for short
       options too. -b
,
--bytes
=
LIST
select only these bytes
-c
,
--characters
=
LIST
select only these characters
-d
,
--delimiter
=
DELIM
use DELIM instead of TAB for field delimiter
-f
,
--fields
=
LIST
select only these fields;  also print any line that
              contains no delimiter character, unless the
-s
option is
              specified
-n
(ignored)
--complement
complement the set of selected bytes, characters or fields
-s
,
--only-delimited
do not print lines not containing delimiters
--output-delimiter
=
STRING
use STRING as the output delimiter the default is to use
              the input delimiter
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit

       Use one, and only one of
-b
,
-c
or
-f
. Each LIST is made up of
       one range, or many ranges separated by commas."
131,2,cut,"Each LIST is made up of
       one range, or many ranges separated by commas. Selected input is
       written in the same order that it is read, and is written exactly
       once. Each range is one of:

       N      N'th byte, character or field, counted from 1

       N-     from N'th byte, character or field, to end of line

       N-M    from N'th to M'th (included) byte, character or field
-M
from first to M'th (included) byte, character or field"
132,0,danetool,"Tool to generate and check DNS resource records for the DANE
       protocol."
133,0,cut,"The
cut
utility shall cut out bytes (
-b
option), characters (
-c
option), or character-delimited fields (
-f
option) from each line
       in one or more files, concatenate them, and write them to standard
       output."
134,0,date,"The
date
utility shall write the date and time to standard output
       or attempt to set the system date and time.  By default, the
       current date and time shall be written. If an operand beginning
       with
'+'
is specified, the output format of
date
shall be
       controlled by the conversion specifications and other text in the
       operand."
135,0,cvtsudoers,"The
cvtsudoers
utility accepts one or more security policies in
       either
sudoers
or LDIF format as input, and generates a single
       policy of the specified format as output. The default input
       format is
sudoers. The default output format is LDIF."
135,1,cvtsudoers,"The default output format is LDIF. It is only
       possible to convert a policy file that is syntactically correct. If no
input_file
is specified, or if it is â-â, the policy is read
       from the standard input."
135,2,cvtsudoers,"If no
input_file
is specified, or if it is â-â, the policy is read
       from the standard input. Input files may be optionally prefixed
       with a host name followed by a colon (â:â) to make the policy
       rules specific to a host when merging multiple files. By default,
       the result is written to the standard output."
135,3,cvtsudoers,"By default,
       the result is written to the standard output. The options are as follows:
-b
dn
,
--base
=
dn
The base DN (distinguished name) that will be used when
               performing LDAP queries. Typically this is of the form
               âou=SUDOers,dc=my-domain,dc=comâ for the domain my-
               domain.com."
135,4,cvtsudoers,"Typically this is of the form
               âou=SUDOers,dc=my-domain,dc=comâ for the domain my-
               domain.com. If this option is not specified, the value of
               the SUDOERS_BASE environment variable will be used
               instead. Only necessary when converting to LDIF format."
135,5,cvtsudoers,"Only necessary when converting to LDIF format. -c
conf_file
,
--config
=
conf_file
Specify the path to the configuration file. Defaults to
/etc/cvtsudoers.conf
."
135,6,cvtsudoers,"Defaults to
/etc/cvtsudoers.conf
. -d
deftypes
,
--defaults
=
deftypes
Only convert
Defaults
entries of the specified types. One
               or more
Defaults
types may be specified, separated by a
               comma (â,â)."
135,7,cvtsudoers,"One
               or more
Defaults
types may be specified, separated by a
               comma (â,â). The supported types are:

               all      All Defaults entries. global   Global Defaults entries that are applied
                        regardless of user, runas, host, or command."
135,8,cvtsudoers,"global   Global Defaults entries that are applied
                        regardless of user, runas, host, or command. user     Per-user Defaults entries. runas    Per-runas user Defaults entries."
135,9,cvtsudoers,runas    Per-runas user Defaults entries. host     Per-host Defaults entries. command  Per-command Defaults entries.
135,10,cvtsudoers,"command  Per-command Defaults entries. See the
Defaults
section in
sudoers
(5) for more
               information. If the
-d
option is not specified, all
Defaults
entries
               will be converted."
135,11,cvtsudoers,"If the
-d
option is not specified, all
Defaults
entries
               will be converted. -e
,
--expand-aliases
Expand aliases in
input_file
. Aliases are preserved by
               default when the output
format
is JSON or sudoers."
135,12,cvtsudoers,"Aliases are preserved by
               default when the output
format
is JSON or sudoers. -f
output_format
,
--output-format
=
output_format
Specify the output format (case-insensitive). The
               following formats are supported:

               CSV      CSV (comma-separated value) files are often used
                        by spreadsheets and report generators."
135,13,cvtsudoers,"The
               following formats are supported:

               CSV      CSV (comma-separated value) files are often used
                        by spreadsheets and report generators. See âCSV
                        output formatâ for more details. JSON     JSON (JavaScript Object Notation) files are
                        usually easier for third-party applications to
                        consume than the traditional
sudoers
format."
135,14,cvtsudoers,"JSON     JSON (JavaScript Object Notation) files are
                        usually easier for third-party applications to
                        consume than the traditional
sudoers
format. The
                        various values have explicit types which removes
                        much of the ambiguity of the
sudoers
format. See
                        âJSON output formatâ for more details."
135,15,cvtsudoers,"See
                        âJSON output formatâ for more details. LDIF     LDIF (LDAP Data Interchange Format) files can be
                        imported into an LDAP server for use with
sudoers.ldap
(5). Conversion to LDIF has the following limitations:
â¢
Command, host, runas, and user-specific
                           Defaults lines cannot be translated as they
                           don't have an equivalent in the sudoers LDAP
                           schema."
135,16,cvtsudoers,"Conversion to LDIF has the following limitations:
â¢
Command, host, runas, and user-specific
                           Defaults lines cannot be translated as they
                           don't have an equivalent in the sudoers LDAP
                           schema. â¢
Command, host, runas, and user aliases are not
                           supported by the sudoers LDAP schema so they
                           are expanded during the conversion. sudoers  Traditional sudoers format."
135,17,cvtsudoers,"sudoers  Traditional sudoers format. A new sudoers file
                        will be reconstructed from the parsed input file. Comments are not preserved and data from any
                        include files will be output inline."
135,18,cvtsudoers,"Comments are not preserved and data from any
                        include files will be output inline. --group-file
=
file
When the
-M
option is also specified, perform group
               queries using
file
instead of the system group database. -h
,
--help
Display a short help message to the standard output and
               exit."
135,19,cvtsudoers,"-h
,
--help
Display a short help message to the standard output and
               exit. -i
input_format
,
--input-format
=
input_format
Specify the input format. The following formats are
               supported:

               LDIF     LDIF (LDAP Data Interchange Format) files can be
                        exported from an LDAP server to convert security
                        policies used by
sudoers.ldap
(5)."
135,20,cvtsudoers,"The following formats are
               supported:

               LDIF     LDIF (LDAP Data Interchange Format) files can be
                        exported from an LDAP server to convert security
                        policies used by
sudoers.ldap
(5). If a base DN
                        (distinguished name) is specified, only sudoRole
                        objects that match the base DN will be processed. Not all sudoOptions specified in a sudoRole can
                        be translated from LDIF to sudoers format."
135,21,cvtsudoers,"Not all sudoOptions specified in a sudoRole can
                        be translated from LDIF to sudoers format. sudoers  Traditional sudoers format. This is the default
                        input format."
135,22,cvtsudoers,"This is the default
                        input format. -I
increment
,
--increment
=
increment
When generating LDIF output, increment each sudoOrder
               attribute by the specified number. Defaults to an
               increment of 1."
135,23,cvtsudoers,"Defaults to an
               increment of 1. -l
log_file
,
--logfile
=
log_file
Log conversion warnings to
log_file
instead of to the
               standard error. This is particularly useful when merging
               multiple
sudoers
files, which can generate a large number
               of warnings."
135,24,cvtsudoers,"This is particularly useful when merging
               multiple
sudoers
files, which can generate a large number
               of warnings. -m
filter
,
--match
=
filter
Only output rules that match the specified
filter
. A
filter
expression is made up of one or more
key =
value
pairs, separated by a comma (â,â)."
135,25,cvtsudoers,"A
filter
expression is made up of one or more
key =
value
pairs, separated by a comma (â,â). The
key
may be âcmndâ
               (or âcmdâ), âhostâ, âgroupâ, or âuserâ. For example,
user
=
operator
or
host
=
www
."
135,26,cvtsudoers,"For example,
user
=
operator
or
host
=
www
. An upper-case
Cmnd_Alias
,
Host_alias
, or
User_Alias
may be specified as the âcmndâ,
               âhostâ, or âuserâ. A matching
sudoers
rule may also include users, groups,
               and hosts that are not part of the
filter
."
135,27,cvtsudoers,"A matching
sudoers
rule may also include users, groups,
               and hosts that are not part of the
filter
. This can
               happen when a rule includes multiple users, groups, or
               hosts. To prune out any non-matching user, group, or host
               from the rules, the
-p
option may be used."
135,28,cvtsudoers,"To prune out any non-matching user, group, or host
               from the rules, the
-p
option may be used. By default, the password and group databases are not
               consulted when matching against the filter so the users
               and groups do not need to be present on the local system
               (see the
-M
option). Only aliases that are referenced by
               the filtered policy rules will be displayed."
135,29,cvtsudoers,"Only aliases that are referenced by
               the filtered policy rules will be displayed. -M
,
--match-local
When the
-m
option is also specified, use password and
               group database information when matching users and groups
               in the filter. Only users and groups in the filter that
               exist on the local system will match, and a user's groups
               will automatically be added to the filter."
135,30,cvtsudoers,"Only users and groups in the filter that
               exist on the local system will match, and a user's groups
               will automatically be added to the filter. If the
-M
is
not
specified, users and groups in the filter do not need
               to exist on the local system, but all groups used for
               matching must be explicitly listed in the filter. -o
output_file
,
--output
=
output_file
Write the converted output to
output_file
."
135,31,cvtsudoers,"-o
output_file
,
--output
=
output_file
Write the converted output to
output_file
. If no
output_file
is specified, or if it is â-â, the converted
sudoers
policy will be written to the standard output. -O
start_point
,
--order-start
=
start_point
When generating LDIF output, use the number specified by
start_point
in the sudoOrder attribute of the first
               sudoRole object."
135,32,cvtsudoers,"-O
start_point
,
--order-start
=
start_point
When generating LDIF output, use the number specified by
start_point
in the sudoOrder attribute of the first
               sudoRole object. Subsequent sudoRole object use a
               sudoOrder value generated by adding an
increment
, see the
-I
option for details. Defaults to a starting point of 1."
135,33,cvtsudoers,"Defaults to a starting point of 1. A starting point of 0 will disable the generation of
               sudoOrder attributes in the resulting LDIF file. --passwd-file
=
file
When the
-M
option is also specified, perform passwd
               queries using
file
instead of the system passwd database."
135,34,cvtsudoers,"--passwd-file
=
file
When the
-M
option is also specified, perform passwd
               queries using
file
instead of the system passwd database. -p
,
--prune-matches
When the
-m
option is also specified,
cvtsudoers
will
               prune out non-matching users, groups, and hosts from
               matching entries. -P
padding
,
--padding
=
padding
When generating LDIF output, construct the initial
               sudoOrder value by concatenating
order_start
and
increment
, padding the
increment
with zeros until it
               consists of
padding
digits."
135,35,cvtsudoers,"-P
padding
,
--padding
=
padding
When generating LDIF output, construct the initial
               sudoOrder value by concatenating
order_start
and
increment
, padding the
increment
with zeros until it
               consists of
padding
digits. For example, if
order_start
is 1027,
padding
is 3, and
increment
is 1, the value of
               sudoOrder for the first entry will be 1027000, followed by
               1027001, 1027002, etc. If the number of sudoRole entries
               is larger than the padding would allow,
cvtsudoers
will
               exit with an error."
135,36,cvtsudoers,"If the number of sudoRole entries
               is larger than the padding would allow,
cvtsudoers
will
               exit with an error. By default, no padding is performed. -s
sections
,
--suppress
=
sections
Suppress the output of specific
sections
of the security
               policy."
135,37,cvtsudoers,"-s
sections
,
--suppress
=
sections
Suppress the output of specific
sections
of the security
               policy. One or more section names may be specified,
               separated by a comma (â,â). The supported section name
               are:
defaults
,
aliases
and
privileges
(which may be
               shortened to
privs
)."
135,38,cvtsudoers,"The supported section name
               are:
defaults
,
aliases
and
privileges
(which may be
               shortened to
privs
). -V
,
--version
Print the
cvtsudoers
and
sudoers
grammar versions and
               exit. Merging multiple files
When multiple input files are specified,
cvtsudoers
will attempt
       to merge them into a single policy file."
135,39,cvtsudoers,"Merging multiple files
When multiple input files are specified,
cvtsudoers
will attempt
       to merge them into a single policy file. It is assumed that user
       and group names are consistent among the policy files to be
       merged. For example, user âbobâ on one host is the same as user
       âbobâ on another host."
135,40,cvtsudoers,"For example, user âbobâ on one host is the same as user
       âbobâ on another host. When merging policy files, it is possible to prefix the input file
       name with a host name, separated by a colon (â:â). When the files
       are merged, the host name will be used to restrict the policy
       rules to that specific host where possible."
135,41,cvtsudoers,"When the files
       are merged, the host name will be used to restrict the policy
       rules to that specific host where possible. The merging process is performed as follows:
â¢
Each input file is parsed into internal sudoers data
          structures. â¢
Aliases are merged and renamed as necessary to avoid conflicts."
135,42,cvtsudoers,"â¢
Aliases are merged and renamed as necessary to avoid conflicts. In the event of a conflict, the first alias found is left as-is
          and subsequent aliases of the same name are renamed with a
          numeric suffix separated with a underscore (â_â). For example,
          if there are two different aliases named SERVERS, the first
          will be left as-is and the second will be renamed SERVERS_1."
135,43,cvtsudoers,"For example,
          if there are two different aliases named SERVERS, the first
          will be left as-is and the second will be renamed SERVERS_1. References to the renamed alias are also updated in the policy
          file. Duplicate aliases (those with identical contents) are
          pruned."
135,44,cvtsudoers,"Duplicate aliases (those with identical contents) are
          pruned. â¢
Defaults settings are merged and duplicates are removed. If
          there are conflicts in the Defaults settings, a warning is
          emitted for each conflict."
135,45,cvtsudoers,"If
          there are conflicts in the Defaults settings, a warning is
          emitted for each conflict. If a host name is specified with
          the input file,
cvtsudoers
will change the global Defaults
          settings in that file to be host-specific. A warning is
          emitted for command, user, or runas-specific Defaults settings
          which cannot be made host-specific."
135,46,cvtsudoers,"A warning is
          emitted for command, user, or runas-specific Defaults settings
          which cannot be made host-specific. â¢
Per-user rules are merged and duplicates are removed. If a
          host name is specified with the input file,
cvtsudoers
will
          change rules that specify a host name of
ALL
to the host name
          associated with the policy file being merged."
135,47,cvtsudoers,"If a
          host name is specified with the input file,
cvtsudoers
will
          change rules that specify a host name of
ALL
to the host name
          associated with the policy file being merged. The merging of
          rules is currently fairly simplistic but will be improved in a
          later release. It is possible to merge policy files with differing formats."
135,48,cvtsudoers,"It is possible to merge policy files with differing formats. The cvtsudoers.conf file
Options in the form âkeyword = valueâ may also be specified in a
       configuration file,
/etc/cvtsudoers.conf
by default. The
       following keywords are recognized:
defaults =
deftypes
See the description of the
-d
command line option."
135,49,cvtsudoers,"The
       following keywords are recognized:
defaults =
deftypes
See the description of the
-d
command line option. expand_aliases =
yes
|
no
See the description of the
-e
command line option. group_file =
file
See the description of the
--group-file
command line option."
135,50,cvtsudoers,"group_file =
file
See the description of the
--group-file
command line option. input_format =
ldif
|
sudoers
See the description of the
-i
command line option. match =
filter
See the description of the
-m
command line option."
135,51,cvtsudoers,"match =
filter
See the description of the
-m
command line option. match_local =
yes
|
no
See the description of the
-M
command line option. order_increment =
increment
See the description of the
-I
command line option."
135,52,cvtsudoers,"order_increment =
increment
See the description of the
-I
command line option. order_start =
start_point
See the description of the
-O
command line option. output_format =
csv
|
json
|
ldif
|
sudoers
See the description of the
-f
command line option."
135,53,cvtsudoers,"output_format =
csv
|
json
|
ldif
|
sudoers
See the description of the
-f
command line option. padding =
padding
See the description of the
-P
command line option. passwd_file =
file
See the description of the
--passwd-file
command line
             option."
135,54,cvtsudoers,"passwd_file =
file
See the description of the
--passwd-file
command line
             option. prune_matches =
yes
|
no
See the description of the
-p
command line option. sudoers_base =
dn
See the description of the
-b
command line option."
135,55,cvtsudoers,"sudoers_base =
dn
See the description of the
-b
command line option. suppress =
sections
See the description of the
-s
command line option. Options on the command line will override values from the
       configuration file."
135,56,cvtsudoers,"Options on the command line will override values from the
       configuration file. JSON output format
The
sudoers
JSON format may contain any of the following top-level
       objects:

       Defaults
             An array of objects, each containing an
Options
array and an
             optional
Binding
array. The
Options
array consists of one or more objects, each
             containing a âname:valueâ pair that corresponds to a
sudoers
Defaults
setting."
135,57,cvtsudoers,"The
Options
array consists of one or more objects, each
             containing a âname:valueâ pair that corresponds to a
sudoers
Defaults
setting. Options
that operate on a list will also
             include an
operation
entry in the object, with a value of
             âlist_assignâ for â=â, âlist_addâ for â+=â, or âlist_removeâ
             for â-=â. The optional
Binding
array consists of one or more objects,
             each containing a âname:valueâ pair and an optional
negated
entry, which will negate any comparison performed with the
             object."
135,58,cvtsudoers,"The optional
Binding
array consists of one or more objects,
             each containing a âname:valueâ pair and an optional
negated
entry, which will negate any comparison performed with the
             object. If a
Binding
is present, the setting will only take
             effect if one of the specified
command
,
hostname
,
netgroup
,
networkaddr
,
nonunixgid
,
nonunixgroup
,
usergid
,
usergroup
,
userid
,
username
, or alias entries match. For example, the following
sudoers
entry:

             Defaults@somehost set_home, env_keep += DISPLAY

             converts to:

             ""Defaults"": [
                 {
                     ""Binding"": [
                         { ""hostname"": ""somehost"" }
                     ],
                     ""Options"": [
                         { ""set_home"": true },
                         {
                             ""operation"": ""list_add"",
                             ""env_keep"": [
                                 ""DISPLAY""
                             ]
                         }
                     ]
                 }
             ]

       User_Aliases
             A JSON object containing one or more
sudoers User_Alias
entries where each named alias has as its value an array
             containing one or more objects."
135,59,cvtsudoers,"For example, the following
sudoers
entry:

             Defaults@somehost set_home, env_keep += DISPLAY

             converts to:

             ""Defaults"": [
                 {
                     ""Binding"": [
                         { ""hostname"": ""somehost"" }
                     ],
                     ""Options"": [
                         { ""set_home"": true },
                         {
                             ""operation"": ""list_add"",
                             ""env_keep"": [
                                 ""DISPLAY""
                             ]
                         }
                     ]
                 }
             ]

       User_Aliases
             A JSON object containing one or more
sudoers User_Alias
entries where each named alias has as its value an array
             containing one or more objects. Each object contains a
             âname:valueâ pair and an optional
negated
entry, which will
             negate any comparison performed with the object. The name
             may be one of
netgroup
,
nonunixgid
,
nonunixgroup
,
useralias
,
usergid
,
usergroup
,
userid
, or
username
."
135,60,cvtsudoers,"The name
             may be one of
netgroup
,
nonunixgid
,
nonunixgroup
,
useralias
,
usergid
,
usergroup
,
userid
, or
username
. For example, the following
sudoers
entry:

             User_Alias SYSADMIN = will, %wheel, +admin

             converts to:

             ""User_Aliases"": {
                 ""SYSADMIN"": [
                     { ""username"": ""will"" },
                     { ""usergroup"": ""wheel"" },
                     { ""netgroup"": ""admin"" }
                 ]
             }

       Runas_Aliases
             A JSON object containing one or more
sudoers Runas_Alias
entries, where each named alias has as its value an array
             containing one or more objects. Each object contains a
             âname:valueâ pair and an optional
negated
entry, which will
             negate any comparison performed with the object."
135,61,cvtsudoers,"Each object contains a
             âname:valueâ pair and an optional
negated
entry, which will
             negate any comparison performed with the object. The name
             may be one of
netgroup
,
nonunixgid
,
nonunixgroup
,
runasalias
,
usergid
,
usergroup
,
userid
, or
username
. For example, the following
sudoers
entry:

             Runas_Alias DB = oracle, sybase : OP = root, operator

             converts to:

             ""Runas_Aliases"": {
                 ""DB"": [
                     { ""username"": ""oracle"" },
                     { ""username"": ""sybase"" }
                 ],
                 ""OP"": [
                     { ""username"": ""root"" },
                     { ""username"": ""operator"" }
                 ]
             }

       Host_Aliases
             A JSON object containing one or more
sudoers Host_Alias
entries where each named alias has as its value an array
             containing one or more objects."
135,62,cvtsudoers,"For example, the following
sudoers
entry:

             Runas_Alias DB = oracle, sybase : OP = root, operator

             converts to:

             ""Runas_Aliases"": {
                 ""DB"": [
                     { ""username"": ""oracle"" },
                     { ""username"": ""sybase"" }
                 ],
                 ""OP"": [
                     { ""username"": ""root"" },
                     { ""username"": ""operator"" }
                 ]
             }

       Host_Aliases
             A JSON object containing one or more
sudoers Host_Alias
entries where each named alias has as its value an array
             containing one or more objects. Each object contains a
             âname:valueâ pair and an optional
negated
entry, which will
             negate any comparison performed with the object. The name
             may be one of
hostalias
,
hostname
,
netgroup
, or
networkaddr
."
135,63,cvtsudoers,"The name
             may be one of
hostalias
,
hostname
,
netgroup
, or
networkaddr
. For example, the following
sudoers
entries:

             Host_Alias DORMNET = 128.138.243.0, 128.138.204.0/24
             Host_Alias SERVERS = boulder, refuge

             convert to:

             ""Host_Aliases"": {
                 ""DORMNET"": [
                     { ""networkaddr"": ""128.138.243.0"" },
                     { ""networkaddr"": ""128.138.204.0/24"" }
                 ],
                 ""SERVERS"": [
                     { ""hostname"": ""boulder"" },
                     { ""hostname"": ""refuge"" }
                 ]
             }

       Cmnd_Aliases
             A JSON object containing one or more
sudoers Cmnd_Alias
entries where each named alias has as its value an array
             containing one or more objects. Each object contains a
             âname:valueâ pair and an optional
negated
entry, which will
             negate any comparison performed with the object."
135,64,cvtsudoers,"Each object contains a
             âname:valueâ pair and an optional
negated
entry, which will
             negate any comparison performed with the object. The name
             may be either another
cmndalias
or a
command
. For example,
             the following
sudoers
entries:

             Cmnd_Alias SHELLS = /bin/bash, /bin/csh, /bin/sh, /bin/zsh
             Cmnd_Alias VIPW = /usr/bin/chpass, /usr/bin/chfn, /usr/bin/chsh, \
                               /usr/bin/passwd, /usr/sbin/vigr, /usr/sbin/vipw

             convert to:

             ""Cmnd_Aliases"": {
                 ""SHELLS"": [
                     { ""command"": ""/bin/bash"" },
                     { ""command"": ""/bin/csh"" },
                     { ""command"": ""/bin/sh"" },
                     { ""command"": ""/bin/zsh"" }
                 ],
                 ""VIPW"": [
                     { ""command"": ""/usr/bin/chpass"" },
                     { ""command"": ""/usr/bin/chfn"" },
                     { ""command"": ""/usr/bin/chsh"" },
                     { ""command"": ""/usr/bin/passwd"" },
                     { ""command"": ""/usr/sbin/vigr"" },
                     { ""command"": ""/usr/sbin/vipw"" }
                 ]
             }

       User_Specs
             A JSON array containing one or more objects, each
             representing a
sudoers
User_Spec."
135,65,cvtsudoers,"For example,
             the following
sudoers
entries:

             Cmnd_Alias SHELLS = /bin/bash, /bin/csh, /bin/sh, /bin/zsh
             Cmnd_Alias VIPW = /usr/bin/chpass, /usr/bin/chfn, /usr/bin/chsh, \
                               /usr/bin/passwd, /usr/sbin/vigr, /usr/sbin/vipw

             convert to:

             ""Cmnd_Aliases"": {
                 ""SHELLS"": [
                     { ""command"": ""/bin/bash"" },
                     { ""command"": ""/bin/csh"" },
                     { ""command"": ""/bin/sh"" },
                     { ""command"": ""/bin/zsh"" }
                 ],
                 ""VIPW"": [
                     { ""command"": ""/usr/bin/chpass"" },
                     { ""command"": ""/usr/bin/chfn"" },
                     { ""command"": ""/usr/bin/chsh"" },
                     { ""command"": ""/usr/bin/passwd"" },
                     { ""command"": ""/usr/sbin/vigr"" },
                     { ""command"": ""/usr/sbin/vipw"" }
                 ]
             }

       User_Specs
             A JSON array containing one or more objects, each
             representing a
sudoers
User_Spec. Each object in the
User_Specs
array should contain a
User_List
array, a
Host_List
array and a
Cmnd_Specs
array. A
User_List
consists of one or more objects."
135,66,cvtsudoers,"A
User_List
consists of one or more objects. Each object
             contains a âname:valueâ pair and an optional
negated
entry,
             which will negate any comparison performed with the object. The name may be one of
netgroup
,
nonunixgid
,
nonunixgroup
,
useralias
,
usergid
,
usergroup
,
userid
, or
username
."
135,67,cvtsudoers,"The name may be one of
netgroup
,
nonunixgid
,
nonunixgroup
,
useralias
,
usergid
,
usergroup
,
userid
, or
username
. If
username
is set to the special value
ALL
, it will match any
             user. A
Host_List
consists of one or more objects."
135,68,cvtsudoers,"A
Host_List
consists of one or more objects. Each object
             contains a âname:valueâ pair and an optional
negated
entry,
             which will negate any comparison performed with the object. The name may be one of
hostalias
,
hostname
,
netgroup
, or
networkaddr
."
135,69,cvtsudoers,"The name may be one of
hostalias
,
hostname
,
netgroup
, or
networkaddr
. If
hostname
is set to the special value
ALL
,
             it will match any host. The
Cmnd_Specs
array consists of one or more JSON objects
             describing a command that may be run."
135,70,cvtsudoers,"The
Cmnd_Specs
array consists of one or more JSON objects
             describing a command that may be run. Each
Cmnd_Specs
is
             made up of a
Commands
array, an optional
runasusers
array,
             an optional
runasgroups
array, and an optional
Options
array. The
Commands
array consists of one or more objects
             containing âname:valueâ pair elements."
135,71,cvtsudoers,"The
Commands
array consists of one or more objects
             containing âname:valueâ pair elements. The following names
             and values are supported:

             command  A string containing the command to run. The
                      special value
ALL
it will match any command."
135,72,cvtsudoers,"The
                      special value
ALL
it will match any command. negated  A boolean value that, if true, will negate any
                      comparison performed with the object. sha224   One or more SHA224 digests for the
command
in
                      string form."
135,73,cvtsudoers,"sha224   One or more SHA224 digests for the
command
in
                      string form. Multiple digests of the same type are
                      stored as an array. sha256   One or more SHA256 digests for the
command
in
                      string form."
135,74,cvtsudoers,"sha256   One or more SHA256 digests for the
command
in
                      string form. Multiple digests of the same type are
                      stored as an array. sha384   One or more SHA384 digests for the
command
in
                      string form."
135,75,cvtsudoers,"sha384   One or more SHA384 digests for the
command
in
                      string form. Multiple digests of the same type are
                      stored as an array. sha512   One or more SHA512 digests for the
command
in
                      string form."
135,76,cvtsudoers,"sha512   One or more SHA512 digests for the
command
in
                      string form. Multiple digests of the same type are
                      stored as an array. The
runasusers
array consists of objects describing users
             the command may be run as."
135,77,cvtsudoers,"The
runasusers
array consists of objects describing users
             the command may be run as. Each object contains a
             âname:valueâ pair and an optional
negated
entry, which will
             negate any comparison performed with the object. The name
             may be one of
netgroup
,
nonunixgid
,
nonunixgroup
,
runasalias
,
usergid
,
usergroup
,
userid
, or
username
."
135,78,cvtsudoers,"The name
             may be one of
netgroup
,
nonunixgid
,
nonunixgroup
,
runasalias
,
usergid
,
usergroup
,
userid
, or
username
. If
username
is set to the special value
ALL
, it will match any
             user. If
username
is set to the empty string ââ, it will
             match the invoking user."
135,79,cvtsudoers,"If
username
is set to the empty string ââ, it will
             match the invoking user. The
runasgroups
array consists of objects describing groups
             the command may be run as. Each object contains a
             âname:valueâ pair and an optional
negated
entry, which will
             negate any comparison performed with the object."
135,80,cvtsudoers,"Each object contains a
             âname:valueâ pair and an optional
negated
entry, which will
             negate any comparison performed with the object. The name
             may be one of
runasalias
,
usergid
, or
usergroup
. If
usergroup
is set to the special value
ALL
, it will match any
             group."
135,81,cvtsudoers,"If
usergroup
is set to the special value
ALL
, it will match any
             group. The
Options
array is of the same format as the one in the
Defaults
object. Any
Tag_Spec
entries in
sudoers
are
             converted to
Options
."
135,82,cvtsudoers,"Any
Tag_Spec
entries in
sudoers
are
             converted to
Options
. A user with âsudo ALLâ privileges
             will automatically have the
setenv
option enabled to match
             the implicit behavior provided by
sudoers
. For example, the following
sudoers
entry:

             millert ALL = (ALL : ALL) NOPASSWD: ALL, !/usr/bin/id

             converts to:

             ""User_Specs"": [
                 {
                     ""User_List"": [
                         { ""username"": ""millert"" }
                     ],
                     ""Host_List"": [
                         { ""hostname"": ""ALL"" }
                     ],
                     ""Cmnd_Specs"": [
                         {
                             ""runasusers"": [
                                 { ""username"": ""ALL"" }
                             ],
                             ""runasgroups"": [
                                 { ""usergroup"": ""ALL"" }
                             ],
                             ""Options"": [
                                 { ""authenticate"": false },
                                 { ""setenv"": true }
                             ],
                             ""Commands"": [
                                 { ""command"": ""ALL"" },
                                 {
                                     ""command"": ""/usr/bin/id"",
                                     ""negated"": true
                                 }
                             ]
                         }
                     ]
                 }
             ]
CSV output format
CSV (comma-separated value) files are often used by spreadsheets
       and report generators."
135,83,cvtsudoers,"For example, the following
sudoers
entry:

             millert ALL = (ALL : ALL) NOPASSWD: ALL, !/usr/bin/id

             converts to:

             ""User_Specs"": [
                 {
                     ""User_List"": [
                         { ""username"": ""millert"" }
                     ],
                     ""Host_List"": [
                         { ""hostname"": ""ALL"" }
                     ],
                     ""Cmnd_Specs"": [
                         {
                             ""runasusers"": [
                                 { ""username"": ""ALL"" }
                             ],
                             ""runasgroups"": [
                                 { ""usergroup"": ""ALL"" }
                             ],
                             ""Options"": [
                                 { ""authenticate"": false },
                                 { ""setenv"": true }
                             ],
                             ""Commands"": [
                                 { ""command"": ""ALL"" },
                                 {
                                     ""command"": ""/usr/bin/id"",
                                     ""negated"": true
                                 }
                             ]
                         }
                     ]
                 }
             ]
CSV output format
CSV (comma-separated value) files are often used by spreadsheets
       and report generators. For CSV output,
cvtsudoers
double quotes
       strings that contain commas. For each literal double quote
       character present inside the string, two double quotes are output."
135,84,cvtsudoers,"For each literal double quote
       character present inside the string, two double quotes are output. This method of quoting commas is compatible with most spreadsheet
       programs. There are three possible sections in
cvtsudoers
's CSV output, each
       separated by a blank line:

       defaults
             This section includes any
Defaults
settings in
sudoers
."
135,85,cvtsudoers,"There are three possible sections in
cvtsudoers
's CSV output, each
       separated by a blank line:

       defaults
             This section includes any
Defaults
settings in
sudoers
. The
defaults
section begins with the following heading:

                   defaults_type,binding,name,operator,value

             The fields are as follows:

             defaults_type
                   The type of
Defaults
setting; one of
defaults
,
defaults_command
,
defaults_host
,
defaults_runas
, or
defaults_user
. binding
                   For
defaults_command
,
defaults_host
,
defaults_runas
,
                   and
defaults_user
this is the value that must match
                   for the setting to be applied."
135,86,cvtsudoers,"binding
                   For
defaults_command
,
defaults_host
,
defaults_runas
,
                   and
defaults_user
this is the value that must match
                   for the setting to be applied. name  The name of the
Defaults
setting. operator
                   The operator determines how the value is applied to
                   the setting."
135,87,cvtsudoers,"operator
                   The operator determines how the value is applied to
                   the setting. It may be either â=â (assignment), â+=â
                   (append), or â-=â (remove). value
                   The setting's value, usually a string or, for settings
                   used in a boolean context,
true
or
false
."
135,88,cvtsudoers,"value
                   The setting's value, usually a string or, for settings
                   used in a boolean context,
true
or
false
. aliases
             This section includes any
Cmnd_Alias Host_Alias
,
Runas_Alias
, or
User_Alias
, entries from
sudoers
. The
aliases
section begins with the following heading:

                   alias_type,alias_name,members

             The fields are as follows:

             alias_type
                   The type of alias; one of
Cmnd_Alias
,
Host_Alias
,
Runas_Alias
, or
User_Alias
."
135,89,cvtsudoers,"The
aliases
section begins with the following heading:

                   alias_type,alias_name,members

             The fields are as follows:

             alias_type
                   The type of alias; one of
Cmnd_Alias
,
Host_Alias
,
Runas_Alias
, or
User_Alias
. alias_name
                   The name of the alias; a string starting with an
                   upper-case letter that consists of upper-case letters,
                   digits, or underscores. members
                   A comma-separated list of members belonging to the
                   alias."
135,90,cvtsudoers,"members
                   A comma-separated list of members belonging to the
                   alias. Due to the use of commas,
members
is
                   surrounded by double quotes if it contains more than
                   one member. rules
             This section includes the
sudoers
rules that grant
             privileges."
135,91,cvtsudoers,"rules
             This section includes the
sudoers
rules that grant
             privileges. The
rules
section begins with the following
             heading:

                   rule,user,host,runusers,rungroups,options,command

             The fields are as follows:

             rule  This field indicates a
sudoers rule
entry. user  The user the rule applies to."
135,92,cvtsudoers,"user  The user the rule applies to. This may also be a Unix
                   group (preceded by a â%â character), a non-Unix group
                   (preceded by â%:â) or a netgroup (preceded by a â+â
                   character) or a
User_Alias
. If set to the special
                   value
ALL
, it will match any user."
135,93,cvtsudoers,"If set to the special
                   value
ALL
, it will match any user. host  The host the rule applies to. This may also be a
                   netgroup (preceded by a â+â character) or a
Host_Alias
."
135,94,cvtsudoers,"This may also be a
                   netgroup (preceded by a â+â character) or a
Host_Alias
. If set to the special value
ALL
, it will
                   match any host. runusers
                   An optional comma-separated list of users (or
Runas_Alias
es) the command may be run as."
135,95,cvtsudoers,"runusers
                   An optional comma-separated list of users (or
Runas_Alias
es) the command may be run as. If it
                   contains more than one member, the value is surrounded
                   by double quotes. If set to the special value
ALL
, it
                   will match any user."
135,96,cvtsudoers,"If set to the special value
ALL
, it
                   will match any user. If empty, the root user is
                   assumed. rungroups
                   An optional comma-separated list of groups (or
Runas_Alias
es) the command may be run as."
135,97,cvtsudoers,"rungroups
                   An optional comma-separated list of groups (or
Runas_Alias
es) the command may be run as. If it
                   contains more than one member, the value is surrounded
                   by double quotes. If set to the special value
ALL
, it
                   will match any group."
135,98,cvtsudoers,"If set to the special value
ALL
, it
                   will match any group. If empty, the
runuser
's group
                   is used. options
                   An optional list of
Defaults
settings to apply to the
                   command."
135,99,cvtsudoers,"options
                   An optional list of
Defaults
settings to apply to the
                   command. Any
Tag_Spec
entries in
sudoers
are
                   converted to
options
. commands
                   A list of commands, with optional arguments, that the
                   user is allowed to run."
135,100,cvtsudoers,"commands
                   A list of commands, with optional arguments, that the
                   user is allowed to run. If set to the special value
ALL
, it will match any command. For example, the following
sudoers
entry:

             millert ALL = (ALL : ALL) NOPASSWD: ALL, !/usr/bin/id

             converts to:

             rule,millert,ALL,ALL,ALL,""!authenticate"",""ALL,!/usr/bin/id"""
136,0,cxref,"The
cxref
utility shall analyze a collection of C-language
file
s
       and attempt to build a cross-reference table. Information from
#define
lines shall be included in the symbol table. A sorted
       listing shall be written to standard output of all symbols (auto,
       static, and global) in each
file
separately, or with the
-c
option, in combination."
136,1,cxref,"Information from
#define
lines shall be included in the symbol table. A sorted
       listing shall be written to standard output of all symbols (auto,
       static, and global) in each
file
separately, or with the
-c
option, in combination. Each symbol shall contain an <asterisk>
       before the declaring reference."
137,0,date,"Display date and time in the given FORMAT. With
-s
, or with
       [MMDDhhmm[[CC]YY][.ss]], set the date and time. Mandatory arguments to long options are mandatory for short
       options too."
137,1,date,"Mandatory arguments to long options are mandatory for short
       options too. -d
,
--date
=
STRING
display time described by STRING, not 'now'
--debug
annotate the parsed date, and warn about questionable usage
              to stderr
-f
,
--file
=
DATEFILE
like
--date
; once for each line of DATEFILE
-I[FMT]
,
--iso-8601
[=
FMT
]
              output date/time in ISO 8601 format. FMT='date' for date
              only (the default), 'hours', 'minutes', 'seconds', or 'ns'
              for date and time to the indicated precision."
137,2,date,"FMT='date' for date
              only (the default), 'hours', 'minutes', 'seconds', or 'ns'
              for date and time to the indicated precision. Example:
              2006-08-14T02:34:56-06:00
--resolution
output the available resolution of timestamps Example:
              0.000000001
-R
,
--rfc-email
output date and time in RFC 5322 format. Example: Mon, 14
              Aug 2006 02:34:56
-0600
--rfc-3339
=
FMT
output date/time in RFC 3339 format."
137,3,date,"Example: Mon, 14
              Aug 2006 02:34:56
-0600
--rfc-3339
=
FMT
output date/time in RFC 3339 format. FMT='date',
              'seconds', or 'ns' for date and time to the indicated
              precision. Example: 2006-08-14 02:34:56-06:00
-r
,
--reference
=
FILE
display the last modification time of FILE
-s
,
--set
=
STRING
set time described by STRING
-u
,
--utc
,
--universal
print or set Coordinated Universal Time (UTC)
--help
display this help and exit
--version
output version information and exit

       All options that specify the date to display are mutually
       exclusive."
137,4,date,"Example: 2006-08-14 02:34:56-06:00
-r
,
--reference
=
FILE
display the last modification time of FILE
-s
,
--set
=
STRING
set time described by STRING
-u
,
--utc
,
--universal
print or set Coordinated Universal Time (UTC)
--help
display this help and exit
--version
output version information and exit

       All options that specify the date to display are mutually
       exclusive. I.e.:
--date
,
--file
,
--reference
,
--resolution
. FORMAT controls the output."
137,5,date,"FORMAT controls the output. Interpreted sequences are:

       %%     a literal %

       %a     locale's abbreviated weekday name (e.g., Sun)

       %A     locale's full weekday name (e.g., Sunday)

       %b     locale's abbreviated month name (e.g., Jan)

       %B     locale's full month name (e.g., January)

       %c     locale's date and time (e.g., Thu Mar  3 23:05:25 2005)

       %C     century; like %Y, except omit last two digits (e.g., 20)

       %d     day of month (e.g., 01)

       %D     date (ambiguous); same as %m/%d/%y

       %e     day of month, space padded; same as %_d

       %F     full date; like %+4Y-%m-%d

       %g     last two digits of year of ISO week number (ambiguous;
              00-99); see %G

       %G     year of ISO week number; normally useful only with %V

       %h     same as %b

       %H     hour (00..23)

       %I     hour (01..12)

       %j     day of year (001..366)

       %k     hour, space padded ( 0..23); same as %_H

       %l     hour, space padded ( 1..12); same as %_I

       %m     month (01..12)

       %M     minute (00..59)

       %n     a newline

       %N     nanoseconds (000000000..999999999)

       %p     locale's equivalent of either AM or PM; blank if not known

       %P     like %p, but lower case

       %q     quarter of year (1..4)

       %r     locale's 12-hour clock time (e.g., 11:11:04 PM)

       %R     24-hour hour and minute; same as %H:%M

       %s     seconds since the Epoch (1970-01-01 00:00 UTC)

       %S     second (00..60)

       %t     a tab

       %T     time; same as %H:%M:%S

       %u     day of week (1..7); 1 is Monday

       %U     week number of year, with Sunday as first day of week
              (00..53)

       %V     ISO week number, with Monday as first day of week (01..53)

       %w     day of week (0..6); 0 is Sunday

       %W     week number of year, with Monday as first day of week
              (00..53)

       %x     locale's date (can be ambiguous; e.g., 12/31/99)

       %X     locale's time representation (e.g., 23:13:48)

       %y     last two digits of year (ambiguous; 00..99)

       %Y     year

       %z     +hhmm numeric time zone (e.g.,
-0400
)

       %:z    +hh:mm numeric time zone (e.g.,
-04
:00)

       %::z   +hh:mm:ss numeric time zone (e.g.,
-04
:00:00)

       %:::z  numeric time zone with : to necessary precision (e.g.,
-04
,
              +05:30)

       %Z     alphabetic time zone abbreviation (e.g., EDT)

       By default, date pads numeric fields with zeroes. The following
       optional flags may follow '%':

       -      (hyphen) do not pad the field

       _      (underscore) pad with spaces

       0      (zero) pad with zeros

       +      pad with zeros, and put '+' before future years with >4
              digits

       ^      use upper case if possible

       #      use opposite case if possible

       After any flags comes an optional field width, as a decimal
       number; then an optional modifier, which is either E to use the
       locale's alternate representations if available, or O to use the
       locale's alternate numeric symbols if available."
138,0,dash,"dash
is the standard command interpreter for the system. The
       current version of
dash
is in the process of being changed to
       conform with the POSIX 1003.2 and 1003.2a specifications for the
       shell. This version has many features which make it appear
       similar in some respects to the Korn shell, but it is not a Korn
       shell clone (see
ksh
(1))."
138,1,dash,"This version has many features which make it appear
       similar in some respects to the Korn shell, but it is not a Korn
       shell clone (see
ksh
(1)). Only features designated by POSIX, plus
       a few Berkeley extensions, are being incorporated into this shell. This man page is not intended to be a tutorial or a complete
       specification of the shell."
138,2,dash,"This man page is not intended to be a tutorial or a complete
       specification of the shell. Overview
The shell is a command that reads lines from either a file or the
       terminal, interprets them, and generally executes other commands. It is the program that is running when a user logs into the system
       (although a user can select a different shell with the
chsh
(1)
       command)."
138,3,dash,"It is the program that is running when a user logs into the system
       (although a user can select a different shell with the
chsh
(1)
       command). The shell implements a language that has flow control
       constructs, a macro facility that provides a variety of features
       in addition to data storage, along with built in history and line
       editing capabilities. It incorporates many features to aid
       interactive use and has the advantage that the interpretative
       language is common to both interactive and non-interactive use
       (shell scripts)."
138,4,dash,"It incorporates many features to aid
       interactive use and has the advantage that the interpretative
       language is common to both interactive and non-interactive use
       (shell scripts). That is, commands can be typed directly to the
       running shell or can be put into a file and the file can be
       executed directly by the shell. Invocation
If no args are present and if the standard input of the shell is
       connected to a terminal (or if the
-i
flag is set), and the
-c
option is not present, the shell is considered an interactive
       shell."
138,5,dash,"Invocation
If no args are present and if the standard input of the shell is
       connected to a terminal (or if the
-i
flag is set), and the
-c
option is not present, the shell is considered an interactive
       shell. An interactive shell generally prompts before each command
       and handles programming and command errors differently (as
       described below). When first starting, the shell inspects
       argument 0, and if it begins with a dash â-â, the shell is also
       considered a login shell."
138,6,dash,"When first starting, the shell inspects
       argument 0, and if it begins with a dash â-â, the shell is also
       considered a login shell. This is normally done automatically by
       the system when the user first logs in. A login shell first reads
       commands from the files
/etc/profile
and
.profile
if they exist."
138,7,dash,"A login shell first reads
       commands from the files
/etc/profile
and
.profile
if they exist. If the environment variable ENV is set on entry to an interactive
       shell, or is set in the
.profile
of a login shell, the shell next
       reads commands from the file named in ENV. Therefore, a user
       should place commands that are to be executed only at login time
       in the
.profile
file, and commands that are executed for every
       interactive shell inside the ENV file."
138,8,dash,"Therefore, a user
       should place commands that are to be executed only at login time
       in the
.profile
file, and commands that are executed for every
       interactive shell inside the ENV file. To set the ENV variable to
       some file, place the following line in your
.profile
of your home
       directory
ENV=$HOME/.shinit; export ENV
substituting for â.shinitâ any filename you wish. If command line arguments besides the options have been specified,
       then the shell treats the first argument as the name of a file
       from which to read commands (a shell script), and the remaining
       arguments are set as the positional parameters of the shell ($1,
       $2, etc)."
138,9,dash,"If command line arguments besides the options have been specified,
       then the shell treats the first argument as the name of a file
       from which to read commands (a shell script), and the remaining
       arguments are set as the positional parameters of the shell ($1,
       $2, etc). Otherwise, the shell reads commands from its standard
       input. Argument List Processing
All of the single letter options that have a corresponding name
       can be used as an argument to the
-o
option."
138,10,dash,"Argument List Processing
All of the single letter options that have a corresponding name
       can be used as an argument to the
-o
option. The set
-o
name is
       provided next to the single letter option in the description
       below. Specifying a dash â-â turns the option on, while using a
       plus â+â disables the option."
138,11,dash,"Specifying a dash â-â turns the option on, while using a
       plus â+â disables the option. The following options can be set
       from the command line or with the
set
builtin (described later). -a
allexport
Export all variables assigned to."
138,12,dash,"-a
allexport
Export all variables assigned to. -c
Read commands from the
command_string
operand instead of from the standard input. Special parameter 0 will be set from the
command_name
operand and the positional
                              parameters ($1, $2, etc.)  set from the
                              remaining argument operands."
138,13,dash,"Special parameter 0 will be set from the
command_name
operand and the positional
                              parameters ($1, $2, etc.)  set from the
                              remaining argument operands. -C
noclobber
Don't overwrite existing files with â>â. -e
errexit
If not interactive, exit immediately if any
                              untested command fails."
138,14,dash,"-e
errexit
If not interactive, exit immediately if any
                              untested command fails. The exit status of
                              a command is considered to be explicitly
                              tested if the command is used to control an
if
,
elif
,
while
, or
until
; or if the
                              command is the left hand operand of an â&&â
                              or â||â operator. -f
noglob
Disable pathname expansion."
138,15,dash,"-f
noglob
Disable pathname expansion. -n
noexec
If not interactive, read commands but do
                              not execute them. This is useful for
                              checking the syntax of shell scripts."
138,16,dash,"This is useful for
                              checking the syntax of shell scripts. -u
nounset
Write a message to standard error when
                              attempting to expand a variable that is not
                              set, and if the shell is not interactive,
                              exit immediately. -v
verbose
The shell writes its input to standard
                              error as it is read."
138,17,dash,"-v
verbose
The shell writes its input to standard
                              error as it is read. Useful for debugging. -x
xtrace
Write each command to standard error
                              (preceded by a â+ â) before it is executed."
138,18,dash,"-x
xtrace
Write each command to standard error
                              (preceded by a â+ â) before it is executed. Useful for debugging. -I
ignoreeof
Ignore EOF's from input when interactive."
138,19,dash,"-I
ignoreeof
Ignore EOF's from input when interactive. -i
interactive
Force the shell to behave interactively. -l
Make dash act as if it had been invoked as
                              a login shell."
138,20,dash,"-l
Make dash act as if it had been invoked as
                              a login shell. -m
monitor
Turn on job control (set automatically when
                              interactive). -s
stdin
Read commands from standard input (set
                              automatically if no file arguments are
                              present)."
138,21,dash,"-s
stdin
Read commands from standard input (set
                              automatically if no file arguments are
                              present). This option has no effect when
                              set after the shell has already started
                              running (i.e. with
set
)."
138,22,dash,"with
set
). -V
vi
Enable the built-in
vi
(1) command line
                              editor (disables
-E
if it has been set). -E
emacs
Enable the built-in
emacs
(1) command line
                              editor (disables
-V
if it has been set)."
138,23,dash,"-E
emacs
Enable the built-in
emacs
(1) command line
                              editor (disables
-V
if it has been set). -b
notify
Enable asynchronous notification of
                              background job completion. (UNIMPLEMENTED
                              for 4.4alpha)
Lexical Structure
The shell reads input in terms of lines from a file and breaks it
       up into words at whitespace (blanks and tabs), and at certain
       sequences of characters that are special to the shell called
       âoperatorsâ."
138,24,dash,"(UNIMPLEMENTED
                              for 4.4alpha)
Lexical Structure
The shell reads input in terms of lines from a file and breaks it
       up into words at whitespace (blanks and tabs), and at certain
       sequences of characters that are special to the shell called
       âoperatorsâ. There are two types of operators: control operators
       and redirection operators (their meaning is discussed later). Following is a list of operators:

             Control operators:
& && ( ) ; ;;
|
|| <newline>
Redirection operators:
< > >| << >> <& >& <<- <>
Quoting
Quoting is used to remove the special meaning of certain
       characters or words to the shell, such as operators, whitespace,
       or keywords."
138,25,dash,"Following is a list of operators:

             Control operators:
& && ( ) ; ;;
|
|| <newline>
Redirection operators:
< > >| << >> <& >& <<- <>
Quoting
Quoting is used to remove the special meaning of certain
       characters or words to the shell, such as operators, whitespace,
       or keywords. There are three types of quoting: matched single
       quotes, matched double quotes, and backslash. Backslash
A backslash preserves the literal meaning of the following
       character, with the exception of â¨newlineâ©."
138,26,dash,"Backslash
A backslash preserves the literal meaning of the following
       character, with the exception of â¨newlineâ©. A backslash preceding
       a â¨newlineâ© is treated as a line continuation. Single Quotes
Enclosing characters in single quotes preserves the literal
       meaning of all the characters (except single quotes, making it
       impossible to put single-quotes in a single-quoted string)."
138,27,dash,"Single Quotes
Enclosing characters in single quotes preserves the literal
       meaning of all the characters (except single quotes, making it
       impossible to put single-quotes in a single-quoted string). Double Quotes
Enclosing characters within double quotes preserves the literal
       meaning of all characters except dollarsign ($), backquote (`),
       and backslash (\). The backslash inside double quotes is
       historically weird, and serves to quote only the following
       characters:
$ ` "" \ <newline>
."
138,28,dash,"The backslash inside double quotes is
       historically weird, and serves to quote only the following
       characters:
$ ` "" \ <newline>
. Otherwise it remains literal. Reserved Words
Reserved words are words that have special meaning to the shell
       and are recognized at the beginning of a line and after a control
       operator."
138,29,dash,"Reserved Words
Reserved words are words that have special meaning to the shell
       and are recognized at the beginning of a line and after a control
       operator. The following are reserved words:

             ! elif    fi      while   case
             else    for     then    {       }
             do      done    until   if      esac

       Their meaning is discussed later."
138,30,dash,"elif    fi      while   case
             else    for     then    {       }
             do      done    until   if      esac

       Their meaning is discussed later. Aliases
An alias is a name and corresponding value set using the
alias
(1)
       builtin command. Whenever a reserved word may occur (see above),
       and after checking for reserved words, the shell checks the word
       to see if it matches an alias."
138,31,dash,"Whenever a reserved word may occur (see above),
       and after checking for reserved words, the shell checks the word
       to see if it matches an alias. If it does, it replaces it in the
       input stream with its value. For example, if there is an alias
       called âlfâ with the value âls -Fâ, then the input:
lf foobar
â¨returnâ©

       would become
ls -F foobar
â¨returnâ©

       Aliases provide a convenient way for naive users to create
       shorthands for commands without having to learn how to create
       functions with arguments."
138,32,dash,"For example, if there is an alias
       called âlfâ with the value âls -Fâ, then the input:
lf foobar
â¨returnâ©

       would become
ls -F foobar
â¨returnâ©

       Aliases provide a convenient way for naive users to create
       shorthands for commands without having to learn how to create
       functions with arguments. They can also be used to create
       lexically obscure code. This use is discouraged."
138,33,dash,"This use is discouraged. Commands
The shell interprets the words it reads according to a language,
       the specification of which is outside the scope of this man page
       (refer to the BNF in the POSIX 1003.2 document). Essentially
       though, a line is read and if the first word of the line (or after
       a control operator) is not a reserved word, then the shell has
       recognized a simple command."
138,34,dash,"Essentially
       though, a line is read and if the first word of the line (or after
       a control operator) is not a reserved word, then the shell has
       recognized a simple command. Otherwise, a complex command or some
       other special construct may have been recognized. Simple Commands
If a simple command has been recognized, the shell performs the
       following actions:

             1."
138,35,dash,"Simple Commands
If a simple command has been recognized, the shell performs the
       following actions:

             1. Leading words of the form âname=valueâ are stripped off
                  and assigned to the environment of the simple command. Redirection operators and their arguments (as described
                  below) are stripped off and saved for processing."
138,36,dash,"Redirection operators and their arguments (as described
                  below) are stripped off and saved for processing. 2. The remaining words are expanded as described in the
                  section called âExpansionsâ, and the first remaining
                  word is considered the command name and the command is
                  located."
138,37,dash,"The remaining words are expanded as described in the
                  section called âExpansionsâ, and the first remaining
                  word is considered the command name and the command is
                  located. The remaining words are considered the
                  arguments of the command. If no command name resulted,
                  then the âname=valueâ variable assignments recognized
                  in item 1 affect the current shell."
138,38,dash,"If no command name resulted,
                  then the âname=valueâ variable assignments recognized
                  in item 1 affect the current shell. 3. Redirections are performed as described in the next
                  section."
138,39,dash,"Redirections are performed as described in the next
                  section. Redirections
Redirections are used to change where a command reads its input or
       sends its output. In general, redirections open, close, or
       duplicate an existing reference to a file."
138,40,dash,"In general, redirections open, close, or
       duplicate an existing reference to a file. The overall format
       used for redirection is:
[n]
redir-op file
where
redir-op
is one of the redirection operators mentioned
       previously. Following is a list of the possible redirections."
138,41,dash,"Following is a list of the possible redirections. The [n] is an optional number between 0 and 9, as in â3â (not
       â[3]â), that refers to a file descriptor. [n]> file   Redirect standard output (or n) to file."
138,42,dash,"[n]> file   Redirect standard output (or n) to file. [n]>| file  Same, but override the
-C
option. [n]>> file  Append standard output (or n) to file."
138,43,dash,[n]>> file  Append standard output (or n) to file. [n]< file   Redirect standard input (or n) from file. [n1]<&n2    Copy file descriptor n2 as stdin (or fd n1).
138,44,dash,[n1]<&n2    Copy file descriptor n2 as stdin (or fd n1). [n]<&-      Close standard input (or n). [n1]>&n2    Copy file descriptor n2 as stdout (or fd n1).
138,45,dash,"[n1]>&n2    Copy file descriptor n2 as stdout (or fd n1). [n]>&-      Close standard output (or n). [n]<> file  Open file for reading and writing on standard
                         input (or n)."
138,46,dash,"[n]<> file  Open file for reading and writing on standard
                         input (or n). The following redirection is often called a âhere-documentâ. [n]<< delimiter
here-doc-text ..."
138,47,dash,"[n]<< delimiter
here-doc-text ... delimiter
All the text on successive lines up to the delimiter is saved away
       and made available to the command on standard input, or file
       descriptor n if it is specified. If the delimiter as specified on
       the initial line is quoted, then the here-doc-text is treated
       literally, otherwise the text is subjected to parameter expansion,
       command substitution, and arithmetic expansion (as described in
       the section on âExpansionsâ)."
138,48,dash,"If the delimiter as specified on
       the initial line is quoted, then the here-doc-text is treated
       literally, otherwise the text is subjected to parameter expansion,
       command substitution, and arithmetic expansion (as described in
       the section on âExpansionsâ). If the operator is â<<-â instead of
       â<<â, then leading tabs in the here-doc-text are stripped. Search and Execution
There are three types of commands: shell functions, builtin
       commands, and normal programs â and the command is searched for
       (by name) in that order."
138,49,dash,"Search and Execution
There are three types of commands: shell functions, builtin
       commands, and normal programs â and the command is searched for
       (by name) in that order. They each are executed in a different
       way. When a shell function is executed, all of the shell positional
       parameters (except $0, which remains unchanged) are set to the
       arguments of the shell function."
138,50,dash,"When a shell function is executed, all of the shell positional
       parameters (except $0, which remains unchanged) are set to the
       arguments of the shell function. The variables which are
       explicitly placed in the environment of the command (by placing
       assignments to them before the function name) are made local to
       the function and are set to the values given. Then the command
       given in the function definition is executed."
138,51,dash,"Then the command
       given in the function definition is executed. The positional
       parameters are restored to their original values when the command
       completes. This all occurs within the current shell."
138,52,dash,"This all occurs within the current shell. Shell builtins are executed internally to the shell, without
       spawning a new process. Otherwise, if the command name doesn't match a function or
       builtin, the command is searched for as a normal program in the
       file system (as described in the next section)."
138,53,dash,"Otherwise, if the command name doesn't match a function or
       builtin, the command is searched for as a normal program in the
       file system (as described in the next section). When a normal
       program is executed, the shell runs the program, passing the
       arguments and the environment to the program. If the program is
       not a normal executable file (i.e., if it does not begin with the
       ""magic number"" whose ASCII representation is ""#!"", so
execve
(2)
       returns ENOEXEC then) the shell will interpret the program in a
       subshell."
138,54,dash,"If the program is
       not a normal executable file (i.e., if it does not begin with the
       ""magic number"" whose ASCII representation is ""#!"", so
execve
(2)
       returns ENOEXEC then) the shell will interpret the program in a
       subshell. The child shell will reinitialize itself in this case,
       so that the effect will be as if a new shell had been invoked to
       handle the ad-hoc shell script, except that the location of hashed
       commands located in the parent shell will be remembered by the
       child. Note that previous versions of this document and the source code
       itself misleadingly and sporadically refer to a shell script
       without a magic number as a ""shell procedure""."
138,55,dash,"Note that previous versions of this document and the source code
       itself misleadingly and sporadically refer to a shell script
       without a magic number as a ""shell procedure"". Path Search
When locating a command, the shell first looks to see if it has a
       shell function by that name. Then it looks for a builtin command
       by that name."
138,56,dash,"Then it looks for a builtin command
       by that name. If a builtin command is not found, one of two
       things happen:

       1. Command names containing a slash are simply executed without
            performing any searches."
138,57,dash,"Command names containing a slash are simply executed without
            performing any searches. 2. The shell searches each entry in PATH in turn for the
            command."
138,58,dash,"The shell searches each entry in PATH in turn for the
            command. The value of the PATH variable should be a series
            of entries separated by colons. Each entry consists of a
            directory name."
138,59,dash,"Each entry consists of a
            directory name. The current directory may be indicated
            implicitly by an empty directory name, or explicitly by a
            single period. Command Exit Status
Each command has an exit status that can influence the behaviour
       of other shell commands."
138,60,dash,"Command Exit Status
Each command has an exit status that can influence the behaviour
       of other shell commands. The paradigm is that a command exits
       with zero for normal or success, and non-zero for failure, error,
       or a false indication. The man page for each command should
       indicate the various exit codes and what they mean."
138,61,dash,"The man page for each command should
       indicate the various exit codes and what they mean. Additionally,
       the builtin commands return exit codes, as does an executed shell
       function. If a command consists entirely of variable assignments then the
       exit status of the command is that of the last command
       substitution if any, otherwise 0."
138,62,dash,"If a command consists entirely of variable assignments then the
       exit status of the command is that of the last command
       substitution if any, otherwise 0. Complex Commands
Complex commands are combinations of simple commands with control
       operators or reserved words, together creating a larger complex
       command. More generally, a command is one of the following:
â¢
simple command
â¢
pipeline
â¢
list or compound-list
â¢
compound command
â¢
function definition

       Unless otherwise stated, the exit status of a command is that of
       the last simple command executed by the command."
138,63,dash,"More generally, a command is one of the following:
â¢
simple command
â¢
pipeline
â¢
list or compound-list
â¢
compound command
â¢
function definition

       Unless otherwise stated, the exit status of a command is that of
       the last simple command executed by the command. Pipelines
A pipeline is a sequence of one or more commands separated by the
       control operator |. The standard output of all but the last
       command is connected to the standard input of the next command."
138,64,dash,"The standard output of all but the last
       command is connected to the standard input of the next command. The standard output of the last command is inherited from the
       shell, as usual. The format for a pipeline is:
[!] command1
[|
command2 ...]
The standard output of command1 is connected to the standard input
       of command2."
138,65,dash,"The format for a pipeline is:
[!] command1
[|
command2 ...]
The standard output of command1 is connected to the standard input
       of command2. The standard input, standard output, or both of a
       command is considered to be assigned by the pipeline before any
       redirection specified by redirection operators that are part of
       the command. If the pipeline is not in the background (discussed later), the
       shell waits for all commands to complete."
138,66,dash,"If the pipeline is not in the background (discussed later), the
       shell waits for all commands to complete. If the
pipefail
option was enabled when the shell began execution
       of the pipeline, the pipeline's exit status is the exit status of
       the last command specified in the pipeline that exited with non-
       zero status, or zero if all commands in the pipeline exited with a
       status of zero. If the
pipefail
option was not enabled, the
       pipeline's exit status is the exit status of the last command
       specified in the pipeline; the exit statuses of any other commands
       are not used."
138,67,dash,"If the
pipefail
option was not enabled, the
       pipeline's exit status is the exit status of the last command
       specified in the pipeline; the exit statuses of any other commands
       are not used. If the reserved word ! precedes the pipeline, its
       exit status is the logical NOT of the exit status described above."
138,68,dash,"precedes the pipeline, its
       exit status is the logical NOT of the exit status described above. Because pipeline assignment of standard input or standard output
       or both takes place before redirection, it can be modified by
       redirection. For example:
$ command1 2>&1
|
command2
sends both the standard output and standard error of command1 to
       the standard input of command2."
138,69,dash,"For example:
$ command1 2>&1
|
command2
sends both the standard output and standard error of command1 to
       the standard input of command2. A ; or â¨newlineâ© terminator causes the preceding AND-OR-list
       (described next) to be executed sequentially; a & causes
       asynchronous execution of the preceding AND-OR-list. Note that unlike some other shells, each process in the pipeline
       is a child of the invoking shell (unless it is a shell builtin, in
       which case it executes in the current shell â but any effect it
       has on the environment is wiped)."
138,70,dash,"Note that unlike some other shells, each process in the pipeline
       is a child of the invoking shell (unless it is a shell builtin, in
       which case it executes in the current shell â but any effect it
       has on the environment is wiped). Background Commands â &
If a command is terminated by the control operator ampersand (&),
       the shell executes the command asynchronously â that is, the shell
       does not wait for the command to finish before executing the next
       command. The format for running a command in background is:
command1 & [command2 & ...]
If the shell is not interactive, the standard input of an
       asynchronous command is set to
/dev/null
."
138,71,dash,"The format for running a command in background is:
command1 & [command2 & ...]
If the shell is not interactive, the standard input of an
       asynchronous command is set to
/dev/null
. Lists â Generally Speaking
A list is a sequence of zero or more commands separated by
       newlines, semicolons, or ampersands, and optionally terminated by
       one of these three characters. The commands in a list are
       executed in the order they are written."
138,72,dash,"The commands in a list are
       executed in the order they are written. If command is followed by
       an ampersand, the shell starts the command and immediately
       proceeds onto the next command; otherwise it waits for the command
       to terminate before proceeding to the next one. Short-Circuit List Operators
â&&â and â||â are AND-OR list operators."
138,73,dash,"Short-Circuit List Operators
â&&â and â||â are AND-OR list operators. â&&â executes the first
       command, and then executes the second command if and only if the
       exit status of the first command is zero. â||â is similar, but
       executes the second command if and only if the exit status of the
       first command is nonzero."
138,74,dash,"â||â is similar, but
       executes the second command if and only if the exit status of the
       first command is nonzero. â&&â and â||â both have the same
       priority. Flow-Control Constructs â if, while, for, case
The syntax of the if command is

             if list
             then list
             [ elif list
             then    list ] ..."
138,75,dash,"Flow-Control Constructs â if, while, for, case
The syntax of the if command is

             if list
             then list
             [ elif list
             then    list ] ... [ else list ]
             fi

       The syntax of the while command is

             while list
             do   list
             done

       The two lists are executed repeatedly while the exit status of the
       first list is zero. The until command is similar, but has the
       word until in place of while, which causes it to repeat until the
       exit status of the first list is zero."
138,76,dash,"The until command is similar, but has the
       word until in place of while, which causes it to repeat until the
       exit status of the first list is zero. The syntax of the for command is

             for variable [ in [ word ... ] ]
             do   list
             done

       The words following
in
are expanded, and then the list is executed
       repeatedly with the variable set to each word in turn."
138,77,dash,"] ]
             do   list
             done

       The words following
in
are expanded, and then the list is executed
       repeatedly with the variable set to each word in turn. Omitting
       in word ... is equivalent to in ""$@""."
138,78,dash,"is equivalent to in ""$@"". The syntax of the break and continue command is

             break [ num ]
             continue [ num ]

       Break terminates the num innermost for or while loops. Continue
       continues with the next iteration of the innermost loop."
138,79,dash,"Continue
       continues with the next iteration of the innermost loop. These
       are implemented as builtin commands. The syntax of the case command is

             case word in
             [(]pattern) list ;;
             ..."
138,80,dash,"The syntax of the case command is

             case word in
             [(]pattern) list ;;
             ... esac

       The pattern can actually be one or more patterns (see âShell
       Patternsâ described later), separated by â|â characters. The â(â
       character before the pattern is optional."
138,81,dash,"The â(â
       character before the pattern is optional. Grouping Commands Together
Commands may be grouped by writing either
(list)
or
{ list; }
The first of these executes the commands in a subshell. Builtin
       commands grouped into a (list) will not affect the current shell."
138,82,dash,"Builtin
       commands grouped into a (list) will not affect the current shell. The second form does not fork another shell so is slightly more
       efficient. Grouping commands together this way allows you to
       redirect their output as though they were one program:

             { printf "" hello "" ; printf "" world\n"" ; } > greeting

       Note that â}â must follow a control operator (here, â;â) so that
       it is recognized as a reserved word and not as another command
       argument."
138,83,dash,"Grouping commands together this way allows you to
       redirect their output as though they were one program:

             { printf "" hello "" ; printf "" world\n"" ; } > greeting

       Note that â}â must follow a control operator (here, â;â) so that
       it is recognized as a reserved word and not as another command
       argument. Functions
The syntax of a function definition is
name
()
command
A function definition is an executable statement; when executed it
       installs a function named name and returns an exit status of zero. The command is normally a list enclosed between â{â and â}â."
138,84,dash,"The command is normally a list enclosed between â{â and â}â. Variables may be declared to be local to a function by using a
       local command. This should appear as the first statement of a
       function, and the syntax is
local
[
variable
|
-
]
..."
138,85,dash,"This should appear as the first statement of a
       function, and the syntax is
local
[
variable
|
-
]
... Local is implemented as a builtin command. When a variable is made local, it inherits the initial value and
       exported and readonly flags from the variable with the same name
       in the surrounding scope, if there is one."
138,86,dash,"When a variable is made local, it inherits the initial value and
       exported and readonly flags from the variable with the same name
       in the surrounding scope, if there is one. Otherwise, the
       variable is initially unset. The shell uses dynamic scoping, so
       that if you make the variable x local to function f, which then
       calls function g, references to the variable x made inside g will
       refer to the variable x declared inside f, not to the global
       variable named x."
138,87,dash,"The shell uses dynamic scoping, so
       that if you make the variable x local to function f, which then
       calls function g, references to the variable x made inside g will
       refer to the variable x declared inside f, not to the global
       variable named x. The only special parameter that can be made local is â-â. Making
       â-â local any shell options that are changed via the set command
       inside the function to be restored to their original values when
       the function returns."
138,88,dash,"Making
       â-â local any shell options that are changed via the set command
       inside the function to be restored to their original values when
       the function returns. The syntax of the return command is
return
[
exitstatus
]

       It terminates the currently executing function. Return is
       implemented as a builtin command."
138,89,dash,"Return is
       implemented as a builtin command. Variables and Parameters
The shell maintains a set of parameters. A parameter denoted by a
       name is called a variable."
138,90,dash,"A parameter denoted by a
       name is called a variable. When starting up, the shell turns all
       the environment variables into shell variables. New variables can
       be set using the form
name=value
Variables set by the user must have a name consisting solely of
       alphabetics, numerics, and underscores - the first of which must
       not be numeric."
138,91,dash,"New variables can
       be set using the form
name=value
Variables set by the user must have a name consisting solely of
       alphabetics, numerics, and underscores - the first of which must
       not be numeric. A parameter can also be denoted by a number or a
       special character as explained below. Positional Parameters
A positional parameter is a parameter denoted by a number (n > 0)."
138,92,dash,"Positional Parameters
A positional parameter is a parameter denoted by a number (n > 0). The shell sets these initially to the values of its command line
       arguments that follow the name of the shell script. The
set
builtin can also be used to set or reset them."
138,93,dash,"The
set
builtin can also be used to set or reset them. Special Parameters
A special parameter is a parameter denoted by one of the following
       special characters. The value of the parameter is listed next to
       its character."
138,94,dash,"The value of the parameter is listed next to
       its character. *            Expands to the positional parameters, starting from
                    one. When the expansion occurs within a double-
                    quoted string it expands to a single field with the
                    value of each parameter separated by the first
                    character of the IFS variable, or by a â¨spaceâ© if IFS
                    is unset."
138,95,dash,"When the expansion occurs within a double-
                    quoted string it expands to a single field with the
                    value of each parameter separated by the first
                    character of the IFS variable, or by a â¨spaceâ© if IFS
                    is unset. @            Expands to the positional parameters, starting from
                    one. When the expansion occurs within double-quotes,
                    each positional parameter expands as a separate
                    argument."
138,96,dash,"When the expansion occurs within double-quotes,
                    each positional parameter expands as a separate
                    argument. If there are no positional parameters, the
                    expansion of @ generates zero arguments, even when @
                    is double-quoted. What this basically means, for
                    example, is if $1 is âabcâ and $2 is âdef ghiâ, then
                    ""$@"" expands to the two arguments:
""abc"" ""def ghi""
#            Expands to the number of positional parameters."
138,97,dash,"What this basically means, for
                    example, is if $1 is âabcâ and $2 is âdef ghiâ, then
                    ""$@"" expands to the two arguments:
""abc"" ""def ghi""
#            Expands to the number of positional parameters. ? Expands to the exit status of the most recent
                    pipeline."
138,98,dash,"Expands to the exit status of the most recent
                    pipeline. - (Hyphen.)  Expands to the current option flags (the single-
                    letter option names concatenated into a string) as
                    specified on invocation, by the set builtin command,
                    or implicitly by the shell. $            Expands to the process ID of the invoked shell."
138,99,dash,"$            Expands to the process ID of the invoked shell. A
                    subshell retains the same value of $ as its parent. !"
138,100,dash,"! Expands to the process ID of the most recent
                    background command executed from the current shell. For a pipeline, the process ID is that of the last
                    command in the pipeline."
138,101,dash,"For a pipeline, the process ID is that of the last
                    command in the pipeline. 0 (Zero.)    Expands to the name of the shell or shell script. Word Expansions
This clause describes the various expansions that are performed on
       words."
138,102,dash,"Word Expansions
This clause describes the various expansions that are performed on
       words. Not all expansions are performed on every word, as
       explained later. Tilde expansions, parameter expansions, command substitutions,
       arithmetic expansions, and quote removals that occur within a
       single word expand to a single field."
138,103,dash,"Tilde expansions, parameter expansions, command substitutions,
       arithmetic expansions, and quote removals that occur within a
       single word expand to a single field. It is only field splitting
       or pathname expansion that can create multiple fields from a
       single word. The single exception to this rule is the expansion
       of the special parameter @ within double-quotes, as was described
       above."
138,104,dash,"The single exception to this rule is the expansion
       of the special parameter @ within double-quotes, as was described
       above. The order of word expansion is:

       1. Tilde Expansion, Parameter Expansion, Command Substitution,
            Arithmetic Expansion (these all occur at the same time)."
138,105,dash,"Tilde Expansion, Parameter Expansion, Command Substitution,
            Arithmetic Expansion (these all occur at the same time). 2. Field Splitting is performed on fields generated by step (1)
            unless the IFS variable is null."
138,106,dash,"Field Splitting is performed on fields generated by step (1)
            unless the IFS variable is null. 3. Pathname Expansion (unless set
-f
is in effect)."
138,107,dash,"Pathname Expansion (unless set
-f
is in effect). 4. Quote Removal."
138,108,dash,"Quote Removal. The $ character is used to introduce parameter expansion, command
       substitution, or arithmetic evaluation. Tilde Expansion (substituting a user's home directory)
A word beginning with an unquoted tilde character (~) is subjected
       to tilde expansion."
138,109,dash,"Tilde Expansion (substituting a user's home directory)
A word beginning with an unquoted tilde character (~) is subjected
       to tilde expansion. All the characters up to a slash (/) or the
       end of the word are treated as a username and are replaced with
       the user's home directory. If the username is missing (as in
~/foobar
), the tilde is replaced with the value of the
HOME
variable (the current user's home directory)."
138,110,dash,"If the username is missing (as in
~/foobar
), the tilde is replaced with the value of the
HOME
variable (the current user's home directory). Parameter Expansion
The format for parameter expansion is as follows:
${expression}
where expression consists of all characters until the matching
       â}â. Any â}â escaped by a backslash or within a quoted string,
       and characters in embedded arithmetic expansions, command
       substitutions, and variable expansions, are not examined in
       determining the matching â}â."
138,111,dash,"Any â}â escaped by a backslash or within a quoted string,
       and characters in embedded arithmetic expansions, command
       substitutions, and variable expansions, are not examined in
       determining the matching â}â. The simplest form for parameter expansion is:
${parameter}
The value, if any, of parameter is substituted. The parameter name or symbol can be enclosed in braces, which are
       optional except for positional parameters with more than one digit
       or when parameter is followed by a character that could be
       interpreted as part of the name."
138,112,dash,"The parameter name or symbol can be enclosed in braces, which are
       optional except for positional parameters with more than one digit
       or when parameter is followed by a character that could be
       interpreted as part of the name. If a parameter expansion occurs
       inside double-quotes:

       1. Pathname expansion is not performed on the results of the
            expansion."
138,113,dash,"Pathname expansion is not performed on the results of the
            expansion. 2. Field splitting is not performed on the results of the
            expansion, with the exception of @."
138,114,dash,"Field splitting is not performed on the results of the
            expansion, with the exception of @. In addition, a parameter expansion can be modified by using one of
       the following formats. ${parameter:-word}    Use Default Values."
138,115,dash,"${parameter:-word}    Use Default Values. If parameter is unset
                             or null, the expansion of word is
                             substituted; otherwise, the value of
                             parameter is substituted. ${parameter:=word}    Assign Default Values."
138,116,dash,"${parameter:=word}    Assign Default Values. If parameter is
                             unset or null, the expansion of word is
                             assigned to parameter. In all cases, the
                             final value of parameter is substituted."
138,117,dash,"In all cases, the
                             final value of parameter is substituted. Only variables, not positional parameters or
                             special parameters, can be assigned in this
                             way. ${parameter:?[word]}  Indicate Error if Null or Unset."
138,118,dash,"${parameter:?[word]}  Indicate Error if Null or Unset. If
                             parameter is unset or null, the expansion of
                             word (or a message indicating it is unset if
                             word is omitted) is written to standard
                             error and the shell exits with a nonzero
                             exit status. Otherwise, the value of
                             parameter is substituted."
138,119,dash,"Otherwise, the value of
                             parameter is substituted. An interactive
                             shell need not exit. ${parameter:+word}    Use Alternative Value."
138,120,dash,"${parameter:+word}    Use Alternative Value. If parameter is
                             unset or null, null is substituted;
                             otherwise, the expansion of word is
                             substituted. In the parameter expansions shown previously, use of the colon in
       the format results in a test for a parameter that is unset or
       null; omission of the colon results in a test for a parameter that
       is only unset."
138,121,dash,"In the parameter expansions shown previously, use of the colon in
       the format results in a test for a parameter that is unset or
       null; omission of the colon results in a test for a parameter that
       is only unset. ${#parameter}         String Length. The length in characters of
                             the value of parameter."
138,122,dash,"The length in characters of
                             the value of parameter. The following four varieties of parameter expansion provide for
       substring processing. In each case, pattern matching notation
       (see âShell Patternsâ), rather than regular expression notation,
       is used to evaluate the patterns."
138,123,dash,"In each case, pattern matching notation
       (see âShell Patternsâ), rather than regular expression notation,
       is used to evaluate the patterns. If parameter is * or @, the
       result of the expansion is unspecified. Enclosing the full
       parameter expansion string in double-quotes does not cause the
       following four varieties of pattern characters to be quoted,
       whereas quoting characters within the braces has this effect."
138,124,dash,"Enclosing the full
       parameter expansion string in double-quotes does not cause the
       following four varieties of pattern characters to be quoted,
       whereas quoting characters within the braces has this effect. ${parameter%word}     Remove Smallest Suffix Pattern. The word is
                             expanded to produce a pattern."
138,125,dash,"The word is
                             expanded to produce a pattern. The
                             parameter expansion then results in
                             parameter, with the smallest portion of the
                             suffix matched by the pattern deleted. ${parameter%%word}    Remove Largest Suffix Pattern."
138,126,dash,"${parameter%%word}    Remove Largest Suffix Pattern. The word is
                             expanded to produce a pattern. The
                             parameter expansion then results in
                             parameter, with the largest portion of the
                             suffix matched by the pattern deleted."
138,127,dash,"The
                             parameter expansion then results in
                             parameter, with the largest portion of the
                             suffix matched by the pattern deleted. ${parameter#word}     Remove Smallest Prefix Pattern. The word is
                             expanded to produce a pattern."
138,128,dash,"The word is
                             expanded to produce a pattern. The
                             parameter expansion then results in
                             parameter, with the smallest portion of the
                             prefix matched by the pattern deleted. ${parameter##word}    Remove Largest Prefix Pattern."
138,129,dash,"${parameter##word}    Remove Largest Prefix Pattern. The word is
                             expanded to produce a pattern. The
                             parameter expansion then results in
                             parameter, with the largest portion of the
                             prefix matched by the pattern deleted."
138,130,dash,"The
                             parameter expansion then results in
                             parameter, with the largest portion of the
                             prefix matched by the pattern deleted. Command Substitution
Command substitution allows the output of a command to be
       substituted in place of the command name itself. Command
       substitution occurs when the command is enclosed as follows:
$(command)
or (âbackquotedâ version):
`command`
The shell expands the command substitution by executing command in
       a subshell environment and replacing the command substitution with
       the standard output of the command, removing sequences of one or
       more â¨newlineâ©s at the end of the substitution."
138,131,dash,"Command
       substitution occurs when the command is enclosed as follows:
$(command)
or (âbackquotedâ version):
`command`
The shell expands the command substitution by executing command in
       a subshell environment and replacing the command substitution with
       the standard output of the command, removing sequences of one or
       more â¨newlineâ©s at the end of the substitution. (Embedded
       â¨newlineâ©s before the end of the output are not removed; however,
       during field splitting, they may be translated into â¨spaceâ©s,
       depending on the value of IFS and quoting that is in effect.)
Arithmetic Expansion
Arithmetic expansion provides a mechanism for evaluating an
       arithmetic expression and substituting its value. The format for
       arithmetic expansion is as follows:
$((expression))
The expression is treated as if it were in double-quotes, except
       that a double-quote inside the expression is not treated
       specially."
138,132,dash,"The format for
       arithmetic expansion is as follows:
$((expression))
The expression is treated as if it were in double-quotes, except
       that a double-quote inside the expression is not treated
       specially. The shell expands all tokens in the expression for
       parameter expansion, command substitution, and quote removal. Next, the shell treats this as an arithmetic expression and
       substitutes the value of the expression."
138,133,dash,"Next, the shell treats this as an arithmetic expression and
       substitutes the value of the expression. White Space Splitting (Field Splitting)
After parameter expansion, command substitution, and arithmetic
       expansion the shell scans the results of expansions and
       substitutions that did not occur in double-quotes for field
       splitting and multiple fields can result. The shell treats each character of the IFS as a delimiter and uses
       the delimiters to split the results of parameter expansion and
       command substitution into fields."
138,134,dash,"The shell treats each character of the IFS as a delimiter and uses
       the delimiters to split the results of parameter expansion and
       command substitution into fields. If IFS is empty, field splitting yields no fields if the input
       string was empty, and one string with the unchanged value of the
       input otherwise. For example, with the default IFS, â
read -r
lâ
       will remove any initial whitespace, but âIFS=
read -r
lâ will
       leave the entire line in l."
138,135,dash,"For example, with the default IFS, â
read -r
lâ
       will remove any initial whitespace, but âIFS=
read -r
lâ will
       leave the entire line in l. Pathname Expansion (File Name Generation)
Unless the
-f
flag is set, file name generation is performed after
       word splitting is complete. Each word is viewed as a series of
       patterns, separated by slashes."
138,136,dash,"Each word is viewed as a series of
       patterns, separated by slashes. The process of expansion replaces
       the word with the names of all existing files whose names can be
       formed by replacing each pattern with a string that matches the
       specified pattern. There are two restrictions on this: first, a
       pattern cannot match a string containing a slash, and second, a
       pattern cannot match a string starting with a period unless the
       first character of the pattern is a period."
138,137,dash,"There are two restrictions on this: first, a
       pattern cannot match a string containing a slash, and second, a
       pattern cannot match a string starting with a period unless the
       first character of the pattern is a period. The next section
       describes the patterns used for both Pathname Expansion and the
case
command. Shell Patterns
A pattern consists of normal characters, which match themselves,
       and meta-characters."
138,138,dash,"Shell Patterns
A pattern consists of normal characters, which match themselves,
       and meta-characters. The meta-characters are â!â, â*â, â?â, and
       â[â. These characters lose their special meanings if they are
       quoted."
138,139,dash,"These characters lose their special meanings if they are
       quoted. When command or variable substitution is performed and
       the dollar sign or back quotes are not double quoted, the value of
       the variable or the output of the command is scanned for these
       characters and they are turned into meta-characters. An asterisk (â*â) matches any string of characters."
138,140,dash,"An asterisk (â*â) matches any string of characters. A question
       mark matches any single character. A left bracket (â[â)
       introduces a character class."
138,141,dash,"A left bracket (â[â)
       introduces a character class. The end of the character class is
       indicated by a (â]â); if the â]â is missing then the â[â matches a
       â[â rather than introducing a character class. A character class
       matches any of the characters between the square brackets."
138,142,dash,"A character class
       matches any of the characters between the square brackets. A
       range of characters may be specified using a minus sign. The
       character class may be complemented by making an exclamation point
       the first character of the character class."
138,143,dash,"The
       character class may be complemented by making an exclamation point
       the first character of the character class. To include a â]â in a character class, make it the first character
       listed (after the â!â, if any). To include a minus sign, make it
       the first or last character listed."
138,144,dash,"To include a minus sign, make it
       the first or last character listed. Builtins
This section lists the builtin commands which are builtin because
       they need to perform some operation that can't be performed by a
       separate process. In addition to these, there are several other
       commands that may be builtin for efficiency (e.g."
138,145,dash,"In addition to these, there are several other
       commands that may be builtin for efficiency (e.g. printf
(1),
echo
(1),
test
(1), etc). :

       true   A null command that returns a 0 (true) exit value."
138,146,dash,":

       true   A null command that returns a 0 (true) exit value. false  A null command that returns a 1 (false) exit value. ."
138,147,dash,". file
              The commands in the specified file are read and executed by
              the shell. alias [
name
[
=string ..."
138,148,dash,"alias [
name
[
=string ... ]]
              If
name=string
is specified, the shell defines the alias
name
with value
string
. If just
name
is specified, the
              value of the alias
name
is printed."
138,149,dash,"If just
name
is specified, the
              value of the alias
name
is printed. With no arguments, the
alias
builtin prints the names and values of all defined
              aliases (see
unalias
). bg [
job
]
..."
138,150,dash,"bg [
job
]
... Continue the specified jobs (or the current job if no jobs
              are given) in the background. command [
-p
] [
-v
] [
-V
]
command
[
arg ..."
138,151,dash,"command [
-p
] [
-v
] [
-V
]
command
[
arg ... ]
              Execute the specified command but ignore shell functions
              when searching for it. (This is useful when you have a
              shell function with the same name as a builtin command.)
-p
search for command using a PATH that guarantees to
                     find all the standard utilities."
138,152,dash,"(This is useful when you have a
              shell function with the same name as a builtin command.)
-p
search for command using a PATH that guarantees to
                     find all the standard utilities. -V
Do not execute the command but search for the
                     command and print the resolution of the command
                     search. This is the same as the type builtin."
138,153,dash,"This is the same as the type builtin. -v
Do not execute the command but search for the
                     command and print the absolute pathname of
                     utilities, the name for builtins or the expansion of
                     aliases. cd|chdir
-
cd|chdir [
-LP
] [
directory
]
              Switch to the specified directory (default HOME)."
138,154,dash,"cd|chdir
-
cd|chdir [
-LP
] [
directory
]
              Switch to the specified directory (default HOME). If an
              entry for CDPATH appears in the environment of the
cd
command or the shell variable CDPATH is set and the
              directory name does not begin with a slash, then the
              directories listed in CDPATH will be searched for the
              specified directory. The format of CDPATH is the same as
              that of PATH."
138,155,dash,"The format of CDPATH is the same as
              that of PATH. If a single dash is specified as the
              argument, it will be replaced by the value of OLDPWD. The
cd
command will print out the name of the directory that it
              actually switched to if this is different from the name
              that the user gave."
138,156,dash,"The
cd
command will print out the name of the directory that it
              actually switched to if this is different from the name
              that the user gave. These may be different either because
              the CDPATH mechanism was used or because the argument is a
              single dash. The
-P
option causes the physical directory
              structure to be used, that is, all symbolic links are
              resolved to their respective values."
138,157,dash,"The
-P
option causes the physical directory
              structure to be used, that is, all symbolic links are
              resolved to their respective values. The
-L
option turns
              off the effect of any preceding
-P
options. echo [
-n
]
args..."
138,158,dash,"echo [
-n
]
args... Print the arguments on the standard output, separated by
              spaces. Unless the
-n
option is present, a newline is
              output following the arguments."
138,159,dash,"Unless the
-n
option is present, a newline is
              output following the arguments. If any of the following sequences of characters is
              encountered during output, the sequence is not output. Instead, the specified action is performed:
\b
A backspace character is output."
138,160,dash,"Instead, the specified action is performed:
\b
A backspace character is output. \c
Subsequent output is suppressed. This is normally
                      used at the end of the last argument to suppress
                      the trailing newline that
echo
would otherwise
                      output."
138,161,dash,"This is normally
                      used at the end of the last argument to suppress
                      the trailing newline that
echo
would otherwise
                      output. \f
Output a form feed. \n
Output a newline character."
138,162,dash,"\n
Output a newline character. \r
Output a carriage return. \t
Output a (horizontal) tab character."
138,163,dash,"\t
Output a (horizontal) tab character. \v
Output a vertical tab. \0
digits
Output the character whose value is given by zero
                      to three octal digits."
138,164,dash,"\0
digits
Output the character whose value is given by zero
                      to three octal digits. If there are zero digits, a
                      nul character is output. \\
Output a backslash."
138,165,dash,"\\
Output a backslash. All other backslash sequences elicit undefined behaviour. eval
string ..."
138,166,dash,"eval
string ... Concatenate all the arguments with spaces. Then re-parse
              and execute the command."
138,167,dash,"Then re-parse
              and execute the command. exec [
command arg ... ]
              Unless command is omitted, the shell process is replaced
              with the specified program (which must be a real program,
              not a shell builtin or function)."
138,168,dash,"]
              Unless command is omitted, the shell process is replaced
              with the specified program (which must be a real program,
              not a shell builtin or function). Any redirections on the
exec
command are marked as permanent, so that they are not
              undone when the
exec
command finishes. exit [
exitstatus
]
              Terminate the shell process."
138,169,dash,"exit [
exitstatus
]
              Terminate the shell process. If
exitstatus
is given it is
              used as the exit status of the shell; otherwise the exit
              status of the preceding command is used. export
name ..."
138,170,dash,"export
name ... export
-p
The specified names are exported so that they will appear
              in the environment of subsequent commands. The only way to
              un-export a variable is to unset it."
138,171,dash,"The only way to
              un-export a variable is to unset it. The shell allows the
              value of a variable to be set at the same time it is
              exported by writing
export name=value
With no arguments the export command lists the names of all
              exported variables. With the
-p
option specified the
              output will be formatted suitably for non-interactive use."
138,172,dash,"With the
-p
option specified the
              output will be formatted suitably for non-interactive use. fc [
-e
editor
] [
first
[
last
]]

       fc
-l
[
-nr
] [
first
[
last
]]

       fc
-s
[
old=new
] [
first
]
              The
fc
builtin lists, or edits and re-executes, commands
              previously entered to an interactive shell. -e
editor
                     Use the editor named by editor to edit the commands."
138,173,dash,"-e
editor
                     Use the editor named by editor to edit the commands. The editor string is a command name, subject to
                     search via the PATH variable. The value in the
                     FCEDIT variable is used as a default when
-e
is not
                     specified."
138,174,dash,"The value in the
                     FCEDIT variable is used as a default when
-e
is not
                     specified. If FCEDIT is null or unset, the value of
                     the EDITOR variable is used. If EDITOR is null or
                     unset,
ed
(1) is used as the editor."
138,175,dash,"If EDITOR is null or
                     unset,
ed
(1) is used as the editor. -l
(ell)
                     List the commands rather than invoking an editor on
                     them. The commands are written in the sequence
                     indicated by the first and last operands, as
                     affected by
-r
, with each command preceded by the
                     command number."
138,176,dash,"The commands are written in the sequence
                     indicated by the first and last operands, as
                     affected by
-r
, with each command preceded by the
                     command number. -n
Suppress command numbers when listing with -l. -r
Reverse the order of the commands listed (with
-l
)
                     or edited (with neither
-l
nor
-s
)."
138,177,dash,"-r
Reverse the order of the commands listed (with
-l
)
                     or edited (with neither
-l
nor
-s
). -s
Re-execute the command without invoking an editor. first

              last   Select the commands to list or edit."
138,178,dash,"first

              last   Select the commands to list or edit. The number of
                     previous commands that can be accessed are
                     determined by the value of the HISTSIZE variable. The value of first or last or both are one of the
                     following:

                     [+]number
                            A positive number representing a command
                            number; command numbers can be displayed with
                            the
-l
option."
138,179,dash,"The value of first or last or both are one of the
                     following:

                     [+]number
                            A positive number representing a command
                            number; command numbers can be displayed with
                            the
-l
option. -number
A negative decimal number representing the
                            command that was executed number of commands
                            previously. For example, -1 is the
                            immediately previous command."
138,180,dash,"For example, -1 is the
                            immediately previous command. string
                     A string indicating the most recently entered
                     command that begins with that string. If the
                     old=new operand is not also specified with
-s
, the
                     string form of the first operand cannot contain an
                     embedded equal sign."
138,181,dash,"If the
                     old=new operand is not also specified with
-s
, the
                     string form of the first operand cannot contain an
                     embedded equal sign. The following environment variables affect the execution of
              fc:

              FCEDIT    Name of the editor to use. HISTSIZE  The number of previous commands that are
                        accessible."
138,182,dash,"HISTSIZE  The number of previous commands that are
                        accessible. fg [
job
]
              Move the specified job or the current job to the
              foreground. getopts
optstring var
[
arg ..."
138,183,dash,"getopts
optstring var
[
arg ... ]
              The POSIX
getopts
command, not to be confused with the
Bell
Labs
-derived
getopt
(1). The first argument should be a series of letters, each of
              which may be optionally followed by a colon to indicate
              that the option requires an argument."
138,184,dash,"The first argument should be a series of letters, each of
              which may be optionally followed by a colon to indicate
              that the option requires an argument. The variable
              specified is set to the parsed option. The
getopts
command deprecates the older
getopt
(1) utility
              due to its handling of arguments containing whitespace."
138,185,dash,"The
getopts
command deprecates the older
getopt
(1) utility
              due to its handling of arguments containing whitespace. The
getopts
builtin may be used to obtain options and their
              arguments from a list of parameters. When invoked,
getopts
places the value of the next option from the option string
              in the list in the shell variable specified by
var
and its
              index in the shell variable OPTIND."
138,186,dash,"When invoked,
getopts
places the value of the next option from the option string
              in the list in the shell variable specified by
var
and its
              index in the shell variable OPTIND. When the shell is
              invoked, OPTIND is initialized to 1. For each option that
              requires an argument, the
getopts
builtin will place it in
              the shell variable OPTARG."
138,187,dash,"For each option that
              requires an argument, the
getopts
builtin will place it in
              the shell variable OPTARG. If an option is not allowed for
              in the
optstring
, then OPTARG will be unset. By default, the variables
$1
,
..."
138,188,dash,"By default, the variables
$1
,
... ,
$n
are inspected; if
arg
s are specified, they'll be parsed instead. optstring
is a string of recognized option letters (see
getopt
(3))."
138,189,dash,"optstring
is a string of recognized option letters (see
getopt
(3)). If a letter is followed by a colon, the option
              is expected to have an argument which may or may not be
              separated from it by white space. If an option character
              is not found where expected,
getopts
will set the variable
var
to a â?â;
getopts
will then unset OPTARG and write
              output to standard error."
138,190,dash,"If an option character
              is not found where expected,
getopts
will set the variable
var
to a â?â;
getopts
will then unset OPTARG and write
              output to standard error. By specifying a colon as the
              first character of
optstring
all errors will be ignored. After the last option
getopts
will return a non-zero value
              and set
var
to â?â."
138,191,dash,"After the last option
getopts
will return a non-zero value
              and set
var
to â?â. The following code fragment shows how one might process the
              arguments for a command that can take the options [a] and
              [b], and the option [c], which requires an argument. while getopts abc: f
                    do
                            case $f in
                            a | b)  flag=$f;;
                            c)      carg=$OPTARG;;
                            \?)     echo $USAGE; exit 1;;
                            esac
                    done
                    shift $((OPTIND - 1))

              This code will accept any of the following as equivalent:

                    cmd -acarg file file
                    cmd -a -c arg file file
                    cmd -carg -a file file
                    cmd -a -carg -- file file

       hash [
command ..."
138,192,dash,"while getopts abc: f
                    do
                            case $f in
                            a | b)  flag=$f;;
                            c)      carg=$OPTARG;;
                            \?)     echo $USAGE; exit 1;;
                            esac
                    done
                    shift $((OPTIND - 1))

              This code will accept any of the following as equivalent:

                    cmd -acarg file file
                    cmd -a -c arg file file
                    cmd -carg -a file file
                    cmd -a -carg -- file file

       hash [
command ... ]

       hash
-r
The shell maintains a hash table which remembers the
              locations of commands. With no arguments whatsoever, the
hash
command prints out the contents of this table."
138,193,dash,"With no arguments whatsoever, the
hash
command prints out the contents of this table. Entries which have not been looked at since the last
cd
command are marked with an asterisk; it is possible for
              these entries to be invalid. With arguments, the
hash
command removes the specified
              commands from the hash table (unless they are functions)
              and then locates them."
138,194,dash,"With arguments, the
hash
command removes the specified
              commands from the hash table (unless they are functions)
              and then locates them. The
-r
option causes the hash
              command to delete all the entries in the hash table except
              for functions. jobs [
-lp
] [
job ..."
138,195,dash,"jobs [
-lp
] [
job ... ]
              Display the status of all, or just the specified,
job
s:
                   By default  display the job number, currency (
+-
)
                               status, if any, the job state, and its
                               shell command. -l
also output the PID of the group leader,
                               and just the PID and shell commands of
                               other members of the job."
138,196,dash,"-l
also output the PID of the group leader,
                               and just the PID and shell commands of
                               other members of the job. -p
Display only leader PIDs, one per line. kill [
-s
sigspec
|
-
signum
|
-
sigspec
] [
pid
|
job ..."
138,197,dash,"kill [
-s
sigspec
|
-
signum
|
-
sigspec
] [
pid
|
job ... ]
              Equivalent to
kill
(1), but a
job
spec may also be
              specified. Signals can be either case-insensitive names
              without SIG prefixes or decimal numbers; the default is
              TERM."
138,198,dash,"Signals can be either case-insensitive names
              without SIG prefixes or decimal numbers; the default is
              TERM. kill
-l
[
signum
|
exitstatus
]
              List available signal names without the SIG prefix
              (
sigspec
s). If
signum
specified, display just the
sigspec
for that signal."
138,199,dash,"If
signum
specified, display just the
sigspec
for that signal. If
exitstatus
specified (>
128
), display
              just the
sigspec
that caused it. pwd [
-LP
]
              builtin command remembers what the current directory is
              rather than recomputing it each time."
138,200,dash,"pwd [
-LP
]
              builtin command remembers what the current directory is
              rather than recomputing it each time. This makes it
              faster. However, if the current directory is renamed, the
              builtin version of
pwd
will continue to print the old name
              for the directory."
138,201,dash,"However, if the current directory is renamed, the
              builtin version of
pwd
will continue to print the old name
              for the directory. The
-P
option causes the physical value
              of the current working directory to be shown, that is, all
              symbolic links are resolved to their respective values. The
-L
option turns off the effect of any preceding
-P
options."
138,202,dash,"The
-L
option turns off the effect of any preceding
-P
options. read [
-p
prompt
] [
-r
]
variable
[
... ]
              The prompt is printed if the
-p
option is specified and the
              standard input is a terminal."
138,203,dash,"]
              The prompt is printed if the
-p
option is specified and the
              standard input is a terminal. Then a line is read from the
              standard input. The trailing newline is deleted from the
              line and the line is split as described in the section on
              word splitting above, and the pieces are assigned to the
              variables in order."
138,204,dash,"The trailing newline is deleted from the
              line and the line is split as described in the section on
              word splitting above, and the pieces are assigned to the
              variables in order. At least one variable must be
              specified. If there are more pieces than variables, the
              remaining pieces (along with the characters in IFS that
              separated them) are assigned to the last variable."
138,205,dash,"If there are more pieces than variables, the
              remaining pieces (along with the characters in IFS that
              separated them) are assigned to the last variable. If
              there are more variables than pieces, the remaining
              variables are assigned the null string. The
read
builtin
              will indicate success unless EOF is encountered on input,
              in which case failure is returned."
138,206,dash,"The
read
builtin
              will indicate success unless EOF is encountered on input,
              in which case failure is returned. By default, unless the
-r
option is specified, the
              backslash â\â acts as an escape character, causing the
              following character to be treated literally. If a
              backslash is followed by a newline, the backslash and the
              newline will be deleted."
138,207,dash,"If a
              backslash is followed by a newline, the backslash and the
              newline will be deleted. readonly
name ... readonly
-p
The specified names are marked as read only, so that they
              cannot be subsequently modified or unset."
138,208,dash,"readonly
-p
The specified names are marked as read only, so that they
              cannot be subsequently modified or unset. The shell allows
              the value of a variable to be set at the same time it is
              marked read only by writing
readonly name=value
With no arguments the readonly command lists the names of
              all read only variables. With the
-p
option specified the
              output will be formatted suitably for non-interactive use."
138,209,dash,"With the
-p
option specified the
              output will be formatted suitably for non-interactive use. printf
format
[
value
]... printf
formats and prints its arguments according to
format
, a character string which contains three types of
              objects: plain characters, which are simply copied to
              standard output, character escape sequences which are
              converted and copied to the standard output, and format
              specifications, each of which causes printing of the next
              successive
value
."
138,210,dash,"printf
formats and prints its arguments according to
format
, a character string which contains three types of
              objects: plain characters, which are simply copied to
              standard output, character escape sequences which are
              converted and copied to the standard output, and format
              specifications, each of which causes printing of the next
              successive
value
. Each
value
is treated as a string if the corresponding
              format specification is either
b
,
c
, or
s
; otherwise it is
              evaluated as a C constant, with the following additions:
â¢
A leading plus or minus sign is allowed. â¢
If the leading character is a single or double
                        quote, the value of the next byte."
138,211,dash,"â¢
If the leading character is a single or double
                        quote, the value of the next byte. The format string is reused as often as necessary until all
value
s are consumed. Any extra format specifications are
              evaluated with zero or the null string."
138,212,dash,"Any extra format specifications are
              evaluated with zero or the null string. Character escape sequences are in backslash notation as
              defined in ANSI X3.159-1989 (âANSI C89â). The characters
              and their meanings are as follows:
\a
Write a <bell> character."
138,213,dash,"The characters
              and their meanings are as follows:
\a
Write a <bell> character. \b
Write a <backspace> character. \f
Write a <form-feed> character."
138,214,dash,"\f
Write a <form-feed> character. \n
Write a <new-line> character. \r
Write a <carriage return> character."
138,215,dash,"\r
Write a <carriage return> character. \t
Write a <tab> character. \v
Write a <vertical tab> character."
138,216,dash,"\v
Write a <vertical tab> character. \\
Write a backslash character. \
num
Write an 8-bit character whose ASCII value is
                            the 1-, 2-, or 3-digit octal number
num
."
138,217,dash,"\
num
Write an 8-bit character whose ASCII value is
                            the 1-, 2-, or 3-digit octal number
num
. Each format specification is introduced by the percent
              character (``%''). The remainder of the format
              specification includes, in the following order:

              Zero or more of the following flags:
#
A `#' character specifying that the value
                              should be printed in an ``alternative
                              form''."
138,218,dash,"The remainder of the format
              specification includes, in the following order:

              Zero or more of the following flags:
#
A `#' character specifying that the value
                              should be printed in an ``alternative
                              form''. For
b
,
c
,
d
, and
s
formats, this
                              option has no effect. For the
o
format the
                              precision of the number is increased to
                              force the first character of the output
                              string to a zero."
138,219,dash,"For the
o
format the
                              precision of the number is increased to
                              force the first character of the output
                              string to a zero. For the
x
(
X
) format, a
                              non-zero result has the string
0x
(
0X
)
                              prepended to it. For
e
,
E
,
f
,
g
, and
G
formats, the result will always contain a
                              decimal point, even if no digits follow the
                              point (normally, a decimal point only
                              appears in the results of those formats if
                              a digit follows the decimal point)."
138,220,dash,"For
e
,
E
,
f
,
g
, and
G
formats, the result will always contain a
                              decimal point, even if no digits follow the
                              point (normally, a decimal point only
                              appears in the results of those formats if
                              a digit follows the decimal point). For
g
and
G
formats, trailing zeros are not
                              removed from the result as they would
                              otherwise be. -
A minus sign `-' which specifies
left
adjustment
of the output in the indicated
                              field;
+
A `+' character specifying that there
                              should always be a sign placed before the
                              number when using signed formats."
138,221,dash,"-
A minus sign `-' which specifies
left
adjustment
of the output in the indicated
                              field;
+
A `+' character specifying that there
                              should always be a sign placed before the
                              number when using signed formats. â â     A space specifying that a blank should be
                              left before a positive number for a signed
                              format. A `+' overrides a space if both
                              are used;
0
A zero `0' character indicating that zero-
                              padding should be used rather than blank-
                              padding."
138,222,dash,"A `+' overrides a space if both
                              are used;
0
A zero `0' character indicating that zero-
                              padding should be used rather than blank-
                              padding. A `-' overrides a `0' if both are
                              used;

              Field Width:
                      An optional digit string specifying a
field width
;
                      if the output string has fewer characters than the
                      field width it will be blank-padded on the left (or
                      right, if the left-adjustment indicator has been
                      given) to make up the field width (note that a
                      leading zero is a flag, but an embedded zero is
                      part of a field width);

              Precision:
                      An optional period, â
. â, followed by an optional
                      digit string giving a
precision
which specifies the
                      number of digits to appear after the decimal point,
                      for
e
and
f
formats, or the maximum number of bytes
                      to be printed from a string (
b
and
s
formats); if
                      the digit string is missing, the precision is
                      treated as zero;

              Format:
                      A character which indicates the type of format to
                      use (one of
diouxXfwEgGbcs
)."
138,223,dash,"â, followed by an optional
                      digit string giving a
precision
which specifies the
                      number of digits to appear after the decimal point,
                      for
e
and
f
formats, or the maximum number of bytes
                      to be printed from a string (
b
and
s
formats); if
                      the digit string is missing, the precision is
                      treated as zero;

              Format:
                      A character which indicates the type of format to
                      use (one of
diouxXfwEgGbcs
). A field width or precision may be â
*
â instead of a digit
              string. In this case an
argument
supplies the field width
              or precision."
138,224,dash,"In this case an
argument
supplies the field width
              or precision. The format characters and their meanings are:
diouXx
The
argument
is printed as a signed decimal (d
                          or i), unsigned octal, unsigned decimal, or
                          unsigned hexadecimal (X or x), respectively. f
The
argument
is printed in the style [-]ddd
."
138,225,dash,"f
The
argument
is printed in the style [-]ddd
. ddd
                          where the number of d's after the decimal point
                          is equal to the precision specification for the
                          argument. If the precision is missing, 6
                          digits are given; if the precision is
                          explicitly 0, no digits and no decimal point
                          are printed."
138,226,dash,"If the precision is missing, 6
                          digits are given; if the precision is
                          explicitly 0, no digits and no decimal point
                          are printed. eE
The
argument
is printed in the style
                          [-]d
. ddd
e
Â±dd where there is one digit before
                          the decimal point and the number after is equal
                          to the precision specification for the
                          argument; when the precision is missing, 6
                          digits are produced."
138,227,dash,"ddd
e
Â±dd where there is one digit before
                          the decimal point and the number after is equal
                          to the precision specification for the
                          argument; when the precision is missing, 6
                          digits are produced. An upper-case E is used
                          for an `E' format. gG
The
argument
is printed in style
f
or in style
e
(
E
) whichever gives full precision in minimum
                          space."
138,228,dash,"gG
The
argument
is printed in style
f
or in style
e
(
E
) whichever gives full precision in minimum
                          space. b
Characters from the string
argument
are printed
                          with backslash-escape sequences expanded. The following additional backslash-escape
                          sequences are supported:
\c
Causes
dash
to ignore any remaining
                                  characters in the string operand
                                  containing it, any remaining string
                                  operands, and any additional characters
                                  in the format operand."
138,229,dash,"The following additional backslash-escape
                          sequences are supported:
\c
Causes
dash
to ignore any remaining
                                  characters in the string operand
                                  containing it, any remaining string
                                  operands, and any additional characters
                                  in the format operand. \0
num
Write an 8-bit character whose ASCII
                                  value is the 1-, 2-, or 3-digit octal
                                  number
num
. c
The first character of
argument
is printed."
138,230,dash,"c
The first character of
argument
is printed. s
Characters from the string
argument
are printed
                          until the end is reached or until the number of
                          bytes indicated by the precision specification
                          is reached; if the precision is omitted, all
                          characters in the string are printed. %
Print a `%'; no argument is used."
138,231,dash,"%
Print a `%'; no argument is used. In no case does a non-existent or small field width cause
              truncation of a field; padding takes place only if the
              specified field width exceeds the actual width. set [{
-options
|
+options
|
-- }
]
arg ..."
138,232,dash,"set [{
-options
|
+options
|
-- }
]
arg ... The
set
command performs three different functions. With no arguments, it lists the values of all shell
              variables."
138,233,dash,"With no arguments, it lists the values of all shell
              variables. If options are given, it sets the specified option flags,
              or clears them as described in the section called âArgument
              List Processingâ. As a special case, if the option is -o
              or +o and no argument is supplied, the shell prints the
              settings of all its options."
138,234,dash,"As a special case, if the option is -o
              or +o and no argument is supplied, the shell prints the
              settings of all its options. If the option is -o, the
              settings are printed in a human-readable format; if the
              option is +o, the settings are printed in a format suitable
              for reinput to the shell to affect the same option
              settings. In addition to the option names listed in the âArgument
              List Processingâ section, the following options may be
              specified as arguments to -o or +o:
pipefail
Derive the exit status of a pipeline from the
                        exit statuses of all of the commands in the
                        pipeline, not just the last command, as described
                        in the âPipelinesâ section."
138,235,dash,"In addition to the option names listed in the âArgument
              List Processingâ section, the following options may be
              specified as arguments to -o or +o:
pipefail
Derive the exit status of a pipeline from the
                        exit statuses of all of the commands in the
                        pipeline, not just the last command, as described
                        in the âPipelinesâ section. The third use of the set command is to set the values of
              the shell's positional parameters to the specified args. To change the positional parameters without changing any
              options, use â--â as the first argument to set."
138,236,dash,"To change the positional parameters without changing any
              options, use â--â as the first argument to set. If no args
              are present, the set command will clear all the positional
              parameters (equivalent to executing âshift $#â.)

       shift [
n
]
              Shift the positional parameters n times. A
shift
sets the
              value of
$1
to the value of
$2
, the value of
$2
to the
              value of
$3
, and so on, decreasing the value of
$#
by one."
138,237,dash,"A
shift
sets the
              value of
$1
to the value of
$2
, the value of
$2
to the
              value of
$3
, and so on, decreasing the value of
$#
by one. If n is greater than the number of positional parameters,
shift
will issue an error message, and exit with return
              status 2. test
expression
[
expression
]
The
test
utility evaluates the expression and, if it
              evaluates to true, returns a zero (true) exit status;
              otherwise it returns 1 (false)."
138,238,dash,"test
expression
[
expression
]
The
test
utility evaluates the expression and, if it
              evaluates to true, returns a zero (true) exit status;
              otherwise it returns 1 (false). If there is no expression,
              test also returns 1 (false). All operators and flags are separate arguments to the
test
utility."
138,239,dash,"All operators and flags are separate arguments to the
test
utility. The following primaries are used to construct expression:
-b
file
True if
file
exists and is a block special
                            file. -c
file
True if
file
exists and is a character
                            special file."
138,240,dash,"-c
file
True if
file
exists and is a character
                            special file. -d
file
True if
file
exists and is a directory. -e
file
True if
file
exists (regardless of type)."
138,241,dash,"-e
file
True if
file
exists (regardless of type). -f
file
True if
file
exists and is a regular file. -g
file
True if
file
exists and its set group ID flag
                            is set."
138,242,dash,"-g
file
True if
file
exists and its set group ID flag
                            is set. -h
file
True if
file
exists and is a symbolic link. -k
file
True if
file
exists and its sticky bit is
                            set."
138,243,dash,"-k
file
True if
file
exists and its sticky bit is
                            set. -n
string
True if the length of
string
is nonzero. -p
file
True if
file
is a named pipe (FIFO)."
138,244,dash,"-p
file
True if
file
is a named pipe (FIFO). -r
file
True if
file
exists and is readable. -s
file
True if
file
exists and has a size greater
                            than zero."
138,245,dash,"-s
file
True if
file
exists and has a size greater
                            than zero. -t
file_descriptor
True if the file whose file descriptor number
                            is
file_descriptor
is open and is associated
                            with a terminal. -u
file
True if
file
exists and its set user ID flag
                            is set."
138,246,dash,"-u
file
True if
file
exists and its set user ID flag
                            is set. -w
file
True if
file
exists and is writable. True
                            indicates only that the write flag is on."
138,247,dash,"True
                            indicates only that the write flag is on. The file is not writable on a read-only file
                            system even if this test indicates true. -x
file
True if
file
exists and is executable."
138,248,dash,"-x
file
True if
file
exists and is executable. True
                            indicates only that the execute flag is on. If
file
is a directory, true indicates that
file
can be searched."
138,249,dash,"If
file
is a directory, true indicates that
file
can be searched. -z
string
True if the length of
string
is zero. -L
file
True if
file
exists and is a symbolic link."
138,250,dash,"-L
file
True if
file
exists and is a symbolic link. This operator is retained for compatibility
                            with previous versions of this program. Do
                            not rely on its existence; use
-h
instead."
138,251,dash,"Do
                            not rely on its existence; use
-h
instead. -O
file
True if
file
exists and its owner matches the
                            effective user id of this process. -G
file
True if
file
exists and its group matches the
                            effective group id of this process."
138,252,dash,"-G
file
True if
file
exists and its group matches the
                            effective group id of this process. -S
file
True if
file
exists and is a socket. file1
-nt
file2
True if
file1
and
file2
exist and
file1
is
                            newer than
file2
, or if
file1
exists but
file2
doesn't."
138,253,dash,"file1
-nt
file2
True if
file1
and
file2
exist and
file1
is
                            newer than
file2
, or if
file1
exists but
file2
doesn't. file1
-ot
file2
True if
file1
and
file2
exist and
file1
is
                            older than
file2
, or if
file2
exists but
file1
doesn't. file1
-ef
file2
True if
file1
and
file2
exist and refer to
                            the same file."
138,254,dash,"file1
-ef
file2
True if
file1
and
file2
exist and refer to
                            the same file. string
True if
string
is not the null string. s1
=
s2
True if the strings
s1
and
s2
are identical."
138,255,dash,"s1
=
s2
True if the strings
s1
and
s2
are identical. s1
!=
s2
True if the strings
s1
and
s2
are not
                            identical. s1
<
s2
True if string
s1
comes before
s2
based on
                            the ASCII value of their characters."
138,256,dash,"s1
<
s2
True if string
s1
comes before
s2
based on
                            the ASCII value of their characters. s1
>
s2
True if string
s1
comes after
s2
based on the
                            ASCII value of their characters. n1
-eq
n2
True if the integers
n1
and
n2
are
                            algebraically equal."
138,257,dash,"n1
-eq
n2
True if the integers
n1
and
n2
are
                            algebraically equal. n1
-ne
n2
True if the integers
n1
and
n2
are not
                            algebraically equal. n1
-gt
n2
True if the integer
n1
is algebraically
                            greater than the integer
n2
."
138,258,dash,"n1
-gt
n2
True if the integer
n1
is algebraically
                            greater than the integer
n2
. n1
-ge
n2
True if the integer
n1
is algebraically
                            greater than or equal to the integer
n2
. n1
-lt
n2
True if the integer
n1
is algebraically less
                            than the integer
n2
."
138,259,dash,"n1
-lt
n2
True if the integer
n1
is algebraically less
                            than the integer
n2
. n1
-le
n2
True if the integer
n1
is algebraically less
                            than or equal to the integer
n2
. These primaries can be combined with the following
              operators:
!"
138,260,dash,"These primaries can be combined with the following
              operators:
! expression
True if
expression
is false. expression1
-a
expression2
True if both
expression1
and
expression2
are
                            true."
138,261,dash,"expression1
-a
expression2
True if both
expression1
and
expression2
are
                            true. expression1
-o
expression2
True if either
expression1
or
expression2
are
                            true. (
expression
)
True if expression is true."
138,262,dash,"(
expression
)
True if expression is true. The
-a
operator has higher precedence than the
-o
operator. times  Print the accumulated user and system times for the shell
              and for processes run from the shell."
138,263,dash,"times  Print the accumulated user and system times for the shell
              and for processes run from the shell. The return status is
              0. trap [
action signal ..."
138,264,dash,"trap [
action signal ... ]
              Cause the shell to parse and execute action when any of the
              specified signals are received. The signals are specified
              by signal number or as the name of the signal."
138,265,dash,"The signals are specified
              by signal number or as the name of the signal. If
signal
is
0
or
EXIT
, the action is executed when the shell exits
              normally (that is not via an unhandled signal like SIGINT). action
may be empty (
''
), which causes the specified
              signals to be ignored."
138,266,dash,"action
may be empty (
''
), which causes the specified
              signals to be ignored. With
action
omitted or set to `-'
              the specified signals are set to their default action. When the shell forks off a subshell, it resets trapped (but
              not ignored) signals to the default action."
138,267,dash,"When the shell forks off a subshell, it resets trapped (but
              not ignored) signals to the default action. The
trap
command has no effect on signals that were ignored on entry
              to the shell. trap
without any arguments cause it to write
              a list of signals and their associated action to the
              standard output in a format that is suitable as an input to
              the shell that achieves the same trapping results."
138,268,dash,"trap
without any arguments cause it to write
              a list of signals and their associated action to the
              standard output in a format that is suitable as an input to
              the shell that achieves the same trapping results. Examples:
trap
List trapped signals and their corresponding action
trap '' INT QUIT tstp 30
Ignore signals INT QUIT TSTP USR1
trap date INT
Print date upon receiving signal INT

       type [
name ... ]
              Interpret each name as a command and print the resolution
              of the command search."
138,269,dash,"]
              Interpret each name as a command and print the resolution
              of the command search. Possible resolutions are: shell
              keyword, alias, shell builtin, command, tracked alias and
              not found. For aliases the alias expansion is printed; for
              commands and tracked aliases the complete pathname of the
              command is printed."
138,270,dash,"For aliases the alias expansion is printed; for
              commands and tracked aliases the complete pathname of the
              command is printed. ulimit [
-H
|
-S
] [
-a
|
-tfdscmlpnvwr
[
value
]]
              Inquire about or set the hard or soft limits on processes
              or set new limits. The choice between hard limit (which no
              process is allowed to violate, and which may not be raised
              once it has been lowered) and soft limit (which causes
              processes to be signaled but not necessarily killed, and
              which may be raised) is made with these flags:
-H
set or inquire about hard limits
-S
set or inquire about soft limits."
138,271,dash,"The choice between hard limit (which no
              process is allowed to violate, and which may not be raised
              once it has been lowered) and soft limit (which causes
              processes to be signaled but not necessarily killed, and
              which may be raised) is made with these flags:
-H
set or inquire about hard limits
-S
set or inquire about soft limits. If neither
-H
nor
-S
is specified, the soft limit is
                          displayed or both limits are set. If both are
                          specified, the last one wins."
138,272,dash,"If both are
                          specified, the last one wins. The limit to be interrogated or set, then, is chosen by
              specifying any one of these flags:
-a
show all the current limits
-t
show or set the limit on CPU time (in seconds)
-f
show or set the limit on the largest file that
                          can be created (in 512-byte blocks)
-d
show or set the limit on the data segment size
                          of a process (in kilobytes)
-s
show or set the limit on the stack size of a
                          process (in kilobytes)
-c
show or set the limit on the largest core dump
                          size that can be produced (in 512-byte blocks)
-m
show or set the limit on the total physical
                          memory that can be in use by a process (in
                          kilobytes)
-l
show or set the limit on how much memory a
                          process can lock with
mlock
(2) (in kilobytes)
-p
show or set the limit on the number of
                          processes this user can have at one time
-n
show or set the limit on the number files a
                          process can have open at once
-v
show or set the limit on the total virtual
                          memory that can be in use by a process (in
                          kilobytes)
-w
show or set the limit on the total number of
                          locks held by a process
-r
show or set the limit on the real-time
                          scheduling priority of a process

              If none of these is specified, it is the limit on file size
              that is shown or set. If
value
is specified, the limit is
              set to that number; otherwise the current limit is
              displayed."
138,273,dash,"If
value
is specified, the limit is
              set to that number; otherwise the current limit is
              displayed. The special
value
unlimited
represents the lack
              of any limit. Limits of an arbitrary process can be displayed or set
              using the
sysctl
(8) utility."
138,274,dash,"Limits of an arbitrary process can be displayed or set
              using the
sysctl
(8) utility. umask [
mask
]
              Set the value of umask (see
umask
(2)) to the specified
              octal value. If the argument is omitted, the umask value
              is printed."
138,275,dash,"If the argument is omitted, the umask value
              is printed. unalias [
-a
] [
name
]
              If
name
is specified, the shell removes that alias. If
-a
is specified, all aliases are removed."
138,276,dash,"If
-a
is specified, all aliases are removed. unset [
-fv
]
name ... The specified variables and functions are unset and
              unexported."
138,277,dash,"The specified variables and functions are unset and
              unexported. If
-f
or
-v
is specified, the corresponding
              function or variable is unset, respectively. If a given
              name corresponds to both a variable and a function, and no
              options are given, only the variable is unset."
138,278,dash,"If a given
              name corresponds to both a variable and a function, and no
              options are given, only the variable is unset. wait [
job
]
              Wait for the specified job to complete and return the exit
              status of the last process in the job. If the argument is
              omitted, wait for all jobs to complete and return an exit
              status of zero."
138,279,dash,"If the argument is
              omitted, wait for all jobs to complete and return an exit
              status of zero. Command Line Editing
When
dash
is being used interactively from a terminal, the current
       command and the command history (see
fc
in âBuiltinsâ) can be
       edited using vi-mode command-line editing. This mode uses
       commands, described below, similar to a subset of those described
       in the vi man page."
138,280,dash,"This mode uses
       commands, described below, similar to a subset of those described
       in the vi man page. The command âset -o viâ enables vi-mode
       editing and places sh into vi insert mode. With vi-mode enabled,
       sh can be switched between insert mode and command mode."
138,281,dash,"With vi-mode enabled,
       sh can be switched between insert mode and command mode. It is
       similar to vi: typing â¨ESCâ© enters vi command mode. Hitting
       â¨returnâ© while in command mode will pass the line to the shell."
139,0,curl,"curl
is a tool for transferring data from or to a server using
       URLs. It supports these protocols: DICT, FILE, FTP, FTPS, GOPHER,
       GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S,
       RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET,
       TFTP, WS and WSS. curl is powered by libcurl for all transfer-related features."
139,1,curl,"It supports these protocols: DICT, FILE, FTP, FTPS, GOPHER,
       GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S,
       RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET,
       TFTP, WS and WSS. curl is powered by libcurl for all transfer-related features. See
libcurl
(3) for details."
140,0,dbprobe,"The
dbprobe
utility is used by
pmdadbping(1)
to measure response
       time from a database.  A given query is executed on the database
       at the requested interval (
delay
, which defaults to 60 seconds).
       This response time measure can be exported via the Performance Co-
       Pilot framework for live and historical monitoring using
pmdadbping
(1)."
141,0,dbpmda,"dbpmda
is an interactive interface to the interactions between a
       Performance Metric Domain Agent (
PMDA(3)
) and the Performance
       Metric Collector Daemon (
pmcd(1)
). This allows PMDAs to be
       attached, initialized and exercised to test for correctness. dbpmda
interactively prompts the user for commands, many of which
       emulate the Protocol Data Units (PDUs) that may be sent by a
pmcd(1)
process."
141,1,dbpmda,"dbpmda
interactively prompts the user for commands, many of which
       emulate the Protocol Data Units (PDUs) that may be sent by a
pmcd(1)
process. After running
dbpmda
, enter the command
help
to
       get a list of the available commands. The example section below
       illustrates a session using
dbpmda
to test a PMDA."
141,2,dbpmda,"The example section below
       illustrates a session using
dbpmda
to test a PMDA. To simplify repetitive testing of a PMDA, the file
.dbpmdarc
in
       the current working directory can contain a list of commands that
       will be executed by
dbpmda
on startup, before the user is prompted
       to enter further commands interactively. While processing the
.dbpmdarc
file, interactive mode and command echoing are enabled
       and then reset at the end of the
.dbpmdarc
file (see the
-i
and
-e
command line options below)."
141,3,dbpmda,"While processing the
.dbpmdarc
file, interactive mode and command echoing are enabled
       and then reset at the end of the
.dbpmdarc
file (see the
-i
and
-e
command line options below). The
-f
command line option prevents startup processing of a
.dbpmdarc
file (if it exists). If the system supports
readline(3)
then this will be used to read
       commands when input is from a tty device, so history and command
       line editing are available."
141,4,dbpmda,"The
-f
command line option prevents startup processing of a
.dbpmdarc
file (if it exists). If the system supports
readline(3)
then this will be used to read
       commands when input is from a tty device, so history and command
       line editing are available. As there are no timeout constraints on a PMDA while using
dbpmda
(as compared to
pmcd(1)
), another debugger like
gdb(1)
can be used
       on the PMDA process once it has been attached to
dbpmda
."
142,0,dd,"Copy a file, converting and formatting according to the operands. bs=BYTES
              read and write up to BYTES bytes at a time (default: 512);
              overrides ibs and obs

       cbs=BYTES
              convert BYTES bytes at a time

       conv=CONVS
              convert the file as per the comma separated symbol list

       count=N
              copy only N input blocks

       ibs=BYTES
              read up to BYTES bytes at a time (default: 512)

       if=FILE
              read from FILE instead of stdin

       iflag=FLAGS
              read as per the comma separated symbol list

       obs=BYTES
              write BYTES bytes at a time (default: 512)

       of=FILE
              write to FILE instead of stdout

       oflag=FLAGS
              write as per the comma separated symbol list

       seek=N (or oseek=N) skip N obs-sized output blocks

       skip=N (or iseek=N) skip N ibs-sized input blocks

       status=LEVEL
              The LEVEL of information to print to stderr; 'none'
              suppresses everything but error messages, 'noxfer'
              suppresses the final transfer statistics, 'progress' shows
              periodic transfer statistics

       N and BYTES may be followed by the following multiplicative
       suffixes: c=1, w=2, b=512, kB=1000, K=1024, MB=1000*1000,
       M=1024*1024, xM=M, GB=1000*1000*1000, G=1024*1024*1024, and so on
       for T, P, E, Z, Y, R, Q. Binary prefixes can be used, too: KiB=K,
       MiB=M, and so on."
142,1,dd,"Binary prefixes can be used, too: KiB=K,
       MiB=M, and so on. If N ends in 'B', it counts bytes not blocks. Each CONV symbol may be:

       ascii  from EBCDIC to ASCII

       ebcdic from ASCII to EBCDIC

       ibm    from ASCII to alternate EBCDIC

       block  pad newline-terminated records with spaces to cbs-size

       unblock
              replace trailing spaces in cbs-size records with newline

       lcase  change upper case to lower case

       ucase  change lower case to upper case

       sparse try to seek rather than write all-NUL output blocks

       swab   swap every pair of input bytes

       sync   pad every input block with NULs to ibs-size; when used with
              block or unblock, pad with spaces rather than NULs

       excl   fail if the output file already exists

       nocreat
              do not create the output file

       notrunc
              do not truncate the output file

       noerror
              continue after read errors

       fdatasync
              physically write output file data before finishing

       fsync  likewise, but also write metadata

       Each FLAG symbol may be:

       append append mode (makes sense only for output; conv=notrunc
              suggested)

       direct use direct I/O for data

       directory
              fail unless a directory

       dsync  use synchronized I/O for data

       sync   likewise, but also for metadata

       fullblock
              accumulate full blocks of input (iflag only)

       nonblock
              use non-blocking I/O

       noatime
              do not update access time

       nocache
              Request to drop cache."
142,2,dd,"Each CONV symbol may be:

       ascii  from EBCDIC to ASCII

       ebcdic from ASCII to EBCDIC

       ibm    from ASCII to alternate EBCDIC

       block  pad newline-terminated records with spaces to cbs-size

       unblock
              replace trailing spaces in cbs-size records with newline

       lcase  change upper case to lower case

       ucase  change lower case to upper case

       sparse try to seek rather than write all-NUL output blocks

       swab   swap every pair of input bytes

       sync   pad every input block with NULs to ibs-size; when used with
              block or unblock, pad with spaces rather than NULs

       excl   fail if the output file already exists

       nocreat
              do not create the output file

       notrunc
              do not truncate the output file

       noerror
              continue after read errors

       fdatasync
              physically write output file data before finishing

       fsync  likewise, but also write metadata

       Each FLAG symbol may be:

       append append mode (makes sense only for output; conv=notrunc
              suggested)

       direct use direct I/O for data

       directory
              fail unless a directory

       dsync  use synchronized I/O for data

       sync   likewise, but also for metadata

       fullblock
              accumulate full blocks of input (iflag only)

       nonblock
              use non-blocking I/O

       noatime
              do not update access time

       nocache
              Request to drop cache. See also oflag=sync

       noctty do not assign controlling terminal from file

       nofollow
              do not follow symlinks

       Sending a USR1 signal to a running 'dd' process makes it print I/O
       statistics to standard error and then resume copying. Options are:
--help
display this help and exit
--version
output version information and exit"
143,0,dd,"The
dd
utility shall copy the specified input file to the
       specified output file with possible conversions using specific
       input and output block sizes. It shall read the input one block at
       a time, using the specified input block size; it shall then
       process the block of data actually returned, which could be
       smaller than the requested block size. It shall apply any
       conversions that have been specified and write the resulting data
       to the output in blocks of the specified output block size."
143,1,dd,"It shall apply any
       conversions that have been specified and write the resulting data
       to the output in blocks of the specified output block size. If the
bs
=
expr
operand is specified and no conversions other than
sync
,
noerror
, or
notrunc
are requested, the data returned from each
       input block shall be written as a separate output block; if the
       read returns less than a full block and the
sync
conversion is not
       specified, the resulting output block shall be the same size as
       the input block. If the
bs
=
expr
operand is not specified, or a
       conversion other than
sync
,
noerror
, or
notrunc
is requested, the
       input shall be processed and collected into full-sized output
       blocks until the end of the input is reached."
143,2,dd,"If the
bs
=
expr
operand is not specified, or a
       conversion other than
sync
,
noerror
, or
notrunc
is requested, the
       input shall be processed and collected into full-sized output
       blocks until the end of the input is reached. The processing order shall be as follows:

        1. An input block is read."
143,3,dd,"An input block is read. 2. If the input block is shorter than the specified input block
           size and the
sync
conversion is specified, null bytes shall be
           appended to the input data up to the specified size."
143,4,dd,"If the input block is shorter than the specified input block
           size and the
sync
conversion is specified, null bytes shall be
           appended to the input data up to the specified size. (If
           either
block
or
unblock
is also specified, <space> characters
           shall be appended instead of null bytes.) The remaining
           conversions and output shall include the pad characters as if
           they had been read from the input. 3."
143,5,dd,"3. If the
bs
=
expr
operand is specified and no conversion other
           than
sync
or
noerror
is requested, the resulting data shall be
           written to the output as a single block, and the remaining
           steps are omitted. 4."
143,6,dd,"4. If the
swab
conversion is specified, each pair of input data
           bytes shall be swapped. If there is an odd number of bytes in
           the input block, the last byte in the input record shall not
           be swapped."
143,7,dd,"If there is an odd number of bytes in
           the input block, the last byte in the input record shall not
           be swapped. 5. Any remaining conversions (
block
,
unblock
,
lcase
, and
ucase
)
           shall be performed."
143,8,dd,"Any remaining conversions (
block
,
unblock
,
lcase
, and
ucase
)
           shall be performed. These conversions shall operate on the
           input data independently of the input blocking; an input or
           output fixed-length record may span block boundaries. 6."
143,9,dd,"6. The data resulting from input or conversion or both shall be
           aggregated into output blocks of the specified size. After the
           end of input is reached, any remaining output shall be written
           as a block without padding if
conv
=
sync
is not specified;
           thus, the final output block may be shorter than the output
           block size."
144,0,derb,"derb
reads the compiled resource
bundle
files passed on the
       command line and write them back in text form. The resulting text
       files have a
.txt
extension while compiled resource bundle source
       files typically have a
.res
extension. It is customary to name the resource bundles by their locale name,
       i.e."
144,1,derb,"It is customary to name the resource bundles by their locale name,
       i.e. to use a local identifier for the
bundle
filename, e.g. ja_JP.res
for Japanese (Japan) data, or
root.res
for the root
       bundle."
144,2,derb,"ja_JP.res
for Japanese (Japan) data, or
root.res
for the root
       bundle. This is especially important for
derb
since the locale
       name is not accessible directly from the compiled resource bundle,
       and to know which locale to ask for when opening the bundle. derb
will produce a file whose base name is the base name of the
       compiled resource file itself."
144,3,derb,"This is especially important for
derb
since the locale
       name is not accessible directly from the compiled resource bundle,
       and to know which locale to ask for when opening the bundle. derb
will produce a file whose base name is the base name of the
       compiled resource file itself. If the
--to-stdout
,
-c
option is
       used, however, the text will be written on the standard output."
145,0,debuginfo-install,"debuginfo-install
is a program which installs the RPMs needed to
       debug the specified package.  The package argument can be a
       wildcard, but will only match installed packages.
debuginfo-
install
will then enable any debuginfo repositories, and install
       the relevant debuginfo rpm."
146,0,delta,"The
delta
utility shall be used to permanently introduce into the
       named SCCS files changes that were made to the files retrieved by
get
(called the
g-files
, or generated files)."
147,0,deallocvt,"The command
deallocvt
deallocates kernel memory and data
       structures for all unused virtual consoles. If one or more
       arguments
N
... are given, only the corresponding consoles
/dev/ttyN
are deallocated."
147,1,deallocvt,"If one or more
       arguments
N
... are given, only the corresponding consoles
/dev/ttyN
are deallocated. A virtual console is unused if it is not the foreground console,
       and no process has it open for reading or writing, and no text has
       been selected on its screen."
148,0,df,"This manual page documents the GNU version of
df
. df
displays the
       amount of space available on the file system containing each file
       name argument. If no file name is given, the space available on
       all currently mounted file systems is shown."
148,1,df,"If no file name is given, the space available on
       all currently mounted file systems is shown. Space is shown in 1K
       blocks by default, unless the environment variable POSIXLY_CORRECT
       is set, in which case 512-byte blocks are used. If an argument is the absolute file name of a device node
       containing a mounted file system,
df
shows the space available on
       that file system rather than on the file system containing the
       device node."
148,2,df,"Space is shown in 1K
       blocks by default, unless the environment variable POSIXLY_CORRECT
       is set, in which case 512-byte blocks are used. If an argument is the absolute file name of a device node
       containing a mounted file system,
df
shows the space available on
       that file system rather than on the file system containing the
       device node. This version of
df
cannot show the space available
       on unmounted file systems, because on most kinds of systems doing
       so requires non-portable intimate knowledge of file system
       structures."
149,0,df,"The
df
utility shall write the amount of available space and file
       slots for file systems on which the invoking user has appropriate
       read access. File systems shall be specified by the
file
operands;
       when none are specified, information shall be written for all file
       systems. The format of the default output from
df
is unspecified,
       but all space figures are reported in 512-byte units, unless the
-k
option is specified."
149,1,df,"File systems shall be specified by the
file
operands;
       when none are specified, information shall be written for all file
       systems. The format of the default output from
df
is unspecified,
       but all space figures are reported in 512-byte units, unless the
-k
option is specified. This output shall contain at least the
       file system names, amount of available space on each of these file
       systems, and, if no options other than
-t
are specified, the
       number of free file slots, or
inode
s, available; when
-t
is
       specified, the output shall contain the total allocated space as
       well."
150,0,dh,"dh
runs a sequence of debhelper commands. The supported
sequence
s
       correspond to the targets of a
debian/rules
file:
build-arch
,
build-indep
,
build
,
clean
,
install-indep
,
install-arch
,
install
,
binary-arch
,
binary-indep
, and
binary
."
151,0,dh_auto_build,"dh_auto_build
is a debhelper program that tries to automatically
       build a package. It does so by running the appropriate command for
       the build system it detects the package uses. For example, if a
Makefile
is found, this is done by running
make
(or
MAKE
, if the
       environment variable is set)."
151,1,dh_auto_build,"For example, if a
Makefile
is found, this is done by running
make
(or
MAKE
, if the
       environment variable is set). If there's a
setup.py
, or
Build.PL
,
       it is run to build the package. This is intended to work for about 90% of packages."
151,2,dh_auto_build,"If there's a
setup.py
, or
Build.PL
,
       it is run to build the package. This is intended to work for about 90% of packages. If it doesn't
       work, you're encouraged to skip using
dh_auto_build
at all, and
       just run the build process manually."
152,0,dh_auto_clean,"dh_auto_clean
is a debhelper program that tries to automatically
       clean up after a package build. It does so by running the
       appropriate command for the build system it detects the package
       uses. For example, if there's a
Makefile
and it contains a
distclean
,
realclean
, or
clean
target, then this is done by
       running
make
(or
MAKE
, if the environment variable is set)."
152,1,dh_auto_clean,"For example, if there's a
Makefile
and it contains a
distclean
,
realclean
, or
clean
target, then this is done by
       running
make
(or
MAKE
, if the environment variable is set). If
       there is a
setup.py
or
Build.PL
, it is run to clean the package. This is intended to work for about 90% of packages."
152,2,dh_auto_clean,"If
       there is a
setup.py
or
Build.PL
, it is run to clean the package. This is intended to work for about 90% of packages. If it doesn't
       work, or tries to use the wrong clean target, you're encouraged to
       skip using
dh_auto_clean
at all, and just run
make clean
manually."
153,0,dh_auto_configure,"dh_auto_configure
is a debhelper program that tries to
       automatically configure a package prior to building. It does so by
       running the appropriate command for the build system it detects
       the package uses. For example, it looks for and runs a
./configure
script,
Makefile.PL
,
Build.PL
, or
cmake
."
153,1,dh_auto_configure,"For example, it looks for and runs a
./configure
script,
Makefile.PL
,
Build.PL
, or
cmake
. A standard
       set of parameters is determined and passed to the program that is
       run. Some build systems, such as make, do not need a configure
       step; for these
dh_auto_configure
will exit without doing
       anything."
153,2,dh_auto_configure,"Some build systems, such as make, do not need a configure
       step; for these
dh_auto_configure
will exit without doing
       anything. This is intended to work for about 90% of packages. If it doesn't
       work, you're encouraged to skip using
dh_auto_configure
at all,
       and just run
./configure
or its equivalent manually."
154,0,dh_assistant,"dh_assistant
is a debhelper program that provides introspection
       into the debhelper stack to assist third-party tools (e.g.
       linters) or third-party debhelper implementations not using the
       debhelper script API (e.g., because they are not written in Perl)."
155,0,dh_auto_test,"dh_auto_test
is a debhelper program that tries to automatically
       run a package's test suite. It does so by running the appropriate
       command for the build system it detects the package uses. For
       example, if there's a Makefile and it contains a
test
or
check
target, then this is done by running
make
(or
MAKE
, if the
       environment variable is set)."
155,1,dh_auto_test,"For
       example, if there's a Makefile and it contains a
test
or
check
target, then this is done by running
make
(or
MAKE
, if the
       environment variable is set). If the test suite fails, the command
       will exit nonzero. If there's no test suite, it will exit zero
       without doing anything."
155,2,dh_auto_test,"If there's no test suite, it will exit zero
       without doing anything. This is intended to work for about 90% of packages with a test
       suite. If it doesn't work, you're encouraged to skip using
dh_auto_test
at all, and just run the test suite manually."
156,0,dh_auto_install,"dh_auto_install
is a debhelper program that tries to automatically
       install built files. It does so by running the appropriate command
       for the build system it detects the package uses. For example, if
       there's a
Makefile
and it contains a
install
target, then this is
       done by running
make
(or
MAKE
, if the environment variable is
       set)."
156,1,dh_auto_install,"For example, if
       there's a
Makefile
and it contains a
install
target, then this is
       done by running
make
(or
MAKE
, if the environment variable is
       set). If there is a
setup.py
or
Build.PL
, it is used. Note that
       the Ant build system does not support installation, so
dh_auto_install
will not install files built using Ant."
156,2,dh_auto_install,"Note that
       the Ant build system does not support installation, so
dh_auto_install
will not install files built using Ant. In compat 14 or later,
dh_auto_install
will use
debian/tmp
as the
       default
--destdir
and should be moved from there to the
       appropriate package build directory using
dh_install(1)
or similar
       tools. Though if the
single-binary
addon for
dh(1)
is activated,
       then it will pass an explicit
--destdir=debian/
package
/
to
dh_auto_install
."
156,3,dh_auto_install,"Though if the
single-binary
addon for
dh(1)
is activated,
       then it will pass an explicit
--destdir=debian/
package
/
to
dh_auto_install
. For earlier compat levels then unless
--destdir
option is
       specified, the files are installed into debian/
package
/ if there
       is only one binary package. In the multiple binary package case,
       the files are instead installed into
debian/tmp/
, and should be
       moved from there to the appropriate package build directory using
dh_install(1)
or similar tools."
156,4,dh_auto_install,"In the multiple binary package case,
       the files are instead installed into
debian/tmp/
, and should be
       moved from there to the appropriate package build directory using
dh_install(1)
or similar tools. DESTDIR
is used to tell make where to install the files. If the
       Makefile was generated by MakeMaker from a
Makefile.PL
, it will
       automatically set
PREFIX=/usr
too, since such Makefiles need that."
156,5,dh_auto_install,"If the
       Makefile was generated by MakeMaker from a
Makefile.PL
, it will
       automatically set
PREFIX=/usr
too, since such Makefiles need that. This is intended to work for about 90% of packages. If it doesn't
       work, or tries to use the wrong install target, you're encouraged
       to skip using
dh_auto_install
at all, and just run make install
       manually."
157,0,dh_builddeb,"dh_builddeb
simply calls
dpkg-deb(1)
to build a Debian package or
       packages. It will also build dbgsym packages when
dh_strip(1)
and
dh_gencontrol(1)
have prepared them. It supports building multiple binary packages in parallel, when
       enabled by DEB_BUILD_OPTIONS."
157,1,dh_builddeb,"It will also build dbgsym packages when
dh_strip(1)
and
dh_gencontrol(1)
have prepared them. It supports building multiple binary packages in parallel, when
       enabled by DEB_BUILD_OPTIONS. When the
Rules-Requires-Root
field is not (effectively)
binary-
targets
,
dh_builddeb
will pass
--root-owner-group
to
dpkg-deb(1)
."
158,0,dh_bugfiles,"dh_bugfiles
is a debhelper program that is responsible for
       installing bug reporting customization files (bug scripts and/or
       bug control files and/or presubj files) into package build
       directories."
159,0,dh_clean,"dh_clean
is a debhelper program that is responsible for cleaning
       up. It should be the last step of the
clean
target and other
       debhelper commands generally assume that
dh_clean
will clean up
       after them. It removes the package build directories, and removes some other
       files including
debian/files
, and any detritus left behind by
       other debhelper commands."
159,1,dh_clean,"It removes the package build directories, and removes some other
       files including
debian/files
, and any detritus left behind by
       other debhelper commands. It also removes common files and
       directories that should not appear in a Debian diff:
         #*# *~ DEADJOE *.orig *.rej *.SUMS __pycache__ TAGS .deps/* *.P
       *-stamp

       It does not run ""make clean"" to clean up after the build process. Use
dh_auto_clean(1)
to do things like that."
160,0,dh_compress,"dh_compress
is a debhelper program that is responsible for
       compressing the files in package build directories, and makes sure
       that any symlinks that pointed to the files before they were
       compressed are updated to point to the new files.

       By default,
dh_compress
compresses files that Debian policy
       mandates should be compressed, namely all files in
usr/share/info
,
usr/share/man
, files in
usr/share/doc
that are larger than 4k in
       size, (except the
copyright
file,
.html
and other web files, image
       files, and files that appear to be already compressed based on
       their extensions), and all
changelog
files. Plus PCF fonts
       underneath
usr/share/fonts/X11/"
161,0,dh_fixperms,"dh_fixperms
is a debhelper program that is responsible for setting
       the permissions of files and directories in package build
       directories to a sane state -- a state that complies with Debian
       policy. dh_fixperms
makes all files in
usr/share/doc
in the package build
       directory (excluding files in the
examples/
directory) be mode
       644. It also changes the permissions of all man pages to mode 644."
161,1,dh_fixperms,"It also changes the permissions of all man pages to mode 644. It removes group and other write permission from all files. It
       removes execute permissions from any libraries, headers, Perl
       modules, or desktop files that have it set."
161,2,dh_fixperms,"It
       removes execute permissions from any libraries, headers, Perl
       modules, or desktop files that have it set. It makes all files in
       the standard
bin
and
sbin
directories,
usr/games/
and
etc/init.d
executable (since v4). Finally, it removes the setuid and setgid
       bits from all files in the package."
161,3,dh_fixperms,"It makes all files in
       the standard
bin
and
sbin
directories,
usr/games/
and
etc/init.d
executable (since v4). Finally, it removes the setuid and setgid
       bits from all files in the package. When the
Rules-Requires-Root
field has the (effective) value of
binary-targets
,
dh_fixperms
will also reset the ownership of all
       paths to ""root:root""."
162,0,dh_gencontrol,"dh_gencontrol
is a debhelper program that is responsible for
       generating control files, and installing them into the
DEBIAN
directory with the proper permissions. This program is merely a wrapper around
dpkg-gencontrol(1)
, which
       calls it once for each package being acted on (plus related dbgsym
       packages), and passes in some additional useful flags. Note
that if you use
dh_gencontrol
, you must also use
dh_builddeb(1)
to build the packages."
162,1,dh_gencontrol,"Note
that if you use
dh_gencontrol
, you must also use
dh_builddeb(1)
to build the packages. Otherwise, your build may
       fail to build as
dh_gencontrol
(via
dpkg-gencontrol(1)
) declares
       which packages are built. As debhelper automatically generates
       dbgsym packages, it some times adds additional packages, which
       will be built by
dh_builddeb(1)
."
163,0,dh_dwz,"dh_dwz
is a debhelper program that will optimize the
       (uncompressed) size of the DWARF debug information in ELF
       binaries.  It does so by running
dwz
(1) on all the ELF binaries in
       the package."
164,0,dh_icons,"dh_icons
is a debhelper program that updates caches of Freedesktop
       icons when needed, using the
update-icon-caches
program provided
       by GTK+2.12. Currently this program does not handle installation
       of the files, though it may do so at a later date, so should be
       run after icons are installed in the package build directories. It takes care of adding maintainer script fragments to call
update-icon-caches
for icon directories."
164,1,dh_icons,"Currently this program does not handle installation
       of the files, though it may do so at a later date, so should be
       run after icons are installed in the package build directories. It takes care of adding maintainer script fragments to call
update-icon-caches
for icon directories. (This is not done for
       gnome and hicolor icons, as those are handled by triggers.)  These
       commands are inserted into the maintainer scripts by
dh_installdeb(1)
."
165,0,dh_installchangelogs,"dh_installchangelogs
is a debhelper program that is responsible
       for installing changelogs into package build directories. An upstream
changelog
file may be specified as an option. If none
       is specified,
dh_installchangelogs
may look for files with names
       that seem likely to be changelogs as described in the next
       paragraphs."
165,1,dh_installchangelogs,"If none
       is specified,
dh_installchangelogs
may look for files with names
       that seem likely to be changelogs as described in the next
       paragraphs. In non-native packages,
dh_installchangelogs
will first look for
       changelog files installed by the upstream build system into
usr/share/doc/package
(of the package build directory) and rename
       the most likely candidate (if any) to
usr/share/doc/package/changelog
. Note that
dh_installchangelogs
does
not
look into any source directory (such as
debian/tmp
)."
165,2,dh_installchangelogs,"Note that
dh_installchangelogs
does
not
look into any source directory (such as
debian/tmp
). Otherwise,
dh_installchangelogs
(at compatibility level 7 or any
       later) will look for changelog files in the source directory (e.g. the root or the
docs
subdirectory)."
165,3,dh_installchangelogs,"the root or the
docs
subdirectory). It will look for
changelog
,
changes
and
history
optionally with common extensions (such as
.txt
,
.md
,
.rst
,
.org
, etc.)

       If a changelog file is specified and is an
html
file (determined
       by file extension), it will be installed as
usr/share/doc/package/changelog.html
instead. If the html
       changelog is converted to plain text, that variant can be
       specified as a second parameter."
165,4,dh_installchangelogs,"If the html
       changelog is converted to plain text, that variant can be
       specified as a second parameter. When no plain text variant is
       specified, a short
usr/share/doc/package/changelog
is generated,
       pointing readers at the html changelog file. The
debchange
-style Debian changelogs are trimmed to include only
       entries more recent than the release date of
oldstable
."
165,5,dh_installchangelogs,"When no plain text variant is
       specified, a short
usr/share/doc/package/changelog
is generated,
       pointing readers at the html changelog file. The
debchange
-style Debian changelogs are trimmed to include only
       entries more recent than the release date of
oldstable
. No
       trimming will be performed if the
--no-trim
option is passed or if
       the
DEB_BUILD_OPTIONS
environment variable contains
notrimdch
."
166,0,dh_installalternatives,"dh_installalternatives
is a debhelper program that is responsible
       for parsing the declarative alternatives format and insert the
       relevant maintscripts snippets to interface with
update-alternatives(1)"
167,0,dh_install,"dh_install
is a debhelper program that handles installing files
       into package build directories. There are many
dh_install
*
commands that handle installing specific types of files such as
       documentation, examples, man pages, and so on, and they should be
       used when possible as they often have extra intelligence for those
       particular tasks. dh_install
, then, is useful for installing
       everything else, for which no particular intelligence is needed."
167,1,dh_install,"dh_install
, then, is useful for installing
       everything else, for which no particular intelligence is needed. It is a replacement for the old
dh_movefiles
command. This program may be used in one of two ways."
167,2,dh_install,"This program may be used in one of two ways. If you just have a
       file or two that the upstream Makefile does not install for you,
       you can run
dh_install
on them to move them into place. On the
       other hand, maybe you have a large package that builds multiple
       binary packages."
167,3,dh_install,"On the
       other hand, maybe you have a large package that builds multiple
       binary packages. You can use the upstream
Makefile
to install it
       all into
debian/tmp
, and then use
dh_install
to copy directories
       and files from there into the proper package build directories. From debhelper compatibility level 7 on,
dh_install
will fall back
       to looking in
debian/tmp
for files, if it does not find them in
       the current directory (or wherever you've told it to look using
--sourcedir
)."
168,0,dh_installcatalogs,"dh_installcatalogs
is a debhelper program that installs and
       registers SGML catalogs. It complies with the Debian XML/SGML
       policy. Catalogs will be registered in a supercatalog, in
/etc/sgml/package.cat
."
168,1,dh_installcatalogs,"Catalogs will be registered in a supercatalog, in
/etc/sgml/package.cat
. This command automatically adds maintainer script snippets for
       registering and unregistering the catalogs and supercatalogs
       (unless
-n
is used). These snippets are inserted into the
       maintainer scripts and the
triggers
file by
dh_installdeb
; see
dh_installdeb(1)
for an explanation of Debhelper maintainer script
       snippets."
168,2,dh_installcatalogs,"This command automatically adds maintainer script snippets for
       registering and unregistering the catalogs and supercatalogs
       (unless
-n
is used). These snippets are inserted into the
       maintainer scripts and the
triggers
file by
dh_installdeb
; see
dh_installdeb(1)
for an explanation of Debhelper maintainer script
       snippets. A dependency on
sgml-base
will be added to
${misc:Depends}
, so be
       sure your package uses that variable in
debian/control
."
169,0,dh_installcron,"dh_installcron
is a debhelper program that is responsible for
       installing cron scripts."
170,0,dh_installdeb,"dh_installdeb
is a debhelper program that is responsible for
       installing files into the
DEBIAN
directories in package build
       directories with the correct permissions."
171,0,dh_installdirs,"dh_installdirs
is a debhelper program that is responsible for
       creating subdirectories in package build directories.

       Many packages can get away with omitting the call to
dh_installdirs
completely.  Notably, other
dh_*
commands are
       expected to create directories as needed."
172,0,dh_installdocs,"dh_installdocs
is a debhelper program that is responsible for
       installing documentation into
usr/share/doc/package
in package
       build directories. In compat 10 and earlier,
dh_install(1)
may be a better tool for
       handling the upstream documentation, when upstream's own build
       system installs all the desired documentation correctly. In this
       case,
dh_installdocs
is still useful for installing packaging
       related documentation (e.g."
172,1,dh_installdocs,"In this
       case,
dh_installdocs
is still useful for installing packaging
       related documentation (e.g. the
debian/copyright
file). From debhelper compatibility level 11 on,
dh_install
will fall
       back to looking in
debian/tmp
for files, if it does not find them
       in the current directory (or wherever you've told it to look using
--sourcedir
)."
172,2,dh_installdocs,"From debhelper compatibility level 11 on,
dh_install
will fall
       back to looking in
debian/tmp
for files, if it does not find them
       in the current directory (or wherever you've told it to look using
--sourcedir
). In compat 11 and later,
dh_installdocs
offers many of the features
       that
dh_install(1)
also has. Furthermore,
dh_installdocs
also
       supports the
nodoc
build profile to exclude documentation
       (regardless of compat level)."
173,0,dh_installemacsen,"dh_installemacsen
is a debhelper program that is responsible for
       installing files used by the Debian
emacsen-common
package into
       package build directories. It also automatically generates the
preinst postinst
and
prerm
commands needed to register a package as an Emacs add on package. The commands are added to the maintainer scripts by
dh_installdeb
."
173,1,dh_installemacsen,"It also automatically generates the
preinst postinst
and
prerm
commands needed to register a package as an Emacs add on package. The commands are added to the maintainer scripts by
dh_installdeb
. See
dh_installdeb(1)
for an explanation of how this works."
174,0,dh_installdebconf,"dh_installdebconf
is a debhelper program that is responsible for
       installing files used by debconf into package build directories. It also automatically generates the
postrm
commands needed to
       interface with debconf. The commands are added to the maintainer
       scripts by
dh_installdeb
."
174,1,dh_installdebconf,"The commands are added to the maintainer
       scripts by
dh_installdeb
. See
dh_installdeb(1)
for an explanation
       of how that works. Note that if you use debconf, your package probably needs to
       depend on it (it will be added to
${misc:Depends}
by this
       program)."
174,2,dh_installdebconf,"Note that if you use debconf, your package probably needs to
       depend on it (it will be added to
${misc:Depends}
by this
       program). Note that for your config script to be called by
dpkg
, your
postinst
needs to source debconf's confmodule. dh_installdebconf
does not install this statement into the
postinst
automatically as
       it is too hard to do it right."
175,0,dh_installexamples,"dh_installexamples
is a debhelper program that is responsible for
       installing examples into
usr/share/doc/package/examples
in package
       build directories.

       From debhelper compatibility level 11 on,
dh_install
will fall
       back to looking in
debian/tmp
for files, if it does not find them
       in the current directory (or wherever you've told it to look using
--sourcedir
)."
176,0,dh_installgsettings,"dh_installgsettings
is a debhelper program that is responsible for
       installing GSettings override files and generating appropriate
       dependencies on the GSettings backend.

       The dependency on the backend will be generated in
${misc:Depends}
."
177,0,dh_installinfo,"dh_installinfo
is a debhelper program that is responsible for
       installing info files into
usr/share/info
in the package build
       directory.

       From debhelper compatibility level 11 on,
dh_install
will fall
       back to looking in
debian/tmp
for files, if it does not find them
       in the current directory (or wherever you've told it to look using
--sourcedir
)."
178,0,dh_installifupdown,"dh_installifupdown
is a debhelper program that is responsible for
       installing
if-up
,
if-down
,
if-pre-up
, and
if-post-down
hook
       scripts into package build directories."
179,0,dh_installinit,"dh_installinit
is a debhelper program that is responsible for
       installing init scripts with associated defaults files. In
       compatibility levels up to and including 10,
dh_installinit
will
       also install some systemd related files provided by the debian
       packaging (see the ""FILES"" section below). In compatibility
       levels up to and including 11,
dh_installinit
will also handle
       upstart jobs provided in the debian packaging (see the ""FILES"" for
       more information on this as well)."
179,1,dh_installinit,"In compatibility
       levels up to and including 11,
dh_installinit
will also handle
       upstart jobs provided in the debian packaging (see the ""FILES"" for
       more information on this as well). It also automatically generates the
postinst
and
postrm
and
prerm
commands needed to set up the symlinks in
/etc/rc*.d/
to start and
       stop the init scripts. In compat 10 or earlier: If a package only ships a systemd service
       file and no sysvinit script is provided, you may want to exclude
       the call to dh_installinit for that package (e.g."
179,2,dh_installinit,"In compat 10 or earlier: If a package only ships a systemd service
       file and no sysvinit script is provided, you may want to exclude
       the call to dh_installinit for that package (e.g. via
-N
). Otherwise, you may get warnings from lintian about init.d scripts
       not being included in the package."
180,0,dh_installinitramfs,"dh_installinitramfs
is a debhelper program that is responsible for
       installing Debian package provided initramfs hooks.

       If
dh_installinitramfs
installs or detects one or more initramfs
       hooks in the package, then it also automatically generates the
       noawait trigger
update-initframfs
command needed to interface with
       the Debian initramfs system.  This trigger is inserted into the
       packaging by
dh_installdeb(1)
."
181,0,dh_installlogcheck,"dh_installlogcheck
is a debhelper program that is responsible for
       installing logcheck rule files."
182,0,dh_installman,"dh_installman
is a debhelper program that handles installing man
       pages into the correct locations in package build directories. In compat 10 and earlier, this program was primarily for when
       upstream's build system does not properly install them as a part
       of its install step (or it does not have an install step). In
       compat 11 and later, it also supports the default searchdir plus
       --sourcedir like
dh_install(1)
and has the advantage that it
       respects the nodoc build profile (unlike
dh_install(1)
)."
182,1,dh_installman,"In
       compat 11 and later, it also supports the default searchdir plus
       --sourcedir like
dh_install(1)
and has the advantage that it
       respects the nodoc build profile (unlike
dh_install(1)
). Even if you prefer to use
dh_install(1)
for installing the
       manpages,
dh_installman
can still be useful for converting the
       manpage encoding to UTF-8 and for converting
.so
links (as
       described below). However, that part happens automatically
       without any explicit configuration."
182,2,dh_installman,"However, that part happens automatically
       without any explicit configuration. You tell
dh_installman
what man pages go in your packages, and it
       figures out where to install them based on the section field in
       their
.TH
or
.Dt
line. If you have a properly formatted
.TH
or
.Dt
line, your man page will be installed into the right directory,
       with the right name (this includes proper handling of pages with a
       subsection, like
3perl
, which are placed in
man3
, and given an
       extension of
.3perl
)."
182,3,dh_installman,"If you have a properly formatted
.TH
or
.Dt
line, your man page will be installed into the right directory,
       with the right name (this includes proper handling of pages with a
       subsection, like
3perl
, which are placed in
man3
, and given an
       extension of
.3perl
). If your
.TH
or
.Dt
line is incorrect or
       missing, the program may guess wrong based on the file extension. It also supports translated man pages, by looking for extensions
       like
.ll.8
and
.ll_LL.8
, or by use of the
--language
switch."
182,4,dh_installman,"It also supports translated man pages, by looking for extensions
       like
.ll.8
and
.ll_LL.8
, or by use of the
--language
switch. If
dh_installman
seems to install a man page into the wrong
       section or with the wrong extension, this is because the man page
       has the wrong section listed in its
.TH
or
.Dt
line. Edit the man
       page and correct the section, and
dh_installman
will follow suit."
182,5,dh_installman,"Edit the man
       page and correct the section, and
dh_installman
will follow suit. See
man(7)
for details about the
.TH
section, and
mdoc
(7) for the
.Dt
section. If
dh_installman
seems to install a man page into a
       directory like
/usr/share/man/pl/man1/
, that is because your
       program has a name like
foo.pl
, and
dh_installman
assumes that
       means it is translated into Polish."
182,6,dh_installman,"If
dh_installman
seems to install a man page into a
       directory like
/usr/share/man/pl/man1/
, that is because your
       program has a name like
foo.pl
, and
dh_installman
assumes that
       means it is translated into Polish. Use
--language=C
to avoid
       this. After the man page installation step,
dh_installman
will check to
       see if any of the man pages in the temporary directories of any of
       the packages it is acting on contain
.so
links."
182,7,dh_installman,"After the man page installation step,
dh_installman
will check to
       see if any of the man pages in the temporary directories of any of
       the packages it is acting on contain
.so
links. If so, it changes
       them to symlinks. Also,
dh_installman
will use man to guess the character encoding
       of each manual page and convert it to UTF-8."
182,8,dh_installman,"Also,
dh_installman
will use man to guess the character encoding
       of each manual page and convert it to UTF-8. If the guesswork
       fails for some reason, you can override it using an encoding
       declaration. See
manconv(1)
for details."
182,9,dh_installman,"If the guesswork
       fails for some reason, you can override it using an encoding
       declaration. See
manconv(1)
for details. From debhelper compatibility level 11 on,
dh_install
will fall
       back to looking in
debian/tmp
for files, if it does not find them
       in the current directory (or wherever you've told it to look using
--sourcedir
)."
183,0,dh_installlogrotate,"dh_installlogrotate
is a debhelper program that is responsible for
       installing logrotate config files into
etc/logrotate.d
in package
       build directories.  Files named
debian/package.logrotate
are
       installed."
184,0,dh_installmanpages,"dh_installmanpages
is a debhelper program that is responsible for
       automatically installing man pages into
usr/share/man/
in package
       build directories. This is a DWIM-style program, with an interface unlike the rest of
       debhelper. It is deprecated, and you are encouraged to use
dh_installman(1)
instead."
184,1,dh_installmanpages,"It is deprecated, and you are encouraged to use
dh_installman(1)
instead. dh_installmanpages
scans the current directory and all
       subdirectories for filenames that look like man pages. (Note that
       only real files are looked at; symlinks are ignored.) It uses
file(1)
to verify that the files are in the correct format."
184,2,dh_installmanpages,"(Note that
       only real files are looked at; symlinks are ignored.) It uses
file(1)
to verify that the files are in the correct format. Then,
       based on the files' extensions, it installs them into the correct
       man directory. All filenames specified as parameters will be skipped by
dh_installmanpages
."
184,3,dh_installmanpages,"All filenames specified as parameters will be skipped by
dh_installmanpages
. This is useful if by default it installs some
       man pages that you do not want to be installed. After the man page installation step,
dh_installmanpages
will
       check to see if any of the man pages are
.so
links."
184,4,dh_installmanpages,"This is useful if by default it installs some
       man pages that you do not want to be installed. After the man page installation step,
dh_installmanpages
will
       check to see if any of the man pages are
.so
links. If so, it
       changes them to symlinks."
185,0,dh_installmenu,"dh_installmenu
is a debhelper program that is responsible for
       installing files used by the Debian
menu
package into package
       build directories.

       It also automatically generates the
postinst
and
postrm
commands
       needed to interface with the Debian
menu
package. These commands
       are inserted into the maintainer scripts by
dh_installdeb(1)
."
186,0,dh_installmime,"dh_installmime
is a debhelper program that is responsible for
       installing mime files into package build directories."
187,0,dh_installmodules,"dh_installmodules
is a debhelper program that is responsible for
       registering kernel modules.

       Kernel modules are searched for in the package build directory and
       if found,
preinst
,
postinst
and
postrm
commands are automatically
       generated to run
depmod
and register the modules when the package
       is installed.  These commands are inserted into the maintainer
       scripts by
dh_installdeb(1)
."
188,0,dh_installpam,"dh_installpam
is a debhelper program that is responsible for
       installing files used by PAM into package build directories."
189,0,dh_installppp,"dh_installppp
is a debhelper program that is responsible for
       installing ppp ip-up and ip-down scripts into package build
       directories."
190,0,dh_installsystemd,"dh_installsystemd
is a debhelper program that is responsible for
       installing package maintainer supplied systemd unit files. It also finds the service files installed by a package and
       generates
preinst
,
postinst
, and
prerm
code blocks for enabling,
       disabling, starting, stopping, and restarting the corresponding
       systemd services, when the package is installed, updated, or
       removed. These snippets are added to the maintainer scripts by
dh_installdeb(1)
."
190,1,dh_installsystemd,"These snippets are added to the maintainer scripts by
dh_installdeb(1)
. deb-systemd-helper
(1) is used to enable and disable systemd units,
       thus it is not necessary that the machine actually runs systemd
       during package installation time, enabling happens on all machines
       in order to be able to switch from sysvinit to systemd and back. dh_installsystemd
operates on all unit files installed by a
       package."
190,2,dh_installsystemd,"dh_installsystemd
operates on all unit files installed by a
       package. For only generating blocks for specific unit files, pass
       them as arguments, ""dh_installsystemd quota.service"". Specific
       unit files can be excluded from processing using the
-X
common
debhelper
(1) option."
191,0,dh_installsystemduser,"dh_installsystemduser
finds the systemd user instance service
       files installed by a package and generates
preinst
,
postinst
, and
prerm
code blocks for enabling, disabling, starting, stopping, and
       restarting the corresponding systemd user instance services, when
       the package is installed, updated, or removed. These snippets are
       added to the maintainer scripts by
dh_installdeb(1)
. deb-systemd-helper
(1) is used to enable and disable the systemd
       units, thus it is not necessary that the machine actually runs
       systemd during package installation time, enabling happens on all
       machines."
191,1,dh_installsystemduser,"deb-systemd-helper
(1) is used to enable and disable the systemd
       units, thus it is not necessary that the machine actually runs
       systemd during package installation time, enabling happens on all
       machines. dh_installsystemduser
operates on all user instance unit files
       installed by a package. For only generating blocks for specific
       unit files, pass them as arguments."
191,2,dh_installsystemduser,"dh_installsystemduser
operates on all user instance unit files
       installed by a package. For only generating blocks for specific
       unit files, pass them as arguments. Specific unit files can be
       excluded from processing using the
-X
common
debhelper
(1) option."
192,0,dh_installudev,"dh_installudev
is a debhelper program that is responsible for
       installing
udev
rules files."
193,0,dh_installwm,"dh_installwm
is a debhelper program that is responsible for
       generating the
postinst
and
prerm
commands that register a window
       manager with
update-alternatives
(8). The window manager's man page
       is also registered as a slave symlink (in v6 mode and up). It
       must be installed in
usr/share/man/man1/
in the package build
       directory prior to calling
dh_installwm
."
193,1,dh_installwm,"The window manager's man page
       is also registered as a slave symlink (in v6 mode and up). It
       must be installed in
usr/share/man/man1/
in the package build
       directory prior to calling
dh_installwm
. In compat 9 and earlier,
       the manpage was optional."
194,0,dh_installsysusers,"dh_installsysusers
is a debhelper program that is responsible for
       installing package maintainer supplied systemd sysusers files.

       It also finds the systemd sysusers files installed in a package
       and generates relevant integration snippets for enabling the users
       on installation.  These snippets are added to the package by
dh_installdeb(1)
."
195,0,dh_installtmpfiles,"dh_installtmpfiles
is a debhelper program that is responsible for
       installing package maintainer supplied tmpfiles.d configuration
       files (e.g. for systemd-tmpfiles). It also finds the tmpfiles.d configuration files installed by a
       package and generates
postinst
code blocks for activating the
       tmpfiles.d configuration when the package is installed."
195,1,dh_installtmpfiles,"It also finds the tmpfiles.d configuration files installed by a
       package and generates
postinst
code blocks for activating the
       tmpfiles.d configuration when the package is installed. These
       snippets are added to the maintainer scripts by
dh_installdeb(1)
. In compat 14+, tmpfiles.d files are copied into the
postrm
script,
       and they are used with systemd-tmpfiles --remove after the package
       is removed and --purge when the package is purged."
195,2,dh_installtmpfiles,"These
       snippets are added to the maintainer scripts by
dh_installdeb(1)
. In compat 14+, tmpfiles.d files are copied into the
postrm
script,
       and they are used with systemd-tmpfiles --remove after the package
       is removed and --purge when the package is purged. This allows one
       to use the tmpfiles.d mechanism to clean up files that are no
       longer needed after a package has been removed/purged."
196,0,dh_installxfonts,"dh_installxfonts
is a debhelper program that is responsible for
       registering X fonts, so their corresponding
fonts.dir
,
fonts.alias
, and
fonts.scale
be rebuilt properly at install time. Before calling this program, you should have installed any X fonts
       provided by your package into the appropriate location in the
       package build directory, and if you have
fonts.alias
or
fonts.scale
files, you should install them into the correct
       location under
etc/X11/fonts
in your package build directory. Your package should depend on
xfonts-utils
so that the
update-fonts-
*
commands are available."
196,1,dh_installxfonts,"Your package should depend on
xfonts-utils
so that the
update-fonts-
*
commands are available. (This program adds that
       dependency to
${misc:Depends}
.)

       This program automatically generates the
postinst
and
postrm
commands needed to register X fonts. These commands are inserted
       into the maintainer scripts by
dh_installdeb
."
196,2,dh_installxfonts,"(This program adds that
       dependency to
${misc:Depends}
.)

       This program automatically generates the
postinst
and
postrm
commands needed to register X fonts. These commands are inserted
       into the maintainer scripts by
dh_installdeb
. See
dh_installdeb(1)
for an explanation of how this works."
197,0,dh_link,"dh_link
is a debhelper program that creates symlinks in package
       build directories. dh_link
accepts a list of pairs of source and destination files. The source files are the already existing files that will be
       symlinked from (called
target
by
ln(1)
)."
197,1,dh_link,"The source files are the already existing files that will be
       symlinked from (called
target
by
ln(1)
). The destination files are
       the symlinks that will be created (called
link name
by
ln(1)
). There
must
be an equal number of source and destination files
       specified."
197,2,dh_link,"There
must
be an equal number of source and destination files
       specified. Be sure you
do
specify the absolute path to both the source and
       destination files (unlike you would do if you were using something
       like
ln(1)
). Please note that the leading slash is optional."
197,3,dh_link,"Please note that the leading slash is optional. dh_link
will generate symlinks that comply with Debian policy -
       absolute when policy says they should be absolute, and relative
       links with as short a path as possible. It will also create any
       subdirectories it needs to put the symlinks in."
197,4,dh_link,"It will also create any
       subdirectories it needs to put the symlinks in. Any pre-existing destination files will be replaced with symlinks. dh_link
also scans the package build tree for existing symlinks
       which do not conform to Debian policy, and corrects them (v4 or
       later)."
198,0,dh_lintian,"dh_lintian
is a debhelper program that is responsible for
       installing override files used by lintian into package build
       directories."
199,0,dh_makeshlibs,"dh_makeshlibs
is a debhelper program that automatically scans for
       shared libraries, and generates a shlibs file for the libraries it
       finds. It will also ensure that ldconfig is invoked during install and
       removal when it finds shared libraries. Since debhelper
       9.20151004, this is done via a dpkg trigger."
199,1,dh_makeshlibs,"Since debhelper
       9.20151004, this is done via a dpkg trigger. In older versions of
       debhelper,
dh_makeshlibs
would generate a maintainer script for
       this purpose. Since debhelper 12.3,
dh_makeshlibs
will by default add an
       additional
udeb
line for udebs in the shlibs file, when the udeb
       has the same name as the deb followed by a ""-udeb"" suffix (e.g."
199,2,dh_makeshlibs,"Since debhelper 12.3,
dh_makeshlibs
will by default add an
       additional
udeb
line for udebs in the shlibs file, when the udeb
       has the same name as the deb followed by a ""-udeb"" suffix (e.g. if
       the deb is called ""libfoo1"", then debhelper will auto-detect the
       udeb if it is named ""libfoo1-udeb""). Please use the
--add-udeb
and
--no-add-udeb
options below when this auto-detection is
       insufficient."
199,3,dh_makeshlibs,"Please use the
--add-udeb
and
--no-add-udeb
options below when this auto-detection is
       insufficient. If you previously used
--add-udeb
and are considering to migrate
       to using the new auto-detection feature in 12.3, then please
       remember to test that the resulting
DEBIAN/shlibs
files are as
       expected. There are some known corner cases, where the
       auto-detection is insufficient."
199,4,dh_makeshlibs,"If you previously used
--add-udeb
and are considering to migrate
       to using the new auto-detection feature in 12.3, then please
       remember to test that the resulting
DEBIAN/shlibs
files are as
       expected. There are some known corner cases, where the
       auto-detection is insufficient. These include when the udeb
       contains library files from multiple regular deb packages or when
       the packages do not follow the expected naming convention."
200,0,dh_listpackages,"dh_listpackages
is a debhelper program that outputs a list of all
       binary packages debhelper commands will act on. If you pass it
       some options, it will change the list to match the packages other
       debhelper commands would act on if passed the same options.

       Packages are listed in the order they appear in
debian/control
."
201,0,dh_missing,"dh_missing
compares the list of installed files with the files in
       the source directory. If any of the files (and symlinks) in the
       source directory were not installed to somewhere, it will warn on
       stderr about that (
--list-missing
) or fail (
--fail-missing
). Please note that in compat 11 and earlier without either of these
       options,
dh_missing
will silently do nothing."
201,1,dh_missing,"Please note that in compat 11 and earlier without either of these
       options,
dh_missing
will silently do nothing. In compat 12,
--list-missing
is the default  In compat 13 and later,
--fail-missing
is the default. This may be useful if you have a large package and want to make
       sure that you don't miss installing newly added files in new
       upstream releases."
201,2,dh_missing,"In compat 12,
--list-missing
is the default  In compat 13 and later,
--fail-missing
is the default. This may be useful if you have a large package and want to make
       sure that you don't miss installing newly added files in new
       upstream releases. Remember to test different kinds of builds (dpkg-buildpackage
       -A/-B/...) as you may experience varying results when only a
       subset of the packages are built."
202,0,dh_md5sums,"dh_md5sums
is a debhelper program that is responsible for
       generating a
DEBIAN/md5sums
file, which lists the md5sums of each
       file in the package. These files are used by
dpkg --verify
or the
debsums
(1) program. All files in
DEBIAN/
are omitted from the
md5sums
file, as are all
       conffiles (unless you use the
--include-conffiles
switch)."
202,1,dh_md5sums,"These files are used by
dpkg --verify
or the
debsums
(1) program. All files in
DEBIAN/
are omitted from the
md5sums
file, as are all
       conffiles (unless you use the
--include-conffiles
switch). The md5sums file is installed with proper permissions and
       ownerships."
203,0,dh_perl,"dh_perl
is a debhelper program that is responsible for generating
       the
${perl:Depends}
substitutions and adding them to substvars
       files. The program will look at Perl scripts and modules in your package,
       and will use this information to generate a dependency on
perl
or
perlapi
. The dependency will be substituted into your package's
control
file wherever you place the token
${perl:Depends}
."
203,1,dh_perl,"The program will look at Perl scripts and modules in your package,
       and will use this information to generate a dependency on
perl
or
perlapi
. The dependency will be substituted into your package's
control
file wherever you place the token
${perl:Depends}
. dh_perl
also cleans up empty directories that MakeMaker can
       generate when installing Perl modules."
204,0,dh_movetousr,"dh_movetousr
is a
debhelper
program that canonicalizes paths
       inside packages according to merged-/usr. Shipping aliased paths
       is known to cause problems with
dpkg
, so this helper moves all
       affected files to
/usr
regardless of how they were installed. The
       compatibility symlinks ensure that converted packages continue to
       work."
204,1,dh_movetousr,"The
       compatibility symlinks ensure that converted packages continue to
       work. In the process, absolute symbolic links may become relative
       or vice versa due to Debian policy section 10.5. Please keep in mind that moving files in this way is known to
       cause problems."
204,2,dh_movetousr,"Please keep in mind that moving files in this way is known to
       cause problems. Known problems have been documented at
       <
https://people.debian.org/~helmutg/dep17.html
>. For instance, if
       files have been moved between packages, use of this tool may cause
       file loss during upgrades (P1)."
204,3,dh_movetousr,"For instance, if
       files have been moved between packages, use of this tool may cause
       file loss during upgrades (P1). Most problems can be detected by
       <
https://salsa.debian.org/helmutg/dumat
>, which uses the Debian
       bug tracking for feedback. Therefore, it is recommended to upload
       to
experimental
when moving files (e.g."
204,4,dh_movetousr,"Therefore, it is recommended to upload
       to
experimental
when moving files (e.g. using this helper) or
       restructuring packages that earlier moved files. A particular
       problem not being detected is about
dpkg-statoverride
(P5)."
204,5,dh_movetousr,"A particular
       problem not being detected is about
dpkg-statoverride
(P5). Please review uses of
dpkg-statoverride
in maintainer scripts and
       update them as needed. For these reasons,
dh_movetousr
is not
       automatically enabled in e.g."
204,6,dh_movetousr,"For these reasons,
dh_movetousr
is not
       automatically enabled in e.g. a compatibility level. While we want to move files to
/usr
in
trixie
and beyond, we do
       not want to move them in
bookworm
and earlier."
204,7,dh_movetousr,"While we want to move files to
/usr
in
trixie
and beyond, we do
       not want to move them in
bookworm
and earlier. This poses
       challenges to backporting packages, because any such moves have to
       be reverted during the backport. A backport of
debhelper
to
bookworm
shall include a stub for this helper doing nothing to
       achieve this goal."
204,8,dh_movetousr,"A backport of
debhelper
to
bookworm
shall include a stub for this helper doing nothing to
       achieve this goal. For packages that do not need to be backported
       (e.g. packages targeting
forky
and beyond), consider updating
       locations instead of using this helper."
204,9,dh_movetousr,"packages targeting
forky
and beyond), consider updating
       locations instead of using this helper. When the only affected
       type of file is
systemd
units, consider using
dh_installsystemd
or
       detecting the unit location from ""pkgconf
       --variable=systemdsystemunitdir systemd"" instead of this helper as
       both will work in backports. For further information on the state of the transition refer to
       <
https://wiki.debian.org/UsrMerge
>."
204,10,dh_movetousr,"When the only affected
       type of file is
systemd
units, consider using
dh_installsystemd
or
       detecting the unit location from ""pkgconf
       --variable=systemdsystemunitdir systemd"" instead of this helper as
       both will work in backports. For further information on the state of the transition refer to
       <
https://wiki.debian.org/UsrMerge
>. dh_movetousr
shall be removed from
debhelper
during
forky+1
is
       release cycle."
205,0,dh_prep,"dh_prep
is a debhelper program that performs some file cleanups in
       preparation for building a binary package. (This is what
dh_clean
-k
used to do.) It removes the package build directories,
debian/tmp
, and some temp files that are generated when building a
       binary package.

       It is typically run at the top of the
binary-arch
and
binary-indep
targets, or at the top of a target such as install that they
       depend on."
206,0,dh_shlibdeps,"dh_shlibdeps
is a debhelper program that is responsible for
       calculating shared library dependencies for packages.

       This program is merely a wrapper around
dpkg-shlibdeps(1)
that
       calls it once for each package listed in the
control
file, passing
       it a list of ELF executables and shared libraries it has found."
207,0,dh_movefiles,"dh_movefiles
is a debhelper program that is responsible for moving
       files out of
debian/tmp
or some other directory and into other
       package build directories. This may be useful if your package has
       a
Makefile
that installs everything into
debian/tmp
, and you need
       to break that up into subpackages.

       Note:
dh_install
is a much better program, and you are recommended
       to use it instead of
dh_movefiles
."
208,0,dh_strip,"dh_strip
is a debhelper program that is responsible for stripping
       out debug symbols in executables, shared libraries, and static
       libraries that are not needed during execution. This program examines your package build directories and works out
       what to strip on its own. It uses
file(1)
and file permissions and
       filenames to figure out what files are shared libraries (
*.so
),
       executable binaries, and static (
lib*.a
) and debugging libraries
       (
lib*_g.a
,
debug/*.so
), and strips each as much as is possible."
208,1,dh_strip,"It uses
file(1)
and file permissions and
       filenames to figure out what files are shared libraries (
*.so
),
       executable binaries, and static (
lib*.a
) and debugging libraries
       (
lib*_g.a
,
debug/*.so
), and strips each as much as is possible. (Which is not at all for debugging libraries.) In general it seems
       to make very good guesses, and will do the right thing in almost
       all cases. Since it is very hard to automatically guess if a file is a
       module, and hard to determine how to strip a module,
dh_strip
does
       not currently deal with stripping binary modules such as
.o
files."
209,0,dh_systemd_start,"dh_systemd_start
is a debhelper program that is responsible for
       starting/stopping or restarting systemd unit files in case no
       corresponding sysv init script is available.

       As with
dh_installinit
, the unit file is stopped before upgrades
       and started afterwards (unless
--restart-after-upgrade
is
       specified, in which case it will only be restarted after the
       upgrade).  This logic is not used when there is a corresponding
       SysV init script because invoke-rc.d performs the
       stop/start/restart in that case."
210,0,dh_systemd_enable,"dh_systemd_enable
is a debhelper program that is responsible for
       enabling and disabling systemd unit files. In the simple case, it finds all unit files installed by a package
       (e.g. bacula-fd.service) and enables them."
210,1,dh_systemd_enable,"bacula-fd.service) and enables them. It is not necessary
       that the machine actually runs systemd during package installation
       time, enabling happens on all machines in order to be able to
       switch from sysvinit to systemd and back. In the complex case, you can call
dh_systemd_enable
and
dh_systemd_start
manually (by overwriting the debian/rules
       targets) and specify flags per unit file."
210,2,dh_systemd_enable,"In the complex case, you can call
dh_systemd_enable
and
dh_systemd_start
manually (by overwriting the debian/rules
       targets) and specify flags per unit file. An example is colord,
       which ships colord.service, a dbus-activated service without an
       [Install] section. This service file cannot be enabled or disabled
       (a state called ""static"" by systemd) because it has no [Install]
       section."
210,3,dh_systemd_enable,"This service file cannot be enabled or disabled
       (a state called ""static"" by systemd) because it has no [Install]
       section. Therefore, running dh_systemd_enable does not make sense. For only generating blocks for specific service files, you need to
       pass them as arguments, e.g."
210,4,dh_systemd_enable,"Therefore, running dh_systemd_enable does not make sense. For only generating blocks for specific service files, you need to
       pass them as arguments, e.g. dh_systemd_enable quota.service
and
dh_systemd_enable --name=quotarpc quotarpc.service
."
211,0,dh_testroot,"dh_testroot
is used to determine if the target is being run with
       suffient access to root(-like) features. The definition of sufficient access depends on whether the builder
       (the tool invoking the
debian/rules
target) supports the
Rules-
Requires-Root
(RÂ³) field. If the builder supports RÂ³, then it
       will set the environment variable
DEB_RULES_REQUIRES_ROOT
and
dh_testroot
will validate that the builder followed the minimum
       requirements for the given value of
DEB_RULES_REQUIRES_ROOT
."
211,1,dh_testroot,"If the builder supports RÂ³, then it
       will set the environment variable
DEB_RULES_REQUIRES_ROOT
and
dh_testroot
will validate that the builder followed the minimum
       requirements for the given value of
DEB_RULES_REQUIRES_ROOT
. If the builder does not support
Rules-Requires-Root
, then it will
       not set the
DEB_RULES_REQUIRES_ROOT
environment variable. This
       will in turn make
dh_testroot
(and the rest of debhelper) fall
       back to assuming that (fake)root is implied."
211,2,dh_testroot,"This
       will in turn make
dh_testroot
(and the rest of debhelper) fall
       back to assuming that (fake)root is implied. The following is a summary of how
dh_testroot
behaves based on the
DEB_RULES_REQUIRES_ROOT
environment variable (leading and trailing
       whitespace in the variable is ignored). -   If unset, or set to ""binary-targets"", then
dh_testroot
asserts
           that it is run as root or under
fakeroot
(1)."
211,3,dh_testroot,"-   If unset, or set to ""binary-targets"", then
dh_testroot
asserts
           that it is run as root or under
fakeroot
(1). -   If set to ""no"", then
dh_testroot
returns successfully (without
           performing any additional checks). -   If set to any other value than the above, then
dh_testroot
asserts that it is either run as root (or under
fakeroot
(1))
           or the builder has provided the
DEB_GAIN_ROOT_CMD
environment
           variable (e.g."
211,4,dh_testroot,"-   If set to any other value than the above, then
dh_testroot
asserts that it is either run as root (or under
fakeroot
(1))
           or the builder has provided the
DEB_GAIN_ROOT_CMD
environment
           variable (e.g. via dpkg-buildpackage -r). Please note that
dh_testroot
does
not
read the
Rules-Requires-Root
field."
211,5,dh_testroot,"Please note that
dh_testroot
does
not
read the
Rules-Requires-Root
field. Which implies that
dh_testroot
may produce incorrect
       result if the builder lies in
DEB_RULES_REQUIRES_ROOT
. On the
       flip side, it also enables things like testing for what will
       happen when
DEB_RULES_REQUIRES_ROOT
is set to a given value."
212,0,dh_testdir,"dh_testdir
tries to make sure that you are in the correct
       directory when building a Debian package. It makes sure that the
       file
debian/control
exists, as well as any other files you
       specify. If not, it exits with an error."
213,0,dh_ucf,"dh_ucf
is a debhelper program that is responsible for generating
       the
postinst
and
postrm
commands that register files with
ucf
(1)
       and
ucfr
(1)."
214,0,dh_update_autotools_config,"dh_update_autotools_config
replaces all occurrences of
config.sub
and
config.guess
in the source tree by the up-to-date versions
       found in the autotools-dev package.  The original files are backed
       up and restored by
dh_clean
."
215,0,dh_usrlocal,"dh_usrlocal
is a debhelper program that can be used for building
       packages that will provide a subdirectory in
/usr/local
when
       installed. It finds subdirectories of
usr/local
in the package build
       directory, and removes them, replacing them with maintainer script
       snippets (unless
-n
is used) to create the directories at install
       time, and remove them when the package is removed, in a manner
       compliant with Debian policy. These snippets are inserted into the
       maintainer scripts by
dh_installdeb
."
215,1,dh_usrlocal,"These snippets are inserted into the
       maintainer scripts by
dh_installdeb
. See
dh_installdeb(1)
for an
       explanation of debhelper maintainer script snippets. When the
DEB_RULES_REQUIRES_ROOT
environment variable is not
       (effectively)
binary-targets
, the directories in
/usr/local
will
       be handled as if they were owned by root:root (see below)."
215,2,dh_usrlocal,"When the
DEB_RULES_REQUIRES_ROOT
environment variable is not
       (effectively)
binary-targets
, the directories in
/usr/local
will
       be handled as if they were owned by root:root (see below). When the
DEB_RULES_REQUIRES_ROOT
environment variable has an
       effective value of
binary-targets
, the owners, groups and
       permissions will be preserved with the sole exception where the
       directory is owned by root:root. If a directory is owned by root:root, then ownership will be
       determined at install time."
215,3,dh_usrlocal,"If a directory is owned by root:root, then ownership will be
       determined at install time. The ownership and permission bits
       will either be root:root mode 0755 or root:staff mode 02775. The
       actual choice depends on whether the system has
/etc/staff-group-for-usr-local
(as documented in the Debian Policy
       Manual Â§9.1.2 since version 4.1.4)"
216,0,diff,"Compare FILES line by line. Mandatory arguments to long options are mandatory for short
       options too. --normal
output a normal diff (the default)
-q
,
--brief
report only when files differ
-s
,
--report-identical-files
report when two files are the same
-c
,
-C
NUM,
--context
[=
NUM
]
              output NUM (default 3) lines of copied context
-u
,
-U
NUM,
--unified
[=
NUM
]
              output NUM (default 3) lines of unified context
-e
,
--ed
output an ed script
-n
,
--rcs
output an RCS format diff
-y
,
--side-by-side
output in two columns
-W
,
--width
=
NUM
output at most NUM (default 130) print columns
--left-column
output only the left column of common lines
--suppress-common-lines
do not output common lines
-p
,
--show-c-function
show which C function each change is in
-F
,
--show-function-line
=
RE
show the most recent line matching RE
--label
LABEL
              use LABEL instead of file name and timestamp (can be
              repeated)
-t
,
--expand-tabs
expand tabs to spaces in output
-T
,
--initial-tab
make tabs line up by prepending a tab
--tabsize
=
NUM
tab stops every NUM (default 8) print columns
--suppress-blank-empty
suppress space or tab before empty output lines
-l
,
--paginate
pass output through 'pr' to paginate it
-r
,
--recursive
recursively compare any subdirectories found
--no-dereference
don't follow symbolic links
-N
,
--new-file
treat absent files as empty
--unidirectional-new-file
treat absent first files as empty
--ignore-file-name-case
ignore case when comparing file names
--no-ignore-file-name-case
consider case when comparing file names
-x
,
--exclude
=
PAT
exclude files that match PAT
-X
,
--exclude-from
=
FILE
exclude files that match any pattern in FILE
-S
,
--starting-file
=
FILE
start with FILE when comparing directories
--from-file
=
FILE1
compare FILE1 to all operands; FILE1 can be a directory
--to-file
=
FILE2
compare all operands to FILE2; FILE2 can be a directory
-i
,
--ignore-case
ignore case differences in file contents
-E
,
--ignore-tab-expansion
ignore changes due to tab expansion
-Z
,
--ignore-trailing-space
ignore white space at line end
-b
,
--ignore-space-change
ignore changes in the amount of white space
-w
,
--ignore-all-space
ignore all white space
-B
,
--ignore-blank-lines
ignore changes where lines are all blank
-I
,
--ignore-matching-lines
=
RE
ignore changes where all lines match RE
-a
,
--text
treat all files as text
--strip-trailing-cr
strip trailing carriage return on input
-D
,
--ifdef
=
NAME
output merged file with '#ifdef NAME' diffs
--GTYPE-group-format
=
GFMT
format GTYPE input groups with GFMT
--line-format
=
LFMT
format all input lines with LFMT
--LTYPE-line-format
=
LFMT
format LTYPE input lines with LFMT

              These format options provide fine-grained control over the
              output

              of diff, generalizing
-D
/--ifdef."
216,1,diff,"--normal
output a normal diff (the default)
-q
,
--brief
report only when files differ
-s
,
--report-identical-files
report when two files are the same
-c
,
-C
NUM,
--context
[=
NUM
]
              output NUM (default 3) lines of copied context
-u
,
-U
NUM,
--unified
[=
NUM
]
              output NUM (default 3) lines of unified context
-e
,
--ed
output an ed script
-n
,
--rcs
output an RCS format diff
-y
,
--side-by-side
output in two columns
-W
,
--width
=
NUM
output at most NUM (default 130) print columns
--left-column
output only the left column of common lines
--suppress-common-lines
do not output common lines
-p
,
--show-c-function
show which C function each change is in
-F
,
--show-function-line
=
RE
show the most recent line matching RE
--label
LABEL
              use LABEL instead of file name and timestamp (can be
              repeated)
-t
,
--expand-tabs
expand tabs to spaces in output
-T
,
--initial-tab
make tabs line up by prepending a tab
--tabsize
=
NUM
tab stops every NUM (default 8) print columns
--suppress-blank-empty
suppress space or tab before empty output lines
-l
,
--paginate
pass output through 'pr' to paginate it
-r
,
--recursive
recursively compare any subdirectories found
--no-dereference
don't follow symbolic links
-N
,
--new-file
treat absent files as empty
--unidirectional-new-file
treat absent first files as empty
--ignore-file-name-case
ignore case when comparing file names
--no-ignore-file-name-case
consider case when comparing file names
-x
,
--exclude
=
PAT
exclude files that match PAT
-X
,
--exclude-from
=
FILE
exclude files that match any pattern in FILE
-S
,
--starting-file
=
FILE
start with FILE when comparing directories
--from-file
=
FILE1
compare FILE1 to all operands; FILE1 can be a directory
--to-file
=
FILE2
compare all operands to FILE2; FILE2 can be a directory
-i
,
--ignore-case
ignore case differences in file contents
-E
,
--ignore-tab-expansion
ignore changes due to tab expansion
-Z
,
--ignore-trailing-space
ignore white space at line end
-b
,
--ignore-space-change
ignore changes in the amount of white space
-w
,
--ignore-all-space
ignore all white space
-B
,
--ignore-blank-lines
ignore changes where lines are all blank
-I
,
--ignore-matching-lines
=
RE
ignore changes where all lines match RE
-a
,
--text
treat all files as text
--strip-trailing-cr
strip trailing carriage return on input
-D
,
--ifdef
=
NAME
output merged file with '#ifdef NAME' diffs
--GTYPE-group-format
=
GFMT
format GTYPE input groups with GFMT
--line-format
=
LFMT
format all input lines with LFMT
--LTYPE-line-format
=
LFMT
format LTYPE input lines with LFMT

              These format options provide fine-grained control over the
              output

              of diff, generalizing
-D
/--ifdef. LTYPE is 'old', 'new', or 'unchanged'. GTYPE is LTYPE or 'changed'."
216,2,diff,"GTYPE is LTYPE or 'changed'. GFMT (only) may contain:

       %<     lines from FILE1

       %>     lines from FILE2

       %=     lines common to FILE1 and FILE2

       %[-][WIDTH][.[PREC]]{doxX}LETTER
              printf-style spec for LETTER

              LETTERs are as follows for new group, lower case for old
              group:

       F      first line number

       L      last line number

       N      number of lines = L-F+1

       E      F-1

       M      L+1

       %(A=B?T:E)
              if A equals B then T else E

              LFMT (only) may contain:

       %L     contents of line

       %l     contents of line, excluding any trailing newline

       %[-][WIDTH][.[PREC]]{doxX}n
              printf-style spec for input line number

              Both GFMT and LFMT may contain:

       %%     %

       %c'C'  the single character C

       %c'\OOO'
              the character with octal code OOO

       C      the character C (other characters represent themselves)
-d
,
--minimal
try hard to find a smaller set of changes
--horizon-lines
=
NUM
keep NUM lines of the common prefix and suffix
--speed-large-files
assume large files and many scattered small changes
--color
[=
WHEN
]
              color output; WHEN is 'never', 'always', or 'auto'; plain
--color
means
--color=
'auto'
--palette
=
PALETTE
the colors to use when
--color
is active; PALETTE is a
              colon-separated list of terminfo capabilities
--help
display this help and exit
-v
,
--version
output version information and exit

       FILES are 'FILE1 FILE2' or 'DIR1 DIR2' or 'DIR FILE' or 'FILE
       DIR'. If
--from-file
or
--to-file
is given, there are no
       restrictions on FILE(s)."
216,3,diff,"If
--from-file
or
--to-file
is given, there are no
       restrictions on FILE(s). If a FILE is '-', read standard input. Exit status is 0 if inputs are the same, 1 if different, 2 if
       trouble."
217,0,diff,"The
diff
utility shall compare the contents of
file1
and
file2
and
       write to standard output a list of changes necessary to convert
file1
into
file2
.  This list should be minimal. No output shall be
       produced if the files are identical."
218,0,diff3,"Compare three files line by line. Mandatory arguments to long options are mandatory for short
       options too. -A
,
--show-all
output all changes, bracketing conflicts
-e
,
--ed
output ed script incorporating changes from OLDFILE to
              YOURFILE into MYFILE
-E
,
--show-overlap
like
-e
, but bracket conflicts
-3
,
--easy-only
like
-e
, but incorporate only nonoverlapping changes
-x
,
--overlap-only
like
-e
, but incorporate only overlapping changes
-X
like
-x
, but bracket conflicts
-i
append 'w' and 'q' commands to ed scripts
-m
,
--merge
output actual merged file, according to
-A
if no other
              options are given
-a
,
--text
treat all files as text
--strip-trailing-cr
strip trailing carriage return on input
-T
,
--initial-tab
make tabs line up by prepending a tab
--diff-program
=
PROGRAM
use PROGRAM to compare files
-L
,
--label
=
LABEL
use LABEL instead of file name (can be repeated up to three
              times)
--help
display this help and exit
-v
,
--version
output version information and exit

       The default output format is a somewhat human-readable
       representation of the changes."
218,1,diff3,"-A
,
--show-all
output all changes, bracketing conflicts
-e
,
--ed
output ed script incorporating changes from OLDFILE to
              YOURFILE into MYFILE
-E
,
--show-overlap
like
-e
, but bracket conflicts
-3
,
--easy-only
like
-e
, but incorporate only nonoverlapping changes
-x
,
--overlap-only
like
-e
, but incorporate only overlapping changes
-X
like
-x
, but bracket conflicts
-i
append 'w' and 'q' commands to ed scripts
-m
,
--merge
output actual merged file, according to
-A
if no other
              options are given
-a
,
--text
treat all files as text
--strip-trailing-cr
strip trailing carriage return on input
-T
,
--initial-tab
make tabs line up by prepending a tab
--diff-program
=
PROGRAM
use PROGRAM to compare files
-L
,
--label
=
LABEL
use LABEL instead of file name (can be repeated up to three
              times)
--help
display this help and exit
-v
,
--version
output version information and exit

       The default output format is a somewhat human-readable
       representation of the changes. The
-e
,
-E
,
-x
,
-X
(and corresponding long) options cause an ed
       script to be output instead of the default. Finally, the
-m
(
--merge
) option causes diff3 to do the merge
       internally and output the actual merged file."
218,2,diff3,"Finally, the
-m
(
--merge
) option causes diff3 to do the merge
       internally and output the actual merged file. For unusual input,
       this is more robust than using ed. If a FILE is '-', read standard input."
218,3,diff3,"For unusual input,
       this is more robust than using ed. If a FILE is '-', read standard input. Exit status is 0 if
       successful, 1 if conflicts, 2 if trouble."
219,0,dir,"List information about the FILEs (the current directory by
       default). Sort entries alphabetically if none of
-cftuvSUX
nor
--sort
is specified. Mandatory arguments to long options are mandatory for short
       options too."
219,1,dir,"Mandatory arguments to long options are mandatory for short
       options too. -a
,
--all
do not ignore entries starting with . -A
,
--almost-all
do not list implied ."
219,2,dir,"-A
,
--almost-all
do not list implied . and .. --author
with
-l
, print the author of each file
-b
,
--escape
print C-style escapes for nongraphic characters
--block-size
=
SIZE
with
-l
, scale sizes by SIZE when printing them; e.g.,
              '--block-size=M'; see SIZE format below
-B
,
--ignore-backups
do not list implied entries ending with ~
-c
with
-lt
: sort by, and show, ctime (time of last change of
              file status information); with
-l
: show ctime and sort by
              name; otherwise: sort by ctime, newest first
-C
list entries by columns
--color
[=
WHEN
]
              color the output WHEN; more info below
-d
,
--directory
list directories themselves, not their contents
-D
,
--dired
generate output designed for Emacs' dired mode
-f
same as
-a -U
-F
,
--classify
[=
WHEN
]
              append indicator (one of */=>@|) to entries WHEN
--file-type
likewise, except do not append '*'
--format
=
WORD
across
-x
, commas
-m
, horizontal
-x
, long
-l
, single-column
-1
, verbose
-l
, vertical
-C
--full-time
like
-l --time-style
=
full-iso
-g
like
-l
, but do not list owner
--group-directories-first
group directories before files
-G
,
--no-group
in a long listing, don't print group names
-h
,
--human-readable
with
-l
and
-s
, print sizes like 1K 234M 2G etc."
219,3,dir,"--author
with
-l
, print the author of each file
-b
,
--escape
print C-style escapes for nongraphic characters
--block-size
=
SIZE
with
-l
, scale sizes by SIZE when printing them; e.g.,
              '--block-size=M'; see SIZE format below
-B
,
--ignore-backups
do not list implied entries ending with ~
-c
with
-lt
: sort by, and show, ctime (time of last change of
              file status information); with
-l
: show ctime and sort by
              name; otherwise: sort by ctime, newest first
-C
list entries by columns
--color
[=
WHEN
]
              color the output WHEN; more info below
-d
,
--directory
list directories themselves, not their contents
-D
,
--dired
generate output designed for Emacs' dired mode
-f
same as
-a -U
-F
,
--classify
[=
WHEN
]
              append indicator (one of */=>@|) to entries WHEN
--file-type
likewise, except do not append '*'
--format
=
WORD
across
-x
, commas
-m
, horizontal
-x
, long
-l
, single-column
-1
, verbose
-l
, vertical
-C
--full-time
like
-l --time-style
=
full-iso
-g
like
-l
, but do not list owner
--group-directories-first
group directories before files
-G
,
--no-group
in a long listing, don't print group names
-h
,
--human-readable
with
-l
and
-s
, print sizes like 1K 234M 2G etc. --si
likewise, but use powers of 1000 not 1024
-H
,
--dereference-command-line
follow symbolic links listed on the command line
--dereference-command-line-symlink-to-dir
follow each command line symbolic link that points to a
              directory
--hide
=
PATTERN
do not list implied entries matching shell PATTERN
              (overridden by
-a
or
-A
)
--hyperlink
[=
WHEN
]
              hyperlink file names WHEN
--indicator-style
=
WORD
append indicator with style WORD to entry names: none
              (default), slash (
-p
), file-type (
--file-type
), classify
              (
-F
)
-i
,
--inode
print the index number of each file
-I
,
--ignore
=
PATTERN
do not list implied entries matching shell PATTERN
-k
,
--kibibytes
default to 1024-byte blocks for file system usage; used
              only with
-s
and per directory totals
-l
use a long listing format
-L
,
--dereference
when showing file information for a symbolic link, show
              information for the file the link references rather than
              for the link itself
-m
fill width with a comma separated list of entries
-n
,
--numeric-uid-gid
like
-l
, but list numeric user and group IDs
-N
,
--literal
print entry names without quoting
-o
like
-l
, but do not list group information
-p
,
--indicator-style
=
slash
append / indicator to directories
-q
,
--hide-control-chars
print ? instead of nongraphic characters
--show-control-chars
show nongraphic characters as-is (the default, unless
              program is 'ls' and output is a terminal)
-Q
,
--quote-name
enclose entry names in double quotes
--quoting-style
=
WORD
use quoting style WORD for entry names: literal, locale,
              shell, shell-always, shell-escape, shell-escape-always, c,
              escape (overrides QUOTING_STYLE environment variable)
-r
,
--reverse
reverse order while sorting
-R
,
--recursive
list subdirectories recursively
-s
,
--size
print the allocated size of each file, in blocks
-S
sort by file size, largest first
--sort
=
WORD
change default 'name' sort to WORD: none (
-U
), size (
-S
),
              time (
-t
), version (
-v
), extension (
-X
), name, width
--time
=
WORD
select which timestamp used to display or sort; access time
              (
-u
): atime, access, use; metadata change time (
-c
): ctime,
              status; modified time (default): mtime, modification; birth
              time: birth, creation;

              with
-l
, WORD determines which time to show; with
--sort
=
time
, sort by WORD (newest first)
--time-style
=
TIME_STYLE
time/date format with
-l
; see TIME_STYLE below
-t
sort by time, newest first; see
--time
-T
,
--tabsize
=
COLS
assume tab stops at each COLS instead of 8
-u
with
-lt
: sort by, and show, access time; with
-l
: show
              access time and sort by name; otherwise: sort by access
              time, newest first
-U
do not sort directory entries
-v
natural sort of (version) numbers within text
-w
,
--width
=
COLS
set output width to COLS."
219,4,dir,"instead of nongraphic characters
--show-control-chars
show nongraphic characters as-is (the default, unless
              program is 'ls' and output is a terminal)
-Q
,
--quote-name
enclose entry names in double quotes
--quoting-style
=
WORD
use quoting style WORD for entry names: literal, locale,
              shell, shell-always, shell-escape, shell-escape-always, c,
              escape (overrides QUOTING_STYLE environment variable)
-r
,
--reverse
reverse order while sorting
-R
,
--recursive
list subdirectories recursively
-s
,
--size
print the allocated size of each file, in blocks
-S
sort by file size, largest first
--sort
=
WORD
change default 'name' sort to WORD: none (
-U
), size (
-S
),
              time (
-t
), version (
-v
), extension (
-X
), name, width
--time
=
WORD
select which timestamp used to display or sort; access time
              (
-u
): atime, access, use; metadata change time (
-c
): ctime,
              status; modified time (default): mtime, modification; birth
              time: birth, creation;

              with
-l
, WORD determines which time to show; with
--sort
=
time
, sort by WORD (newest first)
--time-style
=
TIME_STYLE
time/date format with
-l
; see TIME_STYLE below
-t
sort by time, newest first; see
--time
-T
,
--tabsize
=
COLS
assume tab stops at each COLS instead of 8
-u
with
-lt
: sort by, and show, access time; with
-l
: show
              access time and sort by name; otherwise: sort by access
              time, newest first
-U
do not sort directory entries
-v
natural sort of (version) numbers within text
-w
,
--width
=
COLS
set output width to COLS. 0 means no limit
-x
list entries by lines instead of by columns
-X
sort alphabetically by entry extension
-Z
,
--context
print any security context of each file
--zero
end each output line with NUL, not newline
-1
list one file per line
--help
display this help and exit
--version
output version information and exit

       The SIZE argument is an integer and optional unit (example: 10K is
       10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,..."
219,5,dir,"Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,... (powers of 1000). Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on."
219,6,dir,"Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on. The TIME_STYLE argument can be full-iso, long-iso, iso, locale, or
       +FORMAT. FORMAT is interpreted like in
date(1)
."
219,7,dir,"FORMAT is interpreted like in
date(1)
. If FORMAT is
       FORMAT1<newline>FORMAT2, then FORMAT1 applies to non-recent files
       and FORMAT2 to recent files. TIME_STYLE prefixed with 'posix-'
       takes effect only outside the POSIX locale."
219,8,dir,"TIME_STYLE prefixed with 'posix-'
       takes effect only outside the POSIX locale. Also the TIME_STYLE
       environment variable sets the default style to use. The WHEN argument defaults to 'always' and can also be 'auto' or
       'never'."
219,9,dir,"The WHEN argument defaults to 'always' and can also be 'auto' or
       'never'. Using color to distinguish file types is disabled both by default
       and with
--color
=
never
. With
--color
=
auto
, ls emits color codes
       only when standard output is connected to a terminal."
219,10,dir,"With
--color
=
auto
, ls emits color codes
       only when standard output is connected to a terminal. The
       LS_COLORS environment variable can change the settings. Use the
dircolors(1)
command to set it."
219,11,dir,"The
       LS_COLORS environment variable can change the settings. Use the
dircolors(1)
command to set it. Exit status:
0      if OK,

       1      if minor problems (e.g., cannot access subdirectory),

       2      if serious trouble (e.g., cannot access command-line
              argument)."
220,0,diffman-git,"The
diffman-git
command formats a manual page at two
git(1)
commits, and then runs
diff(1)
on the formatted outputs.

       If the
commit
is not specified, it diffs the working directory
       against HEAD.

       If the
base-commit
is not specified, the comparison is done
       against the previous commit."
221,0,dircolors,"Output commands to set the LS_COLORS environment variable. Determine format of output:
-b
,
--sh
,
--bourne-shell
output Bourne shell code to set LS_COLORS
-c
,
--csh
,
--c-shell
output C shell code to set LS_COLORS
-p
,
--print-database
output defaults
--print-ls-colors
output fully escaped colors for display
--help
display this help and exit
--version
output version information and exit

       If FILE is specified, read it to determine which colors to use for
       which file types and extensions. Otherwise, a precompiled
       database is used."
221,1,dircolors,"Determine format of output:
-b
,
--sh
,
--bourne-shell
output Bourne shell code to set LS_COLORS
-c
,
--csh
,
--c-shell
output C shell code to set LS_COLORS
-p
,
--print-database
output defaults
--print-ls-colors
output fully escaped colors for display
--help
display this help and exit
--version
output version information and exit

       If FILE is specified, read it to determine which colors to use for
       which file types and extensions. Otherwise, a precompiled
       database is used. For details on the format of these files, run
       'dircolors
--print-database
'."
222,0,dirname,"Output each NAME with its last non-slash component and trailing
       slashes removed; if NAME contains no /'s, output '.' (meaning the
       current directory).
-z
,
--zero
end each output line with NUL, not newline
--help
display this help and exit
--version
output version information and exit"
223,0,dirname,"The
string
operand shall be treated as a pathname, as defined in
       the Base Definitions volume of POSIX.1â2017,
Section 3.271
,
Pathname
. The string
string
shall be converted to the name of the
       directory containing the filename corresponding to the last
       pathname component in
string
, performing actions equivalent to the
       following steps in order:

        1. If
string
is
//
, skip steps 2 to 5."
223,1,dirname,"If
string
is
//
, skip steps 2 to 5. 2. If
string
consists entirely of <slash> characters,
string
shall be set to a single <slash> character."
223,2,dirname,"If
string
consists entirely of <slash> characters,
string
shall be set to a single <slash> character. In this case, skip
           steps 3 to 8. 3."
223,3,dirname,"3. If there are any trailing <slash> characters in
string
, they
           shall be removed. 4."
223,4,dirname,"4. If there are no <slash> characters remaining in
string
,
string
shall be set to a single <period> character. In this case,
           skip steps 5 to 8."
223,5,dirname,"In this case,
           skip steps 5 to 8. 5. If there are any trailing non-<slash> characters in
string
,
           they shall be removed."
223,6,dirname,"If there are any trailing non-<slash> characters in
string
,
           they shall be removed. 6. If the remaining
string
is
//
, it is implementation-defined
           whether steps 7 and 8 are skipped or processed."
223,7,dirname,"If the remaining
string
is
//
, it is implementation-defined
           whether steps 7 and 8 are skipped or processed. 7. If there are any trailing <slash> characters in
string
, they
           shall be removed."
223,8,dirname,"If there are any trailing <slash> characters in
string
, they
           shall be removed. 8. If the remaining
string
is empty,
string
shall be set to a
           single <slash> character."
223,9,dirname,"8. If the remaining
string
is empty,
string
shall be set to a
           single <slash> character. The resulting string shall be written to standard output."
224,0,dkvis,"dkvis
displays a three dimensional bar chart of disk activity. Each row of bars on the base plane represents a disk controller
       (or host adapter, or bus), and the bars within a row correspond to
       the disks attached to the controller. The label to the left of each row identifies the common part of
       disk name for all disks in that row, e.g."
224,1,dkvis,"The label to the left of each row identifies the common part of
       disk name for all disks in that row, e.g. dks3
for all IRIX SCSI
       disks attached to controller number 3. The height of the bars is proportional to the activity."
224,2,dkvis,"The height of the bars is proportional to the activity. The user can specify a list of disks as
diskid
arguments using the
       disk naming scheme reported by
          $ pminfo -f disk.dev.total
       e.g. hda
or
dks0d4
or
sda
or
scsi/host1/bus0/target4/lun0/disc
or
20000080e5114459/lun3/c2p1
depending on the type of disks."
224,3,dkvis,"hda
or
dks0d4
or
sda
or
scsi/host1/bus0/target4/lun0/disc
or
20000080e5114459/lun3/c2p1
depending on the type of disks. Alternatively, if the
diskid
argument contains one of the
       characters
^
or
. or
[
then
diskid
will be treated as a regular
       expression in the style of
egrep
(1) and the matching set of disk
       names will be used instead of
diskid
."
224,4,dkvis,"or
[
then
diskid
will be treated as a regular
       expression in the style of
egrep
(1) and the matching set of disk
       names will be used instead of
diskid
. If one or more
diskid
arguments is specified, only the disks in
       this list are displayed in the view. The disks are grouped in the
       scene by controller as in the default scene when all disks are
       present."
224,5,dkvis,"The disks are grouped in the
       scene by controller as in the default scene when all disks are
       present. dkvis
generates a
pmview(1)
configuration file, and passes most
       command line options to
pmview(1)
. Therefore, the command line
       options
-A
,
-a
,
-C
,
-h
,
-n
,
-O
,
-p
,
-S
,
-t
,
-T
,
-Z
and
-z
, and the
       user interface are described in the
pmview(1)
man page."
225,0,dmesg,"dmesg
is used to examine or control the kernel ring buffer.

       The default action is to display all messages from the kernel ring
       buffer."
226,0,hostname,"Hostname
is the program that is used to either set or display the
       current host, domain or node name of the system. These names are
       used by many of the networking programs to identify the machine. The domain name is also used by NIS/YP."
226,1,hostname,"The domain name is also used by NIS/YP. GET NAME
When called without any arguments, the program displays the
       current names:
hostname
will print the name of the system as returned by the
gethostname(2)
function. domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function."
226,2,hostname,"domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function. This is also
       known as the YP/NIS domain name of the system. nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function."
226,3,hostname,"nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function. dnsdomainname
will print the domain part of the FQDN (Fully
       Qualified Domain Name). The complete FQDN of the system is
       returned with
hostname --fqdn
."
226,4,hostname,"The complete FQDN of the system is
       returned with
hostname --fqdn
. SET NAME
When called with one argument or with the
--file
option, the
       commands set the host name, the NIS/YP domain name or the node
       name. Note, that only the super-user can change the names."
226,5,hostname,"Note, that only the super-user can change the names. It is not possible to set the FQDN or the DNS domain name with the
dnsdomainname
command (see
THE FQDN
below). The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g."
226,6,hostname,"The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g. /etc/hostname
). THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command."
226,7,hostname,"THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command. The FQDN of the system is the name that the
resolver(3)
returns
       for the host name. Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name."
226,8,hostname,"Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name. The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it."
226,9,hostname,"The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it. If
hosts
is the first
       lookup method, you can change the FQDN in
/etc/hosts
."
227,0,dlltool,"dlltool
reads its inputs, which can come from the
-d
and
-b
options as well as object files specified on the command line. It
       then processes these inputs and if the
-e
option has been
       specified it creates a exports file. If the
-l
option has been
       specified it creates a library file and if the
-z
option has been
       specified it creates a def file."
227,1,dlltool,"If the
-l
option has been
       specified it creates a library file and if the
-z
option has been
       specified it creates a def file. Any or all of the
-e
,
-l
and
-z
options can be present in one invocation of dlltool. When creating a DLL, along with the source for the DLL, it is
       necessary to have three other files."
227,2,dlltool,"When creating a DLL, along with the source for the DLL, it is
       necessary to have three other files. dlltool
can help with the
       creation of these files. The first file is a
.def
file which specifies which functions are
       exported from the DLL, which functions the DLL imports, and so on."
227,3,dlltool,"The first file is a
.def
file which specifies which functions are
       exported from the DLL, which functions the DLL imports, and so on. This is a text file and can be created by hand, or
dlltool
can be
       used to create it using the
-z
option. In this case
dlltool
will
       scan the object files specified on its command line looking for
       those functions which have been specially marked as being exported
       and put entries for them in the
.def
file it creates."
227,4,dlltool,"In this case
dlltool
will
       scan the object files specified on its command line looking for
       those functions which have been specially marked as being exported
       and put entries for them in the
.def
file it creates. In order to mark a function as being exported from a DLL, it needs
       to have an
-export:<name_of_function>
entry in the
.drectve
section of the object file. This can be done in C by using the
asm()
operator:

                 asm ("".section .drectve"");
                 asm ("".ascii \""-export:my_func\"""");

                 int my_func (void) { ..."
227,5,dlltool,"This can be done in C by using the
asm()
operator:

                 asm ("".section .drectve"");
                 asm ("".ascii \""-export:my_func\"""");

                 int my_func (void) { ... }

       The second file needed for DLL creation is an exports file. This
       file is linked with the object files that make up the body of the
       DLL and it handles the interface between the DLL and the outside
       world."
227,6,dlltool,"This
       file is linked with the object files that make up the body of the
       DLL and it handles the interface between the DLL and the outside
       world. This is a binary file and it can be created by giving the
-e
option to
dlltool
when it is creating or reading in a
.def
file. The third file needed for DLL creation is the library file that
       programs will link with in order to access the functions in the
       DLL (an `import library')."
227,7,dlltool,"The third file needed for DLL creation is the library file that
       programs will link with in order to access the functions in the
       DLL (an `import library'). This file can be created by giving the
-l
option to dlltool when it is creating or reading in a
.def
file. If the
-y
option is specified, dlltool generates a delay-import
       library that can be used instead of the normal import library to
       allow a program to link to the dll only as soon as an imported
       function is called for the first time."
227,8,dlltool,"If the
-y
option is specified, dlltool generates a delay-import
       library that can be used instead of the normal import library to
       allow a program to link to the dll only as soon as an imported
       function is called for the first time. The resulting executable
       will need to be linked to the static delayimp library containing
       _
_delayLoadHelper2()
, which in turn will import LoadLibraryA and
       GetProcAddress from kernel32. dlltool
builds the library file by hand, but it builds the exports
       file by creating temporary files containing assembler statements
       and then assembling these."
227,9,dlltool,"dlltool
builds the library file by hand, but it builds the exports
       file by creating temporary files containing assembler statements
       and then assembling these. The
-S
command-line option can be used
       to specify the path to the assembler that dlltool will use, and
       the
-f
option can be used to pass specific flags to that
       assembler. The
-n
can be used to prevent dlltool from deleting
       these temporary assembler files when it is done, and if
-n
is
       specified twice then this will prevent dlltool from deleting the
       temporary object files it used to build the library."
227,10,dlltool,"The
-n
can be used to prevent dlltool from deleting
       these temporary assembler files when it is done, and if
-n
is
       specified twice then this will prevent dlltool from deleting the
       temporary object files it used to build the library. Here is an example of creating a DLL from a source file
dll.c
and
       also creating a program (from an object file called
program.o
)
       that uses that DLL:

                 gcc -c dll.c
                 dlltool -e exports.o -l dll.lib dll.o
                 gcc dll.o exports.o -o dll.dll
                 gcc program.o dll.lib -o program
dlltool
may also be used to query an existing import library to
       determine the name of the DLL to which it is associated. See the
       description of the
-I
or
--identify
option."
228,0,hostname,"Hostname
is the program that is used to either set or display the
       current host, domain or node name of the system. These names are
       used by many of the networking programs to identify the machine. The domain name is also used by NIS/YP."
228,1,hostname,"The domain name is also used by NIS/YP. GET NAME
When called without any arguments, the program displays the
       current names:
hostname
will print the name of the system as returned by the
gethostname(2)
function. domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function."
228,2,hostname,"domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function. This is also
       known as the YP/NIS domain name of the system. nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function."
228,3,hostname,"nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function. dnsdomainname
will print the domain part of the FQDN (Fully
       Qualified Domain Name). The complete FQDN of the system is
       returned with
hostname --fqdn
."
228,4,hostname,"The complete FQDN of the system is
       returned with
hostname --fqdn
. SET NAME
When called with one argument or with the
--file
option, the
       commands set the host name, the NIS/YP domain name or the node
       name. Note, that only the super-user can change the names."
228,5,hostname,"Note, that only the super-user can change the names. It is not possible to set the FQDN or the DNS domain name with the
dnsdomainname
command (see
THE FQDN
below). The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g."
228,6,hostname,"The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g. /etc/hostname
). THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command."
228,7,hostname,"THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command. The FQDN of the system is the name that the
resolver(3)
returns
       for the host name. Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name."
228,8,hostname,"Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name. The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it."
228,9,hostname,"The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it. If
hosts
is the first
       lookup method, you can change the FQDN in
/etc/hosts
."
229,0,dot,"The shell shall execute commands from the
file
in the current
       environment. If
file
does not contain a <slash>, the shell shall use the search
       path specified by
PATH
to find the directory containing
file
. Unlike normal command search, however, the file searched for by
       the
dot
utility need not be executable."
229,1,dot,"If
file
does not contain a <slash>, the shell shall use the search
       path specified by
PATH
to find the directory containing
file
. Unlike normal command search, however, the file searched for by
       the
dot
utility need not be executable. If no readable file is
       found, a non-interactive shell shall abort; an interactive shell
       shall write a diagnostic message to standard error, but this
       condition shall not be considered a syntax error."
230,0,dpkg-architecture,"dpkg-architecture
provides a facility to determine and set the
       build and host architecture for package building. The build architecture is always determined by either the
DEB_BUILD_ARCH
variable if set (and
--force
not being specified)
       or by an external call to
dpkg(1)
, and cannot be set at the
       command line. You can specify the host architecture by providing one or both of
       the options
--host-arch
and
--host-type
, otherwise the
DEB_HOST_ARCH
variable is used if set (and
--force
not being
       specified)."
230,1,dpkg-architecture,"You can specify the host architecture by providing one or both of
       the options
--host-arch
and
--host-type
, otherwise the
DEB_HOST_ARCH
variable is used if set (and
--force
not being
       specified). The default is determined by an external call to
gcc(1)
, or the same as the build architecture if
CC
or gcc are
       both not available. One out of
--host-arch
and
--host-type
is
       sufficient, the value of the other will be set to a usable
       default."
230,2,dpkg-architecture,"The default is determined by an external call to
gcc(1)
, or the same as the build architecture if
CC
or gcc are
       both not available. One out of
--host-arch
and
--host-type
is
       sufficient, the value of the other will be set to a usable
       default. Indeed, it is often better to only specify one, because
dpkg-architecture
will warn you if your choice does not match the
       default."
231,0,dpkg-buildapi,"dpkg-buildapi
is a tool to retrieve the
dpkg-build-api(7)
level to
       use during build of source Debian packages.

       This program was introduced in dpkg 1.22.0."
232,0,dpkg-buildtree,"dpkg-buildtree
is a tool to perform common operations on the build
       tree for a source package.

       This program was introduced in dpkg 1.22.3."
233,0,dpkg-buildpackage,"dpkg-buildpackage
is a program that automates the process of
       building a Debian package. The
filename
.dsc and
directory
arguments are supported since dpkg
       1.22.7. Their semantics are experimental."
233,1,dpkg-buildpackage,"Their semantics are experimental. It consists of the following steps:
1. It runs the
preinit
hook before reading any source file."
233,2,dpkg-buildpackage,"It runs the
preinit
hook before reading any source file. If a
.dsc
file has been specified it unpacks it anew and changes
           directory to it, if a
directory
has been specified it changes
           directory to it, otherwise it expects the current directory to
           contain the source tree. It prepares the build environment by
           setting various environment variables (see
ENVIRONMENT
), runs
           the
init
hook, and calls
dpkg-source --before-build
(unless
-T
or
--target
has been used)."
233,3,dpkg-buildpackage,"It prepares the build environment by
           setting various environment variables (see
ENVIRONMENT
), runs
           the
init
hook, and calls
dpkg-source --before-build
(unless
-T
or
--target
has been used). 2. It checks that the build-dependencies and build-conflicts are
           satisfied (unless
-d
or
--no-check-builddeps
is specified)."
233,4,dpkg-buildpackage,"It checks that the build-dependencies and build-conflicts are
           satisfied (unless
-d
or
--no-check-builddeps
is specified). 3. If one or more specific targets have been selected with the
-T
or
--target
option, it calls those targets and stops here."
233,5,dpkg-buildpackage,"If one or more specific targets have been selected with the
-T
or
--target
option, it calls those targets and stops here. Otherwise it runs the
preclean
hook and calls
fakeroot
debian/rules clean
to clean the build-tree (unless
-nc
or
--no-pre-clean
is specified). 4."
233,6,dpkg-buildpackage,"4. It runs the
source
hook and calls
dpkg-source -b
to generate
           the source package (if a
source
build has been requested with
--build
or equivalent options, and if no
.dsc
has been
           specified). 5."
233,7,dpkg-buildpackage,"5. It runs the
build
hook and calls
debian/rules
build-target
,
           then runs the
binary
hook followed by
fakeroot debian/rules
binary-target
(unless a source-only build has been requested
           with
--build=source
or equivalent options). Note that
build-target
and
binary-target
are either
build
and
binary
(default case, or if an
any
and
all
build has been requested
           with
--build
or equivalent options), or
build-arch
and
binary-arch
(if an
any
and not
all
build has been requested
           with
--build
or equivalent options), or
build-indep
and
binary-indep
(if an
all
and not
any
build has been requested
           with
--build
or equivalent options)."
233,8,dpkg-buildpackage,"Note that
build-target
and
binary-target
are either
build
and
binary
(default case, or if an
any
and
all
build has been requested
           with
--build
or equivalent options), or
build-arch
and
binary-arch
(if an
any
and not
all
build has been requested
           with
--build
or equivalent options), or
build-indep
and
binary-indep
(if an
all
and not
any
build has been requested
           with
--build
or equivalent options). 6. It runs the
buildinfo
hook and calls
dpkg-genbuildinfo
to
           generate a
.buildinfo
file."
233,9,dpkg-buildpackage,"It runs the
buildinfo
hook and calls
dpkg-genbuildinfo
to
           generate a
.buildinfo
file. Several
dpkg-buildpackage
options
           are forwarded to
dpkg-genbuildinfo
. If a
.dsc
has been
           specified, then it will be referenced in the generated
.buildinfo
file, as we can ascertain the provenance of the
           source tree."
233,10,dpkg-buildpackage,"If a
.dsc
has been
           specified, then it will be referenced in the generated
.buildinfo
file, as we can ascertain the provenance of the
           source tree. 7. It runs the
changes
hook and calls
dpkg-genchanges
to generate
           a
.changes
file."
233,11,dpkg-buildpackage,"It runs the
changes
hook and calls
dpkg-genchanges
to generate
           a
.changes
file. The name of the
.changes
file will depend on
           the type of build and will be as specific as necessary but not
           more; the name will be:
source-name
_
binary-version
_
arch
.changes
for a build that includes
any
source-name
_
binary-version
_all.changes
otherwise for a build that includes
all
source-name
_
source-version
_source.changes
. otherwise for a build that includes
source
Many
dpkg-buildpackage
options are forwarded to
dpkg-genchanges
."
233,12,dpkg-buildpackage,"otherwise for a build that includes
source
Many
dpkg-buildpackage
options are forwarded to
dpkg-genchanges
. 8. It runs the
postclean
hook and if
-tc
or
--post-clean
is
           specified, it will call
fakeroot debian/rules clean
again."
233,13,dpkg-buildpackage,"It runs the
postclean
hook and if
-tc
or
--post-clean
is
           specified, it will call
fakeroot debian/rules clean
again. 9. It calls
dpkg-source --after-build
."
233,14,dpkg-buildpackage,"It calls
dpkg-source --after-build
. 10. It runs the
check
hook and calls a package checker for the
.changes
file (if a command is specified in
DEB_CHECK_COMMAND
or with
--check-command
)."
233,15,dpkg-buildpackage,"It runs the
check
hook and calls a package checker for the
.changes
file (if a command is specified in
DEB_CHECK_COMMAND
or with
--check-command
). 11. It runs the
sign
hook and signs using the OpenPGP backend (as
           long as it is not an UNRELEASED build, or
--no-sign
is
           specified) to sign the
.dsc
file (if any, unless
-us
or
--unsigned-source
is specified), the
.buildinfo
file (unless
-ui
,
--unsigned-buildinfo
,
-uc
or
--unsigned-changes
is
           specified) and the
.changes
file (unless
-uc
or
--unsigned-changes
is specified)."
233,16,dpkg-buildpackage,"It runs the
sign
hook and signs using the OpenPGP backend (as
           long as it is not an UNRELEASED build, or
--no-sign
is
           specified) to sign the
.dsc
file (if any, unless
-us
or
--unsigned-source
is specified), the
.buildinfo
file (unless
-ui
,
--unsigned-buildinfo
,
-uc
or
--unsigned-changes
is
           specified) and the
.changes
file (unless
-uc
or
--unsigned-changes
is specified). 12. If a
.dsc
file has been specified, it removes the extracted
           source directory."
233,17,dpkg-buildpackage,"If a
.dsc
file has been specified, it removes the extracted
           source directory. 13. It runs the
done
hook."
234,0,dpkg-buildflags,"dpkg-buildflags
is a tool to retrieve compilation flags to use
       during build of Debian packages. The default flags are defined by the vendor but they can be
       extended/overridden in several ways:

       1. system-wide with
/usr/local/etc/dpkg/buildflags.conf
;

       2."
234,1,dpkg-buildflags,"system-wide with
/usr/local/etc/dpkg/buildflags.conf
;

       2. for the current user with
$XDG_CONFIG_HOME/dpkg/buildflags.conf
where
$XDG_CONFIG_HOME
defaults to
$HOME/.config
;

       3. temporarily by the user with environment variables (see
           section ""ENVIRONMENT"");

       4."
234,2,dpkg-buildflags,"temporarily by the user with environment variables (see
           section ""ENVIRONMENT"");

       4. dynamically by the package maintainer with environment
           variables set via
debian/rules
(see section ""ENVIRONMENT""). The configuration files can contain four types of directives:
SET
flag value
Override the flag named
flag
to have the value
value
."
234,3,dpkg-buildflags,"The configuration files can contain four types of directives:
SET
flag value
Override the flag named
flag
to have the value
value
. STRIP
flag value
Strip from the flag named
flag
all the build flags listed in
value
. Since dpkg 1.16.1."
234,4,dpkg-buildflags,"Since dpkg 1.16.1. APPEND
flag value
Extend the flag named
flag
by appending the options given in
value
. A space is prepended to the appended value if the
           flag's current value is non-empty."
234,5,dpkg-buildflags,"A space is prepended to the appended value if the
           flag's current value is non-empty. PREPEND
flag value
Extend the flag named
flag
by prepending the options given in
value
. A space is appended to the prepended value if the
           flag's current value is non-empty."
234,6,dpkg-buildflags,"A space is appended to the prepended value if the
           flag's current value is non-empty. Since dpkg 1.16.1. The configuration files can contain comments on lines starting
       with a hash (#)."
234,7,dpkg-buildflags,"The configuration files can contain comments on lines starting
       with a hash (#). Empty lines are also ignored. This program was introduced in dpkg 1.15.7."
235,0,dpkg-distaddfile,"dpkg-distaddfile
adds an entry for a named file to
debian/files
. It takes three non-option arguments, the filename and the section
       and priority for the
.changes
file. The filename should be specified relative to the directory where
dpkg-genchanges
will expect to find the files, usually
.."
235,1,dpkg-distaddfile,"It takes three non-option arguments, the filename and the section
       and priority for the
.changes
file. The filename should be specified relative to the directory where
dpkg-genchanges
will expect to find the files, usually
.. , rather
       than being a pathname relative to the current directory when
dpkg-
distaddfile
is run."
236,0,dpkg-checkbuilddeps,"This program checks the installed packages in the system against
       the build dependencies and build conflicts listed in the control
       file.  If any are not met, it displays them and exits with a
       nonzero return code.

       By default,
debian/control
is read, but an alternate control
       filename may be specified on the command line."
237,0,dpkg-deb,"dpkg-deb
packs, unpacks and provides information about Debian
       archives. Use
dpkg
to install and remove packages from your system. You can also invoke
dpkg-deb
by calling
dpkg
with whatever options
       you want to pass to
dpkg-deb
."
237,1,dpkg-deb,"You can also invoke
dpkg-deb
by calling
dpkg
with whatever options
       you want to pass to
dpkg-deb
. dpkg
will spot that you wanted
dpkg-deb
and run it for you. For most commands taking an input archive argument, the archive
       can be read from standard input if the archive name is given as a
       single minus character (Â«
-
Â»); otherwise lack of support will be
       documented in their respective command description."
238,0,dpkg-divert,"dpkg-divert
is the utility used to set up and update the list of
       diversions. File
diversions
are a way of forcing
dpkg(1)
not to install a file
       into its location, but to a
diverted
location. Diversions can be
       used through the package maintainer scripts to move a file away
       when it causes a conflict."
238,1,dpkg-divert,"File
diversions
are a way of forcing
dpkg(1)
not to install a file
       into its location, but to a
diverted
location. Diversions can be
       used through the package maintainer scripts to move a file away
       when it causes a conflict. System administrators can also use it
       to override some package's configuration file, or whenever some
       files (which aren't marked as âconffilesâ) need to be preserved by
dpkg
, when installing a newer version of a package which contains
       those files."
239,0,dpkg-genchanges,"dpkg-genchanges
reads information from an unpacked and built
       Debian source tree and from the files it has generated and
       generates a Debian upload control file (
.changes
file)."
240,0,dpkg-genbuildinfo,"dpkg-genbuildinfo
reads information from an unpacked and built
       Debian source tree and from the files it has generated and
       generates a Debian control file describing the build environment
       and the build artifacts (
.buildinfo
file).

       This program was introduced in dpkg 1.18.11."
241,0,dpkg-gencontrol,"dpkg-gencontrol
reads information from an unpacked Debian source
       tree and generates a binary package control file (which defaults
       to debian/tmp/DEBIAN/control); during this process it will
       simplify the relation fields. Thus
Pre-Depends
,
Depends
,
Recommends
and
Suggests
are simplified
       in this order by removing dependencies which are known to be true
       according to the stronger dependencies already parsed. It will
       also remove any self-dependency (in fact it will remove any
       dependency which evaluates to true given the current version of
       the package as installed)."
241,1,dpkg-gencontrol,"It will
       also remove any self-dependency (in fact it will remove any
       dependency which evaluates to true given the current version of
       the package as installed). Logically it keeps the intersection of
       multiple dependencies on the same package. The order of
       dependencies is preserved as best as possible: if any dependency
       must be discarded due to another dependency appearing further in
       the field, the superseding dependency will take the place of the
       discarded one."
241,2,dpkg-gencontrol,"The order of
       dependencies is preserved as best as possible: if any dependency
       must be discarded due to another dependency appearing further in
       the field, the superseding dependency will take the place of the
       discarded one. The other relation fields (
Enhances
,
Conflicts
,
Breaks
,
Replaces
and
Provides
) are also simplified individually by computing the
       union of the various dependencies when a package is listed
       multiple times in the field. dpkg-gencontrol
also adds an entry for the binary package to
debian/files
."
242,0,dpkg-gensymbols,"dpkg-gensymbols
scans a temporary build tree (debian/tmp by
       default) looking for libraries and generates a
symbols
file
       describing them. This file, if non-empty, is then installed in
       the DEBIAN subdirectory of the build tree so that it ends up
       included in the control information of the package. When generating those files, it uses as input some symbols files
       provided by the maintainer."
242,1,dpkg-gensymbols,"When generating those files, it uses as input some symbols files
       provided by the maintainer. It looks for the following files (and
       uses the first that is found):

       â¢   debian/
package
.symbols. arch
â¢   debian/symbols."
242,2,dpkg-gensymbols,"arch
â¢   debian/symbols. arch
â¢   debian/
package
.symbols

       â¢   debian/symbols

       The main interest of those files is to provide the minimal version
       associated to each symbol provided by the libraries. Usually it
       corresponds to the first version of that package that provided the
       symbol, but it can be manually incremented by the maintainer if
       the ABI of the symbol is extended without breaking backwards
       compatibility."
242,3,dpkg-gensymbols,"Usually it
       corresponds to the first version of that package that provided the
       symbol, but it can be manually incremented by the maintainer if
       the ABI of the symbol is extended without breaking backwards
       compatibility. It's the responsibility of the maintainer to keep
       those files up-to-date and accurate, but
dpkg-gensymbols
helps
       with that. When the generated symbols files differ from the maintainer
       supplied one,
dpkg-gensymbols
will print a diff between the two
       versions."
242,4,dpkg-gensymbols,"When the generated symbols files differ from the maintainer
       supplied one,
dpkg-gensymbols
will print a diff between the two
       versions. Furthermore if the difference is too significant, it
       will even fail (you can customize how much difference you can
       tolerate, see the
-c
option). This program was introduced in dpkg 1.14.8."
243,0,dpkg-mergechangelogs,"This program will use the 3 provided versions of the Debian
       changelog to generate a merged changelog file. The resulting
       changelog is stored in the file
out
or output to the standard
       output if that parameter is not given. Each entry is identified by its version number and they are
       assumed to be not conflicting, they are simply merged in the right
       order (by decreasing version number)."
243,1,dpkg-mergechangelogs,"Each entry is identified by its version number and they are
       assumed to be not conflicting, they are simply merged in the right
       order (by decreasing version number). When
--merge-prereleases
is
       used, the part of the version number after the last tilde is
       dropped so that 1.0-1~exp1 and 1.0-1~exp5 are considered to be the
       same entry. When the same version is available in both
new-a
and
new-b
, a standard line-based 3-way merge is attempted (provided
       that the module Algorithm::Merge is available â it's part of the
       package libalgorithm-merge-perl â otherwise you get a global
       conflict on the content of the entry)."
243,2,dpkg-mergechangelogs,"When
--merge-prereleases
is
       used, the part of the version number after the last tilde is
       dropped so that 1.0-1~exp1 and 1.0-1~exp5 are considered to be the
       same entry. When the same version is available in both
new-a
and
new-b
, a standard line-based 3-way merge is attempted (provided
       that the module Algorithm::Merge is available â it's part of the
       package libalgorithm-merge-perl â otherwise you get a global
       conflict on the content of the entry). This program was introduced in dpkg 1.15.7."
244,0,dpkg-maintscript-helper,"This program is designed to be run within maintainer scripts to
       achieve some tasks that
dpkg
can't (yet) handle natively either
       because of design decisions or due to current limitations. Many of those tasks require coordinated actions from several
       maintainer scripts (
preinst
,
postinst
,
prerm
,
postrm
). To avoid
       mistakes the same call simply needs to be put in all scripts and
       the program will automatically adapt its behavior based on the
       environment variable
DPKG_MAINTSCRIPT_NAME
and on the maintainer
       scripts arguments that you have to forward after a double hyphen."
244,1,dpkg-maintscript-helper,"Many of those tasks require coordinated actions from several
       maintainer scripts (
preinst
,
postinst
,
prerm
,
postrm
). To avoid
       mistakes the same call simply needs to be put in all scripts and
       the program will automatically adapt its behavior based on the
       environment variable
DPKG_MAINTSCRIPT_NAME
and on the maintainer
       scripts arguments that you have to forward after a double hyphen. This program was introduced in dpkg 1.15.7."
245,0,dpkg-name,"This manual page documents the
dpkg-name
program which provides an
       easy way to rename
Debian
packages into their full package names. A full package name consists of
package
_
version
_
architecture
. package-type
as specified in the
       control file of the package."
245,1,dpkg-name,"package-type
as specified in the
       control file of the package. The
version
part of the filename
       consists of the upstream version information optionally followed
       by a hyphen and the revision information. The
package-type
part
       comes from that field if present or will fall back to
deb
."
246,0,dpkg-parsechangelog,"dpkg-parsechangelog
reads and parses the changelog of an unpacked
       Debian source tree and outputs the information in it to standard
       output in a machine-readable form."
247,0,dpkg-query,"dpkg-query
is a tool to show information about packages listed in
       the
dpkg
database."
248,0,dpkg-realpath,"dpkg-realpath
is a tool (since dpkg 1.20.1) to resolve a pathname,
       that takes the
dpkg(1)
root directory into account, either
       implicitly from the
DPKG_ROOT
environment variable or from the
       command-line
--root
or
--instdir
options, and returns an absolute
pathname
relative to the root directory. The root directory must
       not be prefixed to the
pathname
to be resolved. This is intended to be used by other
dpkg
helpers, or by
       maintainer scripts instead of using
realpath(1)
or
readlink(1)
to
       canonicalize pathnames, as these latter commands do not support
       canonicalization relative to a different root than
/
."
248,1,dpkg-realpath,"The root directory must
       not be prefixed to the
pathname
to be resolved. This is intended to be used by other
dpkg
helpers, or by
       maintainer scripts instead of using
realpath(1)
or
readlink(1)
to
       canonicalize pathnames, as these latter commands do not support
       canonicalization relative to a different root than
/
. This program was introduced in dpkg 1.20.1."
249,0,dpkg-scanpackages,"dpkg-scanpackages
sorts through a tree of Debian binary packages
       and creates a Packages file, used by
apt
(8),
dselect(1)
, etc, to
       tell the user what packages are available for installation. These
       Packages files are the same as those found on Debian archive sites
       and media discs. You might use
dpkg-scanpackages
yourself if
       making a directory of local packages to install on a cluster of
       machines."
249,1,dpkg-scanpackages,"You might use
dpkg-scanpackages
yourself if
       making a directory of local packages to install on a cluster of
       machines. Note
: If you want to access the generated Packages file with
apt
(8) you will probably need to compress the file with
xz
(1)
       (generating a Packages.xz file),
bzip2
(1) (generating a
       Packages.bz2 file) or
gzip
(1) (generating a Packages.gz file). apt
(8) ignores uncompressed Packages files except on local access
       (i.e."
249,2,dpkg-scanpackages,"apt
(8) ignores uncompressed Packages files except on local access
       (i.e. file://
sources). binary-path
is the name of the tree of the binary packages to
       process (for example,
contrib/binary-i386
)."
249,3,dpkg-scanpackages,"binary-path
is the name of the tree of the binary packages to
       process (for example,
contrib/binary-i386
). It is best to make
       this relative to the root of the Debian archive, because every
       Filename field in the new Packages file will start with this
       string. override-file
is the name of a file to read which contains
       information about how the package fits into the distribution (the
       file can be compressed since dpkg 1.15.5); see
deb-override(5)
."
249,4,dpkg-scanpackages,"override-file
is the name of a file to read which contains
       information about how the package fits into the distribution (the
       file can be compressed since dpkg 1.15.5); see
deb-override(5)
. path-prefix
is an optional string to be prepended to the Filename
       fields. If more than one version of a package is found only the newest one
       is included in the output."
249,5,dpkg-scanpackages,"path-prefix
is an optional string to be prepended to the Filename
       fields. If more than one version of a package is found only the newest one
       is included in the output. If they have the same version and only
       differ in architecture only the first one found is used."
250,0,dpkg-scansources,"dpkg-scansources
scans the given
binary-dir
for
.dsc
files. These
       are used to create a Debian source index, which is output to
       stdout. The
override-file
, if given, is used to set priorities in the
       resulting index stanzas and to override the maintainer field given
       in the
.dsc
files."
250,1,dpkg-scansources,"The
override-file
, if given, is used to set priorities in the
       resulting index stanzas and to override the maintainer field given
       in the
.dsc
files. The file can be compressed (since dpkg
       1.15.5). See
deb-override(5)
for the format of this file."
250,2,dpkg-scansources,"See
deb-override(5)
for the format of this file. Note
: Since the override file is indexed by binary, not source
       packages, there's a bit of a problem here. The current
       implementation uses the highest priority of all the binary
       packages produced by a
.dsc
file for the priority of the source
       package, and the override entry for the first binary package
       listed in the
.dsc
file to modify maintainer information."
250,3,dpkg-scansources,"The current
       implementation uses the highest priority of all the binary
       packages produced by a
.dsc
file for the priority of the source
       package, and the override entry for the first binary package
       listed in the
.dsc
file to modify maintainer information. This
       might change. The
path-prefix
, if given, is prepended to the directory field in
       the generated source index."
250,4,dpkg-scansources,"The
path-prefix
, if given, is prepended to the directory field in
       the generated source index. You generally use this to make the
       directory fields contain the path from the top of the Debian
       archive hierarchy. Note
: If you want to access the generated Sources file with
apt
(8)
       you will probably need to compress the file with
gzip
(1)
       (generating a Sources.gz file)."
250,5,dpkg-scansources,"Note
: If you want to access the generated Sources file with
apt
(8)
       you will probably need to compress the file with
gzip
(1)
       (generating a Sources.gz file). apt
(8) ignores uncompressed
       Sources files except on local access (i.e. file://
sources)."
251,0,dpkg-shlibdeps,"dpkg-shlibdeps
calculates shared library dependencies for
       executables named in its arguments. The dependencies are added to
       the substitution variables file
debian/substvars
as variable names
shlibs:
dependency-field
where
dependency-field
is a dependency
       field name. Any other variables starting with
shlibs:
are removed
       from the file."
251,1,dpkg-shlibdeps,"Any other variables starting with
shlibs:
are removed
       from the file. dpkg-shlibdeps
has two possible sources of information to generate
       dependency information. Either
symbols
files or
shlibs
files."
251,2,dpkg-shlibdeps,"Either
symbols
files or
shlibs
files. For each binary that
dpkg-shlibdeps
analyzes, it finds out the
       list of libraries that it's linked with. Then, for each library,
       it looks up either the
symbols
file, or the
shlibs
file (if the
       former doesn't exist or if debian/shlibs.local contains the
       relevant dependency)."
251,3,dpkg-shlibdeps,"Then, for each library,
       it looks up either the
symbols
file, or the
shlibs
file (if the
       former doesn't exist or if debian/shlibs.local contains the
       relevant dependency). Both files are supposed to be provided by
       the library package and should thus be available as
       /usr/local/var/lib/dpkg/info/
package
. symbols
or
       /usr/local/var/lib/dpkg/info/
package
."
251,4,dpkg-shlibdeps,"symbols
or
       /usr/local/var/lib/dpkg/info/
package
. shlibs
. The package name is
       identified in two steps: find the library file on the system
       (looking in the same directories that
ld.so
would use), then use
dpkg -S
library-file
to lookup the package providing the library."
251,5,dpkg-shlibdeps,"The package name is
       identified in two steps: find the library file on the system
       (looking in the same directories that
ld.so
would use), then use
dpkg -S
library-file
to lookup the package providing the library. Symbols files
Symbols files contain finer-grained dependency information by
       providing the minimum dependency for each symbol that the library
       exports. The script tries to find a symbols file associated to a
       library package in the following places (first match is used):

       debian/*/DEBIAN/symbols
           Shared library information generated by the current build
           process that also invoked
dpkg-shlibdeps
."
251,6,dpkg-shlibdeps,"The script tries to find a symbols file associated to a
       library package in the following places (first match is used):

       debian/*/DEBIAN/symbols
           Shared library information generated by the current build
           process that also invoked
dpkg-shlibdeps
. They are generated
           by
dpkg-gensymbols(1)
. They are only used if the library is
           found in a package's build tree."
251,7,dpkg-shlibdeps,"They are only used if the library is
           found in a package's build tree. The symbols file in that
           build tree takes precedence over symbols files from other
           binary packages. /usr/local/etc/dpkg/symbols/
package
.symbols."
251,8,dpkg-shlibdeps,"/usr/local/etc/dpkg/symbols/
package
.symbols. arch
/usr/local/etc/dpkg/symbols/
package
.symbols
           Per-system overriding shared library dependency information. arch
is the architecture of the current system (obtained by
dpkg-architecture -qDEB_HOST_ARCH
)."
251,9,dpkg-shlibdeps,"arch
is the architecture of the current system (obtained by
dpkg-architecture -qDEB_HOST_ARCH
). Output from â
dpkg-query --control-path
package
symbolsâ
           Package-provided shared library dependency information. Unless overridden by
--admindir
, those files are located in
           /usr/local/var/lib/dpkg."
251,10,dpkg-shlibdeps,"Unless overridden by
--admindir
, those files are located in
           /usr/local/var/lib/dpkg. While scanning the symbols used by all binaries,
dpkg-shlibdeps
remembers the (biggest) minimal version needed for each library. At the end of the process, it is able to write out the minimal
       dependency for every library used (provided that the information
       of the
symbols
files are accurate)."
251,11,dpkg-shlibdeps,"At the end of the process, it is able to write out the minimal
       dependency for every library used (provided that the information
       of the
symbols
files are accurate). As a safe-guard measure, a symbols file can provide a
Build-Depends-Package
or
Build-Depends-Packages
meta-information
       field and
dpkg-shlibdeps
will extract the minimal version required
       by the corresponding package in the
Build-Depends
field and use
       this version if it's higher than the minimal version computed by
       scanning symbols. Shlibs files
Shlibs files associate directly a library to a dependency (without
       looking at the symbols)."
251,12,dpkg-shlibdeps,"Shlibs files
Shlibs files associate directly a library to a dependency (without
       looking at the symbols). It's thus often stronger than really
       needed but very safe and easy to handle. The dependencies for a library are looked up in several places."
251,13,dpkg-shlibdeps,"The dependencies for a library are looked up in several places. The first file providing information for the library of interest
       is used:

       debian/shlibs.local
           Package-local overriding shared library dependency
           information. /usr/local/etc/dpkg/shlibs.override
           Per-system overriding shared library dependency information."
251,14,dpkg-shlibdeps,"/usr/local/etc/dpkg/shlibs.override
           Per-system overriding shared library dependency information. debian/*/DEBIAN/shlibs
           Shared library information generated by the current build
           process that also invoked
dpkg-shlibdeps
. They are only used
           if the library is found in a package's build tree."
251,15,dpkg-shlibdeps,"They are only used
           if the library is found in a package's build tree. The shlibs
           file in that build tree takes precedence over shlibs files
           from other binary packages. Output from â
dpkg-query --control-path
package
shlibsâ
           Package-provided shared library dependency information."
251,16,dpkg-shlibdeps,"Output from â
dpkg-query --control-path
package
shlibsâ
           Package-provided shared library dependency information. Unless overridden by
--admindir
, those files are located in
           /usr/local/var/lib/dpkg. /usr/local/etc/dpkg/shlibs.default
           Per-system default shared library dependency information."
251,17,dpkg-shlibdeps,"Unless overridden by
--admindir
, those files are located in
           /usr/local/var/lib/dpkg. /usr/local/etc/dpkg/shlibs.default
           Per-system default shared library dependency information. The extracted dependencies are then directly used (except if they
       are filtered out because they have been identified as duplicate,
       or as weaker than another dependency)."
252,0,dpkg-split,"dpkg-split
splits Debian binary package files into smaller parts
       and reassembles them again, to support the storage of large
       package files on small media such as floppy disks. It can be operated manually using the
--split
,
--join
and
--info
options. It also has an automatic mode, invoked using the
--auto
option,
       where it maintains a queue of parts seen but not yet reassembled
       and reassembles a package file when it has seen all of its parts."
252,1,dpkg-split,"It also has an automatic mode, invoked using the
--auto
option,
       where it maintains a queue of parts seen but not yet reassembled
       and reassembles a package file when it has seen all of its parts. The
--listq
and
--discard
options allow the management of the
       queue. All splitting, joining and queueing operations produce informative
       messages on standard output; these may safely be ignored."
253,0,dpkg-vendor,"dpkg-vendor
is a tool to query information about vendors listed in
/usr/local/etc/dpkg/origins
. /usr/local/etc/dpkg/origins/default
contains information about the current vendor. The origin files provide metadata about specific vendors, such as
       their URL or where to file bug reports, and are usually used both
       to determine the behavior of tools and resulting contents during
       package builds targeting a specific vendor, and to describe the
       provenance of packages."
253,1,dpkg-vendor,"The origin files provide metadata about specific vendors, such as
       their URL or where to file bug reports, and are usually used both
       to determine the behavior of tools and resulting contents during
       package builds targeting a specific vendor, and to describe the
       provenance of packages. Packages can explicitly declare their vendor by including an
Origin
field, otherwise the vendor for a package without such
       field is assumed to be the one pointed to by the
default
origin
       symbolic link. The
default
symbolic link is also used to denote the origin of the
       current installation managed by
dpkg
, be that a full distribution
       or an overlay on top of an existing base system that contains
       either no packaging system or a native one."
253,2,dpkg-vendor,"Packages can explicitly declare their vendor by including an
Origin
field, otherwise the vendor for a package without such
       field is assumed to be the one pointed to by the
default
origin
       symbolic link. The
default
symbolic link is also used to denote the origin of the
       current installation managed by
dpkg
, be that a full distribution
       or an overlay on top of an existing base system that contains
       either no packaging system or a native one. This program was introduced in dpkg 1.15.1."
254,0,dpkg-trigger,"dpkg-trigger
is a tool to explicitly activate triggers and check
       for its support on the running
dpkg
. This can be used by maintainer scripts in complex and conditional
       situations where the file triggers, or the declarative
activate
triggers control file directive, are insufficiently rich. It can
       also be used for testing and by system administrators (but note
       that the triggers won't actually be run by
dpkg-trigger
)."
254,1,dpkg-trigger,"It can
       also be used for testing and by system administrators (but note
       that the triggers won't actually be run by
dpkg-trigger
). Unrecognized trigger name syntaxes are an error for
dpkg-trigger
. This program was introduced in dpkg 1.14.17."
255,0,dpkg-statoverride,"â
stat overrides
â are a way to tell
dpkg(1)
to use a different
       owner or mode for a path when a package is installed (this applies
       to any filesystem object that
dpkg
handles, including directories,
       devices, etc.). This can be used to force programs that are
       normally setuid to be install without a setuid flag, or only
       executable by a certain group. dpkg-statoverride
is a utility to manage the list of stat
       overrides."
255,1,dpkg-statoverride,"This can be used to force programs that are
       normally setuid to be install without a setuid flag, or only
       executable by a certain group. dpkg-statoverride
is a utility to manage the list of stat
       overrides. It has three basic functions: adding, removing and
       listing overrides."
256,0,dpkg-source,"dpkg-source
packs and unpacks Debian source archives.

       None of these commands allow multiple options to be combined into
       one, and they do not allow the value for an option to be specified
       in a separate argument."
257,0,dselect,"dselect
is one of the primary user interfaces for managing
       packages on a Debian system. At the
dselect
main menu, the system
       administrator can:

       â¢   Update the list of available package versions,

       â¢   View the status of installed and available packages,

       â¢   Alter package selections and manage dependencies,

       â¢   Install new packages or upgrade to newer versions. dselect
operates as a front-end to
dpkg(1)
, the low-level Debian
       package handling tool."
257,1,dselect,"dselect
operates as a front-end to
dpkg(1)
, the low-level Debian
       package handling tool. It features a full-screen package
       selections manager with package depends and conflicts resolver. When run with administrator privileges, packages can be installed,
       upgraded and removed."
257,2,dselect,"When run with administrator privileges, packages can be installed,
       upgraded and removed. Various access methods can be configured to
       retrieve available package version information and installable
       packages from package repositories. Depending on the used access
       method, these repositories can be public archive servers on the
       internet, local archive servers or media discs."
257,3,dselect,"Depending on the used access
       method, these repositories can be public archive servers on the
       internet, local archive servers or media discs. The recommended
       access method is
apt
, which is provided by the package
apt
(8). Normally
dselect
is invoked without parameters."
257,4,dselect,"Normally
dselect
is invoked without parameters. An interactive
       menu is presented, offering the user a list of commands. If a
       command is given as argument, then that command is started
       immediately."
257,5,dselect,"An interactive
       menu is presented, offering the user a list of commands. If a
       command is given as argument, then that command is started
       immediately. Several command line parameters are still available
       to modify the running behaviour of
dselect
or show additional
       information about the program."
258,0,dtrace,"The dtrace command converts probe descriptions defined in
file.d
into a probe header file via the
-h
option or a probe description
       file via the
-G
option."
259,0,du,"Summarize device usage of the set of FILEs, recursively for
       directories. Mandatory arguments to long options are mandatory for short
       options too. -0
,
--null
end each output line with NUL, not newline
-a
,
--all
write counts for all files, not just directories
--apparent-size
print apparent sizes rather than device usage; although the
              apparent size is usually smaller, it may be larger due to
              holes in ('sparse') files, internal fragmentation, indirect
              blocks, and the like
-B
,
--block-size
=
SIZE
scale sizes by SIZE before printing them; e.g., '-BM'
              prints sizes in units of 1,048,576 bytes; see SIZE format
              below
-b
,
--bytes
equivalent to '--apparent-size
--block-size
=
1
'
-c
,
--total
produce a grand total
-D
,
--dereference-args
dereference only symlinks that are listed on the command
              line
-d
,
--max-depth
=
N
print the total for a directory (or file, with
--all
) only
              if it is N or fewer levels below the command line argument;
--max-depth
=
0
is the same as
--summarize
--files0-from
=
F
summarize device usage of the NUL-terminated file names
              specified in file F; if F is -, then read names from
              standard input
-H
equivalent to
--dereference-args
(
-D
)
-h
,
--human-readable
print sizes in human readable format (e.g., 1K 234M 2G)
--inodes
list inode usage information instead of block usage
-k
like
--block-size
=
1K
-L
,
--dereference
dereference all symbolic links
-l
,
--count-links
count sizes many times if hard linked
-m
like
--block-size
=
1M
-P
,
--no-dereference
don't follow any symbolic links (this is the default)
-S
,
--separate-dirs
for directories do not include size of subdirectories
--si
like
-h
, but use powers of 1000 not 1024
-s
,
--summarize
display only a total for each argument
-t
,
--threshold
=
SIZE
exclude entries smaller than SIZE if positive, or entries
              greater than SIZE if negative
--time
show time of the last modification of any file in the
              directory, or any of its subdirectories
--time
=
WORD
show time as WORD instead of modification time: atime,
              access, use, ctime or status
--time-style
=
STYLE
show times using STYLE, which can be: full-iso, long-iso,
              iso, or +FORMAT; FORMAT is interpreted like in 'date'
-X
,
--exclude-from
=
FILE
exclude files that match any pattern in FILE
--exclude
=
PATTERN
exclude files that match PATTERN
-x
,
--one-file-system
skip directories on different file systems
--help
display this help and exit
--version
output version information and exit

       Display values are in units of the first available SIZE from
--block-size
, and the DU_BLOCK_SIZE, BLOCK_SIZE and BLOCKSIZE
       environment variables."
259,1,du,"-0
,
--null
end each output line with NUL, not newline
-a
,
--all
write counts for all files, not just directories
--apparent-size
print apparent sizes rather than device usage; although the
              apparent size is usually smaller, it may be larger due to
              holes in ('sparse') files, internal fragmentation, indirect
              blocks, and the like
-B
,
--block-size
=
SIZE
scale sizes by SIZE before printing them; e.g., '-BM'
              prints sizes in units of 1,048,576 bytes; see SIZE format
              below
-b
,
--bytes
equivalent to '--apparent-size
--block-size
=
1
'
-c
,
--total
produce a grand total
-D
,
--dereference-args
dereference only symlinks that are listed on the command
              line
-d
,
--max-depth
=
N
print the total for a directory (or file, with
--all
) only
              if it is N or fewer levels below the command line argument;
--max-depth
=
0
is the same as
--summarize
--files0-from
=
F
summarize device usage of the NUL-terminated file names
              specified in file F; if F is -, then read names from
              standard input
-H
equivalent to
--dereference-args
(
-D
)
-h
,
--human-readable
print sizes in human readable format (e.g., 1K 234M 2G)
--inodes
list inode usage information instead of block usage
-k
like
--block-size
=
1K
-L
,
--dereference
dereference all symbolic links
-l
,
--count-links
count sizes many times if hard linked
-m
like
--block-size
=
1M
-P
,
--no-dereference
don't follow any symbolic links (this is the default)
-S
,
--separate-dirs
for directories do not include size of subdirectories
--si
like
-h
, but use powers of 1000 not 1024
-s
,
--summarize
display only a total for each argument
-t
,
--threshold
=
SIZE
exclude entries smaller than SIZE if positive, or entries
              greater than SIZE if negative
--time
show time of the last modification of any file in the
              directory, or any of its subdirectories
--time
=
WORD
show time as WORD instead of modification time: atime,
              access, use, ctime or status
--time-style
=
STYLE
show times using STYLE, which can be: full-iso, long-iso,
              iso, or +FORMAT; FORMAT is interpreted like in 'date'
-X
,
--exclude-from
=
FILE
exclude files that match any pattern in FILE
--exclude
=
PATTERN
exclude files that match PATTERN
-x
,
--one-file-system
skip directories on different file systems
--help
display this help and exit
--version
output version information and exit

       Display values are in units of the first available SIZE from
--block-size
, and the DU_BLOCK_SIZE, BLOCK_SIZE and BLOCKSIZE
       environment variables. Otherwise, units default to 1024 bytes (or
       512 if POSIXLY_CORRECT is set). The SIZE argument is an integer and optional unit (example: 10K is
       10*1024)."
259,2,du,"The SIZE argument is an integer and optional unit (example: 10K is
       10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,... (powers of 1000)."
259,3,du,"Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,... (powers of 1000). Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on."
260,0,du,"By default, the
du
utility shall write to standard output the size
       of the file space allocated to, and the size of the file space
       allocated to each subdirectory of, the file hierarchy rooted in
       each of the specified files. By default, when a symbolic link is
       encountered on the command line or in the file hierarchy,
du
shall
       count the size of the symbolic link (rather than the file
       referenced by the link), and shall not follow the link to another
       portion of the file hierarchy. The size of the file space
       allocated to a file of type directory shall be defined as the sum
       total of space allocated to all files in the file hierarchy rooted
       in the directory plus the space allocated to the directory itself."
260,1,du,"The size of the file space
       allocated to a file of type directory shall be defined as the sum
       total of space allocated to all files in the file hierarchy rooted
       in the directory plus the space allocated to the directory itself. When
du
cannot
stat
() files or
stat
() or read directories, it
       shall report an error condition and the final exit status is
       affected. A file that occurs multiple times under one file operand
       and that has a link count greater than 1 shall be counted and
       written for only one entry."
260,2,du,"A file that occurs multiple times under one file operand
       and that has a link count greater than 1 shall be counted and
       written for only one entry. It is implementation-defined whether a
       file that has a link count no greater than 1 is counted and
       written just once, or is counted and written for each occurrence. It is implementation-defined whether a file that occurs under one
       file operand is counted for other file operands."
260,3,du,"It is implementation-defined whether a file that occurs under one
       file operand is counted for other file operands. The directory
       entry that is selected in the report is unspecified. By default,
       file sizes shall be written in 512-byte units, rounded up to the
       next 512-byte unit."
261,0,dumpkeys,"dumpkeys
writes, to the standard output, the current contents of
       the keyboard driver's translation tables, in the format specified
       by
keymaps(5)
.

       Using the various options, the format of the output can be
       controlled and also other information from the kernel and the
       programs
dumpkeys(1)
and
loadkeys(1)
can be obtained."
262,0,dpkg,"dpkg
is a medium-level tool to install, build, remove and manage
       Debian packages. The primary and more user-friendly front-end for
dpkg
as a CLI (command-line interface) is
apt
(8) and as a TUI
       (terminal user interface) is
aptitude
(8). dpkg
itself is
       controlled entirely via command line parameters, which consist of
       exactly one action and zero or more options."
262,1,dpkg,"dpkg
itself is
       controlled entirely via command line parameters, which consist of
       exactly one action and zero or more options. The action-parameter
       tells
dpkg
what to do and options control the behavior of the
       action in some way. dpkg
can also be used as a front-end to
dpkg-deb(1)
and
dpkg-query(1)
."
262,2,dpkg,"dpkg
can also be used as a front-end to
dpkg-deb(1)
and
dpkg-query(1)
. The list of supported actions can be found later
       on in the
ACTIONS
section. If any such action is encountered
dpkg
just runs
dpkg-deb
or
dpkg-query
with the parameters given to it,
       but no specific options are currently passed to them, to use any
       such option the back-ends need to be called directly."
263,0,echo,"Echo the STRING(s) to standard output. -n
do not output the trailing newline
-e
enable interpretation of backslash escapes
-E
disable interpretation of backslash escapes (default)
--help
display this help and exit
--version
output version information and exit

       If
-e
is in effect, the following sequences are recognized:

       \\     backslash

       \a     alert (BEL)

       \b     backspace

       \c     produce no further output

       \e     escape

       \f     form feed

       \n     new line

       \r     carriage return

       \t     horizontal tab

       \v     vertical tab

       \0NNN  byte with octal value NNN (1 to 3 digits)

       \xHH   byte with hexadecimal value HH (1 to 2 digits)

       Your shell may have its own version of echo, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports."
263,1,echo,"-n
do not output the trailing newline
-e
enable interpretation of backslash escapes
-E
disable interpretation of backslash escapes (default)
--help
display this help and exit
--version
output version information and exit

       If
-e
is in effect, the following sequences are recognized:

       \\     backslash

       \a     alert (BEL)

       \b     backspace

       \c     produce no further output

       \e     escape

       \f     form feed

       \n     new line

       \r     carriage return

       \t     horizontal tab

       \v     vertical tab

       \0NNN  byte with octal value NNN (1 to 3 digits)

       \xHH   byte with hexadecimal value HH (1 to 2 digits)

       Your shell may have its own version of echo, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports. Consider using the
printf(1)
command instead, as it avoids
       problems when outputting option-like strings."
264,0,echo,"The
echo
utility writes its arguments to standard output, followed
       by a <newline>.  If there are no arguments, only the <newline> is
       written."
265,0,elfedit,"elfedit
updates the ELF header and program property of ELF files
       which have the matching ELF machine and file types. The options
       control how and which fields in the ELF header and program
       property should be updated. elffile
..."
265,1,elfedit,"elffile
... are the ELF files to be updated. 32-bit and 64-bit ELF
       files are supported, as are archives containing ELF files."
266,0,env,"Set each NAME to VALUE in the environment and run COMMAND. Mandatory arguments to long options are mandatory for short
       options too. -a
,
--argv0
=
ARG
pass ARG as the zeroth argument of COMMAND
-i
,
--ignore-environment
start with an empty environment
-0
,
--null
end each output line with NUL, not newline
-u
,
--unset
=
NAME
remove variable from the environment
-C
,
--chdir
=
DIR
change working directory to DIR
-S
,
--split-string
=
S
process and split S into separate arguments; used to pass
              multiple arguments on shebang lines
--block-signal
[=
SIG
]
              block delivery of SIG signal(s) to COMMAND
--default-signal
[=
SIG
]
              reset handling of SIG signal(s) to the default
--ignore-signal
[=
SIG
]
              set handling of SIG signal(s) to do nothing
--list-signal-handling
list non default signal handling to stderr
-v
,
--debug
print verbose information for each processing step
--help
display this help and exit
--version
output version information and exit

       A mere - implies
-i
."
266,1,env,"-a
,
--argv0
=
ARG
pass ARG as the zeroth argument of COMMAND
-i
,
--ignore-environment
start with an empty environment
-0
,
--null
end each output line with NUL, not newline
-u
,
--unset
=
NAME
remove variable from the environment
-C
,
--chdir
=
DIR
change working directory to DIR
-S
,
--split-string
=
S
process and split S into separate arguments; used to pass
              multiple arguments on shebang lines
--block-signal
[=
SIG
]
              block delivery of SIG signal(s) to COMMAND
--default-signal
[=
SIG
]
              reset handling of SIG signal(s) to the default
--ignore-signal
[=
SIG
]
              set handling of SIG signal(s) to do nothing
--list-signal-handling
list non default signal handling to stderr
-v
,
--debug
print verbose information for each processing step
--help
display this help and exit
--version
output version information and exit

       A mere - implies
-i
. If no COMMAND, print the resulting
       environment. SIG may be a signal name like 'PIPE', or a signal number like
       '13'."
266,2,env,"SIG may be a signal name like 'PIPE', or a signal number like
       '13'. Without SIG, all known signals are included. Multiple
       signals can be comma-separated."
266,3,env,"Multiple
       signals can be comma-separated. An empty SIG argument is a no-op. Exit status:
125    if the env command itself fails

       126    if COMMAND is found but cannot be invoked

       127    if COMMAND cannot be found

       -      the exit status of COMMAND otherwise"
267,0,enosys,"enosys
is a simple command to execute a child process for which
       certain syscalls fail with errno ENOSYS.

       It can be used to test the behavior of applications in the face of
       missing syscalls as would happen when running on old kernels."
268,0,eject,"eject
allows removable media (typically a CD-ROM, floppy disk,
       tape, JAZ, ZIP or USB disk) to be ejected under software control. The command can also control some multi-disc CD-ROM changers, the
       auto-eject feature supported by some devices, and close the disc
       tray of some CD-ROM drives. The device corresponding to
device
or
mountpoint
is ejected."
268,1,eject,"The device corresponding to
device
or
mountpoint
is ejected. If no
       name is specified, the default name
/dev/cdrom
is used. The device
       may be addressed by device name (e.g., 'sda'), device path (e.g.,
       '/dev/sda'), UUID=
uuid
or LABEL=
label
tags."
268,2,eject,"The device
       may be addressed by device name (e.g., 'sda'), device path (e.g.,
       '/dev/sda'), UUID=
uuid
or LABEL=
label
tags. There are four different methods of ejecting, depending on whether
       the device is a CD-ROM, SCSI device, removable floppy, or tape. By
       default
eject
tries all four methods in order until it succeeds."
268,3,eject,"By
       default
eject
tries all four methods in order until it succeeds. If a device partition is specified, the whole-disk device is used. If the device or a device partition is currently mounted, it is
       unmounted before ejecting."
268,4,eject,"If a device partition is specified, the whole-disk device is used. If the device or a device partition is currently mounted, it is
       unmounted before ejecting. The eject is processed on exclusive
       open block device file descriptor if
--no-unmount
or
--force
are
       not specified."
269,0,ed,"The
ed
utility is a line-oriented text editor that uses two modes:
command mode
and
input mode
. In command mode the input characters
       shall be interpreted as commands, and in input mode they shall be
       interpreted as text. See the EXTENDED DESCRIPTION section."
269,1,ed,"In command mode the input characters
       shall be interpreted as commands, and in input mode they shall be
       interpreted as text. See the EXTENDED DESCRIPTION section. If an operand is
'-'
, the results are unspecified."
270,0,envsubst,"Substitutes the values of environment variables. Operation mode:
-v
,
--variables
output the variables occurring in SHELL-FORMAT
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit

       In normal operation mode, standard input is copied to standard
       output, with references to environment variables of the form
       $VARIABLE or ${VARIABLE} being replaced with the corresponding
       values. If a SHELL-FORMAT is given, only those environment
       variables that are referenced in SHELL-FORMAT are substituted;
       otherwise all environment variables references occurring in
       standard input are substituted."
270,1,envsubst,"Operation mode:
-v
,
--variables
output the variables occurring in SHELL-FORMAT
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit

       In normal operation mode, standard input is copied to standard
       output, with references to environment variables of the form
       $VARIABLE or ${VARIABLE} being replaced with the corresponding
       values. If a SHELL-FORMAT is given, only those environment
       variables that are referenced in SHELL-FORMAT are substituted;
       otherwise all environment variables references occurring in
       standard input are substituted. When
--variables
is used, standard input is ignored, and the
       output consists of the environment variables that are referenced
       in SHELL-FORMAT, one per line."
271,0,env,"The
env
utility shall obtain the current environment, modify it
       according to its arguments, then invoke the utility named by the
utility
operand with the modified environment. Optional arguments shall be passed to
utility
. If no
utility
operand is specified, the resulting environment
       shall be written to the standard output, with one
name
=
value
pair
       per line."
271,1,env,"Optional arguments shall be passed to
utility
. If no
utility
operand is specified, the resulting environment
       shall be written to the standard output, with one
name
=
value
pair
       per line. If the first argument is
'-'
, the results are unspecified."
272,0,eqn2graph,nan
273,0,eval,"The
eval
utility shall construct a command by concatenating
argument
s together, separating each with a <space> character.  The
       constructed command shall be read and executed by the shell."
274,0,eqn,nan
275,0,exit,"The
exit
utility shall cause the shell to exit from its current
       execution environment with the exit status specified by the
       unsigned decimal integer
n
. If the current execution environment
       is a subshell environment, the shell shall exit from the subshell
       environment with the specified exit status and continue in the
       environment from which that subshell environment was invoked;
       otherwise, the shell utility shall terminate with the specified
       exit status. If
n
is specified, but its value is not between 0 and
       255 inclusively, the exit status is undefined."
275,1,exit,"If the current execution environment
       is a subshell environment, the shell shall exit from the subshell
       environment with the specified exit status and continue in the
       environment from which that subshell environment was invoked;
       otherwise, the shell utility shall terminate with the specified
       exit status. If
n
is specified, but its value is not between 0 and
       255 inclusively, the exit status is undefined. A
trap
on
EXIT
shall be executed before the shell terminates,
       except when the
exit
utility is invoked in that
trap
itself, in
       which case the shell shall exit immediately."
276,0,exch,"exch
atomically exchanges oldpath and newpath.
exch
is a simple
       command wrapping
RENAME_EXCHANGE
of
renameat2
system call."
277,0,expand,"Convert tabs in each FILE to spaces, writing to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
277,1,expand,"Mandatory arguments to long options are mandatory for short
       options too. -i
,
--initial
do not convert tabs after non blanks
-t
,
--tabs
=
N
have tabs N characters apart, not 8
-t
,
--tabs
=
LIST
use comma separated list of tab positions. The last
              specified position can be prefixed with '/' to specify a
              tab size to use after the last explicitly specified tab
              stop."
277,2,expand,"-i
,
--initial
do not convert tabs after non blanks
-t
,
--tabs
=
N
have tabs N characters apart, not 8
-t
,
--tabs
=
LIST
use comma separated list of tab positions. The last
              specified position can be prefixed with '/' to specify a
              tab size to use after the last explicitly specified tab
              stop. Also a prefix of '+' can be used to align remaining
              tab stops relative to the last specified tab stop instead
              of the first column
--help
display this help and exit
--version
output version information and exit"
278,0,exec,"The
exec
utility shall open, close, and/or copy file descriptors
       as specified by any redirections as part of the command. If
exec
is specified without
command
or
argument
s, and any file
       descriptors with numbers greater than 2 are opened with associated
       redirection statements, it is unspecified whether those file
       descriptors remain open when the shell invokes another utility. Scripts concerned that child shells could misuse open file
       descriptors can always close them explicitly, as shown in one of
       the following examples."
278,1,exec,"Scripts concerned that child shells could misuse open file
       descriptors can always close them explicitly, as shown in one of
       the following examples. If
exec
is specified with
command
, it shall replace the shell with
command
without creating a new process. If
argument
s are
       specified, they shall be arguments to
command
."
278,2,exec,"If
exec
is specified with
command
, it shall replace the shell with
command
without creating a new process. If
argument
s are
       specified, they shall be arguments to
command
. Redirection
       affects the current shell execution environment."
279,0,expand,"The
expand
utility shall write files or the standard input to the
       standard output with <tab> characters replaced with one or more
       <space> characters needed to pad to the next tab stop. Any
       <backspace> characters shall be copied to the output and cause the
       column position count for tab stop calculations to be decremented;
       the column position count shall not be decremented below zero."
280,0,expiry,"The
expiry
command checks (
-c
) the current password expiration and
       forces (
-f
) changes when required. It is callable as a normal user
       command."
281,0,export,"The shell shall give the
export
attribute to the variables
       corresponding to the specified
name
s, which shall cause them to be
       in the environment of subsequently executed commands. If the name
       of a variable is followed by =
word
, then the value of that
       variable shall be set to
word
. The
export
special built-in shall support the Base Definitions
       volume of POSIX.1â2017,
Section 12.2
,
Utility Syntax Guidelines
."
281,1,export,"The
export
special built-in shall support the Base Definitions
       volume of POSIX.1â2017,
Section 12.2
,
Utility Syntax Guidelines
. When
-p
is specified,
export
shall write to the standard output
       the names and values of all exported variables, in the following
       format:

           ""export %s=%s\n"", <
name
>, <
value
>

       if
name
is set, and:

           ""export %s\n"", <
name
>

       if
name
is unset. The shell shall format the output, including the proper use of
       quoting, so that it is suitable for reinput to the shell as
       commands that achieve the same exporting results, except:

        1."
281,2,export,"The shell shall format the output, including the proper use of
       quoting, so that it is suitable for reinput to the shell as
       commands that achieve the same exporting results, except:

        1. Read-only variables with values cannot be reset. 2."
281,3,export,"2. Variables that were unset at the time they were output need
           not be reset to the unset state if a value is assigned to the
           variable between the time the state was saved and the time at
           which the saved output is reinput to the shell. When no arguments are given, the results are unspecified."
282,0,expr,"--help
display this help and exit
--version
output version information and exit

       Print the value of EXPRESSION to standard output. A blank line
       below separates increasing precedence groups. EXPRESSION may be:

       ARG1 | ARG2
              ARG1 if it is neither null nor 0, otherwise ARG2

       ARG1 & ARG2
              ARG1 if neither argument is null or 0, otherwise 0

       ARG1 < ARG2
              ARG1 is less than ARG2

       ARG1 <= ARG2
              ARG1 is less than or equal to ARG2

       ARG1 = ARG2
              ARG1 is equal to ARG2

       ARG1 != ARG2
              ARG1 is unequal to ARG2

       ARG1 >= ARG2
              ARG1 is greater than or equal to ARG2

       ARG1 > ARG2
              ARG1 is greater than ARG2

       ARG1 + ARG2
              arithmetic sum of ARG1 and ARG2

       ARG1 - ARG2
              arithmetic difference of ARG1 and ARG2

       ARG1 * ARG2
              arithmetic product of ARG1 and ARG2

       ARG1 / ARG2
              arithmetic quotient of ARG1 divided by ARG2

       ARG1 % ARG2
              arithmetic remainder of ARG1 divided by ARG2

       STRING : REGEXP
              anchored pattern match of REGEXP in STRING

       match STRING REGEXP
              same as STRING : REGEXP

       substr STRING POS LENGTH
              substring of STRING, POS counted from 1

       index STRING CHARS
              index in STRING where any CHARS is found, or 0

       length STRING
              length of STRING

       + TOKEN
              interpret TOKEN as a string, even if it is a

              keyword like 'match' or an operator like '/'

       ( EXPRESSION )
              value of EXPRESSION

       Beware that many operators need to be escaped or quoted for
       shells."
282,1,expr,"EXPRESSION may be:

       ARG1 | ARG2
              ARG1 if it is neither null nor 0, otherwise ARG2

       ARG1 & ARG2
              ARG1 if neither argument is null or 0, otherwise 0

       ARG1 < ARG2
              ARG1 is less than ARG2

       ARG1 <= ARG2
              ARG1 is less than or equal to ARG2

       ARG1 = ARG2
              ARG1 is equal to ARG2

       ARG1 != ARG2
              ARG1 is unequal to ARG2

       ARG1 >= ARG2
              ARG1 is greater than or equal to ARG2

       ARG1 > ARG2
              ARG1 is greater than ARG2

       ARG1 + ARG2
              arithmetic sum of ARG1 and ARG2

       ARG1 - ARG2
              arithmetic difference of ARG1 and ARG2

       ARG1 * ARG2
              arithmetic product of ARG1 and ARG2

       ARG1 / ARG2
              arithmetic quotient of ARG1 divided by ARG2

       ARG1 % ARG2
              arithmetic remainder of ARG1 divided by ARG2

       STRING : REGEXP
              anchored pattern match of REGEXP in STRING

       match STRING REGEXP
              same as STRING : REGEXP

       substr STRING POS LENGTH
              substring of STRING, POS counted from 1

       index STRING CHARS
              index in STRING where any CHARS is found, or 0

       length STRING
              length of STRING

       + TOKEN
              interpret TOKEN as a string, even if it is a

              keyword like 'match' or an operator like '/'

       ( EXPRESSION )
              value of EXPRESSION

       Beware that many operators need to be escaped or quoted for
       shells. Comparisons are arithmetic if both ARGs are numbers, else
       lexicographical. Pattern matches return the string matched
       between \( and \) or null; if \( and \) are not used, they return
       the number of characters matched or 0."
282,2,expr,"Comparisons are arithmetic if both ARGs are numbers, else
       lexicographical. Pattern matches return the string matched
       between \( and \) or null; if \( and \) are not used, they return
       the number of characters matched or 0. Exit status is 0 if EXPRESSION is neither null nor 0, 1 if
       EXPRESSION is null or 0, 2 if EXPRESSION is syntactically invalid,
       and 3 if an error occurred."
283,0,expect,nan
284,0,factor,"Print the prime factors of each specified integer NUMBER.  If none
       are specified on the command line, read them from standard input.
-h
,
--exponents
print repeated factors in form p^e unless e is 1
--help
display this help and exit
--version
output version information and exit"
285,0,fallocate,"fallocate
is used to manipulate the allocated disk space for a
       file, either to deallocate or preallocate it. For filesystems
       which support the
fallocate(2)
system call, preallocation is done
       quickly by allocating blocks and marking them as uninitialized,
       requiring no IO to the data blocks. This is much faster than
       creating a file by filling it with zeroes."
285,1,fallocate,"For filesystems
       which support the
fallocate(2)
system call, preallocation is done
       quickly by allocating blocks and marking them as uninitialized,
       requiring no IO to the data blocks. This is much faster than
       creating a file by filling it with zeroes. The exit status returned by
fallocate
is 0 on success and 1 on
       failure."
286,0,fadvise,"fadvise
is a simple command wrapping
posix_fadvise(2)
system call
       that is for predeclaring an access pattern for file data."
287,0,expr,"The
expr
utility shall evaluate an expression and write the result
       to standard output."
288,0,false,"Exit with a status code indicating failure.
--help
display this help and exit
--version
output version information and exit

       Your shell may have its own version of false, which usually
       supersedes the version described here.  Please refer to your
       shell's documentation for details about the options it supports."
289,0,ex,"The
ex
utility is a line-oriented text editor. There are two other
       modes of the editorâopen and visualâin which screen-oriented
       editing is available. This is described more fully by the
ex
open
and
visual
commands and in
vi(1p)
."
289,1,ex,"This is described more fully by the
ex
open
and
visual
commands and in
vi(1p)
. If an operand is
'-'
, the results are unspecified. This section uses the term
edit buffer
to describe the current
       working text."
289,2,ex,"This section uses the term
edit buffer
to describe the current
       working text. No specific implementation is implied by this term. All editing changes are performed on the edit buffer, and no
       changes to it shall affect any file until an editor command writes
       the file."
289,3,ex,"All editing changes are performed on the edit buffer, and no
       changes to it shall affect any file until an editor command writes
       the file. Certain terminals do not have all the capabilities necessary to
       support the complete
ex
definition, such as the full-screen
       editing commands (
visual mode
or
open mode
). When these commands
       cannot be supported on such terminals, this condition shall not
       produce an error message such as ``not an editor command'' or
       report a syntax error."
289,4,ex,"Certain terminals do not have all the capabilities necessary to
       support the complete
ex
definition, such as the full-screen
       editing commands (
visual mode
or
open mode
). When these commands
       cannot be supported on such terminals, this condition shall not
       produce an error message such as ``not an editor command'' or
       report a syntax error. The implementation may either accept the
       commands and produce results on the screen that are the result of
       an unsuccessful attempt to meet the requirements of this volume of
       POSIX.1â2017 or report an error describing the terminal-related
       deficiency."
290,0,false,"The
false
utility shall return with a non-zero exit code."
291,0,fc,"The
fc
utility shall list, or shall edit and re-execute, commands
       previously entered to an interactive
sh
. The command history list shall reference commands by number. The
       first number in the list is selected arbitrarily."
291,1,fc,"The
       first number in the list is selected arbitrarily. The relationship
       of a number to its command shall not change except when the user
       logs in and no other process is accessing the list, at which time
       the system may reset the numbering to start the oldest retained
       command at another number (usually 1). When the number reaches an
       implementation-defined upper limit, which shall be no smaller than
       the value in
HISTSIZE
or 32767 (whichever is greater), the shell
       may wrap the numbers, starting the next command with a lower
       number (usually 1)."
291,2,fc,"When the number reaches an
       implementation-defined upper limit, which shall be no smaller than
       the value in
HISTSIZE
or 32767 (whichever is greater), the shell
       may wrap the numbers, starting the next command with a lower
       number (usually 1). However, despite this optional wrapping of
       numbers,
fc
shall maintain the time-ordering sequence of the
       commands. For example, if four commands in sequence are given the
       numbers 32766, 32767, 1 (wrapped), and 2 as they are executed,
       command 32767 is considered the command previous to 1, even though
       its number is higher."
291,3,fc,"For example, if four commands in sequence are given the
       numbers 32766, 32767, 1 (wrapped), and 2 as they are executed,
       command 32767 is considered the command previous to 1, even though
       its number is higher. When commands are edited (when the
-l
option is not specified),
       the resulting lines shall be entered at the end of the history
       list and then re-executed by
sh
. The
fc
command that caused the
       editing shall not be entered into the history list."
291,4,fc,"The
fc
command that caused the
       editing shall not be entered into the history list. If the editor
       returns a non-zero exit status, this shall suppress the entry into
       the history list and the command re-execution. Any command line
       variable assignments or redirection operators used with
fc
shall
       affect both the
fc
command itself as well as the command that
       results; for example:

           fc -s -- -1 2>/dev/null

       reinvokes the previous command, suppressing standard error for
       both
fc
and the previous command."
292,0,fedabipkgdiff,nan
293,0,fg,"If job control is enabled (see the description of
set
-m
), the
fg
utility shall move a background job from the current environment
       (see
Section 2.12
,
Shell Execution Environment
) into the
       foreground.

       Using
fg
to place a job into the foreground shall remove its
       process ID from the list of those ``known in the current shell
       execution environment''; see
Section 2.9.3.1
,
Examples
."
294,0,fgconsole,"If the active Virtual Terminal is
/dev/ttyN
, then prints
N
on
       standard output.

       If the console is a serial console, then ""serial"" is printed
       instead."
295,0,fincore,"fincore
counts pages of file contents being resident in memory (in
       core), and reports the numbers. If an error occurs during
       counting, then an error message is printed to the stderr and
fincore
continues processing the rest of files listed in a command
       line. The default output is subject to change."
295,1,fincore,"The default output is subject to change. So whenever possible, you
       should avoid using default outputs in your scripts. Always
       explicitly define expected columns by using
--output
columns-list
in environments where a stable output is required."
296,0,file,"The
file
utility shall perform a series of tests in sequence on
       each specified
file
in an attempt to classify it:

        1. If
file
does not exist, cannot be read, or its file status
           could not be determined, the output shall indicate that the
           file was processed, but that its type could not be determined. 2."
296,1,file,"2. If the file is not a regular file, its file type shall be
           identified. The file types directory, FIFO, socket, block
           special, and character special shall be identified as such."
296,2,file,"The file types directory, FIFO, socket, block
           special, and character special shall be identified as such. Other implementation-defined file types may also be
           identified. If
file
is a symbolic link, by default the link
           shall be resolved and
file
shall test the type of file
           referenced by the symbolic link."
296,3,file,"If
file
is a symbolic link, by default the link
           shall be resolved and
file
shall test the type of file
           referenced by the symbolic link. (See the
-h
and
-i
options
           below.)

        3. If the length of
file
is zero, it shall be identified as an
           empty file."
296,4,file,"If the length of
file
is zero, it shall be identified as an
           empty file. 4. The
file
utility shall examine an initial segment of
file
and
           shall make a guess at identifying its contents based on
           position-sensitive tests."
296,5,file,"The
file
utility shall examine an initial segment of
file
and
           shall make a guess at identifying its contents based on
           position-sensitive tests. (The answer is not guaranteed to be
           correct; see the
-d
,
-M
, and
-m
options below.)

        5. The
file
utility shall examine
file
and make a guess at
           identifying its contents based on context-sensitive default
           system tests."
296,6,file,"The
file
utility shall examine
file
and make a guess at
           identifying its contents based on context-sensitive default
           system tests. (The answer is not guaranteed to be correct.)

        6. The file shall be identified as a data file."
296,7,file,"The file shall be identified as a data file. If
file
does not exist, cannot be read, or its file status could
       not be determined, the output shall indicate that the file was
       processed, but that its type could not be determined. If
file
is a symbolic link, by default the link shall be resolved
       and
file
shall test the type of file referenced by the symbolic
       link."
297,0,find-filter,"find-filter
is a filter for a list of file names read on standard
       input, and if the files match the
predicate
their names are
       written on standard output. The supported
predicate
forms are based on the file's creation
       time or modification time, and take the form
ctime
or
mtime
followed by a time specification. A time specification takes the
       form of a
+
or
-
followed by days (a non-negative integer),
       optionally followed by a colon (
:
) and hours (an integer in the
       range 0 to 23), optionally followed by another colon (
:
) and
       minutes (an integer in the range 0 to 59)."
297,1,find-filter,"A time specification takes the
       form of a
+
or
-
followed by days (a non-negative integer),
       optionally followed by a colon (
:
) and hours (an integer in the
       range 0 to 23), optionally followed by another colon (
:
) and
       minutes (an integer in the range 0 to 59). The semantics of the time specification are that a file matches
       the predicate if the chosen time attribute for the file is
less
than
(
+
) the current time minus the time specification, else
more
than or equal to
(
-
) the current time minus the time
       specification. Alternatively,
+
means
before
the current time
       minus the time specification, and
-
means
at
or
after
the current
       time minus the time specification."
297,2,find-filter,"Alternatively,
+
means
before
the current time
       minus the time specification, and
-
means
at
or
after
the current
       time minus the time specification. find-filter
is intended to be used to provide finer-grain and
       platform independent selection compared to the
-mtime
or
-ctime
options of
find(1)
. find-filter
is expected to be used as a post-
       filter for the output from
find(1)
, and this is how it is used in
       the
pmlogger_daily(1)
scripts to select files to be compressed or
       culled."
298,0,file,"This manual page documents version 5.46 of the
file
command. file
tests each argument in an attempt to classify it. There are
       three sets of tests, performed in this order: filesystem tests,
       magic tests, and language tests."
298,1,file,"There are
       three sets of tests, performed in this order: filesystem tests,
       magic tests, and language tests. The
first
test that succeeds
       causes the file type to be printed. The type printed will usually contain one of the words
text
(the
       file contains only printing characters and a few common control
       characters and is probably safe to read on an ASCII terminal),
executable
(the file contains the result of compiling a program in
       a form understandable to some UNIX kernel or another), or
data
meaning anything else (data is usually âbinaryâ or non-printable)."
298,2,file,"The type printed will usually contain one of the words
text
(the
       file contains only printing characters and a few common control
       characters and is probably safe to read on an ASCII terminal),
executable
(the file contains the result of compiling a program in
       a form understandable to some UNIX kernel or another), or
data
meaning anything else (data is usually âbinaryâ or non-printable). Exceptions are well-known file formats (core files, tar archives)
       that are known to contain binary data. When modifying magic files
       or the program itself, make sure to
preserve these keywords
."
298,3,file,"When modifying magic files
       or the program itself, make sure to
preserve these keywords
. Users depend on knowing that all the readable files in a directory
       have the word âtextâ printed. Don't do as Berkeley did and change
       âshell commands textâ to âshell scriptâ."
298,4,file,"Don't do as Berkeley did and change
       âshell commands textâ to âshell scriptâ. The filesystem tests are based on examining the return from a
stat
(2) system call. The program checks to see if the file is
       empty, or if it's some sort of special file."
298,5,file,"The program checks to see if the file is
       empty, or if it's some sort of special file. Any known file types
       appropriate to the system you are running on (sockets, symbolic
       links, or named pipes (FIFOs) on those systems that implement
       them) are intuited if they are defined in the system header file
       <
sys/stat.h
>. The magic tests are used to check for files with data in
       particular fixed formats."
298,6,file,"The magic tests are used to check for files with data in
       particular fixed formats. The canonical example of this is a
       binary executable (compiled program) a.out file, whose format is
       defined in <
elf.h
>, <
a.out.h
> and possibly <
exec.h
> in the
       standard include directory. These files have a âmagic numberâ
       stored in a particular place near the beginning of the file that
       tells the UNIX operating system that the file is a binary
       executable, and which of several types thereof."
298,7,file,"These files have a âmagic numberâ
       stored in a particular place near the beginning of the file that
       tells the UNIX operating system that the file is a binary
       executable, and which of several types thereof. The concept of a
       âmagic numberâ has been applied by extension to data files. Any
       file with some invariant identifier at a small fixed offset into
       the file can usually be described in this way."
298,8,file,"Any
       file with some invariant identifier at a small fixed offset into
       the file can usually be described in this way. The information
       identifying these files is read from the compiled magic file
/usr/local/share/misc/magic.mgc
, or the files in the directory
/usr/local/share/misc/magic
if the compiled file does not exist. In addition, if
$HOME/.magic.mgc
or
$HOME/.magic
exists, it will
       be used in preference to the system magic files."
298,9,file,"In addition, if
$HOME/.magic.mgc
or
$HOME/.magic
exists, it will
       be used in preference to the system magic files. If a file does not match any of the entries in the magic file, it
       is examined to see if it seems to be a text file. ASCII,
       ISO-8859-x, non-ISO 8-bit extended-ASCII character sets (such as
       those used on Macintosh and IBM PC systems), UTF-8-encoded
       Unicode, UTF-16-encoded Unicode, and EBCDIC character sets can be
       distinguished by the different ranges and sequences of bytes that
       constitute printable text in each set."
298,10,file,"ASCII,
       ISO-8859-x, non-ISO 8-bit extended-ASCII character sets (such as
       those used on Macintosh and IBM PC systems), UTF-8-encoded
       Unicode, UTF-16-encoded Unicode, and EBCDIC character sets can be
       distinguished by the different ranges and sequences of bytes that
       constitute printable text in each set. If a file passes any of
       these tests, its character set is reported. ASCII, ISO-8859-x,
       UTF-8, and extended-ASCII files are identified as âtextâ because
       they will be mostly readable on nearly any terminal; UTF-16 and
       EBCDIC are only âcharacter dataâ because, while they contain text,
       it is text that will require translation before it can be read."
298,11,file,"ASCII, ISO-8859-x,
       UTF-8, and extended-ASCII files are identified as âtextâ because
       they will be mostly readable on nearly any terminal; UTF-16 and
       EBCDIC are only âcharacter dataâ because, while they contain text,
       it is text that will require translation before it can be read. In addition,
file
will attempt to determine other characteristics
       of text-type files. If the lines of a file are terminated by CR,
       CRLF, or NEL, instead of the Unix-standard LF, this will be
       reported."
298,12,file,"If the lines of a file are terminated by CR,
       CRLF, or NEL, instead of the Unix-standard LF, this will be
       reported. Files that contain embedded escape sequences or
       overstriking will also be identified. Once
file
has determined the character set used in a text-type
       file, it will attempt to determine in what language the file is
       written."
298,13,file,"Once
file
has determined the character set used in a text-type
       file, it will attempt to determine in what language the file is
       written. The language tests look for particular strings (cf. <
names.h
>) that can appear anywhere in the first few blocks of a
       file."
298,14,file,"<
names.h
>) that can appear anywhere in the first few blocks of a
       file. For example, the keyword
.br
indicates that the file is
       most likely a
troff
(1) input file, just as the keyword
struct
indicates a C program. These tests are less reliable than the
       previous two groups, so they are performed last."
298,15,file,"These tests are less reliable than the
       previous two groups, so they are performed last. The language
       test routines also test for some miscellany (such as
tar
(1)
       archives, JSON files). Any file that cannot be identified as having been written in any
       of the character sets listed above is simply said to be âdataâ."
299,0,find-repos-of-install,"find-repos-of-install
is a program which reports the Yum
       repository that a specified package was installed from."
300,0,firecfg,"Firecfg is the desktop integration utility for Firejail sandbox. It allows the user to sandbox applications automatically by
       clicking on desktop manager icons and menus. The integration covers:

              - programs started in a terminal - typing ""firefox"" would
              be enough to start a sandboxed Firefox browser

              - programs started by clicking on desktop manager menus -
              all major desktop managers are supported

              - programs started by clicking on file icons in file
              manager - only Cinnamon, KDE, LXDE/LXQT, MATE and XFCE
              desktop managers are supported in this moment

       To set it up, run ""sudo firecfg"" after installing Firejail
       software."
300,1,firecfg,"The integration covers:

              - programs started in a terminal - typing ""firefox"" would
              be enough to start a sandboxed Firefox browser

              - programs started by clicking on desktop manager menus -
              all major desktop managers are supported

              - programs started by clicking on file icons in file
              manager - only Cinnamon, KDE, LXDE/LXQT, MATE and XFCE
              desktop managers are supported in this moment

       To set it up, run ""sudo firecfg"" after installing Firejail
       software. The same command should also be run after installing
       new programs. If the program is supported by Firejail, the
       symbolic link in /usr/local/bin will be created."
300,2,firecfg,"If the program is supported by Firejail, the
       symbolic link in /usr/local/bin will be created. For a full list
       of programs supported by default run ""cat
       /etc/firejail/firecfg.config"". For user-driven manual integration, see
DESKTOP INTEGRATION
section in
man 1 firejail
."
301,0,find,"The
find
utility shall recursively descend the directory hierarchy
       from each file specified by
path
, evaluating a Boolean expression
       composed of the primaries described in the OPERANDS section for
       each file encountered. Each
path
operand shall be evaluated
       unaltered as it was provided, including all trailing <slash>
       characters; all pathnames for other files encountered in the
       hierarchy shall consist of the concatenation of the current
path
operand, a <slash> if the current
path
operand did not end in one,
       and the filename relative to the
path
operand. The relative
       portion shall contain no dot or dot-dot components, no trailing
       <slash> characters, and only single <slash> characters between
       pathname components."
301,1,find,"The relative
       portion shall contain no dot or dot-dot components, no trailing
       <slash> characters, and only single <slash> characters between
       pathname components. The
find
utility shall be able to descend to arbitrary depths in a
       file hierarchy and shall not fail due to path length limitations
       (unless a
path
operand specified by the application exceeds
       {PATH_MAX} requirements). The
find
utility shall detect infinite loops; that is, entering a
       previously visited directory that is an ancestor of the last file
       encountered."
301,2,find,"The
find
utility shall detect infinite loops; that is, entering a
       previously visited directory that is an ancestor of the last file
       encountered. When it detects an infinite loop,
find
shall write a
       diagnostic message to standard error and shall either recover its
       position in the hierarchy or terminate. If a file is removed from or added to the directory hierarchy
       being searched it is unspecified whether or not
find
includes that
       file in its search."
302,0,firecfg,"Firecfg is the desktop integration utility for Firejail sandbox. It allows the user to sandbox applications automatically by
       clicking on desktop manager icons and menus. The integration covers:

              - programs started in a terminal - typing ""firefox"" would
              be enough to start a sandboxed Firefox browser

              - programs started by clicking on desktop manager menus -
              all major desktop managers are supported

              - programs started by clicking on file icons in file
              manager - only Cinnamon, KDE, LXDE/LXQT, MATE and XFCE
              desktop managers are supported in this moment

       To set it up, run ""sudo firecfg"" after installing Firejail
       software."
302,1,firecfg,"The integration covers:

              - programs started in a terminal - typing ""firefox"" would
              be enough to start a sandboxed Firefox browser

              - programs started by clicking on desktop manager menus -
              all major desktop managers are supported

              - programs started by clicking on file icons in file
              manager - only Cinnamon, KDE, LXDE/LXQT, MATE and XFCE
              desktop managers are supported in this moment

       To set it up, run ""sudo firecfg"" after installing Firejail
       software. The same command should also be run after installing
       new programs. If the program is supported by Firejail, the
       symbolic link in /usr/local/bin will be created."
302,2,firecfg,"If the program is supported by Firejail, the
       symbolic link in /usr/local/bin will be created. For a full list
       of programs supported by default run ""cat
       /etc/firejail/firecfg.config"". For user-driven manual integration, see
DESKTOP INTEGRATION
section in
man 1 firejail
."
303,0,find,"This manual page documents the GNU version of
find
. GNU
find
searches the directory tree rooted at each given starting-point by
       evaluating the given expression from left to right, according to
       the rules of precedence (see section OPERATORS), until the outcome
       is known (the left hand side is false for
and
operations, true for
or
), at which point
find
moves on to the next file name. If no
       starting-point is specified, `.' is assumed."
303,1,find,"If no
       starting-point is specified, `.' is assumed. If you are using
find
in an environment where security is
       important (for example if you are using it to search directories
       that are writable by other users), you should read the `Security
       Considerations' chapter of the findutils documentation, which is
       called
Finding Files
and comes with findutils. That document also
       includes a lot more detail and discussion than this manual page,
       so you may find it a more useful source of information."
304,0,firejail,"Firejail is a SUID sandbox program that reduces the risk of
       security breaches by restricting the running environment of
       untrusted applications using Linux namespaces, seccomp-bpf and
       Linux capabilities. It allows a process and all its descendants
       to have their own private view of the globally shared kernel
       resources, such as the network stack, process table, mount table. Firejail can work in a SELinux or AppArmor environment, and it is
       integrated with Linux Control Groups."
304,1,firejail,"Firejail can work in a SELinux or AppArmor environment, and it is
       integrated with Linux Control Groups. Written in C with virtually no dependencies, the software runs on
       any Linux computer with a 3.x kernel version or newer. It can
       sandbox any type of processes: servers, graphical applications,
       and even user login sessions."
304,2,firejail,"It can
       sandbox any type of processes: servers, graphical applications,
       and even user login sessions. Firejail allows the user to manage application security using
       security profiles. Each profile defines a set of permissions for
       a specific application or group of applications."
304,3,firejail,"Each profile defines a set of permissions for
       a specific application or group of applications. The software
       includes security profiles for a number of more common Linux
       programs, such as Mozilla Firefox, Chromium, VLC, Transmission
       etc. Firejail is currently implemented as an SUID binary, which means
       that if a malicious or compromised user account manages to exploit
       a bug in Firejail, that could ultimately lead to a privilege
       escalation to root."
304,4,firejail,"Firejail is currently implemented as an SUID binary, which means
       that if a malicious or compromised user account manages to exploit
       a bug in Firejail, that could ultimately lead to a privilege
       escalation to root. To mitigate this, it is recommended to only
       allow trusted users to run firejail (see firejail-users(5) for
       details on how to achieve that). For more details on the
       security/usability tradeoffs of Firejail, see: #4601 
       â¨
https://github.com/netblue30/firejail/discussions/4601
â©

       Alternative sandbox technologies like snap (
https://snapcraft.io/
)
       and flatpak (
https://flatpak.org/
) are not supported."
304,5,firejail,"To mitigate this, it is recommended to only
       allow trusted users to run firejail (see firejail-users(5) for
       details on how to achieve that). For more details on the
       security/usability tradeoffs of Firejail, see: #4601 
       â¨
https://github.com/netblue30/firejail/discussions/4601
â©

       Alternative sandbox technologies like snap (
https://snapcraft.io/
)
       and flatpak (
https://flatpak.org/
) are not supported. Snap and
       flatpak packages have their own native management tools and will
       not work when sandboxed with Firejail."
305,0,firemon,"Firemon monitors programs started in a Firejail sandbox. Without
       a PID specified, all processes started by Firejail are monitored. Descendants of these processes are also being monitored."
305,1,firemon,"Without
       a PID specified, all processes started by Firejail are monitored. Descendants of these processes are also being monitored. On
       Grsecurity systems only root user can run this program."
306,0,firemon,"Firemon monitors programs started in a Firejail sandbox. Without
       a PID specified, all processes started by Firejail are monitored. Descendants of these processes are also being monitored."
306,1,firemon,"Without
       a PID specified, all processes started by Firejail are monitored. Descendants of these processes are also being monitored. On
       Grsecurity systems only root user can run this program."
307,0,flatpak-build-bundle,"Creates a single-file named FILENAME for the application (or
       runtime) named NAME in the repository at LOCATION. If a BRANCH is
       specified, this branch of the application is used. The collection ID set on the repository at LOCATION (if set) will
       be used for the bundle."
307,1,flatpak-build-bundle,"If a BRANCH is
       specified, this branch of the application is used. The collection ID set on the repository at LOCATION (if set) will
       be used for the bundle. Unless
--oci
is used, the format of the bundle file is that of an
       ostree static delta (against an empty base) with some flatpak
       specific metadata for the application icons and appdata."
308,0,flatpak-build-commit-from,"Creates new commits on the DST-REF branch in the DST-REPO, with
       the contents (and most of the metadata) taken from another branch,
       either from another repo, or from another branch in the same
       repository. The collection ID set on DST-REPO (if set) will be used for the
       newly created commits. This command is very useful when you want to maintain a branch
       with a clean history that has no unsigned or broken commits."
308,1,flatpak-build-commit-from,"This command is very useful when you want to maintain a branch
       with a clean history that has no unsigned or broken commits. For
       instance, you can import the head from a different repository from
       an automatic builder when you've verified that it worked. The new
       commit will have no parents or signatures from the autobuilder,
       and can be properly signed with the official key."
308,2,flatpak-build-commit-from,"For
       instance, you can import the head from a different repository from
       an automatic builder when you've verified that it worked. The new
       commit will have no parents or signatures from the autobuilder,
       and can be properly signed with the official key. Any deltas that affect the original commit and that match parent
       commits in the destination repository are copied and rewritten for
       the new commit id."
309,0,flatpak-build-export,"Creates or updates a repository with an application build. LOCATION is the location of the repository. DIRECTORY must be a
       finalized build directory."
309,1,flatpak-build-export,"DIRECTORY must be a
       finalized build directory. If BRANCH is not specified, it is
       assumed to be ""master"". If LOCATION exists, it is assumed to be an OSTree repository,
       otherwise a new OSTree repository is created at this location."
309,2,flatpak-build-export,"If LOCATION exists, it is assumed to be an OSTree repository,
       otherwise a new OSTree repository is created at this location. The
       repository can be inspected with the
ostree
tool. The contents of DIRECTORY are committed on the branch with name
       app/APPNAME/ARCH/BRANCH, where ARCH is the architecture of the
       runtime that the application is using."
309,3,flatpak-build-export,"The contents of DIRECTORY are committed on the branch with name
       app/APPNAME/ARCH/BRANCH, where ARCH is the architecture of the
       runtime that the application is using. A commit filter is used to
       enforce that only the contents of the files/ and export/
       subdirectories and the metadata file are included in the commit,
       anything else is ignored. When exporting a flatpak to be published to the internet,
--collection-id=COLLECTION-ID
should be specified as a globally
       unique reverse DNS value to identify the collection of flatpaks
       this will be added to."
309,4,flatpak-build-export,"When exporting a flatpak to be published to the internet,
--collection-id=COLLECTION-ID
should be specified as a globally
       unique reverse DNS value to identify the collection of flatpaks
       this will be added to. Setting a globally unique collection ID
       allows the apps in the repository to be shared over peer to peer
       systems without needing further configuration. The build-update-repo command should be used to update repository
       metadata whenever application builds are added to a repository."
310,0,firejail,"Firejail is a SUID sandbox program that reduces the risk of
       security breaches by restricting the running environment of
       untrusted applications using Linux namespaces, seccomp-bpf and
       Linux capabilities. It allows a process and all its descendants
       to have their own private view of the globally shared kernel
       resources, such as the network stack, process table, mount table. Firejail can work in a SELinux or AppArmor environment, and it is
       integrated with Linux Control Groups."
310,1,firejail,"Firejail can work in a SELinux or AppArmor environment, and it is
       integrated with Linux Control Groups. Written in C with virtually no dependencies, the software runs on
       any Linux computer with a 3.x kernel version or newer. It can
       sandbox any type of processes: servers, graphical applications,
       and even user login sessions."
310,2,firejail,"It can
       sandbox any type of processes: servers, graphical applications,
       and even user login sessions. Firejail allows the user to manage application security using
       security profiles. Each profile defines a set of permissions for
       a specific application or group of applications."
310,3,firejail,"Each profile defines a set of permissions for
       a specific application or group of applications. The software
       includes security profiles for a number of more common Linux
       programs, such as Mozilla Firefox, Chromium, VLC, Transmission
       etc. Firejail is currently implemented as an SUID binary, which means
       that if a malicious or compromised user account manages to exploit
       a bug in Firejail, that could ultimately lead to a privilege
       escalation to root."
310,4,firejail,"Firejail is currently implemented as an SUID binary, which means
       that if a malicious or compromised user account manages to exploit
       a bug in Firejail, that could ultimately lead to a privilege
       escalation to root. To mitigate this, it is recommended to only
       allow trusted users to run firejail (see firejail-users(5) for
       details on how to achieve that). For more details on the
       security/usability tradeoffs of Firejail, see: #4601 
       â¨
https://github.com/netblue30/firejail/discussions/4601
â©

       Alternative sandbox technologies like snap (
https://snapcraft.io/
)
       and flatpak (
https://flatpak.org/
) are not supported."
310,5,firejail,"To mitigate this, it is recommended to only
       allow trusted users to run firejail (see firejail-users(5) for
       details on how to achieve that). For more details on the
       security/usability tradeoffs of Firejail, see: #4601 
       â¨
https://github.com/netblue30/firejail/discussions/4601
â©

       Alternative sandbox technologies like snap (
https://snapcraft.io/
)
       and flatpak (
https://flatpak.org/
) are not supported. Snap and
       flatpak packages have their own native management tools and will
       not work when sandboxed with Firejail."
311,0,flatpak-build-finish,"Finalizes a build directory, to prepare it for exporting. DIRECTORY is the name of the directory. The result of this command is that desktop files, icons, D-Bus
       service files, and AppStream metainfo files from the files
       subdirectory are copied to a new export subdirectory."
311,1,flatpak-build-finish,"The result of this command is that desktop files, icons, D-Bus
       service files, and AppStream metainfo files from the files
       subdirectory are copied to a new export subdirectory. In the
       metadata file, the command key is set in the [Application] group,
       and the supported keys in the [Environment] group are set
       according to the options. As part of finalization you can also specify permissions that the
       app needs, using the various options specified below."
311,2,flatpak-build-finish,"As part of finalization you can also specify permissions that the
       app needs, using the various options specified below. Additionally
       during finalization the permissions from the runtime are inherited
       into the app unless you specify
--no-inherit-permissions
You should review the exported files and the application metadata
       before creating and distributing an application bundle. It is an error to run build-finish on a directory that has not
       been initialized as a build directory, or has already been
       finalized."
312,0,flatpak-build-import-bundle,"Imports a bundle from a file named FILENAME into the repository at
       LOCATION.

       The format of the bundle file is that generated by build-bundle."
313,0,flatpak-build-init,"Initializes a separate build directory. DIRECTORY is the name of
       the directory. APPNAME is the application id of the app that will
       be built."
313,1,flatpak-build-init,"APPNAME is the application id of the app that will
       be built. SDK and RUNTIME specify the sdk and runtime that the
       application should be built against and run in. BRANCH specify
       the version of sdk and runtime

       Initializes a directory as build directory which can be used as
       target directory of
flatpak build
."
313,2,flatpak-build-init,"BRANCH specify
       the version of sdk and runtime

       Initializes a directory as build directory which can be used as
       target directory of
flatpak build
. It creates a metadata inside
       the given directory. Additionally, empty files and var
       subdirectories are created."
313,3,flatpak-build-init,"It creates a metadata inside
       the given directory. Additionally, empty files and var
       subdirectories are created. It is an error to run build-init on a directory that has already
       been initialized as a build directory."
314,0,flatpak-build-sign,"Signs the commit for a specified application or runtime in a local
       repository. LOCATION is the location of the repository. ID is
       the name of the application, or runtime if --runtime is specified."
314,1,flatpak-build-sign,"ID is
       the name of the application, or runtime if --runtime is specified. If BRANCH is not specified, it is assumed to be ""master"". Applications can also be signed during build-export, but it is
       sometimes useful to add additional signatures later."
315,0,flatpak-build,"Runs a build command in a directory. DIRECTORY must have been
       initialized with
flatpak build-init
. The sdk that is specified in the metadata file in the directory is
       mounted at /usr and the files and var subdirectories are mounted
       at /app and /var, respectively."
315,1,flatpak-build,"DIRECTORY must have been
       initialized with
flatpak build-init
. The sdk that is specified in the metadata file in the directory is
       mounted at /usr and the files and var subdirectories are mounted
       at /app and /var, respectively. They are writable, and their
       contents are preserved between build commands, to allow
       accumulating build artifacts there."
316,0,flatpak-build-update-repo,"Updates repository metadata for the repository at LOCATION. This
       command generates an OSTree summary file that lists the contents
       of the repository. The summary is used by flatpak remote-ls and
       other commands to display the contents of remote repositories."
316,1,flatpak-build-update-repo,"This
       command generates an OSTree summary file that lists the contents
       of the repository. The summary is used by flatpak remote-ls and
       other commands to display the contents of remote repositories. After this command, LOCATION can be used as the repository
       location for flatpak remote-add, either by exporting it over http,
       or directly with a file: url."
317,0,flatpak-config,"The flatpak config command shows or modifies the configuration of
       a flatpak installation. The following keys are supported:
languages
The languages that are included when installing Locale
           extensions. The value is a semicolon-separated list of
           two-letter language codes, or one of the special values * or
           *all*."
317,1,flatpak-config,"The value is a semicolon-separated list of
           two-letter language codes, or one of the special values * or
           *all*. If this key is unset, flatpak defaults to including the
extra-languages
key and the current locale. extra-languages
This key is used when languages is not set, and it defines
           extra locale extensions on top of the system configured
           languages."
317,2,flatpak-config,"extra-languages
This key is used when languages is not set, and it defines
           extra locale extensions on top of the system configured
           languages. The value is a semicolon-separated list of locale
           identifiers (language, optional locale, optional codeset,
           optional modifier) as documented by
setlocale(3)
(for example,
           en;en_DK;zh_HK.big5hkscs;uz_UZ.utf8@cyrillic). For configuration of individual remotes, see
flatpak-remote-modify(1)
."
317,3,flatpak-config,"The value is a semicolon-separated list of locale
           identifiers (language, optional locale, optional codeset,
           optional modifier) as documented by
setlocale(3)
(for example,
           en;en_DK;zh_HK.big5hkscs;uz_UZ.utf8@cyrillic). For configuration of individual remotes, see
flatpak-remote-modify(1)
. For configuration of individual
       applications, see
flatpak-override(1)
."
318,0,flatpak-document-export,"Creates a document id for a local file that can be exposed to
       sandboxed applications, allowing them access to files that they
       would not otherwise see. The exported files are exposed in a fuse
       filesystem at /run/user/$UID/doc/.

       This command also lets you modify the per-application permissions
       of the documents, granting or revoking access to the file on a
       per-application basis."
319,0,flatpak-document-unexport,"Removes the document id for the file from the document portal.
       This will make the document unavailable to all sandboxed
       applications."
320,0,flatpak-create-usb,"Copies the specified apps and/or runtimes REFs onto the removable
       media mounted at MOUNT-PATH, along with all the dependencies and
       metadata needed for installing them. This is one way of
       transferring flatpaks between computers that doesn't require an
       Internet connection. After using this command, the USB drive can
       be connected to another computer which already has the relevant
       remote(s) configured, and Flatpak will install or update from the
       drive offline (see below)."
320,1,flatpak-create-usb,"After using this command, the USB drive can
       be connected to another computer which already has the relevant
       remote(s) configured, and Flatpak will install or update from the
       drive offline (see below). If online, the drive will be used as a
       cache, meaning some objects will be pulled from it and others from
       the Internet. For this process to work a collection ID must be
       configured on the relevant remotes on both the source and
       destination computers, and on the remote server."
320,2,flatpak-create-usb,"For this process to work a collection ID must be
       configured on the relevant remotes on both the source and
       destination computers, and on the remote server. On the destination computer one can install from the USB (or any
       mounted filesystem) using the
--sideload-repo
option with
flatpak
install
. It's also possible to configure sideload paths using
       symlinks; see
flatpak(1)
."
320,3,flatpak-create-usb,"It's also possible to configure sideload paths using
       symlinks; see
flatpak(1)
. Flatpak also includes systemd units to
       automatically sideload from hot-plugged USB drives, but these may
       or may not be enabled depending on your Linux distribution. Each REF argument is a full or partial identifier in the flatpak
       ref format, which looks like ""(app|runtime)/ID/ARCH/BRANCH""."
320,4,flatpak-create-usb,"Each REF argument is a full or partial identifier in the flatpak
       ref format, which looks like ""(app|runtime)/ID/ARCH/BRANCH"". All
       elements except ID are optional and can be left out, including the
       slashes, so most of the time you need only specify ID. Any part
       left out will be matched against what is installed, and if there
       are multiple matches an error message will list the alternatives."
320,5,flatpak-create-usb,"Any part
       left out will be matched against what is installed, and if there
       are multiple matches an error message will list the alternatives. By default this looks for both installed apps and runtimes with
       the given REF, but you can limit this by using the
--app
or
--runtime
option. All REFs must be in the same installation (user, system, or
       other)."
320,6,flatpak-create-usb,"All REFs must be in the same installation (user, system, or
       other). Otherwise it's ambiguous which repository metadata refs to
       put on the USB drive. By default
flatpak create-usb
uses .ostree/repo as the destination
       directory under MOUNT-PATH but if you specify another location
       using
--destination-repo
a symbolic link will be created for you
       in .ostree/repos.d."
320,7,flatpak-create-usb,"By default
flatpak create-usb
uses .ostree/repo as the destination
       directory under MOUNT-PATH but if you specify another location
       using
--destination-repo
a symbolic link will be created for you
       in .ostree/repos.d. This ensures that either way the repository
       will be found by flatpak (and other consumers of libostree) for
       install/update operations. Unless overridden with the
--system
,
--user
, or
--installation
options, this command searches both the system-wide installation
       and the per-user one for REF and errors out if it exists in more
       than one."
321,0,flatpak-document-info,"Shows information about an exported file, such as the document id,
       the fuse path, the original location in the filesystem, and the
       per-application permissions.

       FILE can either be a file in the fuse filesystem at
       /run/user/$UID/doc/, or a file anywhere else."
322,0,flatpak-documents,"Lists exported files, with their document id and the full path to
       their origin. If an APPID is specified, only the files exported to
       this app are listed."
323,0,flatpak-enter,"Enter a running sandbox. INSTANCE must be either the pid of a process running in a flatpak
       sandbox, or the ID of a running application, or the instance ID of
       a running sandbox. You can use
flatpak ps
to find the instance IDs
       of running flatpaks."
323,1,flatpak-enter,"You can use
flatpak ps
to find the instance IDs
       of running flatpaks. COMMAND is the command to run in the sandbox. Extra arguments are
       passed on to the command."
323,2,flatpak-enter,"Extra arguments are
       passed on to the command. This creates a new process within the running sandbox, with the
       same environment. This is useful when you want to debug a problem
       with a running application."
323,3,flatpak-enter,"This is useful when you want to debug a problem
       with a running application. This command works as a regular user if the system support
       unprivileged user namespace. If that is not available you need to
       run run it like:
sudo -E flatpak enter
."
324,0,flatpak-history,"Shows changes to the flatpak installations on the system. This
       includes installs, updates and removals of applications and
       runtimes. By default, both per-user and system-wide installations are shown."
324,1,flatpak-history,"By default, both per-user and system-wide installations are shown. Use the
--user
,
--installation
or
--system
options to change this. The information for the history command is taken from the systemd
       journal, and can also be accessed using e.g."
324,2,flatpak-history,"Use the
--user
,
--installation
or
--system
options to change this. The information for the history command is taken from the systemd
       journal, and can also be accessed using e.g. journalctl
MESSAGE_ID=c7b39b1e006b464599465e105b361485"
325,0,flatpak-kill,"Stop a running Flatpak instance.

       INSTANCE can be either the numeric instance ID or the application
       ID of a running Flatpak. You can use
flatpak ps
to find the
       instance IDs of running flatpaks."
326,0,flatpak-install,"Installs an application or runtime. The primary way to install is
       to specify a REMOTE name as the source and one ore more REFs to
       specify the application or runtime to install. If REMOTE is
       omitted, the configured remotes are searched for the first REF and
       the user is asked to confirm the resulting choice."
326,1,flatpak-install,"If REMOTE is
       omitted, the configured remotes are searched for the first REF and
       the user is asked to confirm the resulting choice. Each REF argument is a full or partial identifier in the flatpak
       ref format, which looks like ""(app|runtime)/ID/ARCH/BRANCH"". All
       elements except ID are optional and can be left out, including the
       slashes, so most of the time you need only specify ID."
326,2,flatpak-install,"All
       elements except ID are optional and can be left out, including the
       slashes, so most of the time you need only specify ID. Any part
       left out will be matched against what is in the remote, and if
       there are multiple matches you will be prompted to choose one of
       them. You will also be prompted with choices if REF doesn't match
       anything in the remote exactly but is similar to one or more refs
       in the remote (e.g."
326,3,flatpak-install,"You will also be prompted with choices if REF doesn't match
       anything in the remote exactly but is similar to one or more refs
       in the remote (e.g. ""devhelp"" is similar to ""org.gnome.Devhelp""),
       but this fuzzy matching behavior is disabled if REF contains any
       slashes or periods. By default this looks for both apps and runtimes with the given
       REF in the specified REMOTE, but you can limit this by using the
--app
or
--runtime
option, or by supplying the initial element in
       the REF."
326,4,flatpak-install,"By default this looks for both apps and runtimes with the given
       REF in the specified REMOTE, but you can limit this by using the
--app
or
--runtime
option, or by supplying the initial element in
       the REF. If REMOTE is a uri or a path (absolute or relative starting with
       ./) to a local repository, then that repository will be used as
       the source, and a temporary remote will be created for the
       lifetime of the REF. If the specified REMOTE has a collection ID configured on it,
       Flatpak will search the sideload-repos directories configured
       either with the
--sideload-repo
option, or on a per-installation
       or system-wide basis (see
flatpak(1)
)."
326,5,flatpak-install,"If the specified REMOTE has a collection ID configured on it,
       Flatpak will search the sideload-repos directories configured
       either with the
--sideload-repo
option, or on a per-installation
       or system-wide basis (see
flatpak(1)
). The alternative form of the command (with
--from
or
--bundle
)
       allows to install directly from a source such as a .flatpak
       single-file bundle or a .flatpakref application description. The
       options are optional if the first argument has the expected
       filename extension."
326,6,flatpak-install,"The
       options are optional if the first argument has the expected
       filename extension. Note that flatpak allows to have multiple branches of an
       application and runtimes installed and used at the same time. However, only one version of an application can be current,
       meaning its exported files (for instance desktop files and icons)
       are visible to the host."
326,7,flatpak-install,"However, only one version of an application can be current,
       meaning its exported files (for instance desktop files and icons)
       are visible to the host. The last installed version is made
       current by default, but this can manually changed with flatpak
       make-current. Unless overridden with the
--user
or the
--installation
option,
       this command installs the application or runtime in the default
       system-wide installation."
327,0,flatpak-info,"Show info about an installed application or runtime. By default, the output is formatted in a friendly format. If you
       specify any of the
--show-..."
327,1,flatpak-info,"If you
       specify any of the
--show-... or
--file-access
options, the
       output is instead formatted in a machine-readable format. By default, both per-user and system-wide installations are
       queried."
327,2,flatpak-info,"or
--file-access
options, the
       output is instead formatted in a machine-readable format. By default, both per-user and system-wide installations are
       queried. Use the
--user
,
--system
or
--installation
options to
       change this."
328,0,flatpak-make-current,"Makes a particular branch of an application current. Only the
       current branch of an app has its exported files (such as desktop
       files and icons) made visible to the host. When a new branch is installed it will automatically be made
       current, so this command is often not needed."
328,1,flatpak-make-current,"Only the
       current branch of an app has its exported files (such as desktop
       files and icons) made visible to the host. When a new branch is installed it will automatically be made
       current, so this command is often not needed. Unless overridden with the
--user
or
--installation
options, this
       command changes the default system-wide installation."
329,0,flatpak-override,"Overrides the application specified runtime requirements. This can
       be used to grant a sandboxed application more or less resources
       than it requested. By default the application gets access to the resources it
       requested when it is started."
329,1,flatpak-override,"By default the application gets access to the resources it
       requested when it is started. But the user can override it on a
       particular instance by specifying extra arguments to
flatpak run
,
       or every time by using
flatpak override
. The application overrides are saved in text files residing in
       $XDG_DATA_HOME/flatpak/overrides in user mode."
329,2,flatpak-override,"The application overrides are saved in text files residing in
       $XDG_DATA_HOME/flatpak/overrides in user mode. If the application ID APP is not specified then the overrides
       affect all applications, but the per-application overrides can
       override the global overrides. Unless overridden with the
--user
or
--installation
options, this
       command changes the default system-wide installation."
330,0,flatpak-list,"Lists the names of the installed applications and runtimes. By default, both apps and runtimes are shown, but you can change
       this by using the
--app
or
--runtime
options. By default, both per-user and system-wide installations are shown."
330,1,flatpak-list,"By default, both per-user and system-wide installations are shown. Use the
--user
,
--installation
or
--system
options to change this. The list command can also be used to find installed apps that use
       a certain runtime, with the
--app-runtime
option."
331,0,flatpak-permission-remove,"Removes an entry for the object with id ID to the permission store
       table TABLE. The ID must be in a suitable format for the table. If
       APP_ID is specified, only the entry for that application is
       removed."
331,1,flatpak-permission-remove,"If
       APP_ID is specified, only the entry for that application is
       removed. The permission store is used by portals. Each portal generally has
       its own table in the permission store, and the format of the table
       entries is specific to each portal."
332,0,flatpak-mask,"Flatpak maintains a list of patterns that define which refs are
       masked. A masked ref will never be updated or automatically
       installed (for example a masked extension marked auto-download
       will not be downloaded). You can still manually install such refs,
       but once they are installed the version will be pinned."
332,1,flatpak-mask,"You can still manually install such refs,
       but once they are installed the version will be pinned. The patterns are just a partial ref, with the * character matching
       anything within that part of the ref. Here are some example
       patterns:

           org.some.App
           org.some.App//unstable
           app/org.domain.*
           org.some.App/arm

       To list the current set of masks, run this command without any
       patterns."
333,0,flatpak-permission-reset,"Removes all permissions for the given app from the Flatpak
       permission store.

       The permission store is used by portals. Each portal generally has
       its own table in the permission store, and the format of the table
       entries is specific to each portal."
334,0,flatpak-permission-set,"Set the permissions for an application in an entry in the
       permission store. The entry is identified by TABLE and ID, the
       application is identified by APP_ID. The PERMISSION strings must
       be in a format suitable for the table."
334,1,flatpak-permission-set,"The PERMISSION strings must
       be in a format suitable for the table. The permission store is used by portals. Each portal generally has
       its own table in the permission store, and the format of the table
       entries is specific to each portal."
335,0,flatpak-permission-show,"Lists dynamic permissions for the given app which are stored in
       the Flatpak permission store.

       The permission store is used by portals. Each portal generally has
       its own table in the permission store, and the format of the table
       entries is specific to each portal."
336,0,flatpak-pin,"Flatpak maintains a list of patterns that define which refs are
       pinned. A pinned ref will never be automatically uninstalled (as
       are unused runtimes periodically). This can be useful if for
       example you are using a runtime for development purposes."
336,1,flatpak-pin,"This can be useful if for
       example you are using a runtime for development purposes. Runtimes that are explicitly installed, rather than installed as a
       dependency of something else, are automatically pinned. The patterns are just a partial ref, with the * character matching
       anything within that part of the ref."
336,2,flatpak-pin,"The patterns are just a partial ref, with the * character matching
       anything within that part of the ref. Only runtimes can be pinned,
       not apps. Here are some example patterns:

           org.some.Runtime
           org.some.Runtime//unstable
           runtime/org.domain.*
           org.some.Runtime/arm

       To list the current set of pins, run this command without any
       patterns."
337,0,flatpak-permissions,"Lists dynamic permissions which are stored in the Flatpak
       permission store. When called without arguments, lists all the entries in all
       permission store tables. When called with one argument, lists all
       the entries in the named table."
337,1,flatpak-permissions,"When called with one argument, lists all
       the entries in the named table. When called with two arguments,
       lists the entry in the named table for the given object ID. The permission store is used by portals."
337,2,flatpak-permissions,"When called with two arguments,
       lists the entry in the named table for the given object ID. The permission store is used by portals. Each portal generally has
       its own table in the permission store, and the format of the table
       entries is specific to each portal."
338,0,flatpak-remote-add,"Adds a remote repository to the flatpak repository configuration. NAME is the name for the new remote, and LOCATION is a url or
       pathname. The LOCATION is either a flatpak repository, or a
       .flatpakrepo file which describes a repository."
338,1,flatpak-remote-add,"The LOCATION is either a flatpak repository, or a
       .flatpakrepo file which describes a repository. In the former case
       you may also have to specify extra options, such as the gpg key
       for the repo. Unless overridden with the
--user
or
--installation
options, this
       command changes the default system-wide installation."
339,0,flatpak-ps,"Lists useful information about running Flatpak instances.

       To see full details of a running instance, you can open the file
       /run/user/$UID/.flatpak/$INSTANCE/info, where
$INSTANCE
is the
       instance ID reported by flatpak ps."
340,0,flatpak-remote-ls,"Shows runtimes and applications that are available in the remote
       repository with the name REMOTE, or all remotes if one isn't
       specified. You can find all configured remote repositories with
flatpak remotes
. REMOTE can be a file:// URI pointing to a local repository instead
       of a remote name."
340,1,flatpak-remote-ls,"You can find all configured remote repositories with
flatpak remotes
. REMOTE can be a file:// URI pointing to a local repository instead
       of a remote name. Unless overridden with the
--system
,
--user
, or
--installation
options, this command uses either the default system-wide
       installation or the per-user one, depending on which has the
       specified REMOTE."
341,0,flatpak-remote-info,"Shows information about the runtime or application REF from the
       remote repository with the name REMOTE. You can find all
       configured remote repositories with flatpak remotes. By default, the output is formatted in a friendly format."
341,1,flatpak-remote-info,"By default, the output is formatted in a friendly format. If you
       specify one of the
--show-... options, the output is instead
       formatted in a machine-readable format."
341,2,flatpak-remote-info,"If you
       specify one of the
--show-... options, the output is instead
       formatted in a machine-readable format. Unless overridden with the
--system
,
--user
, or
--installation
options, this command uses either the default system-wide
       installation or the per-user one, depending on which has the
       specified REMOTE."
342,0,flatpak-remote-delete,"Removes a remote repository from the flatpak repository
       configuration.  NAME is the name of an existing remote.

       Unless overridden with the
--system
,
--user
, or
--installation
options, this command uses either the default system-wide
       installation or the per-user one, depending on which has the
       specified REMOTE."
343,0,flatpak-remote-modify,"Modifies options for an existing remote repository in the flatpak
       repository configuration.  NAME is the name for the remote.

       Unless overridden with the
--system
,
--user
, or
--installation
options, this command uses either the default system-wide
       installation or the per-user one, depending on which has the
       specified REMOTE."
344,0,flatpak-remotes,"Lists the known remote repositories, in priority order.

       By default, both per-user and system-wide installations are shown.
       Use the
--user
,
--system
or
--installation
options to change this."
345,0,flatpak-repair,"Repair a flatpak installation by pruning and reinstalling invalid
       objects. The repair command does all of the following:

       â¢   Scan all locally available refs, removing any that don't
           correspond to a deployed ref. â¢   Verify each commit they point to, removing any invalid objects
           and noting any missing objects."
345,1,flatpak-repair,"â¢   Verify each commit they point to, removing any invalid objects
           and noting any missing objects. â¢   Remove any refs that had an invalid object, and any
           non-partial refs that had missing objects. â¢   Prune all objects not referenced by a ref, which gets rid of
           any possibly invalid non-scanned objects."
345,2,flatpak-repair,"â¢   Prune all objects not referenced by a ref, which gets rid of
           any possibly invalid non-scanned objects. â¢   Enumerate all deployed refs and re-install any that are not in
           the repo (or are partial for a non-subdir deploy). Note that
flatpak repair
has to be run with root privileges to
       operate on the system installation."
345,3,flatpak-repair,"â¢   Enumerate all deployed refs and re-install any that are not in
           the repo (or are partial for a non-subdir deploy). Note that
flatpak repair
has to be run with root privileges to
       operate on the system installation. An alternative command for repairing OSTree repositories is ostree
       fsck."
346,0,flatpak-run,"If REF names an installed application, Flatpak runs the
       application in a sandboxed environment. Extra arguments are passed
       on to the application. The current branch and arch of the
       application is used unless otherwise specified with
--branch
or
--arch
."
346,1,flatpak-run,"The current branch and arch of the
       application is used unless otherwise specified with
--branch
or
--arch
. See
flatpak-make-current(1)
. If REF names a runtime, a shell is opened in the runtime."
346,2,flatpak-run,"If REF names a runtime, a shell is opened in the runtime. This is
       useful for development and testing. If there is ambiguity about
       which branch to use, you will be prompted to choose."
346,3,flatpak-run,"If there is ambiguity about
       which branch to use, you will be prompted to choose. Use
--branch
to avoid this. The primary arch is used unless otherwise specified
       with
--arch
."
346,4,flatpak-run,"The primary arch is used unless otherwise specified
       with
--arch
. By default, Flatpak will look for the application or runtime in
       the per-user installation first, then in all system installations. This can be overridden with the
--user
,
--system
and
--installation
options."
346,5,flatpak-run,"This can be overridden with the
--user
,
--system
and
--installation
options. Flatpak creates a sandboxed environment for the application to run
       in by mounting the right runtime at /usr and a writable directory
       at /var, whose content is preserved between application runs. The
       application itself is mounted at /app."
346,6,flatpak-run,"The
       application itself is mounted at /app. The details of the sandboxed environment are controlled by the
       application metadata and various options like
--share
and
--socket
that are passed to the run command: Access is allowed if it was
       requested either in the application metadata file or with an
       option and the user hasn't overridden it. The remaining arguments are passed to the command that gets run in
       the sandboxed environment."
346,7,flatpak-run,"The remaining arguments are passed to the command that gets run in
       the sandboxed environment. See the
--file-forwarding
option for
       handling of file arguments. Environment variables are generally passed on to the sandboxed
       application, with certain exceptions."
346,8,flatpak-run,"Environment variables are generally passed on to the sandboxed
       application, with certain exceptions. The application metadata can
       override environment variables, as well as the
--env
option. Apart
       from that, Flatpak always unsets or overrides the following
       variables, since their session values are likely to interfere with
       the functioning of the sandbox:
           PATH
           LD_LIBRARY_PATH
           LD_PRELOAD
           LD_AUDIT
           XDG_CONFIG_DIRS
           XDG_DATA_DIRS
           SHELL
           TEMP
           TEMPDIR
           TMP
           TMPDIR
           XDG_RUNTIME_DIR
           container
           TZDIR
           PYTHONPATH
           PERLLIB
           PERL5LIB
           XCURSOR_PATH
           GST_PLUGIN_PATH_1_0
           GST_REGISTRY
           GST_REGISTRY_1_0
           GST_PLUGIN_PATH
           GST_PLUGIN_SYSTEM_PATH
           GST_PLUGIN_SCANNER
           GST_PLUGIN_SCANNER_1_0
           GST_PLUGIN_SYSTEM_PATH_1_0
           GST_PRESET_PATH
           GST_PTP_HELPER
           GST_PTP_HELPER_1_0
           GST_INSTALL_PLUGINS_HELPER
           KRB5CCNAME
           XKB_CONFIG_ROOT
           GIO_EXTRA_MODULES
           GDK_BACKEND
           VK_ADD_DRIVER_FILES
           VK_ADD_LAYER_PATH
           VK_DRIVER_FILES
           VK_ICD_FILENAMES
           VK_LAYER_PATH
           __EGL_EXTERNAL_PLATFORM_CONFIG_DIRS
           __EGL_EXTERNAL_PLATFORM_CONFIG_FILENAMES
           __EGL_VENDOR_LIBRARY_DIRS
           __EGL_VENDOR_LIBRARY_FILENAMES

       Also several environment variables with the prefix ""GST_"" that are
       used by gstreamer are unset (since Flatpak 1.12.5)."
346,9,flatpak-run,"Apart
       from that, Flatpak always unsets or overrides the following
       variables, since their session values are likely to interfere with
       the functioning of the sandbox:
           PATH
           LD_LIBRARY_PATH
           LD_PRELOAD
           LD_AUDIT
           XDG_CONFIG_DIRS
           XDG_DATA_DIRS
           SHELL
           TEMP
           TEMPDIR
           TMP
           TMPDIR
           XDG_RUNTIME_DIR
           container
           TZDIR
           PYTHONPATH
           PERLLIB
           PERL5LIB
           XCURSOR_PATH
           GST_PLUGIN_PATH_1_0
           GST_REGISTRY
           GST_REGISTRY_1_0
           GST_PLUGIN_PATH
           GST_PLUGIN_SYSTEM_PATH
           GST_PLUGIN_SCANNER
           GST_PLUGIN_SCANNER_1_0
           GST_PLUGIN_SYSTEM_PATH_1_0
           GST_PRESET_PATH
           GST_PTP_HELPER
           GST_PTP_HELPER_1_0
           GST_INSTALL_PLUGINS_HELPER
           KRB5CCNAME
           XKB_CONFIG_ROOT
           GIO_EXTRA_MODULES
           GDK_BACKEND
           VK_ADD_DRIVER_FILES
           VK_ADD_LAYER_PATH
           VK_DRIVER_FILES
           VK_ICD_FILENAMES
           VK_LAYER_PATH
           __EGL_EXTERNAL_PLATFORM_CONFIG_DIRS
           __EGL_EXTERNAL_PLATFORM_CONFIG_FILENAMES
           __EGL_VENDOR_LIBRARY_DIRS
           __EGL_VENDOR_LIBRARY_FILENAMES

       Also several environment variables with the prefix ""GST_"" that are
       used by gstreamer are unset (since Flatpak 1.12.5). Flatpak also overrides the XDG environment variables to point
       sandboxed applications at their writable filesystem locations
       below ~/.var/app/$APPID/:
           XDG_DATA_HOME
           XDG_CONFIG_HOME
           XDG_CACHE_HOME
           XDG_STATE_HOME (since Flatpak 1.13)

       Apps can use the
--persist=.local/state
and
--unset-env=XDG_STATE_HOME
options to get a Flatpak
       1.13-compatible ~/.local/state on older versions of Flatpak. The host values of these variables are made available inside the
       sandbox via these HOST_-prefixed variables:
           HOST_XDG_DATA_HOME
           HOST_XDG_CONFIG_HOME
           HOST_XDG_CACHE_HOME
           HOST_XDG_STATE_HOME (since Flatpak 1.13)

       Flatpak sets the environment variable
FLATPAK_ID
to the
       application ID of the running app."
346,10,flatpak-run,"The host values of these variables are made available inside the
       sandbox via these HOST_-prefixed variables:
           HOST_XDG_DATA_HOME
           HOST_XDG_CONFIG_HOME
           HOST_XDG_CACHE_HOME
           HOST_XDG_STATE_HOME (since Flatpak 1.13)

       Flatpak sets the environment variable
FLATPAK_ID
to the
       application ID of the running app. Flatpak also bind-mounts as read-only the host's /etc/os-release
       (if available, or /usr/lib/os-release as a fallback) to
       /run/host/os-release in accordance with the
os-release
specification
[1]. If parental controls support is enabled, flatpak will check the
       current userâs parental controls settings, and will refuse to run
       an app if it is blocklisted for the current user."
347,0,flatpak-repo,"Show information about a local repository.

       If you need to modify a local repository, see the
flatpak
build-update-repo
command, or use the
ostree
tool."
348,0,flatpak-search,"Searches for applications and runtimes matching TEXT. Note that
       this uses appstream data that can be updated with the
flatpak
update
command. The appstream data is updated automatically only
       if it's at least a day old."
349,0,flatpak-spawn,"Unlike other flatpak commands,
flatpak-spawn
is available to
       applications inside the sandbox. It runs COMMAND outside the
       sandbox: either in another sandbox, or on the host.

       When called without
--host
,
flatpak-spawn
uses the Flatpak portal
       to create a copy of the sandbox it was called from, optionally
       using tighter permissions and optionally the latest version of the
       app and runtime (see
--latest-version
)."
350,0,flatpak-uninstall,"Uninstalls an application or runtime. REF is a reference to the
       application or runtime to uninstall. Each REF argument is a full or partial identifier in the flatpak
       ref format, which looks like ""(app|runtime)/ID/ARCH/BRANCH""."
350,1,flatpak-uninstall,"Each REF argument is a full or partial identifier in the flatpak
       ref format, which looks like ""(app|runtime)/ID/ARCH/BRANCH"". All
       elements except ID are optional and can be left out, including the
       slashes, so most of the time you need only specify ID. Any part
       left out will be matched against what is installed, and if there
       are multiple matches you will be prompted to choose between them."
350,2,flatpak-uninstall,"Any part
       left out will be matched against what is installed, and if there
       are multiple matches you will be prompted to choose between them. You will also be prompted if REF doesn't match any installed ref
       exactly but is similar (e.g. ""gedit"" is similar to
       ""org.gnome.gedit""), but this fuzzy matching behavior is disabled
       if REF contains any slashes or periods."
350,3,flatpak-uninstall,"""gedit"" is similar to
       ""org.gnome.gedit""), but this fuzzy matching behavior is disabled
       if REF contains any slashes or periods. By default this looks for both installed apps and runtimes with
       the given REF, but you can limit this by using the
--app
or
--runtime
option, or by supplying the initial element in the REF. Normally, this command removes the ref for this
       application/runtime from the local OSTree repository and purges
       any objects that are no longer needed to free up disk space."
350,4,flatpak-uninstall,"Normally, this command removes the ref for this
       application/runtime from the local OSTree repository and purges
       any objects that are no longer needed to free up disk space. If
       the same application is later reinstalled, the objects will be
       pulled from the remote repository again. The
--keep-ref
option can
       be used to prevent this."
350,5,flatpak-uninstall,"The
--keep-ref
option can
       be used to prevent this. When
--delete-data
is specified while removing an app, its data
       directory in ~/.var/app and any permissions it might have are
       removed. When
--delete-data
is used without a REF, all 'unowned'
       app data is removed."
350,6,flatpak-uninstall,"When
--delete-data
is specified while removing an app, its data
       directory in ~/.var/app and any permissions it might have are
       removed. When
--delete-data
is used without a REF, all 'unowned'
       app data is removed. Unless overridden with the
--system
,
--user
, or
--installation
options, this command searches both the system-wide installation
       and the per-user one for REF and errors out if it exists in more
       than one."
351,0,flock,"This utility manages
flock(2)
locks from within shell scripts or
       from the command line. The first and second of the above forms wrap the lock around the
       execution of a
command
, in a manner similar to
su(1)
or
newgrp(1)
. They lock a specified
file
or
directory
, which is created
       (assuming appropriate permissions) if it does not already exist."
351,1,flock,"They lock a specified
file
or
directory
, which is created
       (assuming appropriate permissions) if it does not already exist. By default, if the lock cannot be immediately acquired,
flock
waits until the lock is available. The third form uses an open file by its file descriptor
number
."
351,2,flock,"By default, if the lock cannot be immediately acquired,
flock
waits until the lock is available. The third form uses an open file by its file descriptor
number
. See the examples below for how that can be used."
352,0,flatpak,"Flatpak is a tool for managing applications and the runtimes they
       use. In the Flatpak model, applications can be built and
       distributed independently from the host system they are used on,
       and they are isolated from the host system ('sandboxed') to some
       degree, at runtime. Flatpak can operate in system-wide or per-user mode."
352,1,flatpak,"Flatpak can operate in system-wide or per-user mode. The
       system-wide data (runtimes, applications and configuration) is
       located in $prefix/var/lib/flatpak/, and the per-user data is in
       $HOME/.local/share/flatpak/. Below these locations, there is a
       local repository in the repo/ subdirectory and installed runtimes
       and applications are in the corresponding runtime/ and app/
       subdirectories."
352,2,flatpak,"Below these locations, there is a
       local repository in the repo/ subdirectory and installed runtimes
       and applications are in the corresponding runtime/ and app/
       subdirectories. System-wide remotes can be statically preconfigured by dropping
flatpakrepo(5)
files into /usr/share/flatpak/remotes.d/ and
       /etc/flatpak/remotes.d/. If a file with the same name exists in
       both, the file under /etc will take precedence."
352,3,flatpak,"If a file with the same name exists in
       both, the file under /etc will take precedence. In addition to the system-wide installation in
       $prefix/var/lib/flatpak/, which is always considered the default
       one unless overridden, more system-wide installations can be
       defined via configuration files in /etc/flatpak/installations.d/,
       which must define at least the id of the installation and the
       absolute path to it. Other optional parameters like DisplayName,
       Priority or StorageType are also supported."
352,4,flatpak,"Other optional parameters like DisplayName,
       Priority or StorageType are also supported. Flatpak uses OSTree to distribute and deploy data. The
       repositories it uses are OSTree repositories and can be
       manipulated with the
ostree
utility."
352,5,flatpak,"The
       repositories it uses are OSTree repositories and can be
       manipulated with the
ostree
utility. Installed runtimes and
       applications are OSTree checkouts. Basic commands for building flatpaks such as build-init, build and
       build-finish are included in the flatpak utility."
352,6,flatpak,"Basic commands for building flatpaks such as build-init, build and
       build-finish are included in the flatpak utility. For higher-level
       build support, see the separate
flatpak-builder
(1) tool. Flatpak supports installing from sideload repos."
352,7,flatpak,"Flatpak supports installing from sideload repos. These are partial
       copies of a repository (generated by
flatpak create-usb
) that are
       used as an installation source when offline (and online as a
       performance improvement). Such repositories are configured by
       creating symlinks to the sideload sources in the sideload-repos
       subdirectory of the installation directory (i.e."
352,8,flatpak,"Such repositories are configured by
       creating symlinks to the sideload sources in the sideload-repos
       subdirectory of the installation directory (i.e. typically
       /var/lib/flatpak/sideload-repos or
       ~/.local/share/flatpak/sideload-repos). Additionally symlinks can
       be created in /run/flatpak/sideload-repos which is a better
       location for non-persistent sources (as it is cleared on reboot)."
352,9,flatpak,"typically
       /var/lib/flatpak/sideload-repos or
       ~/.local/share/flatpak/sideload-repos). Additionally symlinks can
       be created in /run/flatpak/sideload-repos which is a better
       location for non-persistent sources (as it is cleared on reboot). These symlinks can point to either the directory given to
flatpak
create-usb
which by default writes to the subpath .ostree/repo, or
       directly to an ostree repo."
353,0,flatpak-update,"Updates applications and runtimes. REF is a reference to the
       application or runtime to update. If no REF is given, everything
       is updated, as well as appstream info for all remotes."
353,1,flatpak-update,"If no REF is given, everything
       is updated, as well as appstream info for all remotes. Each REF argument is a full or partial identifier in the flatpak
       ref format, which looks like ""(app|runtime)/ID/ARCH/BRANCH"". All
       elements except ID are optional and can be left out, including the
       slashes, so most of the time you need only specify ID."
353,2,flatpak-update,"All
       elements except ID are optional and can be left out, including the
       slashes, so most of the time you need only specify ID. Any part
       left out will be matched against what is installed, and if there
       are multiple matches an error message will list the alternatives. By default this looks for both apps and runtimes with the given
       REF, but you can limit this by using the
--app
or
--runtime
option, or by supplying the initial element in the REF."
353,3,flatpak-update,"By default this looks for both apps and runtimes with the given
       REF, but you can limit this by using the
--app
or
--runtime
option, or by supplying the initial element in the REF. Normally, this command updates the application to the tip of its
       branch. But it is possible to check out another commit, with the
--commit
option."
353,4,flatpak-update,"But it is possible to check out another commit, with the
--commit
option. If the configured remote for a ref being updated has a collection
       ID configured on it, Flatpak will search the sideload-repos
       directories configured either with the
--sideload-repo
option, or
       on a per-installation or system-wide basis (see
flatpak(1)
). Note that updating a runtime is different from installing a
       different branch, and runtime updates are expected to keep strict
       compatibility."
353,5,flatpak-update,"Note that updating a runtime is different from installing a
       different branch, and runtime updates are expected to keep strict
       compatibility. If an application update does cause a problem, it
       is possible to go back to the previous version, with the
--commit
option. In addition to updates, this command will offer to uninstall any
       unused end-of-life runtimes."
353,6,flatpak-update,"In addition to updates, this command will offer to uninstall any
       unused end-of-life runtimes. Runtimes that were explicitly
       installed (not as a dependency) or explicitly pinned (see
flatpak-pin(1)
) are left installed even if unused and end-of-life. Unless overridden with the
--user
,
--system
or
--installation
option, this command updates any matching refs in the standard
       system-wide installation and the per-user one."
354,0,fmt,"Reformat each paragraph in the FILE(s), writing to standard
       output. The option
-WIDTH
is an abbreviated form of
--width
=
DIGITS
. With no FILE, or when FILE is -, read standard input."
354,1,fmt,"With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too. -c
,
--crown-margin
preserve indentation of first two lines
-p
,
--prefix
=
STRING
reformat only lines beginning with STRING, reattaching the
              prefix to reformatted lines
-s
,
--split-only
split long lines, but do not refill
-t
,
--tagged-paragraph
indentation of first line different from second
-u
,
--uniform-spacing
one space between words, two after sentences
-w
,
--width
=
WIDTH
maximum line width (default of 75 columns)
-g
,
--goal
=
WIDTH
goal width (default of 93% of width)
--help
display this help and exit
--version
output version information and exit"
355,0,fold,"Wrap input lines in each FILE, writing to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
355,1,fold,"With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too. -b
,
--bytes
count bytes rather than columns
-s
,
--spaces
break at spaces
-w
,
--width
=
WIDTH
use WIDTH columns instead of 80
--help
display this help and exit
--version
output version information and exit"
356,0,fold,"The
fold
utility is a filter that shall fold lines from its input
       files, breaking the lines to have a maximum of
width
column
       positions (or bytes, if the
-b
option is specified). Lines shall
       be broken by the insertion of a <newline> such that each output
       line (referred to later in this section as a
segment
) is the
       maximum width possible that does not exceed the specified number
       of column positions (or bytes). A line shall not be broken in the
       middle of a character."
356,1,fold,"A line shall not be broken in the
       middle of a character. The behavior is undefined if
width
is less
       than the number of columns any single character in the input would
       occupy. If the <carriage-return>, <backspace>, or <tab> characters are
       encountered in the input, and the
-b
option is not specified, they
       shall be treated specially:

       <backspace>
                 The current count of line width shall be decremented by
                 one, although the count never shall become negative."
356,2,fold,"If the <carriage-return>, <backspace>, or <tab> characters are
       encountered in the input, and the
-b
option is not specified, they
       shall be treated specially:

       <backspace>
                 The current count of line width shall be decremented by
                 one, although the count never shall become negative. The
fold
utility shall not insert a <newline> immediately
                 before or after any <backspace>, unless the following
                 character has a width greater than 1 and would cause the
                 line width to exceed
width
. <carriage-return>
                 The current count of line width shall be set to zero."
356,3,fold,"<carriage-return>
                 The current count of line width shall be set to zero. The
fold
utility shall not insert a <newline>
                 immediately before or after any <carriage-return>. <tab>     Each <tab> encountered shall advance the column position
                 pointer to the next tab stop."
356,4,fold,"The
fold
utility shall not insert a <newline>
                 immediately before or after any <carriage-return>. <tab>     Each <tab> encountered shall advance the column position
                 pointer to the next tab stop. Tab stops shall be at each
                 column position
n
such that
n
modulo 8 equals 1."
357,0,fort77,"The
fort77
utility is the interface to the FORTRAN compilation
       system; it shall accept the full FORTRAN-77 language defined by
       the ANSI X3.9â1978 standard. The system conceptually consists of a
       compiler and link editor. The files referenced by
operand
s are
       compiled and linked to produce an executable file."
357,1,fort77,"The files referenced by
operand
s are
       compiled and linked to produce an executable file. It is
       unspecified whether the linking occurs entirely within the
       operation of
fort77
; some implementations may produce objects that
       are not fully resolved until the file is executed. If the
-c
option is present, for all pathname operands of the form
file
.f
, the files:

           $(basename
pathname
.f).o

       shall be created or overwritten as the result of successful
       compilation."
357,2,fort77,"If the
-c
option is present, for all pathname operands of the form
file
.f
, the files:

           $(basename
pathname
.f).o

       shall be created or overwritten as the result of successful
       compilation. If the
-c
option is not specified, it is unspecified
       whether such
.o
files are created or deleted for the
file
.f
operands. If there are no options that prevent link editing (such as
-c
) and
       all operands compile and link without error, the resulting
       executable file shall be written into the file named by the
-o
option (if present) or to the file
a.out
."
357,3,fort77,"If the
-c
option is not specified, it is unspecified
       whether such
.o
files are created or deleted for the
file
.f
operands. If there are no options that prevent link editing (such as
-c
) and
       all operands compile and link without error, the resulting
       executable file shall be written into the file named by the
-o
option (if present) or to the file
a.out
. The executable file
       shall be created as specified in the System Interfaces volume of
       POSIX.1â2017, except that the file permissions shall be set to:
       S_IRWXO | S_IRWXG | S_IRWXU

       and that the bits specified by the
umask
of the process shall be
       cleared."
358,0,free,"free
displays the total amount of free and used physical and swap
       memory in the system, as well as the buffers and caches used by
       the kernel. The information is gathered by parsing /proc/meminfo. The displayed columns are:
total
Total usable memory (MemTotal and SwapTotal in
              /proc/meminfo)."
358,1,free,"The displayed columns are:
total
Total usable memory (MemTotal and SwapTotal in
              /proc/meminfo). This includes the physical and swap memory
              minus a few reserved bits and kernel binary code. used
Used or unavailable memory (calculated as
total
-
available
)
free
Unused memory (MemFree and SwapFree in /proc/meminfo)
shared
Memory used (mostly) by tmpfs (Shmem in /proc/meminfo)
buffers
Memory used by kernel buffers (Buffers in /proc/meminfo)
cache
Memory used by the page cache and slabs (Cached and
              SReclaimable in /proc/meminfo)
buff/cache
Sum of
buffers
and
cache
available
Estimation of how much memory is available for starting new
              applications, without swapping."
358,2,free,"This includes the physical and swap memory
              minus a few reserved bits and kernel binary code. used
Used or unavailable memory (calculated as
total
-
available
)
free
Unused memory (MemFree and SwapFree in /proc/meminfo)
shared
Memory used (mostly) by tmpfs (Shmem in /proc/meminfo)
buffers
Memory used by kernel buffers (Buffers in /proc/meminfo)
cache
Memory used by the page cache and slabs (Cached and
              SReclaimable in /proc/meminfo)
buff/cache
Sum of
buffers
and
cache
available
Estimation of how much memory is available for starting new
              applications, without swapping. Unlike the data provided by
              the
cache
or
free
fields, this field takes into account
              page cache and also that not all reclaimable memory slabs
              will be reclaimed due to items being in use (MemAvailable
              in /proc/meminfo, available on kernels 3.14, emulated on
              kernels 2.6.27+, otherwise the same as
free
)"
359,0,inotifywait,"inotifywait
efficiently waits for changes to files using Linux's
inotify(7)
interface by default. It is suitable for waiting for
       changes to files from shell scripts. It can either exit once an
       event occurs, or continually execute and output events as they
       occur."
359,1,inotifywait,"It can either exit once an
       event occurs, or continually execute and output events as they
       occur. fsnotifywait
is similar to
inotifywait
but it is using Linux's
fanotify(7)
interface by default. If explicitly specified, it uses
       the
inotify(7)
interface."
360,0,inotifywatch,"inotifywatch
listens for filesystem events using Linux's
inotify(7)
interface by default, then outputs a summary count of
       the events received on each file or directory.
fsnotifywatch
is similar to
inotifywatch
but it is using Linux's
fanotify(7)
interface by default. If explicitly specified, it uses
       the
inotify(7)
interface."
361,0,fuse2fs,"fuse2fs
is a FUSE file system client that supports reading and
       writing from devices or image files containing ext2, ext3, and
       ext4 file systems."
362,0,fuser,"The
fuser
utility shall write to standard output the process IDs
       of processes running on the local system that have one or more
       named files open. For block special devices, all processes using
       any file on that device are listed. The
fuser
utility shall write to standard error additional
       information about the named files indicating how the file is being
       used."
362,1,fuser,"The
fuser
utility shall write to standard error additional
       information about the named files indicating how the file is being
       used. Any output for processes running on remote systems that have a
       named file open is unspecified. A user may need appropriate privileges to invoke the
fuser
utility."
363,0,fuser,"fuser
displays the PIDs of processes using the specified files or
       file systems. In the default display  mode,  each  file  name  is
       followed by a letter denoting the type of access:
c
current directory. e
executable being run."
363,1,fuser,"e
executable being run. f
open file. f
is omitted in default display mode."
363,2,fuser,"f
is omitted in default display mode. F
open file for writing. F
is omitted in default
                     display mode."
363,3,fuser,"F
is omitted in default
                     display mode. r
root directory. m
mmap'ed file or shared library."
363,4,fuser,"m
mmap'ed file or shared library. . Placeholder, omitted in default display mode."
363,5,fuser,"Placeholder, omitted in default display mode. fuser
returns a non-zero return code if none of the specified
       files is accessed or in case of a fatal error. If at least one
       access has been found,
fuser
returns zero."
363,6,fuser,"If at least one
       access has been found,
fuser
returns zero. In order to look up processes using TCP and UDP sockets, the
       corresponding name space has to be selected with the
-n
option. By
       default
fuser
will look in both IPv6 and IPv4 sockets."
363,7,fuser,"By
       default
fuser
will look in both IPv6 and IPv4 sockets. To change
       the default behavior, use the
-4
and
-6
options. The socket(s)
       can be specified by the local and remote port, and the remote
       address."
363,8,fuser,"The socket(s)
       can be specified by the local and remote port, and the remote
       address. All fields are optional, but commas in front of missing
       fields must be present:

       [
lcl_port
][,[
rmt_host
][,[
rmt_port
]]]

       Either symbolic or numeric values can be used for IP addresses and
       port numbers. fuser
outputs only the PIDs to stdout, everything else is sent to
       stderr."
364,0,fusermount3,"Filesystem in Userspace (FUSE) is a simple interface for userspace
       programs to export a virtual filesystem to the Linux kernel. It
       also aims to provide a secure method for non privileged users to
       create and mount their own filesystem implementations. fusermount3
is a program to mount and unmount FUSE filesystems."
364,1,fusermount3,"fusermount3
is a program to mount and unmount FUSE filesystems. It
       should be called directly only for unmounting FUSE file systems. To allow mounting and unmounting by unprivileged users,
fusermount3
needs to be installed set-uid root."
365,0,galera_new_cluster,"Used to bootstrap a new Galera Cluster when all nodes are down. Run galera_new_cluster on the first node only. On the remaining
       nodes simply run 'service @DAEMON_NAME@ start'."
365,1,galera_new_cluster,"Run galera_new_cluster on the first node only. On the remaining
       nodes simply run 'service @DAEMON_NAME@ start'. â¢
--help
,
-h
Display a help message and exit."
366,0,galera_recovery,"Use: Recover from non-graceful shutdown.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
367,0,ganglia2pcp,"ganglia2pcp
is intended to read a set of ganglia files stored in
       the rrd format and translate them into a Performance Co-Pilot
       (PCP) archive with the basename
outfile
. The intent of this converter is to take all of the rrd files found
       in the input_dir and generate a single pcp archive file. The
       mapping of ganglia metrics to pcp metrics is defined internally."
367,1,ganglia2pcp,"The
       mapping of ganglia metrics to pcp metrics is defined internally. The resultant PCP achive may be used with all the PCP client tools
       to graph subsets of the data using
pmchart(1)
, perform data
       reduction and reporting, filter with the PCP inference engine
pmie(1)
, etc. A series of physical files will be created with the prefix
outfile
."
367,2,ganglia2pcp,"A series of physical files will be created with the prefix
outfile
. These are
outfile
.0
(the performance data),
outfile
.meta
(the metadata that describes the performance data) and
outfile
.index
(a temporal index to improve efficiency of replay
       operations for the archive). If any of these files exists
       already, then
sar2pcp
will
not
overwrite them and will exit with
       an error message of the form

       __pmLogNewFile: ``blah.0'' already exists, not over-written
ganglia2pcp
is a Perl script that uses the PCP::LogImport Perl
       wrapper around the PCP
libpcp_import
library, and as such could be
       used as an example to develop new tools to import other types of
       performance data and create PCP archives."
367,3,ganglia2pcp,"These are
outfile
.0
(the performance data),
outfile
.meta
(the metadata that describes the performance data) and
outfile
.index
(a temporal index to improve efficiency of replay
       operations for the archive). If any of these files exists
       already, then
sar2pcp
will
not
overwrite them and will exit with
       an error message of the form

       __pmLogNewFile: ``blah.0'' already exists, not over-written
ganglia2pcp
is a Perl script that uses the PCP::LogImport Perl
       wrapper around the PCP
libpcp_import
library, and as such could be
       used as an example to develop new tools to import other types of
       performance data and create PCP archives. The RRDs Perl wrapper
       is used to parse the raw rrd format files."
368,0,gcore,"Generate core dumps of one or more running programs with process
       IDs
pid1
,
pid2
, etc.  A core file produced by
gcore
is equivalent
       to one produced by the kernel when the process crashes (and when
       ""ulimit -c"" was used to set up an appropriate core dump limit).
       However, unlike after a crash, after
gcore
finishes its job the
       program remains running without any change."
369,0,gcov-dump,"gcov-dump
is a tool you can use in conjunction with GCC to dump
       content of gcda and gcno profile files offline."
370,0,gcov-tool,"gcov-tool
is an offline tool to process gcc's gcda profile files. Current gcov-tool supports the following functionalities:

       *   merge two sets of profiles with weights. *   read one set of profile and rewrite profile contents."
370,1,gcov-tool,"*   read one set of profile and rewrite profile contents. One can
           scale or normalize the count values. Examples of the use cases for this tool are:

       *   Collect the profiles for different set of inputs, and use this
           tool to merge them."
370,2,gcov-tool,"Examples of the use cases for this tool are:

       *   Collect the profiles for different set of inputs, and use this
           tool to merge them. One can specify the weight to factor in
           the relative importance of each input. *   Rewrite the profile after removing a subset of the gcda files,
           while maintaining the consistency of the summary and the
           histogram."
370,3,gcov-tool,"*   Rewrite the profile after removing a subset of the gcda files,
           while maintaining the consistency of the summary and the
           histogram. *   It can also be used to debug or libgcov code as the tools
           shares the majority code as the runtime library. Note that for the merging operation, this profile generated
       offline may contain slight different values from the online merged
       profile."
370,4,gcov-tool,"Note that for the merging operation, this profile generated
       offline may contain slight different values from the online merged
       profile. Here are a list of typical differences:

       *   histogram difference: This offline tool recomputes the
           histogram after merging the counters. The resulting histogram,
           therefore, is precise."
370,5,gcov-tool,"The resulting histogram,
           therefore, is precise. The online merging does not have this
           capability -- the histogram is merged from two histograms and
           the result is an approximation. *   summary checksum difference: Summary checksum uses a CRC32
           operation."
370,6,gcov-tool,"*   summary checksum difference: Summary checksum uses a CRC32
           operation. The value depends on the link list order of gcov-
           info objects. This order is different in gcov-tool from that
           in the online merge."
370,7,gcov-tool,"This order is different in gcov-tool from that
           in the online merge. It's expected to have different summary
           checksums. It does not really matter as the compiler does not
           use this checksum anywhere."
370,8,gcov-tool,"It does not really matter as the compiler does not
           use this checksum anywhere. *   value profile counter values difference: Some counter values
           for value profile are runtime dependent, like heap addresses. It's normal to see some difference in these kind of counters."
371,0,gawk,"Gawk
is the GNU Project's implementation of the AWK programming
       language. It conforms to the definition of the language in the
       POSIX 1003.1 standard. This version in turn is based on the
       description in
The AWK Programming Language
, by Aho, Kernighan,
       and Weinberger."
371,1,gawk,"This version in turn is based on the
       description in
The AWK Programming Language
, by Aho, Kernighan,
       and Weinberger. Gawk
provides the additional features found in
       the current version of Brian Kernighan's
awk
and numerous GNU-
       specific extensions. The command line consists of options to
gawk
itself, the AWK
       program text (if not supplied via the
-f
or
--include
options),
       and values to be made available in the
ARGC
and
ARGV
pre-defined
       AWK variables."
372,0,gcov,"gcov
is a test coverage program. Use it in concert with GCC to
       analyze your programs to help create more efficient, faster
       running code and to discover untested parts of your program. You
       can use
gcov
as a profiling tool to help discover where your
       optimization efforts will best affect your code."
372,1,gcov,"You
       can use
gcov
as a profiling tool to help discover where your
       optimization efforts will best affect your code. You can also use
gcov
along with the other profiling tool,
gprof
, to assess which
       parts of your code use the greatest amount of computing time. Profiling tools help you analyze your code's performance."
372,2,gcov,"Profiling tools help you analyze your code's performance. Using a
       profiler such as
gcov
or
gprof
, you can find out some basic
       performance statistics, such as:

       *   how often each line of code executes

       *   what lines of code are actually executed

       *   how much computing time each section of code uses

       Once you know these things about how your code works when
       compiled, you can look at each module to see which modules should
       be optimized. gcov
helps you determine where to work on
       optimization."
372,3,gcov,"gcov
helps you determine where to work on
       optimization. Software developers also use coverage testing in concert with
       testsuites, to make sure software is actually good enough for a
       release. Testsuites can verify that a program works as expected;
       a coverage program tests to see how much of the program is
       exercised by the testsuite."
372,4,gcov,"Testsuites can verify that a program works as expected;
       a coverage program tests to see how much of the program is
       exercised by the testsuite. Developers can then determine what
       kinds of test cases need to be added to the testsuites to create
       both better testing and a better final product. You should compile your code without optimization if you plan to
       use
gcov
because the optimization, by combining some lines of code
       into one function, may not give you as much information as you
       need to look for `hot spots' where the code is using a great deal
       of computer time."
372,5,gcov,"You should compile your code without optimization if you plan to
       use
gcov
because the optimization, by combining some lines of code
       into one function, may not give you as much information as you
       need to look for `hot spots' where the code is using a great deal
       of computer time. Likewise, because
gcov
accumulates statistics
       by line (at the lowest resolution), it works best with a
       programming style that places only one statement on each line. If
       you use complicated macros that expand to loops or to other
       control structures, the statistics are less helpful---they only
       report on the line where the macro call appears."
372,6,gcov,"If
       you use complicated macros that expand to loops or to other
       control structures, the statistics are less helpful---they only
       report on the line where the macro call appears. If your complex
       macros behave like functions, you can replace them with inline
       functions to solve this problem. gcov
creates a logfile called
sourcefile.gcov
which indicates how
       many times each line of a source file
sourcefile.c
has executed."
372,7,gcov,"gcov
creates a logfile called
sourcefile.gcov
which indicates how
       many times each line of a source file
sourcefile.c
has executed. You can use these logfiles along with
gprof
to aid in fine-tuning
       the performance of your programs. gprof
gives timing information
       you can use along with the information you get from
gcov
."
372,8,gcov,"gprof
gives timing information
       you can use along with the information you get from
gcov
. gcov
works only on code compiled with GCC. It is not compatible
       with any other profiling or test coverage mechanism."
373,0,gdb-add-index,"When GDB finds a symbol file, it scans the symbols in the file in
       order to construct an internal symbol table. This lets most GDB
       operations work quickly--at the cost of a delay early on. For
       large programs, this delay can be quite lengthy, so GDB provides a
       way to build an index, which speeds up startup."
373,1,gdb-add-index,"For
       large programs, this delay can be quite lengthy, so GDB provides a
       way to build an index, which speeds up startup. To determine whether a file contains such an index, use the
       command ""readelf -S filename"": the index is stored in a section
       named "".gdb_index"" (pre-DWARF 5) or "".debug_names"" and
       "".debug_str"" (DWARF 5). Indexes can only be produced on systems
       which use ELF binaries and DWARF debug information (i.e., sections
       named "".debug_*"")."
373,2,gdb-add-index,"Indexes can only be produced on systems
       which use ELF binaries and DWARF debug information (i.e., sections
       named "".debug_*""). By default
gdb-add-index
will add a pre-DWARF 5 "".gdb_index""
       section to
filename
. With
-dwarf-5
DWARF 5 sections are added
       instead."
373,3,gdb-add-index,"With
-dwarf-5
DWARF 5 sections are added
       instead. filename
must be writable. gdb-add-index
uses GDB,
objcopy
, and
readelf
found in the
PATH
environment variable."
373,4,gdb-add-index,"gdb-add-index
uses GDB,
objcopy
, and
readelf
found in the
PATH
environment variable. If you want to use different versions of
       these programs, you can specify them through the appropriate
       environment variables (see below). gdb-add-index
exits with status 0 if it succeeds in creating the
       index for
filename
or greater than 0 if an error occurs."
373,5,gdb-add-index,"If you want to use different versions of
       these programs, you can specify them through the appropriate
       environment variables (see below). gdb-add-index
exits with status 0 if it succeeds in creating the
       index for
filename
or greater than 0 if an error occurs. See more in the GDB manual in node ""Index Files"" -- shell command
       ""info -f gdb -n ""Index Files""""."
374,0,gdb,"The purpose of a debugger such as GDB is to allow you to see what
       is going on ""inside"" another program while it executes -- or what
       another program was doing at the moment it crashed. GDB can do four main kinds of things (plus other things in support
       of these) to help you catch bugs in the act:

       â¢   Start your program, specifying anything that might affect its
           behavior. â¢   Make your program stop on specified conditions."
374,1,gdb,"â¢   Make your program stop on specified conditions. â¢   Examine what has happened, when your program has stopped. â¢   Change things in your program, so you can experiment with
           correcting the effects of one bug and go on to learn about
           another."
374,2,gdb,"â¢   Change things in your program, so you can experiment with
           correcting the effects of one bug and go on to learn about
           another. You can use GDB to debug programs written in C, C++, Fortran and
       Modula-2. GDB is invoked with the shell command ""gdb""."
374,3,gdb,"GDB is invoked with the shell command ""gdb"". Once started, it
       reads commands from the terminal until you tell it to exit with
       the GDB command ""quit"" or ""exit"". You can get online help from
       GDB itself by using the command ""help""."
374,4,gdb,"You can get online help from
       GDB itself by using the command ""help"". You can run ""gdb"" with no arguments or options; but the most usual
       way to start GDB is with one argument or two, specifying an
       executable program as the argument:

               gdb program

       You can also start with both an executable program and a core file
       specified:

               gdb program core

       You can, instead, specify a process ID as a second argument or use
       option ""-p"", if you want to debug a running process:

               gdb program 1234
               gdb -p 1234

       would attach GDB to process 1234. With option
-p
you can omit the
program
filename."
374,5,gdb,"With option
-p
you can omit the
program
filename. Here are some of the most frequently needed GDB commands:
break [
file
:][
function
|
line
]
Set a breakpoint at
function
or
line
(in
file
). run [
arglist
]
Start your program (with
arglist
, if specified)."
374,6,gdb,"run [
arglist
]
Start your program (with
arglist
, if specified). bt
Backtrace: display the program stack. print
expr
Display the value of an expression."
374,7,gdb,"print
expr
Display the value of an expression. c
Continue running your program (after stopping, e.g. at a
           breakpoint)."
374,8,gdb,"at a
           breakpoint). next
Execute next program line (after stopping); step
over
any
           function calls in the line. edit [
file
:]
function
look at the program line where it is presently stopped."
374,9,gdb,"edit [
file
:]
function
look at the program line where it is presently stopped. list [
file
:]
function
type the text of the program in the vicinity of where it is
           presently stopped. step
Execute next program line (after stopping); step
into
any
           function calls in the line."
374,10,gdb,"step
Execute next program line (after stopping); step
into
any
           function calls in the line. help [
name
]
Show information about GDB command
name
, or general
           information about using GDB. quit
exit
Exit from GDB."
374,11,gdb,"quit
exit
Exit from GDB. For full details on GDB, see
Using GDB: A Guide to the GNU Source-
Level Debugger
, by Richard M. Stallman and Roland H."
374,12,gdb,"Stallman and Roland H. Pesch. The
       same text is available online as the ""gdb"" entry in the ""info""
       program."
375,0,gdbserver,"gdbserver
is a program that allows you to run GDB on a different
       machine than the one which is running the program being debugged. Usage (server (target) side):

       First, you need to have a copy of the program you want to debug
       put onto the target system. The program can be stripped to save
       space if needed, as
gdbserver
doesn't care about symbols."
375,1,gdbserver,"The program can be stripped to save
       space if needed, as
gdbserver
doesn't care about symbols. All
       symbol handling is taken care of by the GDB running on the host
       system. To use the server, you log on to the target system, and run the
gdbserver
program."
375,2,gdbserver,"To use the server, you log on to the target system, and run the
gdbserver
program. You must tell it (a) how to communicate with
       GDB, (b) the name of your program, and (c) its arguments. The
       general syntax is:

               target> gdbserver <comm> <program> [<args> ...]

       For example, using a serial port, you might say:

               target> gdbserver /dev/com1 emacs foo.txt

       This tells
gdbserver
to debug emacs with an argument of foo.txt,
       and to communicate with GDB via
/dev/com1
."
375,3,gdbserver,"The
       general syntax is:

               target> gdbserver <comm> <program> [<args> ...]

       For example, using a serial port, you might say:

               target> gdbserver /dev/com1 emacs foo.txt

       This tells
gdbserver
to debug emacs with an argument of foo.txt,
       and to communicate with GDB via
/dev/com1
. gdbserver
now waits
       patiently for the host GDB to communicate with it. To use a TCP connection, you could say:

               target> gdbserver host:2345 emacs foo.txt

       This says pretty much the same thing as the last example, except
       that we are going to communicate with the ""host"" GDB via TCP."
375,4,gdbserver,"To use a TCP connection, you could say:

               target> gdbserver host:2345 emacs foo.txt

       This says pretty much the same thing as the last example, except
       that we are going to communicate with the ""host"" GDB via TCP. The
       ""host:2345"" argument means that we are expecting to see a TCP
       connection from ""host"" to local TCP port 2345. (Currently, the
       ""host"" part is ignored.)  You can choose any number you want for
       the port number as long as it does not conflict with any existing
       TCP ports on the target system."
375,5,gdbserver,"(Currently, the
       ""host"" part is ignored.)  You can choose any number you want for
       the port number as long as it does not conflict with any existing
       TCP ports on the target system. This same port number must be
       used in the host GDBs ""target remote"" command, which will be
       described shortly. Note that if you chose a port number that
       conflicts with another service,
gdbserver
will print an error
       message and exit."
375,6,gdbserver,"Note that if you chose a port number that
       conflicts with another service,
gdbserver
will print an error
       message and exit. gdbserver
can also attach to running programs. This is
       accomplished via the
--attach
argument."
375,7,gdbserver,"This is
       accomplished via the
--attach
argument. The syntax is:

               target> gdbserver --attach <comm> <pid>
pid
is the process ID of a currently running process. It isn't
       necessary to point
gdbserver
at a binary for the running process."
375,8,gdbserver,"It isn't
       necessary to point
gdbserver
at a binary for the running process. To start ""gdbserver"" without supplying an initial command to run
       or process ID to attach, use the
--multi
command line option. In
       such case you should connect using ""target extended-remote"" to
       start the program you want to debug."
375,9,gdbserver,"In
       such case you should connect using ""target extended-remote"" to
       start the program you want to debug. target> gdbserver --multi <comm>

       Usage (host side):

       You need an unstripped copy of the target program on your host
       system, since GDB needs to examine its symbol tables and such. Start up GDB as you normally would, with the target program as the
       first argument."
375,10,gdbserver,"Start up GDB as you normally would, with the target program as the
       first argument. (You may need to use the
--baud
option if the
       serial line is running at anything except 9600 baud.)  That is
       ""gdb TARGET-PROG"", or ""gdb --baud BAUD TARGET-PROG"". After that,
       the only new command you need to know about is ""target remote"" (or
       ""target extended-remote"")."
375,11,gdbserver,"After that,
       the only new command you need to know about is ""target remote"" (or
       ""target extended-remote""). Its argument is either a device name
       (usually a serial device, like
/dev/ttyb
), or a ""HOST:PORT""
       descriptor. For example:

               (gdb) target remote /dev/ttyb

       communicates with the server via serial line
/dev/ttyb
, and:

               (gdb) target remote the-target:2345

       communicates via a TCP connection to port 2345 on host
       `the-target', where you previously started up
gdbserver
with the
       same port number."
375,12,gdbserver,"For example:

               (gdb) target remote /dev/ttyb

       communicates with the server via serial line
/dev/ttyb
, and:

               (gdb) target remote the-target:2345

       communicates via a TCP connection to port 2345 on host
       `the-target', where you previously started up
gdbserver
with the
       same port number. Note that for TCP connections, you must start
       up
gdbserver
prior to using the `target remote' command, otherwise
       you may get an error that looks something like `Connection
       refused'. gdbserver
can also debug multiple inferiors at once, described in
       the GDB manual in node ""Inferiors Connections and Programs"" --
       shell command ""info -f gdb -n 'Inferiors Connections and
       Programs'""."
375,13,gdbserver,"Note that for TCP connections, you must start
       up
gdbserver
prior to using the `target remote' command, otherwise
       you may get an error that looks something like `Connection
       refused'. gdbserver
can also debug multiple inferiors at once, described in
       the GDB manual in node ""Inferiors Connections and Programs"" --
       shell command ""info -f gdb -n 'Inferiors Connections and
       Programs'"". In such case use the ""extended-remote"" GDB command
       variant:

               (gdb) target extended-remote the-target:2345

       The
gdbserver
option
--multi
may or may not be used in such case."
376,0,genbrk,"genbrk
reads the break (boundary) rule source code from
rule-file
and creates a break iteration data file. Normally this data file
       has the
.brk
extension.

       The details of the rule syntax can be found in ICU's User Guide."
377,0,gencat,"The
gencat
utility shall merge the message text source file
msgfile
into a formatted message catalog
catfile
. The file
catfile
shall be created if it does not already exist. If
catfile
does exist, its messages shall be included in the new
catfile
."
377,1,gencat,"The file
catfile
shall be created if it does not already exist. If
catfile
does exist, its messages shall be included in the new
catfile
. If
       set and message numbers collide, the new message text defined in
msgfile
shall replace the old message text currently contained in
catfile
."
378,0,gdiffmk,nan
379,0,gencfu,"gencfu
reads confusable character definitions in the input file,
       which are plain text files containing confusable character
       definitions in the input format defined by Unicode UAX39 for the
       files
confusables.txt
and
confusablesWholeScript.txt. This source
       (.txt) format is also accepted by ICU spoof detectors. The files
       must be encoded in utf-8 format, with or without a BOM."
379,1,gencfu,"This source
       (.txt) format is also accepted by ICU spoof detectors. The files
       must be encoded in utf-8 format, with or without a BOM. Normally
       the output data file has the
.cfu
extension."
380,0,gencnval,"gencnval
converts the ICU aliases file
converterfile
into the
       binary file
cnvalias.icu
.  This binary file can then be read
       directly by ICU, or used by
pkgdata(1)
for incorporation into a
       larger archive or library.

       If
converterfile
is not provided, the default ICU
convrtrs.txt
file is used."
381,0,gendict,"gendict
reads the word list from
dictionary-file
and creates a
       string trie dictionary file. Normally this data file has the
.dict
extension. Words begin at the beginning of a line and are terminated by the
       first whitespace."
381,1,gendict,"Normally this data file has the
.dict
extension. Words begin at the beginning of a line and are terminated by the
       first whitespace. Lines that begin with whitespace are ignored."
382,0,gendiff,"gendiff
is a rather simple script which aids in generating a diff
       file from a single directory. It takes a directory name and a
       ""diff-extension"" as its only arguments. The diff extension should
       be a unique sequence of characters added to the end of all
       original, unmodified files."
382,1,gendiff,"The diff extension should
       be a unique sequence of characters added to the end of all
       original, unmodified files. The output of the program is a diff
       file which may be applied with the
patch
program to recreate the
       changes. The usual sequence of events for creating a diff is to create two
       identical directories, make changes in one directory, and then use
       the
diff
utility to create a list of differences between the two."
382,2,gendiff,"The usual sequence of events for creating a diff is to create two
       identical directories, make changes in one directory, and then use
       the
diff
utility to create a list of differences between the two. Using gendiff eliminates the need for the extra, original and
       unmodified directory copy. Instead, only the individual files
       that are modified need to be saved."
382,3,gendiff,"Instead, only the individual files
       that are modified need to be saved. Before editing a file, copy the file, appending the extension you
       have chosen to the filename. I.e."
382,4,gendiff,"I.e. if you were going to edit
       somefile.cpp and have chosen the extension ""fix"", copy it to
       somefile.cpp.fix before editing it. Then edit the first copy
       (somefile.cpp)."
382,5,gendiff,"if you were going to edit
       somefile.cpp and have chosen the extension ""fix"", copy it to
       somefile.cpp.fix before editing it. Then edit the first copy
       (somefile.cpp). After editing all the files you need to edit in this fashion,
       enter the directory one level above where your source code
       resides, and then type

                  $ gendiff somedirectory .fix > mydiff-fix.patch

       You should redirect the output to a file (as illustrated) unless
       you want to see the results on stdout."
383,0,pmdatxmon,"pmdatxmon
is an example Performance Metrics Domain Agent (PMDA)
       which exports a small number of performance metrics from a
       simulated transaction monitor. The txmon PMDA is shipped as both binary and source code and is
       designed to be an aid for PMDA developers; the txmon PMDA
       demonstrates how performance data can be exported from an
       application (in this case
txrecord
) to the PCP infrastructure via
       a shared memory segment. As a matter of convenience,
pmdatxmon
creates (and destroys on exit) the shared memory segment."
383,1,pmdatxmon,"As a matter of convenience,
pmdatxmon
creates (and destroys on exit) the shared memory segment. The
tx_type
arguments are arbitrary unique tags used to identify
       different transaction types. The
txrecord
application simulates the processing of one or more
       transactions identified by
tx_type
and with an observed service
       time of
servtime ."
383,2,pmdatxmon,"The
txrecord
application simulates the processing of one or more
       transactions identified by
tx_type
and with an observed service
       time of
servtime . With the
-l
option,
txrecord
displays the current summary of the
       transaction activity from the shared memory segment. genload
is a shell and
awk
(1) script that acts as a front-end to
txrecord
to generate a constant load of simulated transaction
       activity."
383,3,pmdatxmon,"genload
is a shell and
awk
(1) script that acts as a front-end to
txrecord
to generate a constant load of simulated transaction
       activity. A brief description of the
pmdatxmon
command line options follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
383,4,pmdatxmon,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
txmon.log
is written in the current directory of
pmcd(1)
when
pmdatxmon
is started, i.e."
383,5,pmdatxmon,"By default, a log file named
txmon.log
is written in the current directory of
pmcd(1)
when
pmdatxmon
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log
            file cannot be created or is not writable, output is written
            to the standard error instead."
383,6,pmdatxmon,"If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
384,0,genpmda,"genpmda
is a rapid application development tool for creating new
       Performance Metrics Domain Agents, see
PMDA(3)
. It provides a
       very easy and efficient way to extend the Performance Co-pilot
       (PCP) with new performance metrics without needing to understand
       the low level details of how PMDAs are constructed. genpmda
reads a config file containing an augmented Performance
       Metrics Name Space, see
PMNS(5)
, and automatically generates
       virtually all of the source code to implement a fully functional
       PMDA, including the Makefile, name space, support scripts for
       configuring the new PMDA, and the metrics help text."
384,1,genpmda,"genpmda
reads a config file containing an augmented Performance
       Metrics Name Space, see
PMNS(5)
, and automatically generates
       virtually all of the source code to implement a fully functional
       PMDA, including the Makefile, name space, support scripts for
       configuring the new PMDA, and the metrics help text. Fairly
       simple PMDAs can be automatically generated from the config file
       without writing any additional code. More complicated PMDAs, e.g."
384,2,genpmda,"More complicated PMDAs, e.g. containing multiple instance domains, require only the refresh
       methods for the instance domains to be written manually. An example of the config file format accepted by
genpmda
is given
       below."
385,0,genrb,"genrb
converts the resource
bundle
source files passed on the
       command line to their binary form or to a Java source file for use
       with ICU4J. The resulting binary files have a
.res
extension
       while resource bundle source files typically have a
.txt
extension. Java source files have a
java
extension and follow the
       ICU4J naming conventions."
385,1,genrb,"Java source files have a
java
extension and follow the
       ICU4J naming conventions. It is customary to name the resource bundles by their locale name,
       i.e. to use a local identifier for the
bundle
filename, e.g."
385,2,genrb,"to use a local identifier for the
bundle
filename, e.g. ja_JP.txt
for Japanese (Japan) data, or
root.txt
for the root
       bundle. In any case,
genrb
will produce a file whose base name is
       the name of the locale found in the resource file, not the base
       name of the resource file itself."
385,3,genrb,"ja_JP.txt
for Japanese (Japan) data, or
root.txt
for the root
       bundle. In any case,
genrb
will produce a file whose base name is
       the name of the locale found in the resource file, not the base
       name of the resource file itself. The binary files can be read directly by ICU, or used by
pkgdata(1)
for incorporation into a larger archive or library."
386,0,getfacl,"For each file, getfacl displays the file name, owner, the group,
       and the Access Control List (ACL). If a directory has a default
       ACL, getfacl also displays the default ACL. Non-directories cannot
       have default ACLs."
386,1,getfacl,"Non-directories cannot
       have default ACLs. If getfacl is used on a file system that does not support ACLs,
       getfacl displays the access permissions defined by the traditional
       file mode permission bits. The output format of getfacl is as follows:
               1:  # file: somedir/
               2:  # owner: lisa
               3:  # group: staff
               4:  # flags: -s-
               5:  user::rwx
               6:  user:joe:rwx               #effective:r-x
               7:  group::rwx                 #effective:r-x
               8:  group:cool:r-x
               9:  mask::r-x
              10:  other::r-x
              11:  default:user::rwx
              12:  default:user:joe:rwx       #effective:r-x
              13:  default:group::r-x
              14:  default:mask::r-x
              15:  default:other::---

       Lines 1--3 indicate the file name, owner, and owning group."
386,2,getfacl,"The output format of getfacl is as follows:
               1:  # file: somedir/
               2:  # owner: lisa
               3:  # group: staff
               4:  # flags: -s-
               5:  user::rwx
               6:  user:joe:rwx               #effective:r-x
               7:  group::rwx                 #effective:r-x
               8:  group:cool:r-x
               9:  mask::r-x
              10:  other::r-x
              11:  default:user::rwx
              12:  default:user:joe:rwx       #effective:r-x
              13:  default:group::r-x
              14:  default:mask::r-x
              15:  default:other::---

       Lines 1--3 indicate the file name, owner, and owning group. Line 4 indicates the setuid (s), setgid (s), and sticky (t) bits:
       either the letter representing the bit, or else a dash (-). This
       line is included if any of those bits is set and left out
       otherwise, so it will not be shown for most files."
386,3,getfacl,"This
       line is included if any of those bits is set and left out
       otherwise, so it will not be shown for most files. (See
       CONFORMANCE TO POSIX 1003.1e DRAFT STANDARD 17 below.)

       Lines 5, 7 and 10 correspond to the user, group and other fields
       of the file mode permission bits. These three are called the base
       ACL entries."
386,4,getfacl,"These three are called the base
       ACL entries. Lines 6 and 8 are named user and named group entries. Line 9 is the effective rights mask."
386,5,getfacl,"Line 9 is the effective rights mask. This entry limits the
       effective rights granted to all groups and to named users. (The
       file owner and others permissions are not affected by the
       effective rights mask; all other entries are.)  Lines 11--15
       display the default ACL associated with this directory."
386,6,getfacl,"(The
       file owner and others permissions are not affected by the
       effective rights mask; all other entries are.)  Lines 11--15
       display the default ACL associated with this directory. Directories may have a default ACL. Regular files never have a
       default ACL."
386,7,getfacl,"Regular files never have a
       default ACL. The default behavior for getfacl is to display both the ACL and
       the default ACL, and to include an effective rights comment for
       lines where the rights of the entry differ from the effective
       rights. If output is to a terminal, the effective rights comment is
       aligned to column 40."
386,8,getfacl,"If output is to a terminal, the effective rights comment is
       aligned to column 40. Otherwise, a single tab character separates
       the ACL entry and the effective rights comment. The ACL listings of multiple files are separated by blank lines."
386,9,getfacl,"The ACL listings of multiple files are separated by blank lines. The output of getfacl can also be used as input to setfacl. PERMISSIONS
Process with search access to a file (i.e., processes with read
       access to the containing directory of a file) are also granted
       read access to the file's ACLs."
386,10,getfacl,"The output of getfacl can also be used as input to setfacl. PERMISSIONS
Process with search access to a file (i.e., processes with read
       access to the containing directory of a file) are also granted
       read access to the file's ACLs. This is analogous to the
       permissions required for accessing the file mode."
387,0,getent,"The
getent
command displays entries from databases supported by
       the Name Service Switch libraries, which are configured in
/etc/nsswitch.conf
. If one or more
key
arguments are provided,
       then only the entries that match the supplied keys will be
       displayed. Otherwise, if no
key
is provided, all entries will be
       displayed (unless the database does not support enumeration)."
387,1,getent,"Otherwise, if no
key
is provided, all entries will be
       displayed (unless the database does not support enumeration). The
database
may be any of those supported by the GNU C Library,
       listed below:
ahosts
When no
key
is provided, use
sethostent(3)
,
gethostent(3)
,
              and
endhostent(3)
to enumerate the hosts database. This is
              identical to using
hosts(5)
."
387,2,getent,"This is
              identical to using
hosts(5)
. When one or more
key
arguments are provided, pass each
key
in succession to
getaddrinfo(3)
with the address family
AF_UNSPEC
,
              enumerating each socket address structure returned. ahostsv4
Same as
ahosts
, but use the address family
AF_INET
."
387,3,getent,"ahostsv4
Same as
ahosts
, but use the address family
AF_INET
. ahostsv6
Same as
ahosts
, but use the address family
AF_INET6
. The
              call to
getaddrinfo(3)
in this case includes the
AI_V4MAPPED
flag."
387,4,getent,"The
              call to
getaddrinfo(3)
in this case includes the
AI_V4MAPPED
flag. aliases
When no
key
is provided, use
setaliasent(3)
,
getaliasent(3)
, and
endaliasent(3)
to enumerate the aliases
              database. When one or more
key
arguments are provided,
              pass each
key
in succession to
getaliasbyname(3)
and
              display the result."
387,5,getent,"When one or more
key
arguments are provided,
              pass each
key
in succession to
getaliasbyname(3)
and
              display the result. ethers
When one or more
key
arguments are provided, pass each
key
in succession to
ether_aton(3)
and
ether_hostton(3)
until a
              result is obtained, and display the result. Enumeration is
              not supported on
ethers
, so a
key
must be provided."
387,6,getent,"Enumeration is
              not supported on
ethers
, so a
key
must be provided. group
When no
key
is provided, use
setgrent(3)
,
getgrent(3)
, and
endgrent(3)
to enumerate the group database. When one or
              more
key
arguments are provided, pass each numeric
key
to
getgrgid(3)
and each nonnumeric
key
to
getgrnam(3)
and
              display the result."
387,7,getent,"When one or
              more
key
arguments are provided, pass each numeric
key
to
getgrgid(3)
and each nonnumeric
key
to
getgrnam(3)
and
              display the result. gshadow
When no
key
is provided, use
setsgent
(3),
getsgent
(3), and
endsgent
(3) to enumerate the gshadow database. When one or
              more
key
arguments are provided, pass each
key
in
              succession to
getsgnam
(3) and display the result."
387,8,getent,"When one or
              more
key
arguments are provided, pass each
key
in
              succession to
getsgnam
(3) and display the result. hosts
When no
key
is provided, use
sethostent(3)
,
gethostent(3)
,
              and
endhostent(3)
to enumerate the hosts database. When
              one or more
key
arguments are provided, pass each
key
to
gethostbyaddr(3)
or
gethostbyname2(3)
, depending on whether
              a call to
inet_pton(3)
indicates that the
key
is an IPv6 or
              IPv4 address or not, and display the result."
387,9,getent,"When
              one or more
key
arguments are provided, pass each
key
to
gethostbyaddr(3)
or
gethostbyname2(3)
, depending on whether
              a call to
inet_pton(3)
indicates that the
key
is an IPv6 or
              IPv4 address or not, and display the result. initgroups
When one or more
key
arguments are provided, pass each
key
in succession to
getgrouplist(3)
and display the result. Enumeration is not supported on
initgroups
, so a
key
must
              be provided."
387,10,getent,"Enumeration is not supported on
initgroups
, so a
key
must
              be provided. netgroup
When one
key
is provided, pass the
key
to
setnetgrent(3)
and, using
getnetgrent(3)
display the resulting string
              triple (
hostname
,
username
,
domainname
). Alternatively,
              three
keys
may be provided, which are interpreted as the
hostname
,
username
, and
domainname
to match to a netgroup
              name via
innetgr(3)
."
387,11,getent,"Alternatively,
              three
keys
may be provided, which are interpreted as the
hostname
,
username
, and
domainname
to match to a netgroup
              name via
innetgr(3)
. Enumeration is not supported on
netgroup
, so either one or three
keys
must be provided. networks
When no
key
is provided, use
setnetent(3)
,
getnetent(3)
,
              and
endnetent(3)
to enumerate the networks database."
387,12,getent,"networks
When no
key
is provided, use
setnetent(3)
,
getnetent(3)
,
              and
endnetent(3)
to enumerate the networks database. When
              one or more
key
arguments are provided, pass each numeric
key
to
getnetbyaddr(3)
and each nonnumeric
key
to
getnetbyname(3)
and display the result. passwd
When no
key
is provided, use
setpwent(3)
,
getpwent(3)
, and
endpwent(3)
to enumerate the passwd database."
387,13,getent,"passwd
When no
key
is provided, use
setpwent(3)
,
getpwent(3)
, and
endpwent(3)
to enumerate the passwd database. When one or
              more
key
arguments are provided, pass each numeric
key
to
getpwuid(3)
and each nonnumeric
key
to
getpwnam(3)
and
              display the result. protocols
When no
key
is provided, use
setprotoent(3)
,
getprotoent(3)
, and
endprotoent(3)
to enumerate the
              protocols database."
387,14,getent,"protocols
When no
key
is provided, use
setprotoent(3)
,
getprotoent(3)
, and
endprotoent(3)
to enumerate the
              protocols database. When one or more
key
arguments are
              provided, pass each numeric
key
to
getprotobynumber(3)
and
              each nonnumeric
key
to
getprotobyname(3)
and display the
              result. rpc
When no
key
is provided, use
setrpcent(3)
,
getrpcent(3)
,
              and
endrpcent(3)
to enumerate the rpc database."
387,15,getent,"rpc
When no
key
is provided, use
setrpcent(3)
,
getrpcent(3)
,
              and
endrpcent(3)
to enumerate the rpc database. When one
              or more
key
arguments are provided, pass each numeric
key
to
getrpcbynumber(3)
and each nonnumeric
key
to
getrpcbyname(3)
and display the result. services
When no
key
is provided, use
setservent(3)
,
getservent(3)
,
              and
endservent(3)
to enumerate the services database."
387,16,getent,"services
When no
key
is provided, use
setservent(3)
,
getservent(3)
,
              and
endservent(3)
to enumerate the services database. When
              one or more
key
arguments are provided, pass each numeric
key
to
getservbynumber
(3) and each nonnumeric
key
to
getservbyname(3)
and display the result. shadow
When no
key
is provided, use
setspent(3)
,
getspent(3)
, and
endspent(3)
to enumerate the shadow database."
387,17,getent,"When
              one or more
key
arguments are provided, pass each numeric
key
to
getservbynumber
(3) and each nonnumeric
key
to
getservbyname(3)
and display the result. shadow
When no
key
is provided, use
setspent(3)
,
getspent(3)
, and
endspent(3)
to enumerate the shadow database. When one or
              more
key
arguments are provided, pass each
key
in
              succession to
getspnam(3)
and display the result."
388,0,getconf,"In the first synopsis form, the
getconf
utility shall write to the
       standard output the value of the variable specified by the
system_var
operand. In the second synopsis form, the
getconf
utility shall write to
       the standard output the value of the variable specified by the
path_var
operand for the path specified by the
pathname
operand. The value of each configuration variable shall be determined as if
       it were obtained by calling the function from which it is defined
       to be available by this volume of POSIX.1â2017 or by the System
       Interfaces volume of POSIX.1â2017 (see the OPERANDS section)."
388,1,getconf,"In the second synopsis form, the
getconf
utility shall write to
       the standard output the value of the variable specified by the
path_var
operand for the path specified by the
pathname
operand. The value of each configuration variable shall be determined as if
       it were obtained by calling the function from which it is defined
       to be available by this volume of POSIX.1â2017 or by the System
       Interfaces volume of POSIX.1â2017 (see the OPERANDS section). The
       value shall reflect conditions in the current operating
       environment."
389,0,get,"The
get
utility shall generate a text file from each named SCCS
file
according to the specifications given by its options.

       The generated text shall normally be written into a file called
       the
g-file
whose name is derived from the SCCS filename by simply
       removing the leading
""s.""
."
390,0,getfattr,"For each file,
getfattr
displays the file name, and the set of
       extended attribute names (and optionally values) which are
       associated with that file. Per default only attributes in the user
       namespace are displayed, see
-m
. The output format of
getfattr -d
is as follows:
               1:  # file: somedir/
               2:  user.name0=""value0""
               3:  user.name1=""value1""
               4:  user.name2=""value2""
               5:  ..."
390,1,getfattr,"The output format of
getfattr -d
is as follows:
               1:  # file: somedir/
               2:  user.name0=""value0""
               3:  user.name1=""value1""
               4:  user.name2=""value2""
               5:  ... Line 1 identifies the file name for which the following lines are
       being reported. The remaining lines (lines 2 to 4 above) show the
name
and
value
pairs associated with the specified file."
391,0,getopt,"getopt
is used to break up (
parse
) options in command lines for
       easy parsing by shell procedures, and to check for valid options. It uses the GNU
getopt(3)
routines to do this. The parameters
getopt
is called with can be divided into two
       parts: options which modify the way
getopt
will do the parsing
       (the
options
and the
optstring
in the
SYNOPSIS
), and the
       parameters which are to be parsed (
parameters
in the
SYNOPSIS
)."
391,1,getopt,"The parameters
getopt
is called with can be divided into two
       parts: options which modify the way
getopt
will do the parsing
       (the
options
and the
optstring
in the
SYNOPSIS
), and the
       parameters which are to be parsed (
parameters
in the
SYNOPSIS
). The second part will start at the first non-option parameter that
       is not an option argument, or after the first occurrence of '
--
'. If no '
-o
' or '
--options
' option is found in the first part, the
       first parameter of the second part is used as the short options
       string."
391,2,getopt,"If no '
-o
' or '
--options
' option is found in the first part, the
       first parameter of the second part is used as the short options
       string. If the environment variable
GETOPT_COMPATIBLE
is set, or if the
       first
parameter
is not an option (does not start with a '
-
', the
       first format in the
SYNOPSIS
),
getopt
will generate output that is
       compatible with that of other versions of
getopt(1)
. It will still
       do parameter shuffling and recognize optional arguments (see the
COMPATIBILITY
section for more information)."
391,3,getopt,"It will still
       do parameter shuffling and recognize optional arguments (see the
COMPATIBILITY
section for more information). Traditional implementations of
getopt(1)
are unable to cope with
       whitespace and other (shell-specific) special characters in
       arguments and non-option parameters. To solve this problem, this
       implementation can generate quoted output which must once again be
       interpreted by the shell (usually by using the
eval
command)."
391,4,getopt,"To solve this problem, this
       implementation can generate quoted output which must once again be
       interpreted by the shell (usually by using the
eval
command). This
       has the effect of preserving those characters, but you must call
getopt
in a way that is no longer compatible with other versions
       (the second or third format in the
SYNOPSIS
). To determine whether
       this enhanced version of
getopt(1)
is installed, a special test
       option (
-T
) can be used."
392,0,getopts,"The
getopts
utility shall retrieve options and option-arguments
       from a list of parameters. It shall support the Utility Syntax
       Guidelines 3 to 10, inclusive, described in the Base Definitions
       volume of POSIX.1â2017,
Section 12.2
,
Utility Syntax Guidelines
. Each time it is invoked, the
getopts
utility shall place the value
       of the next option in the shell variable specified by the
name
operand and the index of the next argument to be processed in the
       shell variable
OPTIND
."
392,1,getopts,"Each time it is invoked, the
getopts
utility shall place the value
       of the next option in the shell variable specified by the
name
operand and the index of the next argument to be processed in the
       shell variable
OPTIND
. Whenever the shell is invoked,
OPTIND
shall be initialized to 1. When the option requires an option-argument, the
getopts
utility
       shall place it in the shell variable
OPTARG
."
392,2,getopts,"When the option requires an option-argument, the
getopts
utility
       shall place it in the shell variable
OPTARG
. If no option was
       found, or if the option that was found does not have an option-
       argument,
OPTARG
shall be unset. If an option character not contained in the
optstring
operand is
       found where an option character is expected, the shell variable
       specified by
name
shall be set to the <question-mark> (
'?'
)
       character."
392,3,getopts,"If an option character not contained in the
optstring
operand is
       found where an option character is expected, the shell variable
       specified by
name
shall be set to the <question-mark> (
'?'
)
       character. In this case, if the first character in
optstring
is a
       <colon> (
':'
), the shell variable
OPTARG
shall be set to the
       option character found, but no output shall be written to standard
       error; otherwise, the shell variable
OPTARG
shall be unset and a
       diagnostic message shall be written to standard error. This
       condition shall be considered to be an error detected in the way
       arguments were presented to the invoking application, but shall
       not be an error in
getopts
processing."
392,4,getopts,"This
       condition shall be considered to be an error detected in the way
       arguments were presented to the invoking application, but shall
       not be an error in
getopts
processing. If an option-argument is missing:

        *  If the first character of
optstring
is a <colon>, the shell
           variable specified by
name
shall be set to the <colon>
           character and the shell variable
OPTARG
shall be set to the
           option character found. *  Otherwise, the shell variable specified by
name
shall be set
           to the <question-mark> character, the shell variable
OPTARG
shall be unset, and a diagnostic message shall be written to
           standard error."
392,5,getopts,"*  Otherwise, the shell variable specified by
name
shall be set
           to the <question-mark> character, the shell variable
OPTARG
shall be unset, and a diagnostic message shall be written to
           standard error. This condition shall be considered to be an
           error detected in the way arguments were presented to the
           invoking application, but shall not be an error in
getopts
processing; a diagnostic message shall be written as stated,
           but the exit status shall be zero. When the end of options is encountered, the
getopts
utility shall
       exit with a return value greater than zero; the shell variable
OPTIND
shall be set to the index of the first operand, or the
       value
""$#""
+1 if there are no operands; the
name
variable shall be
       set to the <question-mark> character."
392,6,getopts,"When the end of options is encountered, the
getopts
utility shall
       exit with a return value greater than zero; the shell variable
OPTIND
shall be set to the index of the first operand, or the
       value
""$#""
+1 if there are no operands; the
name
variable shall be
       set to the <question-mark> character. Any of the following shall
       identify the end of options: the first
""--""
argument that is not
       an option-argument, finding an argument that is not an option-
       argument and does not begin with a
'-'
, or encountering an error. The shell variables
OPTIND
and
OPTARG
shall be local to the caller
       of
getopts
and shall not be exported by default."
392,7,getopts,"The shell variables
OPTIND
and
OPTARG
shall be local to the caller
       of
getopts
and shall not be exported by default. The shell variable specified by the
name
operand,
OPTIND
, and
OPTARG
shall affect the current shell execution environment; see
Section 2.12
,
Shell Execution Environment
. If the application sets
OPTIND
to the value 1, a new set of
       parameters can be used: either the current positional parameters
       or new
arg
values."
392,8,getopts,"The shell variable specified by the
name
operand,
OPTIND
, and
OPTARG
shall affect the current shell execution environment; see
Section 2.12
,
Shell Execution Environment
. If the application sets
OPTIND
to the value 1, a new set of
       parameters can be used: either the current positional parameters
       or new
arg
values. Any other attempt to invoke
getopts
multiple
       times in a single shell execution environment with parameters
       (positional parameters or
arg
operands) that are not the same in
       all invocations, or with an
OPTIND
value modified to be a value
       other than 1, produces unspecified results."
393,0,g++,"When you invoke GCC, it normally does preprocessing, compilation,
       assembly and linking. The ""overall options"" allow you to stop
       this process at an intermediate stage. For example, the
-c
option
       says not to run the linker."
393,1,g++,"For example, the
-c
option
       says not to run the linker. Then the output consists of object
       files output by the assembler. Other options are passed on to one or more stages of processing."
393,2,g++,"Other options are passed on to one or more stages of processing. Some options control the preprocessor and others the compiler
       itself. Yet other options control the assembler and linker; most
       of these are not documented here, since you rarely need to use any
       of them."
393,3,g++,"Yet other options control the assembler and linker; most
       of these are not documented here, since you rarely need to use any
       of them. Most of the command-line options that you can use with GCC are
       useful for C programs; when an option is only useful with another
       language (usually C++), the explanation says so explicitly. If
       the description for a particular option does not mention a source
       language, you can use that option with all supported languages."
393,4,g++,"If
       the description for a particular option does not mention a source
       language, you can use that option with all supported languages. The usual way to run GCC is to run the executable called
gcc
, or
machine
-gcc
when cross-compiling, or
machine
-gcc-
version
to run a
       specific version of GCC. When you compile C++ programs, you
       should invoke GCC as
g++
instead."
393,5,g++,"When you compile C++ programs, you
       should invoke GCC as
g++
instead. The
gcc
program accepts options and file names as operands. Many
       options have multi-letter names; therefore multiple single-letter
       options may
not
be grouped:
-dv
is very different from
-d -v
."
393,6,g++,"Many
       options have multi-letter names; therefore multiple single-letter
       options may
not
be grouped:
-dv
is very different from
-d -v
. You can mix options and other arguments. For the most part, the
       order you use doesn't matter."
393,7,g++,"For the most part, the
       order you use doesn't matter. Order does matter when you use
       several options of the same kind; for example, if you specify
-L
more than once, the directories are searched in the order
       specified. Also, the placement of the
-l
option is significant."
393,8,g++,"Also, the placement of the
-l
option is significant. Many options have long names starting with
-f
or with
-W
---for
       example,
-fmove-loop-invariants
,
-Wformat
and so on. Most of
       these have both positive and negative forms; the negative form of
-ffoo
is
-fno-foo
."
393,9,g++,"Most of
       these have both positive and negative forms; the negative form of
-ffoo
is
-fno-foo
. This manual documents only one of these two
       forms, whichever one is not the default. Some options take one or more arguments typically separated either
       by a space or by the equals sign (
=
) from the option name."
393,10,g++,"Some options take one or more arguments typically separated either
       by a space or by the equals sign (
=
) from the option name. Unless
       documented otherwise, an argument can be either numeric or a
       string. Numeric arguments must typically be small unsigned
       decimal or hexadecimal integers."
393,11,g++,"Numeric arguments must typically be small unsigned
       decimal or hexadecimal integers. Hexadecimal arguments must begin
       with the
0x
prefix. Arguments to options that specify a size
       threshold of some sort may be arbitrarily large decimal or
       hexadecimal integers followed by a byte size suffix designating a
       multiple of bytes such as ""kB"" and ""KiB"" for kilobyte and
       kibibyte, respectively, ""MB"" and ""MiB"" for megabyte and mebibyte,
       ""GB"" and ""GiB"" for gigabyte and gigibyte, and so on."
393,12,g++,"Arguments to options that specify a size
       threshold of some sort may be arbitrarily large decimal or
       hexadecimal integers followed by a byte size suffix designating a
       multiple of bytes such as ""kB"" and ""KiB"" for kilobyte and
       kibibyte, respectively, ""MB"" and ""MiB"" for megabyte and mebibyte,
       ""GB"" and ""GiB"" for gigabyte and gigibyte, and so on. Such
       arguments are designated by
byte-size
in the following text. Refer to the NIST, IEC, and other relevant national and
       international standards for the full listing and explanation of
       the binary and decimal byte size prefixes."
394,0,gettext,"The
gettext
program translates a natural language message into the
       user's language, by looking up the translation in a message
       catalog. Display native language translation of a textual message. -d
,
--domain
=
TEXTDOMAIN
retrieve translated messages from TEXTDOMAIN
-c
,
--context
=
CONTEXT
specify context for MSGID
-e
enable expansion of some escape sequences
-n
suppress trailing newline
-E
(ignored for compatibility)

       [TEXTDOMAIN] MSGID
              retrieve translated message corresponding to MSGID from
              TEXTDOMAIN
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
display version information and exit

       If the TEXTDOMAIN parameter is not given, the domain is determined
       from the environment variable TEXTDOMAIN."
394,1,gettext,"-d
,
--domain
=
TEXTDOMAIN
retrieve translated messages from TEXTDOMAIN
-c
,
--context
=
CONTEXT
specify context for MSGID
-e
enable expansion of some escape sequences
-n
suppress trailing newline
-E
(ignored for compatibility)

       [TEXTDOMAIN] MSGID
              retrieve translated message corresponding to MSGID from
              TEXTDOMAIN
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
display version information and exit

       If the TEXTDOMAIN parameter is not given, the domain is determined
       from the environment variable TEXTDOMAIN. If the message catalog
       is not found in the regular directory, another location can be
       specified with the environment variable TEXTDOMAINDIR. When used
       with the
-s
option the program behaves like the 'echo' command."
394,2,gettext,"When used
       with the
-s
option the program behaves like the 'echo' command. But it does not simply copy its arguments to stdout. Instead
       those messages found in the selected catalog are translated."
394,3,gettext,"But it does not simply copy its arguments to stdout. Instead
       those messages found in the selected catalog are translated. Standard search directory: /usr/local/share/locale"
395,0,getsubids,"The
getsubids
command lists the subordinate user ID ranges for a
       given user. The subordinate group IDs can be listed using the
-g
option."
396,0,gettextize,Prepares a source package to use gettext.
397,0,gfortran,"The
gfortran
command supports all the options supported by the
gcc
command. Only options specific to GNU Fortran are documented
       here. All GCC and GNU Fortran options are accepted both by
gfortran
and
       by
gcc
(as well as any other drivers built at the same time, such
       as
g++
), since adding GNU Fortran to the GCC distribution enables
       acceptance of GNU Fortran options by all of the relevant drivers."
397,1,gfortran,"All GCC and GNU Fortran options are accepted both by
gfortran
and
       by
gcc
(as well as any other drivers built at the same time, such
       as
g++
), since adding GNU Fortran to the GCC distribution enables
       acceptance of GNU Fortran options by all of the relevant drivers. In some cases, options have positive and negative forms; the
       negative form of
-ffoo
would be
-fno-foo
. This manual documents
       only one of these two forms, whichever one is not the default."
398,0,git-add,"This command updates the index using the current content found in
       the working tree, to prepare the content staged for the next
       commit. It typically adds the current content of existing paths as
       a whole, but with some options it can also be used to add content
       with only part of the changes made to the working tree files
       applied, or remove paths that do not exist in the working tree
       anymore. The ""index"" holds a snapshot of the content of the working tree,
       and it is this snapshot that is taken as the contents of the next
       commit."
398,1,git-add,"The ""index"" holds a snapshot of the content of the working tree,
       and it is this snapshot that is taken as the contents of the next
       commit. Thus after making any changes to the working tree, and
       before running the commit command, you must use the
add
command to
       add any new or modified files to the index. This command can be performed multiple times before a commit."
398,2,git-add,"This command can be performed multiple times before a commit. It
       only adds the content of the specified file(s) at the time the add
       command is run; if you want subsequent changes included in the
       next commit, then you must run
git add
again to add the new
       content to the index. The
git status
command can be used to obtain a summary of which
       files have changes that are staged for the next commit."
398,3,git-add,"The
git status
command can be used to obtain a summary of which
       files have changes that are staged for the next commit. The
git add
command will not add ignored files by default. If any
       ignored files were explicitly specified on the command line,
git
add
will fail with a list of ignored files."
398,4,git-add,"If any
       ignored files were explicitly specified on the command line,
git
add
will fail with a list of ignored files. Ignored files reached
       by directory recursion or filename globbing performed by Git
       (quote your globs before the shell) will be silently ignored. The
git add
command can be used to add ignored files with the
-f
(force) option."
398,5,git-add,"Ignored files reached
       by directory recursion or filename globbing performed by Git
       (quote your globs before the shell) will be silently ignored. The
git add
command can be used to add ignored files with the
-f
(force) option. Please see
git-commit(1)
for alternative ways to add content to a
       commit."
399,0,git-am,"Splits mail messages in a mailbox into commit log messages,
       authorship information, and patches, and applies them to the
       current branch. You could think of it as a reverse operation of
git-format-patch(1)
run on a branch with a straight history
       without merges."
400,0,git-archimport,"Imports a project from one or more GNU Arch repositories. It will
       follow branches and repositories within the namespaces defined by
       the <archive>/<branch> parameters supplied. If it cannot find the
       remote branch a merge comes from it will just import it as a
       regular commit."
400,1,git-archimport,"If it cannot find the
       remote branch a merge comes from it will just import it as a
       regular commit. If it can find it, it will mark it as a merge
       whenever possible (see discussion below). The script expects you to provide the key roots where it can start
       the import from an
initial import
or
tag
type of Arch commit."
400,2,git-archimport,"The script expects you to provide the key roots where it can start
       the import from an
initial import
or
tag
type of Arch commit. It
       will follow and import new branches within the provided roots. It expects to be dealing with one project only."
400,3,git-archimport,"It expects to be dealing with one project only. If it sees
       branches that have different roots, it will refuse to run. In that
       case, edit your <archive>/<branch> parameters to define clearly
       the scope of the import."
400,4,git-archimport,"In that
       case, edit your <archive>/<branch> parameters to define clearly
       the scope of the import. git archimport
uses
tla
extensively in the background to access
       the Arch repository. Make sure you have a recent version of
tla
available in the path."
400,5,git-archimport,"Make sure you have a recent version of
tla
available in the path. tla
must know about the repositories you
       pass to
git archimport
. For the initial import,
git archimport
expects to find itself in
       an empty directory."
400,6,git-archimport,"For the initial import,
git archimport
expects to find itself in
       an empty directory. To follow the development of a project that
       uses Arch, rerun
git archimport
with the same parameters as the
       initial import to perform incremental imports. While
git archimport
will try to create sensible branch names for
       the archives that it imports, it is also possible to specify Git
       branch names manually."
400,7,git-archimport,"While
git archimport
will try to create sensible branch names for
       the archives that it imports, it is also possible to specify Git
       branch names manually. To do so, write a Git branch name after
       each <archive>/<branch> parameter, separated by a colon. This way,
       you can shorten the Arch branch names and convert Arch jargon to
       Git jargon, for example mapping a ""PROJECT--devo--VERSION"" branch
       to ""master""."
400,8,git-archimport,"This way,
       you can shorten the Arch branch names and convert Arch jargon to
       Git jargon, for example mapping a ""PROJECT--devo--VERSION"" branch
       to ""master"". Associating multiple Arch branches to one Git branch is possible;
       the result will make the most sense only if no commits are made to
       the first branch, after the second branch is created. Still, this
       is useful to convert Arch repositories that had been rotated
       periodically."
401,0,gcc,"When you invoke GCC, it normally does preprocessing, compilation,
       assembly and linking. The ""overall options"" allow you to stop
       this process at an intermediate stage. For example, the
-c
option
       says not to run the linker."
401,1,gcc,"For example, the
-c
option
       says not to run the linker. Then the output consists of object
       files output by the assembler. Other options are passed on to one or more stages of processing."
401,2,gcc,"Other options are passed on to one or more stages of processing. Some options control the preprocessor and others the compiler
       itself. Yet other options control the assembler and linker; most
       of these are not documented here, since you rarely need to use any
       of them."
401,3,gcc,"Yet other options control the assembler and linker; most
       of these are not documented here, since you rarely need to use any
       of them. Most of the command-line options that you can use with GCC are
       useful for C programs; when an option is only useful with another
       language (usually C++), the explanation says so explicitly. If
       the description for a particular option does not mention a source
       language, you can use that option with all supported languages."
401,4,gcc,"If
       the description for a particular option does not mention a source
       language, you can use that option with all supported languages. The usual way to run GCC is to run the executable called
gcc
, or
machine
-gcc
when cross-compiling, or
machine
-gcc-
version
to run a
       specific version of GCC. When you compile C++ programs, you
       should invoke GCC as
g++
instead."
401,5,gcc,"When you compile C++ programs, you
       should invoke GCC as
g++
instead. The
gcc
program accepts options and file names as operands. Many
       options have multi-letter names; therefore multiple single-letter
       options may
not
be grouped:
-dv
is very different from
-d -v
."
401,6,gcc,"Many
       options have multi-letter names; therefore multiple single-letter
       options may
not
be grouped:
-dv
is very different from
-d -v
. You can mix options and other arguments. For the most part, the
       order you use doesn't matter."
401,7,gcc,"For the most part, the
       order you use doesn't matter. Order does matter when you use
       several options of the same kind; for example, if you specify
-L
more than once, the directories are searched in the order
       specified. Also, the placement of the
-l
option is significant."
401,8,gcc,"Also, the placement of the
-l
option is significant. Many options have long names starting with
-f
or with
-W
---for
       example,
-fmove-loop-invariants
,
-Wformat
and so on. Most of
       these have both positive and negative forms; the negative form of
-ffoo
is
-fno-foo
."
401,9,gcc,"Most of
       these have both positive and negative forms; the negative form of
-ffoo
is
-fno-foo
. This manual documents only one of these two
       forms, whichever one is not the default. Some options take one or more arguments typically separated either
       by a space or by the equals sign (
=
) from the option name."
401,10,gcc,"Some options take one or more arguments typically separated either
       by a space or by the equals sign (
=
) from the option name. Unless
       documented otherwise, an argument can be either numeric or a
       string. Numeric arguments must typically be small unsigned
       decimal or hexadecimal integers."
401,11,gcc,"Numeric arguments must typically be small unsigned
       decimal or hexadecimal integers. Hexadecimal arguments must begin
       with the
0x
prefix. Arguments to options that specify a size
       threshold of some sort may be arbitrarily large decimal or
       hexadecimal integers followed by a byte size suffix designating a
       multiple of bytes such as ""kB"" and ""KiB"" for kilobyte and
       kibibyte, respectively, ""MB"" and ""MiB"" for megabyte and mebibyte,
       ""GB"" and ""GiB"" for gigabyte and gigibyte, and so on."
401,12,gcc,"Arguments to options that specify a size
       threshold of some sort may be arbitrarily large decimal or
       hexadecimal integers followed by a byte size suffix designating a
       multiple of bytes such as ""kB"" and ""KiB"" for kilobyte and
       kibibyte, respectively, ""MB"" and ""MiB"" for megabyte and mebibyte,
       ""GB"" and ""GiB"" for gigabyte and gigibyte, and so on. Such
       arguments are designated by
byte-size
in the following text. Refer to the NIST, IEC, and other relevant national and
       international standards for the full listing and explanation of
       the binary and decimal byte size prefixes."
402,0,git-annotate,"Annotates each line in the given file with information from the
       commit which introduced the line. Optionally annotates from a
       given revision.

       The only difference between this command and
git-blame(1)
is that
       they use slightly different output formats, and this command
       exists only for backward compatibility to support existing
       scripts, and provide a more familiar command name for people
       coming from other SCM systems."
403,0,git-apply,"Reads the supplied diff output (i.e. ""a patch"") and applies it to
       files. When running from a subdirectory in a repository, patched
       paths outside the directory are ignored."
403,1,git-apply,"When running from a subdirectory in a repository, patched
       paths outside the directory are ignored. With the
--index
option,
       the patch is also applied to the index, and with the
--cached
option, the patch is only applied to the index. Without these
       options, the command applies the patch only to files, and does not
       require them to be in a Git repository."
403,2,git-apply,"Without these
       options, the command applies the patch only to files, and does not
       require them to be in a Git repository. This command applies the patch but does not create a commit. Use
git-am(1)
to create commits from patches generated by
git-format-patch(1)
and/or received by email."
404,0,git-archive,"Creates an archive of the specified format containing the tree
       structure for the named tree, and writes it out to the standard
       output. If <prefix> is specified it is prepended to the filenames
       in the archive. git archive
behaves differently when given a tree ID as opposed to
       a commit ID or tag ID."
404,1,git-archive,"git archive
behaves differently when given a tree ID as opposed to
       a commit ID or tag ID. When a tree ID is provided, the current
       time is used as the modification time of each file in the archive. On the other hand, when a commit ID or tag ID is provided, the
       commit time as recorded in the referenced commit object is used
       instead."
404,2,git-archive,"On the other hand, when a commit ID or tag ID is provided, the
       commit time as recorded in the referenced commit object is used
       instead. Additionally the commit ID is stored in a global extended
       pax header if the tar format is used; it can be extracted using
git get-tar-commit-id
. In ZIP files it is stored as a file
       comment."
405,0,git-bisect,"The command takes various subcommands, and different options
       depending on the subcommand:

           git bisect start [--term-(bad|new)=<term-new> --term-(good|old)=<term-old>]
                            [--no-checkout] [--first-parent] [<bad> [<good>...]] [--] [<pathspec>...]
           git bisect (bad|new|<term-new>) [<rev>]
           git bisect (good|old|<term-old>) [<rev>...]
           git bisect terms [--term-(good|old) | --term-(bad|new)]
           git bisect skip [(<rev>|<range>)...]
           git bisect reset [<commit>]
           git bisect (visualize|view)
           git bisect replay <logfile>
           git bisect log
           git bisect run <cmd> [<arg>...]
           git bisect help

       This command uses a binary search algorithm to find which commit
       in your projectâs history introduced a bug. You use it by first
       telling it a ""bad"" commit that is known to contain the bug, and a
       ""good"" commit that is known to be before the bug was introduced. Then
git bisect
picks a commit between those two endpoints and
       asks you whether the selected commit is ""good"" or ""bad""."
405,1,git-bisect,"Then
git bisect
picks a commit between those two endpoints and
       asks you whether the selected commit is ""good"" or ""bad"". It
       continues narrowing down the range until it finds the exact commit
       that introduced the change. In fact,
git bisect
can be used to find the commit that changed
any
property of your project; e.g., the commit that fixed a bug,
       or the commit that caused a benchmarkâs performance to improve."
405,2,git-bisect,"In fact,
git bisect
can be used to find the commit that changed
any
property of your project; e.g., the commit that fixed a bug,
       or the commit that caused a benchmarkâs performance to improve. To
       support this more general usage, the terms ""old"" and ""new"" can be
       used in place of ""good"" and ""bad"", or you can choose your own
       terms. See section ""Alternate terms"" below for more information."
405,3,git-bisect,"See section ""Alternate terms"" below for more information. Basic bisect commands: start, bad, good
As an example, suppose you are trying to find the commit that
       broke a feature that was known to work in version
v2.6.13-rc2
of
       your project. You start a bisect session as follows:

           $ git bisect start
           $ git bisect bad                 # Current version is bad
           $ git bisect good v2.6.13-rc2    # v2.6.13-rc2 is known to be good

       Once you have specified at least one bad and one good commit,
git
bisect
selects a commit in the middle of that range of history,
       checks it out, and outputs something similar to the following:

           Bisecting: 675 revisions left to test after this (roughly 10 steps)

       You should now compile the checked-out version and test it."
405,4,git-bisect,"You start a bisect session as follows:

           $ git bisect start
           $ git bisect bad                 # Current version is bad
           $ git bisect good v2.6.13-rc2    # v2.6.13-rc2 is known to be good

       Once you have specified at least one bad and one good commit,
git
bisect
selects a commit in the middle of that range of history,
       checks it out, and outputs something similar to the following:

           Bisecting: 675 revisions left to test after this (roughly 10 steps)

       You should now compile the checked-out version and test it. If
       that version works correctly, type

           $ git bisect good

       If that version is broken, type

           $ git bisect bad

       Then
git bisect
will respond with something like

           Bisecting: 337 revisions left to test after this (roughly 9 steps)

       Keep repeating the process: compile the tree, test it, and
       depending on whether it is good or bad run
git bisect good
or
git
bisect bad
to ask for the next commit that needs testing. Eventually there will be no more revisions left to inspect, and
       the command will print out a description of the first bad commit."
405,5,git-bisect,"Eventually there will be no more revisions left to inspect, and
       the command will print out a description of the first bad commit. The reference
refs/bisect/bad
will be left pointing at that
       commit. Bisect reset
After a bisect session, to clean up the bisection state and return
       to the original HEAD, issue the following command:

           $ git bisect reset

       By default, this will return your tree to the commit that was
       checked out before
git bisect start
."
405,6,git-bisect,"Bisect reset
After a bisect session, to clean up the bisection state and return
       to the original HEAD, issue the following command:

           $ git bisect reset

       By default, this will return your tree to the commit that was
       checked out before
git bisect start
. (A new
git bisect start
will
       also do that, as it cleans up the old bisection state.)

       With an optional argument, you can return to a different commit
       instead:

           $ git bisect reset <commit>

       For example,
git bisect reset bisect/bad
will check out the first
       bad revision, while
git bisect reset HEAD
will leave you on the
       current bisection commit and avoid switching commits at all. Alternate terms
Sometimes you are not looking for the commit that introduced a
       breakage, but rather for a commit that caused a change between
       some other ""old"" state and ""new"" state."
405,7,git-bisect,"Alternate terms
Sometimes you are not looking for the commit that introduced a
       breakage, but rather for a commit that caused a change between
       some other ""old"" state and ""new"" state. For example, you might be
       looking for the commit that introduced a particular fix. Or you
       might be looking for the first commit in which the source-code
       filenames were finally all converted to your companyâs naming
       standard."
405,8,git-bisect,"Or you
       might be looking for the first commit in which the source-code
       filenames were finally all converted to your companyâs naming
       standard. Or whatever. In such cases it can be very confusing to use the terms ""good"" and
       ""bad"" to refer to ""the state before the change"" and ""the state
       after the change""."
405,9,git-bisect,"In such cases it can be very confusing to use the terms ""good"" and
       ""bad"" to refer to ""the state before the change"" and ""the state
       after the change"". So instead, you can use the terms ""old"" and
       ""new"", respectively, in place of ""good"" and ""bad"". (But note that
       you cannot mix ""good"" and ""bad"" with ""old"" and ""new"" in a single
       session.)

       In this more general usage, you provide
git bisect
with a ""new""
       commit that has some property and an ""old"" commit that doesnât
       have that property."
405,10,git-bisect,"(But note that
       you cannot mix ""good"" and ""bad"" with ""old"" and ""new"" in a single
       session.)

       In this more general usage, you provide
git bisect
with a ""new""
       commit that has some property and an ""old"" commit that doesnât
       have that property. Each time
git bisect
checks out a commit, you
       test if that commit has the property. If it does, mark the commit
       as ""new""; otherwise, mark it as ""old""."
405,11,git-bisect,"If it does, mark the commit
       as ""new""; otherwise, mark it as ""old"". When the bisection is done,
git bisect
will report which commit introduced the property. To use ""old"" and ""new"" instead of ""good"" and bad, you must run
git
bisect start
without commits as argument and then run the
       following commands to add the commits:

           git bisect old [<rev>]

       to indicate that a commit was before the sought change, or

           git bisect new [<rev>...]

       to indicate that it was after."
405,12,git-bisect,"To use ""old"" and ""new"" instead of ""good"" and bad, you must run
git
bisect start
without commits as argument and then run the
       following commands to add the commits:

           git bisect old [<rev>]

       to indicate that a commit was before the sought change, or

           git bisect new [<rev>...]

       to indicate that it was after. To get a reminder of the currently used terms, use

           git bisect terms

       You can get just the old term with
git bisect terms --term-old
or
git bisect terms --term-good
;
git bisect terms --term-new
and
git
bisect terms --term-bad
can be used to learn how to call the
       commits more recent than the sought change. If you would like to use your own terms instead of ""bad""/""good"" or
       ""new""/""old"", you can choose any names you like (except existing
       bisect subcommands like
reset
,
start
, ...) by starting the
       bisection using

           git bisect start --term-old <term-old> --term-new <term-new>

       For example, if you are looking for a commit that introduced a
       performance regression, you might use

           git bisect start --term-old fast --term-new slow

       Or if you are looking for the commit that fixed a bug, you might
       use

           git bisect start --term-new fixed --term-old broken

       Then, use
git bisect
<term-old>
and
git bisect
<term-new>
instead
       of
git bisect good
and
git bisect bad
to mark commits."
405,13,git-bisect,"If you would like to use your own terms instead of ""bad""/""good"" or
       ""new""/""old"", you can choose any names you like (except existing
       bisect subcommands like
reset
,
start
, ...) by starting the
       bisection using

           git bisect start --term-old <term-old> --term-new <term-new>

       For example, if you are looking for a commit that introduced a
       performance regression, you might use

           git bisect start --term-old fast --term-new slow

       Or if you are looking for the commit that fixed a bug, you might
       use

           git bisect start --term-new fixed --term-old broken

       Then, use
git bisect
<term-old>
and
git bisect
<term-new>
instead
       of
git bisect good
and
git bisect bad
to mark commits. Bisect visualize/view
To see the currently remaining suspects in
gitk
, issue the
       following command during the bisection process (the subcommand
view
can be used as an alternative to
visualize
):

           $ git bisect visualize

       Git detects a graphical environment through various environment
       variables:
DISPLAY
, which is set in X Window System environments
       on Unix systems. SESSIONNAME
, which is set under Cygwin in
       interactive desktop sessions."
405,14,git-bisect,"SESSIONNAME
, which is set under Cygwin in
       interactive desktop sessions. MSYSTEM
, which is set under Msys2
       and Git for Windows. SECURITYSESSIONID
, which may be set on macOS
       in interactive desktop sessions."
405,15,git-bisect,"SECURITYSESSIONID
, which may be set on macOS
       in interactive desktop sessions. If none of these environment variables is set,
git log
is used
       instead. You can also give command-line options such as
-p
and
--stat
."
405,16,git-bisect,"You can also give command-line options such as
-p
and
--stat
. $ git bisect visualize --stat
Bisect log and bisect replay
After having marked revisions as good or bad, issue the following
       command to show what has been done so far:

           $ git bisect log

       If you discover that you made a mistake in specifying the status
       of a revision, you can save the output of this command to a file,
       edit it to remove the incorrect entries, and then issue the
       following commands to return to a corrected state:

           $ git bisect reset
           $ git bisect replay that-file
Avoiding testing a commit
If, in the middle of a bisect session, you know that the suggested
       revision is not a good one to test (e.g. it fails to build and you
       know that the failure does not have anything to do with the bug
       you are chasing), you can manually select a nearby commit and test
       that one instead."
405,17,git-bisect,"it fails to build and you
       know that the failure does not have anything to do with the bug
       you are chasing), you can manually select a nearby commit and test
       that one instead. For example:

           $ git bisect good/bad                   # previous round was good or bad. Bisecting: 337 revisions left to test after this (roughly 9 steps)
           $ git bisect visualize                  # oops, that is uninteresting."
405,18,git-bisect,"Bisecting: 337 revisions left to test after this (roughly 9 steps)
           $ git bisect visualize                  # oops, that is uninteresting. $ git reset --hard HEAD~3               # try 3 revisions before what
                                                   # was suggested

       Then compile and test the chosen revision, and afterwards mark the
       revision as good or bad in the usual manner. Bisect skip
Instead of choosing a nearby commit by yourself, you can ask Git
       to do it for you by issuing the command:

           $ git bisect skip                 # Current version cannot be tested

       However, if you skip a commit adjacent to the one you are looking
       for, Git will be unable to tell exactly which of those commits was
       the first bad one."
405,19,git-bisect,"Bisect skip
Instead of choosing a nearby commit by yourself, you can ask Git
       to do it for you by issuing the command:

           $ git bisect skip                 # Current version cannot be tested

       However, if you skip a commit adjacent to the one you are looking
       for, Git will be unable to tell exactly which of those commits was
       the first bad one. You can also skip a range of commits, instead of just one commit,
       using range notation. For example:

           $ git bisect skip v2.5..v2.6

       This tells the bisect process that no commit after
v2.5
, up to and
       including
v2.6
, should be tested."
405,20,git-bisect,"For example:

           $ git bisect skip v2.5..v2.6

       This tells the bisect process that no commit after
v2.5
, up to and
       including
v2.6
, should be tested. Note that if you also want to skip the first commit of the range
       you would issue the command:

           $ git bisect skip v2.5 v2.5..v2.6

       This tells the bisect process that the commits between
v2.5
and
v2.6
(inclusive) should be skipped. Cutting down bisection by giving more parameters to bisect start
You can further cut down the number of trials, if you know what
       part of the tree is involved in the problem you are tracking down,
       by specifying pathspec parameters when issuing the
bisect start
command:

           $ git bisect start -- arch/i386 include/asm-i386

       If you know beforehand more than one good commit, you can narrow
       the bisect space down by specifying all of the good commits
       immediately after the bad commit when issuing the
bisect start
command:

           $ git bisect start v2.6.20-rc6 v2.6.20-rc4 v2.6.20-rc1 --
                              # v2.6.20-rc6 is bad
                              # v2.6.20-rc4 and v2.6.20-rc1 are good
Bisect run
If you have a script that can tell if the current source code is
       good or bad, you can bisect by issuing the command:

           $ git bisect run my_script arguments

       Note that the script (
my_script
in the above example) should exit
       with code 0 if the current source code is good/old, and exit with
       a code between 1 and 127 (inclusive), except 125, if the current
       source code is bad/new."
405,21,git-bisect,"Cutting down bisection by giving more parameters to bisect start
You can further cut down the number of trials, if you know what
       part of the tree is involved in the problem you are tracking down,
       by specifying pathspec parameters when issuing the
bisect start
command:

           $ git bisect start -- arch/i386 include/asm-i386

       If you know beforehand more than one good commit, you can narrow
       the bisect space down by specifying all of the good commits
       immediately after the bad commit when issuing the
bisect start
command:

           $ git bisect start v2.6.20-rc6 v2.6.20-rc4 v2.6.20-rc1 --
                              # v2.6.20-rc6 is bad
                              # v2.6.20-rc4 and v2.6.20-rc1 are good
Bisect run
If you have a script that can tell if the current source code is
       good or bad, you can bisect by issuing the command:

           $ git bisect run my_script arguments

       Note that the script (
my_script
in the above example) should exit
       with code 0 if the current source code is good/old, and exit with
       a code between 1 and 127 (inclusive), except 125, if the current
       source code is bad/new. Any other exit code will abort the bisect process. It should be
       noted that a program that terminates via
exit
(
-1
) leaves $?"
405,22,git-bisect,"It should be
       noted that a program that terminates via
exit
(
-1
) leaves $? = 255,
       (see the exit(3) manual page), as the value is chopped with &
0377
. The special exit code 125 should be used when the current source
       code cannot be tested."
405,23,git-bisect,"The special exit code 125 should be used when the current source
       code cannot be tested. If the script exits with this code, the
       current revision will be skipped (see
git bisect skip
above). 125
       was chosen as the highest sensible value to use for this purpose,
       because 126 and 127 are used by POSIX shells to signal specific
       error status (127 is for command not found, 126 is for command
       found but not executableâthese details do not matter, as they are
       normal errors in the script, as far as
bisect run
is concerned)."
405,24,git-bisect,"125
       was chosen as the highest sensible value to use for this purpose,
       because 126 and 127 are used by POSIX shells to signal specific
       error status (127 is for command not found, 126 is for command
       found but not executableâthese details do not matter, as they are
       normal errors in the script, as far as
bisect run
is concerned). You may often find that during a bisect session you want to have
       temporary modifications (e.g. s/#define DEBUG 0/#define DEBUG 1/
       in a header file, or ""revision that does not have this commit
       needs this patch applied to work around another problem this
       bisection is not interested in"") applied to the revision being
       tested."
405,25,git-bisect,"s/#define DEBUG 0/#define DEBUG 1/
       in a header file, or ""revision that does not have this commit
       needs this patch applied to work around another problem this
       bisection is not interested in"") applied to the revision being
       tested. To cope with such a situation, after the inner
git bisect
finds
       the next revision to test, the script can apply the patch before
       compiling, run the real test, and afterwards decide if the
       revision (possibly with the needed patch) passed the test and then
       rewind the tree to the pristine state. Finally the script should
       exit with the status of the real test to let the
git bisect run
command loop determine the eventual outcome of the bisect session."
406,0,git-bugreport,"Collects information about the userâs machine, Git client, and
       repository state, in addition to a form requesting information
       about the behavior the user observed, and stores it in a single
       text file which the user can then share, for example to the Git
       mailing list, in order to report an observed bug. The following information is requested from the user:

       â¢   Reproduction steps

       â¢   Expected behavior

       â¢   Actual behavior

       The following information is captured automatically:

       â¢
git version --build-options
â¢   uname sysname, release, version, and machine strings

       â¢   Compiler-specific info string

       â¢   A list of enabled hooks

       â¢   $SHELL

       Additional information may be gathered into a separate zip archive
       using the
--diagnose
option, and can be attached alongside the
       bugreport document to provide additional context to readers. This tool is invoked via the typical Git setup process, which
       means that in some cases, it might not be able to launch - for
       example, if a relevant config file is unreadable."
406,1,git-bugreport,"The following information is requested from the user:

       â¢   Reproduction steps

       â¢   Expected behavior

       â¢   Actual behavior

       The following information is captured automatically:

       â¢
git version --build-options
â¢   uname sysname, release, version, and machine strings

       â¢   Compiler-specific info string

       â¢   A list of enabled hooks

       â¢   $SHELL

       Additional information may be gathered into a separate zip archive
       using the
--diagnose
option, and can be attached alongside the
       bugreport document to provide additional context to readers. This tool is invoked via the typical Git setup process, which
       means that in some cases, it might not be able to launch - for
       example, if a relevant config file is unreadable. In this kind of
       scenario, it may be helpful to manually gather the kind of
       information listed above when manually asking for help."
407,0,git-blame,"Annotates each line in the given file with information from the
       revision which last modified the line. Optionally, start
       annotating from the given revision. When specified one or more times,
-L
restricts annotation to the
       requested lines."
407,1,git-blame,"When specified one or more times,
-L
restricts annotation to the
       requested lines. The origin of lines is automatically followed across whole-file
       renames (currently there is no option to turn the rename-following
       off). To follow lines moved from one file to another, or to follow
       lines that were copied and pasted from another file, etc., see the
-C
and
-M
options."
407,2,git-blame,"To follow lines moved from one file to another, or to follow
       lines that were copied and pasted from another file, etc., see the
-C
and
-M
options. The report does not tell you anything about lines which have been
       deleted or replaced; you need to use a tool such as
git diff
or
       the ""pickaxe"" interface briefly mentioned in the following
       paragraph. Apart from supporting file annotation, Git also supports searching
       the development history for when a code snippet occurred in a
       change."
407,3,git-blame,"Apart from supporting file annotation, Git also supports searching
       the development history for when a code snippet occurred in a
       change. This makes it possible to track when a code snippet was
       added to a file, moved or copied between files, and eventually
       deleted or replaced. It works by searching for a text string in
       the diff."
407,4,git-blame,"This makes it possible to track when a code snippet was
       added to a file, moved or copied between files, and eventually
       deleted or replaced. It works by searching for a text string in
       the diff. A small example of the pickaxe interface that searches
       for
blame_usage
:

           $ git log --pretty=oneline -S'blame_usage'
           5040f17eba15504bad66b14a645bddd9b015ebb7 blame -S <ancestry-file>
           ea4c7f9bf69e781dd0cd88d2bccb2bf5cc15c9a7 git-blame: Make the output"
408,0,git-bundle,"Create, unpack, and manipulate ""bundle"" files. Bundles are used
       for the ""offline"" transfer of Git objects without an active
       ""server"" sitting on the other side of the network connection. They can be used to create both incremental and full backups of a
       repository (see the ""full backup"" example in ""EXAMPLES""), and to
       relay the state of the references in one repository to another
       (see the second example)."
408,1,git-bundle,"They can be used to create both incremental and full backups of a
       repository (see the ""full backup"" example in ""EXAMPLES""), and to
       relay the state of the references in one repository to another
       (see the second example). Git commands that fetch or otherwise ""read"" via protocols such as
ssh://
and
https://
can also operate on bundle files. It is
       possible
git-clone(1)
a new repository from a bundle, to use
git-fetch(1)
to fetch from one, and to list the references
       contained within it with
git-ls-remote(1)
."
408,2,git-bundle,"It is
       possible
git-clone(1)
a new repository from a bundle, to use
git-fetch(1)
to fetch from one, and to list the references
       contained within it with
git-ls-remote(1)
. Thereâs no
       corresponding ""write"" support, i.e. a
git push
into a bundle is
       not supported."
409,0,git-branch,"If
--list
is given, or if there are no non-option arguments,
       existing branches are listed; the current branch will be
       highlighted in green and marked with an asterisk. Any branches
       checked out in linked worktrees will be highlighted in cyan and
       marked with a plus sign. Option
-r
causes the remote-tracking
       branches to be listed, and option
-a
shows both local and remote
       branches."
409,1,git-branch,"Option
-r
causes the remote-tracking
       branches to be listed, and option
-a
shows both local and remote
       branches. If a
<pattern>
is given, it is used as a shell wildcard to
       restrict the output to matching branches. If multiple patterns are
       given, a branch is shown if it matches any of the patterns."
409,2,git-branch,"If multiple patterns are
       given, a branch is shown if it matches any of the patterns. Note that when providing a
<pattern>
, you must use
--list
;
       otherwise the command may be interpreted as branch creation. With
--contains
, shows only the branches that contain the named
       commit (in other words, the branches whose tip commits are
       descendants of the named commit),
--no-contains
inverts it."
409,3,git-branch,"With
--contains
, shows only the branches that contain the named
       commit (in other words, the branches whose tip commits are
       descendants of the named commit),
--no-contains
inverts it. With
--merged
, only branches merged into the named commit (i.e. the
       branches whose tip commits are reachable from the named commit)
       will be listed."
409,4,git-branch,"the
       branches whose tip commits are reachable from the named commit)
       will be listed. With
--no-merged
only branches not merged into the
       named commit will be listed. If the <commit> argument is missing
       it defaults to
HEAD
(i.e."
409,5,git-branch,"If the <commit> argument is missing
       it defaults to
HEAD
(i.e. the tip of the current branch). The commandâs second form creates a new branch head named
       <branchname> which points to the current
HEAD
, or <start-point> if
       given."
409,6,git-branch,"The commandâs second form creates a new branch head named
       <branchname> which points to the current
HEAD
, or <start-point> if
       given. As a special case, for <start-point>, you may use ""A
...B
""
       as a shortcut for the merge base of
A
and
B
if there is exactly
       one merge base. You can leave out at most one of
A
and
B
, in which
       case it defaults to
HEAD
."
409,7,git-branch,"You can leave out at most one of
A
and
B
, in which
       case it defaults to
HEAD
. Note that this will create the new branch, but it will not switch
       the working tree to it; use ""git switch <newbranch>"" to switch to
       the new branch. When a local branch is started off a remote-tracking branch, Git
       sets up the branch (specifically the
branch."
409,8,git-branch,"When a local branch is started off a remote-tracking branch, Git
       sets up the branch (specifically the
branch. <name>
.remote
and
branch. <name>
.merge
configuration entries) so that
git pull
will
       appropriately merge from the remote-tracking branch."
409,9,git-branch,"<name>
.merge
configuration entries) so that
git pull
will
       appropriately merge from the remote-tracking branch. This behavior
       may be changed via the global
branch.autoSetupMerge
configuration
       flag. That setting can be overridden by using the
--track
and
--no-track
options, and changed later using
git branch
--set-upstream-to
."
409,10,git-branch,"That setting can be overridden by using the
--track
and
--no-track
options, and changed later using
git branch
--set-upstream-to
. With a
-m
or
-M
option, <oldbranch> will be renamed to
       <newbranch>. If <oldbranch> had a corresponding reflog, it is
       renamed to match <newbranch>, and a reflog entry is created to
       remember the branch renaming."
409,11,git-branch,"If <oldbranch> had a corresponding reflog, it is
       renamed to match <newbranch>, and a reflog entry is created to
       remember the branch renaming. If <newbranch> exists, -M must be
       used to force the rename to happen. The
-c
and
-C
options have the exact same semantics as
-m
and
-M
,
       except instead of the branch being renamed, it will be copied to a
       new name, along with its config and reflog."
409,12,git-branch,"The
-c
and
-C
options have the exact same semantics as
-m
and
-M
,
       except instead of the branch being renamed, it will be copied to a
       new name, along with its config and reflog. With a
-d
or
-D
option,
<branchname>
will be deleted. You may
       specify more than one branch for deletion."
409,13,git-branch,"You may
       specify more than one branch for deletion. If the branch currently
       has a reflog then the reflog will also be deleted. Use
-r
together with
-d
to delete remote-tracking branches."
409,14,git-branch,"Use
-r
together with
-d
to delete remote-tracking branches. Note,
       that it only makes sense to delete remote-tracking branches if
       they no longer exist in the remote repository or if
git fetch
was
       configured not to fetch them again. See also the
prune
subcommand
       of
git-remote(1)
for a way to clean up all obsolete
       remote-tracking branches."
410,0,git-cat-file,"Output the contents or other properties such as size, type or
       delta information of one or more objects. This command can operate in two modes, depending on whether an
       option from the
--batch
family is specified. In non-batch mode, the command provides information on an object
       named on the command line."
410,1,git-cat-file,"This command can operate in two modes, depending on whether an
       option from the
--batch
family is specified. In non-batch mode, the command provides information on an object
       named on the command line. In batch mode, arguments are read from standard input."
411,0,git-check-attr,"For every pathname, this command will list if each attribute is
unspecified
,
set
, or
unset
as a gitattribute on that pathname."
412,0,git-check-mailmap,"For each âName <user@host>â, â<user@host>â, or âuser@hostâ from
       the command-line or standard input (when using
--stdin
), look up
       the personâs canonical name and email address (see ""Mapping
       Authors"" below). If found, print them; otherwise print the input
       as-is."
413,0,git-check-ignore,"For each pathname given via the command-line or from a file via
--stdin
, check whether the file is excluded by .gitignore (or
       other input files to the exclude mechanism) and output the path if
       it is excluded.

       By default, tracked files are not shown at all since they are not
       subject to exclude rules; but see â--no-indexâ."
414,0,git-check-ref-format,"Checks if a given
refname
is acceptable, and exits with a non-zero
       status if it is not. A reference is used in Git to specify branches and tags. A branch
       head is stored in the
refs/heads
hierarchy, while a tag is stored
       in the
refs/tags
hierarchy of the ref namespace (typically in
$GIT_DIR/refs/heads
and
$GIT_DIR/refs/tags
directories or, as
       entries in file
$GIT_DIR/packed-refs
if refs are packed by
git
gc
)."
414,1,git-check-ref-format,"A branch
       head is stored in the
refs/heads
hierarchy, while a tag is stored
       in the
refs/tags
hierarchy of the ref namespace (typically in
$GIT_DIR/refs/heads
and
$GIT_DIR/refs/tags
directories or, as
       entries in file
$GIT_DIR/packed-refs
if refs are packed by
git
gc
). Git imposes the following rules on how references are named:

        1. They can include slash
/
for hierarchical (directory)
           grouping, but no slash-separated component can begin with a
           dot ."
414,2,git-check-ref-format,"They can include slash
/
for hierarchical (directory)
           grouping, but no slash-separated component can begin with a
           dot . or end with the sequence
.lock
. 2."
414,3,git-check-ref-format,"2. They must contain at least one
/
. This enforces the presence
           of a category like
heads/
,
tags/
etc."
414,4,git-check-ref-format,"This enforces the presence
           of a category like
heads/
,
tags/
etc. but the actual names are
           not restricted. If the
--allow-onelevel
option is used, this
           rule is waived."
414,5,git-check-ref-format,"If the
--allow-onelevel
option is used, this
           rule is waived. 3. They cannot have two consecutive dots .."
414,6,git-check-ref-format,They cannot have two consecutive dots .. anywhere. 4.
414,7,git-check-ref-format,"4. They cannot have ASCII control characters (i.e. bytes whose
           values are lower than \040, or \177
DEL
), space, tilde
~
,
           caret
^
, or colon
:
anywhere."
414,8,git-check-ref-format,"bytes whose
           values are lower than \040, or \177
DEL
), space, tilde
~
,
           caret
^
, or colon
:
anywhere. 5. They cannot have question-mark ?, asterisk *, or open bracket
           [ anywhere."
414,9,git-check-ref-format,"They cannot have question-mark ?, asterisk *, or open bracket
           [ anywhere. See the
--refspec-pattern
option below for an
           exception to this rule. 6."
414,10,git-check-ref-format,"6. They cannot begin or end with a slash
/
or contain multiple
           consecutive slashes (see the
--normalize
option below for an
           exception to this rule). 7."
414,11,git-check-ref-format,7. They cannot end with a dot .. 8.
414,12,git-check-ref-format,"8. They cannot contain a sequence
@
{. 9."
414,13,git-check-ref-format,"9. They cannot be the single character
@
. 10."
414,14,git-check-ref-format,"10. They cannot contain a \. These rules make it easy for shell script based tools to parse
       reference names, pathname expansion by the shell when a reference
       name is used unquoted (by mistake), and also avoid ambiguities in
       certain reference name expressions (see
gitrevisions(7)
):

        1."
414,15,git-check-ref-format,"These rules make it easy for shell script based tools to parse
       reference names, pathname expansion by the shell when a reference
       name is used unquoted (by mistake), and also avoid ambiguities in
       certain reference name expressions (see
gitrevisions(7)
):

        1. A double-dot .. is often used as in
ref1..ref2
, and in some
           contexts this notation means
^ref1 ref2
(i.e."
414,16,git-check-ref-format,"is often used as in
ref1..ref2
, and in some
           contexts this notation means
^ref1 ref2
(i.e. not in
ref1
and
           in
ref2
). 2."
414,17,git-check-ref-format,"2. A tilde
~
and caret
^
are used to introduce the postfix
nth
parent
and
peel onion
operation. 3."
414,18,git-check-ref-format,"3. A colon
:
is used as in
srcref:dstref
to mean ""use srcrefâs
           value and store it in dstref"" in fetch and push operations. It
           may also be used to select a specific object such as with
git
cat-file
: ""git cat-file blob v1.3.3:refs.c""."
414,19,git-check-ref-format,"It
           may also be used to select a specific object such as with
git
cat-file
: ""git cat-file blob v1.3.3:refs.c"". 4. at-open-brace
@
{ is used as a notation to access a reflog
           entry."
414,20,git-check-ref-format,"at-open-brace
@
{ is used as a notation to access a reflog
           entry. With the
--branch
option, the command takes a name and checks if
       it can be used as a valid branch name (e.g. when creating a new
       branch)."
414,21,git-check-ref-format,"when creating a new
       branch). But be cautious when using the previous checkout syntax
       that may refer to a detached HEAD state. The rule
git
check-ref-format --branch $name
implements may be stricter than
       what
git check-ref-format refs/heads/$name
says (e.g."
414,22,git-check-ref-format,"The rule
git
check-ref-format --branch $name
implements may be stricter than
       what
git check-ref-format refs/heads/$name
says (e.g. a dash may
       appear at the beginning of a ref component, but it is explicitly
       forbidden at the beginning of a branch name). When run with the
--branch
option in a repository, the input is first expanded for
       the âprevious checkout syntaxâ
@
{-n}."
414,23,git-check-ref-format,"When run with the
--branch
option in a repository, the input is first expanded for
       the âprevious checkout syntaxâ
@
{-n}. For example,
@
{-1} is a way
       to refer the last thing that was checked out using ""git switch"" or
       ""git checkout"" operation. This option should be used by porcelains
       to accept this syntax anywhere a branch name is expected, so they
       can act as if you typed the branch name."
414,24,git-check-ref-format,"For example,
@
{-1} is a way
       to refer the last thing that was checked out using ""git switch"" or
       ""git checkout"" operation. This option should be used by porcelains
       to accept this syntax anywhere a branch name is expected, so they
       can act as if you typed the branch name. As an exception note
       that, the âprevious checkout operationâ might result in a commit
       object name when the N-th last thing checked out was not a branch."
415,0,git-checkout-index,"Copies all listed files from the index to the working directory
       (not overwriting existing files)."
416,0,git-cherry-pick,"Given one or more existing commits, apply the change each one
       introduces, recording a new commit for each. This requires your
       working tree to be clean (no modifications from the HEAD commit). When it is not obvious how to apply a change, the following
       happens:

        1."
416,1,git-cherry-pick,"When it is not obvious how to apply a change, the following
       happens:

        1. The current branch and
HEAD
pointer stay at the last commit
           successfully made. 2."
416,2,git-cherry-pick,"2. The
CHERRY_PICK_HEAD
ref is set to point at the commit that
           introduced the change that is difficult to apply. 3."
416,3,git-cherry-pick,"3. Paths in which the change applied cleanly are updated both in
           the index file and in your working tree. 4."
416,4,git-cherry-pick,"4. For conflicting paths, the index file records up to three
           versions, as described in the ""TRUE MERGE"" section of
git-merge(1)
. The working tree files will include a
           description of the conflict bracketed by the usual conflict
           markers <<<<<<< and >>>>>>>."
416,5,git-cherry-pick,"The working tree files will include a
           description of the conflict bracketed by the usual conflict
           markers <<<<<<< and >>>>>>>. 5. No other modifications are made."
416,6,git-cherry-pick,"5. No other modifications are made. See
git-merge(1)
for some hints on resolving such conflicts."
417,0,git-cherry,"Determine whether there are commits in
<head>
.. <upstream>
that are
       equivalent to those in the range
<limit>
.. <head>
."
417,1,git-cherry,"<head>
. The equivalence test is based on the diff, after removing
       whitespace and line numbers. git-cherry therefore detects when
       commits have been ""copied"" by means of
git-cherry-pick(1)
,
git-am(1)
or
git-rebase(1)
."
417,2,git-cherry,"git-cherry therefore detects when
       commits have been ""copied"" by means of
git-cherry-pick(1)
,
git-am(1)
or
git-rebase(1)
. Outputs the SHA1 of every commit in
<limit>
.. <head>
, prefixed with
-
for commits that have an equivalent in <upstream>, and
+
for
       commits that do not."
418,0,git-citool,"A Tcl/Tk based graphical interface to review modified files, stage
       them into the index, enter a commit message and record the new
       commit onto the current branch. This interface is an alternative
       to the less interactive
git commit
program. git citool
is actually a standard alias for
git gui citool
."
418,1,git-citool,"This interface is an alternative
       to the less interactive
git commit
program. git citool
is actually a standard alias for
git gui citool
. See
git-gui(1)
for more details."
419,0,git-checkout,"Updates files in the working tree to match the version in the
       index or the specified tree. If no pathspec was given,
git
checkout
will also update
HEAD
to set the specified branch as the
       current branch. git checkout
[<branch>]
           To prepare for working on
<branch>
, switch to it by updating
           the index and the files in the working tree, and by pointing
HEAD
at the branch."
419,1,git-checkout,"git checkout
[<branch>]
           To prepare for working on
<branch>
, switch to it by updating
           the index and the files in the working tree, and by pointing
HEAD
at the branch. Local modifications to the files in the
           working tree are kept, so that they can be committed to the
<branch>
. If
<branch>
is not found but there does exist a tracking
           branch in exactly one remote (call it
<remote>
) with a
           matching name and
--no-guess
is not specified, treat as
           equivalent to

               $ git checkout -b <branch> --track <remote>/<branch>

           You could omit
<branch>
, in which case the command degenerates
           to ""check out the current branch"", which is a glorified no-op
           with rather expensive side-effects to show only the tracking
           information, if it exists, for the current branch."
419,2,git-checkout,"If
<branch>
is not found but there does exist a tracking
           branch in exactly one remote (call it
<remote>
) with a
           matching name and
--no-guess
is not specified, treat as
           equivalent to

               $ git checkout -b <branch> --track <remote>/<branch>

           You could omit
<branch>
, in which case the command degenerates
           to ""check out the current branch"", which is a glorified no-op
           with rather expensive side-effects to show only the tracking
           information, if it exists, for the current branch. git checkout
-b|-B <new-branch> [<start-point>]
           Specifying
-b
causes a new branch to be created as if
git-branch(1)
were called and then checked out. In this case
           you can use the
--track
or
--no-track
options, which will be
           passed to
git branch
."
419,3,git-checkout,"In this case
           you can use the
--track
or
--no-track
options, which will be
           passed to
git branch
. As a convenience,
--track
without
-b
implies branch creation; see the description of
--track
below. If
-B
is given,
<new-branch>
is created if it doesnât exist;
           otherwise, it is reset."
419,4,git-checkout,"If
-B
is given,
<new-branch>
is created if it doesnât exist;
           otherwise, it is reset. This is the transactional equivalent
           of

               $ git branch -f <branch> [<start-point>]
               $ git checkout <branch>

           that is to say, the branch is not reset/created unless ""git
           checkout"" is successful (e.g., when the branch is in use in
           another worktree, not just the current branch stays the same,
           but the branch is not reset to the start-point, either). git checkout
--detach [<branch>],
git checkout
[--detach] <commit>
           Prepare to work on top of
<commit>
, by detaching
HEAD
at it
           (see ""DETACHED HEAD"" section), and updating the index and the
           files in the working tree."
419,5,git-checkout,"git checkout
--detach [<branch>],
git checkout
[--detach] <commit>
           Prepare to work on top of
<commit>
, by detaching
HEAD
at it
           (see ""DETACHED HEAD"" section), and updating the index and the
           files in the working tree. Local modifications to the files in
           the working tree are kept, so that the resulting working tree
           will be the state recorded in the commit plus the local
           modifications. When the
<commit>
argument is a branch name, the
--detach
option can be used to detach
HEAD
at the tip of the branch
           (
git checkout
<branch>
would check out that branch without
           detaching
HEAD
)."
419,6,git-checkout,"When the
<commit>
argument is a branch name, the
--detach
option can be used to detach
HEAD
at the tip of the branch
           (
git checkout
<branch>
would check out that branch without
           detaching
HEAD
). Omitting
<branch>
detaches
HEAD
at the tip of the current
           branch. git checkout
[-f|--ours|--theirs|-m|--conflict=<style>]
       [<tree-ish>] [--] <pathspec>...,
git checkout
[-f|--ours|--theirs|-m|--conflict=<style>] [<tree-ish>]
       --pathspec-from-file=<file> [--pathspec-file-nul]
           Overwrite the contents of the files that match the pathspec."
419,7,git-checkout,"git checkout
[-f|--ours|--theirs|-m|--conflict=<style>]
       [<tree-ish>] [--] <pathspec>...,
git checkout
[-f|--ours|--theirs|-m|--conflict=<style>] [<tree-ish>]
       --pathspec-from-file=<file> [--pathspec-file-nul]
           Overwrite the contents of the files that match the pathspec. When the
<tree-ish>
(most often a commit) is not given,
           overwrite working tree with the contents in the index. When
           the
<tree-ish>
is given, overwrite both the index and the
           working tree with the contents at the
<tree-ish>
."
419,8,git-checkout,"When
           the
<tree-ish>
is given, overwrite both the index and the
           working tree with the contents at the
<tree-ish>
. The index may contain unmerged entries because of a previous
           failed merge. By default, if you try to check out such an
           entry from the index, the checkout operation will fail and
           nothing will be checked out."
419,9,git-checkout,"By default, if you try to check out such an
           entry from the index, the checkout operation will fail and
           nothing will be checked out. Using
-f
will ignore these
           unmerged entries. The contents from a specific side of the
           merge can be checked out of the index by using
--ours
or
--theirs
."
419,10,git-checkout,"The contents from a specific side of the
           merge can be checked out of the index by using
--ours
or
--theirs
. With
-m
, changes made to the working tree file can
           be discarded to re-create the original conflicted merge
           result. git checkout
(-p|--patch) [<tree-ish>] [--] [<pathspec>...]
           This is similar to the previous mode, but lets you use the
           interactive interface to show the ""diff"" output and choose
           which hunks to use in the result."
419,11,git-checkout,"With
-m
, changes made to the working tree file can
           be discarded to re-create the original conflicted merge
           result. git checkout
(-p|--patch) [<tree-ish>] [--] [<pathspec>...]
           This is similar to the previous mode, but lets you use the
           interactive interface to show the ""diff"" output and choose
           which hunks to use in the result. See below for the
           description of
--patch
option."
420,0,git-clean,"Cleans the working tree by recursively removing files that are not
       under version control, starting from the current directory. Normally, only files unknown to Git are removed, but if the
-x
option is specified, ignored files are also removed. This can, for
       example, be useful to remove all build products."
420,1,git-clean,"This can, for
       example, be useful to remove all build products. If any optional
<pathspec>
... arguments are given, only those
       paths that match the pathspec are affected."
421,0,git-clone,"Clones a repository into a newly created directory, creates
       remote-tracking branches for each branch in the cloned repository
       (visible using
git branch --remotes
), and creates and checks out
       an initial branch that is forked from the cloned repositoryâs
       currently active branch.

       After the clone, a plain
git fetch
without arguments will update
       all the remote-tracking branches, and a
git pull
without arguments
       will in addition merge the remote master branch into the current
       master branch, if any (this is untrue when
--single-branch
is
       given; see below).

       This default configuration is achieved by creating references to
       the remote branch heads under
refs/remotes/origin
and by
       initializing
remote.origin.url
and
remote.origin.fetch
configuration variables."
422,0,git-commit-graph,Manage the serialized commit-graph file.
423,0,git-column,"This command formats the lines of its standard input into a table
       with multiple columns. Each input line occupies one cell of the
       table. It is used internally by other git commands to format
       output into columns."
424,0,git-commit-tree,"This is usually not what an end user wants to run directly. See
git-commit(1)
instead. Creates a new commit object based on the provided tree object and
       emits the new commit object id on stdout."
424,1,git-commit-tree,"Creates a new commit object based on the provided tree object and
       emits the new commit object id on stdout. The log message is read
       from the standard input, unless
-m
or
-F
options are given. The
-m
and
-F
options can be given any number of times, in any
       order."
424,2,git-commit-tree,"The
-m
and
-F
options can be given any number of times, in any
       order. The commit log message will be composed in the order in
       which the options are given. A commit object may have any number of parents."
424,3,git-commit-tree,"A commit object may have any number of parents. With exactly one
       parent, it is an ordinary commit. Having more than one parent
       makes the commit a merge between several lines of history."
424,4,git-commit-tree,"Having more than one parent
       makes the commit a merge between several lines of history. Initial
       (root) commits have no parents. While a tree represents a particular directory state of a working
       directory, a commit represents that state in ""time"", and explains
       how to get there."
424,5,git-commit-tree,"Initial
       (root) commits have no parents. While a tree represents a particular directory state of a working
       directory, a commit represents that state in ""time"", and explains
       how to get there. Normally a commit would identify a new ""HEAD"" state, and while Git
       doesnât care where you save the note about that state, in practice
       we tend to just write the result to the file that is pointed at by
.git/HEAD
, so that we can always see what the last committed state
       was."
425,0,git-count-objects,"Counts the number of unpacked object files and disk space consumed
       by them, to help you decide when it is a good time to repack."
426,0,git-credential-cache,"This command caches credentials for use by future Git programs. The stored credentials are kept in memory of the cache-daemon
       process (instead of being written to a file) and are forgotten
       after a configurable timeout. Credentials are forgotten sooner if
       the cache-daemon dies, for example if the system restarts."
426,1,git-credential-cache,"Credentials are forgotten sooner if
       the cache-daemon dies, for example if the system restarts. The
       cache is accessible over a Unix domain socket, restricted to the
       current user by filesystem permissions. You probably donât want to invoke this command directly; it is
       meant to be used as a credential helper by other parts of Git."
426,2,git-credential-cache,"The
       cache is accessible over a Unix domain socket, restricted to the
       current user by filesystem permissions. You probably donât want to invoke this command directly; it is
       meant to be used as a credential helper by other parts of Git. See
gitcredentials(7)
or
EXAMPLES
below."
427,0,git-credential-cache--daemon,"Note
You probably donât want to invoke this command yourself; it is
           started automatically when you use
git-credential-cache(1)
. This command listens on the Unix domain socket specified by
<socket-path>
for
git-credential-cache
clients. Clients may store
       and retrieve credentials."
427,1,git-credential-cache--daemon,"Clients may store
       and retrieve credentials. Each credential is held for a timeout
       specified by the client; once no credentials are held, the daemon
       exits. If the
--debug
option is specified, the daemon does not close its
       stderr stream, and may output extra diagnostics to it even after
       it has begun listening for clients."
428,0,git-commit,"Create a new commit containing the current contents of the index
       and the given log message describing the changes. The new commit
       is a direct child of HEAD, usually the tip of the current branch,
       and the branch is updated to point to it (unless no branch is
       associated with the working tree, in which case
HEAD
is ""detached""
       as described in
git-checkout(1)
). The content to be committed can be specified in several ways:

        1."
428,1,git-commit,"The content to be committed can be specified in several ways:

        1. by using
git-add(1)
to incrementally ""add"" changes to the
           index before using the
commit
command (Note: even modified
           files must be ""added"");

        2. by using
git-rm(1)
to remove files from the working tree and
           the index, again before using the
commit
command;

        3."
428,2,git-commit,"by using
git-rm(1)
to remove files from the working tree and
           the index, again before using the
commit
command;

        3. by listing files as arguments to the
commit
command (without
--interactive
or
--patch
switch), in which case the commit
           will ignore changes staged in the index, and instead record
           the current content of the listed files (which must already be
           known to Git);

        4. by using the
-a
switch with the
commit
command to
           automatically ""add"" changes from all known files (i.e."
428,3,git-commit,"by using the
-a
switch with the
commit
command to
           automatically ""add"" changes from all known files (i.e. all
           files that are already listed in the index) and to
           automatically ""rm"" files in the index that have been removed
           from the working tree, and then perform the actual commit;

        5. by using the
--interactive
or
--patch
switches with the
commit
command to decide one by one which files or hunks should be
           part of the commit in addition to contents in the index,
           before finalizing the operation."
428,4,git-commit,"by using the
--interactive
or
--patch
switches with the
commit
command to decide one by one which files or hunks should be
           part of the commit in addition to contents in the index,
           before finalizing the operation. See the âInteractive Modeâ
           section of
git-add(1)
to learn how to operate these modes. The
--dry-run
option can be used to obtain a summary of what is
       included by any of the above for the next commit by giving the
       same set of parameters (options and paths)."
428,5,git-commit,"See the âInteractive Modeâ
           section of
git-add(1)
to learn how to operate these modes. The
--dry-run
option can be used to obtain a summary of what is
       included by any of the above for the next commit by giving the
       same set of parameters (options and paths). If you make a commit and then find a mistake immediately after
       that, you can recover from it with
git reset
."
429,0,git-credential-store,"Note
Using this helper will store your passwords unencrypted on
           disk, protected only by filesystem permissions. If this is not
           an acceptable security tradeoff, try
git-credential-cache(1)
,
           or find a helper that integrates with secure storage provided
           by your operating system. This command stores credentials indefinitely on disk for use by
       future Git programs."
429,1,git-credential-store,"This command stores credentials indefinitely on disk for use by
       future Git programs. You probably donât want to invoke this command directly; it is
       meant to be used as a credential helper by other parts of git. See
gitcredentials(7)
or
EXAMPLES
below."
430,0,git-cvsexportcommit,"Exports a commit from Git to a CVS checkout, making it easier to
       merge patches from a Git repository into a CVS repository. Specify the name of a CVS checkout using the -w switch or execute
       it from the root of the CVS working copy. In the latter case
       GIT_DIR must be defined."
430,1,git-cvsexportcommit,"In the latter case
       GIT_DIR must be defined. See examples below. It does its best to do the safe thing, it will check that the
       files are unchanged and up to date in the CVS checkout, and it
       will not autocommit by default."
430,2,git-cvsexportcommit,"It does its best to do the safe thing, it will check that the
       files are unchanged and up to date in the CVS checkout, and it
       will not autocommit by default. Supports file additions, removals, and commits that affect binary
       files. If the commit is a merge commit, you must tell
git cvsexportcommit
what parent the changeset should be done against."
431,0,git-cvsimport,"WARNING: git cvsimport
uses cvsps version 2, which is considered
       deprecated; it does not work with cvsps version 3 and later. If
       you are performing a one-shot import of a CVS repository consider
       using
cvs2git
[1] or
cvs-fast-export
[2]. Imports a CVS repository into Git."
431,1,git-cvsimport,"Imports a CVS repository into Git. It will either create a new
       repository, or incrementally import into an existing one. Splitting the CVS log into patch sets is done by
cvsps
."
431,2,git-cvsimport,"Splitting the CVS log into patch sets is done by
cvsps
. At least
       version 2.1 is required. WARNING:
for certain situations the import leads to incorrect
       results."
431,3,git-cvsimport,"WARNING:
for certain situations the import leads to incorrect
       results. Please see the section ISSUES for further reference. You should
never
do any work of your own on the branches that are
       created by
git cvsimport
."
431,4,git-cvsimport,"You should
never
do any work of your own on the branches that are
       created by
git cvsimport
. By default initial import will create
       and populate a ""master"" branch from the CVS repositoryâs main
       branch which youâre free to work with; after that, you need to
git
merge
incremental imports, or any CVS branches, yourself. It is
       advisable to specify a named remote via -r to separate and protect
       the incoming branches."
431,5,git-cvsimport,"It is
       advisable to specify a named remote via -r to separate and protect
       the incoming branches. If you intend to set up a shared public repository that all
       developers can read/write, or if you want to use
git-cvsserver(1)
,
       then you probably want to make a bare clone of the imported
       repository, and use the clone as the shared repository. See
gitcvs-migration(7)
."
432,0,git-credential,"Git has an internal interface for storing and retrieving
       credentials from system-specific helpers, as well as prompting the
       user for usernames and passwords. The git-credential command
       exposes this interface to scripts which may want to retrieve,
       store, or prompt for credentials in the same manner as Git. The
       design of this scriptable interface models the internal C API; see
       credential.h for more background on the concepts."
432,1,git-credential,"The
       design of this scriptable interface models the internal C API; see
       credential.h for more background on the concepts. git-credential takes an ""action"" option on the command-line (one
       of
fill
,
approve
, or
reject
) and reads a credential description on
       stdin (see INPUT/OUTPUT FORMAT). If the action is
fill
, git-credential will attempt to add
       ""username"" and ""password"" attributes to the description by reading
       config files, by contacting any configured credential helpers, or
       by prompting the user."
432,2,git-credential,"If the action is
fill
, git-credential will attempt to add
       ""username"" and ""password"" attributes to the description by reading
       config files, by contacting any configured credential helpers, or
       by prompting the user. The username and password attributes of the
       credential description are then printed to stdout together with
       the attributes already provided. If the action is
approve
, git-credential will send the description
       to any configured credential helpers, which may store the
       credential for later use."
432,3,git-credential,"If the action is
approve
, git-credential will send the description
       to any configured credential helpers, which may store the
       credential for later use. If the action is
reject
, git-credential will send the description
       to any configured credential helpers, which may erase any stored
       credentials matching the description. If the action is
capability
, git-credential will announce any
       capabilities it supports to standard output."
432,4,git-credential,"If the action is
reject
, git-credential will send the description
       to any configured credential helpers, which may erase any stored
       credentials matching the description. If the action is
capability
, git-credential will announce any
       capabilities it supports to standard output. If the action is
approve
or
reject
, no output should be emitted."
433,0,git-cvsserver,"This application is a CVS emulation layer for Git. It is highly functional. However, not all methods are implemented,
       and for those methods that are implemented, not all switches are
       implemented."
433,1,git-cvsserver,"However, not all methods are implemented,
       and for those methods that are implemented, not all switches are
       implemented. Testing has been done using both the CLI CVS client, and the
       Eclipse CVS plugin. Most functionality works fine with both of
       these clients."
434,0,git-daemon,"A really simple TCP Git daemon that normally listens on port
       ""DEFAULT_GIT_PORT"" aka 9418. It waits for a connection asking for
       a service, and will serve that service if it is enabled. It verifies that the directory has the magic file
       ""git-daemon-export-ok"", and it will refuse to export any Git
       directory that hasnât explicitly been marked for export this way
       (unless the
--export-all
parameter is specified)."
434,1,git-daemon,"It verifies that the directory has the magic file
       ""git-daemon-export-ok"", and it will refuse to export any Git
       directory that hasnât explicitly been marked for export this way
       (unless the
--export-all
parameter is specified). If you pass some
       directory paths as
git daemon
arguments, the offers are limited to
       repositories within those directories. By default, only
upload-pack
service is enabled, which serves
git
fetch-pack
and
git ls-remote
clients, which are invoked from
git
fetch
,
git pull
, and
git clone
."
434,2,git-daemon,"By default, only
upload-pack
service is enabled, which serves
git
fetch-pack
and
git ls-remote
clients, which are invoked from
git
fetch
,
git pull
, and
git clone
. This is ideally suited for read-only updates, i.e., pulling from
       Git repositories. An
upload-archive
also exists to serve
git archive
."
435,0,git-diagnose,"Collects detailed information about the userâs machine, Git
       client, and repository state and packages that information into a
       zip archive. The generated archive can then, for example, be
       shared with the Git mailing list to help debug an issue or serve
       as a reference for independent debugging. By default, the following information is captured in the archive:

       â¢
git version --build-options
â¢   The path to the repository root

       â¢   The available disk space on the filesystem

       â¢   The name and size of each packfile, including those in
           alternate object stores

       â¢   The total count of loose objects, as well as counts broken
           down by
.git/objects
subdirectory

       Additional information can be collected by selecting a different
       diagnostic mode using the
--mode
option."
435,1,git-diagnose,"The generated archive can then, for example, be
       shared with the Git mailing list to help debug an issue or serve
       as a reference for independent debugging. By default, the following information is captured in the archive:

       â¢
git version --build-options
â¢   The path to the repository root

       â¢   The available disk space on the filesystem

       â¢   The name and size of each packfile, including those in
           alternate object stores

       â¢   The total count of loose objects, as well as counts broken
           down by
.git/objects
subdirectory

       Additional information can be collected by selecting a different
       diagnostic mode using the
--mode
option. This tool differs from
git-bugreport(1)
in that it collects much
       more detailed information with a greater focus on reporting the
       size and data shape of repository contents."
436,0,git-describe,"The command finds the most recent tag that is reachable from a
       commit. If the tag points to the commit, then only the tag is
       shown. Otherwise, it suffixes the tag name with the number of
       additional commits on top of the tagged object and the abbreviated
       object name of the most recent commit."
436,1,git-describe,"Otherwise, it suffixes the tag name with the number of
       additional commits on top of the tagged object and the abbreviated
       object name of the most recent commit. The result is a
       ""human-readable"" object name which can also be used to identify
       the commit to other git commands. By default (without --all or --tags)
git describe
only shows
       annotated tags."
436,2,git-describe,"By default (without --all or --tags)
git describe
only shows
       annotated tags. For more information about creating annotated tags
       see the -a and -s options to
git-tag(1)
. If the given object refers to a blob, it will be described as
<commit-ish>
:
<path>
, such that the blob can be found at
<path>
in
       the
<commit-ish>
, which itself describes the first commit in which
       this blob occurs in a reverse revision walk from HEAD."
437,0,git-diff-index,"Compare the content and mode of the blobs found in a tree object
       with the corresponding tracked files in the working tree, or with
       the corresponding paths in the index. When <path> arguments are
       present, compare only paths matching those patterns. Otherwise all
       tracked files are compared."
438,0,git-config,"You can query/set/replace/unset options with this command. The
       name is actually the section and the key separated by a dot, and
       the value will be escaped. Multiple lines can be added to an option by using the
--append
option."
438,1,git-config,"Multiple lines can be added to an option by using the
--append
option. If you want to update or unset an option which can occur
       on multiple lines, a
value-pattern
(which is an extended regular
       expression, unless the
--fixed-value
option is given) needs to be
       given. Only the existing values that match the pattern are updated
       or unset."
438,2,git-config,"Only the existing values that match the pattern are updated
       or unset. If you want to handle the lines that do
not
match the
       pattern, just prepend a single exclamation mark in front (see also
       the section called âEXAMPLESâ), but note that this only works when
       the
--fixed-value
option is not in use. The
--type=
<type>
option instructs
git config
to ensure that
       incoming and outgoing values are canonicalize-able under the given
       <type>."
438,3,git-config,"The
--type=
<type>
option instructs
git config
to ensure that
       incoming and outgoing values are canonicalize-able under the given
       <type>. If no
--type=
<type>
is given, no canonicalization will be
       performed. Callers may unset an existing
--type
specifier with
--no-type
."
438,4,git-config,"Callers may unset an existing
--type
specifier with
--no-type
. When reading, the values are read from the system, global and
       repository local configuration files by default, and options
--system
,
--global
,
--local
,
--worktree
and
--file
<filename>
can
       be used to tell the command to read from only that location (see
       the section called âFILESâ). When writing, the new value is written to the repository local
       configuration file by default, and options
--system
,
--global
,
--worktree
,
--file
<filename>
can be used to tell the command to
       write to that location (you can say
--local
but that is the
       default)."
438,5,git-config,"When writing, the new value is written to the repository local
       configuration file by default, and options
--system
,
--global
,
--worktree
,
--file
<filename>
can be used to tell the command to
       write to that location (you can say
--local
but that is the
       default). This command will fail with non-zero status upon error. Some exit
       codes are:

       â¢   The section or key is invalid (ret=1),

       â¢   no section or name was provided (ret=2),

       â¢   the config file is invalid (ret=3),

       â¢   the config file cannot be written (ret=4),

       â¢   you try to unset an option which does not exist (ret=5),

       â¢   you try to unset/set an option for which multiple lines match
           (ret=5), or

       â¢   you try to use an invalid regexp (ret=6)."
438,6,git-config,"Some exit
       codes are:

       â¢   The section or key is invalid (ret=1),

       â¢   no section or name was provided (ret=2),

       â¢   the config file is invalid (ret=3),

       â¢   the config file cannot be written (ret=4),

       â¢   you try to unset an option which does not exist (ret=5),

       â¢   you try to unset/set an option for which multiple lines match
           (ret=5), or

       â¢   you try to use an invalid regexp (ret=6). On success, the command returns the exit code 0. A list of all available configuration variables can be obtained
       using the
git help --config
command."
439,0,git-fast-export,"This program dumps the given revisions in a form suitable to be
       piped into
git fast-import
.

       You can use it as a human-readable bundle replacement (see
git-bundle(1)
), or as a format that can be edited before being fed
       to
git fast-import
in order to do history rewrites (an ability
       relied on by tools like
git filter-repo
)."
440,0,git-difftool,"git difftool
is a Git command that allows you to compare and edit
       files between revisions using common diff tools.
git difftool
is a
       frontend to
git diff
and accepts the same options and arguments.
       See
git-diff(1)
."
441,0,git-diff-files,"Compares the files in the working tree and the index. When paths
       are specified, compares only those named paths. Otherwise all
       entries in the index are compared."
441,1,git-diff-files,"When paths
       are specified, compares only those named paths. Otherwise all
       entries in the index are compared. The output format is the same
       as for
git diff-index
and
git diff-tree
."
442,0,git-diff-tree,"Compare the content and mode of blobs found via two tree objects.

       If there is only one <tree-ish> given, the commit is compared with
       its parents (see --stdin below).

       Note that
git diff-tree
can use the tree encapsulated in a commit
       object."
443,0,git-diff,"Show changes between the working tree and the index or a tree,
       changes between the index and a tree, changes between two trees,
       changes resulting from a merge, changes between two blob objects,
       or changes between two files on disk. git diff
[
<options>
] [
--
] [
<path>
...]
           This form is to view the changes you made relative to the
           index (staging area for the next commit). In other words, the
           differences are what you
could
tell Git to further add to the
           index but you still havenât."
443,1,git-diff,"In other words, the
           differences are what you
could
tell Git to further add to the
           index but you still havenât. You can stage these changes by
           using
git-add(1)
. git diff
[
<options>
]
--no-index
[
--
]
<path> <path>
This form is to compare the given two paths on the filesystem."
443,2,git-diff,"git diff
[
<options>
]
--no-index
[
--
]
<path> <path>
This form is to compare the given two paths on the filesystem. You can omit the
--no-index
option when running the command in
           a working tree controlled by Git and at least one of the paths
           points outside the working tree, or when running the command
           outside a working tree controlled by Git. This form implies
--exit-code
."
443,3,git-diff,"This form implies
--exit-code
. git diff
[
<options>
]
--cached
[
--merge-base
] [
<commit>
] [
--
]
       [
<path>
...]
           This form is to view the changes you staged for the next
           commit relative to the named
<commit>
. Typically you would
           want comparison with the latest commit, so if you do not give
<commit>
, it defaults to
HEAD
."
443,4,git-diff,"Typically you would
           want comparison with the latest commit, so if you do not give
<commit>
, it defaults to
HEAD
. If
HEAD
does not exist (e.g. unborn branches) and
<commit>
is not given, it shows all
           staged changes."
443,5,git-diff,"unborn branches) and
<commit>
is not given, it shows all
           staged changes. --staged
is a synonym of
--cached
. If
--merge-base
is given, instead of using
<commit>
, use the
           merge base of
<commit>
and
HEAD
."
443,6,git-diff,"If
--merge-base
is given, instead of using
<commit>
, use the
           merge base of
<commit>
and
HEAD
. git diff --cached
--merge-base A
is equivalent to
git diff --cached $
(
git
merge-base A HEAD
). git diff
[
<options>
] [
--merge-base
]
<commit>
[
--
] [
<path>
...]
           This form is to view the changes you have in your working tree
           relative to the named
<commit>
."
443,7,git-diff,"git diff
[
<options>
] [
--merge-base
]
<commit>
[
--
] [
<path>
...]
           This form is to view the changes you have in your working tree
           relative to the named
<commit>
. You can use
HEAD
to compare it
           with the latest commit, or a branch name to compare with the
           tip of a different branch. If
--merge-base
is given, instead of using
<commit>
, use the
           merge base of
<commit>
and
HEAD
."
443,8,git-diff,"If
--merge-base
is given, instead of using
<commit>
, use the
           merge base of
<commit>
and
HEAD
. git diff --merge-base A
is
           equivalent to
git diff $
(
git merge-base A HEAD
). git diff
[
<options>
] [
--merge-base
]
<commit> <commit>
[
--
]
       [
<path>
...]
           This is to view the changes between two arbitrary
<commit>
."
443,9,git-diff,"git diff
[
<options>
] [
--merge-base
]
<commit> <commit>
[
--
]
       [
<path>
...]
           This is to view the changes between two arbitrary
<commit>
. If
--merge-base
is given, use the merge base of the two
           commits for the ""before"" side. git diff --merge-base A B
is
           equivalent to
git diff $
(
git merge-base A B
)
B
."
443,10,git-diff,"git diff --merge-base A B
is
           equivalent to
git diff $
(
git merge-base A B
)
B
. git diff
[
<options>
]
<commit> <commit>
... <commit>
[
--
] [
<path>
...]
           This form is to view the results of a merge commit."
443,11,git-diff,"<commit>
[
--
] [
<path>
...]
           This form is to view the results of a merge commit. The first
           listed
<commit>
must be the merge itself; the remaining two or
           more commits should be its parents. Convenient ways to produce
           the desired set of revisions are to use the suffixes
@
and
^
!."
443,12,git-diff,"Convenient ways to produce
           the desired set of revisions are to use the suffixes
@
and
^
!. If
A
is a merge commit, then
git diff A A^@
,
git diff A^
! and
git show A
all give the same combined diff."
443,13,git-diff,"and
git show A
all give the same combined diff. git diff
[
<options>
]
<commit>
.. <commit>
[
--
] [
<path>
...]
           This is synonymous to the earlier form (without the ..) for
           viewing the changes between two arbitrary
<commit>
."
443,14,git-diff,"<commit>
[
--
] [
<path>
...]
           This is synonymous to the earlier form (without the ..) for
           viewing the changes between two arbitrary
<commit>
. If
<commit>
on one side is omitted, it will have the same effect
           as using
HEAD
instead. git diff
[
<options>
]
<commit>
..."
443,15,git-diff,"git diff
[
<options>
]
<commit>
... <commit>
[
--
] [
<path>
...]
           This form is to view the changes on the branch containing and
           up to the second
<commit>
, starting at a common ancestor of
           both
<commit>
. git diff A...B
is equivalent to
git diff $
(
git
merge-base A B
)
B
."
443,16,git-diff,"git diff A...B
is equivalent to
git diff $
(
git
merge-base A B
)
B
. You can omit any one of
<commit>
, which has
           the same effect as using
HEAD
instead. Just in case you are doing something exotic, it should be noted
       that all of the
<commit>
in the above description, except in the
--merge-base
case and in the last two forms that use .."
443,17,git-diff,"Just in case you are doing something exotic, it should be noted
       that all of the
<commit>
in the above description, except in the
--merge-base
case and in the last two forms that use .. notations,
       can be any
<tree>
. A tree of interest is the one pointed to by the
       ref named
AUTO_MERGE
, which is written by the
ort
merge strategy
       upon hitting merge conflicts (see
git-merge(1)
)."
443,18,git-diff,"A tree of interest is the one pointed to by the
       ref named
AUTO_MERGE
, which is written by the
ort
merge strategy
       upon hitting merge conflicts (see
git-merge(1)
). Comparing the
       working tree with
AUTO_MERGE
shows changes youâve made so far to
       resolve textual conflicts (see the examples below). For a more complete list of ways to spell
<commit>
, see
       ""SPECIFYING REVISIONS"" section in
gitrevisions(7)
."
443,19,git-diff,"For a more complete list of ways to spell
<commit>
, see
       ""SPECIFYING REVISIONS"" section in
gitrevisions(7)
. However,
diff
is about comparing two
endpoints
, not ranges, and the range
       notations (
<commit>
.. <commit>
and
<commit>
..."
443,20,git-diff,"<commit>
and
<commit>
... <commit>
) do not mean
       a range as defined in the ""SPECIFYING RANGES"" section in
gitrevisions(7)
. git diff
[
<options>
]
<blob> <blob>
This form is to view the differences between the raw contents
           of two blob objects."
444,0,git-fast-import,"This program is usually not what the end user wants to run
       directly. Most end users want to use one of the existing frontend
       programs, which parses a specific type of foreign source and feeds
       the contents stored there to
git fast-import
. fast-import reads a mixed command/data stream from standard input
       and writes one or more packfiles directly into the current
       repository."
444,1,git-fast-import,"fast-import reads a mixed command/data stream from standard input
       and writes one or more packfiles directly into the current
       repository. When EOF is received on standard input, fast import
       writes out updated branch and tag refs, fully updating the current
       repository with the newly imported data. The fast-import backend itself can import into an empty repository
       (one that has already been initialized by
git init
) or
       incrementally update an existing populated repository."
444,2,git-fast-import,"When EOF is received on standard input, fast import
       writes out updated branch and tag refs, fully updating the current
       repository with the newly imported data. The fast-import backend itself can import into an empty repository
       (one that has already been initialized by
git init
) or
       incrementally update an existing populated repository. Whether or
       not incremental imports are supported from a particular foreign
       source depends on the frontend program in use."
445,0,git-fetch-pack,"Usually you would want to use
git fetch
, which is a higher level
       wrapper of this command, instead. Invokes
git-upload-pack
on a possibly remote repository and asks
       it to send objects missing from this repository, to update the
       named heads. The list of commits available locally is found out by
       scanning the local refs/ hierarchy and sent to
git-upload-pack
running on the other end."
445,1,git-fetch-pack,"Invokes
git-upload-pack
on a possibly remote repository and asks
       it to send objects missing from this repository, to update the
       named heads. The list of commits available locally is found out by
       scanning the local refs/ hierarchy and sent to
git-upload-pack
running on the other end. This command degenerates to download everything to complete the
       asked refs from the remote side when the local side does not have
       a common ancestor commit."
446,0,git-fmt-merge-msg,"Takes the list of merged objects on stdin and produces a suitable
       commit message to be used for the merge commit, usually to be
       passed as the
<merge-message>
argument of
git merge
.

       This command is intended mostly for internal use by scripts
       automatically invoking
git merge
."
447,0,git-for-each-repo,"Run a Git command on a list of repositories. The arguments after
       the known options or
--
indicator are used as the arguments for
       the Git subprocess. THIS COMMAND IS EXPERIMENTAL."
447,1,git-for-each-repo,"THIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE. For example, we could run maintenance on each of a list of
       repositories stored in a
maintenance.repo
config variable using

           git for-each-repo --config=maintenance.repo maintenance run

       This will run
git -C
<repo>
maintenance run
for each value
<repo>
in the multi-valued config variable
maintenance.repo
."
448,0,git-for-each-ref,"Iterate over all refs that match
<pattern>
and show them according
       to the given
<format>
, after sorting them according to the given
       set of
<key>
. If
<count>
is given, stop after showing that many
       refs. The interpolated values in
<format>
can optionally be quoted
       as string literals in the specified host language allowing their
       direct evaluation in that language."
449,0,git-filter-branch,"Lets you rewrite Git revision history by rewriting the branches
       mentioned in the <rev-list-options>, applying custom filters on
       each revision. Those filters can modify each tree (e.g. removing a
       file or running a perl rewrite on all files) or information about
       each commit."
449,1,git-filter-branch,"removing a
       file or running a perl rewrite on all files) or information about
       each commit. Otherwise, all information (including original commit
       times or merge information) will be preserved. The command will only rewrite the
positive
refs mentioned in the
       command line (e.g."
449,2,git-filter-branch,"The command will only rewrite the
positive
refs mentioned in the
       command line (e.g. if you pass
a..b
, only
b
will be rewritten). If
       you specify no filters, the commits will be recommitted without
       any changes, which would normally have no effect."
449,3,git-filter-branch,"If
       you specify no filters, the commits will be recommitted without
       any changes, which would normally have no effect. Nevertheless,
       this may be useful in the future for compensating for some Git
       bugs or such, therefore such a usage is permitted. NOTE
: This command honors
.git/info/grafts
file and refs in the
refs/replace/
namespace."
449,4,git-filter-branch,"NOTE
: This command honors
.git/info/grafts
file and refs in the
refs/replace/
namespace. If you have any grafts or replacement
       refs defined, running this command will make them permanent. WARNING
!"
449,5,git-filter-branch,"WARNING
! The rewritten history will have different object names
       for all the objects and will not converge with the original
       branch. You will not be able to easily push and distribute the
       rewritten branch on top of the original branch."
449,6,git-filter-branch,"You will not be able to easily push and distribute the
       rewritten branch on top of the original branch. Please do not use
       this command if you do not know the full implications, and avoid
       using it anyway, if a simple single commit would suffice to fix
       your problem. (See the ""RECOVERING FROM UPSTREAM REBASE"" section
       in
git-rebase(1)
for further information about rewriting published
       history.)

       Always verify that the rewritten version is correct: The original
       refs, if different from the rewritten ones, will be stored in the
       namespace
refs/original/
."
449,7,git-filter-branch,"(See the ""RECOVERING FROM UPSTREAM REBASE"" section
       in
git-rebase(1)
for further information about rewriting published
       history.)

       Always verify that the rewritten version is correct: The original
       refs, if different from the rewritten ones, will be stored in the
       namespace
refs/original/
. Note that since this operation is very I/O expensive, it might be
       a good idea to redirect the temporary directory off-disk with the
-d
option, e.g. on tmpfs."
449,8,git-filter-branch,"on tmpfs. Reportedly the speedup is very
       noticeable. Filters
The filters are applied in the order as listed below."
449,9,git-filter-branch,"Filters
The filters are applied in the order as listed below. The
       <command> argument is always evaluated in the shell context using
       the
eval
command (with the notable exception of the commit filter,
       for technical reasons). Prior to that, the
$GIT_COMMIT
environment
       variable will be set to contain the id of the commit being
       rewritten."
449,10,git-filter-branch,"Prior to that, the
$GIT_COMMIT
environment
       variable will be set to contain the id of the commit being
       rewritten. Also, GIT_AUTHOR_NAME, GIT_AUTHOR_EMAIL,
       GIT_AUTHOR_DATE, GIT_COMMITTER_NAME, GIT_COMMITTER_EMAIL, and
       GIT_COMMITTER_DATE are taken from the current commit and exported
       to the environment, in order to affect the author and committer
       identities of the replacement commit created by
git-commit-tree(1)
after the filters have run. If any evaluation of <command> returns a non-zero exit status, the
       whole operation will be aborted."
449,11,git-filter-branch,"Also, GIT_AUTHOR_NAME, GIT_AUTHOR_EMAIL,
       GIT_AUTHOR_DATE, GIT_COMMITTER_NAME, GIT_COMMITTER_EMAIL, and
       GIT_COMMITTER_DATE are taken from the current commit and exported
       to the environment, in order to affect the author and committer
       identities of the replacement commit created by
git-commit-tree(1)
after the filters have run. If any evaluation of <command> returns a non-zero exit status, the
       whole operation will be aborted. A
map
function is available that takes an ""original sha1 id""
       argument and outputs a ""rewritten sha1 id"" if the commit has been
       already rewritten, and ""original sha1 id"" otherwise; the
map
function can return several ids on separate lines if your commit
       filter emitted multiple commits."
450,0,git-fetch,"Fetch branches and/or tags (collectively, ""refs"") from one or more
       other repositories, along with the objects necessary to complete
       their histories. Remote-tracking branches are updated (see the
       description of <refspec> below for ways to control this behavior). By default, any tag that points into the histories being fetched
       is also fetched; the effect is to fetch tags that point at
       branches that you are interested in."
450,1,git-fetch,"By default, any tag that points into the histories being fetched
       is also fetched; the effect is to fetch tags that point at
       branches that you are interested in. This default behavior can be
       changed by using the --tags or --no-tags options or by configuring
       remote.<name>.tagOpt. By using a refspec that fetches tags
       explicitly, you can fetch tags that do not point into branches you
       are interested in as well."
450,2,git-fetch,"By using a refspec that fetches tags
       explicitly, you can fetch tags that do not point into branches you
       are interested in as well. git fetch
can fetch from either a single named repository or URL,
       or from several repositories at once if <group> is given and there
       is a remotes.<group> entry in the configuration file. (See
git-config(1)
)."
450,3,git-fetch,"(See
git-config(1)
). When no remote is specified, by default the
origin
remote will be
       used, unless thereâs an upstream branch configured for the current
       branch. The names of refs that are fetched, together with the object names
       they point at, are written to
.git/FETCH_HEAD
."
450,4,git-fetch,"When no remote is specified, by default the
origin
remote will be
       used, unless thereâs an upstream branch configured for the current
       branch. The names of refs that are fetched, together with the object names
       they point at, are written to
.git/FETCH_HEAD
. This information
       may be used by scripts or other git commands, such as
git-pull(1)
."
451,0,git-format-patch,"Prepare each non-merge commit with its ""patch"" in one ""message""
       per commit, formatted to resemble a UNIX mailbox. The output of
       this command is convenient for e-mail submission or for use with
git am
. A ""message"" generated by the command consists of three parts:

       â¢   A brief metadata header that begins with
From
<commit>
with a
           fixed
Mon Sep 17 00:00:00 2001
datestamp to help programs like
           ""file(1)"" to recognize that the file is an output from this
           command, fields that record the author identity, the author
           date, and the title of the change (taken from the first
           paragraph of the commit log message)."
451,1,git-format-patch,"A ""message"" generated by the command consists of three parts:

       â¢   A brief metadata header that begins with
From
<commit>
with a
           fixed
Mon Sep 17 00:00:00 2001
datestamp to help programs like
           ""file(1)"" to recognize that the file is an output from this
           command, fields that record the author identity, the author
           date, and the title of the change (taken from the first
           paragraph of the commit log message). â¢   The second and subsequent paragraphs of the commit log
           message. â¢   The ""patch"", which is the ""diff -p --stat"" output (see
git-diff(1)
) between the commit and its parent."
451,2,git-format-patch,"â¢   The ""patch"", which is the ""diff -p --stat"" output (see
git-diff(1)
) between the commit and its parent. The log message and the patch are separated by a line with a
       three-dash line. There are two ways to specify which commits to operate on."
451,3,git-format-patch,"There are two ways to specify which commits to operate on. 1. A single commit, <since>, specifies that the commits leading
           to the tip of the current branch that are not in the history
           that leads to the <since> to be output."
451,4,git-format-patch,"A single commit, <since>, specifies that the commits leading
           to the tip of the current branch that are not in the history
           that leads to the <since> to be output. 2. Generic <revision-range> expression (see ""SPECIFYING
           REVISIONS"" section in
gitrevisions(7)
) means the commits in
           the specified range."
451,5,git-format-patch,"Generic <revision-range> expression (see ""SPECIFYING
           REVISIONS"" section in
gitrevisions(7)
) means the commits in
           the specified range. The first rule takes precedence in the case of a single <commit>. To apply the second rule, i.e., format everything since the
       beginning of history up until <commit>, use the
--root
option:
git
format-patch --root
<commit>
."
451,6,git-format-patch,"To apply the second rule, i.e., format everything since the
       beginning of history up until <commit>, use the
--root
option:
git
format-patch --root
<commit>
. If you want to format only <commit>
       itself, you can do this with
git format-patch -1
<commit>
. By default, each output file is numbered sequentially from 1, and
       uses the first line of the commit message (massaged for pathname
       safety) as the filename."
451,7,git-format-patch,"By default, each output file is numbered sequentially from 1, and
       uses the first line of the commit message (massaged for pathname
       safety) as the filename. With the
--numbered-files
option, the
       output file names will only be numbers, without the first line of
       the commit appended. The names of the output files are printed to
       standard output, unless the
--stdout
option is specified."
451,8,git-format-patch,"The names of the output files are printed to
       standard output, unless the
--stdout
option is specified. If
-o
is specified, output files are created in <dir>. Otherwise
       they are created in the current working directory."
451,9,git-format-patch,"Otherwise
       they are created in the current working directory. The default
       path can be set with the
format.outputDirectory
configuration
       option. The
-o
option takes precedence over
format.outputDirectory
."
451,10,git-format-patch,"The
-o
option takes precedence over
format.outputDirectory
. To store patches in the current working
       directory even when
format.outputDirectory
points elsewhere, use
-o
.. All directory components will be created."
451,11,git-format-patch,"All directory components will be created. By default, the subject of a single patch is ""[PATCH] "" followed
       by the concatenation of lines from the commit message up to the
       first blank line (see the DISCUSSION section of
git-commit(1)
). When multiple patches are output, the subject prefix will instead
       be ""[PATCH n/m] ""."
451,12,git-format-patch,"When multiple patches are output, the subject prefix will instead
       be ""[PATCH n/m] "". To force 1/1 to be added for a single patch,
       use
-n
. To omit patch numbers from the subject, use
-N
."
451,13,git-format-patch,"To force 1/1 to be added for a single patch,
       use
-n
. To omit patch numbers from the subject, use
-N
. If given
--thread
,
git-format-patch
will generate
In-Reply-To
and
References
headers to make the second and subsequent patch mails
       appear as replies to the first mail; this also generates a
Message-ID
header to reference."
452,0,git-fsck-objects,"This is a synonym for
git-fsck(1)
. Please refer to the
       documentation of that command."
453,0,git-fsck,"Verifies the connectivity and validity of the objects in the
       database."
454,0,git-fsmonitor--daemon,"A daemon to watch the working directory for file and directory
       changes using platform-specific filesystem notification
       facilities.

       This daemon communicates directly with commands like
git status
using the
simple IPC
[1] interface instead of the slower
githooks(5)
interface.

       This daemon is built into Git so that no third-party tools are
       required."
455,0,git-gc,"Runs a number of housekeeping tasks within the current repository,
       such as compressing file revisions (to reduce disk space and
       increase performance), removing unreachable objects which may have
       been created from prior invocations of
git add
, packing refs,
       pruning reflog, rerere metadata or stale working trees. May also
       update ancillary indexes such as the commit-graph. When common porcelain operations that create objects are run, they
       will check whether the repository has grown substantially since
       the last maintenance, and if so run
git gc
automatically."
455,1,git-gc,"When common porcelain operations that create objects are run, they
       will check whether the repository has grown substantially since
       the last maintenance, and if so run
git gc
automatically. See
gc.auto
below for how to disable this behavior. Running
git gc
manually should only be needed when adding objects
       to a repository without regularly running such porcelain commands,
       to do a one-off repository optimization, or e.g."
455,2,git-gc,"Running
git gc
manually should only be needed when adding objects
       to a repository without regularly running such porcelain commands,
       to do a one-off repository optimization, or e.g. to clean up a
       suboptimal mass-import. See the ""PACKFILE OPTIMIZATION"" section in
git-fast-import(1)
for more details on the import case."
456,0,git-get-tar-commit-id,"Read a tar archive created by
git archive
from the standard input
       and extract the commit ID stored in it. It reads only the first
       1024 bytes of input, thus its runtime is not influenced by the
       size of the tar archive very much. If no commit ID is found,
git get-tar-commit-id
quietly exits with
       a return code of 1."
456,1,git-get-tar-commit-id,"It reads only the first
       1024 bytes of input, thus its runtime is not influenced by the
       size of the tar archive very much. If no commit ID is found,
git get-tar-commit-id
quietly exits with
       a return code of 1. This can happen if the archive had not been
       created using
git archive
or if the first parameter of
git archive
had been a tree ID instead of a commit ID or tag."
457,0,git-grep,"Look for specified patterns in the tracked files in the work tree,
       blobs registered in the index file, or blobs in given tree
       objects. Patterns are lists of one or more search expressions
       separated by newline characters. An empty string as search
       expression matches all lines."
458,0,git-gui,"A Tcl/Tk based graphical user interface to Git. git gui
focuses on
       allowing users to make changes to their repository by making new
       commits, amending existing ones, creating branches, performing
       local merges, and fetching/pushing to remote repositories. Unlike
gitk
,
git gui
focuses on commit generation and single file
       annotation and does not show project history."
458,1,git-gui,"Unlike
gitk
,
git gui
focuses on commit generation and single file
       annotation and does not show project history. It does however
       supply menu actions to start a
gitk
session from within
git gui
. git gui
is known to work on all popular UNIX systems, Mac OS X,
       and Windows (under both Cygwin and MSYS)."
458,2,git-gui,"It does however
       supply menu actions to start a
gitk
session from within
git gui
. git gui
is known to work on all popular UNIX systems, Mac OS X,
       and Windows (under both Cygwin and MSYS). To the extent possible
       OS specific user interface guidelines are followed, making
git gui
a fairly native interface for users."
459,0,git-hash-object,"Computes the object ID value for an object with specified type
       with the contents of the named file (which can be outside of the
       work tree), and optionally writes the resulting object into the
       object database. Reports its object ID to its standard output.
       When <type> is not specified, it defaults to ""blob""."
460,0,git-help,"With no options and no
<command>
or
<doc>
given, the synopsis of
       the
git
command and a list of the most commonly used Git commands
       are printed on the standard output. If the option
--all
or
-a
is given, all available commands are
       printed on the standard output. If the option
--guides
or
-g
is given, a list of the Git concept
       guides is also printed on the standard output."
460,1,git-help,"If the option
--guides
or
-g
is given, a list of the Git concept
       guides is also printed on the standard output. If a command or other documentation is given, the relevant manual
       page will be brought up. The
man
program is used by default for
       this purpose, but this can be overridden by other options or
       configuration variables."
460,2,git-help,"The
man
program is used by default for
       this purpose, but this can be overridden by other options or
       configuration variables. If an alias is given, git shows the definition of the alias on
       standard output. To get the manual page for the aliased command,
       use
git
<command>
--help
."
460,3,git-help,"To get the manual page for the aliased command,
       use
git
<command>
--help
. Note that
git --help
... is identical to
git help
..."
460,4,git-help,"is identical to
git help
... because the
       former is internally converted into the latter. To display the
git(1)
man page, use
git help git
."
460,5,git-help,"because the
       former is internally converted into the latter. To display the
git(1)
man page, use
git help git
. This page can be displayed with
git help help
or
git help --help
."
461,0,git-hook,"A command interface for running git hooks (see
githooks(5)
), for
       use by other scripted git commands."
462,0,git-http-backend,"A simple CGI program to serve the contents of a Git repository to
       Git clients accessing the repository over
http://
and
https://
protocols. The program supports clients fetching using both the
       smart HTTP protocol and the backwards-compatible dumb HTTP
       protocol, as well as clients pushing using the smart HTTP
       protocol. It also supports Gitâs more-efficient ""v2"" protocol if
       properly configured; see the discussion of
GIT_PROTOCOL
in the
       ENVIRONMENT section below."
462,1,git-http-backend,"It also supports Gitâs more-efficient ""v2"" protocol if
       properly configured; see the discussion of
GIT_PROTOCOL
in the
       ENVIRONMENT section below. It verifies that the directory has the magic file
       ""git-daemon-export-ok"", and it will refuse to export any Git
       directory that hasnât explicitly been marked for export this way
       (unless the
GIT_HTTP_EXPORT_ALL
environment variable is set). By default, only the
upload-pack
service is enabled, which serves
git fetch-pack
and
git ls-remote
clients, which are invoked from
git fetch
,
git pull
, and
git clone
."
462,2,git-http-backend,"It verifies that the directory has the magic file
       ""git-daemon-export-ok"", and it will refuse to export any Git
       directory that hasnât explicitly been marked for export this way
       (unless the
GIT_HTTP_EXPORT_ALL
environment variable is set). By default, only the
upload-pack
service is enabled, which serves
git fetch-pack
and
git ls-remote
clients, which are invoked from
git fetch
,
git pull
, and
git clone
. If the client is
       authenticated, the
receive-pack
service is enabled, which serves
git send-pack
clients, which is invoked from
git push
."
463,0,git-http-fetch,"Downloads a remote Git repository via HTTP. This command always gets all objects. Historically, there were
       three options
-a
,
-c
and
-t
for choosing which objects to
       download."
463,1,git-http-fetch,"This command always gets all objects. Historically, there were
       three options
-a
,
-c
and
-t
for choosing which objects to
       download. They are now silently ignored."
464,0,git-http-push,"Sends missing objects to the remote repository, and updates the
       remote branch.
NOTE
: This command is temporarily disabled if your libcurl is
       older than 7.16, as the combination has been reported not to work
       and sometimes corrupts the repository."
465,0,git-imap-send,"This command uploads a mailbox generated with
git format-patch
into an IMAP drafts folder. This allows patches to be sent as
       other email is when using mail clients that cannot read mailbox
       files directly. The command also works with any general mailbox in
       which emails have the fields ""From"", ""Date"", and ""Subject"" in that
       order."
465,1,git-imap-send,"This allows patches to be sent as
       other email is when using mail clients that cannot read mailbox
       files directly. The command also works with any general mailbox in
       which emails have the fields ""From"", ""Date"", and ""Subject"" in that
       order. Typical usage is something like:

       git format-patch --signoff --stdout --attach origin | git
       imap-send"
466,0,git-index-pack,"Reads a packed archive (.pack) from the specified file, builds a
       pack index file (.idx) for it, and optionally writes a
       reverse-index (.rev) for the specified pack. The packed archive,
       together with the pack index, can then be placed in the
       objects/pack/ directory of a Git repository."
467,0,git-init-db,"This is a synonym for
git-init(1)
. Please refer to the
       documentation of that command."
468,0,git-instaweb,"A simple script to set up
gitweb
and a web server for browsing the
       local repository."
469,0,git-init,"This command creates an empty Git repository - basically a
.git
directory with subdirectories for
objects
,
refs/heads
,
refs/tags
,
       and template files. An initial branch without any commits will be
       created (see the
--initial-branch
option below for its name). If the
GIT_DIR
environment variable is set then it specifies a
       path to use instead of
./.git
for the base of the repository."
469,1,git-init,"If the
GIT_DIR
environment variable is set then it specifies a
       path to use instead of
./.git
for the base of the repository. If the object storage directory is specified via the
GIT_OBJECT_DIRECTORY
environment variable then the sha1
       directories are created underneath; otherwise, the default
$GIT_DIR/objects
directory is used. Running
git init
in an existing repository is safe."
469,2,git-init,"Running
git init
in an existing repository is safe. It will not
       overwrite things that are already there. The primary reason for
       rerunning
git init
is to pick up newly added templates (or to move
       the repository to another place if
--separate-git-dir
is given)."
470,0,git-interpret-trailers,"Add or parse
trailer
lines that look similar to RFC 822 e-mail
       headers, at the end of the otherwise free-form part of a commit
       message. For example, in the following commit message

           subject

           Lorem ipsum dolor sit amet, consectetur adipiscing elit. Signed-off-by: Alice <alice@example.com>
           Signed-off-by: Bob <bob@example.com>

       the last two lines starting with ""Signed-off-by"" are trailers."
470,1,git-interpret-trailers,"Signed-off-by: Alice <alice@example.com>
           Signed-off-by: Bob <bob@example.com>

       the last two lines starting with ""Signed-off-by"" are trailers. This command reads commit messages from either the <file>
       arguments or the standard input if no <file> is specified. If
--parse
is specified, the output consists of the parsed trailers
       coming from the input, without influencing them with any command
       line options or configuration variables."
470,2,git-interpret-trailers,"If
--parse
is specified, the output consists of the parsed trailers
       coming from the input, without influencing them with any command
       line options or configuration variables. Otherwise, this command applies
trailer. * configuration variables
       (which could potentially add new trailers, as well as reposition
       them), as well as any command line arguments that can override
       configuration variables (such as
--trailer=."
470,3,git-interpret-trailers,"* configuration variables
       (which could potentially add new trailers, as well as reposition
       them), as well as any command line arguments that can override
       configuration variables (such as
--trailer=. .. which could also
       add new trailers), to each input file."
470,4,git-interpret-trailers,"which could also
       add new trailers), to each input file. The result is emitted on
       the standard output. This command can also operate on the output of
git-format-patch(1)
, which is more elaborate than a plain commit
       message."
470,5,git-interpret-trailers,"This command can also operate on the output of
git-format-patch(1)
, which is more elaborate than a plain commit
       message. Namely, such output includes a commit message (as above),
       a ""---"" divider line, and a patch part. For these inputs, the
       divider and patch parts are not modified by this command and are
       emitted as is on the output, unless
--no-divider
is specified."
470,6,git-interpret-trailers,"For these inputs, the
       divider and patch parts are not modified by this command and are
       emitted as is on the output, unless
--no-divider
is specified. Some configuration variables control the way the
--trailer
arguments are applied to each input and the way any existing
       trailer in the input is changed. They also make it possible to
       automatically add some trailers."
470,7,git-interpret-trailers,"They also make it possible to
       automatically add some trailers. By default, a
<key>=<value>
or
<key>:<value>
argument given using
--trailer
will be appended after the existing trailers only if the
       last trailer has a different (<key>, <value>) pair (or if there is
       no existing trailer). The <key> and <value> parts will be trimmed
       to remove starting and trailing whitespace, and the resulting
       trimmed <key> and <value> will appear in the output like this:

           key: value

       This means that the trimmed <key> and <value> will be separated by
       ': ' (one colon followed by one space)."
470,8,git-interpret-trailers,"The <key> and <value> parts will be trimmed
       to remove starting and trailing whitespace, and the resulting
       trimmed <key> and <value> will appear in the output like this:

           key: value

       This means that the trimmed <key> and <value> will be separated by
       ': ' (one colon followed by one space). For convenience, a <key-alias> can be configured to make using
--trailer
shorter to type on the command line. This can be
       configured using the
trailer.<key-alias>.key
configuration
       variable."
470,9,git-interpret-trailers,"This can be
       configured using the
trailer.<key-alias>.key
configuration
       variable. The <keyAlias> must be a prefix of the full <key>
       string, although case sensitivity does not matter. For example, if
       you have

           trailer.sign.key ""Signed-off-by: ""

       in your configuration, you only need to specify
--trailer=
""sign:
foo
"" on the command line instead of
--trailer=
""Signed-off-by:
foo
""."
470,10,git-interpret-trailers,"For example, if
       you have

           trailer.sign.key ""Signed-off-by: ""

       in your configuration, you only need to specify
--trailer=
""sign:
foo
"" on the command line instead of
--trailer=
""Signed-off-by:
foo
"". By default the new trailer will appear at the end of all the
       existing trailers. If there is no existing trailer, the new
       trailer will appear at the end of the input."
470,11,git-interpret-trailers,"If there is no existing trailer, the new
       trailer will appear at the end of the input. A blank line will be
       added before the new trailer if there isnât one already. Existing trailers are extracted from the input by looking for a
       group of one or more lines that (i) is all trailers, or (ii)
       contains at least one Git-generated or user-configured trailer and
       consists of at least 25% trailers."
470,12,git-interpret-trailers,"Existing trailers are extracted from the input by looking for a
       group of one or more lines that (i) is all trailers, or (ii)
       contains at least one Git-generated or user-configured trailer and
       consists of at least 25% trailers. The group must be preceded by
       one or more empty (or whitespace-only) lines. The group must
       either be at the end of the input or be the last non-whitespace
       lines before a line that starts with
---
(followed by a space or
       the end of the line)."
470,13,git-interpret-trailers,"The group must
       either be at the end of the input or be the last non-whitespace
       lines before a line that starts with
---
(followed by a space or
       the end of the line). When reading trailers, there can be no whitespace before or inside
       the <key>, but any number of regular space and tab characters are
       allowed between the <key> and the separator. There can be
       whitespaces before, inside or after the <value>."
470,14,git-interpret-trailers,"There can be
       whitespaces before, inside or after the <value>. The <value> may
       be split over multiple lines with each subsequent line starting
       with at least one whitespace, like the ""folding"" in RFC 822. Example:

           key: This is a very long value, with spaces and
             newlines in it."
470,15,git-interpret-trailers,"Example:

           key: This is a very long value, with spaces and
             newlines in it. Note that trailers do not follow (nor are they intended to follow)
       many of the rules for RFC 822 headers. For example they do not
       follow the encoding rule."
471,0,git-ls-files,"This command merges the file listing in the index with the actual
       working directory list, and shows different combinations of the
       two.

       Several flags can be used to determine which files are shown, and
       each file may be printed multiple times if there are multiple
       entries in the index or if multiple statuses are applicable for
       the relevant file selection options."
472,0,git-ls-remote,"Displays references available in a remote repository along with
       the associated commit IDs."
473,0,git-ls-tree,"Lists the contents of a given tree object, like what ""/bin/ls -a""
       does in the current working directory. Note that:

       â¢   the behaviour is slightly different from that of ""/bin/ls"" in
           that the
<path>
denotes just a list of patterns to match, e.g. so specifying directory name (without
-r
) will behave
           differently, and order of the arguments does not matter."
473,1,git-ls-tree,"so specifying directory name (without
-r
) will behave
           differently, and order of the arguments does not matter. â¢   the behaviour is similar to that of ""/bin/ls"" in that the
<path>
is taken as relative to the current working directory. E.g."
473,2,git-ls-tree,"E.g. when you are in a directory
sub
that has a directory
dir
,
           you can run
git ls-tree -r HEAD dir
to list the contents of
           the tree (that is
sub/dir
in
HEAD
). You donât want to give a
           tree that is not at the root level (e.g."
473,3,git-ls-tree,"You donât want to give a
           tree that is not at the root level (e.g. git ls-tree -r
HEAD:sub dir
) in this case, as that would result in asking for
sub/sub/dir
in the
HEAD
commit. However, the current working
           directory can be ignored by passing --full-tree option."
474,0,git-mailsplit,"Splits a mbox file or a Maildir into a list of files: ""0001""
       ""0002"" .. in the specified directory so you can process them
       further from there.
Important
Maildir splitting relies upon filenames being sorted to output
           patches in the correct order."
475,0,git-mailinfo,"Reads a single e-mail message from the standard input, and writes
       the commit log message in <msg> file, and the patches in <patch>
       file. The author name, e-mail and e-mail subject are written out
       to the standard output to be used by
git am
to create a commit. It
       is usually not necessary to use this command directly."
475,1,git-mailinfo,"The author name, e-mail and e-mail subject are written out
       to the standard output to be used by
git am
to create a commit. It
       is usually not necessary to use this command directly. See
git-am(1)
instead."
476,0,git-maintenance,"Run tasks to optimize Git repository data, speeding up other Git
       commands and reducing storage requirements for the repository. Git commands that add repository data, such as
git add
or
git
fetch
, are optimized for a responsive user experience. These
       commands do not take time to optimize the Git data, since such
       optimizations scale with the full size of the repository while
       these user commands each perform a relatively small action."
476,1,git-maintenance,"Git commands that add repository data, such as
git add
or
git
fetch
, are optimized for a responsive user experience. These
       commands do not take time to optimize the Git data, since such
       optimizations scale with the full size of the repository while
       these user commands each perform a relatively small action. The
git maintenance
command provides flexibility for how to
       optimize the Git repository."
477,0,git-merge-base,"git merge-base
finds the best common ancestor(s) between two
       commits to use in a three-way merge. One common ancestor is
better
than another common ancestor if the latter is an ancestor of the
       former. A common ancestor that does not have any better common
       ancestor is a
best common ancestor
, i.e."
477,1,git-merge-base,"A common ancestor that does not have any better common
       ancestor is a
best common ancestor
, i.e. a
merge base
. Note that
       there can be more than one merge base for a pair of commits."
478,0,git-merge-index,"This looks up the <file>(s) in the index and, if there are any
       merge entries, passes the SHA-1 hash for those files as arguments
       1, 2, 3 (empty argument if no file), and <file> as argument 4.
       File modes for the three files are passed as arguments 5, 6 and 7."
479,0,git-merge-file,"Given three files
<current>
,
<base>
and
<other>
,
git merge-file
incorporates all changes that lead from
<base>
to
<other>
into
<current>
. The result ordinarily goes into
<current>
. git
merge-file
is useful for combining separate changes to an
       original."
479,1,git-merge-file,"git
merge-file
is useful for combining separate changes to an
       original. Suppose
<base>
is the original, and both
<current>
and
<other>
are modifications of
<base>
, then
git merge-file
combines
       both changes. A conflict occurs if both
<current>
and
<other>
have changes in a
       common segment of lines."
479,2,git-merge-file,"A conflict occurs if both
<current>
and
<other>
have changes in a
       common segment of lines. If a conflict is found,
git merge-file
normally outputs a warning and brackets the conflict with lines
       containing <<<<<<< and >>>>>>> markers. A typical conflict will
       look like this:

           <<<<<<< A
           lines in file A
           =======
           lines in file B
           >>>>>>> B

       If there are conflicts, the user should edit the result and delete
       one of the alternatives."
479,3,git-merge-file,"A typical conflict will
       look like this:

           <<<<<<< A
           lines in file A
           =======
           lines in file B
           >>>>>>> B

       If there are conflicts, the user should edit the result and delete
       one of the alternatives. When
--ours
,
--theirs
, or
--union
option
       is in effect, however, these conflicts are resolved favouring
       lines from
<current>
, lines from
<other>
, or lines from both
       respectively. The length of the conflict markers can be given with
       the
--marker-size
option."
479,4,git-merge-file,"The length of the conflict markers can be given with
       the
--marker-size
option. If
--object-id
is specified, exactly the same behavior occurs,
       except that instead of specifying what to merge as files, it is
       specified as a list of object IDs referring to blobs. The exit value of this program is negative on error, and the
       number of conflicts otherwise (truncated to 127 if there are more
       than that many conflicts)."
479,5,git-merge-file,"The exit value of this program is negative on error, and the
       number of conflicts otherwise (truncated to 127 if there are more
       than that many conflicts). If the merge was clean, the exit value
       is 0. git merge-file
is designed to be a minimal clone of RCS
merge
;
       that is, it implements all of RCS
merge
's functionality which is
       needed by
git(1)
."
480,0,git-log,"Shows the commit logs. List commits that are reachable by following the
parent
links from
       the given commit(s), but exclude commits that are reachable from
       the one(s) given with a
^
in front of them. The output is given in
       reverse chronological order by default."
480,1,git-log,"The output is given in
       reverse chronological order by default. You can think of this as a set operation. Commits reachable from
       any of the commits given on the command line form a set, and then
       commits reachable from any of the ones given with
^
in front are
       subtracted from that set."
480,2,git-log,"Commits reachable from
       any of the commits given on the command line form a set, and then
       commits reachable from any of the ones given with
^
in front are
       subtracted from that set. The remaining commits are what comes out
       in the commandâs output. Various other options and paths
       parameters can be used to further limit the result."
480,3,git-log,"Various other options and paths
       parameters can be used to further limit the result. Thus, the following command:

           $ git log foo bar ^baz

       means ""list all the commits which are reachable from
foo
or
bar
,
       but not from
baz
"". A special notation ""
<commit1>
.."
480,4,git-log,"A special notation ""
<commit1>
.. <commit2>
"" can be used as a
       short-hand for ""^
<commit1> <commit2>
"". For example, either of the
       following may be used interchangeably:

           $ git log origin..HEAD
           $ git log HEAD ^origin

       Another special notation is ""
<commit1>
..."
480,5,git-log,"For example, either of the
       following may be used interchangeably:

           $ git log origin..HEAD
           $ git log HEAD ^origin

       Another special notation is ""
<commit1>
... <commit2>
"" which is
       useful for merges. The resulting set of commits is the symmetric
       difference between the two operands."
480,6,git-log,"<commit2>
"" which is
       useful for merges. The resulting set of commits is the symmetric
       difference between the two operands. The following two commands
       are equivalent:

           $ git log A B --not $(git merge-base --all A B)
           $ git log A...B

       The command takes options applicable to the
git-rev-list(1)
command to control what is shown and how, and options applicable
       to the
git-diff(1)
command to control how the changes each commit
       introduces are shown."
481,0,git-merge-tree,"This command has a modern
--write-tree
mode and a deprecated
--trivial-merge
mode. With the exception of the DEPRECATED
       DESCRIPTION section at the end, the rest of this documentation
       describes the modern
--write-tree
mode. Performs a merge, but does not make any new commits and does not
       read from or write to either the working tree or index."
481,1,git-merge-tree,"Performs a merge, but does not make any new commits and does not
       read from or write to either the working tree or index. The performed merge will use the same features as the ""real""
git-merge(1)
, including:

       â¢   three way content merges of individual files

       â¢   rename detection

       â¢   proper directory/file conflict handling

       â¢   recursive ancestor consolidation (i.e. when there is more than
           one merge base, creating a virtual merge base by merging the
           merge bases)

       â¢   etc."
481,2,git-merge-tree,"when there is more than
           one merge base, creating a virtual merge base by merging the
           merge bases)

       â¢   etc. After the merge completes, a new toplevel tree object is created. See
OUTPUT
below for details."
482,0,git-merge-one-file,"This is the standard helper program to use with
git merge-index
to
       resolve a merge after the trivial merge done with
git read-tree
-m
."
483,0,git-merge,"Incorporates changes from the named commits (since the time their
       histories diverged from the current branch) into the current
       branch. This command is used by
git pull
to incorporate changes
       from another repository and can be used by hand to merge changes
       from one branch into another. Assume the following history exists and the current branch is
master
:

                     A---B---C topic
                    /
               D---E---F---G master

       Then
git merge topic
will replay the changes made on the
topic
branch since it diverged from
master
(i.e.,
E
) until its current
       commit (
C
) on top of
master
, and record the result in a new commit
       along with the names of the two parent commits and a log message
       from the user describing the changes."
483,1,git-merge,"Assume the following history exists and the current branch is
master
:

                     A---B---C topic
                    /
               D---E---F---G master

       Then
git merge topic
will replay the changes made on the
topic
branch since it diverged from
master
(i.e.,
E
) until its current
       commit (
C
) on top of
master
, and record the result in a new commit
       along with the names of the two parent commits and a log message
       from the user describing the changes. Before the operation,
ORIG_HEAD
is set to the tip of the current branch (
C
). A---B---C topic
                    /         \
               D---E---F---G---H master

       A merge stops if thereâs a conflict that cannot be resolved
       automatically or if
--no-commit
was provided when initiating the
       merge."
483,2,git-merge,"A---B---C topic
                    /         \
               D---E---F---G---H master

       A merge stops if thereâs a conflict that cannot be resolved
       automatically or if
--no-commit
was provided when initiating the
       merge. At that point you can run
git merge --abort
or
git merge
--continue
. git merge --abort
will abort the merge process and try to
       reconstruct the pre-merge state."
483,3,git-merge,"git merge --abort
will abort the merge process and try to
       reconstruct the pre-merge state. However, if there were
       uncommitted changes when the merge started (and especially if
       those changes were further modified after the merge was started),
git merge --abort
will in some cases be unable to reconstruct the
       original (pre-merge) changes. Therefore:
Warning
: Running
git merge
with non-trivial uncommitted changes is
       discouraged: while possible, it may leave you in a state that is
       hard to back out of in the case of a conflict."
484,0,git-mergetool--lib,"This is not a command the end user would want to run. Ever. This
       documentation is meant for people who are studying the
       Porcelain-ish scripts and/or are writing new ones."
484,1,git-mergetool--lib,"This
       documentation is meant for people who are studying the
       Porcelain-ish scripts and/or are writing new ones. The
git-mergetool--lib
scriptlet is designed to be sourced (using
       .) by other shell scripts to set up functions for working with Git
       merge tools. Before sourcing
git-mergetool--lib
, your script must set
TOOL_MODE
to define the operation mode for the functions listed below."
484,2,git-mergetool--lib,"The
git-mergetool--lib
scriptlet is designed to be sourced (using
       .) by other shell scripts to set up functions for working with Git
       merge tools. Before sourcing
git-mergetool--lib
, your script must set
TOOL_MODE
to define the operation mode for the functions listed below. diff
and
merge
are valid values."
485,0,git-mergetool,"Use
git mergetool
to run one of several merge utilities to resolve
       merge conflicts. It is typically run after
git merge
. If one or more <file> parameters are given, the merge tool program
       will be run to resolve differences in each file (skipping those
       without conflicts)."
485,1,git-mergetool,"If one or more <file> parameters are given, the merge tool program
       will be run to resolve differences in each file (skipping those
       without conflicts). Specifying a directory will include all
       unresolved files in that path. If no <file> names are specified,
git mergetool
will run the merge tool program on every file with
       merge conflicts."
486,0,git-mktag,"Reads a tagâs contents on standard input and creates a tag object. The output is the new tagâs <object> identifier. This command is mostly equivalent to
git-hash-object(1)
invoked
       with
-t tag -w --stdin
."
486,1,git-mktag,"This command is mostly equivalent to
git-hash-object(1)
invoked
       with
-t tag -w --stdin
. I.e. both of these will create and write a
       tag found in
my-tag
:

           git mktag <my-tag
           git hash-object -t tag -w --stdin <my-tag

       The difference is that mktag will die before writing the tag if
       the tag doesnât pass a
git-fsck(1)
check."
486,2,git-mktag,"both of these will create and write a
       tag found in
my-tag
:

           git mktag <my-tag
           git hash-object -t tag -w --stdin <my-tag

       The difference is that mktag will die before writing the tag if
       the tag doesnât pass a
git-fsck(1)
check. The ""fsck"" check done by mktag is stricter than what
git-fsck(1)
would run by default in that all
fsck. <msg-id>
messages are
       promoted from warnings to errors (so e.g."
486,3,git-mktag,"<msg-id>
messages are
       promoted from warnings to errors (so e.g. a missing ""tagger"" line
       is an error). Extra headers in the object are also an error under mktag, but
       ignored by
git-fsck(1)
."
486,4,git-mktag,"Extra headers in the object are also an error under mktag, but
       ignored by
git-fsck(1)
. This extra check can be turned off by
       setting the appropriate
fsck. <msg-id>
variable:

           git -c fsck.extraHeaderEntry=ignore mktag <my-tag-with-headers"
487,0,git-mv,"Move or rename a file, directory, or symlink. git mv [-v] [-f] [-n] [-k] <source> <destination>
           git mv [-v] [-f] [-n] [-k] <source> ... <destination-directory>

       In the first form, it renames <source>, which must exist and be
       either a file, symlink or directory, to <destination>."
487,1,git-mv,"<destination-directory>

       In the first form, it renames <source>, which must exist and be
       either a file, symlink or directory, to <destination>. In the
       second form, the last argument has to be an existing directory;
       the given sources will be moved into this directory. The index is updated after successful completion, but the change
       must still be committed."
488,0,git-multi-pack-index,Write or verify a multi-pack-index (MIDX) file.
489,0,git-name-rev,"Finds symbolic names suitable for human digestion for revisions
       given in any format parsable by
git rev-parse
."
490,0,git-mktree,"Reads standard input in non-recursive
ls-tree
output format, and
       creates a tree object. The order of the tree entries is normalized
       by mktree so pre-sorting the input is not required. The object
       name of the tree object built is written to the standard output."
491,0,git-notes,"Adds, removes, or reads notes attached to objects, without
       touching the objects themselves. By default, notes are saved to and read from
refs/notes/commits
,
       but this default can be overridden. See the OPTIONS,
       CONFIGURATION, and ENVIRONMENT sections below."
491,1,git-notes,"See the OPTIONS,
       CONFIGURATION, and ENVIRONMENT sections below. If this ref does
       not exist, it will be quietly created when it is first needed to
       store a note. A typical use of notes is to supplement a commit message without
       changing the commit itself."
491,2,git-notes,"A typical use of notes is to supplement a commit message without
       changing the commit itself. Notes can be shown by
git log
along
       with the original commit message. To distinguish these notes from
       the message stored in the commit object, the notes are indented
       like the message, after an unindented line saying ""Notes
       (
<refname>
):"" (or ""Notes:"" for
refs/notes/commits
)."
491,3,git-notes,"To distinguish these notes from
       the message stored in the commit object, the notes are indented
       like the message, after an unindented line saying ""Notes
       (
<refname>
):"" (or ""Notes:"" for
refs/notes/commits
). Notes can also be added to patches prepared with
git format-patch
by using the
--notes
option. Such notes are added as a patch
       commentary after a three dash separator line."
491,4,git-notes,"Such notes are added as a patch
       commentary after a three dash separator line. To change which notes are shown by
git log
, see the
notes.displayRef
discussion in CONFIGURATION. See the
notes.rewrite."
491,5,git-notes,"To change which notes are shown by
git log
, see the
notes.displayRef
discussion in CONFIGURATION. See the
notes.rewrite. <command>
configuration for a way to carry
       notes across commands that rewrite commits."
492,0,git-pack-redundant,"This program computes which packs in your repository are
       redundant. The output is suitable for piping to
xargs rm
if you
       are in the root of the repository. git pack-redundant
accepts a list of objects on standard input."
492,1,git-pack-redundant,"git pack-redundant
accepts a list of objects on standard input. Any objects given will be ignored when checking which packs are
       required. This makes the following command useful when wanting to
       remove packs which contain unreachable objects."
492,2,git-pack-redundant,"Any objects given will be ignored when checking which packs are
       required. This makes the following command useful when wanting to
       remove packs which contain unreachable objects. git fsck --full --unreachable | cut -d ' ' -f3 | \ git
       pack-redundant --all | xargs rm"
493,0,git-pack-objects,"Reads list of objects from the standard input, and writes either
       one or more packed archives with the specified base-name to disk,
       or a packed archive to the standard output. A packed archive is an efficient way to transfer a set of objects
       between two repositories as well as an access efficient archival
       format. In a packed archive, an object is either stored as a
       compressed whole or as a difference from some other object."
493,1,git-pack-objects,"In a packed archive, an object is either stored as a
       compressed whole or as a difference from some other object. The
       latter is often called a delta. The packed archive format (.pack) is designed to be self-contained
       so that it can be unpacked without any further information."
493,2,git-pack-objects,"The packed archive format (.pack) is designed to be self-contained
       so that it can be unpacked without any further information. Therefore, each object that a delta depends upon must be present
       within the pack. A pack index file (.idx) is generated for fast, random access to
       the objects in the pack."
493,3,git-pack-objects,"A pack index file (.idx) is generated for fast, random access to
       the objects in the pack. Placing both the index file (.idx) and
       the packed archive (.pack) in the pack/ subdirectory of
       $GIT_OBJECT_DIRECTORY (or any of the directories on
       $GIT_ALTERNATE_OBJECT_DIRECTORIES) enables Git to read from the
       pack archive. The
git unpack-objects
command can read the packed archive and
       expand the objects contained in the pack into ""one-file
       one-object"" format; this is typically done by the smart-pull
       commands when a pack is created on-the-fly for efficient network
       transport by their peers."
494,0,git-p4,"This command provides a way to interact with p4 repositories using
       Git. Create a new Git repository from an existing p4 repository using
git p4 clone
, giving it one or more p4 depot paths. Incorporate
       new commits from p4 changes with
git p4 sync
."
494,1,git-p4,"Incorporate
       new commits from p4 changes with
git p4 sync
. The
sync
command is
       also used to include new branches from other p4 depot paths. Submit Git changes back to p4 using
git p4 submit
."
494,2,git-p4,"The
sync
command is
       also used to include new branches from other p4 depot paths. Submit Git changes back to p4 using
git p4 submit
. The command
git
p4 rebase
does a sync plus rebases the current branch onto the
       updated p4 remote branch."
495,0,git-pack-refs,"Traditionally, tips of branches and tags (collectively known as
refs
) were stored one file per ref in a (sub)directory under
$GIT_DIR/refs
directory. While many branch tips tend to be updated
       often, most tags and some branch tips are never updated. When a
       repository has hundreds or thousands of tags, this
       one-file-per-ref format both wastes storage and hurts performance."
495,1,git-pack-refs,"When a
       repository has hundreds or thousands of tags, this
       one-file-per-ref format both wastes storage and hurts performance. This command is used to solve the storage and performance problem
       by storing the refs in a single file,
$GIT_DIR/packed-refs
. When a
       ref is missing from the traditional
$GIT_DIR/refs
directory
       hierarchy, it is looked up in this file and used if found."
495,2,git-pack-refs,"When a
       ref is missing from the traditional
$GIT_DIR/refs
directory
       hierarchy, it is looked up in this file and used if found. Subsequent updates to branches always create new files under
$GIT_DIR/refs
directory hierarchy. A recommended practice to deal with a repository with too many
       refs is to pack its refs with
--all
once, and occasionally run
git
pack-refs
."
495,3,git-pack-refs,"A recommended practice to deal with a repository with too many
       refs is to pack its refs with
--all
once, and occasionally run
git
pack-refs
. Tags are by definition stationary and are not expected
       to change. Branch heads will be packed with the initial
pack-refs
--all
, but only the currently active branch heads will become
       unpacked, and the next
pack-refs
(without
--all
) will leave them
       unpacked."
496,0,git-patch-id,"Read a patch from the standard input and compute the patch ID for
       it. A ""patch ID"" is nothing but a sum of SHA-1 of the file diffs
       associated with a patch, with line numbers ignored. As such, itâs
       ""reasonably stable"", but at the same time also reasonably unique,
       i.e., two patches that have the same ""patch ID"" are almost
       guaranteed to be the same thing."
496,1,git-patch-id,"As such, itâs
       ""reasonably stable"", but at the same time also reasonably unique,
       i.e., two patches that have the same ""patch ID"" are almost
       guaranteed to be the same thing. The main usecase for this command is to look for likely duplicate
       commits. When dealing with
git diff-tree
output, it takes advantage of the
       fact that the patch is prefixed with the object name of the
       commit, and outputs two 40-byte hexadecimal strings."
496,2,git-patch-id,"When dealing with
git diff-tree
output, it takes advantage of the
       fact that the patch is prefixed with the object name of the
       commit, and outputs two 40-byte hexadecimal strings. The first
       string is the patch ID, and the second string is the commit ID. This can be used to make a mapping from patch ID to commit ID."
497,0,git-prune-packed,"This program searches the
$GIT_OBJECT_DIRECTORY
for all objects
       that currently exist in a pack file as well as in the independent
       object directories. All such extra objects are removed. A pack is a collection of objects, individually compressed, with
       delta compression applied, stored in a single file, with an
       associated index file."
497,1,git-prune-packed,"All such extra objects are removed. A pack is a collection of objects, individually compressed, with
       delta compression applied, stored in a single file, with an
       associated index file. Packs are used to reduce the load on mirror systems, backup
       engines, disk storage, etc."
498,0,git-prune,"Note
In most cases, users should run
git gc
, which calls
git prune
. See the section ""NOTES"", below. This runs
git fsck --unreachable
using all the refs available in
refs/
, optionally with an additional set of objects specified on
       the command line, and prunes all unpacked objects unreachable from
       any of these head objects from the object database."
498,1,git-prune,"This runs
git fsck --unreachable
using all the refs available in
refs/
, optionally with an additional set of objects specified on
       the command line, and prunes all unpacked objects unreachable from
       any of these head objects from the object database. In addition,
       it prunes the unpacked objects that are also found in packs by
       running
git prune-packed
. It also removes entries from
       .git/shallow that are not reachable by any ref."
498,2,git-prune,"It also removes entries from
       .git/shallow that are not reachable by any ref. Note that unreachable, packed objects will remain. If this is not
       desired, see
git-repack(1)
."
499,0,git-quiltimport,"Applies a quilt patchset onto the current Git branch, preserving
       the patch boundaries, patch order, and patch descriptions present
       in the quilt patchset. For each patch the code attempts to extract the author from the
       patch description. If that fails it falls back to the author
       specified with --author."
499,1,git-quiltimport,"If that fails it falls back to the author
       specified with --author. If the --author flag was not given the
       patch description is displayed and the user is asked to
       interactively enter the author of the patch. If a subject is not found in the patch description the patch name
       is preserved as the 1 line subject in the Git description."
500,0,git-pull,"Incorporates changes from a remote repository into the current
       branch. If the current branch is behind the remote, then by
       default it will fast-forward the current branch to match the
       remote. If the current branch and the remote have diverged, the
       user needs to specify how to reconcile the divergent branches with
--rebase
or
--no-rebase
(or the corresponding configuration option
       in
pull.rebase
)."
500,1,git-pull,"If the current branch and the remote have diverged, the
       user needs to specify how to reconcile the divergent branches with
--rebase
or
--no-rebase
(or the corresponding configuration option
       in
pull.rebase
). More precisely,
git pull
runs
git fetch
with the given parameters
       and then depending on configuration options or command line flags,
       will call either
git rebase
or
git merge
to reconcile diverging
       branches. <repository> should be the name of a remote repository as passed
       to
git-fetch(1)
."
500,2,git-pull,"<repository> should be the name of a remote repository as passed
       to
git-fetch(1)
. <refspec> can name an arbitrary remote ref (for
       example, the name of a tag) or even a collection of refs with
       corresponding remote-tracking branches (e.g.,
       refs/heads/*:refs/remotes/origin/*), but usually it is the name of
       a branch in the remote repository. Default values for <repository> and <branch> are read from the
       ""remote"" and ""merge"" configuration for the current branch as set
       by
git-branch(1)
--track
."
500,3,git-pull,"Default values for <repository> and <branch> are read from the
       ""remote"" and ""merge"" configuration for the current branch as set
       by
git-branch(1)
--track
. Assume the following history exists and the current branch is
       ""
master
"":

                     A---B---C master on origin
                    /
               D---E---F---G master
                   ^
                   origin/master in your repository

       Then ""
git pull
"" will fetch and replay the changes from the remote
master
branch since it diverged from the local
master
(i.e.,
E
)
       until its current commit (
C
) on top of
master
and record the
       result in a new commit along with the names of the two parent
       commits and a log message from the user describing the changes. A---B---C origin/master
                    /         \
               D---E---F---G---H master

       See
git-merge(1)
for details, including how conflicts are
       presented and handled."
500,4,git-pull,"A---B---C origin/master
                    /         \
               D---E---F---G---H master

       See
git-merge(1)
for details, including how conflicts are
       presented and handled. In Git 1.7.0 or later, to cancel a conflicting merge, use
git
reset --merge
. Warning
: In older versions of Git, running
git pull
with uncommitted changes is discouraged: while possible, it leaves
       you in a state that may be hard to back out of in the case of a
       conflict."
500,5,git-pull,"Warning
: In older versions of Git, running
git pull
with uncommitted changes is discouraged: while possible, it leaves
       you in a state that may be hard to back out of in the case of a
       conflict. If any of the remote changes overlap with local uncommitted
       changes, the merge will be automatically canceled and the work
       tree untouched. It is generally best to get any local changes in
       working order before pulling or stash them away with
git-stash(1)
."
501,0,git-push,"Updates remote refs using local refs, while sending objects
       necessary to complete the given refs. You can make interesting things happen to a repository every time
       you push into it, by setting up
hooks
there. See documentation for
git-receive-pack(1)
."
501,1,git-push,"See documentation for
git-receive-pack(1)
. When the command line does not specify where to push with the
<repository>
argument,
branch. *.remote configuration for the
       current branch is consulted to determine where to push."
501,2,git-push,"*.remote configuration for the
       current branch is consulted to determine where to push. If the
       configuration is missing, it defaults to
origin
. When the command line does not specify what to push with
<refspec>
..."
501,3,git-push,"When the command line does not specify what to push with
<refspec>
... arguments or
--all
,
--mirror
,
--tags
options, the
       command finds the default
<refspec>
by consulting
remote. *.push
       configuration, and if it is not found, honors
push.default
configuration to decide what to push (See
git-config(1)
for the
       meaning of
push.default
)."
501,4,git-push,"arguments or
--all
,
--mirror
,
--tags
options, the
       command finds the default
<refspec>
by consulting
remote. *.push
       configuration, and if it is not found, honors
push.default
configuration to decide what to push (See
git-config(1)
for the
       meaning of
push.default
). When neither the command-line nor the configuration specifies what
       to push, the default behavior is used, which corresponds to the
simple
value for
push.default
: the current branch is pushed to the
       corresponding upstream branch, but as a safety measure, the push
       is aborted if the upstream branch does not have the same name as
       the local one."
502,0,git-range-diff,"This command shows the differences between two versions of a patch
       series, or more generally, two commit ranges (ignoring merge
       commits). In the presence of
<path>
arguments, these commit ranges are
       limited accordingly. To that end, it first finds pairs of commits from both commit
       ranges that correspond with each other."
502,1,git-range-diff,"To that end, it first finds pairs of commits from both commit
       ranges that correspond with each other. Two commits are said to
       correspond when the diff between their patches (i.e. the author
       information, the commit message and the commit diff) is reasonably
       small compared to the patches' size."
502,2,git-range-diff,"the author
       information, the commit message and the commit diff) is reasonably
       small compared to the patches' size. See ``Algorithm`` below for
       details. Finally, the list of matching commits is shown in the order of the
       second commit range, with unmatched commits being inserted just
       after all of their ancestors have been shown."
502,3,git-range-diff,"Finally, the list of matching commits is shown in the order of the
       second commit range, with unmatched commits being inserted just
       after all of their ancestors have been shown. There are three ways to specify the commit ranges:

       â¢
<range1> <range2>
: Either commit range can be of the form
<base>
.. <rev>
,
<rev>
^
!"
502,4,git-range-diff,"<rev>
,
<rev>
^
! or
<rev>
^-
<n>
. See
SPECIFYING RANGES
in
gitrevisions(7)
for more details."
502,5,git-range-diff,"See
SPECIFYING RANGES
in
gitrevisions(7)
for more details. â¢
<rev1>
... <rev2>
."
502,6,git-range-diff,"<rev2>
. This is equivalent to
<rev2>
.. <rev1>
<rev1>
.."
502,7,git-range-diff,"<rev1>
<rev1>
.. <rev2>
. â¢
<base> <rev1> <rev2>
: This is equivalent to
<base>
.."
502,8,git-range-diff,"â¢
<base> <rev1> <rev2>
: This is equivalent to
<base>
.. <rev1>
<base>
.. <rev2>
."
503,0,git-read-tree,"Reads the tree information given by <tree-ish> into the index, but
       does not actually
update
any of the files it ""caches"". (see:
git-checkout-index(1)
)

       Optionally, it can merge a tree into the index, perform a
       fast-forward (i.e. 2-way) merge, or a 3-way merge, with the
-m
flag."
503,1,git-read-tree,"2-way) merge, or a 3-way merge, with the
-m
flag. When used with
-m
, the
-u
flag causes it to also update the
       files in the work tree with the result of the merge. Only trivial merges are done by
git read-tree
itself."
503,2,git-read-tree,"When used with
-m
, the
-u
flag causes it to also update the
       files in the work tree with the result of the merge. Only trivial merges are done by
git read-tree
itself. Only
       conflicting paths will be in an unmerged state when
git read-tree
returns."
504,0,git-receive-pack,"Invoked by
git send-pack
and updates the repository with the
       information fed from the remote end. This command is usually not invoked directly by the end user. The
       UI for the protocol is on the
git send-pack
side, and the program
       pair is meant to be used to push updates to a remote repository."
504,1,git-receive-pack,"The
       UI for the protocol is on the
git send-pack
side, and the program
       pair is meant to be used to push updates to a remote repository. For pull operations, see
git-fetch-pack(1)
. The command allows for the creation and fast-forwarding of sha1
       refs (heads/tags) on the remote end (strictly speaking, it is the
       local end
git-receive-pack
runs, but to the user who is sitting at
       the send-pack end, it is updating the remote."
504,2,git-receive-pack,"The command allows for the creation and fast-forwarding of sha1
       refs (heads/tags) on the remote end (strictly speaking, it is the
       local end
git-receive-pack
runs, but to the user who is sitting at
       the send-pack end, it is updating the remote. Confused?)

       There are other real-world examples of using update and
       post-update hooks found in the Documentation/howto directory. git-receive-pack
honours the receive.denyNonFastForwards config
       option, which tells it if updates to a ref should be denied if
       they are not fast-forwards."
504,3,git-receive-pack,"Confused?)

       There are other real-world examples of using update and
       post-update hooks found in the Documentation/howto directory. git-receive-pack
honours the receive.denyNonFastForwards config
       option, which tells it if updates to a ref should be denied if
       they are not fast-forwards. A number of other receive.* config options are available to tweak
       its behavior, see
git-config(1)
."
505,0,git-rebase,"If
<branch>
is specified,
git rebase
will perform an automatic
git
switch
<branch>
before doing anything else. Otherwise it remains
       on the current branch. If
<upstream>
is not specified, the upstream configured in
branch."
505,1,git-rebase,"If
<upstream>
is not specified, the upstream configured in
branch. <name>
.remote
and
branch. <name>
.merge
options will be used
       (see
git-config(1)
for details) and the
--fork-point
option is
       assumed."
505,2,git-rebase,"<name>
.merge
options will be used
       (see
git-config(1)
for details) and the
--fork-point
option is
       assumed. If you are currently not on any branch or if the current
       branch does not have a configured upstream, the rebase will abort. All changes made by commits in the current branch but that are not
       in
<upstream>
are saved to a temporary area."
505,3,git-rebase,"All changes made by commits in the current branch but that are not
       in
<upstream>
are saved to a temporary area. This is the same set
       of commits that would be shown by
git log
<upstream>
..HEAD
; or by
git log
'fork_point'
..HEAD
, if
--fork-point
is active (see the
       description on
--fork-point
below); or by
git log HEAD
, if the
--root
option is specified. The current branch is reset to
<upstream>
or
<newbase>
if the
--onto
option was supplied."
505,4,git-rebase,"The current branch is reset to
<upstream>
or
<newbase>
if the
--onto
option was supplied. This has the exact same effect as
git
reset --hard
<upstream>
(or
<newbase>
). ORIG_HEAD
is set to point
       at the tip of the branch before the reset."
505,5,git-rebase,"ORIG_HEAD
is set to point
       at the tip of the branch before the reset. Note
ORIG_HEAD
is not guaranteed to still point to the previous
           branch tip at the end of the rebase if other commands that
           write that pseudo-ref (e.g. git reset
) are used during the
           rebase."
505,6,git-rebase,"git reset
) are used during the
           rebase. The previous branch tip, however, is accessible using
           the reflog of the current branch (i.e. @
{1}, see
gitrevisions(7)
)."
505,7,git-rebase,"@
{1}, see
gitrevisions(7)
). The commits that were previously saved into the temporary area are
       then reapplied to the current branch, one by one, in order. Note
       that any commits in
HEAD
which introduce the same textual changes
       as a commit in
HEAD.."
505,8,git-rebase,"Note
       that any commits in
HEAD
which introduce the same textual changes
       as a commit in
HEAD.. <upstream>
are omitted (i.e., a patch already
       accepted upstream with a different commit message or timestamp
       will be skipped). It is possible that a merge failure will prevent this process from
       being completely automatic."
505,9,git-rebase,"It is possible that a merge failure will prevent this process from
       being completely automatic. You will have to resolve any such
       merge failure and run
git rebase --continue
. Another option is to
       bypass the commit that caused the merge failure with
git rebase
--skip
."
505,10,git-rebase,"Another option is to
       bypass the commit that caused the merge failure with
git rebase
--skip
. To check out the original
<branch>
and remove the
.git/rebase-apply
working files, use the command
git rebase
--abort
instead. Assume the following history exists and the current branch is
       ""topic"":

                     A---B---C topic
                    /
               D---E---F---G master

       From this point, the result of either of the following commands:

           git rebase master
           git rebase master topic

       would be:

                             A'--B'--C' topic
                            /
               D---E---F---G master
NOTE:
The latter form is just a short-hand of
git checkout topic
followed by
git rebase master
."
505,11,git-rebase,"Assume the following history exists and the current branch is
       ""topic"":

                     A---B---C topic
                    /
               D---E---F---G master

       From this point, the result of either of the following commands:

           git rebase master
           git rebase master topic

       would be:

                             A'--B'--C' topic
                            /
               D---E---F---G master
NOTE:
The latter form is just a short-hand of
git checkout topic
followed by
git rebase master
. When rebase exits
topic
will remain
       the checked-out branch. If the upstream branch already contains a change you have made
       (e.g., because you mailed a patch which was applied upstream),
       then that commit will be skipped and warnings will be issued (if
       the
merge
backend is used)."
505,12,git-rebase,"If the upstream branch already contains a change you have made
       (e.g., because you mailed a patch which was applied upstream),
       then that commit will be skipped and warnings will be issued (if
       the
merge
backend is used). For example, running
git rebase master
on the following history (in which
A
' and
A
introduce the same set
       of changes, but have different committer information):

                     A---B---C topic
                    /
               D---E---A'---F master

       will result in:

                              B'---C' topic
                             /
               D---E---A'---F master

       Here is how you would transplant a topic branch based on one
       branch to another, to pretend that you forked the topic branch
       from the latter branch, using
rebase --onto
. First letâs assume your
topic
is based on branch
next
."
505,13,git-rebase,"First letâs assume your
topic
is based on branch
next
. For
       example, a feature developed in
topic
depends on some
       functionality which is found in
next
. o---o---o---o---o  master
                    \
                     o---o---o---o---o  next
                                      \
                                       o---o---o  topic

       We want to make
topic
forked from branch
master
; for example,
       because the functionality on which
topic
depends was merged into
       the more stable
master
branch."
505,14,git-rebase,"o---o---o---o---o  master
                    \
                     o---o---o---o---o  next
                                      \
                                       o---o---o  topic

       We want to make
topic
forked from branch
master
; for example,
       because the functionality on which
topic
depends was merged into
       the more stable
master
branch. We want our tree to look like this:

               o---o---o---o---o  master
                   |            \
                   |             o'--o'--o'  topic
                    \
                     o---o---o---o---o  next

       We can get this using the following command:

           git rebase --onto master next topic

       Another example of --onto option is to rebase part of a branch. If
       we have the following situation:

                                       H---I---J topicB
                                      /
                             E---F---G  topicA
                            /
               A---B---C---D  master

       then the command

           git rebase --onto master topicA topicB

       would result in:

                            H'--I'--J'  topicB
                           /
                           | E---F---G  topicA
                           |/
               A---B---C---D  master

       This is useful when topicB does not depend on topicA."
505,15,git-rebase,"If
       we have the following situation:

                                       H---I---J topicB
                                      /
                             E---F---G  topicA
                            /
               A---B---C---D  master

       then the command

           git rebase --onto master topicA topicB

       would result in:

                            H'--I'--J'  topicB
                           /
                           | E---F---G  topicA
                           |/
               A---B---C---D  master

       This is useful when topicB does not depend on topicA. A range of commits could also be removed with rebase. If we have
       the following situation:

               E---F---G---H---I---J  topicA

       then the command

           git rebase --onto topicA~5 topicA~3 topicA

       would result in the removal of commits F and G:

               E---H'---I'---J'  topicA

       This is useful if F and G were flawed in some way, or should not
       be part of topicA."
505,16,git-rebase,"If we have
       the following situation:

               E---F---G---H---I---J  topicA

       then the command

           git rebase --onto topicA~5 topicA~3 topicA

       would result in the removal of commits F and G:

               E---H'---I'---J'  topicA

       This is useful if F and G were flawed in some way, or should not
       be part of topicA. Note that the argument to
--onto
and the
<upstream>
parameter can be any valid commit-ish. In case of conflict,
git rebase
will stop at the first problematic
       commit and leave conflict markers in the tree."
505,17,git-rebase,"In case of conflict,
git rebase
will stop at the first problematic
       commit and leave conflict markers in the tree. You can use
git
diff
to locate the markers (<<<<<<) and make edits to resolve the
       conflict. For each file you edit, you need to tell Git that the
       conflict has been resolved, typically this would be done with

           git add <filename>

       After resolving the conflict manually and updating the index with
       the desired resolution, you can continue the rebasing process with

           git rebase --continue

       Alternatively, you can undo the
git rebase
with

           git rebase --abort"
506,0,git-refs,This command provides low-level access to refs.
507,0,git-remote-ext,"This remote helper uses the specified
<command>
to connect to a
       remote Git server. Data written to stdin of the specified
<command>
is assumed to be
       sent to a git:// server, git-upload-pack, git-receive-pack or
       git-upload-archive (depending on situation), and data read from
       stdout of <command> is assumed to be received from the same
       service. Command and arguments are separated by an unescaped space."
507,1,git-remote-ext,"Command and arguments are separated by an unescaped space. The following sequences have a special meaning:

       '% '
           Literal space in command or argument. %%
Literal percent sign."
507,2,git-remote-ext,"%%
Literal percent sign. %s
Replaced with name (receive-pack, upload-pack, or
           upload-archive) of the service Git wants to invoke. %S
Replaced with long name (git-receive-pack, git-upload-pack, or
           git-upload-archive) of the service Git wants to invoke."
507,3,git-remote-ext,"%S
Replaced with long name (git-receive-pack, git-upload-pack, or
           git-upload-archive) of the service Git wants to invoke. %G
(must be the first characters in an argument)
           This argument will not be passed to
<command>
. Instead, it
           will cause the helper to start by sending git:// service
           requests to the remote side with the service field set to an
           appropriate value and the repository field set to the rest of
           the argument."
507,4,git-remote-ext,"Instead, it
           will cause the helper to start by sending git:// service
           requests to the remote side with the service field set to an
           appropriate value and the repository field set to the rest of
           the argument. Default is not to send such a request. This is useful if the remote side is git:// server accessed
           over some tunnel."
507,5,git-remote-ext,"This is useful if the remote side is git:// server accessed
           over some tunnel. %V
(must be first characters in argument)
           This argument will not be passed to
<command>
. Instead it sets
           the vhost field in the git:// service request (to the rest of
           the argument)."
507,6,git-remote-ext,"%V
(must be first characters in argument)
           This argument will not be passed to
<command>
. Instead it sets
           the vhost field in the git:// service request (to the rest of
           the argument). Default is not to send vhost in such request
           (if sent)."
508,0,git-reflog,"This command manages the information recorded in the reflogs. Reference logs, or ""reflogs"", record when the tips of branches and
       other references were updated in the local repository. Reflogs are
       useful in various Git commands, to specify the old value of a
       reference."
508,1,git-reflog,"Reflogs are
       useful in various Git commands, to specify the old value of a
       reference. For example,
HEAD@
{2} means ""where HEAD used to be two
       moves ago"",
master@
{one.week.ago} means ""where master used to
       point to one week ago in this local repository"", and so on. See
gitrevisions(7)
for more details."
508,2,git-reflog,"See
gitrevisions(7)
for more details. The command takes various subcommands, and different options
       depending on the subcommand:

       The ""show"" subcommand (which is also the default, in the absence
       of any subcommands) shows the log of the reference provided in the
       command-line (or
HEAD
, by default). The reflog covers all recent
       actions, and in addition the
HEAD
reflog records branch switching."
508,3,git-reflog,"The reflog covers all recent
       actions, and in addition the
HEAD
reflog records branch switching. git reflog show
is an alias for
git log -g --abbrev-commit
--pretty=oneline
; see
git-log(1)
for more information. The ""list"" subcommand lists all refs which have a corresponding
       reflog."
508,4,git-reflog,"The ""list"" subcommand lists all refs which have a corresponding
       reflog. The ""expire"" subcommand prunes older reflog entries. Entries older
       than
expire
time, or entries older than
expire-unreachable
time
       and not reachable from the current tip, are removed from the
       reflog."
508,5,git-reflog,"Entries older
       than
expire
time, or entries older than
expire-unreachable
time
       and not reachable from the current tip, are removed from the
       reflog. This is typically not used directly by end users â
       instead, see
git-gc(1)
. The ""delete"" subcommand deletes single entries from the reflog."
508,6,git-reflog,"The ""delete"" subcommand deletes single entries from the reflog. Its argument must be an
exact
entry (e.g. ""
git reflog delete
master@
{2}"")."
508,7,git-reflog,"""
git reflog delete
master@
{2}""). This subcommand is also typically not used directly
       by end users. The ""exists"" subcommand checks whether a ref has a reflog."
508,8,git-reflog,"This subcommand is also typically not used directly
       by end users. The ""exists"" subcommand checks whether a ref has a reflog. It
       exits with zero status if the reflog exists, and non-zero status
       if it does not."
509,0,git-remote-fd,"This helper uses specified file descriptors to connect to a remote
       Git server. This is not meant for end users but for programs and
       scripts calling git fetch, push, or archive. If only <infd> is given, it is assumed to be a bidirectional
       socket connected to a remote Git server (git-upload-pack,
       git-receive-pack, or git-upload-archive)."
509,1,git-remote-fd,"If only <infd> is given, it is assumed to be a bidirectional
       socket connected to a remote Git server (git-upload-pack,
       git-receive-pack, or git-upload-archive). If both <infd> and
       <outfd> are given, they are assumed to be pipes connected to a
       remote Git server (<infd> being the inbound pipe and <outfd> being
       the outbound pipe). It is assumed that any handshaking procedures have already been
       completed (such as sending service request for git://) before this
       helper is started."
509,2,git-remote-fd,"It is assumed that any handshaking procedures have already been
       completed (such as sending service request for git://) before this
       helper is started. <anything> can be any string. It is ignored."
509,3,git-remote-fd,"<anything> can be any string. It is ignored. It is meant for
       providing information to the user in the URL in case that URL is
       displayed in some context."
510,0,git-repack,"This command is used to combine all objects that do not currently
       reside in a ""pack"", into a pack. It can also be used to
       re-organize existing packs into a single, more efficient pack. A pack is a collection of objects, individually compressed, with
       delta compression applied, stored in a single file, with an
       associated index file."
510,1,git-repack,"It can also be used to
       re-organize existing packs into a single, more efficient pack. A pack is a collection of objects, individually compressed, with
       delta compression applied, stored in a single file, with an
       associated index file. Packs are used to reduce the load on mirror systems, backup
       engines, disk storage, etc."
511,0,git-remote,"Manage the set of repositories (""remotes"") whose branches you
       track."
512,0,git-replace,"Adds a
replace
reference in
refs/replace/
namespace. The name of the
replace
reference is the SHA-1 of the object that
       is replaced. The content of the
replace
reference is the SHA-1 of
       the replacement object."
512,1,git-replace,"The content of the
replace
reference is the SHA-1 of
       the replacement object. The replaced object and the replacement object must be of the same
       type. This restriction can be bypassed using
-f
."
512,2,git-replace,"This restriction can be bypassed using
-f
. Unless
-f
is given, the
replace
reference must not yet exist. There is no other restriction on the replaced and replacement
       objects."
512,3,git-replace,"There is no other restriction on the replaced and replacement
       objects. Merge commits can be replaced by non-merge commits and
       vice versa. Replacement references will be used by default by all Git commands
       except those doing reachability traversal (prune, pack transfer
       and fsck)."
512,4,git-replace,"Replacement references will be used by default by all Git commands
       except those doing reachability traversal (prune, pack transfer
       and fsck). It is possible to disable the use of replacement references for
       any command using the
--no-replace-objects
option just after
git
. For example if commit
foo
has been replaced by commit
bar
:

           $ git --no-replace-objects cat-file commit foo

       shows information about commit
foo
, while:

           $ git cat-file commit foo

       shows information about commit
bar
."
512,5,git-replace,"It is possible to disable the use of replacement references for
       any command using the
--no-replace-objects
option just after
git
. For example if commit
foo
has been replaced by commit
bar
:

           $ git --no-replace-objects cat-file commit foo

       shows information about commit
foo
, while:

           $ git cat-file commit foo

       shows information about commit
bar
. The
GIT_NO_REPLACE_OBJECTS
environment variable can be set to
       achieve the same effect as the
--no-replace-objects
option."
513,0,git-request-pull,"Generate a request asking your upstream project to pull changes
       into their tree. The request, printed to the standard output,
       begins with the branch description, summarizes the changes, and
       indicates from where they can be pulled.

       The upstream project is expected to have the commit named by
<start>
and the output asks it to integrate the changes you made
       since that commit, up to the commit named by
<end>
, by visiting
       the repository named by
<URL>
."
514,0,git-replay,"Takes ranges of commits and replays them onto a new location. Leaves the working tree and the index untouched, and updates no
       references. The output of this command is meant to be used as
       input to
git update-ref --stdin
, which would update the relevant
       branches (see the OUTPUT section below)."
514,1,git-replay,"The output of this command is meant to be used as
       input to
git update-ref --stdin
, which would update the relevant
       branches (see the OUTPUT section below). THIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE."
515,0,git-rerere,"In a workflow employing relatively long lived topic branches, the
       developer sometimes needs to resolve the same conflicts over and
       over again until the topic branches are done (either merged to the
       ""release"" branch, or sent out and accepted upstream).

       This command assists the developer in this process by recording
       conflicted automerge results and corresponding hand resolve
       results on the initial manual merge, and applying previously
       recorded hand resolutions to their corresponding automerge
       results.
Note
You need to set the configuration variable
rerere.enabled
in
           order to enable this command."
516,0,git-restore,"Restore specified paths in the working tree with some contents
       from a restore source. If a path is tracked but does not exist in
       the restore source, it will be removed to match the source. The command can also be used to restore the content in the index
       with
--staged
, or restore both the working tree and the index with
--staged --worktree
."
516,1,git-restore,"The command can also be used to restore the content in the index
       with
--staged
, or restore both the working tree and the index with
--staged --worktree
. By default, if
--staged
is given, the contents are restored from
HEAD
, otherwise from the index. Use
--source
to restore from a
       different commit."
516,2,git-restore,"Use
--source
to restore from a
       different commit. See ""Reset, restore and revert"" in
git(1)
for the differences
       between the three commands. THIS COMMAND IS EXPERIMENTAL."
516,3,git-restore,"See ""Reset, restore and revert"" in
git(1)
for the differences
       between the three commands. THIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE."
517,0,git-reset,"In the first three forms, copy entries from
<tree-ish>
to the
       index. In the last form, set the current branch head (
HEAD
) to
<commit>
, optionally modifying index and working tree to match. The
<tree-ish>
/
<commit>
defaults to
HEAD
in all forms."
517,1,git-reset,"The
<tree-ish>
/
<commit>
defaults to
HEAD
in all forms. git reset
[-q] [<tree-ish>] [--] <pathspec>...,
git reset
[-q]
       [--pathspec-from-file=<file> [--pathspec-file-nul]] [<tree-ish>]
           These forms reset the index entries for all paths that match
           the
<pathspec>
to their state at
<tree-ish>
. (It does not
           affect the working tree or the current branch.)

           This means that
git reset
<pathspec>
is the opposite of
git
add
<pathspec>
."
517,2,git-reset,"(It does not
           affect the working tree or the current branch.)

           This means that
git reset
<pathspec>
is the opposite of
git
add
<pathspec>
. This command is equivalent to
git restore
[
--source=
<tree-ish>
]
--staged
<pathspec>
.... After running
git reset
<pathspec>
to update the index entry,
           you can use
git-restore(1)
to check the contents out of the
           index to the working tree."
517,3,git-reset,"After running
git reset
<pathspec>
to update the index entry,
           you can use
git-restore(1)
to check the contents out of the
           index to the working tree. Alternatively, using
git-restore(1)
and specifying a commit with
--source
, you can copy the
           contents of a path out of a commit to the index and to the
           working tree in one go. git reset
(--patch | -p) [<tree-ish>] [--] [<pathspec>...]
           Interactively select hunks in the difference between the index
           and
<tree-ish>
(defaults to
HEAD
)."
517,4,git-reset,"git reset
(--patch | -p) [<tree-ish>] [--] [<pathspec>...]
           Interactively select hunks in the difference between the index
           and
<tree-ish>
(defaults to
HEAD
). The chosen hunks are
           applied in reverse to the index. This means that
git reset -p
is the opposite of
git add -p
,
           i.e."
517,5,git-reset,"This means that
git reset -p
is the opposite of
git add -p
,
           i.e. you can use it to selectively reset hunks. See the
           âInteractive Modeâ section of
git-add(1)
to learn how to
           operate the
--patch
mode."
517,6,git-reset,"See the
           âInteractive Modeâ section of
git-add(1)
to learn how to
           operate the
--patch
mode. git reset
[<mode>] [<commit>]
           This form resets the current branch head to
<commit>
and
           possibly updates the index (resetting it to the tree of
<commit>
) and the working tree depending on
<mode>
. Before the
           operation,
ORIG_HEAD
is set to the tip of the current branch."
517,7,git-reset,"Before the
           operation,
ORIG_HEAD
is set to the tip of the current branch. If
<mode>
is omitted, defaults to
--mixed
. The
<mode>
must be
           one of the following:

           --soft
               Does not touch the index file or the working tree at all
               (but resets the head to
<commit>
, just like all modes do)."
517,8,git-reset,"The
<mode>
must be
           one of the following:

           --soft
               Does not touch the index file or the working tree at all
               (but resets the head to
<commit>
, just like all modes do). This leaves all your changed files ""Changes to be
               committed"", as
git status
would put it. --mixed
               Resets the index but not the working tree (i.e., the
               changed files are preserved but not marked for commit) and
               reports what has not been updated."
517,9,git-reset,"--mixed
               Resets the index but not the working tree (i.e., the
               changed files are preserved but not marked for commit) and
               reports what has not been updated. This is the default
               action. If
-N
is specified, removed paths are marked as
               intent-to-add (see
git-add(1)
)."
517,10,git-reset,"If
-N
is specified, removed paths are marked as
               intent-to-add (see
git-add(1)
). --hard
               Resets the index and working tree. Any changes to tracked
               files in the working tree since
<commit>
are discarded."
517,11,git-reset,"Any changes to tracked
               files in the working tree since
<commit>
are discarded. Any untracked files or directories in the way of writing
               any tracked files are simply deleted. --merge
               Resets the index and updates the files in the working tree
               that are different between
<commit>
and
HEAD
, but keeps
               those which are different between the index and working
               tree (i.e."
517,12,git-reset,"--merge
               Resets the index and updates the files in the working tree
               that are different between
<commit>
and
HEAD
, but keeps
               those which are different between the index and working
               tree (i.e. which have changes which have not been added). If a file that is different between
<commit>
and the index
               has unstaged changes, reset is aborted."
517,13,git-reset,"If a file that is different between
<commit>
and the index
               has unstaged changes, reset is aborted. In other words,
--merge
does something like a
git
read-tree -u -m
<commit>
, but carries forward unmerged
               index entries. --keep
               Resets index entries and updates files in the working tree
               that are different between
<commit>
and
HEAD
."
517,14,git-reset,"--keep
               Resets index entries and updates files in the working tree
               that are different between
<commit>
and
HEAD
. If a file
               that is different between
<commit>
and
HEAD
has local
               changes, reset is aborted. --[no-]recurse-submodules
               When the working tree is updated, using
               --recurse-submodules will also recursively reset the
               working tree of all active submodules according to the
               commit recorded in the superproject, also setting the
               submodules' HEAD to be detached at that commit."
517,15,git-reset,"If a file
               that is different between
<commit>
and
HEAD
has local
               changes, reset is aborted. --[no-]recurse-submodules
               When the working tree is updated, using
               --recurse-submodules will also recursively reset the
               working tree of all active submodules according to the
               commit recorded in the superproject, also setting the
               submodules' HEAD to be detached at that commit. See ""Reset, restore and revert"" in
git(1)
for the differences
       between the three commands."
518,0,git-revert,"Given one or more existing commits, revert the changes that the
       related patches introduce, and record some new commits that record
       them. This requires your working tree to be clean (no
       modifications from the HEAD commit). Note:
git revert
is used to record some new commits to reverse the
       effect of some earlier commits (often only a faulty one)."
518,1,git-revert,"Note:
git revert
is used to record some new commits to reverse the
       effect of some earlier commits (often only a faulty one). If you
       want to throw away all uncommitted changes in your working
       directory, you should see
git-reset(1)
, particularly the
--hard
option. If you want to extract specific files as they were in
       another commit, you should see
git-restore(1)
, specifically the
--source
option."
518,2,git-revert,"If you want to extract specific files as they were in
       another commit, you should see
git-restore(1)
, specifically the
--source
option. Take care with these alternatives as both will
       discard uncommitted changes in your working directory. See ""Reset, restore and revert"" in
git(1)
for the differences
       between the three commands."
519,0,git-rm,"Remove files matching pathspec from the index, or from the working
       tree and the index. git rm
will not remove a file from just your
       working directory. (There is no option to remove a file only from
       the working tree and yet keep it in the index; use
/bin/rm
if you
       want to do that.) The files being removed have to be identical to
       the tip of the branch, and no updates to their contents can be
       staged in the index, though that default behavior can be
       overridden with the
-f
option."
519,1,git-rm,"(There is no option to remove a file only from
       the working tree and yet keep it in the index; use
/bin/rm
if you
       want to do that.) The files being removed have to be identical to
       the tip of the branch, and no updates to their contents can be
       staged in the index, though that default behavior can be
       overridden with the
-f
option. When
--cached
is given, the staged
       content has to match either the tip of the branch or the file on
       disk, allowing the file to be removed from just the index. When
       sparse-checkouts are in use (see
git-sparse-checkout(1)
),
git rm
will only remove paths within the sparse-checkout patterns."
520,0,git-send-pack,"Usually you would want to use
git push
, which is a higher-level
       wrapper of this command, instead. See
git-push(1)
.

       Invokes
git-receive-pack
on a possibly remote repository, and
       updates it from the current repository, sending named refs."
521,0,git-send-email,"Takes the patches given on the command line and emails them out. Patches can be specified as files, directories (which will send
       all files in the directory), or directly as a revision list. In
       the last case, any format accepted by
git-format-patch(1)
can be
       passed to git send-email, as well as options understood by
git-format-patch(1)
."
521,1,git-send-email,"In
       the last case, any format accepted by
git-format-patch(1)
can be
       passed to git send-email, as well as options understood by
git-format-patch(1)
. The header of the email is configurable via command-line options. If not specified on the command line, the user will be prompted
       with a ReadLine enabled interface to provide the necessary
       information."
521,2,git-send-email,"If not specified on the command line, the user will be prompted
       with a ReadLine enabled interface to provide the necessary
       information. There are two formats accepted for patch files:

        1. mbox format files

           This is what
git-format-patch(1)
generates."
521,3,git-send-email,"mbox format files

           This is what
git-format-patch(1)
generates. Most headers and
           MIME formatting are ignored. 2."
521,4,git-send-email,"Most headers and
           MIME formatting are ignored. 2. The original format used by Greg Kroah-Hartmanâs
send_lots_of_email.pl
script

           This format expects the first line of the file to contain the
           ""Cc:"" value and the ""Subject:"" of the message as the second
           line."
522,0,git-rev-parse,"Many Git porcelainish commands take a mixture of flags (i.e. parameters that begin with a dash
-
) and parameters meant for the
       underlying
git rev-list
command they use internally and flags and
       parameters for the other commands they use downstream of
git
rev-list
. The primary purpose of this command is to allow calling
       programs to distinguish between them."
522,1,git-rev-parse,"The primary purpose of this command is to allow calling
       programs to distinguish between them. There are a few other
       operation modes that have nothing to do with the above ""help parse
       command line options"". Unless otherwise specified, most of the options and operation
       modes require you to run this command inside a git repository or a
       working tree that is under the control of a git repository, and
       will give you a fatal error otherwise."
523,0,git-rev-list,"List commits that are reachable by following the
parent
links from
       the given commit(s), but exclude commits that are reachable from
       the one(s) given with a
^
in front of them. The output is given in
       reverse chronological order by default. You can think of this as a set operation."
523,1,git-rev-list,"You can think of this as a set operation. Commits reachable from
       any of the commits given on the command line form a set, and then
       commits reachable from any of the ones given with
^
in front are
       subtracted from that set. The remaining commits are what comes out
       in the commandâs output."
523,2,git-rev-list,"The remaining commits are what comes out
       in the commandâs output. Various other options and paths
       parameters can be used to further limit the result. Thus, the following command:

           $ git rev-list foo bar ^baz

       means ""list all the commits which are reachable from
foo
or
bar
,
       but not from
baz
""."
523,3,git-rev-list,"Thus, the following command:

           $ git rev-list foo bar ^baz

       means ""list all the commits which are reachable from
foo
or
bar
,
       but not from
baz
"". A special notation ""
<commit1>
.. <commit2>
"" can be used as a
       short-hand for ""^
<commit1> <commit2>
""."
523,4,git-rev-list,"<commit2>
"" can be used as a
       short-hand for ""^
<commit1> <commit2>
"". For example, either of the
       following may be used interchangeably:

           $ git rev-list origin..HEAD
           $ git rev-list HEAD ^origin

       Another special notation is ""
<commit1>
... <commit2>
"" which is
       useful for merges."
523,5,git-rev-list,"<commit2>
"" which is
       useful for merges. The resulting set of commits is the symmetric
       difference between the two operands. The following two commands
       are equivalent:

           $ git rev-list A B --not $(git merge-base --all A B)
           $ git rev-list A...B
rev-list
is an essential Git command, since it provides the
       ability to build and traverse commit ancestry graphs."
523,6,git-rev-list,"The resulting set of commits is the symmetric
       difference between the two operands. The following two commands
       are equivalent:

           $ git rev-list A B --not $(git merge-base --all A B)
           $ git rev-list A...B
rev-list
is an essential Git command, since it provides the
       ability to build and traverse commit ancestry graphs. For this
       reason, it has a lot of different options that enable it to be
       used by commands as different as
git bisect
and
git repack
."
524,0,git-sh-i18n--envsubst,"This is not a command the end user would want to run. Ever. This
       documentation is meant for people who are studying the plumbing
       scripts and/or are writing new ones."
524,1,git-sh-i18n--envsubst,"This
       documentation is meant for people who are studying the plumbing
       scripts and/or are writing new ones. git sh-i18n--envsubst
is Gitâs stripped-down copy of the GNU
envsubst
(
1
) program that comes with the GNU gettext package. Itâs
       used internally by
git-sh-i18n(1)
to interpolate the variables
       passed to the
eval_gettext
function."
524,2,git-sh-i18n--envsubst,"Itâs
       used internally by
git-sh-i18n(1)
to interpolate the variables
       passed to the
eval_gettext
function. No promises are made about the interface, or that this program
       wonât disappear without warning in the next version of Git. Donât
       use it."
525,0,git-series,"git series
tracks changes to a patch series over time. git series
also tracks a cover letter for the patch series, formats the
       series for email, and prepares pull requests. Use
git series start
seriesname
to start a patch series
seriesname
."
525,1,git-series,"Use
git series start
seriesname
to start a patch series
seriesname
. Use normal
git
commands to commit changes, and use
git series status
to check what has changed. Use
git series cover
to add or edit a cover letter."
525,2,git-series,"Use
git series cover
to add or edit a cover letter. Use
git series add
and
git series
commit
(or
git series commit -a
) to commit changes to the patch
       series. Use
git series rebase -i
to help rework or reorganize the
       patch series."
525,3,git-series,"Use
git series rebase -i
to help rework or reorganize the
       patch series. Use
git series format
to prepare the patch series
       to send via email, or
git series req
to prepare a ""please pull""
       mail. Running
git series
without arguments shows the list of patch
       series, marking the current patch series with a '*'."
526,0,git-sh-setup,"This is not a command the end user would want to run. Ever. This
       documentation is meant for people who are studying the
       Porcelain-ish scripts and/or are writing new ones."
526,1,git-sh-setup,"This
       documentation is meant for people who are studying the
       Porcelain-ish scripts and/or are writing new ones. The
git sh-setup
scriptlet is designed to be sourced (using .) by
       other shell scripts to set up some variables pointing at the
       normal Git directories and a few helper shell functions. Before sourcing it, your script should set up a few variables;
USAGE
(and
LONG_USAGE
, if any) is used to define the message given
       by
usage
() shell function."
526,2,git-sh-setup,"Before sourcing it, your script should set up a few variables;
USAGE
(and
LONG_USAGE
, if any) is used to define the message given
       by
usage
() shell function. SUBDIRECTORY_OK
can be set if the
       script can run from a subdirectory of the working tree (some
       commands do not). The scriptlet sets
GIT_DIR
and
GIT_OBJECT_DIRECTORY
shell
       variables, but does
not
export them to the environment."
527,0,git-sh-i18n,"This is not a command the end user would want to run. Ever. This
       documentation is meant for people who are studying the
       Porcelain-ish scripts and/or are writing new ones."
527,1,git-sh-i18n,"This
       documentation is meant for people who are studying the
       Porcelain-ish scripts and/or are writing new ones. The 'git sh-i18n scriptlet is designed to be sourced (using .) by
       Gitâs porcelain programs implemented in shell script. It provides
       wrappers for the GNU
gettext
and
eval_gettext
functions accessible
       through the
gettext.sh
script, and provides pass-through fallbacks
       on systems without GNU gettext."
528,0,git-shell,"This is a login shell for SSH accounts to provide restricted Git
       access. It permits execution only of server-side Git commands
       implementing the pull/push functionality, plus custom commands
       present in a subdirectory named
git-shell-commands
in the userâs
       home directory."
529,0,git-status,"Displays paths that have differences between the index file and
       the current HEAD commit, paths that have differences between the
       working tree and the index file, and paths in the working tree
       that are not tracked by Git (and are not ignored by
gitignore(5)
).
       The first are what you
would
commit by running
git commit
; the
       second and third are what you
could
commit by running
git add
before running
git commit
."
530,0,git-show-branch,"Shows the commit ancestry graph starting from the commits named
       with <rev>s or <glob>s (or all refs under refs/heads and/or
       refs/tags) semi-visually.

       It cannot show more than 26 branches and commits at a time.

       It uses
showbranch.default
multi-valued configuration items if no
       <rev> or <glob> is given on the command line."
531,0,git-show-index,"Read the
.idx
file for a Git packfile (created with
git-pack-objects(1)
or
git-index-pack(1)
) from the standard input,
       and dump its contents. The output consists of one object per line,
       with each line containing two or three space-separated columns:

       â¢   the first column is the offset in bytes of the object within
           the corresponding packfile

       â¢   the second column is the object id of the object

       â¢   if the index version is 2 or higher, the third column contains
           the CRC32 of the object data

       The objects are output in the order in which they are found in the
       index file, which should be (in a correctly constructed file)
       sorted by object id. Note that you can get more information on a packfile by calling
git-verify-pack(1)
."
531,1,git-show-index,"The output consists of one object per line,
       with each line containing two or three space-separated columns:

       â¢   the first column is the offset in bytes of the object within
           the corresponding packfile

       â¢   the second column is the object id of the object

       â¢   if the index version is 2 or higher, the third column contains
           the CRC32 of the object data

       The objects are output in the order in which they are found in the
       index file, which should be (in a correctly constructed file)
       sorted by object id. Note that you can get more information on a packfile by calling
git-verify-pack(1)
. However, as this command considers only the
       index file itself, itâs both faster and more flexible."
532,0,git-show-ref,"Displays references available in a local repository along with the
       associated commit IDs. Results can be filtered using a pattern and
       tags can be dereferenced into object IDs. Additionally, it can be
       used to test whether a particular ref exists."
532,1,git-show-ref,"Additionally, it can be
       used to test whether a particular ref exists. By default, shows the tags, heads, and remote refs. The
--exclude-existing
form is a filter that does the inverse."
532,2,git-show-ref,"The
--exclude-existing
form is a filter that does the inverse. It
       reads refs from stdin, one ref per line, and shows those that
       donât exist in the local repository. The
--exists
form can be used to check for the existence of a
       single references."
532,3,git-show-ref,"The
--exists
form can be used to check for the existence of a
       single references. This form does not verify whether the reference
       resolves to an actual object. Use of this utility is encouraged in favor of directly accessing
       files under the
.git
directory."
533,0,git-sparse-checkout,"This command is used to create sparse checkouts, which change the
       working tree from having all tracked files present to only having
       a subset of those files. It can also switch which subset of files
       are present, or undo and go back to having all tracked files
       present in the working copy. The subset of files is chosen by providing a list of directories
       in cone mode (the default), or by providing a list of patterns in
       non-cone mode."
533,1,git-sparse-checkout,"The subset of files is chosen by providing a list of directories
       in cone mode (the default), or by providing a list of patterns in
       non-cone mode. When in a sparse-checkout, other Git commands behave a bit
       differently. For example, switching branches will not update paths
       outside the sparse-checkout directories/patterns, and
git commit
-a
will not record paths outside the sparse-checkout
       directories/patterns as deleted."
533,2,git-sparse-checkout,"For example, switching branches will not update paths
       outside the sparse-checkout directories/patterns, and
git commit
-a
will not record paths outside the sparse-checkout
       directories/patterns as deleted. THIS COMMAND IS EXPERIMENTAL. ITS BEHAVIOR, AND THE BEHAVIOR OF
       OTHER COMMANDS IN THE PRESENCE OF SPARSE-CHECKOUTS, WILL LIKELY
       CHANGE IN THE FUTURE."
534,0,git-stage,"This is a synonym for
git-add(1)
. Please refer to the
       documentation of that command."
535,0,git-stash,"Use
git stash
when you want to record the current state of the
       working directory and the index, but want to go back to a clean
       working directory. The command saves your local modifications away
       and reverts the working directory to match the
HEAD
commit. The modifications stashed away by this command can be listed with
git stash list
, inspected with
git stash show
, and restored
       (potentially on top of a different commit) with
git stash apply
."
535,1,git-stash,"The modifications stashed away by this command can be listed with
git stash list
, inspected with
git stash show
, and restored
       (potentially on top of a different commit) with
git stash apply
. Calling
git stash
without any arguments is equivalent to
git stash
push
. A stash is by default listed as ""WIP on
branchname
..."", but
       you can give a more descriptive message on the command line when
       you create one."
535,2,git-stash,"A stash is by default listed as ""WIP on
branchname
..."", but
       you can give a more descriptive message on the command line when
       you create one. The latest stash you created is stored in
refs/stash
; older
       stashes are found in the reflog of this reference and can be named
       using the usual reflog syntax (e.g. stash@
{0} is the most recently
       created stash,
stash@
{1} is the one before it,
stash@
{2.hours.ago}
       is also possible)."
535,3,git-stash,"stash@
{0} is the most recently
       created stash,
stash@
{1} is the one before it,
stash@
{2.hours.ago}
       is also possible). Stashes may also be referenced by specifying
       just the stash index (e.g. the integer
n
is equivalent to
stash@
{n})."
536,0,git-shortlog,"Summarizes
git log
output in a format suitable for inclusion in
       release announcements. Each commit will be grouped by author and
       title. Additionally, ""[PATCH]"" will be stripped from the commit
       description."
536,1,git-shortlog,"Each commit will be grouped by author and
       title. Additionally, ""[PATCH]"" will be stripped from the commit
       description. If no revisions are passed on the command line and either standard
       input is not a terminal or there is no current branch,
git
shortlog
will output a summary of the log read from standard
       input, without reference to the current repository."
537,0,git-show,"Shows one or more objects (blobs, trees, tags and commits). For commits it shows the log message and textual diff. It also
       presents the merge commit in a special format as produced by
git
diff-tree --cc
."
537,1,git-show,"It also
       presents the merge commit in a special format as produced by
git
diff-tree --cc
. For tags, it shows the tag message and the referenced objects. For trees, it shows the names (equivalent to
git ls-tree
with
       --name-only)."
537,2,git-show,"For trees, it shows the names (equivalent to
git ls-tree
with
       --name-only). For plain blobs, it shows the plain contents. Some options that
git log
command understands can be used to
       control how the changes the commit introduces are shown."
537,3,git-show,"For plain blobs, it shows the plain contents. Some options that
git log
command understands can be used to
       control how the changes the commit introduces are shown. This manual page describes only the most frequently used options."
538,0,git-stripspace,"Read text, such as commit messages, notes, tags and branch
       descriptions, from the standard input and clean it in the manner
       used by Git. With no arguments, this will:

       â¢   remove trailing whitespace from all lines

       â¢   collapse multiple consecutive empty lines into one empty line

       â¢   remove empty lines from the beginning and end of the input

       â¢   add a missing
\n
to the last line if necessary. In the case where the input consists entirely of whitespace
       characters, no output will be produced."
538,1,git-stripspace,"In the case where the input consists entirely of whitespace
       characters, no output will be produced. NOTE
: This is intended for cleaning metadata. Prefer the
--whitespace=fix
mode of
git-apply(1)
for correcting whitespace of
       patches or files in the repository."
539,0,git-symbolic-ref,"Given one argument, reads which branch head the given symbolic ref
       refers to and outputs its path, relative to the
.git/
directory. Typically you would give
HEAD
as the <name> argument to see which
       branch your working tree is on. Given two arguments, creates or updates a symbolic ref <name> to
       point at the given branch <ref>."
539,1,git-symbolic-ref,"Given two arguments, creates or updates a symbolic ref <name> to
       point at the given branch <ref>. Given
--delete
and an additional argument, deletes the given
       symbolic ref. A symbolic ref is a regular file that stores a string that begins
       with
ref: refs/
."
539,2,git-symbolic-ref,"Given
--delete
and an additional argument, deletes the given
       symbolic ref. A symbolic ref is a regular file that stores a string that begins
       with
ref: refs/
. For example, your
.git/HEAD
is a regular file
       whose content is
ref: refs/heads/master
."
540,0,git-submodule,"Inspects, updates and manages submodules.

       For more information about submodules, see
gitsubmodules(7)
."
541,0,git-switch,"Switch to a specified branch. The working tree and the index are
       updated to match the branch. All new commits will be added to the
       tip of this branch."
541,1,git-switch,"All new commits will be added to the
       tip of this branch. Optionally a new branch could be created with either
-c
,
-C
,
       automatically from a remote branch of same name (see
--guess
), or
       detach the working tree from any branch with
--detach
, along with
       switching. Switching branches does not require a clean index and working tree
       (i.e."
541,2,git-switch,"Switching branches does not require a clean index and working tree
       (i.e. no differences compared to
HEAD
). The operation is aborted
       however if the operation leads to loss of local changes, unless
       told otherwise with
--discard-changes
or
--merge
."
541,3,git-switch,"The operation is aborted
       however if the operation leads to loss of local changes, unless
       told otherwise with
--discard-changes
or
--merge
. THIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE."
542,0,git-unpack-file,"Creates a file holding the contents of the blob specified by sha1.
       It returns the name of the temporary file in the following format:
       .merge_file_XXXXX"
543,0,git-unpack-objects,"Read a packed archive (.pack) from the standard input, expanding
       the objects contained within and writing them into the repository
       in ""loose"" (one object per file) format. Objects that already exist in the repository will
not
be unpacked
       from the packfile. Therefore, nothing will be unpacked if you use
       this command on a packfile that exists within the target
       repository."
543,1,git-unpack-objects,"Objects that already exist in the repository will
not
be unpacked
       from the packfile. Therefore, nothing will be unpacked if you use
       this command on a packfile that exists within the target
       repository. See
git-repack(1)
for options to generate new packs and replace
       existing ones."
544,0,git-update-ref,"Given two arguments, stores the <new-oid> in the <ref>, possibly
       dereferencing the symbolic refs. E.g. git update-ref HEAD
<new-oid>
updates the current branch head to the new object."
544,1,git-update-ref,"git update-ref HEAD
<new-oid>
updates the current branch head to the new object. Given three arguments, stores the <new-oid> in the <ref>, possibly
       dereferencing the symbolic refs, after verifying that the current
       value of the <ref> matches <old-oid>. E.g."
544,2,git-update-ref,"E.g. git update-ref
refs/heads/master
<new-oid> <old-oid>
updates the master branch
       head to <new-oid> only if its current value is <old-oid>. You can
       specify 40 ""0"" or an empty string as <old-oid> to make sure that
       the ref you are creating does not exist."
544,3,git-update-ref,"You can
       specify 40 ""0"" or an empty string as <old-oid> to make sure that
       the ref you are creating does not exist. The final arguments are object names; this command without any
       options does not support updating a symbolic ref to point to
       another ref (see
git-symbolic-ref(1)
). But
git update-ref --stdin
does have the
symref-
* commands so that regular refs and symbolic
       refs can be committed in the same transaction."
544,4,git-update-ref,"But
git update-ref --stdin
does have the
symref-
* commands so that regular refs and symbolic
       refs can be committed in the same transaction. If --no-deref is given, <ref> itself is overwritten, rather than
       the result of following the symbolic pointers. With
-d
, it deletes the named <ref> after verifying that it still
       contains <old-oid>."
544,5,git-update-ref,"With
-d
, it deletes the named <ref> after verifying that it still
       contains <old-oid>. With
--stdin
, update-ref reads instructions from standard input
       and performs all modifications together. Specify commands of the
       form:

           update SP <ref> SP <new-oid> [SP <old-oid>] LF
           create SP <ref> SP <new-oid> LF
           delete SP <ref> [SP <old-oid>] LF
           verify SP <ref> [SP <old-oid>] LF
           symref-update SP <ref> SP <new-target> [SP (ref SP <old-target> | oid SP <old-oid>)] LF
           symref-create SP <ref> SP <new-target> LF
           symref-delete SP <ref> [SP <old-target>] LF
           symref-verify SP <ref> [SP <old-target>] LF
           option SP <opt> LF
           start LF
           prepare LF
           commit LF
           abort LF

       With
--create-reflog
, update-ref will create a reflog for each ref
       even if one would not ordinarily be created."
544,6,git-update-ref,"Specify commands of the
       form:

           update SP <ref> SP <new-oid> [SP <old-oid>] LF
           create SP <ref> SP <new-oid> LF
           delete SP <ref> [SP <old-oid>] LF
           verify SP <ref> [SP <old-oid>] LF
           symref-update SP <ref> SP <new-target> [SP (ref SP <old-target> | oid SP <old-oid>)] LF
           symref-create SP <ref> SP <new-target> LF
           symref-delete SP <ref> [SP <old-target>] LF
           symref-verify SP <ref> [SP <old-target>] LF
           option SP <opt> LF
           start LF
           prepare LF
           commit LF
           abort LF

       With
--create-reflog
, update-ref will create a reflog for each ref
       even if one would not ordinarily be created. Quote fields containing whitespace as if they were strings in C
       source code; i.e., surrounded by double-quotes and with backslash
       escapes. Use 40 ""0"" characters or the empty string to specify a
       zero value."
544,7,git-update-ref,"Use 40 ""0"" characters or the empty string to specify a
       zero value. To specify a missing value, omit the value and its
       preceding SP entirely. Alternatively, use
-z
to specify in NUL-terminated format, without
       quoting:

           update SP <ref> NUL <new-oid> NUL [<old-oid>] NUL
           create SP <ref> NUL <new-oid> NUL
           delete SP <ref> NUL [<old-oid>] NUL
           verify SP <ref> NUL [<old-oid>] NUL
           symref-update SP <ref> NUL <new-target> [NUL (ref NUL <old-target> | oid NUL <old-oid>)] NUL
           symref-create SP <ref> NUL <new-target> NUL
           symref-delete SP <ref> [NUL <old-target>] NUL
           symref-verify SP <ref> [NUL <old-target>] NUL
           option SP <opt> NUL
           start NUL
           prepare NUL
           commit NUL
           abort NUL

       In this format, use 40 ""0"" to specify a zero value, and use the
       empty string to specify a missing value."
544,8,git-update-ref,"Alternatively, use
-z
to specify in NUL-terminated format, without
       quoting:

           update SP <ref> NUL <new-oid> NUL [<old-oid>] NUL
           create SP <ref> NUL <new-oid> NUL
           delete SP <ref> NUL [<old-oid>] NUL
           verify SP <ref> NUL [<old-oid>] NUL
           symref-update SP <ref> NUL <new-target> [NUL (ref NUL <old-target> | oid NUL <old-oid>)] NUL
           symref-create SP <ref> NUL <new-target> NUL
           symref-delete SP <ref> [NUL <old-target>] NUL
           symref-verify SP <ref> [NUL <old-target>] NUL
           option SP <opt> NUL
           start NUL
           prepare NUL
           commit NUL
           abort NUL

       In this format, use 40 ""0"" to specify a zero value, and use the
       empty string to specify a missing value. In either format, values can be specified in any form that Git
       recognizes as an object name. Commands in any other format or a
       repeated <ref> produce an error."
544,9,git-update-ref,"Commands in any other format or a
       repeated <ref> produce an error. Command meanings are:

       update
           Set <ref> to <new-oid> after verifying <old-oid>, if given. Specify a zero <new-oid> to ensure the ref does not exist
           after the update and/or a zero <old-oid> to make sure the ref
           does not exist before the update."
544,10,git-update-ref,"Specify a zero <new-oid> to ensure the ref does not exist
           after the update and/or a zero <old-oid> to make sure the ref
           does not exist before the update. create
           Create <ref> with <new-oid> after verifying that it does not
           exist. The given <new-oid> may not be zero."
544,11,git-update-ref,"The given <new-oid> may not be zero. delete
           Delete <ref> after verifying that it exists with <old-oid>, if
           given. If given, <old-oid> may not be zero."
544,12,git-update-ref,"If given, <old-oid> may not be zero. symref-update
           Set <ref> to <new-target> after verifying <old-target> or
           <old-oid>, if given. Specify a zero <old-oid> to ensure that
           the ref does not exist before the update."
544,13,git-update-ref,"Specify a zero <old-oid> to ensure that
           the ref does not exist before the update. verify
           Verify <ref> against <old-oid> but do not change it. If
           <old-oid> is zero or missing, the ref must not exist."
544,14,git-update-ref,"If
           <old-oid> is zero or missing, the ref must not exist. symref-create: Create symbolic ref <ref> with <new-target> after
       verifying that it does not exist. symref-delete
           Delete <ref> after verifying that it exists with <old-target>,
           if given."
544,15,git-update-ref,"symref-delete
           Delete <ref> after verifying that it exists with <old-target>,
           if given. symref-verify
           Verify symbolic <ref> against <old-target> but do not change
           it. If <old-target> is missing, the ref must not exist."
544,16,git-update-ref,"If <old-target> is missing, the ref must not exist. Can
           only be used in
no-deref
mode. option
           Modify the behavior of the next command naming a <ref>."
544,17,git-update-ref,"option
           Modify the behavior of the next command naming a <ref>. The
           only valid option is
no-deref
to avoid dereferencing a
           symbolic ref. start
           Start a transaction."
544,18,git-update-ref,"start
           Start a transaction. In contrast to a non-transactional
           session, a transaction will automatically abort if the session
           ends without an explicit commit. This command may create a new
           empty transaction when the current one has been committed or
           aborted already."
544,19,git-update-ref,"This command may create a new
           empty transaction when the current one has been committed or
           aborted already. prepare
           Prepare to commit the transaction. This will create lock files
           for all queued reference updates."
544,20,git-update-ref,"This will create lock files
           for all queued reference updates. If one reference could not
           be locked, the transaction will be aborted. commit
           Commit all reference updates queued for the transaction,
           ending the transaction."
544,21,git-update-ref,"commit
           Commit all reference updates queued for the transaction,
           ending the transaction. abort
           Abort the transaction, releasing all locks if the transaction
           is in prepared state. If all <ref>s can be locked with matching <old-oid>s
       simultaneously, all modifications are performed."
544,22,git-update-ref,"If all <ref>s can be locked with matching <old-oid>s
       simultaneously, all modifications are performed. Otherwise, no
       modifications are performed. Note that while each individual <ref>
       is updated or deleted atomically, a concurrent reader may still
       see a subset of the modifications."
545,0,git-tag,"Add a tag reference in
refs/tags/
, unless
-d/-l/-v
is given to
       delete, list or verify tags. Unless
-f
is given, the named tag must not yet exist. If one of
-a
,
-s
, or
-u
<key-id>
is passed, the command creates a
tag
object, and requires a tag message."
545,1,git-tag,"If one of
-a
,
-s
, or
-u
<key-id>
is passed, the command creates a
tag
object, and requires a tag message. Unless
-m
<msg>
or
-F
<file>
is given, an editor is started for the user to type in the
       tag message. If
-m
<msg>
or
-F
<file>
or
--trailer
<token>
[
=
<value>
] is given
       and
-a
,
-s
, and
-u
<key-id>
are absent,
-a
is implied."
545,2,git-tag,"If
-m
<msg>
or
-F
<file>
or
--trailer
<token>
[
=
<value>
] is given
       and
-a
,
-s
, and
-u
<key-id>
are absent,
-a
is implied. Otherwise, a tag reference that points directly at the given
       object (i.e., a lightweight tag) is created. A GnuPG signed tag object will be created when
-s
or
-u
<key-id>
is used."
545,3,git-tag,"A GnuPG signed tag object will be created when
-s
or
-u
<key-id>
is used. When
-u
<key-id>
is not used, the committer identity for
       the current user is used to find the GnuPG key for signing. The
       configuration variable
gpg.program
is used to specify custom GnuPG
       binary."
545,4,git-tag,"The
       configuration variable
gpg.program
is used to specify custom GnuPG
       binary. Tag objects (created with
-a
,
-s
, or
-u
) are called ""annotated""
       tags; they contain a creation date, the tagger name and e-mail, a
       tagging message, and an optional GnuPG signature. Whereas a
       ""lightweight"" tag is simply a name for an object (usually a commit
       object)."
545,5,git-tag,"Whereas a
       ""lightweight"" tag is simply a name for an object (usually a commit
       object). Annotated tags are meant for release while lightweight tags are
       meant for private or temporary object labels. For this reason,
       some git commands for naming objects (like
git describe
) will
       ignore lightweight tags by default."
546,0,git-svn,"git svn
is a simple conduit for changesets between Subversion and
       Git. It provides a bidirectional flow of changes between a
       Subversion and a Git repository. git svn
can track a standard Subversion repository, following the
       common ""trunk/branches/tags"" layout, with the --stdlayout option."
546,1,git-svn,"git svn
can track a standard Subversion repository, following the
       common ""trunk/branches/tags"" layout, with the --stdlayout option. It can also follow branches and tags in any layout with the
       -T/-t/-b options (see options to
init
below, and also the
clone
command). Once tracking a Subversion repository (with any of the above
       methods), the Git repository can be updated from Subversion by the
fetch
command and Subversion updated from Git by the
dcommit
command."
547,0,git-update-server-info,"A dumb server that does not do on-the-fly pack generations must
       have some auxiliary information files in $GIT_DIR/info and
       $GIT_OBJECT_DIRECTORY/info directories to help clients discover
       what references and packs the server has. This command generates
       such auxiliary files."
548,0,git-update-index,"Modifies the index. Each file mentioned is updated into the index
       and any
unmerged
or
needs updating
state is cleared. See also
git-add(1)
for a more user-friendly way to do some of the
       most common operations on the index."
548,1,git-update-index,"Each file mentioned is updated into the index
       and any
unmerged
or
needs updating
state is cleared. See also
git-add(1)
for a more user-friendly way to do some of the
       most common operations on the index. The way
git update-index
handles files it is told about can be
       modified using the various options:"
549,0,git-upload-archive,"Invoked by
git archive --remote
and sends a generated archive to
       the other end over the Git protocol.

       This command is usually not invoked directly by the end user. The
       UI for the protocol is on the
git archive
side, and the program
       pair is meant to be used to get an archive from a remote
       repository."
550,0,git-var,"Prints a Git logical variable. Exits with code 1 if the variable
       has no value."
551,0,git-upload-pack,"Invoked by
git fetch-pack
, learns what objects the other side is
       missing, and sends them after packing. This command is usually not invoked directly by the end user. The
       UI for the protocol is on the
git fetch-pack
side, and the program
       pair is meant to be used to pull updates from a remote repository."
551,1,git-upload-pack,"This command is usually not invoked directly by the end user. The
       UI for the protocol is on the
git fetch-pack
side, and the program
       pair is meant to be used to pull updates from a remote repository. For push operations, see
git send-pack
."
552,0,git-verify-commit,"Validates the GPG signature created by
git commit -S
."
553,0,git-verify-pack,"Reads given idx file for packed Git archive created with the
git
pack-objects
command and verifies the idx file and the
       corresponding pack file."
554,0,git-version,"With no options given, the version of
git
is printed on the
       standard output.

       Note that
git --version
is identical to
git version
because the
       former is internally converted into the latter."
555,0,git-verify-tag,"Validates the gpg signature created by
git tag
."
556,0,git-whatchanged,"Shows commit logs and diff output each commit introduces. New users are encouraged to use
git-log(1)
instead. The
whatchanged
command is essentially the same as
git-log(1)
but
       defaults to showing the raw format diff output and skipping
       merges."
556,1,git-whatchanged,"New users are encouraged to use
git-log(1)
instead. The
whatchanged
command is essentially the same as
git-log(1)
but
       defaults to showing the raw format diff output and skipping
       merges. The command is primarily kept for historical reasons; fingers of
       many people who learned Git long before
git log
was invented by
       reading the Linux kernel mailing list are trained to type it."
557,0,git-web--browse,"This script tries, as much as possible, to display the URLs and
       FILEs that are passed as arguments, as HTML pages in new tabs on
       an already opened web browser.

       The following browsers (or commands) are currently supported:

       â¢   firefox (this is the default under X Window when not using
           KDE)

       â¢   iceweasel

       â¢   seamonkey

       â¢   iceape

       â¢   chromium (also supported as chromium-browser)

       â¢   google-chrome (also supported as chrome)

       â¢   konqueror (this is the default under KDE, see
Note about
konqueror
below)

       â¢   opera

       â¢   w3m (this is the default outside graphical environments)

       â¢   elinks

       â¢   links

       â¢   lynx

       â¢   dillo

       â¢   open (this is the default under Mac OS X GUI)

       â¢   start (this is the default under MinGW)

       â¢   cygstart (this is the default under Cygwin)

       â¢   xdg-open

       Custom commands may also be specified."
558,0,git-worktree,"Manage multiple working trees attached to the same repository. A git repository can support multiple working trees, allowing you
       to check out more than one branch at a time. With
git worktree add
a new working tree is associated with the repository, along with
       additional metadata that differentiates that working tree from
       others in the same repository."
558,1,git-worktree,"With
git worktree add
a new working tree is associated with the repository, along with
       additional metadata that differentiates that working tree from
       others in the same repository. The working tree, along with this
       metadata, is called a ""worktree"". This new worktree is called a ""linked worktree"" as opposed to the
       ""main worktree"" prepared by
git-init(1)
or
git-clone(1)
."
558,2,git-worktree,"This new worktree is called a ""linked worktree"" as opposed to the
       ""main worktree"" prepared by
git-init(1)
or
git-clone(1)
. A
       repository has one main worktree (if itâs not a bare repository)
       and zero or more linked worktrees. When you are done with a linked
       worktree, remove it with
git worktree remove
."
558,3,git-worktree,"When you are done with a linked
       worktree, remove it with
git worktree remove
. In its simplest form,
git worktree add
<path>
automatically
       creates a new branch whose name is the final component of
<path>
,
       which is convenient if you plan to work on a new topic. For
       instance,
git worktree add ../hotfix
creates new branch
hotfix
and
       checks it out at path
../hotfix
."
558,4,git-worktree,"For
       instance,
git worktree add ../hotfix
creates new branch
hotfix
and
       checks it out at path
../hotfix
. To instead work on an existing
       branch in a new worktree, use
git worktree add
<path> <branch>
. On
       the other hand, if you just plan to make some experimental changes
       or do testing without disturbing existing development, it is often
       convenient to create a
throwaway
worktree not associated with any
       branch."
558,5,git-worktree,"On
       the other hand, if you just plan to make some experimental changes
       or do testing without disturbing existing development, it is often
       convenient to create a
throwaway
worktree not associated with any
       branch. For instance,
git worktree add -d
<path>
creates a new
       worktree with a detached
HEAD
at the same commit as the current
       branch. If a working tree is deleted without using
git worktree remove
,
       then its associated administrative files, which reside in the
       repository (see ""DETAILS"" below), will eventually be removed
       automatically (see
gc.worktreePruneExpire
in
git-config(1)
), or
       you can run
git worktree prune
in the main or any linked worktree
       to clean up any stale administrative files."
558,6,git-worktree,"For instance,
git worktree add -d
<path>
creates a new
       worktree with a detached
HEAD
at the same commit as the current
       branch. If a working tree is deleted without using
git worktree remove
,
       then its associated administrative files, which reside in the
       repository (see ""DETAILS"" below), will eventually be removed
       automatically (see
gc.worktreePruneExpire
in
git-config(1)
), or
       you can run
git worktree prune
in the main or any linked worktree
       to clean up any stale administrative files. If the working tree for a linked worktree is stored on a portable
       device or network share which is not always mounted, you can
       prevent its administrative files from being pruned by issuing the
git worktree lock
command, optionally specifying
--reason
to
       explain why the worktree is locked."
559,0,git-write-tree,"Creates a tree object using the current index. The name of the new
       tree object is printed to standard output. The index must be in a fully merged state."
559,1,git-write-tree,"The index must be in a fully merged state. Conceptually,
git write-tree
sync()s the current index contents
       into a set of tree files. In order to have that match what is
       actually in your directory right now, you need to have done a
git
update-index
phase before you did the
git write-tree
."
560,0,gitk,"Displays changes in a repository or a selected set of commits.
       This includes visualizing the commit graph, showing information
       related to each commit, and the files in the trees of each
       revision."
561,0,glilypond,nan
562,0,gnutls-cli-debug,"TLS debug client. It sets up multiple TLS connections to a server
       and queries its capabilities. It was created to assist in
       debugging GnuTLS, but it might be useful to extract a TLS server's
       capabilities."
562,1,gnutls-cli-debug,"It was created to assist in
       debugging GnuTLS, but it might be useful to extract a TLS server's
       capabilities. It connects to a TLS server, performs tests and
       print the server's capabilities. If called with the `-V' parameter
       more checks will be performed."
562,2,gnutls-cli-debug,"It connects to a TLS server, performs tests and
       print the server's capabilities. If called with the `-V' parameter
       more checks will be performed. Can be used to check for servers
       with special needs or bugs."
563,0,gnutls-cli,"Simple client program to set up a TLS connection to some other
       computer.  It sets up a TLS connection and forwards data from the
       standard input to the secured socket and vice versa."
564,0,gitweb,"Gitweb provides a web interface to Git repositories. Its features
       include:

       â¢   Viewing multiple Git repositories with common root. â¢   Browsing every revision of the repository."
564,1,gitweb,"â¢   Browsing every revision of the repository. â¢   Viewing the contents of files in the repository at any
           revision. â¢   Viewing the revision log of branches, history of files and
           directories, seeing what was changed, when, and by whom."
564,2,gitweb,"â¢   Viewing the revision log of branches, history of files and
           directories, seeing what was changed, when, and by whom. â¢   Viewing the blame/annotation details of any file (if enabled). â¢   Generating RSS and Atom feeds of commits, for any branch."
564,3,gitweb,"â¢   Generating RSS and Atom feeds of commits, for any branch. The
           feeds are auto-discoverable in modern web browsers. â¢   Viewing everything that was changed in a revision, and
           stepping through revisions one at a time, viewing the history
           of the repository."
564,4,gitweb,"â¢   Viewing everything that was changed in a revision, and
           stepping through revisions one at a time, viewing the history
           of the repository. â¢   Finding commits whose commit messages match a given search
           term. See
https://repo.or.cz/w/git.git/tree/HEAD:/gitweb/
for gitweb
       source code, browsed using gitweb itself."
565,0,gnutls-serv,Server program that listens to incoming TLS connections.
566,0,gperl,nan
567,0,gpasswd,"The
gpasswd
command is used to administer /etc/group, and
       /etc/gshadow. Every group can have administrators, members and a
       password. System administrators can use the
-A
option to define group
       administrator(s) and the
-M
option to define members."
567,1,gpasswd,"System administrators can use the
-A
option to define group
       administrator(s) and the
-M
option to define members. They have
       all rights of group administrators and members. gpasswd
called by a group administrator with a group name only
       prompts for the new password of the
group
."
567,2,gpasswd,"gpasswd
called by a group administrator with a group name only
       prompts for the new password of the
group
. If a password is set the members can still use
newgrp(1)
without a
       password, and non-members must supply the password. Notes about group passwords
Group passwords are an inherent security problem since more than
       one person is permitted to know the password."
567,3,gpasswd,"If a password is set the members can still use
newgrp(1)
without a
       password, and non-members must supply the password. Notes about group passwords
Group passwords are an inherent security problem since more than
       one person is permitted to know the password. However, groups are
       a useful tool for permitting co-operation between different users."
568,0,git,"Git is a fast, scalable, distributed revision control system with
       an unusually rich command set that provides both high-level
       operations and full access to internals. See
gittutorial(7)
to get started, then see
giteveryday(7)
for a
       useful minimum set of commands. The
Git Userâs Manual
[1] has a
       more in-depth introduction."
568,1,git,"The
Git Userâs Manual
[1] has a
       more in-depth introduction. After you mastered the basic concepts, you can come back to this
       page to learn what commands Git offers. You can learn more about
       individual Git commands with ""git help command""."
568,2,git,"You can learn more about
       individual Git commands with ""git help command"". gitcli(7)
manual
       page gives you an overview of the command-line command syntax. A formatted and hyperlinked copy of the latest Git documentation
       can be viewed at
https://git.github.io/htmldocs/git.html
or
https://git-scm.com/docs
."
569,0,gpinyin,nan
570,0,gprof,"""gprof"" produces an execution profile of C, Pascal, or Fortran77
       programs. The effect of called routines is incorporated in the
       profile of each caller. The profile data is taken from the call
       graph profile file (
gmon.out
default) which is created by programs
       that are compiled with the
-pg
option of ""cc"", ""pc"", and ""f77""."
570,1,gprof,"The profile data is taken from the call
       graph profile file (
gmon.out
default) which is created by programs
       that are compiled with the
-pg
option of ""cc"", ""pc"", and ""f77"". The
-pg
option also links in versions of the library routines that
       are compiled for profiling. ""Gprof"" reads the given object file
       (the default is ""a.out"") and establishes the relation between its
       symbol table and the call graph profile from
gmon.out
."
570,2,gprof,"""Gprof"" reads the given object file
       (the default is ""a.out"") and establishes the relation between its
       symbol table and the call graph profile from
gmon.out
. If more
       than one profile file is specified, the ""gprof"" output shows the
       sum of the profile information in the given profile files. ""Gprof"" calculates the amount of time spent in each routine."
570,3,gprof,"""Gprof"" calculates the amount of time spent in each routine. Next, these times are propagated along the edges of the call
       graph. Cycles are discovered, and calls into a cycle are made to
       share the time of the cycle."
570,4,gprof,"Cycles are discovered, and calls into a cycle are made to
       share the time of the cycle. Several forms of output are available from the analysis. The
flat profile
shows how much time your program spent in each
       function, and how many times that function was called."
570,5,gprof,"The
flat profile
shows how much time your program spent in each
       function, and how many times that function was called. If you
       simply want to know which functions burn most of the cycles, it is
       stated concisely here. The
call graph
shows, for each function, which functions called
       it, which other functions it called, and how many times."
570,6,gprof,"The
call graph
shows, for each function, which functions called
       it, which other functions it called, and how many times. There is
       also an estimate of how much time was spent in the subroutines of
       each function. This can suggest places where you might try to
       eliminate function calls that use a lot of time."
570,7,gprof,"There is
       also an estimate of how much time was spent in the subroutines of
       each function. This can suggest places where you might try to
       eliminate function calls that use a lot of time. The
annotated source
listing is a copy of the program's source
       code, labeled with the number of times each line of the program
       was executed."
571,0,grap2graph,nan
572,0,grep,"The
grep
utility shall search the input files, selecting lines
       matching one or more patterns; the types of patterns are
       controlled by the options specified. The patterns are specified by
       the
-e
option,
-f
option, or the
pattern_list
operand. The
pattern_list
's value shall consist of one or more patterns
       separated by <newline> characters; the
pattern_file
's contents
       shall consist of one or more patterns terminated by a <newline>
       character."
572,1,grep,"The
pattern_list
's value shall consist of one or more patterns
       separated by <newline> characters; the
pattern_file
's contents
       shall consist of one or more patterns terminated by a <newline>
       character. By default, an input line shall be selected if any
       pattern, treated as an entire basic regular expression (BRE) as
       described in the Base Definitions volume of POSIX.1â2017,
Section
9.3
,
Basic Regular Expressions
, matches any part of the line
       excluding the terminating <newline>; a null BRE shall match every
       line. By default, each selected input line shall be written to the
       standard output."
572,2,grep,"By default, each selected input line shall be written to the
       standard output. Regular expression matching shall be based on text lines. Since a
       <newline> separates or terminates patterns (see the
-e
and
-f
options below), regular expressions cannot contain a <newline>."
572,3,grep,"Regular expression matching shall be based on text lines. Since a
       <newline> separates or terminates patterns (see the
-e
and
-f
options below), regular expressions cannot contain a <newline>. Similarly, since patterns are matched against individual lines
       (excluding the terminating <newline> characters) of the input,
       there is no way for a pattern to match a <newline> found in the
       input."
573,0,grn,nan
574,0,grodvi,nan
575,0,grep,"grep
searches for patterns in each
FILE
. In the synopsis's first
       form, which is used if no
-e
or
-f
options are present, the first
       operand
PATTERNS
is one or more patterns separated by newline
       characters, and
grep
prints each line that matches a pattern. Typically
PATTERNS
should be quoted when
grep
is used in a shell
       command."
575,1,grep,"Typically
PATTERNS
should be quoted when
grep
is used in a shell
       command. A
FILE
of â
-
â stands for standard input. If no
FILE
is given,
       recursive searches examine the working directory, and nonrecursive
       searches read standard input."
576,0,grolbp,nan
577,0,grog,nan
578,0,grohtml,nan
579,0,grolj4,nan
580,0,groff,nan
581,0,grotty,nan
582,0,groups,"Print group memberships for each USERNAME or, if no USERNAME is
       specified, for the current process (which may differ if the groups
       database has changed).
--help
display this help and exit
--version
output version information and exit"
583,0,grops,nan
584,0,guards,"The script reads a configuration file that may contain so-called
       guards, file names, and comments, and writes those file names that
       satisfy all guards to standard output. The script takes a list of
       symbols as its arguments. Each line in the configuration file is
       processed separately."
584,1,guards,"Each line in the configuration file is
       processed separately. Lines may start with a number of guards. The
       following guards are defined:

           +
xxx
Include the file(s) on this line if the symbol
xxx
is
           defined."
584,2,guards,"The
       following guards are defined:

           +
xxx
Include the file(s) on this line if the symbol
xxx
is
           defined. -
xxx
Exclude the file(s) on this line if the symbol
xxx
is
           defined. +!"
584,3,guards,"+! xxx
Include the file(s) on this line if the symbol
xxx
is
           not defined. -!"
584,4,guards,"-! xxx
Exclude the file(s) on this line if the symbol
xxx
is
           not defined. - Exclude this file."
584,5,guards,"- Exclude this file. Used to avoid spurious
--check
messages. The guards are processed left to right."
584,6,guards,"The guards are processed left to right. The last guard that
       matches determines if the file is included. If no guard is
       specified, the
--default
setting determines if the file is
       included."
584,7,guards,"If no guard is
       specified, the
--default
setting determines if the file is
       included. If no configuration file is specified, the script reads from
       standard input. The
--check
option is used to compare the specification file
       against the file system."
584,8,guards,"The
--check
option is used to compare the specification file
       against the file system. If files are referenced in the
       specification that do not exist, or if files are not enlisted in
       the specification file warnings are printed. The
--path
option can
       be used to specify which directory or directories to scan."
584,9,guards,"The
--path
option can
       be used to specify which directory or directories to scan. Multiple directories are separated by a colon ("":"") character. The
--prefix
option specifies the location of the files."
584,10,guards,"The
--prefix
option specifies the location of the files. Alternatively, the
--path=@<file>
syntax can be used to specify a
       file from which the file names will be read. Use
--list
to list all files independent of any rules."
584,11,guards,"Use
--list
to list all files independent of any rules. Use
--invert-match
to list only the excluded patches. Use
--with-guards
to also include all inclusion and exclusion rules."
585,0,gropdf,nan
586,0,hardlink,"hardlink
is a tool that replaces copies of a file with either
       hardlinks or copy-on-write clones, thus saving space. hardlink
first creates a binary tree of file sizes and then
       compares the content of files that have the same size. There are
       two basic content comparison methods."
586,1,hardlink,"There are
       two basic content comparison methods. The
memcmp
method directly
       reads data blocks from files and compares them. The other method
       is based on checksums (like SHA256); in this case for each data
       block a checksum is calculated by the Linux kernel crypto API, and
       this checksum is stored in userspace and used for file
       comparisons."
586,2,hardlink,"The other method
       is based on checksums (like SHA256); in this case for each data
       block a checksum is calculated by the Linux kernel crypto API, and
       this checksum is stored in userspace and used for file
       comparisons. For each file also an ""intro"" buffer (32 bytes) is cached. This
       buffer is used independently from the comparison method and
       requested cache-size and io-size."
586,3,hardlink,"For each file also an ""intro"" buffer (32 bytes) is cached. This
       buffer is used independently from the comparison method and
       requested cache-size and io-size. The ""intro"" buffer dramatically
       reduces operations with data content as files are very often
       different from the beginning."
587,0,gstack,"Print a stack trace of a running program with process ID
pid
. If
       the process is multi-threaded,
gstack
outputs backtraces for every
       thread which exists in the process. The script invokes GDB, attaches to the given process ID, prints
       the stack trace, and detaches from the process."
587,1,gstack,"If
       the process is multi-threaded,
gstack
outputs backtraces for every
       thread which exists in the process. The script invokes GDB, attaches to the given process ID, prints
       the stack trace, and detaches from the process. gstack
exits with non-zero status if ""gdb"" was unable to attach to
       the given process ID for any reason, such as a non-existent
       process ID or insufficient privileges to attach to the process."
588,0,gxditview,nan
589,0,hash,"The
hash
utility shall affect the way the current shell
       environment remembers the locations of utilities found as
       described in
Section 2.9.1.1
,
Command Search and Execution
. Depending on the arguments specified, it shall add utility
       locations to its list of remembered locations or it shall purge
       the contents of the list. When no arguments are specified, it
       shall report on the contents of the list."
589,1,hash,"Depending on the arguments specified, it shall add utility
       locations to its list of remembered locations or it shall purge
       the contents of the list. When no arguments are specified, it
       shall report on the contents of the list. Utilities provided as built-ins to the shell shall not be reported
       by
hash
."
590,0,head,"Print the first 10 lines of each FILE to standard output. With
       more than one FILE, precede each with a header giving the file
       name. With no FILE, or when FILE is -, read standard input."
590,1,head,"With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too. -c
,
--bytes
=
[-]NUM
print the first NUM bytes of each file; with the leading
              '-', print all but the last NUM bytes of each file
-n
,
--lines
=
[-]NUM
print the first NUM lines instead of the first 10; with the
              leading '-', print all but the last NUM lines of each file
-q
,
--quiet
,
--silent
never print headers giving file names
-v
,
--verbose
always print headers giving file names
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit

       NUM may have a multiplier suffix: b 512, kB 1000, K 1024, MB
       1000*1000, M 1024*1024, GB 1000*1000*1000, G 1024*1024*1024, and
       so on for T, P, E, Z, Y, R, Q."
590,2,head,"Mandatory arguments to long options are mandatory for short
       options too. -c
,
--bytes
=
[-]NUM
print the first NUM bytes of each file; with the leading
              '-', print all but the last NUM bytes of each file
-n
,
--lines
=
[-]NUM
print the first NUM lines instead of the first 10; with the
              leading '-', print all but the last NUM lines of each file
-q
,
--quiet
,
--silent
never print headers giving file names
-v
,
--verbose
always print headers giving file names
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit

       NUM may have a multiplier suffix: b 512, kB 1000, K 1024, MB
       1000*1000, M 1024*1024, GB 1000*1000*1000, G 1024*1024*1024, and
       so on for T, P, E, Z, Y, R, Q. Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on."
591,0,head,"The
head
utility shall copy its input files to the standard
       output, ending the output for each file at a designated point.

       Copying shall end at the point in each input file indicated by the
-n
number
option. The option-argument
number
shall be counted in
       units of lines."
592,0,hexdump,"The
hexdump
utility is a filter which displays the specified
       files, or standard input if no files are specified, in a
       user-specified format."
593,0,hostid,"Print the numeric identifier (in hexadecimal) for the current
       host.
--help
display this help and exit
--version
output version information and exit"
594,0,hostname,"Hostname
is the program that is used to either set or display the
       current host, domain or node name of the system. These names are
       used by many of the networking programs to identify the machine. The domain name is also used by NIS/YP."
594,1,hostname,"The domain name is also used by NIS/YP. GET NAME
When called without any arguments, the program displays the
       current names:
hostname
will print the name of the system as returned by the
gethostname(2)
function. domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function."
594,2,hostname,"domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function. This is also
       known as the YP/NIS domain name of the system. nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function."
594,3,hostname,"nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function. dnsdomainname
will print the domain part of the FQDN (Fully
       Qualified Domain Name). The complete FQDN of the system is
       returned with
hostname --fqdn
."
594,4,hostname,"The complete FQDN of the system is
       returned with
hostname --fqdn
. SET NAME
When called with one argument or with the
--file
option, the
       commands set the host name, the NIS/YP domain name or the node
       name. Note, that only the super-user can change the names."
594,5,hostname,"Note, that only the super-user can change the names. It is not possible to set the FQDN or the DNS domain name with the
dnsdomainname
command (see
THE FQDN
below). The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g."
594,6,hostname,"The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g. /etc/hostname
). THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command."
594,7,hostname,"THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command. The FQDN of the system is the name that the
resolver(3)
returns
       for the host name. Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name."
594,8,hostname,"Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name. The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it."
594,9,hostname,"The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it. If
hosts
is the first
       lookup method, you can change the FQDN in
/etc/hosts
."
595,0,hpftodit,nan
596,0,hostnamectl,"hostnamectl
may be used to query and change the system hostname
       and related settings. systemd-hostnamed.service(8)
and this tool distinguish three
       different hostnames: the high-level ""pretty"" hostname which might
       include all kinds of special characters (e.g. ""Lennart's Laptop""),
       the ""static"" hostname which is the user-configured hostname (e.g."
596,1,hostnamectl,"""Lennart's Laptop""),
       the ""static"" hostname which is the user-configured hostname (e.g. ""lennarts-laptop""), and the transient hostname which is a fallback
       value received from network configuration (e.g. ""node12345678"")."
596,2,hostnamectl,"""node12345678""). If a static hostname is set to a valid value, then the transient
       hostname is not used. Note that the pretty hostname has little restrictions on the
       characters and length used, while the static and transient
       hostnames are limited to the usually accepted characters of
       Internet domain names, and 64 characters at maximum (the latter
       being a Linux limitation)."
596,3,hostnamectl,"If a static hostname is set to a valid value, then the transient
       hostname is not used. Note that the pretty hostname has little restrictions on the
       characters and length used, while the static and transient
       hostnames are limited to the usually accepted characters of
       Internet domain names, and 64 characters at maximum (the latter
       being a Linux limitation). Use
systemd-firstboot(1)
to initialize the system hostname for
       mounted (but not booted) system images."
597,0,hugetop,"The
hugetop
command reports the huge page information of system
       and processes. It displays a summary of the system huge page
       status. For each process that has at least one huge page, the
       number of private and shared pages, along with the process PID and
       command name are displayed."
598,0,homectl,"homectl
may be used to create, remove, change or inspect a user's
       home directory. It's primarily a command interfacing with
systemd-homed.service(8)
which manages home directories of users. Home directories managed by systemd-homed.service are
       self-contained, and thus include the user's full metadata record
       in the home's data storage itself, making them easy to migrate
       between machines."
598,1,homectl,"Home directories managed by systemd-homed.service are
       self-contained, and thus include the user's full metadata record
       in the home's data storage itself, making them easy to migrate
       between machines. In particular, a home directory describes a
       matching user record, and every user record managed by
       systemd-homed.service also implies existence and encapsulation of
       a home directory. The user account and home directory become the
       same concept."
598,2,homectl,"The user account and home directory become the
       same concept. The following backing storage mechanisms are supported:

       â¢   An individual LUKS2 encrypted loopback file for a user, stored
           in /home/*.home. At login the file system contained in this
           files is mounted, after the LUKS2 encrypted volume has been
           attached."
598,3,homectl,"At login the file system contained in this
           files is mounted, after the LUKS2 encrypted volume has been
           attached. The user's password is identical to the encryption
           passphrase of the LUKS2 volume. Access to data without
           preceding user authentication is thus not possible, even for
           the system administrator."
598,4,homectl,"Access to data without
           preceding user authentication is thus not possible, even for
           the system administrator. This storage mechanism provides the
           strongest data security and is thus recommended. â¢   Similar, but the LUKS2 encrypted file system is located on
           regular block device, such as a USB storage stick."
598,5,homectl,"â¢   Similar, but the LUKS2 encrypted file system is located on
           regular block device, such as a USB storage stick. In this
           mode home directories and all data they include are nicely
           migratable between machines, simply by plugging the USB stick
           into different systems at different times. â¢   An encrypted directory using ""fscrypt"" on file systems that
           support it (at the moment this is primarily ""ext4""), located
           in /home/*.homedir."
598,6,homectl,"â¢   An encrypted directory using ""fscrypt"" on file systems that
           support it (at the moment this is primarily ""ext4""), located
           in /home/*.homedir. This mechanism also provides encryption,
           but substantially weaker than LUKS2, as most file system
           metadata is unprotected. Moreover it currently does not
           support changing user passwords once the home directory has
           been created."
598,7,homectl,"Moreover it currently does not
           support changing user passwords once the home directory has
           been created. â¢   A ""btrfs"" subvolume for each user, also located in
           /home/*.homedir. This provides no encryption, but good quota
           support."
598,8,homectl,"This provides no encryption, but good quota
           support. â¢   A regular directory for each user, also located in
           /home/*.homedir. This provides no encryption, but is a
           suitable fallback available on all machines, even where LUKS2,
           ""fscrypt"" or ""btrfs"" support is not available."
598,9,homectl,"This provides no encryption, but is a
           suitable fallback available on all machines, even where LUKS2,
           ""fscrypt"" or ""btrfs"" support is not available. â¢   An individual Windows file share (CIFS) for each user. Note that systemd-homed.service and
homectl
will not manage
       ""classic"" UNIX user accounts as created with
useradd(8)
or similar
       tools."
598,10,homectl,"Note that systemd-homed.service and
homectl
will not manage
       ""classic"" UNIX user accounts as created with
useradd(8)
or similar
       tools. In particular, this functionality is not suitable for
       managing system users (i.e. users with a UID below 1000) but is
       exclusive to regular (""human"") users."
598,11,homectl,"users with a UID below 1000) but is
       exclusive to regular (""human"") users. Note that users/home directories managed via
systemd-homed.service
do not show up in /etc/passwd and similar files, they are
       synthesized via glibc NSS during runtime. They are thus resolvable
       and may be enumerated via the
getent(1)
tool."
598,12,homectl,"They are thus resolvable
       and may be enumerated via the
getent(1)
tool. This tool interfaces directly with systemd-homed.service, and may
       execute specific commands on the home directories it manages. Since every home directory managed that way also defines a JSON
       user and group record these home directories may also be inspected
       and enumerated via
userdbctl(1)
."
598,13,homectl,"Since every home directory managed that way also defines a JSON
       user and group record these home directories may also be inspected
       and enumerated via
userdbctl(1)
. Home directories managed by systemd-homed.service are usually in
       one of two states, or in a transition state between them: when
       ""active"" they are unlocked and mounted, and thus accessible to the
       system and its programs; when ""inactive"" they are not mounted and
       thus not accessible. Activation happens automatically at login of
       the user and usually can only complete after a password (or other
       authentication token) has been supplied."
598,14,homectl,"Activation happens automatically at login of
       the user and usually can only complete after a password (or other
       authentication token) has been supplied. Deactivation happens
       after the user fully logged out. A home directory remains active
       as long as the user is logged in at least once, i.e."
598,15,homectl,"A home directory remains active
       as long as the user is logged in at least once, i.e. has at least
       one login session. When the user logs in a second time
       simultaneously the home directory remains active."
598,16,homectl,"has at least
       one login session. When the user logs in a second time
       simultaneously the home directory remains active. It is
       deactivated only after the last of the user's sessions ends."
599,0,htop,"htop
is a cross-platform ncurses-based process viewer. It is similar to
top
, but allows you to scroll vertically and
       horizontally, and interact using a pointing device (mouse). You
       can observe all processes running on the system, along with their
       command line arguments, as well as view them in a tree format,
       select multiple processes and act on them all at once."
599,1,htop,"You
       can observe all processes running on the system, along with their
       command line arguments, as well as view them in a tree format,
       select multiple processes and act on them all at once. Tasks related to processes (killing, renicing) can be done without
       entering their PIDs. pcp-htop
is a version of
htop
built using the Performance Co-Pilot
       (PCP) Metrics API (see
PCPIntro(1)
,
PMAPI(3)
), allowing to extend
htop
to display values from arbitrary metrics."
599,2,htop,"Tasks related to processes (killing, renicing) can be done without
       entering their PIDs. pcp-htop
is a version of
htop
built using the Performance Co-Pilot
       (PCP) Metrics API (see
PCPIntro(1)
,
PMAPI(3)
), allowing to extend
htop
to display values from arbitrary metrics. See the section
       below titled
CONFIG FILES
for further details."
600,0,ibv_asyncwatch,"Display asynchronous events forwarded to userspace for an RDMA
       device."
601,0,ib_acme,"ib_acme provides assistance configuring and testing the ibacm
       service.  The first usage of the service will test that the ibacm
       is running and operating correctly.  The second usage model will
       automatically create address and configuration files for the ibacm
       service."
602,0,ibv_devinfo,"Print information about RDMA devices available for use from
       userspace."
603,0,ibv_uc_pingpong,"Run a simple ping-pong test over InfiniBand via the unreliable
       connected (UC) transport."
604,0,ibv_rc_pingpong,"Run a simple ping-pong test over InfiniBand via the reliable
       connected (RC) transport."
605,0,ibv_srq_pingpong,"Run a simple ping-pong test over InfiniBand via the reliable
       connected (RC) transport, using multiple queue pairs (QPs) and a
       single shared receive queue (SRQ)."
606,0,ibv_devices,List RDMA devices available for use from userspace.
607,0,ibv_ud_pingpong,"Run a simple ping-pong test over InfiniBand via the unreliable
       datagram (UD) transport."
608,0,hg,"The
hg
command provides a command line interface to the Mercurial
       system."
609,0,ibv_xsrq_pingpong,"Run a simple ping-pong test over InfiniBand via the extended
       reliable connected (XRC) transport service, using a shared receive
       queue (SRQ)."
610,0,iconv,"The
iconv
utility shall convert the encoding of characters in
file
from one codeset to another and write the results to standard
       output.

       When the options indicate that charmap files are used to specify
       the codesets (see OPTIONS), the codeset conversion shall be
       accomplished by performing a logical join on the symbolic
       character names in the two charmaps. The implementation need not
       support the use of charmap files for codeset conversion unless the
       POSIX2_LOCALEDEF symbol is defined on the system."
611,0,iconv,"The
iconv
program reads in text in one encoding and outputs the
       text in another encoding. If no input files are given, or if it
       is given as a dash (-),
iconv
reads from standard input. If no
       output file is given,
iconv
writes to standard output."
611,1,iconv,"If no
       output file is given,
iconv
writes to standard output. If no
from-encoding
is given, the default is derived from the
       current locale's character encoding. If no
to-encoding
is given,
       the default is derived from the current locale's character
       encoding."
612,0,icuexportdata,nan
613,0,id,"Print user and group information for each specified USER, or (when
       USER omitted) for the current process.
-a
ignore, for compatibility with other versions
-Z
,
--context
print only the security context of the process
-g
,
--group
print only the effective group ID
-G
,
--groups
print all group IDs
-n
,
--name
print a name instead of a number, for
-ugG
-r
,
--real
print the real ID instead of the effective ID, with
-ugG
-u
,
--user
print only the effective user ID
-z
,
--zero
delimit entries with NUL characters, not whitespace;

              not permitted in default format
--help
display this help and exit
--version
output version information and exit

       Without any OPTION, print some useful set of identified
       information."
614,0,id,"If no
user
operand is provided, the
id
utility shall write the
       user and group IDs and the corresponding user and group names of
       the invoking process to standard output. If the effective and real
       IDs do not match, both shall be written. If multiple groups are
       supported by the underlying system (see the description of
       {NGROUPS_MAX} in the System Interfaces volume of POSIX.1â2017),
       the supplementary group affiliations of the invoking process shall
       also be written."
614,1,id,"If multiple groups are
       supported by the underlying system (see the description of
       {NGROUPS_MAX} in the System Interfaces volume of POSIX.1â2017),
       the supplementary group affiliations of the invoking process shall
       also be written. If a
user
operand is provided and the process has appropriate
       privileges, the user and group IDs of the selected user shall be
       written. In this case, effective IDs shall be assumed to be
       identical to real IDs."
614,2,id,"If a
user
operand is provided and the process has appropriate
       privileges, the user and group IDs of the selected user shall be
       written. In this case, effective IDs shall be assumed to be
       identical to real IDs. If the selected user has more than one
       allowable group membership listed in the group database, these
       shall be written in the same manner as the supplementary groups
       described in the preceding paragraph."
615,0,indomcachectl,"indomcachectl
assists in the management of the Instance Domain
       cache files that are stored in
$PCP_VAR_DIR/config/pmda
. The mandatory
indom
parameter uses a 2-dotted format to specify
       the
domain
and
serial
fields of the instance domain number. The
       required values can be reported for a particular metric using the
-d
option to
pminfo(1)
."
615,1,indomcachectl,"The
       required values can be reported for a particular metric using the
-d
option to
pminfo(1)
. The list of available options can be retrieved using the
-? /
--help
option, which displays a usage message and exits."
615,2,indomcachectl,"/
--help
option, which displays a usage message and exits. If the
-l
/
--list
option is specified the contents of the instance
       domain cache file are dumped on
stdout
and
indomcachectl
exits. Otherwise an empty instance domain cache file will be created."
615,3,indomcachectl,"Otherwise an empty instance domain cache file will be created. The user ownership of the created file is assigned to the uid of
       the caller, but may optionally assigned to the uid of
user
from
       the
passwd(5)
file if the
-u
/
--user
option is specified. The
       group ownership of the created file is assigned to the gid of the
       caller, else the default gid of the user
user
if the
-u
option is
       specified, else the gid of
group
from the
group(5)
file if the
-g
/
--group
option is specified."
615,4,indomcachectl,"The
       group ownership of the created file is assigned to the gid of the
       caller, else the default gid of the user
user
if the
-u
option is
       specified, else the gid of
group
from the
group(5)
file if the
-g
/
--group
option is specified. The instance domain cache file is created with mode 0660 by
       default (some PMDAs use group read-write permission to access and
       update the contents of the file) - if this does not suit the
-m
/
--mode
option may be used to set the mode to the (octal) value
mode
. Because the indom cache files are precious to the associated PMDA
indomcachectl
will not over-write an existing indom cache file."
615,5,indomcachectl,"Because the indom cache files are precious to the associated PMDA
indomcachectl
will not over-write an existing indom cache file. Operation is usually silent, except for errors (or warnings if the
-w
/
--warning
option is used). The exit status is 0 for success, 1
       for failure."
616,0,importctl,"importctl
may be used to download, import, and export disk images
       via
systemd-importd.service(8)
. importctl
operates both on block-level disk images (such as DDIs)
       as well as file-system-level images (tarballs). It supports disk
       images in one of the four following classes:

       â¢   VM images or full OS container images, that may be run via
systemd-vmspawn(1)
or
systemd-nspawn(1)
, and managed via
machinectl(1)
."
616,1,importctl,"It supports disk
       images in one of the four following classes:

       â¢   VM images or full OS container images, that may be run via
systemd-vmspawn(1)
or
systemd-nspawn(1)
, and managed via
machinectl(1)
. â¢   Portable service images, that may be attached and managed via
portablectl(1)
. â¢   System extension (sysext) images, that may be activated via
systemd-sysext(8)
."
616,2,importctl,"â¢   System extension (sysext) images, that may be activated via
systemd-sysext(8)
. â¢   Configuration extension (confext) images, that may be
           activated via
systemd-confext(8)
. When images are downloaded or imported they are placed in the
       following directories, depending on the
--class=
parameter:
Table 1."
616,3,importctl,"â¢   Configuration extension (confext) images, that may be
           activated via
systemd-confext(8)
. When images are downloaded or imported they are placed in the
       following directories, depending on the
--class=
parameter:
Table 1. Classes and Directories
ââââââââââââââ¬âââââââââââââââââââââââ
       â
Class
â
Directory
â
       ââââââââââââââ¼âââââââââââââââââââââââ¤
       â ""machine""  â /var/lib/machines/   â
       ââââââââââââââ¼âââââââââââââââââââââââ¤
       â ""portable"" â /var/lib/portables/  â
       ââââââââââââââ¼âââââââââââââââââââââââ¤
       â ""sysext""   â /var/lib/extensions/ â
       ââââââââââââââ¼âââââââââââââââââââââââ¤
       â ""confext""  â /var/lib/confexts/   â
       ââââââââââââââ´âââââââââââââââââââââââ"
617,0,indxbib,nan
618,0,indent,"This man page is generated from the file
indent.texinfo
. This is
       Edition  of ""The
indent
Manual"", for Indent Version , last updated
       . The
indent
program can be used to make code easier to read."
618,1,indent,"The
indent
program can be used to make code easier to read. It
       can also convert from one style of writing C to another. indent
understands a substantial amount about the syntax of C, but
       it also attempts to cope with incomplete and misformed syntax."
618,2,indent,"It
       can also convert from one style of writing C to another. indent
understands a substantial amount about the syntax of C, but
       it also attempts to cope with incomplete and misformed syntax. In version 1.2 and more recent versions, the GNU style of
       indenting is the default."
619,0,innochecksum,"innochecksum
prints checksums for InnoDB files. This tool reads an
       InnoDB tablespace file, calculates the checksum for each page,
       compares the calculated checksum to the stored checksum, and
       reports mismatches, which indicate damaged pages. It was
       originally developed to speed up verifying the integrity of
       tablespace files after power outages but can also be used after
       file copies."
619,1,innochecksum,"It was
       originally developed to speed up verifying the integrity of
       tablespace files after power outages but can also be used after
       file copies. Because checksum mismatches will cause InnoDB to
       deliberately shut down a running server, it can be preferable to
       use this tool rather than waiting for a server in production usage
       to encounter the damaged pages. innochecksum
cannot be used on tablespace files that the server
       already has open."
619,2,innochecksum,"innochecksum
cannot be used on tablespace files that the server
       already has open. For such files, you should use CHECK TABLE to
       check tables within the tablespace. If checksum mismatches are found, you would normally restore the
       tablespace from backup or start the server and attempt to use
mariadb-dump
to make a backup of the tables within the tablespace."
619,3,innochecksum,"If checksum mismatches are found, you would normally restore the
       tablespace from backup or start the server and attempt to use
mariadb-dump
to make a backup of the tables within the tablespace. Invoke
innochecksum
like this:

           shell>
innochecksum [
options
]
file_name
innochecksum
supports the following options. For options that
       refer to page numbers, the numbers are zero-based."
619,4,innochecksum,"For options that
       refer to page numbers, the numbers are zero-based. â¢
-?, --help
Displays help and exits. â¢
-a
num
, --allow-mismatches=#
Maximum checksum mismatch allowed before innochecksum
           terminates."
619,5,innochecksum,"â¢
-a
num
, --allow-mismatches=#
Maximum checksum mismatch allowed before innochecksum
           terminates. Defaults to 0, which terminates on the first
           mismatch. â¢
-c, --count
Print a count of the number of pages in the file."
619,6,innochecksum,"â¢
-c, --count
Print a count of the number of pages in the file. â¢
-e
num
, --end-page=#
End at this page number. â¢
-i, --per-page-details
Print out per-page detail information."
619,7,innochecksum,"â¢
-i, --per-page-details
Print out per-page detail information. â¢
-I, --info
Synonym for
--help
. â¢
-f, --leaf
Examine leaf index pages."
619,8,innochecksum,"â¢
-f, --leaf
Examine leaf index pages. â¢
-l
fn
, --log=fn
Log output to the specified filename, fn. â¢
-m
num
, --merge=#
Leaf page count if merge given number of consecutive pages."
619,9,innochecksum,"â¢
-m
num
, --merge=#
Leaf page count if merge given number of consecutive pages. â¢
-n, --no-check
Ignore the checksum verification. Until MariaDB 10.6, must be
           used with the --write option."
619,10,innochecksum,"Until MariaDB 10.6, must be
           used with the --write option. â¢
-p
num
, --page-num=#
Check only this page number. â¢
-D
name
, --page-type-dump=name
Dump the page type info for each page in a tablespace."
619,11,innochecksum,"â¢
-D
name
, --page-type-dump=name
Dump the page type info for each page in a tablespace. â¢
-S, --page-type-summary
Display a count of each page type in a tablespace. â¢
-s
num
, --start-page
Start at this page number."
619,12,innochecksum,"â¢
-s
num
, --start-page
Start at this page number. â¢
-u, --skip-corrupt
Skip corrupt pages. â¢
-C
name
, --strict-check=name
Specify the strict checksum algorithm."
619,13,innochecksum,"â¢
-C
name
, --strict-check=name
Specify the strict checksum algorithm. One of: crc32, innodb,
           none. If not specified, validates against innodb, crc32 and
           none."
619,14,innochecksum,"If not specified, validates against innodb, crc32 and
           none. Removed in MariaDB 10.6. â¢
-w
name
, --write=name
Rewrite the checksum algorithm."
619,15,innochecksum,"â¢
-w
name
, --write=name
Rewrite the checksum algorithm. One of crc32, innodb, none. An
           exclusive lock is obtained during use."
619,16,innochecksum,"An
           exclusive lock is obtained during use. Use in conjunction with
           the -no-check option to rewrite an invalid checksum. Removed
           in MariaDB 10.6."
619,17,innochecksum,"Removed
           in MariaDB 10.6. â¢
-v, --verbose
Verbose mode; print a progress indicator every five seconds. â¢
-V, --version
Displays version information and exits."
620,0,systemd,"systemd is a system and service manager for Linux operating
       systems. When run as first process on boot (as PID 1), it acts as
       init system that brings up and maintains userspace services. Separate instances are started for logged-in users to start their
       services."
620,1,systemd,"Separate instances are started for logged-in users to start their
       services. systemd
is usually not invoked directly by the user, but is
       installed as the /sbin/init symlink and started during early boot. The user manager instances are started automatically through the
user@.service(5)
service."
620,2,systemd,"The user manager instances are started automatically through the
user@.service(5)
service. For compatibility with SysV, if the binary is called as
init
and
       is not the first process on the machine (PID is not 1), it will
       execute
telinit
and pass all command line arguments unmodified. That means
init
and
telinit
are mostly equivalent when invoked
       from normal login sessions."
620,3,systemd,"That means
init
and
telinit
are mostly equivalent when invoked
       from normal login sessions. See
telinit(8)
for more information. When run as a system instance, systemd interprets the
       configuration file system.conf and the files in system.conf.d
       directories; when run as a user instance, systemd interprets the
       configuration file user.conf and the files in user.conf.d
       directories."
620,4,systemd,"When run as a system instance, systemd interprets the
       configuration file system.conf and the files in system.conf.d
       directories; when run as a user instance, systemd interprets the
       configuration file user.conf and the files in user.conf.d
       directories. See
systemd-system.conf(5)
for more information. systemd
contains native implementations of various tasks that need
       to be executed as part of the boot process."
620,5,systemd,"systemd
contains native implementations of various tasks that need
       to be executed as part of the boot process. For example, it sets
       the hostname or configures the loopback network device. It also
       sets up and mounts various API file systems, such as /sys/,
       /proc/, and /dev/."
620,6,systemd,"It also
       sets up and mounts various API file systems, such as /sys/,
       /proc/, and /dev/. systemd
will also reset the system clock during early boot if it
       appears to be set incorrectly. See ""System clock epoch"" section
       below."
620,7,systemd,"See ""System clock epoch"" section
       below. Note that some but not all interfaces provided by systemd are
       covered by the
Interface Portability and Stability Promise
[1]. The D-Bus API of
systemd
is described in
org.freedesktop.systemd1(5)
and
org.freedesktop.LogControl1(5)
."
620,8,systemd,"Note that some but not all interfaces provided by systemd are
       covered by the
Interface Portability and Stability Promise
[1]. The D-Bus API of
systemd
is described in
org.freedesktop.systemd1(5)
and
org.freedesktop.LogControl1(5)
. Systems which invoke systemd in a container or initrd environment
       should implement the
Container Interface
[2] or
initrd Interface
[3]
       specifications, respectively."
621,0,inotifywait,"inotifywait
efficiently waits for changes to files using Linux's
inotify(7)
interface by default. It is suitable for waiting for
       changes to files from shell scripts. It can either exit once an
       event occurs, or continually execute and output events as they
       occur."
621,1,inotifywait,"It can either exit once an
       event occurs, or continually execute and output events as they
       occur. fsnotifywait
is similar to
inotifywait
but it is using Linux's
fanotify(7)
interface by default. If explicitly specified, it uses
       the
inotify(7)
interface."
622,0,inotifywatch,"inotifywatch
listens for filesystem events using Linux's
inotify(7)
interface by default, then outputs a summary count of
       the events received on each file or directory.
fsnotifywatch
is similar to
inotifywatch
but it is using Linux's
fanotify(7)
interface by default. If explicitly specified, it uses
       the
inotify(7)
interface."
623,0,install,"This install program copies files (often just compiled) into
       destination locations you choose. If you want to download and
       install a ready-to-use package on a GNU/Linux system, you should
       instead be using a package manager like
yum
(1) or
apt-get
(1). In the first three forms, copy SOURCE to DEST or multiple
       SOURCE(s) to the existing DIRECTORY, while setting permission
       modes and owner/group."
623,1,install,"In the first three forms, copy SOURCE to DEST or multiple
       SOURCE(s) to the existing DIRECTORY, while setting permission
       modes and owner/group. In the 4th form, create all components of
       the given DIRECTORY(ies). Mandatory arguments to long options are mandatory for short
       options too."
623,2,install,"Mandatory arguments to long options are mandatory for short
       options too. --backup
[=
CONTROL
]
              make a backup of each existing destination file
-b
like
--backup
but does not accept an argument
-c
(ignored)
-C
,
--compare
compare content of source and destination files, and if no
              change to content, ownership, and permissions, do not
              modify the destination at all
-d
,
--directory
treat all arguments as directory names; create all
              components of the specified directories
-D
create all leading components of DEST except the last, or
              all components of
--target-directory
, then copy SOURCE to
              DEST
--debug
explain how a file is copied. Implies
-v
-g
,
--group
=
GROUP
set group ownership, instead of process' current group
-m
,
--mode
=
MODE
set permission mode (as in chmod), instead of rwxr-xr-x
-o
,
--owner
=
OWNER
set ownership (super-user only)
-p
,
--preserve-timestamps
apply access/modification times of SOURCE files to
              corresponding destination files
-s
,
--strip
strip symbol tables
--strip-program
=
PROGRAM
program used to strip binaries
-S
,
--suffix
=
SUFFIX
override the usual backup suffix
-t
,
--target-directory
=
DIRECTORY
copy all SOURCE arguments into DIRECTORY
-T
,
--no-target-directory
treat DEST as a normal file
-v
,
--verbose
print the name of each created file or directory
--preserve-context
preserve SELinux security context
-Z
set SELinux security context of destination file and each
              created directory to default type
--context
[=
CTX
]
              like
-Z
, or if CTX is specified then set the SELinux or
              SMACK security context to CTX
--help
display this help and exit
--version
output version information and exit

       The backup suffix is '~', unless set with
--suffix
or
       SIMPLE_BACKUP_SUFFIX."
623,3,install,"Implies
-v
-g
,
--group
=
GROUP
set group ownership, instead of process' current group
-m
,
--mode
=
MODE
set permission mode (as in chmod), instead of rwxr-xr-x
-o
,
--owner
=
OWNER
set ownership (super-user only)
-p
,
--preserve-timestamps
apply access/modification times of SOURCE files to
              corresponding destination files
-s
,
--strip
strip symbol tables
--strip-program
=
PROGRAM
program used to strip binaries
-S
,
--suffix
=
SUFFIX
override the usual backup suffix
-t
,
--target-directory
=
DIRECTORY
copy all SOURCE arguments into DIRECTORY
-T
,
--no-target-directory
treat DEST as a normal file
-v
,
--verbose
print the name of each created file or directory
--preserve-context
preserve SELinux security context
-Z
set SELinux security context of destination file and each
              created directory to default type
--context
[=
CTX
]
              like
-Z
, or if CTX is specified then set the SELinux or
              SMACK security context to CTX
--help
display this help and exit
--version
output version information and exit

       The backup suffix is '~', unless set with
--suffix
or
       SIMPLE_BACKUP_SUFFIX. The version control method may be selected
       via the
--backup
option or through the VERSION_CONTROL environment
       variable. Here are the values:

       none, off
              never make backups (even if
--backup
is given)

       numbered, t
              make numbered backups

       existing, nil
              numbered if numbered backups exist, simple otherwise

       simple, never
              always make simple backups"
624,0,iostat,"The
iostat
command is used for monitoring system input/output
       device loading by observing the time the devices are active in
       relation to their average transfer rates. The
iostat
command
       generates reports that can be used to change system configuration
       to better balance the input/output load between physical disks. The first report generated by the
iostat
command provides
       statistics concerning the time since the system was booted, unless
       the
-y
option is used (in this case, this first report is
       omitted)."
624,1,iostat,"The first report generated by the
iostat
command provides
       statistics concerning the time since the system was booted, unless
       the
-y
option is used (in this case, this first report is
       omitted). Each subsequent report covers the time since the
       previous report. All statistics are reported each time the
iostat
command is run."
624,2,iostat,"All statistics are reported each time the
iostat
command is run. The report consists of a CPU header row followed
       by a row of CPU statistics. On multiprocessor systems, CPU
       statistics are calculated system-wide as averages among all
       processors."
624,3,iostat,"On multiprocessor systems, CPU
       statistics are calculated system-wide as averages among all
       processors. A device header row is displayed followed by a line of
       statistics for each device that is configured. The
interval
parameter specifies the amount of time in seconds
       between each report."
624,4,iostat,"The
interval
parameter specifies the amount of time in seconds
       between each report. The
count
parameter can be specified in
       conjunction with the
interval
parameter. If the
count
parameter is
       specified, the value of
count
determines the number of reports
       generated at
interval
seconds apart."
624,5,iostat,"The
count
parameter can be specified in
       conjunction with the
interval
parameter. If the
count
parameter is
       specified, the value of
count
determines the number of reports
       generated at
interval
seconds apart. If the
interval
parameter is
       specified without the
count
parameter, the
iostat
command
       generates reports continuously."
625,0,intro,"Section 1 of the manual describes user commands and tools, for
       example, file manipulation tools, shells, compilers, web browsers,
       file and image viewers and editors, and so on."
626,0,ionice,"This program sets or gets the I/O scheduling class and priority
       for a program. If no arguments or just
-p
is given,
ionice
will
       query the current I/O scheduling class and priority for that
       process. When
command
is given,
ionice
will run this command with the given
       arguments."
626,1,ionice,"When
command
is given,
ionice
will run this command with the given
       arguments. If no
class
is specified, then
command
will be executed
       with the ""best-effort"" scheduling class. The default priority
       level is 4."
626,2,ionice,"The default priority
       level is 4. As of this writing, a process can be in one of three scheduling
       classes:
Idle
A program running with idle I/O priority will only get disk
           time when no other program has asked for disk I/O for a
           defined grace period. The impact of an idle I/O process on
           normal system activity should be zero."
626,3,ionice,"The impact of an idle I/O process on
           normal system activity should be zero. This scheduling class
           does not take a priority argument. Presently, this scheduling
           class is permitted for an ordinary user (since kernel 2.6.25)."
626,4,ionice,"Presently, this scheduling
           class is permitted for an ordinary user (since kernel 2.6.25). Best-effort
This is the effective scheduling class for any process that
           has not asked for a specific I/O priority. This class takes a
           priority argument from
0-7
, with a lower number being higher
           priority."
626,5,ionice,"This class takes a
           priority argument from
0-7
, with a lower number being higher
           priority. Programs running at the same best-effort priority
           are served in a round-robin fashion. Note that before kernel 2.6.26 a process that has not asked
           for an I/O priority formally uses ""
none
"" as scheduling class,
           but the I/O scheduler will treat such processes as if it were
           in the best-effort class."
626,6,ionice,"Note that before kernel 2.6.26 a process that has not asked
           for an I/O priority formally uses ""
none
"" as scheduling class,
           but the I/O scheduler will treat such processes as if it were
           in the best-effort class. The priority within the best-effort
           class will be dynamically derived from the CPU nice level of
           the process: io_priority = (cpu_nice + 20) / 5. For kernels after 2.6.26 with the CFQ I/O scheduler, a process
           that has not asked for an I/O priority inherits its CPU
           scheduling class."
626,7,ionice,"For kernels after 2.6.26 with the CFQ I/O scheduler, a process
           that has not asked for an I/O priority inherits its CPU
           scheduling class. The I/O priority is derived from the CPU
           nice level of the process (same as before kernel 2.6.26). Realtime
The RT scheduling class is given first access to the disk,
           regardless of what else is going on in the system."
626,8,ionice,"Realtime
The RT scheduling class is given first access to the disk,
           regardless of what else is going on in the system. Thus the RT
           class needs to be used with some care, as it can starve other
           processes. As with the best-effort class, 8 priority levels
           are defined denoting how big a time slice a given process will
           receive on each scheduling window."
626,9,ionice,"Thus the RT
           class needs to be used with some care, as it can starve other
           processes. As with the best-effort class, 8 priority levels
           are defined denoting how big a time slice a given process will
           receive on each scheduling window. This scheduling class is
           not permitted for an ordinary (i.e., non-root) user."
627,0,iostat2pcp,"iostat2pcp
reads a text file created with
iostat(1)
(
infile
) and
       translates this into a Performance Co-Pilot (PCP) archive with the
       basename
outfile
. If
infile
is ``-'' then
iostat2pcp
reads from
       standard input, allowing easy preprocessing of the
iostat(1)
output with
sed(1)
or similar. The resultant PCP archive may be used with all the PCP client
       tools to graph subsets of the data using
pmchart(1)
, perform data
       reduction and reporting, filter with the PCP inference engine
pmie(1)
, etc."
627,1,iostat2pcp,"The resultant PCP archive may be used with all the PCP client
       tools to graph subsets of the data using
pmchart(1)
, perform data
       reduction and reporting, filter with the PCP inference engine
pmie(1)
, etc. A series of physical files will be created with the prefix
outfile
. These are
outfile
.0
(the performance data),
outfile
.meta
(the metadata that describes the performance data) and
outfile
.index
(a temporal index to improve efficiency of replay
       operations for the archive)."
627,2,iostat2pcp,"These are
outfile
.0
(the performance data),
outfile
.meta
(the metadata that describes the performance data) and
outfile
.index
(a temporal index to improve efficiency of replay
       operations for the archive). If any of these files exists
       already, then
iostat2pcp
will
not
overwrite them and will exit
       with an error message. The first output sample from
iostat(1)
contains a statistical
       summary since boot time and is ignored by
iostat2pcp
, so the first
       real data set is the second one in the
iostat(1)
output."
627,3,iostat2pcp,"The first output sample from
iostat(1)
contains a statistical
       summary since boot time and is ignored by
iostat2pcp
, so the first
       real data set is the second one in the
iostat(1)
output. The best results are obtained when
iostat(1)
was run with its own
-t
flag, so each output sample is prefixed with a timestamp. Even
       better is
-t
with $
S_TIME_FORMAT=ISO
set in environment when
iostat(1)
is run, in which case the timestamp includes the
       timezone."
627,4,iostat2pcp,"Even
       better is
-t
with $
S_TIME_FORMAT=ISO
set in environment when
iostat(1)
is run, in which case the timestamp includes the
       timezone. Note that if $
S_TIME_FORMAT=ISO
is
not
used with the
-t
option
       then
iostat(1)
may produce a timestamp controlled by
LC_TIME
from
       the locale that is in a format
iostat2pcp
cannot parse. The
       formats for the timestamp that
iostat2pcp
accepts are illustrated
       by these examples:
2013-07-06T21:34:39+1000
(for the $
S_TIME_FORMAT=ISO
)."
627,5,iostat2pcp,"The
       formats for the timestamp that
iostat2pcp
accepts are illustrated
       by these examples:
2013-07-06T21:34:39+1000
(for the $
S_TIME_FORMAT=ISO
). 2013-07-06 21:34:39
(for some of the European formats, e.g. de_AT, de_BE, de_LU
           and en_DK.utf8)."
627,6,iostat2pcp,"de_AT, de_BE, de_LU
           and en_DK.utf8). 06/07/13 21:34:39
(for all of the $
LC_TIME
settings for English locales outside
           North America, e.g. en_AU, en_GB, en_IE, en_NZ, en_SG and
           en_ZA, and all the Spanish locales, e.g."
627,7,iostat2pcp,"en_AU, en_GB, en_IE, en_NZ, en_SG and
           en_ZA, and all the Spanish locales, e.g. es_ES, es_MX and
           es_AR). In particular, note that some common North American $
LC_TIME
settings will
not
work with
iostat2pcp
(namely, en_US, POSIX and
       C) because they use the MM/DD format which may be incorrectly
       converted with the assumed DD/MM format."
627,8,iostat2pcp,"In particular, note that some common North American $
LC_TIME
settings will
not
work with
iostat2pcp
(namely, en_US, POSIX and
       C) because they use the MM/DD format which may be incorrectly
       converted with the assumed DD/MM format. This is another reason
       to recommend setting $
S_TIME_FORMAT=ISO
. If there are no timestamps in the input stream,
iostat2pcp
will
       try and deduce the sample interval if basic Disk data (
-d
option
       for
iostat(1)
) is found."
627,9,iostat2pcp,"If there are no timestamps in the input stream,
iostat2pcp
will
       try and deduce the sample interval if basic Disk data (
-d
option
       for
iostat(1)
) is found. If this fails, then the
-t
option may be
       used to specify the sample
interval
in seconds. This option is
       ignored if timestamps are found in the input stream."
627,10,iostat2pcp,"This option is
       ignored if timestamps are found in the input stream. The
-S
option may be used to specify as start time for the first
       real sample in
infile
, where
start
must have the format HH:MM:SS. This option is ignored if timestamps are found in the input
       stream."
627,11,iostat2pcp,"This option is ignored if timestamps are found in the input
       stream. The
-V
option specifies the version for the output PCP archive. By default the archive version
$PCP_ARCHIVE_VERSION
(set to 3 in
       current PCP releases) is used, and the only values currently
       supported for
version
are 2 or 3."
627,12,iostat2pcp,"By default the archive version
$PCP_ARCHIVE_VERSION
(set to 3 in
       current PCP releases) is used, and the only values currently
       supported for
version
are 2 or 3. The
-Z
option may be used to specify a timezone. It must have the
       format +HHMM (for hours and minutes East of UTC) or -HHMM (for
       hours and minutes West of UTC)."
627,13,iostat2pcp,"It must have the
       format +HHMM (for hours and minutes East of UTC) or -HHMM (for
       hours and minutes West of UTC). Note in particular that
neither
the
zoneinfo
(aka Olson) format, e.g. Europe/Paris, nor the Posix
TZ
format, e.g."
627,14,iostat2pcp,"Europe/Paris, nor the Posix
TZ
format, e.g. EST+5 is allowed for the
-Z
option. This option
       is ignored if ISO timestamps are found in the input stream."
627,15,iostat2pcp,"This option
       is ignored if ISO timestamps are found in the input stream. If
       the timezone is not specified and cannot be deduced, it defaults
       to ``UTC''. Some additional diagnostic output is generated with the
-v
option."
627,16,iostat2pcp,"If
       the timezone is not specified and cannot be deduced, it defaults
       to ``UTC''. Some additional diagnostic output is generated with the
-v
option. iostat2pcp
is a Perl script that uses the PCP::LogImport Perl
       wrapper around the PCP
libpcp_import
library, and as such could be
       used as an example to develop new tools to import other types of
       performance data and create PCP archives."
628,0,iowatcher,"iowatcher graphs the results of a blktrace run. It can graph the
       result of an existing blktrace, start a new blktrace, or start a
       new blktrace and a benchmark run. It can then create an image or
       movie of the IO from a given trace."
628,1,iowatcher,"It can graph the
       result of an existing blktrace, start a new blktrace, or start a
       new blktrace and a benchmark run. It can then create an image or
       movie of the IO from a given trace. iowatcher can produce either
       SVG files or movies in mp4 format (with ffmpeg) or ogg format
       (with png2theora)."
629,0,ipcmk,"ipcmk
allows you to create System V inter-process communication
       (IPC) objects: shared memory segments, message queues, and
       semaphore arrays."
630,0,ipcrm,"ipcrm
removes System V inter-process communication (IPC) objects
       and associated data structures from the system. In order to delete
       such objects, you must be superuser, or the creator or owner of
       the object. System V IPC objects are of three types: shared memory, message
       queues, and semaphores."
630,1,ipcrm,"System V IPC objects are of three types: shared memory, message
       queues, and semaphores. Deletion of a message queue or semaphore
       object is immediate (regardless of whether any process still holds
       an IPC identifier for the object). A shared memory object is only
       removed after all currently attached processes have detached (â
shmdt(2)
) the object from their virtual address space."
630,2,ipcrm,"A shared memory object is only
       removed after all currently attached processes have detached (â
shmdt(2)
) the object from their virtual address space. Two syntax styles are supported. The old Linux historical syntax
       specifies a three-letter keyword indicating which class of object
       is to be deleted, followed by one or more IPC identifiers for
       objects of this type."
630,3,ipcrm,"The old Linux historical syntax
       specifies a three-letter keyword indicating which class of object
       is to be deleted, followed by one or more IPC identifiers for
       objects of this type. The SUS-compliant syntax allows the specification of zero or more
       objects of all three types in a single command line, with objects
       specified either by key or by identifier (see below). Both keys
       and identifiers may be specified in decimal, hexadecimal
       (specified with an initial '0x' or '0X'), or octal (specified with
       an initial '0')."
630,4,ipcrm,"Both keys
       and identifiers may be specified in decimal, hexadecimal
       (specified with an initial '0x' or '0X'), or octal (specified with
       an initial '0'). The details of the removes are described in
shmctl(2)
,
msgctl(2)
,
       and
semctl(2)
. The identifiers and keys can be found by using
ipcs(1)
."
631,0,ipcrm,"The
ipcrm
utility shall remove zero or more message queues,
       semaphore sets, or shared memory segments. The interprocess
       communication facilities to be removed are specified by the
       options.

       Only a user with appropriate privileges shall be allowed to remove
       an interprocess communication facility that was not created by or
       owned by the user invoking
ipcrm
."
632,0,ipcs,"ipcs
shows information on System V inter-process communication
       facilities. By default it shows information about all three
       resources: shared memory segments, message queues, and semaphore
       arrays."
633,0,ipcs,"The
ipcs
utility shall write information about active interprocess
       communication facilities.

       Without options, information shall be written in short format for
       message queues, shared memory segments, and semaphore sets that
       are currently active in the system. Otherwise, the information
       that is displayed is controlled by the options specified."
634,0,iptables-xml,"iptables-xml
is used to convert the output of iptables-save into
       an easily manipulatable XML format to STDOUT. Use I/O-redirection
       provided by your shell to write to a file. -c
,
--combine
combine consecutive rules with the same matches but
              different targets."
634,1,iptables-xml,"-c
,
--combine
combine consecutive rules with the same matches but
              different targets. iptables does not currently support more
              than one target per match, so this simulates that by
              collecting the targets from consecutive iptables rules into
              one action tag, but only when the rule matches are
              identical. Terminating actions like RETURN, DROP, ACCEPT
              and QUEUE are not combined with subsequent targets."
634,2,iptables-xml,"Terminating actions like RETURN, DROP, ACCEPT
              and QUEUE are not combined with subsequent targets. -v
,
--verbose
Output xml comments containing the iptables line from which
              the XML is derived

       iptables-xml does a mechanistic conversion to a very expressive
       xml format; the only semantic considerations are for -g and -j
       targets in order to discriminate between <call> <goto> and <nane-
       of-target> as it helps xml processing scripts if they can tell the
       difference between a target like SNAT and another chain. Some sample output is:

       <iptables-rules>
         <table name=""mangle"">
           <chain name=""PREROUTING"" policy=""ACCEPT"" packet-count=""63436""
       byte-count=""7137573"">
             <rule>
              <conditions>
               <match>
                 <p>tcp</p>
               </match>
               <tcp>
                 <sport>8443</sport>
               </tcp>
              </conditions>
              <actions>
               <call>
                 <check_ip/>
               </call>
               <ACCEPT/>
              </actions>
             </rule>
           </chain>
         </table> </iptables-rules>

       Conversion from XML to iptables-save format may be done using the
       iptables.xslt script and xsltproc, or a custom program using
       libxsltproc or similar; in this fashion:

       xsltproc iptables.xslt my-iptables.xml | iptables-restore"
635,0,ippeveprinter,"ippeveprinter
is a simple Internet Printing Protocol (IPP) server
       conforming to the IPP Everywhere (PWG 5100.14) specification. It
       can be used to test client software or act as a very basic print
       server that runs a command for every job that is printed."
636,0,ippfind,"ippfind
finds services registered with a DNS server or available
       through local devices. Its primary purpose is to find IPP
       printers and show their URIs, show their current status, or run
       commands. REGISTRATION TYPES
ippfind
supports the following registration types:

       _http._tcp
            HyperText Transport Protocol (HTTP, RFC 2616)

       _https._tcp
            Secure HyperText Transport Protocol (HTTPS, RFC 2818)

       _ipp._tcp
            Internet Printing Protocol (IPP, RFC 2911)

       _ipps._tcp
            Secure Internet Printing Protocol (IPPS, draft)

       _printer._tcp
            Line Printer Daemon (LPD, RFC 1179)
EXPRESSIONS
ippfind
supports expressions much like the
find(1)
utility."
636,1,ippfind,"REGISTRATION TYPES
ippfind
supports the following registration types:

       _http._tcp
            HyperText Transport Protocol (HTTP, RFC 2616)

       _https._tcp
            Secure HyperText Transport Protocol (HTTPS, RFC 2818)

       _ipp._tcp
            Internet Printing Protocol (IPP, RFC 2911)

       _ipps._tcp
            Secure Internet Printing Protocol (IPPS, draft)

       _printer._tcp
            Line Printer Daemon (LPD, RFC 1179)
EXPRESSIONS
ippfind
supports expressions much like the
find(1)
utility. However, unlike
find(1)
,
ippfind
uses POSIX regular expressions
       instead of shell filename matching patterns. If
--exec
,
-l
,
--ls
,
-p
,
--print
,
--print-name
,
-q
,
--quiet
,
-s
, or
-x
is not
       specified,
ippfind
adds
--print
to print the service URI of
       anything it finds."
636,2,ippfind,"If
--exec
,
-l
,
--ls
,
-p
,
--print
,
--print-name
,
-q
,
--quiet
,
-s
, or
-x
is not
       specified,
ippfind
adds
--print
to print the service URI of
       anything it finds. The following expressions are supported:
-d
regex
--domain
regex
True if the domain matches the given regular expression. --false
Always false."
636,3,ippfind,"--false
Always false. -h
regex
--host
regex
True is the hostname matches the given regular expression. -l
--ls
Lists attributes returned by Get-Printer-Attributes for IPP
            printers and traditional
find
""-ls"" output for HTTP URLs."
636,4,ippfind,"-l
--ls
Lists attributes returned by Get-Printer-Attributes for IPP
            printers and traditional
find
""-ls"" output for HTTP URLs. The result is true if the URI is accessible, false otherwise. --local
True if the service is local to this computer."
636,5,ippfind,"--local
True if the service is local to this computer. -N
name
--literal-name
name
True if the service instance name matches the given name. -n
regex
--name
regex
True if the service instance name matches the given regular
            expression."
636,6,ippfind,"-n
regex
--name
regex
True if the service instance name matches the given regular
            expression. --path
regex
True if the URI resource path matches the given regular
            expression. -P
number
[
-
number
]
--port
number
[
-
number
]
            True if the port matches the given number or range."
636,7,ippfind,"-P
number
[
-
number
]
--port
number
[
-
number
]
            True if the port matches the given number or range. -p
--print
Prints the URI if the result of previous expressions is true. The result is always true."
636,8,ippfind,"The result is always true. -q
--quiet
Quiet mode - just returns the exit codes below. -r
--remote
True if the service is not local to this computer."
636,9,ippfind,"-r
--remote
True if the service is not local to this computer. -s
--print-name
Prints the service instance name if the result of previous
            expressions is true. The result is always true."
636,10,ippfind,"The result is always true. --true
Always true. -t
key
--txt
key
True if the TXT record contains the named key."
636,11,ippfind,"-t
key
--txt
key
True if the TXT record contains the named key. --txt-
key regex
True if the TXT record contains the named key and matches the
            given regular expression. -u
regex
--uri
regex
True if the URI matches the given regular expression."
636,12,ippfind,"-u
regex
--uri
regex
True if the URI matches the given regular expression. -x
utility
[
argument
... ]
;
--exec
utility
[
argument
..."
636,13,ippfind,"]
;
--exec
utility
[
argument
... ]
;
Executes the specified program if the current result is true. ""{foo}"" arguments are replaced with the corresponding value -
            see SUBSTITUTIONS below."
636,14,ippfind,"""{foo}"" arguments are replaced with the corresponding value -
            see SUBSTITUTIONS below. Expressions may also contain modifiers:
(
expression
)
Group the result of expressions. !"
636,15,ippfind,"! expression
--not
expression
Unary NOT of the expression. expression expression
expression
--and
expression
Logical AND of expressions."
636,16,ippfind,"expression expression
expression
--and
expression
Logical AND of expressions. expression
--or
expression
Logical OR of expressions. SUBSTITUTIONS
The substitutions for ""{foo}"" in
-e
and
--exec
are:
{service_domain}
Domain name, e.g., ""example.com."", ""local."", etc."
636,17,ippfind,"SUBSTITUTIONS
The substitutions for ""{foo}"" in
-e
and
--exec
are:
{service_domain}
Domain name, e.g., ""example.com."", ""local."", etc. {service_hostname}
Fully-qualified domain name, e.g., ""printer.example.com."",
            ""printer.local."", etc. {service_name}
Service instance name, e.g., ""My Fine Printer""."
636,18,ippfind,"{service_name}
Service instance name, e.g., ""My Fine Printer"". {service_port}
Port number for server, typically 631 for IPP and 80 for
            HTTP. {service_regtype}
DNS-SD registration type, e.g., ""_ipp._tcp"", ""_http._tcp"",
            etc."
636,19,ippfind,"{service_regtype}
DNS-SD registration type, e.g., ""_ipp._tcp"", ""_http._tcp"",
            etc. {service_scheme}
URI scheme for DNS-SD registration type, e.g., ""ipp"", ""http"",
            etc. {}
{service_uri}
URI for service, e.g., ""ipp://printer.local./ipp/print"",
            ""http://printer.local./"", etc."
636,20,ippfind,"{service_scheme}
URI scheme for DNS-SD registration type, e.g., ""ipp"", ""http"",
            etc. {}
{service_uri}
URI for service, e.g., ""ipp://printer.local./ipp/print"",
            ""http://printer.local./"", etc. {txt_
key
}
Value of TXT record
key
(lowercase)."
637,0,ipptool,"ipptool
sends IPP requests to the specified
printer-uri
and tests
       and/or displays the results. Each named
testfile
defines one or
       more requests, including the expected response status, attributes,
       and values. Output is either a plain text, formatted text, CSV,
       JSON, or XML report on the standard output, with a non-zero exit
       status indicating that one or more tests have failed."
637,1,ipptool,"Each named
testfile
defines one or
       more requests, including the expected response status, attributes,
       and values. Output is either a plain text, formatted text, CSV,
       JSON, or XML report on the standard output, with a non-zero exit
       status indicating that one or more tests have failed. The
testfile
format is described in
ipptoolfile(5)
."
638,0,irqtop,"Display kernel interrupt counter information in
top(1)
style view. The default output is subject to change. So whenever possible, you
       should avoid using default outputs in your scripts."
638,1,irqtop,"The default output is subject to change. So whenever possible, you
       should avoid using default outputs in your scripts. Always
       explicitly define expected columns by using
--output
."
639,0,jailcheck,"jailcheck attaches itself to all sandboxes started by the user and
       performs some basic tests on the sandbox filesystem:
1. Virtual directories
jailcheck extracts a list with the main virtual directories
              installed by the sandbox. These directories are build by
              firejail at startup using --private* and --whitelist
              commands."
639,1,jailcheck,"These directories are build by
              firejail at startup using --private* and --whitelist
              commands. 2. Noexec test
jailcheck inserts executable programs in /home/username,
              /tmp, and /var/tmp directories and tries to run them from
              inside the sandbox, thus testing if the directory is
              executable or not."
639,2,jailcheck,"Noexec test
jailcheck inserts executable programs in /home/username,
              /tmp, and /var/tmp directories and tries to run them from
              inside the sandbox, thus testing if the directory is
              executable or not. 3. Read access test
jailcheck creates test files in the directories specified
              by the user and tries to read them from inside the sandbox."
639,3,jailcheck,"Read access test
jailcheck creates test files in the directories specified
              by the user and tries to read them from inside the sandbox. 4. AppArmor test
5."
639,4,jailcheck,"AppArmor test
5. Seccomp test
6. Networking test
The program is started as root using sudo."
640,0,jobs,"The
jobs
utility shall display the status of jobs that were
       started in the current shell environment; see
Section 2.12
,
Shell
Execution Environment
.

       When
jobs
reports the termination status of a job, the shell shall
       remove its process ID from the list of those ``known in the
       current shell execution environment''; see
Section 2.9.3.1
,
Examples
."
641,0,join,"For each pair of input lines with identical join fields, write a
       line to standard output. The default join field is the first,
       delimited by blanks. When FILE1 or FILE2 (not both) is -, read standard input."
641,1,join,"When FILE1 or FILE2 (not both) is -, read standard input. -a
FILENUM
              also print unpairable lines from file FILENUM, where
              FILENUM is 1 or 2, corresponding to FILE1 or FILE2
-e
STRING
              replace missing (empty) input fields with STRING; I.e.,
              missing fields specified with '-12jo' options
-i
,
--ignore-case
ignore differences in case when comparing fields
-j
FIELD
              equivalent to '-1 FIELD
-2
FIELD'
-o
FORMAT
              obey FORMAT while constructing output line
-t
CHAR
              use CHAR as input and output field separator
-v
FILENUM
              like
-a
FILENUM, but suppress joined output lines
-1
FIELD
              join on this FIELD of file 1
-2
FIELD
              join on this FIELD of file 2
--check-order
check that the input is correctly sorted, even if all input
              lines are pairable
--nocheck-order
do not check that the input is correctly sorted
--header
treat the first line in each file as field headers, print
              them without trying to pair them
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit

       Unless
-t
CHAR is given, leading blanks separate fields and are
       ignored, else fields are separated by CHAR. Any FIELD is a field
       number counted from 1."
641,2,join,"Any FIELD is a field
       number counted from 1. FORMAT is one or more comma or blank
       separated specifications, each being 'FILENUM.FIELD' or '0'. Default FORMAT outputs the join field, the remaining fields from
       FILE1, the remaining fields from FILE2, all separated by CHAR."
641,3,join,"Default FORMAT outputs the join field, the remaining fields from
       FILE1, the remaining fields from FILE2, all separated by CHAR. If
       FORMAT is the keyword 'auto', then the first line of each file
       determines the number of fields output for each line. Important: FILE1 and FILE2 must be sorted on the join fields."
641,4,join,"Important: FILE1 and FILE2 must be sorted on the join fields. E.g., use ""sort
-k
1b,1"" if 'join' has no options, or use ""join
-t
''"" if 'sort' has no options. Comparisons honor the rules
       specified by 'LC_COLLATE'."
641,5,join,"E.g., use ""sort
-k
1b,1"" if 'join' has no options, or use ""join
-t
''"" if 'sort' has no options. Comparisons honor the rules
       specified by 'LC_COLLATE'. If the input is not sorted and some
       lines cannot be joined, a warning message will be given."
642,0,join,"The
join
utility shall perform an equality join on the files
file1
and
file2
. The joined files shall be written to the standard
       output. The join field is a field in each file on which the files are
       compared."
642,1,join,"The join field is a field in each file on which the files are
       compared. The
join
utility shall write one line in the output for
       each pair of lines in
file1
and
file2
that have join fields that
       collate equally. The output line by default shall consist of the
       join field, then the remaining fields from
file1
, then the
       remaining fields from
file2
."
642,2,join,"The output line by default shall consist of the
       join field, then the remaining fields from
file1
, then the
       remaining fields from
file2
. This format can be changed by using
       the
-o
option (see below). The
-a
option can be used to add
       unmatched lines to the output."
642,3,join,"The
-a
option can be used to add
       unmatched lines to the output. The
-v
option can be used to output
       only unmatched lines. The files
file1
and
file2
shall be ordered in the collating
       sequence of
sort
-b
on the fields on which they shall be joined,
       by default the first in each line."
642,4,join,"The files
file1
and
file2
shall be ordered in the collating
       sequence of
sort
-b
on the fields on which they shall be joined,
       by default the first in each line. All selected output shall be
       written in the same collating sequence. The default input field separators shall be <blank> characters."
642,5,join,"The default input field separators shall be <blank> characters. In
       this case, multiple separators shall count as one field separator,
       and leading separators shall be ignored. The default output field
       separator shall be a <space>."
642,6,join,"The default output field
       separator shall be a <space>. The field separator and collating sequence can be changed by using
       the
-t
option (see below). If the same key appears more than once in either file, all
       combinations of the set of remaining fields in
file1
and the set
       of remaining fields in
file2
are output in the order of the lines
       encountered."
642,7,join,"The field separator and collating sequence can be changed by using
       the
-t
option (see below). If the same key appears more than once in either file, all
       combinations of the set of remaining fields in
file1
and the set
       of remaining fields in
file2
are output in the order of the lines
       encountered. If the input files are not in the appropriate collating sequence,
       the results are unspecified."
643,0,kbdinfo,"The utility allows you to read and check various parameters of the
       keyboard and virtual console. getmode
Get or check virtual console mode. gkbmode
Gets current keyboard mode."
643,1,kbdinfo,"gkbmode
Gets current keyboard mode. raw
Raw (scancode) mode. These are the raw codes
                     generated by the keyboard."
643,2,kbdinfo,"These are the raw codes
                     generated by the keyboard. mediumraw
Medium raw (scancode) mode. This is extended medium
                     raw mode, with keys above 127 encoded as 0, high 7
                     bits, low 7 bits, with the 0 bearing the 'up' flag
                     if needed."
643,3,kbdinfo,"This is extended medium
                     raw mode, with keys above 127 encoded as 0, high 7
                     bits, low 7 bits, with the 0 bearing the 'up' flag
                     if needed. 0 is reserved, so this shouldn't
                     interfere with anything else. The two bytes after 0
                     will always have the up flag set not to interfere
                     with older applications."
643,4,kbdinfo,"The two bytes after 0
                     will always have the up flag set not to interfere
                     with older applications. This allows for 16384
                     different keycodes, which should be enough. xlate
Translate keycodes using keymap."
643,5,kbdinfo,"xlate
Translate keycodes using keymap. These are the codes
                     generated via the current keysym mapping. unicode
Unicode mode."
643,6,kbdinfo,"unicode
Unicode mode. gkbmeta
Gets meta key handling mode. escprefix
Specifies if pressing the meta (alt) key generates
                     an ESC (\033) prefix followed by the keysym."
643,7,kbdinfo,"escprefix
Specifies if pressing the meta (alt) key generates
                     an ESC (\033) prefix followed by the keysym. metabit
The keysym marked with the high bit set. gkbled
Get keyboard flags CapsLock, NumLock, ScrollLock (not
                lights)."
643,8,kbdinfo,"gkbled
Get keyboard flags CapsLock, NumLock, ScrollLock (not
                lights). scrolllock
The scroll lock is down. numlock
The num lock is down."
643,9,kbdinfo,"scrolllock
The scroll lock is down. numlock
The num lock is down. capslock
The caps lock is down."
644,0,kbd_mode,"Without argument,
kbd_mode
prints the current keyboard mode (RAW,
       MEDIUMRAW or XLATE). With argument, it sets the keyboard mode as
       indicated:

       -s: scancode mode (RAW),

       -k: keycode mode (MEDIUMRAW),

       -a: ASCII mode (XLATE),

       -u: UTF-8 mode (UNICODE). Of course the ""-a"" is only traditional, and the code used can be
       any 8-bit character set."
644,1,kbd_mode,"Of course the ""-a"" is only traditional, and the code used can be
       any 8-bit character set. With ""-u"" a 16-bit character set is
       expected, and these chars are transmitted to the kernel as 1, 2,
       or 3 bytes (following the UTF-8 coding). In these latter two
       modes the key mapping defined by
loadkeys(1)
is used."
644,2,kbd_mode,"In these latter two
       modes the key mapping defined by
loadkeys(1)
is used. kbd_mode operates on the console specified by the ""-C"" option; if
       there is none, the console associated with stdin is used. Warning: changing the keyboard mode, other than between ASCII and
       Unicode, will probably make your keyboard unusable."
644,3,kbd_mode,"Warning: changing the keyboard mode, other than between ASCII and
       Unicode, will probably make your keyboard unusable. Set the ""-f""
       option to force such changes. This command is only meant for use
       (say via remote login) when some program left your keyboard in the
       wrong state."
644,4,kbd_mode,"Set the ""-f""
       option to force such changes. This command is only meant for use
       (say via remote login) when some program left your keyboard in the
       wrong state. Note that in some obsolete versions of this program
       the ""-u"" option was a synonym for ""-s"" and older versions of this
       program may not recognize the ""-f"" option."
645,0,kill,"The command
kill
sends the specified
signal
to the specified
       processes or process groups. If no signal is specified, the
TERM
signal is sent. The default
       action for this signal is to terminate the process."
645,1,kill,"The default
       action for this signal is to terminate the process. This signal
       should be used in preference to the
KILL
signal (number 9), since
       a process may install a handler for the TERM signal in order to
       perform clean-up steps before terminating in an orderly fashion. If a process does not terminate after a
TERM
signal has been sent,
       then the
KILL
signal may be used; be aware that the latter signal
       cannot be caught, and so does not give the target process the
       opportunity to perform any clean-up before terminating."
645,2,kill,"If a process does not terminate after a
TERM
signal has been sent,
       then the
KILL
signal may be used; be aware that the latter signal
       cannot be caught, and so does not give the target process the
       opportunity to perform any clean-up before terminating. Most modern shells have a builtin
kill
command, with a usage
       rather similar to that of the command described here. The
--all
,
--pid
, and
--queue
options, and the possibility to specify
       processes by command name, are local extensions."
645,3,kill,"Most modern shells have a builtin
kill
command, with a usage
       rather similar to that of the command described here. The
--all
,
--pid
, and
--queue
options, and the possibility to specify
       processes by command name, are local extensions. If
signal
is 0, then no actual signal is sent, but error checking
       is still performed."
646,0,kill,"The
kill
utility shall send a signal to the process or processes
       specified by each
pid
operand.

       For each
pid
operand, the
kill
utility shall perform actions
       equivalent to the
kill
() function defined in the System Interfaces
       volume of POSIX.1â2017 called with the following arguments:

        *  The value of the
pid
operand shall be used as the
pid
argument.

        *  The
sig
argument is the value specified by the
-s
option,
-
signal_number
option, or the
-
signal_name
option, or by
           SIGTERM, if none of these options is specified."
647,0,journalctl,"journalctl
is used to print the log entries stored in the journal
       by
systemd-journald.service(8)
and
systemd-journal-remote.service(8)
. If called without parameters, it will show the contents of the
       journal accessible to the calling user, starting with the oldest
       entry collected. If one or more match arguments are passed, the output is filtered
       accordingly."
647,1,journalctl,"If one or more match arguments are passed, the output is filtered
       accordingly. A match is in the format ""FIELD=VALUE"", e.g. ""_SYSTEMD_UNIT=httpd.service"", referring to the components of a
       structured journal entry."
647,2,journalctl,"""_SYSTEMD_UNIT=httpd.service"", referring to the components of a
       structured journal entry. See
systemd.journal-fields(7)
for a list
       of well-known fields. If multiple matches are specified matching
       different fields, the log entries are filtered by both, i.e."
647,3,journalctl,"If multiple matches are specified matching
       different fields, the log entries are filtered by both, i.e. the
       resulting output will show only entries matching all the specified
       matches of this kind. If two matches apply to the same field, then
       they are automatically matched as alternatives, i.e."
647,4,journalctl,"If two matches apply to the same field, then
       they are automatically matched as alternatives, i.e. the resulting
       output will show entries matching any of the specified matches for
       the same field. Finally, the character ""+"" may appear as a
       separate word between other terms on the command line."
647,5,journalctl,"Finally, the character ""+"" may appear as a
       separate word between other terms on the command line. This causes
       all matches before and after to be combined in a disjunction (i.e. logical OR)."
647,6,journalctl,"logical OR). It is also possible to filter the entries by specifying an
       absolute file path as an argument. The file path may be a file or
       a symbolic link and the file must exist at the time of the query."
647,7,journalctl,"The file path may be a file or
       a symbolic link and the file must exist at the time of the query. If a file path refers to an executable binary, an ""_EXE="" match
       for the canonicalized binary path is added to the query. If a file
       path refers to an executable script, a ""_COMM="" match for the
       script name is added to the query."
647,8,journalctl,"If a file
       path refers to an executable script, a ""_COMM="" match for the
       script name is added to the query. If a file path refers to a
       device node, ""_KERNEL_DEVICE="" matches for the kernel name of the
       device and for each of its ancestor devices is added to the query. Symbolic links are dereferenced, kernel names are synthesized, and
       parent devices are identified from the environment at the time of
       the query."
647,9,journalctl,"Symbolic links are dereferenced, kernel names are synthesized, and
       parent devices are identified from the environment at the time of
       the query. In general, a device node is the best proxy for an
       actual device, as log entries do not usually contain fields that
       identify an actual device. For the resulting log entries to be
       correct for the actual device, the relevant parts of the
       environment at the time the entry was logged, in particular the
       actual device corresponding to the device node, must have been the
       same as those at the time of the query."
647,10,journalctl,"For the resulting log entries to be
       correct for the actual device, the relevant parts of the
       environment at the time the entry was logged, in particular the
       actual device corresponding to the device node, must have been the
       same as those at the time of the query. Because device nodes
       generally change their corresponding devices across reboots,
       specifying a device node path causes the resulting entries to be
       restricted to those from the current boot. Additional constraints may be added using options
--boot
,
--unit=
,
       etc., to further limit what entries will be shown (logical AND)."
647,11,journalctl,"Additional constraints may be added using options
--boot
,
--unit=
,
       etc., to further limit what entries will be shown (logical AND). Output is interleaved from all accessible journal files, whether
       they are rotated or currently being written, and regardless of
       whether they belong to the system itself or are accessible user
       journals. The
--header
option can be used to identify which files
are
being shown."
647,12,journalctl,"The
--header
option can be used to identify which files
are
being shown. The set of journal files which will be used can be modified using
       the
--user
,
--system
,
--directory=
, and
--file=
options, see
       below. All users are granted access to their private per-user journals."
647,13,journalctl,"All users are granted access to their private per-user journals. However, by default, only root and users who are members of a few
       special groups are granted access to the system journal and the
       journals of other users. Members of the groups ""systemd-journal"",
       ""adm"", and ""wheel"" can read all journal files."
647,14,journalctl,"Members of the groups ""systemd-journal"",
       ""adm"", and ""wheel"" can read all journal files. Note that the two
       latter groups traditionally have additional privileges specified
       by the distribution. Members of the ""wheel"" group can often
       perform administrative tasks."
647,15,journalctl,"Members of the ""wheel"" group can often
       perform administrative tasks. The output is paged through
less
by default, and long lines are
       ""truncated"" to screen width. The hidden part can be viewed by
       using the left-arrow and right-arrow keys."
647,16,journalctl,"The hidden part can be viewed by
       using the left-arrow and right-arrow keys. Paging can be disabled;
       see the
--no-pager
option and the ""Environment"" section below. When outputting to a tty, lines are colored according to priority:
       lines of level ERROR and higher are colored red; lines of level
       WARNING are colored yellow; lines of level NOTICE are highlighted;
       lines of level INFO are displayed normally; lines of level DEBUG
       are colored grey."
647,17,journalctl,"When outputting to a tty, lines are colored according to priority:
       lines of level ERROR and higher are colored red; lines of level
       WARNING are colored yellow; lines of level NOTICE are highlighted;
       lines of level INFO are displayed normally; lines of level DEBUG
       are colored grey. To write entries
to
the journal, a few methods may be used. In
       general, output from systemd units is automatically connected to
       the journal, see
systemd-journald.service(8)
."
647,18,journalctl,"To write entries
to
the journal, a few methods may be used. In
       general, output from systemd units is automatically connected to
       the journal, see
systemd-journald.service(8)
. In addition,
systemd-cat(1)
may be used to send messages to the journal
       directly."
648,0,kmidiff,nan
649,0,killall,"killall
sends  a  signal  to  all  processes  running  any of the
       specified commands. If no signal name is  specified,  SIGTERM  is
       sent. Signals  can be specified either by name (e.g."
649,1,killall,"Signals  can be specified either by name (e.g. -HUP
or
-SIGHUP
) or
       by number (e.g. -1
) or by option
-s
."
649,2,killall,"-1
) or by option
-s
. If the command name is not  regular  expression  (option
-r
)  and
       contains  a  slash  (
/
),  processes executing that particular file
       will be selected for killing, independent of their name. killall
returns a zero return code if at  least  one  process  has
       been  killed  for  each listed command, or no commands were listed
       and at least one process matched the
-u
and
-Z
search  criteria."
649,3,killall,"killall
returns a zero return code if at  least  one  process  has
       been  killed  for  each listed command, or no commands were listed
       and at least one process matched the
-u
and
-Z
search  criteria. killall
returns non-zero otherwise. A
killall
process never kills itself (but may kill other
killall
processes)."
650,0,keyctl,"This program is used to control the key management facility in
       various ways using a variety of subcommands."
651,0,last,"last
looks  through  the  file
wtmp
(which records all logins/loâ
       gouts) and  prints  information  about  connect  times  of  users. Records are printed from most recent to least recent. Records can
       be specified by tty and username."
651,1,last,"Records can
       be specified by tty and username. tty names can be abbreviated:
last
0
       is equivalent to
last
tty0. Multiple arguments can be specified:
last
root console
       will  print  all  of the entries for the user
root
and all entries
       logged in on the
console
tty."
651,2,last,"Multiple arguments can be specified:
last
root console
       will  print  all  of the entries for the user
root
and all entries
       logged in on the
console
tty. The special users
reboot
and
shutdown
log in when the  system  reâ
       boots or (surprise) shuts down. last
reboot
       will produce a record of reboot times."
651,3,last,"The special users
reboot
and
shutdown
log in when the  system  reâ
       boots or (surprise) shuts down. last
reboot
       will produce a record of reboot times. If
last
is interrupted by a quit signal, it prints out how far its
       search in the
wtmp
file had reached and then quits."
652,0,last,"last
looks  through  the  file
wtmp
(which records all logins/loâ
       gouts) and  prints  information  about  connect  times  of  users. Records are printed from most recent to least recent. Records can
       be specified by tty and username."
652,1,last,"Records can
       be specified by tty and username. tty names can be abbreviated:
last
0
       is equivalent to
last
tty0. Multiple arguments can be specified:
last
root console
       will  print  all  of the entries for the user
root
and all entries
       logged in on the
console
tty."
652,2,last,"Multiple arguments can be specified:
last
root console
       will  print  all  of the entries for the user
root
and all entries
       logged in on the
console
tty. The special users
reboot
and
shutdown
log in when the  system  reâ
       boots or (surprise) shuts down. last
reboot
       will produce a record of reboot times."
652,3,last,"The special users
reboot
and
shutdown
log in when the  system  reâ
       boots or (surprise) shuts down. last
reboot
       will produce a record of reboot times. If
last
is interrupted by a quit signal, it prints out how far its
       search in the
wtmp
file had reached and then quits."
653,0,ldapcompare,"ldapcompare
is a shell-accessible interface to the
ldap_compare_ext(3)
library call. ldapcompare
opens a connection to an LDAP server, binds, and
       performs a compare using specified parameters. The
DN
should be
       a distinguished name in the directory."
653,1,ldapcompare,"The
DN
should be
       a distinguished name in the directory. Attr
should be a known
       attribute. If followed by one colon, the assertion
value
should
       be provided as a string."
653,2,ldapcompare,"If followed by one colon, the assertion
value
should
       be provided as a string. If followed by two colons, the base64
       encoding of the value is provided. The result code of the compare
       is provided as the exit code and, unless ran with
-z
, the program
       prints TRUE, FALSE, or UNDEFINED on standard output."
654,0,lastcomm,"lastcomm
prints  out  information  about previously executed comâ
       mands. If no arguments are specified,
lastcomm
will  print  info
       about  all  of  the commands in
acct
(the record file). If called
       with one or more of
command-name, user-name,
or
terminal-name,
onâ
       ly records containing those items will be displayed."
654,1,lastcomm,"If called
       with one or more of
command-name, user-name,
or
terminal-name,
onâ
       ly records containing those items will be displayed. For example,
       to find out which users used command `a.out' and which users  were
       logged into `tty0', type:
                              lastcomm a.out tty0

       This  will  print any entry for which `a.out' or `tty0' matches in
       any of the record's fields (command, name, or terminal). If  you
       want  to  find only items that match *all* of the arguments on the
       command line, you must use the '-strict-match' option."
654,2,lastcomm,"If  you
       want  to  find only items that match *all* of the arguments on the
       command line, you must use the '-strict-match' option. For  examâ
       ple,  to  list all of the executions of command
a.out
by user
root
on terminal
tty0,
type:
         lastcomm --strict-match --command a.out --user root --tty tty0

       The order of the arguments is not important. For each entry the following information is printed:
          + command name of the process
          + flags, as recorded by the system accounting routines:
               S -- command executed by super-user
               F -- command executed after a fork but without a following
       exec
               C -- command run in PDP-11 compatibility mode (VAX only)
               D -- command terminated with the generation of a core file
               X -- command was terminated with the signal SIGTERM
          + the name of the user who ran the process
          + time the process started"
655,0,ldapmodify,"ldapmodify
is a shell-accessible interface to the
ldap_add_ext(3)
,
ldap_modify_ext(3)
,
ldap_delete_ext(3)
and
ldap_rename(3)
. library calls. ldapadd
is implemented as a hard link to the
       ldapmodify tool."
655,1,ldapmodify,"ldapadd
is implemented as a hard link to the
       ldapmodify tool. When invoked as
ldapadd
the
-a
(add new entry)
       flag is turned on automatically. ldapmodify
opens a connection to an LDAP server, binds, and
       modifies or adds entries."
655,2,ldapmodify,"When invoked as
ldapadd
the
-a
(add new entry)
       flag is turned on automatically. ldapmodify
opens a connection to an LDAP server, binds, and
       modifies or adds entries. The entry information is read from
       standard input or from
file
through the use of the
-f
option."
656,0,ldapexop,"ldapexop issues the LDAP extended operation specified by
oid
or
       one of the special keywords
whoami
,
cancel
, or
refresh
.

       Additional data for the extended operation can be passed to the
       server using
data
or base-64 encoded as
b64data
in the case of
oid
, or using the additional parameters in the case of the
       specially named extended operations above.

       Please note that ldapexop behaves differently for the same
       extended operation when it was given as an OID or as a specially
       named operation:

       Calling ldapexop with the OID of the
whoami
(RFC 4532) extended
       operation

         ldapexop [<options>] 1.3.6.1.4.1.4203.1.11.3

       yields

         # extended operation response
         data:: <base64 encoded response data>

       while calling it with the keyword
whoami
ldapexop [<options>] whoami

       results in

         dn:<client's identity>"
657,0,ldapdelete,"ldapdelete
is a shell-accessible interface to the
ldap_delete_ext(3)
library call. ldapdelete
opens a connection to an LDAP server, binds, and
       deletes one or more entries. If one or more
DN
arguments are
       provided, entries with those Distinguished Names are deleted."
657,1,ldapdelete,"If one or more
DN
arguments are
       provided, entries with those Distinguished Names are deleted. Each
DN
should be provided using the LDAPv3 string representation
       as defined in RFC 4514. If no
DN
arguments are provided, a list
       of DNs is read from standard input (or from
file
if the
-f
flag is
       used)."
658,0,ldapmodrdn,"ldapmodrdn
is a shell-accessible interface to the
ldap_rename(3)
library call.
ldapmodrdn
opens a connection to an LDAP server, binds, and
       modifies the RDN of entries.  The entry information is read from
       standard input, from
file
through the use of the -
f
option, or
       from the command-line pair
dn
and
rdn
."
659,0,ldapmodify,"ldapmodify
is a shell-accessible interface to the
ldap_add_ext(3)
,
ldap_modify_ext(3)
,
ldap_delete_ext(3)
and
ldap_rename(3)
. library calls. ldapadd
is implemented as a hard link to the
       ldapmodify tool."
659,1,ldapmodify,"ldapadd
is implemented as a hard link to the
       ldapmodify tool. When invoked as
ldapadd
the
-a
(add new entry)
       flag is turned on automatically. ldapmodify
opens a connection to an LDAP server, binds, and
       modifies or adds entries."
659,2,ldapmodify,"When invoked as
ldapadd
the
-a
(add new entry)
       flag is turned on automatically. ldapmodify
opens a connection to an LDAP server, binds, and
       modifies or adds entries. The entry information is read from
       standard input or from
file
through the use of the
-f
option."
660,0,ldappasswd,"ldappasswd
is a tool to set the password of an LDAP user. ldappasswd
uses the LDAPv3 Password Modify (RFC 3062) extended
       operation. ldappasswd
sets the password of associated with the user [or an
       optionally specified
user
]."
660,1,ldappasswd,"ldappasswd
sets the password of associated with the user [or an
       optionally specified
user
]. If the new password is not specified
       on the command line and the user doesn't enable prompting, the
       server will be asked to generate a password for the user. ldappasswd
is neither designed nor intended to be a replacement
       for
passwd(1)
and should not be installed as such."
661,0,ldapsearch,"ldapsearch
is a shell-accessible interface to the
ldap_search_ext(3)
library call. ldapsearch
opens a connection to an LDAP server, binds, and
       performs a search using specified parameters. The
filter
should
       conform to the string representation for search filters as defined
       in RFC 4515."
661,1,ldapsearch,"The
filter
should
       conform to the string representation for search filters as defined
       in RFC 4515. If not provided, the default filter,
(objectClass=*)
, is used. If
ldapsearch
finds one or more entries, the attributes specified
       by
attrs
are returned."
661,2,ldapsearch,"If
ldapsearch
finds one or more entries, the attributes specified
       by
attrs
are returned. If
*
is listed, all user attributes are
       returned. If
+
is listed, all operational attributes are
       returned."
661,3,ldapsearch,"If
+
is listed, all operational attributes are
       returned. If no
attrs
are listed, all user attributes are
       returned. If only 1.1 is listed, no attributes will be returned."
661,4,ldapsearch,"If only 1.1 is listed, no attributes will be returned. The search results are displayed using an extended version of
       LDIF. Option
-L
controls the format of the output."
662,0,ld,"ld
combines a number of object and archive files, relocates their
       data and ties up symbol references. Usually the last step in
       compiling a program is to run
ld
. ld
accepts Linker Command Language files written in a superset of
       AT&T's Link Editor Command Language syntax, to provide explicit
       and total control over the linking process."
662,1,ld,"ld
accepts Linker Command Language files written in a superset of
       AT&T's Link Editor Command Language syntax, to provide explicit
       and total control over the linking process. This man page does not describe the command language; see the
ld
entry in ""info"" for full details on the command language and on
       other aspects of the GNU linker. This version of
ld
uses the general purpose BFD libraries to
       operate on object files."
662,2,ld,"This version of
ld
uses the general purpose BFD libraries to
       operate on object files. This allows
ld
to read, combine, and
       write object files in many different formats---for example, COFF
       or ""a.out"". Different formats may be linked together to produce
       any available kind of object file."
662,3,ld,"Different formats may be linked together to produce
       any available kind of object file. Aside from its flexibility, the GNU linker is more helpful than
       other linkers in providing diagnostic information. Many linkers
       abandon execution immediately upon encountering an error; whenever
       possible,
ld
continues executing, allowing you to identify other
       errors (or, in some cases, to get an output file in spite of the
       error)."
662,4,ld,"Many linkers
       abandon execution immediately upon encountering an error; whenever
       possible,
ld
continues executing, allowing you to identify other
       errors (or, in some cases, to get an output file in spite of the
       error). The GNU linker
ld
is meant to cover a broad range of situations,
       and to be as compatible as possible with other linkers. As a
       result, you have many choices to control its behavior."
663,0,ldapvc,"ldapvc
implements the LDAP ""Verify Credentials"" extended
       operation.
Verify Credentials
operation behaves like LDAP Bind but has no
       impact upon the underlying LDAP session."
664,0,ldapwhoami,"ldapwhoami
implements the LDAP ""Who Am I?"" extended operation.
ldapwhoami
opens a connection to an LDAP server, binds, and
       performs a whoami operation."
665,0,ldapurl,"ldapurl
is a command that allows one to either compose or
       decompose LDAP URIs. When invoked with the
-H
option,
ldapurl
extracts the components
       of the
ldapuri
option argument, unescaping hex-escaped chars as
       required. It basically acts as a frontend to the
ldap_url_parse(3)
call."
665,1,ldapurl,"It basically acts as a frontend to the
ldap_url_parse(3)
call. Otherwise, it builds an LDAP URI based on
       the components passed with the appropriate options, performing the
       inverse operation. Option
-H
is incompatible with options
-a
,
-b
,
-E
,
-f
,
-H
,
-h
,
-p
,
-S
, and
-s
."
666,0,lessecho,"lessecho
is a program that simply echos its arguments on standard
       output.  But any metacharacter in the output is preceded by an
       ""escape"" character, which by default is a backslash.
lessecho
is
       invoked internally by
less
, and is not intended to be used
       directly by humans."
667,0,lesskey,"A
lesskey
file specifies a set of key bindings and environment
       variables to be used by subsequent invocations of
less
."
668,0,ldd,"ldd
prints the shared objects (shared libraries) required by each
       program or shared object specified on the command line. An
       example of its use and output is the following:

           $
ldd /bin/ls
linux-vdso.so.1 (0x00007ffcc3563000)
               libselinux.so.1 => /lib64/libselinux.so.1 (0x00007f87e5459000)
               libcap.so.2 => /lib64/libcap.so.2 (0x00007f87e5254000)
               libc.so.6 => /lib64/libc.so.6 (0x00007f87e4e92000)
               libpcre.so.1 => /lib64/libpcre.so.1 (0x00007f87e4c22000)
               libdl.so.2 => /lib64/libdl.so.2 (0x00007f87e4a1e000)
               /lib64/ld-linux-x86-64.so.2 (0x00005574bf12e000)
               libattr.so.1 => /lib64/libattr.so.1 (0x00007f87e4817000)
               libpthread.so.0 => /lib64/libpthread.so.0 (0x00007f87e45fa000)

       In the usual case,
ldd
invokes the standard dynamic linker (see
ld.so(8)
) with the
LD_TRACE_LOADED_OBJECTS
environment variable
       set to 1. This causes the dynamic linker to inspect the program's
       dynamic dependencies, and find (according to the rules described
       in
ld.so(8)
) and load the objects that satisfy those dependencies."
668,1,ldd,"This causes the dynamic linker to inspect the program's
       dynamic dependencies, and find (according to the rules described
       in
ld.so(8)
) and load the objects that satisfy those dependencies. For each dependency,
ldd
displays the location of the matching
       object and the (hexadecimal) address at which it is loaded. (The
linux-vdso
and
ld-linux
shared dependencies are special; see
vdso(7)
and
ld.so(8)
.)
Security
Be aware that in some circumstances (e.g., where the program
       specifies an ELF interpreter other than
ld-linux.so
), some
       versions of
ldd
may attempt to obtain the dependency information
       by attempting to directly execute the program, which may lead to
       the execution of whatever code is defined in the program's ELF
       interpreter, and perhaps to execution of the program itself."
668,2,ldd,"(The
linux-vdso
and
ld-linux
shared dependencies are special; see
vdso(7)
and
ld.so(8)
.)
Security
Be aware that in some circumstances (e.g., where the program
       specifies an ELF interpreter other than
ld-linux.so
), some
       versions of
ldd
may attempt to obtain the dependency information
       by attempting to directly execute the program, which may lead to
       the execution of whatever code is defined in the program's ELF
       interpreter, and perhaps to execution of the program itself. (Before glibc 2.27, the upstream
ldd
implementation did this for
       example, although most distributions provided a modified version
       that did not.)

       Thus, you should
never
employ
ldd
on an untrusted executable,
       since this may result in the execution of arbitrary code. A safer
       alternative when dealing with untrusted executables is:

           $
objdump -p /path/to/program | grep NEEDED
Note, however, that this alternative shows only the direct
       dependencies of the executable, while
ldd
shows the entire
       dependency tree of the executable."
669,0,lexgrog,"lexgrog
is an implementation of the traditional âgroff guessâ
       utility in
lex
. It reads the list of files on its command line as
       either man page source files or preformatted âcatâ pages, and
       displays their name and description as used by
apropos
and
whatis
,
       the list of preprocessing filters required by the man page before
       it is passed to
nroff
or
troff
, or both. If its input is badly formatted,
lexgrog
will print âparse
       failedâ; this may be useful for external programs that need to
       check man pages for correctness."
669,1,lexgrog,"It reads the list of files on its command line as
       either man page source files or preformatted âcatâ pages, and
       displays their name and description as used by
apropos
and
whatis
,
       the list of preprocessing filters required by the man page before
       it is passed to
nroff
or
troff
, or both. If its input is badly formatted,
lexgrog
will print âparse
       failedâ; this may be useful for external programs that need to
       check man pages for correctness. If one of
lexgrog
's input files
       is â-â, it will read from standard input; if any input file is
       compressed, a decompressed version will be read automatically."
670,0,link,"Call the link function to create a link named FILE2 to an existing
       FILE1.
--help
display this help and exit
--version
output version information and exit"
671,0,less,"Less
is a program similar to
more(1)
, but it has many more
       features. Less
does not have to read the entire input file before
       starting, so with large input files it starts up faster than text
       editors like
vi
(1). Less
uses termcap (or terminfo on some
       systems), so it can run on a variety of terminals."
671,1,less,"Less
uses termcap (or terminfo on some
       systems), so it can run on a variety of terminals. There is even
       limited support for hardcopy terminals. (On a hardcopy terminal,
       lines which should be printed at the top of the screen are
       prefixed with a caret.)

       Commands are based on both
more
and
vi
."
671,2,less,"(On a hardcopy terminal,
       lines which should be printed at the top of the screen are
       prefixed with a caret.)

       Commands are based on both
more
and
vi
. Commands may be preceded
       by a decimal number, called N in the descriptions below. The
       number is used by some commands, as indicated."
672,0,lex,"The
lex
utility shall generate C programs to be used in lexical
       processing of character input, and that can be used as an
       interface to
yacc
. The C programs shall be generated from
lex
source code and conform to the ISO C standard, without depending
       on any undefined, unspecified, or implementation-defined behavior,
       except in cases where the code is copied directly from the
       supplied source, or in cases that are documented by the
       implementation. Usually, the
lex
utility shall write the program
       it generates to the file
lex.yy.c
; the state of this file is
       unspecified if
lex
exits with a non-zero exit status."
672,1,lex,"The C programs shall be generated from
lex
source code and conform to the ISO C standard, without depending
       on any undefined, unspecified, or implementation-defined behavior,
       except in cases where the code is copied directly from the
       supplied source, or in cases that are documented by the
       implementation. Usually, the
lex
utility shall write the program
       it generates to the file
lex.yy.c
; the state of this file is
       unspecified if
lex
exits with a non-zero exit status. See the
       EXTENDED DESCRIPTION section for a complete description of the
lex
input language."
673,0,link,"The
link
utility shall perform the function call:

           link(
file1
,
file2
);

       A user may need appropriate privileges to invoke the
link
utility."
674,0,ln,"In the 1st form, create a link to TARGET with the name LINK_NAME. In the 2nd form, create a link to TARGET in the current directory. In the 3rd and 4th forms, create links to each TARGET in
       DIRECTORY."
674,1,ln,"In the 3rd and 4th forms, create links to each TARGET in
       DIRECTORY. Create hard links by default, symbolic links with
--symbolic
. By default, each destination (name of new link)
       should not already exist."
674,2,ln,"By default, each destination (name of new link)
       should not already exist. When creating hard links, each TARGET
       must exist. Symbolic links can hold arbitrary text; if later
       resolved, a relative link is interpreted in relation to its parent
       directory."
674,3,ln,"Symbolic links can hold arbitrary text; if later
       resolved, a relative link is interpreted in relation to its parent
       directory. Mandatory arguments to long options are mandatory for short
       options too. --backup
[=
CONTROL
]
              make a backup of each existing destination file
-b
like
--backup
but does not accept an argument
-d
,
-F
,
--directory
allow the superuser to attempt to hard link directories
              (this will probably fail due to system restrictions, even
              for the superuser)
-f
,
--force
remove existing destination files
-i
,
--interactive
prompt whether to remove destinations
-L
,
--logical
dereference TARGETs that are symbolic links
-n
,
--no-dereference
treat LINK_NAME as a normal file if it is a symbolic link
              to a directory
-P
,
--physical
make hard links directly to symbolic links
-r
,
--relative
with
-s
, create links relative to link location
-s
,
--symbolic
make symbolic links instead of hard links
-S
,
--suffix
=
SUFFIX
override the usual backup suffix
-t
,
--target-directory
=
DIRECTORY
specify the DIRECTORY in which to create the links
-T
,
--no-target-directory
treat LINK_NAME as a normal file always
-v
,
--verbose
print name of each linked file
--help
display this help and exit
--version
output version information and exit

       The backup suffix is '~', unless set with
--suffix
or
       SIMPLE_BACKUP_SUFFIX."
674,4,ln,"--backup
[=
CONTROL
]
              make a backup of each existing destination file
-b
like
--backup
but does not accept an argument
-d
,
-F
,
--directory
allow the superuser to attempt to hard link directories
              (this will probably fail due to system restrictions, even
              for the superuser)
-f
,
--force
remove existing destination files
-i
,
--interactive
prompt whether to remove destinations
-L
,
--logical
dereference TARGETs that are symbolic links
-n
,
--no-dereference
treat LINK_NAME as a normal file if it is a symbolic link
              to a directory
-P
,
--physical
make hard links directly to symbolic links
-r
,
--relative
with
-s
, create links relative to link location
-s
,
--symbolic
make symbolic links instead of hard links
-S
,
--suffix
=
SUFFIX
override the usual backup suffix
-t
,
--target-directory
=
DIRECTORY
specify the DIRECTORY in which to create the links
-T
,
--no-target-directory
treat LINK_NAME as a normal file always
-v
,
--verbose
print name of each linked file
--help
display this help and exit
--version
output version information and exit

       The backup suffix is '~', unless set with
--suffix
or
       SIMPLE_BACKUP_SUFFIX. The version control method may be selected
       via the
--backup
option or through the VERSION_CONTROL environment
       variable. Here are the values:

       none, off
              never make backups (even if
--backup
is given)

       numbered, t
              make numbered backups

       existing, nil
              numbered if numbered backups exist, simple otherwise

       simple, never
              always make simple backups

       Using
-s
ignores
-L
and
-P
."
674,5,ln,"The version control method may be selected
       via the
--backup
option or through the VERSION_CONTROL environment
       variable. Here are the values:

       none, off
              never make backups (even if
--backup
is given)

       numbered, t
              make numbered backups

       existing, nil
              numbered if numbered backups exist, simple otherwise

       simple, never
              always make simple backups

       Using
-s
ignores
-L
and
-P
. Otherwise, the last option specified
       controls behavior when a TARGET is a symbolic link, defaulting to
-P
."
675,0,lkbib,nan
676,0,ln,"In the first synopsis form, the
ln
utility shall create a new
       directory entry (link) at the destination path specified by the
target_file
operand. If the
-s
option is specified, a symbolic
       link shall be created for the file specified by the
source_file
operand. This first synopsis form shall be assumed when the final
       operand does not name an existing directory; if more than two
       operands are specified and the final is not an existing directory,
       an error shall result."
676,1,ln,"This first synopsis form shall be assumed when the final
       operand does not name an existing directory; if more than two
       operands are specified and the final is not an existing directory,
       an error shall result. In the second synopsis form, the
ln
utility shall create a new
       directory entry (link), or if the
-s
option is specified a
       symbolic link, for each file specified by a
source_file
operand,
       at a destination path in the existing directory named by
target_dir
. If the last operand specifies an existing file of a type not
       specified by the System Interfaces volume of POSIX.1â2017, the
       behavior is implementation-defined."
676,2,ln,"If the last operand specifies an existing file of a type not
       specified by the System Interfaces volume of POSIX.1â2017, the
       behavior is implementation-defined. The corresponding destination path for each
source_file
shall be
       the concatenation of the target directory pathname, a <slash>
       character if the target directory pathname did not end in a
       <slash>, and the last pathname component of the
source_file
. The
       second synopsis form shall be assumed when the final operand names
       an existing directory."
676,3,ln,"The
       second synopsis form shall be assumed when the final operand names
       an existing directory. For each
source_file
:

        1. If the destination path exists and was created by a previous
           step, it is unspecified whether
ln
shall write a diagnostic
           message to standard error, do nothing more with the current
source_file
, and go on to any remaining
source_file
s; or will
           continue processing the current
source_file
."
676,4,ln,"If the destination path exists and was created by a previous
           step, it is unspecified whether
ln
shall write a diagnostic
           message to standard error, do nothing more with the current
source_file
, and go on to any remaining
source_file
s; or will
           continue processing the current
source_file
. If the
           destination path exists:

            a. If the
-f
option is not specified,
ln
shall write a
               diagnostic message to standard error, do nothing more with
               the current
source_file
, and go on to any remaining
source_file
s."
676,5,ln,"If the
-f
option is not specified,
ln
shall write a
               diagnostic message to standard error, do nothing more with
               the current
source_file
, and go on to any remaining
source_file
s. b. If the destination path names the same directory entry as
               the current
source_file ln
shall write a diagnostic
               message to standard error, do nothing more with the
               current
source_file
, and go on to any remaining
source_file
s
."
676,6,ln,"If the destination path names the same directory entry as
               the current
source_file ln
shall write a diagnostic
               message to standard error, do nothing more with the
               current
source_file
, and go on to any remaining
source_file
s
. c. Actions shall be performed equivalent to the
unlink
()
               function defined in the System Interfaces volume of
               POSIX.1â2017, called using the destination path as the
path
argument."
676,7,ln,"Actions shall be performed equivalent to the
unlink
()
               function defined in the System Interfaces volume of
               POSIX.1â2017, called using the destination path as the
path
argument. If this fails for any reason,
ln
shall
               write a diagnostic message to standard error, do nothing
               more with the current
source_file
, and go on to any
               remaining
source_file
s. 2."
676,8,ln,"2. If the
-s
option is specified, actions shall be performed
           equivalent to the
symlink
() function with
source_file
as the
path1
argument and the destination path as the
path2
argument. The
ln
utility shall do nothing more with
source_file
and
           shall go on to any remaining files."
676,9,ln,"The
ln
utility shall do nothing more with
source_file
and
           shall go on to any remaining files. 3. If
source_file
is a symbolic link:

            a."
676,10,ln,"If
source_file
is a symbolic link:

            a. If the
-P
option is in effect, actions shall be performed
               equivalent to the
linkat
() function with
source_file
as
               the
path1
argument, the destination path as the
path2
argument, AT_FDCWD as the
fd1
and
fd2
arguments, and zero
               as the
flag
argument. b."
676,11,ln,"b. If the
-L
option is in effect, actions shall be performed
               equivalent to the
linkat
() function with
source_file
as
               the
path1
argument, the destination path as the
path2
argument, AT_FDCWD as the
fd1
and
fd2
arguments, and
               AT_SYMLINK_FOLLOW as the
flag
argument. The
ln
utility shall do nothing more with
source_file
and
           shall go on to any remaining files."
676,12,ln,"The
ln
utility shall do nothing more with
source_file
and
           shall go on to any remaining files. 4. Actions shall be performed equivalent to the
link
() function
           defined in the System Interfaces volume of POSIX.1â2017 using
source_file
as the
path1
argument, and the destination path as
           the
path2
argument."
677,0,loadkeys,"The program
loadkeys
reads the file or files specified by
FILENAME... . Its main purpose is to load the kernel keymap for
       the console."
677,1,loadkeys,". Its main purpose is to load the kernel keymap for
       the console. You can specify console device by the
-C
(or
--console
) option."
678,0,locale,"The
locale
command displays information about the current locale,
       or all locales, on standard output. When invoked without arguments,
locale
displays the current locale
       settings for each locale category (see
locale(5)
), based on the
       settings of the environment variables that control the locale (see
locale(7)
). Values for variables set in the environment are
       printed without double quotes, implied values are printed with
       double quotes."
678,1,locale,"Values for variables set in the environment are
       printed without double quotes, implied values are printed with
       double quotes. If either the
-a
or the
-m
option (or one of their long-format
       equivalents) is specified, the behavior is as follows:
--all-locales
-a
Display a list of all available locales. The
-v
option
              causes the
LC_IDENTIFICATION
metadata about each locale to
              be included in the output."
678,2,locale,"The
-v
option
              causes the
LC_IDENTIFICATION
metadata about each locale to
              be included in the output. --charmaps
-m
Display the available charmaps (character set description
              files). To display the current character set for the
              locale, use
locale -c charmap
."
678,3,locale,"To display the current character set for the
              locale, use
locale -c charmap
. The
locale
command can also be provided with one or more
       arguments, which are the names of locale keywords (for example,
date_fmt
,
ctype-class-names
,
yesexpr
, or
decimal_point
) or locale
       categories (for example,
LC_CTYPE
or
LC_TIME
). For each argument,
       the following is displayed:

       â¢  For a locale keyword, the value of that keyword to be
          displayed."
678,4,locale,"For each argument,
       the following is displayed:

       â¢  For a locale keyword, the value of that keyword to be
          displayed. â¢  For a locale category, the values of all keywords in that
          category are displayed. When arguments are supplied, the following options are meaningful:
--category-name
-c
For a category name argument, write the name of the locale
              category on a separate line preceding the list of keyword
              values for that category."
678,5,locale,"When arguments are supplied, the following options are meaningful:
--category-name
-c
For a category name argument, write the name of the locale
              category on a separate line preceding the list of keyword
              values for that category. For a keyword name argument, write the name of the locale
              category for this keyword on a separate line preceding the
              keyword value. This option improves readability when multiple name
              arguments are specified."
678,6,locale,"This option improves readability when multiple name
              arguments are specified. It can be combined with the
-k
option. --keyword-name
-k
For each keyword whose value is being displayed, include
              also the name of that keyword, so that the output has the
              format:
keyword
=""
value
""

       The
locale
command also knows about the following options:
--verbose
-v
Display additional information for some command-line option
              and argument combinations."
678,7,locale,"--keyword-name
-k
For each keyword whose value is being displayed, include
              also the name of that keyword, so that the output has the
              format:
keyword
=""
value
""

       The
locale
command also knows about the following options:
--verbose
-v
Display additional information for some command-line option
              and argument combinations. --help
-? Display a summary of command-line options and arguments and
              exit."
678,8,locale,"Display a summary of command-line options and arguments and
              exit. --usage
Display a short usage message and exit. --version
-V
Display the program version and exit."
679,0,locale,"The
locale
utility shall write information about the current
       locale environment, or all public locales, to the standard output. For the purposes of this section, a
public locale
is one provided
       by the implementation that is accessible to the application. When
locale
is invoked without any arguments, it shall summarize
       the current locale environment for each locale category as
       determined by the settings of the environment variables defined in
       the Base Definitions volume of POSIX.1â2017,
Chapter 7
,
Locale
."
679,1,locale,"When
locale
is invoked without any arguments, it shall summarize
       the current locale environment for each locale category as
       determined by the settings of the environment variables defined in
       the Base Definitions volume of POSIX.1â2017,
Chapter 7
,
Locale
. When invoked with operands, it shall write values that have been
       assigned to the keywords in the locale categories, as follows:

        *  Specifying a keyword name shall select the named keyword and
           the category containing that keyword. *  Specifying a category name shall select the named category and
           all keywords in that category."
680,0,locate,"This manual page documents the GNU version of
locate
. For each
       given pattern,
locate
searches one or more databases of file names
       and displays the file names that contain the pattern. Patterns
       can contain shell-style metacharacters: `*', `?', and `[]'."
680,1,locate,"Patterns
       can contain shell-style metacharacters: `*', `?', and `[]'. The
       metacharacters do not treat `/' or `.'  specially. Therefore, a
       pattern `foo*bar' can match a file name that contains `foo3/bar',
       and a pattern `*duck*' can match a file name that contains
       `lake/.ducky'."
680,2,locate,"Therefore, a
       pattern `foo*bar' can match a file name that contains `foo3/bar',
       and a pattern `*duck*' can match a file name that contains
       `lake/.ducky'. Patterns that contain metacharacters should be
       quoted to protect them from expansion by the shell. If a pattern is a plain string â it contains no metacharacters â
locate
displays all file names in the database that contain that
       string anywhere."
680,3,locate,"If a pattern is a plain string â it contains no metacharacters â
locate
displays all file names in the database that contain that
       string anywhere. If a pattern does contain metacharacters,
locate
only displays file names that match the pattern exactly. As a
       result, patterns that contain metacharacters should usually begin
       with a `*', and will most often end with one as well."
680,4,locate,"As a
       result, patterns that contain metacharacters should usually begin
       with a `*', and will most often end with one as well. The
       exceptions are patterns that are intended to explicitly match the
       beginning or end of a file name. The file name databases contain lists of files that were on the
       system when the databases were last updated."
680,5,locate,"The file name databases contain lists of files that were on the
       system when the databases were last updated. The system
       administrator can choose the file name of the default database,
       the frequency with which the databases are updated, and the
       directories for which they contain entries; see
updatedb(1)
. If
locate
's output is going to a terminal, unusual characters in
       the output are escaped in the same way as for the -print action of
       the
find
command."
680,6,locate,"The system
       administrator can choose the file name of the default database,
       the frequency with which the databases are updated, and the
       directories for which they contain entries; see
updatedb(1)
. If
locate
's output is going to a terminal, unusual characters in
       the output are escaped in the same way as for the -print action of
       the
find
command. If the output is not going to a terminal, file
       names are printed exactly as-is."
681,0,localedef,"The
localedef
utility shall convert source definitions for locale
       categories into a format usable by the functions and utilities
       whose operational behavior is determined by the setting of the
       locale environment variables defined in the Base Definitions
       volume of POSIX.1â2017,
Chapter 7
,
Locale
. It is implementation-
       defined whether users have the capability to create new locales,
       in addition to those supplied by the implementation. If the
       symbolic constant POSIX2_LOCALEDEF is defined, the system supports
       the creation of new locales."
681,1,localedef,"If the
       symbolic constant POSIX2_LOCALEDEF is defined, the system supports
       the creation of new locales. On XSI-conformant systems, the
       symbolic constant POSIX2_LOCALEDEF shall be defined. The utility shall read source definitions for one or more locale
       categories belonging to the same locale from the file named in the
-i
option (if specified) or from standard input."
681,2,localedef,"The utility shall read source definitions for one or more locale
       categories belonging to the same locale from the file named in the
-i
option (if specified) or from standard input. The
name
operand identifies the target locale. The utility shall
       support the creation of
public
, or generally accessible locales,
       as well as
private
, or restricted-access locales."
681,3,localedef,"The utility shall
       support the creation of
public
, or generally accessible locales,
       as well as
private
, or restricted-access locales. Implementations
       may restrict the capability to create or modify public locales to
       users with appropriate privileges. Each category source definition shall be identified by the
       corresponding environment variable name and terminated by an
END
category-name
statement."
681,4,localedef,"Each category source definition shall be identified by the
       corresponding environment variable name and terminated by an
END
category-name
statement. The following categories shall be
       supported. In addition, the input may contain source for
       implementation-defined categories."
681,5,localedef,"In addition, the input may contain source for
       implementation-defined categories. LC_CTYPE
Defines character classification and case conversion. LC_COLLATE
Defines collation rules."
681,6,localedef,"LC_COLLATE
Defines collation rules. LC_MONETARY
Defines the format and symbols used in formatting of
                 monetary information. LC_NUMERIC
Defines the decimal delimiter, grouping, and grouping
                 symbol for non-monetary numeric editing."
681,7,localedef,"LC_NUMERIC
Defines the decimal delimiter, grouping, and grouping
                 symbol for non-monetary numeric editing. LC_TIME
Defines the format and content of date and time
                 information. LC_MESSAGES
Defines the format and values of affirmative and
                 negative responses."
682,0,localedef,"The
localedef
program reads the indicated
charmap
and
input
files,
       compiles them to a binary form quickly usable by the locale
       functions in the C library (
setlocale(3)
,
localeconv(3)
, etc.),
       and places the output in
outputpath
. The
outputpath
argument is interpreted as follows:

       â¢  If
outputpath
contains a slash character ('/'), it is
          interpreted as the name of the directory where the output
          definitions are to be stored. In this case, there is a
          separate output file for each locale category (
LC_TIME
,
LC_NUMERIC
, and so on)."
682,1,localedef,"In this case, there is a
          separate output file for each locale category (
LC_TIME
,
LC_NUMERIC
, and so on). â¢  If the
--no-archive
option is used,
outputpath
is the name of a
          subdirectory in
/usr/lib/locale
where per-category compiled
          files are placed. â¢  Otherwise,
outputpath
is the name of a locale and the compiled
          locale data is added to the archive file
/usr/lib/locale/locale-archive
."
682,2,localedef,"â¢  Otherwise,
outputpath
is the name of a locale and the compiled
          locale data is added to the archive file
/usr/lib/locale/locale-archive
. A locale archive is a memory-
          mapped file which contains all the system-provided locales; it
          is used by all localized programs when the environment variable
LOCPATH
is not set. In any case,
localedef
aborts if the directory in which it tries
       to write locale files has not already been created."
682,3,localedef,"In any case,
localedef
aborts if the directory in which it tries
       to write locale files has not already been created. If no
charmapfile
is given, the value
ANSI_X3.4-1968
(for ASCII)
       is used by default. If no
inputfile
is given, or if it is given
       as a dash (-),
localedef
reads from standard input."
683,0,logger,"logger
makes entries in the system log.

       When the optional
message
argument is present, it is written to
       the log. If it is not present, and the
-f
option is not given
       either, then standard input is logged."
684,0,localectl,"localectl
may be used to query and change the system locale and
       keyboard layout settings. It communicates with
systemd-localed(8)
to modify files such as /etc/locale.conf and /etc/vconsole.conf. The system locale controls the language settings of system
       services and of the UI before the user logs in, such as the
       display manager, as well as the default for users after login."
684,1,localectl,"The system locale controls the language settings of system
       services and of the UI before the user logs in, such as the
       display manager, as well as the default for users after login. The keyboard settings control the keyboard layout used on the text
       console and of the graphical UI before the user logs in, such as
       the display manager, as well as the default for users after login. Note that the changes performed using this tool might require the
       initrd to be rebuilt to take effect during early system boot."
684,2,localectl,"Note that the changes performed using this tool might require the
       initrd to be rebuilt to take effect during early system boot. The
       initrd is not rebuilt automatically by localectl, this task has to
       be performed manually, usually by reinstalling the distribution's
       kernel package. Note that
systemd-firstboot(1)
may be used to initialize the
       system locale for mounted (but not booted) system images."
685,0,logger,"The
logger
utility saves a message, in an unspecified manner and
       format, containing the
string
operands provided by the user. The
       messages are expected to be evaluated later by personnel
       performing system administration tasks.

       It is implementation-defined whether messages written in locales
       other than the POSIX locale are effective."
686,0,logname,"Print the user's login name.
--help
display this help and exit
--version
output version information and exit"
687,0,logname,"The
logname
utility shall write the user's login name to standard
       output. The login name shall be the string that would be returned
       by the
getlogin
() function defined in the System Interfaces volume
       of POSIX.1â2017. Under the conditions where the
getlogin
()
       function would fail, the
logname
utility shall write a diagnostic
       message to standard error and exit with a non-zero exit status."
688,0,login,"login
is used when signing onto a system. If no argument is given,
login
prompts for the username. The user is then prompted for a password, where appropriate."
688,1,login,"The user is then prompted for a password, where appropriate. Echoing is disabled to prevent revealing the password. Only a
       number of password failures are permitted before
login
exits and
       the communications link is severed."
688,2,login,"Only a
       number of password failures are permitted before
login
exits and
       the communications link is severed. See
LOGIN_RETRIES
in the
CONFIG FILE ITEMS
section. If password aging has been enabled for the account, the user may
       be prompted for a new password before proceeding."
688,3,login,"If password aging has been enabled for the account, the user may
       be prompted for a new password before proceeding. In such case old
       password must be provided and the new password entered before
       continuing. Please refer to
passwd(1)
for more information."
688,4,login,"Please refer to
passwd(1)
for more information. The user and group ID will be set according to their values in the
/etc/passwd
file. There is one exception if the user ID is zero."
688,5,login,"There is one exception if the user ID is zero. In this case, only the primary group ID of the account is set. This should allow the system administrator to login even in case
       of network problems."
688,6,login,"This should allow the system administrator to login even in case
       of network problems. The environment variable values for
$HOME
,
$USER
,
$SHELL
,
$PATH
,
$LOGNAME
, and
$MAIL
are set according to the
       appropriate fields in the password entry. $PATH
defaults to
/usr/local/bin:/bin:/usr/bin
for normal users, and to
/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin
for
       root, if not otherwise configured."
688,7,login,"$PATH
defaults to
/usr/local/bin:/bin:/usr/bin
for normal users, and to
/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin
for
       root, if not otherwise configured. The environment variable
$TERM
will be preserved, if it exists,
       else it will be initialized to the terminal type on your tty. Other environment variables are preserved if the
-p
option is
       given."
688,8,login,"Other environment variables are preserved if the
-p
option is
       given. The environment variables defined by PAM are always preserved. Then the userâs shell is started."
688,9,login,"Then the userâs shell is started. If no shell is specified for the
       user in
/etc/passwd
, then
/bin/sh
is used. If the specified shell
       contains a space, it is treated as a shell script."
688,10,login,"If the specified shell
       contains a space, it is treated as a shell script. If there is no
       home directory specified in
/etc/passwd
, then
/
is used, followed
       by
.hushlogin
check as described below. If the file
.hushlogin
exists, then a ""quiet"" login is performed."
688,11,login,"If the file
.hushlogin
exists, then a ""quiet"" login is performed. This disables the checking of mail and the printing of the last
       login time and message of the day. Otherwise, if
/var/log/lastlog
exists, the last login time is printed, and the current login is
       recorded."
689,0,loginctl,"loginctl
may be used to introspect and control the state of the
systemd(1)
login manager
systemd-logind.service(8)
."
690,0,look,"The
look
utility displays any lines in
file
which contain
string
as a prefix. As
look
performs a binary search, the lines in
file
must be sorted (where
sort(1)
was given the same options
-d
and/or
-f
that
look
is invoked with).

       If
file
is not specified, the file
/usr/share/dict/words
is used,
       only alphanumeric characters are compared and the case of
       alphabetic characters is ignored."
691,0,lookbib,nan
692,0,lp,"lp
submits files for printing or alters a pending job. Use a
       filename of ""-"" to force printing from the standard input. THE DEFAULT DESTINATION
CUPS provides many ways to set the default destination."
692,1,lp,"THE DEFAULT DESTINATION
CUPS provides many ways to set the default destination. The
LPDEST
and
PRINTER
environment variables are consulted first. If neither
       are set, the current default set using the
lpoptions(1)
command is
       used, followed by the default set using the
lpadmin(8)
command."
693,0,lpq,"lpq
shows the current print queue status on the named printer.
       Jobs queued on the default destination will be shown if no printer
       or class is specified on the command-line.

       The
+interval
option allows you to continuously report the jobs in
       the queue until the queue is empty; the list of jobs is shown once
       every
interval
seconds."
694,0,lpoptions,"lpoptions
displays or sets printer options and defaults. If no
       printer is specified using the
-p
option, the default printer is
       used as described in
lp(1)
. If no
-l
,
-o
, or
-r
options are specified, the current options are
       reported on the standard output."
694,1,lpoptions,"If no
-l
,
-o
, or
-r
options are specified, the current options are
       reported on the standard output. Options set with the
lpoptions
command are used by the
lp(1)
and
lpr(1)
commands when submitting jobs. When run by the root user,
lpoptions
gets and sets default options
       and instances for all users in the
/etc/cups/lpoptions
file."
694,2,lpoptions,"Options set with the
lpoptions
command are used by the
lp(1)
and
lpr(1)
commands when submitting jobs. When run by the root user,
lpoptions
gets and sets default options
       and instances for all users in the
/etc/cups/lpoptions
file. Otherwise, the per-user defaults are managed in the
~/.cups/lpoptions
file."
695,0,lp,"The
lp
utility shall copy the input files to an output destination
       in an unspecified manner. The default output destination should be
       to a hardcopy device, such as a printer or microfilm recorder,
       that produces non-volatile, human-readable documents. If such a
       device is not available to the application, or if the system
       provides no such device, the
lp
utility shall exit with a non-zero
       exit status."
695,1,lp,"If such a
       device is not available to the application, or if the system
       provides no such device, the
lp
utility shall exit with a non-zero
       exit status. The actual writing to the output device may occur some time after
       the
lp
utility successfully exits. During the portion of the
       writing that corresponds to each input file, the implementation
       shall guarantee exclusive access to the device."
695,2,lp,"During the portion of the
       writing that corresponds to each input file, the implementation
       shall guarantee exclusive access to the device. The
lp
utility shall associate a unique
request ID
with each
       request. Normally, a banner page is produced to separate and identify each
       print job."
695,3,lp,"The
lp
utility shall associate a unique
request ID
with each
       request. Normally, a banner page is produced to separate and identify each
       print job. This page may be suppressed by implementation-defined
       conditions, such as an operator command or one of the
-o
option
values."
696,0,lpr,"lpr
submits files for printing. Files named on the command line
       are sent to the named printer or the default destination if no
       destination is specified. If no files are listed on the command-
       line,
lpr
reads the print file from the standard input."
696,1,lpr,"If no files are listed on the command-
       line,
lpr
reads the print file from the standard input. THE DEFAULT DESTINATION
CUPS provides many ways to set the default destination. The
LPDEST
and
PRINTER
environment variables are consulted first."
696,2,lpr,"THE DEFAULT DESTINATION
CUPS provides many ways to set the default destination. The
LPDEST
and
PRINTER
environment variables are consulted first. If neither
       are set, the current default set using the
lpoptions(1)
command is
       used, followed by the default set using the
lpadmin(8)
command."
697,0,lprm,"lprm
cancels print jobs that have been queued for printing.  If no
       arguments are supplied, the current job on the default destination
       is canceled.  You can specify one or more job ID numbers to cancel
       those jobs or use the
-
option to cancel all jobs."
698,0,ls,"List information about the FILEs (the current directory by
       default). Sort entries alphabetically if none of
-cftuvSUX
nor
--sort
is specified. Mandatory arguments to long options are mandatory for short
       options too."
698,1,ls,"Mandatory arguments to long options are mandatory for short
       options too. -a
,
--all
do not ignore entries starting with . -A
,
--almost-all
do not list implied ."
698,2,ls,"-A
,
--almost-all
do not list implied . and .. --author
with
-l
, print the author of each file
-b
,
--escape
print C-style escapes for nongraphic characters
--block-size
=
SIZE
with
-l
, scale sizes by SIZE when printing them; e.g.,
              '--block-size=M'; see SIZE format below
-B
,
--ignore-backups
do not list implied entries ending with ~
-c
with
-lt
: sort by, and show, ctime (time of last change of
              file status information); with
-l
: show ctime and sort by
              name; otherwise: sort by ctime, newest first
-C
list entries by columns
--color
[=
WHEN
]
              color the output WHEN; more info below
-d
,
--directory
list directories themselves, not their contents
-D
,
--dired
generate output designed for Emacs' dired mode
-f
same as
-a -U
-F
,
--classify
[=
WHEN
]
              append indicator (one of */=>@|) to entries WHEN
--file-type
likewise, except do not append '*'
--format
=
WORD
across
-x
, commas
-m
, horizontal
-x
, long
-l
, single-column
-1
, verbose
-l
, vertical
-C
--full-time
like
-l --time-style
=
full-iso
-g
like
-l
, but do not list owner
--group-directories-first
group directories before files
-G
,
--no-group
in a long listing, don't print group names
-h
,
--human-readable
with
-l
and
-s
, print sizes like 1K 234M 2G etc."
698,3,ls,"--author
with
-l
, print the author of each file
-b
,
--escape
print C-style escapes for nongraphic characters
--block-size
=
SIZE
with
-l
, scale sizes by SIZE when printing them; e.g.,
              '--block-size=M'; see SIZE format below
-B
,
--ignore-backups
do not list implied entries ending with ~
-c
with
-lt
: sort by, and show, ctime (time of last change of
              file status information); with
-l
: show ctime and sort by
              name; otherwise: sort by ctime, newest first
-C
list entries by columns
--color
[=
WHEN
]
              color the output WHEN; more info below
-d
,
--directory
list directories themselves, not their contents
-D
,
--dired
generate output designed for Emacs' dired mode
-f
same as
-a -U
-F
,
--classify
[=
WHEN
]
              append indicator (one of */=>@|) to entries WHEN
--file-type
likewise, except do not append '*'
--format
=
WORD
across
-x
, commas
-m
, horizontal
-x
, long
-l
, single-column
-1
, verbose
-l
, vertical
-C
--full-time
like
-l --time-style
=
full-iso
-g
like
-l
, but do not list owner
--group-directories-first
group directories before files
-G
,
--no-group
in a long listing, don't print group names
-h
,
--human-readable
with
-l
and
-s
, print sizes like 1K 234M 2G etc. --si
likewise, but use powers of 1000 not 1024
-H
,
--dereference-command-line
follow symbolic links listed on the command line
--dereference-command-line-symlink-to-dir
follow each command line symbolic link that points to a
              directory
--hide
=
PATTERN
do not list implied entries matching shell PATTERN
              (overridden by
-a
or
-A
)
--hyperlink
[=
WHEN
]
              hyperlink file names WHEN
--indicator-style
=
WORD
append indicator with style WORD to entry names: none
              (default), slash (
-p
), file-type (
--file-type
), classify
              (
-F
)
-i
,
--inode
print the index number of each file
-I
,
--ignore
=
PATTERN
do not list implied entries matching shell PATTERN
-k
,
--kibibytes
default to 1024-byte blocks for file system usage; used
              only with
-s
and per directory totals
-l
use a long listing format
-L
,
--dereference
when showing file information for a symbolic link, show
              information for the file the link references rather than
              for the link itself
-m
fill width with a comma separated list of entries
-n
,
--numeric-uid-gid
like
-l
, but list numeric user and group IDs
-N
,
--literal
print entry names without quoting
-o
like
-l
, but do not list group information
-p
,
--indicator-style
=
slash
append / indicator to directories
-q
,
--hide-control-chars
print ? instead of nongraphic characters
--show-control-chars
show nongraphic characters as-is (the default, unless
              program is 'ls' and output is a terminal)
-Q
,
--quote-name
enclose entry names in double quotes
--quoting-style
=
WORD
use quoting style WORD for entry names: literal, locale,
              shell, shell-always, shell-escape, shell-escape-always, c,
              escape (overrides QUOTING_STYLE environment variable)
-r
,
--reverse
reverse order while sorting
-R
,
--recursive
list subdirectories recursively
-s
,
--size
print the allocated size of each file, in blocks
-S
sort by file size, largest first
--sort
=
WORD
change default 'name' sort to WORD: none (
-U
), size (
-S
),
              time (
-t
), version (
-v
), extension (
-X
), name, width
--time
=
WORD
select which timestamp used to display or sort; access time
              (
-u
): atime, access, use; metadata change time (
-c
): ctime,
              status; modified time (default): mtime, modification; birth
              time: birth, creation;

              with
-l
, WORD determines which time to show; with
--sort
=
time
, sort by WORD (newest first)
--time-style
=
TIME_STYLE
time/date format with
-l
; see TIME_STYLE below
-t
sort by time, newest first; see
--time
-T
,
--tabsize
=
COLS
assume tab stops at each COLS instead of 8
-u
with
-lt
: sort by, and show, access time; with
-l
: show
              access time and sort by name; otherwise: sort by access
              time, newest first
-U
do not sort directory entries
-v
natural sort of (version) numbers within text
-w
,
--width
=
COLS
set output width to COLS."
698,4,ls,"instead of nongraphic characters
--show-control-chars
show nongraphic characters as-is (the default, unless
              program is 'ls' and output is a terminal)
-Q
,
--quote-name
enclose entry names in double quotes
--quoting-style
=
WORD
use quoting style WORD for entry names: literal, locale,
              shell, shell-always, shell-escape, shell-escape-always, c,
              escape (overrides QUOTING_STYLE environment variable)
-r
,
--reverse
reverse order while sorting
-R
,
--recursive
list subdirectories recursively
-s
,
--size
print the allocated size of each file, in blocks
-S
sort by file size, largest first
--sort
=
WORD
change default 'name' sort to WORD: none (
-U
), size (
-S
),
              time (
-t
), version (
-v
), extension (
-X
), name, width
--time
=
WORD
select which timestamp used to display or sort; access time
              (
-u
): atime, access, use; metadata change time (
-c
): ctime,
              status; modified time (default): mtime, modification; birth
              time: birth, creation;

              with
-l
, WORD determines which time to show; with
--sort
=
time
, sort by WORD (newest first)
--time-style
=
TIME_STYLE
time/date format with
-l
; see TIME_STYLE below
-t
sort by time, newest first; see
--time
-T
,
--tabsize
=
COLS
assume tab stops at each COLS instead of 8
-u
with
-lt
: sort by, and show, access time; with
-l
: show
              access time and sort by name; otherwise: sort by access
              time, newest first
-U
do not sort directory entries
-v
natural sort of (version) numbers within text
-w
,
--width
=
COLS
set output width to COLS. 0 means no limit
-x
list entries by lines instead of by columns
-X
sort alphabetically by entry extension
-Z
,
--context
print any security context of each file
--zero
end each output line with NUL, not newline
-1
list one file per line
--help
display this help and exit
--version
output version information and exit

       The SIZE argument is an integer and optional unit (example: 10K is
       10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,..."
698,5,ls,"Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,... (powers of 1000). Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on."
698,6,ls,"Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on. The TIME_STYLE argument can be full-iso, long-iso, iso, locale, or
       +FORMAT. FORMAT is interpreted like in
date(1)
."
698,7,ls,"FORMAT is interpreted like in
date(1)
. If FORMAT is
       FORMAT1<newline>FORMAT2, then FORMAT1 applies to non-recent files
       and FORMAT2 to recent files. TIME_STYLE prefixed with 'posix-'
       takes effect only outside the POSIX locale."
698,8,ls,"TIME_STYLE prefixed with 'posix-'
       takes effect only outside the POSIX locale. Also the TIME_STYLE
       environment variable sets the default style to use. The WHEN argument defaults to 'always' and can also be 'auto' or
       'never'."
698,9,ls,"The WHEN argument defaults to 'always' and can also be 'auto' or
       'never'. Using color to distinguish file types is disabled both by default
       and with
--color
=
never
. With
--color
=
auto
, ls emits color codes
       only when standard output is connected to a terminal."
698,10,ls,"With
--color
=
auto
, ls emits color codes
       only when standard output is connected to a terminal. The
       LS_COLORS environment variable can change the settings. Use the
dircolors(1)
command to set it."
698,11,ls,"The
       LS_COLORS environment variable can change the settings. Use the
dircolors(1)
command to set it. Exit status:
0      if OK,

       1      if minor problems (e.g., cannot access subdirectory),

       2      if serious trouble (e.g., cannot access command-line
              argument)."
699,0,lpstat,"lpstat
displays status information about the current classes,
       jobs, and printers.  When run with no arguments,
lpstat
will list
       active jobs queued by the current user."
700,0,lsattr,"lsattr
lists the file attributes on an ext2/ext3/ext4 file system.
       See
chattr(1)
for a description of the attributes and what they
       mean."
701,0,ls,"For each operand that names a file of a type other than directory
       or symbolic link to a directory,
ls
shall write the name of the
       file as well as any requested, associated information. For each
       operand that names a file of type directory,
ls
shall write the
       names of files contained within the directory as well as any
       requested, associated information. Filenames beginning with a
       <period> (
'.'
)  and any associated information shall not be
       written out unless explicitly referenced, the
-A
or
-a
option is
       supplied, or an implementation-defined condition causes them to be
       written."
701,1,ls,"Filenames beginning with a
       <period> (
'.'
)  and any associated information shall not be
       written out unless explicitly referenced, the
-A
or
-a
option is
       supplied, or an implementation-defined condition causes them to be
       written. If one or more of the
-d
,
-F
, or
-l
options are
       specified, and neither the
-H
nor the
-L
option is specified, for
       each operand that names a file of type symbolic link to a
       directory,
ls
shall write the name of the file as well as any
       requested, associated information. If none of the
-d
,
-F
, or
-l
options are specified, or the
-H
or
-L
options are specified, for
       each operand that names a file of type symbolic link to a
       directory,
ls
shall write the names of files contained within the
       directory as well as any requested, associated information."
701,2,ls,"If none of the
-d
,
-F
, or
-l
options are specified, or the
-H
or
-L
options are specified, for
       each operand that names a file of type symbolic link to a
       directory,
ls
shall write the names of files contained within the
       directory as well as any requested, associated information. In
       each case where the names of files contained within a directory
       are written, if the directory contains any symbolic links then
ls
shall evaluate the file information and file type to be those of
       the symbolic link itself, unless the
-L
option is specified. If no operands are specified,
ls
shall behave as if a single
       operand of dot (
'.'
)  had been specified."
701,3,ls,"If no operands are specified,
ls
shall behave as if a single
       operand of dot (
'.'
)  had been specified. If more than one operand
       is specified,
ls
shall write non-directory operands first; it
       shall sort directory and non-directory operands separately
       according to the collating sequence in the current locale. Whenever
ls
sorts filenames or pathnames according to the
       collating sequence in the current locale, if this collating
       sequence does not have a total ordering of all characters (see the
       Base Definitions volume of POSIX.1â2017,
Section 7.3.2
,
LC_COLLATE
), then any filenames or pathnames that collate equally
       should be further compared byte-by-byte using the collating
       sequence for the POSIX locale."
701,4,ls,"Whenever
ls
sorts filenames or pathnames according to the
       collating sequence in the current locale, if this collating
       sequence does not have a total ordering of all characters (see the
       Base Definitions volume of POSIX.1â2017,
Section 7.3.2
,
LC_COLLATE
), then any filenames or pathnames that collate equally
       should be further compared byte-by-byte using the collating
       sequence for the POSIX locale. The
ls
utility shall detect infinite loops; that is, entering a
       previously visited directory that is an ancestor of the last file
       encountered. When it detects an infinite loop,
ls
shall write a
       diagnostic message to standard error and shall either recover its
       position in the hierarchy or terminate."
702,0,lsfd,"lsfd
is intended to be a modern replacement for
lsof(8)
on Linux
       systems. Unlike
lsof
,
lsfd
is specialized to Linux kernel; it
       supports Linux specific features like namespaces with simpler
       code. lsfd
is not a drop-in replacement for
lsof
; they are
       different in the command line interface and output formats."
702,1,lsfd,"lsfd
is not a drop-in replacement for
lsof
; they are
       different in the command line interface and output formats. The default output is subject to change. So whenever possible, you
       should avoid using default outputs in your scripts."
702,2,lsfd,"So whenever possible, you
       should avoid using default outputs in your scripts. Always
       explicitly define expected columns by using
--output
columns-list
in environments where a stable output is required. lsfd
uses Libsmartcols for output formatting and filtering."
702,3,lsfd,"lsfd
uses Libsmartcols for output formatting and filtering. See
       the description of
--output
option for customizing the output
       format, and
--filter
option for filtering. Use
lsfd --list-columns
to get a list of all available columns."
703,0,lsinitrd,"lsinitrd shows the contents of an initramfs image. if <image> is
       omitted, then lsinitrd determines the default location based on
       the local configuration or Linux distribution policy."
704,0,lsclocks,"lsclocks
is a simple command to display system clocks.

       It allows to display information like current time and resolution
       of clocks like CLOCK_MONOTONIC, CLOCK_REALTIME and CLOCK_BOOTTIME."
705,0,lscpu,"lscpu
gathers CPU architecture information from
sysfs
,
/proc/cpuinfo
and any applicable architecture-specific libraries
       (e.g. librtas
on Powerpc). The command output can be optimized for
       parsing or for easy readability by humans."
705,1,lscpu,"The command output can be optimized for
       parsing or for easy readability by humans. The information
       includes, for example, the number of CPUs, threads, cores,
       sockets, and Non-Uniform Memory Access (NUMA) nodes. There is also
       information about the CPU caches and cache sharing, family, model,
       bogoMIPS, byte order, and stepping."
705,2,lscpu,"There is also
       information about the CPU caches and cache sharing, family, model,
       bogoMIPS, byte order, and stepping. The default output formatting on terminal is subject to change and
       maybe optimized for better readability. The output for
       non-terminals (e.g., pipes) is never affected by this optimization
       and it is always in ""Field: data\n"" format."
705,3,lscpu,"The output for
       non-terminals (e.g., pipes) is never affected by this optimization
       and it is always in ""Field: data\n"" format. Use for example ""
lscpu
| less
"" to see the default output without optimizations. In virtualized environments, the CPU architecture information
       displayed reflects the configuration of the guest operating system
       which is typically different from the physical (host) system."
705,4,lscpu,"In virtualized environments, the CPU architecture information
       displayed reflects the configuration of the guest operating system
       which is typically different from the physical (host) system. On
       architectures that support retrieving physical topology
       information,
lscpu
also displays the number of physical sockets,
       chips, cores in the host system. Options that result in an output table have a
list
argument."
705,5,lscpu,"Options that result in an output table have a
list
argument. Use
       this argument to customize the command output. Specify a
       comma-separated list of column labels to limit the output table to
       only the specified columns, arranged in the specified order."
705,6,lscpu,"Specify a
       comma-separated list of column labels to limit the output table to
       only the specified columns, arranged in the specified order. See
COLUMNS
for a list of valid column labels. The column labels are
       not case sensitive."
705,7,lscpu,"The column labels are
       not case sensitive. Not all columns are supported on all architectures. If an
       unsupported column is specified,
lscpu
prints the column but does
       not provide any data for it."
705,8,lscpu,"If an
       unsupported column is specified,
lscpu
prints the column but does
       not provide any data for it. The cache sizes are reported as summary from all CPUs. The
       versions before v2.34 reported per-core sizes, but this output was
       confusing due to complicated CPUs topology and the way how caches
       are shared between CPUs."
705,9,lscpu,"The
       versions before v2.34 reported per-core sizes, but this output was
       confusing due to complicated CPUs topology and the way how caches
       are shared between CPUs. For more details about caches see
--cache
. Since version v2.37
lscpu
follows cache IDs as provided
       by Linux kernel and it does not always start from zero."
706,0,lsirq,"Display kernel interrupt counter information. The default output is subject to change. So whenever possible, you
       should avoid using default outputs in your scripts."
706,1,lsirq,"The default output is subject to change. So whenever possible, you
       should avoid using default outputs in your scripts. Always
       explicitly define expected columns by using
--output
."
707,0,lsipc,"lsipc
shows information on the System V inter-process
       communication facilities for which the calling process has read
       access."
708,0,ltrace,"ltrace
is a program that simply runs the specified
command
until
       it exits. It intercepts and records the dynamic library calls
       which are called by the executed process and the signals which are
       received by that process. It can also intercept and print the
       system calls executed by the program."
708,1,ltrace,"It can also intercept and print the
       system calls executed by the program. Its use is very similar to
strace(1)
. ltrace
shows parameters of invoked functions and system calls."
708,2,ltrace,"ltrace
shows parameters of invoked functions and system calls. To
       determine what arguments each function has, it needs external
       declaration of function prototypes. Those are stored in files
       called
prototype libraries
--see ltrace.conf(5) for details on the
       syntax of these files."
708,3,ltrace,"To
       determine what arguments each function has, it needs external
       declaration of function prototypes. Those are stored in files
       called
prototype libraries
--see ltrace.conf(5) for details on the
       syntax of these files. See the section
PROTOTYPE LIBRARY
DISCOVERY
to learn how
ltrace
finds prototype libraries."
709,0,lsmem,"The
lsmem
command lists the ranges of available memory with their
       online status. The listed memory blocks correspond to the memory
       block representation in sysfs. The command also shows the memory
       block size and the amount of memory in online and offline state."
709,1,lsmem,"The command also shows the memory
       block size and the amount of memory in online and offline state. The default output is compatible with original implementation from
       s390-tools, but itâs strongly recommended to avoid using default
       outputs in your scripts. Always explicitly define expected columns
       by using the
--output
option together with a columns list in
       environments where a stable output is required."
709,2,lsmem,"Always explicitly define expected columns
       by using the
--output
option together with a columns list in
       environments where a stable output is required. The
lsmem
command lists a new memory range always when the current
       memory block distinguish from the previous block by some output
       column. This default behavior is possible to override by the
--split
option (e.g.,
lsmem --split=ZONES
)."
709,3,lsmem,"This default behavior is possible to override by the
--split
option (e.g.,
lsmem --split=ZONES
). The special word
       ""none"" may be used to ignore all differences between memory blocks
       and to create as large as possible continuous ranges. The opposite
       semantic is
--all
to list individual memory blocks."
709,4,lsmem,"The opposite
       semantic is
--all
to list individual memory blocks. Note that some output columns may provide inaccurate information
       if a split policy forces
lsmem
to ignore differences in some
       attributes. For example if you merge removable and non-removable
       memory blocks to the one range than all the range will be marked
       as non-removable on
lsmem
output."
709,5,lsmem,"For example if you merge removable and non-removable
       memory blocks to the one range than all the range will be marked
       as non-removable on
lsmem
output. Not all columns are supported on all systems. If an unsupported
       column is specified,
lsmem
prints the column but does not provide
       any data for it."
709,6,lsmem,"Not all columns are supported on all systems. If an unsupported
       column is specified,
lsmem
prints the column but does not provide
       any data for it. Use the
--help
option to see the columns description."
710,0,lsusb.py,"lsusb.py
is a utility for displaying information about USB buses
       in the system and the devices connected to them. It uses the
usb.ids
file to associate a human-readable name to the vendor and
       product IDs.

       In comparison with
lsusb(8)
, this program can display additional
       information such as the interface speed of a device, and details
       of a device's interfaces including the driver bound to them and
       Linux devices provided by the driver, and the details of device
       and interface endpoints."
711,0,lslogins,"Examine the wtmp and btmp logs,
/etc/shadow
(if necessary) and
/passwd
and output the desired data. The optional argument
username
forces
lslogins
to print all
       available details about the specified user only. In this case the
       output format is different than in case of
-l
or
-g
and unknown is
username
reported as an error."
711,1,lslogins,"The optional argument
username
forces
lslogins
to print all
       available details about the specified user only. In this case the
       output format is different than in case of
-l
or
-g
and unknown is
username
reported as an error. The default action is to list info about all the users in the
       system."
712,0,lttng-add-context,"The
lttng add-context
command adds one or more context fields to a
       channel. Channels are created with the
lttng-enable-channel(1)
command. When context fields are added to a channel, all the events emitted
       within this channel contain the dynamic values of those context
       fields."
712,1,lttng-add-context,"When context fields are added to a channel, all the events emitted
       within this channel contain the dynamic values of those context
       fields. If the
--session
option is omitted, the current tracing session is
       used. If the
--channel
option is omitted, the context fields are
       added to all the selected tracing sessionâs channels."
712,2,lttng-add-context,"If the
--channel
option is omitted, the context fields are
       added to all the selected tracing sessionâs channels. Many context fields can be added to a channel at once by repeating
       the
--type
option. perf counters are available as per-CPU (
perf:cpu:
prefix) as well
       as per-thread (
perf:thread:
prefix) counters."
712,3,lttng-add-context,"perf counters are available as per-CPU (
perf:cpu:
prefix) as well
       as per-thread (
perf:thread:
prefix) counters. Currently, per-CPU
       counters can only be used in the Linux kernel tracing domain,
       while per-thread counters can only be used in the user space
       tracing domain. It is also possible to enable PMU counters by raw ID using the
perf:cpu:raw:rN:NAME
(Linux kernel tracing domain) or
perf:thread:raw:rN:NAME
(user space tracing domain), with:
N
A hexadecimal event descriptor which is the same format as
           used by
perf-record(1)
: a concatenation of the event number
           and umask value provided by the processorâs manufacturer."
712,4,lttng-add-context,"It is also possible to enable PMU counters by raw ID using the
perf:cpu:raw:rN:NAME
(Linux kernel tracing domain) or
perf:thread:raw:rN:NAME
(user space tracing domain), with:
N
A hexadecimal event descriptor which is the same format as
           used by
perf-record(1)
: a concatenation of the event number
           and umask value provided by the processorâs manufacturer. The
           possible values for this field are processor-specific. NAME
Custom name to easily recognize the counter."
712,5,lttng-add-context,"NAME
Custom name to easily recognize the counter. Application-specific context fields can be added to a channel
       using the following syntax:

           $app. PROVIDER
:
TYPE
with:
PROVIDER
Provider name."
712,6,lttng-add-context,"PROVIDER
:
TYPE
with:
PROVIDER
Provider name. TYPE
Context type name. Note
Make sure to
single-quote
the type when running the command
           from a shell, as
$
is a special character for variable
           substitution in most shells."
712,7,lttng-add-context,"Note
Make sure to
single-quote
the type when running the command
           from a shell, as
$
is a special character for variable
           substitution in most shells. Use the
--list
option without other arguments to list the
       available context field names. See the
LIMITATIONS
section below for a list of limitations to
       consider."
713,0,lttng-calibrate,"The
lttng calibrate
commands quantifies the overhead of LTTng
       tracers. The
lttng calibrate
command can be used to find out the combined
       average overhead of the LTTng tracers and the instrumentation
       mechanisms used. This overhead can be calibrated in terms of time
       or using any of the PMU performance counter available on the
       system."
713,1,lttng-calibrate,"This overhead can be calibrated in terms of time
       or using any of the PMU performance counter available on the
       system. For now, the only implemented calibration is the Linux kernel
       function instrumentation (
kretprobes
). Calibrate Linux kernel function instrumentation
As an example, we use an i7 processor with 4 general-purpose PMU
       registers."
713,2,lttng-calibrate,"Calibrate Linux kernel function instrumentation
As an example, we use an i7 processor with 4 general-purpose PMU
       registers. This information is available by issuing
dmesg
, looking
       for
generic registers
. The following sequence of commands gathers a trace executing a
       kretprobe hooked on an empty function, gathering PMU counters LLC
       (Last Level Cache) misses information (use
lttng add-context
--list
to get the list of available PMU counters)."
713,3,lttng-calibrate,"The following sequence of commands gathers a trace executing a
       kretprobe hooked on an empty function, gathering PMU counters LLC
       (Last Level Cache) misses information (use
lttng add-context
--list
to get the list of available PMU counters). lttng create calibrate-function
           lttng enable-event calibrate --kernel \
                                        --function=lttng_calibrate_kretprobe
           lttng add-context --kernel --type=perf:cpu:LLC-load-misses \
                                      --type=perf:cpu:LLC-store-misses \
                                      --type=perf:cpu:LLC-prefetch-misses
           lttng start

           for a in $(seq 1 10); do
               lttng calibrate --kernel --function
           done

           lttng destroy
           babeltrace $(ls -1drt ~/lttng-traces/calibrate-function-* | tail -n 1)

       The output from
babeltrace
(1) can be saved to a text file and
       opened in a spreadsheet (for example, in LibreOffice) to focus on
       the per-PMU counter delta between consecutive
calibrate_entry
and
calibrate_return
events. Note that these counters are per-CPU, so
       scheduling events would need to be present to account for
       migration between CPUs."
713,4,lttng-calibrate,"Note that these counters are per-CPU, so
       scheduling events would need to be present to account for
       migration between CPUs. Therefore, for calibration purposes, only
       events staying on the same CPU must be considered. Hereâs an example of the average result, for the i7, on 10
       samples:
       ââââââââââââââââââââââââââââ¬ââââââââââ¬âââââââââââââââââââââ
       â
PMU counter
â
Average
â
Standard deviation
â
       ââââââââââââââââââââââââââââ¼ââââââââââ¼âââââââââââââââââââââ¤
       â                          â         â                    â
       â
perf_LLC_load_misses
â 5.0     â 0.577              â
       ââââââââââââââââââââââââââââ¼ââââââââââ¼âââââââââââââââââââââ¤
       â                          â         â                    â
       â
perf_LLC_store_misses
â 1.6     â 0.516              â
       ââââââââââââââââââââââââââââ¼ââââââââââ¼âââââââââââââââââââââ¤
       â                          â         â                    â
       â
perf_LLC_prefetch_misses
â 9.0     â 14.742             â
       ââââââââââââââââââââââââââââ´ââââââââââ´âââââââââââââââââââââ

       As we can notice, the load and store misses are relatively stable
       across runs (their standard deviation is relatively low) compared
       to the prefetch misses."
713,5,lttng-calibrate,"Therefore, for calibration purposes, only
       events staying on the same CPU must be considered. Hereâs an example of the average result, for the i7, on 10
       samples:
       ââââââââââââââââââââââââââââ¬ââââââââââ¬âââââââââââââââââââââ
       â
PMU counter
â
Average
â
Standard deviation
â
       ââââââââââââââââââââââââââââ¼ââââââââââ¼âââââââââââââââââââââ¤
       â                          â         â                    â
       â
perf_LLC_load_misses
â 5.0     â 0.577              â
       ââââââââââââââââââââââââââââ¼ââââââââââ¼âââââââââââââââââââââ¤
       â                          â         â                    â
       â
perf_LLC_store_misses
â 1.6     â 0.516              â
       ââââââââââââââââââââââââââââ¼ââââââââââ¼âââââââââââââââââââââ¤
       â                          â         â                    â
       â
perf_LLC_prefetch_misses
â 9.0     â 14.742             â
       ââââââââââââââââââââââââââââ´ââââââââââ´âââââââââââââââââââââ

       As we can notice, the load and store misses are relatively stable
       across runs (their standard deviation is relatively low) compared
       to the prefetch misses. We could conclude from this information
       that LLC load and store misses can be accounted for quite
       precisely, but prefetches within a function seems to behave too
       erratically (not much causality link between the code executed and
       the CPU prefetch activity) to be accounted for."
714,0,lttng-crash,"The
Linux Trace Toolkit: next generation
<
https://lttng.org/
> is
       an open source software package used for correlated tracing of the
       Linux kernel, user applications, and user libraries.

       LTTng consists of Linux kernel modules (for Linux kernel tracing)
       and dynamically loaded libraries (for user application and library
       tracing).

       The
lttng-crash
command-line tool is used to recover and view
       LTTng trace buffers in the event of a system crash."
715,0,lttng-destroy,"The
lttng destroy
command destroys one or more tracing sessions. If no options are specified, the current tracing session is
       destroyed (see
lttng-create(1)
for more information about the
       current tracing session). If
SESSION
is specified, the existing tracing session named
SESSION
is destroyed."
715,1,lttng-destroy,"If
SESSION
is specified, the existing tracing session named
SESSION
is destroyed. lttng list
outputs all the existing tracing
       sessions (see
lttng-list(1)
). If the
--all
option is used,
all
the tracing sessions, as listed
       in the output of
lttng list
, are destroyed."
715,2,lttng-destroy,"If the
--all
option is used,
all
the tracing sessions, as listed
       in the output of
lttng list
, are destroyed. Destroying a tracing session stops any tracing running within the
       latter. By default, the implicit
lttng-stop(1)
command invoked by
       the
lttng destroy
command ensures that the tracing sessionâs trace
       data is valid before returning."
715,3,lttng-destroy,"By default, the implicit
lttng-stop(1)
command invoked by
       the
lttng destroy
command ensures that the tracing sessionâs trace
       data is valid before returning. With the
--no-wait
option, the
lttng-stop(1)
command finishes immediately, hence a local trace
       might not be valid when the command is done. In this case, there
       is no way to know when the trace becomes valid."
715,4,lttng-destroy,"In this case, there
       is no way to know when the trace becomes valid. Destroying a tracing session does not destroy the recorded trace
       data, if any; it frees resources acquired by the session daemon
       and tracer side, making sure to flush all trace data. If at least one rotation occurred during the chosen tracing
       sessionâs lifetime (see
lttng-rotate(1)
and
lttng-enable-rotation(1)
), and without the
--no-wait
option, all
       the tracing sessionâs output directoryâs subdirectories are
       considered trace chunk archives once the command returns: it is
       safe to read them, modify them, move them, or remove them."
716,0,lttng-disable-channel,"The
lttng disable-channel
command disables one or more channels
       previously enabled by the
lttng-enable-channel(1)
command. A channel is always contained in a tracing session (see
lttng-create(1)
for creating a tracing session). The session in
       which a channel is disabled using
lttng disable-channel
can be
       specified using the
--session
option."
716,1,lttng-disable-channel,"The session in
       which a channel is disabled using
lttng disable-channel
can be
       specified using the
--session
option. If the
--session
option is
       omitted, the current tracing session is targeted. Note that re-enabling a disabled channel once its tracing session
       has been active at least once is currently not supported."
717,0,lttng-create,"The
lttng create
command creates a new tracing session. A tracing session is a named container of channels, which in turn
       contain event rules. It is domain-agnostic, in that channels and
       event rules can be enabled for the user space tracer and/or the
       Linux kernel tracer."
717,1,lttng-create,"It is domain-agnostic, in that channels and
       event rules can be enabled for the user space tracer and/or the
       Linux kernel tracer. On execution, an
.lttngrc
file is created, if it does not exist,
       in the userâs home directory. This file contains the name of the
       current tracing session."
717,2,lttng-create,"This file contains the name of the
       current tracing session. When creating a new tracing session with
lttng create
, the current tracing session is set to this new
       tracing session. The
lttng-set-session(1)
command can be used to
       set the current tracing session without manually editing the
.lttngrc
file."
717,3,lttng-create,"The
lttng-set-session(1)
command can be used to
       set the current tracing session without manually editing the
.lttngrc
file. If
SESSION
is omitted, a session name is automatically created
       having this form:
auto-YYYYmmdd-HHMMSS
. SESSION
must not
contain
       the character
/
."
717,4,lttng-create,"SESSION
must not
contain
       the character
/
. The
--shm-path
option can be used to specify the path to the
       shared memory holding the ring buffers. Specifying a location on
       an NVRAM file system makes it possible to retrieve the latest
       recorded trace data when the system reboots after a crash."
717,5,lttng-create,"Specifying a location on
       an NVRAM file system makes it possible to retrieve the latest
       recorded trace data when the system reboots after a crash. To view
       the events of ring buffer files after a system crash, use the
lttng-crash(1)
utility. Tracing sessions are destroyed using the
lttng-destroy(1)
command."
717,6,lttng-create,"Tracing sessions are destroyed using the
lttng-destroy(1)
command. Creation modes
There are four tracing session modes:

       Local mode
           Traces the local system and writes the trace to the local file
           system. The
--output
option specifies the trace path."
717,7,lttng-create,"The
--output
option specifies the trace path. Using
--set-url
=file://
PATH
is the equivalent of using
--output
=
PATH
. The file system output can be disabled using
           the
--no-output
option."
717,8,lttng-create,"The file system output can be disabled using
           the
--no-output
option. If none of the options mentioned above are used, then the
           trace is written locally in the
$LTTNG_HOME/lttng-traces
directory (
$LTTNG_HOME
defaults to
$HOME
). Network streaming mode
           Traces the local system and sends the trace over the network
           to a listening relay daemon (see
lttng-relayd(8)
)."
717,9,lttng-create,"Network streaming mode
           Traces the local system and sends the trace over the network
           to a listening relay daemon (see
lttng-relayd(8)
). The
--set-
url
, or
--ctrl-url
and
--data-url
options set the trace output
           destination (see the
URL format
section below). Snapshot mode
           Traces the local system without writing the trace to the local
           file system (implicit
--no-output
option)."
717,10,lttng-create,"Snapshot mode
           Traces the local system without writing the trace to the local
           file system (implicit
--no-output
option). Channels are
           automatically configured to be snapshot-ready on creation (see
lttng-enable-channel(1)
). The
lttng-snapshot(1)
command is
           used to take snapshots of the current ring buffers."
717,11,lttng-create,"The
lttng-snapshot(1)
command is
           used to take snapshots of the current ring buffers. The
--set-
url
, or
--ctrl-url
and
--data-url
options set the default
           snapshot output destination. Live mode
           Traces the local system, sending trace data to an LTTng relay
           daemon over the network (see
lttng-relayd(8)
)."
717,12,lttng-create,"Live mode
           Traces the local system, sending trace data to an LTTng relay
           daemon over the network (see
lttng-relayd(8)
). The
--set-url
,
           or
--ctrl-url
and
--data-url
options set the trace output
           destination. The live output URLs cannot use the
file://
protocol (see the
URL format
section below)."
717,13,lttng-create,"The live output URLs cannot use the
file://
protocol (see the
URL format
section below). URL format
The
--set-url
,
--ctrl-url
, and
--data-url
options' arguments are
       URLs. The format of those URLs is one of:

           file://
TRACEPATH
NETPROTO
://(
HOST
|
IPADDR
)[:
CTRLPORT
[:
DATAPORT
]][/
TRACEPATH
]

       The
file://
protocol targets the
local file system
and can only be
       used as the
--set-url
optionâs argument when the session is
       created in
local
or
snapshot
mode."
717,14,lttng-create,"The format of those URLs is one of:

           file://
TRACEPATH
NETPROTO
://(
HOST
|
IPADDR
)[:
CTRLPORT
[:
DATAPORT
]][/
TRACEPATH
]

       The
file://
protocol targets the
local file system
and can only be
       used as the
--set-url
optionâs argument when the session is
       created in
local
or
snapshot
mode. TRACEPATH
Absolute path to trace files on the local file system. The other version is available when the session is created in
network streaming
,
snapshot
, or
live
mode."
717,15,lttng-create,"The other version is available when the session is created in
network streaming
,
snapshot
, or
live
mode. NETPROTO
Network protocol, amongst:
net
TCP over IPv4; the default values of
CTRLPORT
and
DATAPORT
are respectively 5342 and 5343. net6
TCP over IPv6: same default ports as the
net
protocol."
717,16,lttng-create,"net6
TCP over IPv6: same default ports as the
net
protocol. tcp
Same as the
net
protocol; can only be used with the
--ctrl-url
and
--data-url
options together. tcp6
Same as the
net6
protocol; can only be used with the
--ctrl-url
and
--data-url
options together."
717,17,lttng-create,"tcp6
Same as the
net6
protocol; can only be used with the
--ctrl-url
and
--data-url
options together. (
HOST
|
IPADDR
)
           Hostname or IP address (IPv6 address
must
be enclosed in
           brackets (
[
and
]
); see RFC 2732
           <
https://www.ietf.org/rfc/rfc2732.txt
>). CTRLPORT
Control port."
717,18,lttng-create,"CTRLPORT
Control port. DATAPORT
Data port. TRACEPATH
Path of trace files on the remote file system."
717,19,lttng-create,"DATAPORT
Data port. TRACEPATH
Path of trace files on the remote file system. This path is
           relative to the base output directory set on the relay daemon
           side; see
lttng-relayd(8)
."
718,0,lttng-disable-event,"The
lttng disable-event
command disables one or more event rules
       previously enabled by the
lttng-enable-event(1)
command. Event rules are always assigned to a channel when they are
       created. If the
--channel
option is omitted, the default channel
       named
channel0
is used."
718,1,lttng-disable-event,"If the
--channel
option is omitted, the default channel
       named
channel0
is used. If the
--session
option is omitted, the chosen channel is picked
       from the current tracing session. If the
--all-events
option is used, all the existing event rules
       of the chosen domain are disabled."
718,2,lttng-disable-event,"If the
--all-events
option is used, all the existing event rules
       of the chosen domain are disabled. Otherwise, at least one event
       rule to disable named
EVENT
must be specified. With the
--kernel
option, the event source type can be specified
       using one of the
--tracepoint
,
--probe
,
--function
, or
--syscall
options."
718,3,lttng-disable-event,"With the
--kernel
option, the event source type can be specified
       using one of the
--tracepoint
,
--probe
,
--function
, or
--syscall
options. See
lttng-enable-event(1)
for more details about event
       source types. Events can be disabled while tracing is active (use
lttng-start(1)
to make a tracing session active)."
719,0,lttng-disable-rotation,"The
lttng disable-rotation
command unsets a rotation schedule for
       the current tracing session, or for the tracing session named
SESSION
if provided, previously set with the
lttng-enable-rotation(1)
command."
720,0,lttng-enable-channel,"The
lttng enable-channel
command can create a new channel, or
       enable one or more existing and disabled ones. A channel is the owner of sub-buffers holding recorded events. Event, rules, when created using
lttng-enable-event(1)
, are always
       assigned to a channel."
720,1,lttng-enable-channel,"Event, rules, when created using
lttng-enable-event(1)
, are always
       assigned to a channel. When creating a new channel, many
       parameters related to those sub-buffers can be fine-tuned. They
       are described in the subsections below."
720,2,lttng-enable-channel,"They
       are described in the subsections below. When
CHANNEL
does not name an existing channel, a channel named
CHANNEL
is created. Otherwise, the disabled channel named
CHANNEL
is enabled."
720,3,lttng-enable-channel,"Otherwise, the disabled channel named
CHANNEL
is enabled. Note that the
lttng-enable-event(1)
command can automatically
       create default channels when no channel exist. A channel is always contained in a tracing session (see
lttng-create(1)
for creating a tracing session)."
720,4,lttng-enable-channel,"A channel is always contained in a tracing session (see
lttng-create(1)
for creating a tracing session). The session in
       which a channel is created using
lttng enable-channel
can be
       specified using the
--session
option. If the
--session
option is
       omitted, the current tracing session is targeted."
720,5,lttng-enable-channel,"If the
--session
option is
       omitted, the current tracing session is targeted. Existing enabled channels can be disabled using
lttng-disable-channel(1)
. Channels of a given session can be
       listed using
lttng-list(1)
."
720,6,lttng-enable-channel,"Channels of a given session can be
       listed using
lttng-list(1)
. See the
LIMITATIONS
section below for a list of limitations of
       this command to consider. Event loss modes
LTTng tracers are non-blocking by default: when no empty
       sub-buffer exists, losing events is acceptable when the
       alternative would be to cause substantial delays in the
       instrumented applicationâs execution."
720,7,lttng-enable-channel,"Event loss modes
LTTng tracers are non-blocking by default: when no empty
       sub-buffer exists, losing events is acceptable when the
       alternative would be to cause substantial delays in the
       instrumented applicationâs execution. LTTng privileges performance over integrity, aiming at perturbing
       the traced system as little as possible in order to make tracing
       of subtle race conditions and rare interrupt cascades possible. You can allow the user space tracer to block with a
--blocking-
timeout
option set to a positive value or to
inf
, and with an
       application which is instrumented with LTTng-UST started with a
       set
LTTNG_UST_ALLOW_BLOCKING
environment variable."
720,8,lttng-enable-channel,"You can allow the user space tracer to block with a
--blocking-
timeout
option set to a positive value or to
inf
, and with an
       application which is instrumented with LTTng-UST started with a
       set
LTTNG_UST_ALLOW_BLOCKING
environment variable. See
lttng-ust(3)
for more details. When it comes to losing events because no empty sub-buffer is
       available, the channelâs event loss mode, specified by one of the
--discard
and
--overwrite
options, determines what to do amongst:

       Discard
           Drop the newest events until a sub-buffer is released."
720,9,lttng-enable-channel,"When it comes to losing events because no empty sub-buffer is
       available, the channelâs event loss mode, specified by one of the
--discard
and
--overwrite
options, determines what to do amongst:

       Discard
           Drop the newest events until a sub-buffer is released. Overwrite
           Clear the sub-buffer containing the oldest recorded events and
           start recording the newest events there. This mode is
           sometimes called
flight recorder mode
because it behaves like
           a flight recorder: always keep a fixed amount of the latest
           data."
720,10,lttng-enable-channel,"This mode is
           sometimes called
flight recorder mode
because it behaves like
           a flight recorder: always keep a fixed amount of the latest
           data. Which mechanism to choose depends on the context: prioritize the
       newest or the oldest events in the ring buffer? Beware that, in overwrite mode (
--overwrite
option), a whole
       sub-buffer is abandoned as soon as a new event doesnât find an
       empty sub-buffer, whereas in discard mode (
--discard
option), only
       the event that doesnât fit is discarded."
720,11,lttng-enable-channel,"Beware that, in overwrite mode (
--overwrite
option), a whole
       sub-buffer is abandoned as soon as a new event doesnât find an
       empty sub-buffer, whereas in discard mode (
--discard
option), only
       the event that doesnât fit is discarded. Also note that a count of lost events is incremented and saved in
       the trace itself when an event is lost in discard mode, whereas no
       information is kept when a sub-buffer gets overwritten before
       being committed. The probability of losing events, if it is experience in a given
       context, can be reduced by fine-tuning the sub-buffers count and
       size (see next subsection)."
720,12,lttng-enable-channel,"The probability of losing events, if it is experience in a given
       context, can be reduced by fine-tuning the sub-buffers count and
       size (see next subsection). Sub-buffers count and size
The
--num-subbuf
and
--subbuf-size
options respectively set the
       number of sub-buffers and their individual size when creating a
       new channel. Note that there is a noticeable tracerâs CPU overhead introduced
       when switching sub-buffers (marking a full one as consumable and
       switching to an empty one for the following events to be
       recorded)."
720,13,lttng-enable-channel,"Note that there is a noticeable tracerâs CPU overhead introduced
       when switching sub-buffers (marking a full one as consumable and
       switching to an empty one for the following events to be
       recorded). Knowing this, the following list presents a few
       practical situations along with how to configure sub-buffers for
       them when creating a channel in overwrite mode (
--overwrite
option):

       High event throughput
           In general, prefer bigger sub-buffers to lower the risk of
           losing events. Having bigger sub-buffers also ensures a lower
           sub-buffer switching frequency."
720,14,lttng-enable-channel,"Having bigger sub-buffers also ensures a lower
           sub-buffer switching frequency. The number of sub-buffers is
           only meaningful if the channel is enabled in overwrite mode:
           in this case, if a sub-buffer overwrite happens, the other
           sub-buffers are left unaltered. Low event throughput
           In general, prefer smaller sub-buffers since the risk of
           losing events is already low."
720,15,lttng-enable-channel,"Low event throughput
           In general, prefer smaller sub-buffers since the risk of
           losing events is already low. Since events happen less
           frequently, the sub-buffer switching frequency should remain
           low and thus the tracerâs overhead should not be a problem. Low memory system
           If the target system has a low memory limit, prefer fewer
           first, then smaller sub-buffers."
720,16,lttng-enable-channel,"Low memory system
           If the target system has a low memory limit, prefer fewer
           first, then smaller sub-buffers. Even if the system is limited
           in memory, it is recommended to keep the sub-buffers as big as
           possible to avoid a high sub-buffer switching frequency. In discard mode (
--discard
option), the sub-buffers count
       parameter is pointless: using two sub-buffers and setting their
       size according to the requirements of the context is fine."
720,17,lttng-enable-channel,"In discard mode (
--discard
option), the sub-buffers count
       parameter is pointless: using two sub-buffers and setting their
       size according to the requirements of the context is fine. Switch timer
When a channelâs switch timer fires, a sub-buffer switch happens. This timer may be used to ensure that event data is consumed and
       committed to trace files periodically in case of a low event
       throughput."
720,18,lttng-enable-channel,"This timer may be used to ensure that event data is consumed and
       committed to trace files periodically in case of a low event
       throughput. Itâs also convenient when big sub-buffers are used to cope with
       sporadic high event throughput, even if the throughput is normally
       lower. Use the
--switch-timer
option to control the switch timerâs period
       of the channel to create."
720,19,lttng-enable-channel,"Use the
--switch-timer
option to control the switch timerâs period
       of the channel to create. Read timer
By default, an internal notification mechanism is used to signal a
       full sub-buffer so that it can be consumed. When such
       notifications must be avoided, for example in real-time
       applications, the channelâs read timer can be used instead."
720,20,lttng-enable-channel,"When such
       notifications must be avoided, for example in real-time
       applications, the channelâs read timer can be used instead. When
       the read timer fires, sub-buffers are checked for consumption when
       they are full. Use the
--read-timer
option to control the read timerâs period of
       the channel to create."
720,21,lttng-enable-channel,"Use the
--read-timer
option to control the read timerâs period of
       the channel to create. Monitor timer
When a channelâs monitor timer fires, its registered trigger
       conditions are evaluated using the current values of its
       properties (for example, the current usage of its sub-buffers). When a trigger condition is true, LTTng executes its associated
       action."
720,22,lttng-enable-channel,"When a trigger condition is true, LTTng executes its associated
       action. The only type of action currently supported is to notify
       one or more user applications. See the installed C/C++ headers in
lttng/action
,
lttng/condition
,
lttng/notification
, and
lttng/trigger
to learn more about
       application notifications and triggers."
720,23,lttng-enable-channel,"See the installed C/C++ headers in
lttng/action
,
lttng/condition
,
lttng/notification
, and
lttng/trigger
to learn more about
       application notifications and triggers. Use the
--monitor-timer
option to control the monitor timerâs
       period of the channel to create. Buffering scheme
In the user space tracing domain, two buffering schemes are
       available when creating a channel:

       Per-process buffering (
--buffers-pid
option)
           Keep one ring buffer per process."
720,24,lttng-enable-channel,"Buffering scheme
In the user space tracing domain, two buffering schemes are
       available when creating a channel:

       Per-process buffering (
--buffers-pid
option)
           Keep one ring buffer per process. Per-user buffering (
--buffers-uid
option)
           Keep one ring buffer for all the processes of a single user. The per-process buffering scheme consumes more memory than the
       per-user option if more than one process is instrumented for
       LTTng-UST."
720,25,lttng-enable-channel,"The per-process buffering scheme consumes more memory than the
       per-user option if more than one process is instrumented for
       LTTng-UST. However, per-process buffering ensures that one process
       having a high event throughput wonât fill all the shared
       sub-buffers, only its own. The Linux kernel tracing domain only has one available buffering
       scheme which is to use a single ring buffer for the whole system
       (
--buffers-global
option)."
720,26,lttng-enable-channel,"The Linux kernel tracing domain only has one available buffering
       scheme which is to use a single ring buffer for the whole system
       (
--buffers-global
option). Trace files limit and size
By default, trace files can grow as large as needed. The maximum
       size of each trace file written by a channel can be set on
       creation using the
--tracefile-size
option."
720,27,lttng-enable-channel,"The maximum
       size of each trace file written by a channel can be set on
       creation using the
--tracefile-size
option. When such a trace
       fileâs size reaches the channelâs fixed maximum size, another
       trace file is created to hold the next recorded events. A file
       count is appended to each trace file name in this case."
720,28,lttng-enable-channel,"A file
       count is appended to each trace file name in this case. If the
--tracefile-size
option is used, the maximum number of
       created trace files is unlimited. To limit them, the
--tracefile-
count
option can be used."
720,29,lttng-enable-channel,"To limit them, the
--tracefile-
count
option can be used. This option is always used in
       conjunction with the
--tracefile-size
option. For example, consider this command:

           $ lttng enable-channel --kernel --tracefile-size=4096 \
                                --tracefile-count=32 my-channel

       Here, for each stream, the maximum size of each trace file is 4
       kiB and there can be a maximum of 32 different files."
720,30,lttng-enable-channel,"For example, consider this command:

           $ lttng enable-channel --kernel --tracefile-size=4096 \
                                --tracefile-count=32 my-channel

       Here, for each stream, the maximum size of each trace file is 4
       kiB and there can be a maximum of 32 different files. When there
       is no space left in the last file,
trace file rotation
happens:
       the first file is cleared and new sub-buffers containing events
       are written there. LTTng does not guarantee that you can view the trace of an active
       tracing session (before you run the
lttng-stop(1)
command), even
       with multiple trace files, because LTTng could overwrite them at
       any moment, or some of them could be incomplete."
720,31,lttng-enable-channel,"When there
       is no space left in the last file,
trace file rotation
happens:
       the first file is cleared and new sub-buffers containing events
       are written there. LTTng does not guarantee that you can view the trace of an active
       tracing session (before you run the
lttng-stop(1)
command), even
       with multiple trace files, because LTTng could overwrite them at
       any moment, or some of them could be incomplete. You can archive a
       tracing sessionâs current trace chunk while the tracing session is
       active to obtain an unmanaged and self-contained LTTng trace: see
lttng-rotate(1)
and
lttng-enable-rotation(1)
."
721,0,lttng-enable-event,"The
lttng enable-event
command can create a new event rule, or
       enable one or more existing and disabled ones. An event rule created by
lttng enable-event
is a set of conditions
       that must be satisfied in order for an actual event to be emitted
       by an LTTng tracer when the execution of an application or the
       Linux kernel reaches an event source (tracepoint, system call,
       dynamic probe). Event sources can be listed with the
lttng-list(1)
command."
721,1,lttng-enable-event,"Event sources can be listed with the
lttng-list(1)
command. The
lttng-disable-event(1)
command can be used to disable existing
       event rules. Event rules are always assigned to a channel when they are
       created."
721,2,lttng-enable-event,"Event rules are always assigned to a channel when they are
       created. If the
--channel
option is omitted, a default channel
       named
channel0
is used (and created automatically if it does not
       exist for the specified domain in the selected tracing session). If the
--session
option is omitted, the chosen channel is picked
       from the current tracing session."
721,3,lttng-enable-event,"If the
--session
option is omitted, the chosen channel is picked
       from the current tracing session. Events can be enabled while tracing is active (use
lttng-start(1)
to make a tracing session active). Event source types
Four types of event sources are available in the Linux kernel
       tracing domain (
--kernel
option):

       Tracepoint (
--tracepoint
option; default)
           A Linux kernel tracepoint, that is, a static instrumentation
           point placed in the kernel source code."
721,4,lttng-enable-event,"Event source types
Four types of event sources are available in the Linux kernel
       tracing domain (
--kernel
option):

       Tracepoint (
--tracepoint
option; default)
           A Linux kernel tracepoint, that is, a static instrumentation
           point placed in the kernel source code. Standard tracepoints
           are designed and placed in the source code by developers and
           record useful payload fields. Dynamic probe (
--probe
option)
           A Linux kernel kprobe, that is, an instrumentation point
           placed dynamically in the compiled kernel code."
721,5,lttng-enable-event,"Dynamic probe (
--probe
option)
           A Linux kernel kprobe, that is, an instrumentation point
           placed dynamically in the compiled kernel code. Dynamic probe
           events do not record any payload field. Function probe (
--function
option)
           A Linux kernel kretprobe, that is, two instrumentation points
           placed dynamically where a function is entered and where it
           returns in the compiled kernel code."
721,6,lttng-enable-event,"Function probe (
--function
option)
           A Linux kernel kretprobe, that is, two instrumentation points
           placed dynamically where a function is entered and where it
           returns in the compiled kernel code. Function probe events do
           not record any payload field. System call (
--syscall
option)
           A Linux kernel system call."
721,7,lttng-enable-event,"System call (
--syscall
option)
           A Linux kernel system call. Two instrumentation points are
           statically placed where a system call function is entered and
           where it returns in the compiled kernel code. System call
           event sources record useful payload fields."
721,8,lttng-enable-event,"System call
           event sources record useful payload fields. The application tracing domains (
--userspace
,
--jul
,
--log4j
, or
--python
options) only support tracepoints. In the cases of the
       JUL, Apache log4j, and Python domains, the event names correspond
       to
logger
names."
721,9,lttng-enable-event,"In the cases of the
       JUL, Apache log4j, and Python domains, the event names correspond
       to
logger
names. Understanding event rule conditions
When creating an event rule with
lttng enable-event
, conditions
       are specified using options. The logical conjunction (logical AND)
       of all those conditions must be true when an event source is
       reached by an application or by the Linux kernel in order for an
       actual event to be emitted by an LTTng tracer."
721,10,lttng-enable-event,"The logical conjunction (logical AND)
       of all those conditions must be true when an event source is
       reached by an application or by the Linux kernel in order for an
       actual event to be emitted by an LTTng tracer. Any condition that is not explicitly specified on creation is
       considered a
donât care
. For example, consider the following commands:

           $ lttng enable-event --userspace hello:world
           $ lttng enable-event --userspace hello:world --loglevel=TRACE_INFO

       Here, two event rules are created."
721,11,lttng-enable-event,"For example, consider the following commands:

           $ lttng enable-event --userspace hello:world
           $ lttng enable-event --userspace hello:world --loglevel=TRACE_INFO

       Here, two event rules are created. The first one has a single
       condition: the tracepoint name must match
hello:world
. The second
       one has two conditions:

       â¢   The tracepoint name must match
hello:world
,
and
â¢   The tracepointâs defined log level must be at least as severe
           as the
TRACE_INFO
level."
721,12,lttng-enable-event,"The second
       one has two conditions:

       â¢   The tracepoint name must match
hello:world
,
and
â¢   The tracepointâs defined log level must be at least as severe
           as the
TRACE_INFO
level. In this case, the second event rule is pointless because the first
       one is more general: it does not care about the tracepointâs log
       level. If an event source matching both event rules is reached by
       the applicationâs execution, only one event is emitted."
721,13,lttng-enable-event,"If an event source matching both event rules is reached by
       the applicationâs execution, only one event is emitted. The available conditions for the Linux kernel domain are:

       â¢   Tracepoint/system call name (
EVENT
argument with
--tracepoint
or
--syscall
options) or dynamic probe/function name/address
           (
--probe
or
--function
optionâs argument) which must match
           event sourceâs equivalent. You can use
*
characters at any place in the tracepoint or
           system call name as wildcards to match zero or more
           characters."
721,14,lttng-enable-event,"You can use
*
characters at any place in the tracepoint or
           system call name as wildcards to match zero or more
           characters. To use a literal
*
character, use
\*
. â¢   Filter expression (
--filter
option) executed against the
           dynamic values of event fields at execution time that must
           evaluate to true."
721,15,lttng-enable-event,"â¢   Filter expression (
--filter
option) executed against the
           dynamic values of event fields at execution time that must
           evaluate to true. See the
Filter expression
section below for
           more information. The available conditions for the application domains are:

       â¢   Tracepoint name (
EVENT
with
--tracepoint
option) which must
           match event sourceâs equivalent."
721,16,lttng-enable-event,"The available conditions for the application domains are:

       â¢   Tracepoint name (
EVENT
with
--tracepoint
option) which must
           match event sourceâs equivalent. You can use
*
characters at any place in the tracepoint name
           as wildcards to match zero or more characters. To use a
           literal
*
character, use
\*
."
721,17,lttng-enable-event,"To use a
           literal
*
character, use
\*
. When you create an event rule
           with a tracepoint name containing a wildcard, you can exclude
           specific tracepoint names from the match with the
--exclude
option. â¢   Filter expression (
--filter
option) executed against the
           dynamic values of event fields at execution time that must
           evaluate to true."
721,18,lttng-enable-event,"â¢   Filter expression (
--filter
option) executed against the
           dynamic values of event fields at execution time that must
           evaluate to true. See the
Filter expression
section below for
           more information. â¢   Eventâs log level that must be at least as severe as a given
           log level (
--loglevel
option) or match exactly a given log
           level (
--loglevel-only
option)."
721,19,lttng-enable-event,"â¢   Eventâs log level that must be at least as severe as a given
           log level (
--loglevel
option) or match exactly a given log
           level (
--loglevel-only
option). When using
lttng enable-event
with a set of conditions that does
       not currently exist for the chosen tracing session, domain, and
       channel, a new event rule is created. Otherwise, the existing
       event rule is enabled if it is currently disabled (see
lttng-disable-event(1)
)."
721,20,lttng-enable-event,"Otherwise, the existing
       event rule is enabled if it is currently disabled (see
lttng-disable-event(1)
). The
--all
option can be used alongside the
--tracepoint
or
--syscall
options. When this option is used, no
EVENT
argument
       must be specified."
721,21,lttng-enable-event,"When this option is used, no
EVENT
argument
       must be specified. This option defines a single event rule
       matching
all
the possible events of a given tracing domain for the
       chosen channel and tracing session. It is the equivalent of an
EVENT
argument named
*
(wildcard)."
721,22,lttng-enable-event,"It is the equivalent of an
EVENT
argument named
*
(wildcard). Filter expression
A filter expression can be specified with the
--filter
option when
       creating a new event rule. If the filter expression evaluates to
       true when executed against the dynamic values of an eventâs fields
       when tracing, the filtering condition passes."
721,23,lttng-enable-event,"If the filter expression evaluates to
       true when executed against the dynamic values of an eventâs fields
       when tracing, the filtering condition passes. Note
Make sure to
single-quote
the filter expression when running
           the command from a shell, as filter expressions typically
           include characters having a special meaning for most shells. The filter expression syntax is similar to C language conditional
       expressions (expressions that can be evaluated by an
if
statement), albeit with a few differences:

       â¢   C integer and floating point number constants are supported,
           as well as literal strings between double quotes (
""
)."
721,24,lttng-enable-event,"The filter expression syntax is similar to C language conditional
       expressions (expressions that can be evaluated by an
if
statement), albeit with a few differences:

       â¢   C integer and floating point number constants are supported,
           as well as literal strings between double quotes (
""
). You can
           use
*
characters at any place in a literal string as wildcards
           to match zero or more characters. To use a literal
*
character, use
\*
."
721,25,lttng-enable-event,"To use a literal
*
character, use
\*
. Examples:
32
,
-0x17
,
0755
,
12.34
,
""a \""literal string\""""
,
""src/*/*.h""
. â¢   The dynamic value of an event field is read by using its name
           as a C identifier."
721,26,lttng-enable-event,"â¢   The dynamic value of an event field is read by using its name
           as a C identifier. The dot and square bracket notations are available, like in
           the C language, to access nested structure and array/sequence
           fields. Only a constant, positive integer number can be used
           within square brackets."
721,27,lttng-enable-event,"Only a constant, positive integer number can be used
           within square brackets. If the index is out of bounds, the
           whole filter expression evaluates to false (the event is
           discarded). An enumeration fieldâs value is an integer."
721,28,lttng-enable-event,"An enumeration fieldâs value is an integer. When the expressionâs field does not exist, the whole filter
           expression evaluates to false. Examples:
my_field
,
target_cpu
,
seq[7]
,
msg.user[1].data[2][17]
."
721,29,lttng-enable-event,"Examples:
my_field
,
target_cpu
,
seq[7]
,
msg.user[1].data[2][17]
. â¢   The dynamic value of a statically-known context field is read
           by prefixing its name with
$ctx. ."
721,30,lttng-enable-event,". Statically-known context
           fields are context fields added to channels without the
$app. prefix using the
lttng-add-context(1)
command."
721,31,lttng-enable-event,"prefix using the
lttng-add-context(1)
command. When the expressionâs statically-known context field does not
           exist, the whole filter expression evaluates to false. Examples:
$ctx.prio
,
$ctx.preemptible
,
$ctx.perf:cpu:stalled-
cycles-frontend
."
721,32,lttng-enable-event,"Examples:
$ctx.prio
,
$ctx.preemptible
,
$ctx.perf:cpu:stalled-
cycles-frontend
. â¢   The dynamic value of an application-specific context field is
           read by prefixing its name with
$app. (follows the format
           used to add such a context field with the
lttng-add-context(1)
command)."
721,33,lttng-enable-event,"(follows the format
           used to add such a context field with the
lttng-add-context(1)
command). When the expressionâs application-specific context field does
           not exist, the whole filter expression evaluates to false. Example:
$app.server:cur_user
."
721,34,lttng-enable-event,"Example:
$app.server:cur_user
. The following precedence table shows the operators which are
       supported in a filter expression. In this table, the highest
       precedence is 1."
721,35,lttng-enable-event,"In this table, the highest
       precedence is 1. Parentheses are supported to bypass the default
       order. Important
Unlike the C language, the
lttng enable-event
filter
           expression syntaxâs bitwise AND and OR operators (
&
and
|
)
           take precedence over relational operators (
<
,
<=
,
>
,
>=
,
==
,
           and
!=
)."
721,36,lttng-enable-event,"Important
Unlike the C language, the
lttng enable-event
filter
           expression syntaxâs bitwise AND and OR operators (
&
and
|
)
           take precedence over relational operators (
<
,
<=
,
>
,
>=
,
==
,
           and
!=
). This means the filter expression
2 & 2 == 2
is true
           while the equivalent C expression is false. ââââââââââââââ¬âââââââââââ¬ââââââââââââââââââ¬ââââââââââââââââ
       â
Precedence
â
Operator
â
Description
â
Associativity
â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 1          â
-
â Unary minus     â Right-to-left â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 1          â
+
â Unary plus      â Right-to-left â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 1          â
!"
721,37,lttng-enable-event,"ââââââââââââââ¬âââââââââââ¬ââââââââââââââââââ¬ââââââââââââââââ
       â
Precedence
â
Operator
â
Description
â
Associativity
â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 1          â
-
â Unary minus     â Right-to-left â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 1          â
+
â Unary plus      â Right-to-left â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 1          â
! â Logical NOT     â Right-to-left â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 1          â
~
â Bitwise NOT     â Right-to-left â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 2          â
<<
â Bitwise left    â Left-to-right â
       â            â          â shift           â               â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 2          â
>>
â Bitwise right   â Left-to-right â
       â            â          â shift           â               â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 3          â
&
â Bitwise AND     â Left-to-right â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 4          â
^
â Bitwise XOR     â Left-to-right â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 5          â
|
â Bitwise OR      â Left-to-right â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 6          â
<
â Less than       â Left-to-right â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 6          â
<=
â Less than or    â Left-to-right â
       â            â          â equal to        â               â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 6          â
>
â Greater than    â Left-to-right â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 6          â
>=
â Greater than or â Left-to-right â
       â            â          â equal to        â               â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 7          â
==
â Equal to        â Left-to-right â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 7          â
!=
â Not equal to    â Left-to-right â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 8          â
&&
â Logical AND     â Left-to-right â
       ââââââââââââââ¼âââââââââââ¼ââââââââââââââââââ¼ââââââââââââââââ¤
       â            â          â                 â               â
       â 9          â
||
â Logical OR      â Left-to-right â
       ââââââââââââââ´âââââââââââ´ââââââââââââââââââ´ââââââââââââââââ

       The arithmetic operators are NOT supported. All integer constants and fields are first casted to signed 64-bit
       integers."
721,38,lttng-enable-event,"All integer constants and fields are first casted to signed 64-bit
       integers. The representation of negative integers is twoâs
       complement. This means that, for example, the signed 8-bit integer
       field 0xff (-1) becomes 0xffffffffffffffff (still -1) once casted."
721,39,lttng-enable-event,"This means that, for example, the signed 8-bit integer
       field 0xff (-1) becomes 0xffffffffffffffff (still -1) once casted. Before a bitwise operator is applied, all its operands are casted
       to unsigned 64-bit integers, and the result is casted back to a
       signed 64-bit integer. For the bitwise NOT operator, it is the
       equivalent of this C expression:

           (int64_t) ~((uint64_t) val)

       For the binary bitwise operators, it is the equivalent of those C
       expressions:

           (int64_t) ((uint64_t) lhs >> (uint64_t) rhs)
           (int64_t) ((uint64_t) lhs << (uint64_t) rhs)
           (int64_t) ((uint64_t) lhs & (uint64_t) rhs)
           (int64_t) ((uint64_t) lhs ^ (uint64_t) rhs)
           (int64_t) ((uint64_t) lhs | (uint64_t) rhs)

       If the right-hand side of a bitwise shift operator (
<<
and
>>
) is
       not in the [0, 63] range, the whole filter expression evaluates to
       false."
721,40,lttng-enable-event,"For the bitwise NOT operator, it is the
       equivalent of this C expression:

           (int64_t) ~((uint64_t) val)

       For the binary bitwise operators, it is the equivalent of those C
       expressions:

           (int64_t) ((uint64_t) lhs >> (uint64_t) rhs)
           (int64_t) ((uint64_t) lhs << (uint64_t) rhs)
           (int64_t) ((uint64_t) lhs & (uint64_t) rhs)
           (int64_t) ((uint64_t) lhs ^ (uint64_t) rhs)
           (int64_t) ((uint64_t) lhs | (uint64_t) rhs)

       If the right-hand side of a bitwise shift operator (
<<
and
>>
) is
       not in the [0, 63] range, the whole filter expression evaluates to
       false. Note
Although it is possible to filter the process ID of an event
           when the
pid
context has been added to its channel using, for
           example,
$ctx.pid == 2832
, it is recommended to use the PID
           tracker instead, which is much more efficient (see
lttng-track(1)
). Filter expression examples:

           msg_id == 23 && size >= 2048

           $ctx.procname == ""lttng*"" && (!flag || poel < 34)

           $app.my_provider:my_context == 17.34e9 || some_enum >= 14

           $ctx.cpu_id == 2 && filename != ""*.log""

           eax_reg & 0xff7 == 0x240 && x[4] >> 12 <= 0x1234
Log levels
Tracepoints and log statements in applications have an attached
       log level."
721,41,lttng-enable-event,"Filter expression examples:

           msg_id == 23 && size >= 2048

           $ctx.procname == ""lttng*"" && (!flag || poel < 34)

           $app.my_provider:my_context == 17.34e9 || some_enum >= 14

           $ctx.cpu_id == 2 && filename != ""*.log""

           eax_reg & 0xff7 == 0x240 && x[4] >> 12 <= 0x1234
Log levels
Tracepoints and log statements in applications have an attached
       log level. Application event rules can contain a
log level
condition. With the
--loglevel
option, the event sourceâs log level must be
       at least as severe as the optionâs argument."
721,42,lttng-enable-event,"With the
--loglevel
option, the event sourceâs log level must be
       at least as severe as the optionâs argument. With the
--loglevel-
only
option, the event sourceâs log level must match the optionâs
       argument. The available log levels are:

       User space domain (
--userspace
option)
           Shortcuts such as
system
are allowed."
721,43,lttng-enable-event,"The available log levels are:

       User space domain (
--userspace
option)
           Shortcuts such as
system
are allowed. â¢
TRACE_EMERG
(0)

           â¢
TRACE_ALERT
(1)

           â¢
TRACE_CRIT
(2)

           â¢
TRACE_ERR
(3)

           â¢
TRACE_WARNING
(4)

           â¢
TRACE_NOTICE
(5)

           â¢
TRACE_INFO
(6)

           â¢
TRACE_DEBUG_SYSTEM
(7)

           â¢
TRACE_DEBUG_PROGRAM
(8)

           â¢
TRACE_DEBUG_PROCESS
(9)

           â¢
TRACE_DEBUG_MODULE
(10)

           â¢
TRACE_DEBUG_UNIT
(11)

           â¢
TRACE_DEBUG_FUNCTION
(12)

           â¢
TRACE_DEBUG_LINE
(13)

           â¢
TRACE_DEBUG
(14)
java.util.logging
domain (
--jul
option)
           Shortcuts such as
severe
are allowed. â¢
JUL_OFF
(
INT32_MAX
)

           â¢
JUL_SEVERE
(1000)

           â¢
JUL_WARNING
(900)

           â¢
JUL_INFO
(800)

           â¢
JUL_CONFIG
(700)

           â¢
JUL_FINE
(500)

           â¢
JUL_FINER
(400)

           â¢
JUL_FINEST
(300)

           â¢
JUL_ALL
(
INT32_MIN
)

       Apache log4j domain (
--log4j
option)
           Shortcuts such as
severe
are allowed."
721,44,lttng-enable-event,"â¢
JUL_OFF
(
INT32_MAX
)

           â¢
JUL_SEVERE
(1000)

           â¢
JUL_WARNING
(900)

           â¢
JUL_INFO
(800)

           â¢
JUL_CONFIG
(700)

           â¢
JUL_FINE
(500)

           â¢
JUL_FINER
(400)

           â¢
JUL_FINEST
(300)

           â¢
JUL_ALL
(
INT32_MIN
)

       Apache log4j domain (
--log4j
option)
           Shortcuts such as
severe
are allowed. â¢
LOG4J_OFF
(
INT32_MAX
)

           â¢
LOG4J_FATAL
(50000)

           â¢
LOG4J_ERROR
(40000)

           â¢
LOG4J_WARN
(30000)

           â¢
LOG4J_INFO
(20000)

           â¢
LOG4J_DEBUG
(10000)

           â¢
LOG4J_TRACE
(5000)

           â¢
LOG4J_ALL
(
INT32_MIN
)

       Python domain (
--python
option)
           Shortcuts such as
critical
are allowed. â¢
PYTHON_CRITICAL
(50)

           â¢
PYTHON_ERROR
(40)

           â¢
PYTHON_WARNING
(30)

           â¢
PYTHON_INFO
(20)

           â¢
PYTHON_DEBUG
(10)

           â¢
PYTHON_NOTSET
(0)"
722,0,lttng-enable-rotation,"The
lttng enable-rotation
command sets a rotation schedule for the
       current tracing session, or for the tracing session named
SESSION
if provided. See
lttng-rotate(1)
for more information about the
       concepts of a tracing session
rotation
and a
trace chunk
. With the
--timer
option, the rotation schedule is set so that an
       automatic rotation occurs at least every
PERIOD
(microseconds
       without a unit suffix)."
722,1,lttng-enable-rotation,"With the
--timer
option, the rotation schedule is set so that an
       automatic rotation occurs at least every
PERIOD
(microseconds
       without a unit suffix). With the
--size
option, the rotation schedule is set so that an
       automatic rotation occurs every time the total size of the flushed
       part of the current trace chunk is at least
SIZE
(bytes without a
       unit suffix). With both the
--timer
and
--size
options, LTTng checks the
       schedule condition periodically using the monitor timers of the
       tracing sessionâs channels."
722,2,lttng-enable-rotation,"With both the
--timer
and
--size
options, LTTng checks the
       schedule condition periodically using the monitor timers of the
       tracing sessionâs channels. This means that, with the
--timer
option, the automatic rotation can occur when the elapsed time
       since the last automatic rotation is greater than
PERIOD
, and with
       the
--size
option, the automatic rotation can occur when the size
       of the flushed part of the current trace chunk is greater than
SIZE
. See the
--monitor-timer
option in
lttng-enable-channel(1)
for more information about the monitor timer."
722,3,lttng-enable-rotation,"See the
--monitor-timer
option in
lttng-enable-channel(1)
for more information about the monitor timer. The naming convention of a trace chunk archive which an automatic
       rotation creates is the same as with the immediate rotation
       command,
lttng-rotate(1)
. You can unset a rotation schedule with the
lttng-disable-rotation(1)
command."
722,4,lttng-enable-rotation,"The naming convention of a trace chunk archive which an automatic
       rotation creates is the same as with the immediate rotation
       command,
lttng-rotate(1)
. You can unset a rotation schedule with the
lttng-disable-rotation(1)
command. See
LIMITATIONS
for important limitations regarding this command."
723,0,lttng-gen-tp,"The
lttng-gen-tp
tool simplifies the generation of LTTng-UST
       tracepoint provider files. It takes a simple template file,
TEMPLATE
, and generates the necessary C code to use the defined
       tracepoints in your application. See the
Template file format
section below for more information about the format of
TEMPLATE
."
723,1,lttng-gen-tp,"See the
Template file format
section below for more information about the format of
TEMPLATE
. Currently,
lttng-gen-tp
can generate the
.h
,
.c
, and
.o
files
       associated with your tracepoint provider. The generated
.h
file
       can be included directly in your application."
723,2,lttng-gen-tp,"The generated
.h
file
       can be included directly in your application. You can let
lttng-
gen-tp
generate the
.o
file or compile the
.c
file yourself. See
lttng-ust(3)
for more information about compiling LTTng-UST
       tracepoint providers."
723,3,lttng-gen-tp,"See
lttng-ust(3)
for more information about compiling LTTng-UST
       tracepoint providers. By default,
lttng-gen-tp
generates the
.h
,
.c
, and
.o
files, their
       basename being the basename of
TEMPLATE
. You can generate one or
       more specific file types with the
--output
option, repeated if
       needed."
723,4,lttng-gen-tp,"You can generate one or
       more specific file types with the
--output
option, repeated if
       needed. Template file format
The template file, which usually has the
.tp
extension, contains a
       list of
LTTNG_UST_TRACEPOINT_EVENT()
definitions and other
       optional definition entries, like
LTTNG_UST_TRACEPOINT_LOGLEVEL()
. See
lttng-ust(3)
for the complete list of available definitions."
723,5,lttng-gen-tp,"See
lttng-ust(3)
for the complete list of available definitions. The
LTTNG_UST_TRACEPOINT_EVENT()
definitions are written as you
       would write them in an LTTng-UST template provider header file. C
       comments are supported (
/* */
and
//
), as well as lines starting
       with
#
."
723,6,lttng-gen-tp,"C
       comments are supported (
/* */
and
//
), as well as lines starting
       with
#
. Note
The provider name (the first argument of
LTTNG_UST_TRACEPOINT_EVENT()
) must be the same in all the
LTTNG_UST_TRACEPOINT_EVENT()
macros of
TEMPLATE
. Hereâs an example:

           LTTNG_UST_TRACEPOINT_EVENT(
               // Tracepoint provider name
               my_provider,

               // Tracepoint/event name
               my_event,

               // Tracepoint arguments (input)
               LTTNG_UST_TP_ARGS(char *, text),

               // Tracepoint/event fields (output)
               LTTNG_UST_TP_FIELDS(
                   lttng_ust_field_string(message, text)
               )
           )"
724,0,lttng-help,"The
lttng help
command displays help information about an LTTng
       command. This command is the equivalent of:

           $ lttng COMMAND --help

       where
COMMAND
is the name of the command about which to get help. If
COMMAND
is omitted,
lttng help
shows general help about the
lttng(1)
command."
724,1,lttng-help,"If
COMMAND
is omitted,
lttng help
shows general help about the
lttng(1)
command. The
lttng help
command attempts to launch
/usr/bin/man
to view the
       commandâs man page. The path to the man pager can be overridden by
       the
LTTNG_MAN_BIN_PATH
environment variable."
725,0,lttng-list,"The
lttng list
command lists tracing sessions, tracing domains,
       channels, and events. Without arguments,
lttng list
lists the existing tracing sessions
       and shows if they are active or not. With one or more of the
--kernel
,
--userspace
,
--jul
,
--log4j
, and
--python
domain options, the command lists the available event
       sources of the selected domain on the system."
725,1,lttng-list,"With one or more of the
--kernel
,
--userspace
,
--jul
,
--log4j
, and
--python
domain options, the command lists the available event
       sources of the selected domain on the system. The JUL, log4j, and
       Python domains list the names of their available
loggers
. The
--syscall
option can be used alongside the
--kernel
option to get
       a list of traceable Linux system calls."
725,2,lttng-list,"The
--syscall
option can be used alongside the
--kernel
option to get
       a list of traceable Linux system calls. The
--fields
option can be
       used to show the fields of the listed event sources. Providing a tracing session name
SESSION
targets a specific
       tracing session."
725,3,lttng-list,"Providing a tracing session name
SESSION
targets a specific
       tracing session. If the
--domain
option is used, domains
       containing at least one channel in the selected tracing session
       are listed. Otherwise, all the domains, channels, and event rules
       of the selected tracing session are listed along with its details
       (trace path, for example), except when the
--channel
option is
       used to isolate a specific channel by name."
726,0,lttng-metadata,"Warning
This command is
deprecated
; it has been replaced by
lttng
regenerate metadata
(see
lttng-regenerate(1)
)."
727,0,lttng-load,"The
lttng load
command loads the configurations of one or more
       tracing sessions from files. The
lttng load
command is used in conjunction with the
lttng-save(1)
command to save and restore the complete
       configurations of tracing sessions. This includes the enabled
       channels and event rules, the context added to channels, the
       tracing activity, and more."
727,1,lttng-load,"This includes the enabled
       channels and event rules, the context added to channels, the
       tracing activity, and more. Once one or more tracing session configurations are loaded, they
       appear exactly as they were saved from the userâs point of view. The following directories are searched, non-recursively, in this
       order for configuration files:

        1."
727,2,lttng-load,"The following directories are searched, non-recursively, in this
       order for configuration files:

        1. $LTTNG_HOME/.lttng/sessions
(
$LTTNG_HOME
defaults to
$HOME
)

        2. /usr/local/etc/lttng/sessions
The input path can be overridden with the
--input-path
option."
727,3,lttng-load,"/usr/local/etc/lttng/sessions
The input path can be overridden with the
--input-path
option. When this option is specified, the default directories are NOT
       searched for configuration files. When itâs not specified,
both
default directories are searched for configuration files."
727,4,lttng-load,"When itâs not specified,
both
default directories are searched for configuration files. If the input path is a
directory
, then:

       â¢   If
SESSION
is specified, the tracing session configuration
           named
SESSION
is searched for in all the files of this
           directory and loaded if found. â¢   If
SESSION
is not specified, the
--all
option is implicit: all
           the tracing session configurations found in all the files in
           this directory are loaded."
727,5,lttng-load,"â¢   If
SESSION
is not specified, the
--all
option is implicit: all
           the tracing session configurations found in all the files in
           this directory are loaded. If the input path is a
file
, then:

       â¢   If
SESSION
is specified, the tracing session configuration
           named
SESSION
is searched for in this file and loaded if
           found. â¢   If
SESSION
is not specified, the
--all
option is implicit: all
           the tracing session configurations found in this file are
           loaded."
727,6,lttng-load,"â¢   If
SESSION
is not specified, the
--all
option is implicit: all
           the tracing session configurations found in this file are
           loaded. Aspects of the loaded configurations can be overridden at load
       time using the
--override-url
and
--override-name
options. By default, existing tracing sessions are not overwritten when
       loading: the command fails."
727,7,lttng-load,"Aspects of the loaded configurations can be overridden at load
       time using the
--override-url
and
--override-name
options. By default, existing tracing sessions are not overwritten when
       loading: the command fails. The
--force
option can be used to
       allow this."
728,0,lttng-regenerate,"The
lttng regenerate
command regenerates specific data of a
       tracing session. As of this version, the
metadata
and
statedump
actions are
       available. Regenerating a tracing sessionâs metadata
The
lttng regenerate metadata
action can be used to resample the
       offset between the systemâs monotonic clock and the wall-clock
       time."
728,1,lttng-regenerate,"Regenerating a tracing sessionâs metadata
The
lttng regenerate metadata
action can be used to resample the
       offset between the systemâs monotonic clock and the wall-clock
       time. This action is meant to be used to resample the wall-clock time
       following a major NTP
       <
https://en.wikipedia.org/wiki/Network_Time_Protocol
> correction. As such, a system booting with an incorrect wall time can be
       traced before its wall time is NTP-corrected."
728,2,lttng-regenerate,"As such, a system booting with an incorrect wall time can be
       traced before its wall time is NTP-corrected. Regenerating the
       tracing sessionâs metadata ensures that trace viewers can
       accurately determine the events time relative to Unix Epoch. If you use
lttng-rotate(1)
or
lttng-enable-rotation(1)
to make
       tracing session rotations, this action regenerates the current and
       next trace chunksâs metadata files."
728,3,lttng-regenerate,"If you use
lttng-rotate(1)
or
lttng-enable-rotation(1)
to make
       tracing session rotations, this action regenerates the current and
       next trace chunksâs metadata files. Regenerating a tracing sessionâs state dump
The
lttng regenerate statedump
action can be used to collect
       up-to-date state dump information during the tracing session. This
       is particularly useful in snapshot (see
lttng-snapshot(1)
) or
       trace file rotation (see
lttng-enable-channel(1)
) modes where the
       state dump information may be lost."
729,0,lttng-rotate,"The
lttng rotate
command archives the current trace chunk of the
       current tracing session, or of the tracing session named
SESSION
if provided, to the file system. This action is called a tracing
       session
rotation
. Once a trace chunk is archived, LTTng does not manage it anymore:
       you can read it, modify it, move it, or remove it."
729,1,lttng-rotate,"Once a trace chunk is archived, LTTng does not manage it anymore:
       you can read it, modify it, move it, or remove it. An archived trace chunk is a collection of metadata and data
       stream files which form a self-contained trace. The
current trace chunk
of a given tracing session includes:

       â¢   The stream files already written to the file system, and which
           are not part of a previously archived trace chunk, since the
           most recent event amongst:

           â¢   The first time the tracing session was started with
lttng-start(1)
."
729,2,lttng-rotate,"The
current trace chunk
of a given tracing session includes:

       â¢   The stream files already written to the file system, and which
           are not part of a previously archived trace chunk, since the
           most recent event amongst:

           â¢   The first time the tracing session was started with
lttng-start(1)
. â¢   The last rotation, either an immediate one with
lttng
rotate
, or an automatic one from a rotation schedule
               previously set with
lttng-enable-rotation(1)
. â¢   The content of all the non-flushed sub-buffers of the tracing
           sessionâs channels."
729,3,lttng-rotate,"â¢   The content of all the non-flushed sub-buffers of the tracing
           sessionâs channels. You can use
lttng rotate
either at any time when the tracing
       session is active (see
lttng-start(1)
), or a single time once the
       tracing session becomes inactive (see
lttng-stop(1)
). By default, the
lttng rotate
command ensures that the rotation is
       done before printing the archived trace chunkâs path and returning
       to the prompt."
729,4,lttng-rotate,"By default, the
lttng rotate
command ensures that the rotation is
       done before printing the archived trace chunkâs path and returning
       to the prompt. The printed path is absolute when the tracing
       session was created in normal mode and relative to the relay
       daemonâs output directory (see the
--output
option in
lttng-relayd(8)
) when it was created in network streaming mode
       (see
lttng-create(1)
). With the
--no-wait
option, the command finishes immediately, hence
       a rotation might not be completed when the command is done."
729,5,lttng-rotate,"With the
--no-wait
option, the command finishes immediately, hence
       a rotation might not be completed when the command is done. In
       this case, there is no easy way to know when the current trace
       chunk is archived, and the command does not print the archived
       trace chunkâs path. Because a rotation causes the tracing sessionâs current
       sub-buffers to be flushed, archived trace chunks are never
       redundant, that is, they do not overlap over time like snapshots
       can (see
lttng-snapshot(1)
)."
729,6,lttng-rotate,"Because a rotation causes the tracing sessionâs current
       sub-buffers to be flushed, archived trace chunks are never
       redundant, that is, they do not overlap over time like snapshots
       can (see
lttng-snapshot(1)
). Also, a rotation does not directly
       cause discarded event records or packets. See
LIMITATIONS
for important limitations regarding this command."
729,7,lttng-rotate,"See
LIMITATIONS
for important limitations regarding this command. Trace chunk archive naming
A trace chunk archive is a subdirectory of a tracing sessionâs
       output directory (see the
--output
option in
lttng-create(1)
)
       which contains, through tracing domain and possibly UID/PID
       subdirectories, metadata and data stream files. A trace chunk archive is, at the same time:

       â¢   A self-contained LTTng trace."
729,8,lttng-rotate,"A trace chunk archive is, at the same time:

       â¢   A self-contained LTTng trace. â¢   A member of a set of trace chunk archives which form the
           complete trace of a tracing session. In other words, an LTTng trace reader can read both the tracing
       session output directory (all the trace chunk archives), or a
       single trace chunk archive."
729,9,lttng-rotate,"In other words, an LTTng trace reader can read both the tracing
       session output directory (all the trace chunk archives), or a
       single trace chunk archive. When a tracing session rotation occurs, the created trace chunk
       archive is named:
BEGIN
-
END
-
ID
BEGIN
Date and time of the beginning of the trace chunk archive with
           the ISO 8601-compatible
YYYYmmddTHHMMSSÂ±HHMM
form, where
YYYYmmdd
is the date and
HHMMSSÂ±HHMM
is the time with the time
           zone offset from UTC. Example:
20171119T152407-0500
END
Date and time of the end of the trace chunk archive with the
           ISO 8601-compatible
YYYYmmddTHHMMSSÂ±HHMM
form, where
YYYYmmdd
is the date and
HHMMSSÂ±HHMM
is the time with the time zone
           offset from UTC."
729,10,lttng-rotate,"Example:
20171119T152407-0500
END
Date and time of the end of the trace chunk archive with the
           ISO 8601-compatible
YYYYmmddTHHMMSSÂ±HHMM
form, where
YYYYmmdd
is the date and
HHMMSSÂ±HHMM
is the time with the time zone
           offset from UTC. Example:
20180118T152407+0930
ID
Unique numeric identifier of the trace chunk within its
           tracing session. Trace chunk archive name example:
20171119T152407-0500-20171119T151422-0500-3"
730,0,lttng-save,"The
lttng save
command saves the configurations of one or more
       tracing sessions to files. The
lttng save
command is used in conjunction with the
lttng-load(1)
command to save and restore the complete
       configurations of tracing sessions. This includes the enabled
       channels and event rules, the context added to channels, the
       tracing activity, and more."
730,1,lttng-save,"This includes the enabled
       channels and event rules, the context added to channels, the
       tracing activity, and more. lttng save
does not save tracing data,
       only the tracing session parameters. If
SESSION
is omitted, all the existing tracing session
       configurations are saved (equivalent to using the
--all
option)."
730,2,lttng-save,"If
SESSION
is omitted, all the existing tracing session
       configurations are saved (equivalent to using the
--all
option). Otherwise,
SESSION
is the name of an existing tracing session. lttng list
outputs all the existing tracing sessions (see
lttng-list(1)
)."
730,3,lttng-save,"lttng list
outputs all the existing tracing sessions (see
lttng-list(1)
). The default output directory path is
$LTTNG_HOME/.lttng/sessions
(
$LTTNG_HOME
defaults to
$HOME
). Each tracing session
       configuration file is named
SESSION.lttng
, where
SESSION
is the
       original tracing session name."
730,4,lttng-save,"Each tracing session
       configuration file is named
SESSION.lttng
, where
SESSION
is the
       original tracing session name. The default output directory path
       can be overridden with the
--output-path
option. By default, existing tracing session configuration files are not
       overwritten when saving; the command fails."
730,5,lttng-save,"The default output directory path
       can be overridden with the
--output-path
option. By default, existing tracing session configuration files are not
       overwritten when saving; the command fails. The
--force
option can
       be used to allow this."
731,0,lttng-snapshot,"The
lttng snapshot
command manages the snapshot outputs and takes
       snapshots. A
snapshot
is a dump of the current sub-buffers of all the
       channels of a given tracing session. When a snapshot is taken, the
       memory dump is sent to the registered snapshot outputs."
731,1,lttng-snapshot,"When a snapshot is taken, the
       memory dump is sent to the registered snapshot outputs. The tracing session should be created in
snapshot mode
to make
       sure taking snapshots is allowed. This is done at tracing session
       creation time using the
lttng-create(1)
command."
731,2,lttng-snapshot,"This is done at tracing session
       creation time using the
lttng-create(1)
command. Note that, when a snapshot is taken, the sub-buffers are not
       cleared. This means that different recorded snapshots may contain
       the same events."
731,3,lttng-snapshot,"This means that different recorded snapshots may contain
       the same events. Snapshot outputs
Snapshot outputs are the destinations of snapshot files when a
       snapshot is taken using the
record
action. As of this version, only one snapshot output is allowed."
731,4,lttng-snapshot,"As of this version, only one snapshot output is allowed. A snapshot output can be added using the
add-output
action. The
       output destination URL is set using either the
URL
positional
       argument, or both the
--ctrl-url
and
--data-url
options."
731,5,lttng-snapshot,"The
       output destination URL is set using either the
URL
positional
       argument, or both the
--ctrl-url
and
--data-url
options. See
lttng-create(1)
to learn more about the URL format. A name can be assigned to an output when adding it using the
--name
option."
731,6,lttng-snapshot,"A name can be assigned to an output when adding it using the
--name
option. This name is part of the names of the snapshot
       files written to this output. By default, the snapshot files can be as big as the sum of the
       sizes of all the sub-buffers or all the channels of the selected
       tracing session."
731,7,lttng-snapshot,"By default, the snapshot files can be as big as the sum of the
       sizes of all the sub-buffers or all the channels of the selected
       tracing session. The maximum total size of all the snapshot files
       can be configured using the
--max-size
option. Snapshot outputs can be listed using the
list-output
action."
731,8,lttng-snapshot,"Snapshot outputs can be listed using the
list-output
action. Snapshot outputs can be removed using the
del-output
action. The
       configured name can be used when removing an output, or an ID as
       listed by the
list-output
action."
731,9,lttng-snapshot,"The
       configured name can be used when removing an output, or an ID as
       listed by the
list-output
action. Taking a snapshot
Taking a snapshot of the current tracing session is as easy as:

           $ lttng snapshot record

       This writes the snapshot files to the configured output. It is
       possible to use a custom, unregistered output at record time using
       the same options supported by the
add-output
action."
731,10,lttng-snapshot,"It is
       possible to use a custom, unregistered output at record time using
       the same options supported by the
add-output
action. Note
Before taking a snapshot on a system with a high event
           throughput, it is recommended to first run
lttng stop
(see
lttng-stop(1)
). Otherwise, the snapshot could contain ""holes"",
           the result of the tracers overwriting unconsumed trace packets
           during the record operation."
731,11,lttng-snapshot,"Note
Before taking a snapshot on a system with a high event
           throughput, it is recommended to first run
lttng stop
(see
lttng-stop(1)
). Otherwise, the snapshot could contain ""holes"",
           the result of the tracers overwriting unconsumed trace packets
           during the record operation. After the snapshot is recorded,
           the tracers can be started again with
lttng start
(see
lttng-start(1)
)."
732,0,lttng-status,"The
lttng status
command shows the status of the current tracing
       session.

       This command is the exact equivalent of:

           $ lttng list CURSESSION

       where
CURSESSION
is the name of the current tracing session. Use
lttng-set-session(1)
to set the current tracing session."
733,0,lttng-set-session,"The
lttng set-session
command sets the current tracing session. SESSION
is the name of an existing tracing session. lttng list
outputs all the existing tracing sessions (see
lttng-list(1)
)."
733,1,lttng-set-session,"lttng list
outputs all the existing tracing sessions (see
lttng-list(1)
). The current tracing session is used by default when a session can
       be specified in other commands. See
lttng-create(1)
for more
       information about the current tracing session."
734,0,lttng-start,"The
lttng start
command starts the various LTTng tracers for a
       given inactive tracing session. Starting the LTTng tracers has the effect that all enabled event
       rules within enabled channels can make their target event sources
emit
trace events. Whether they are recorded to the local file
       system, sent over the network, or not recorded at all depends on
       the specific configuration of the tracing session in which tracing
       is started."
734,1,lttng-start,"Whether they are recorded to the local file
       system, sent over the network, or not recorded at all depends on
       the specific configuration of the tracing session in which tracing
       is started. See
lttng-create(1)
for different session modes. A tracing session with running tracers is said to be
active
."
734,2,lttng-start,"A tracing session with running tracers is said to be
active
. Active tracing sessions can return to the inactive state using the
lttng-stop(1)
command. If
SESSION
is omitted, the LTTng tracers are started for the
       current tracing session (see
lttng-create(1)
for more information
       about the current tracing session)."
734,3,lttng-start,"If
SESSION
is omitted, the LTTng tracers are started for the
       current tracing session (see
lttng-create(1)
for more information
       about the current tracing session). Otherwise, they are started
       for the existing tracing session named
SESSION
. lttng list
outputs
       all the existing tracing sessions (see
lttng-list(1)
)."
735,0,lttng-stop,"The
lttng stop
command stops the various LTTng tracers for a given
       active tracing session. Stopping the LTTng tracers has the effect that all enabled event
       rules within enabled channels cannot make event sources
emit
trace
       events anymore. A tracing session with no running tracers is said to be
inactive
."
735,1,lttng-stop,"A tracing session with no running tracers is said to be
inactive
. Inactive tracing sessions can be set active using the
lttng-start(1)
command. If
SESSION
is omitted, the LTTng tracers are stopped for the
       current tracing session (see
lttng-create(1)
for more information
       about the current tracing session)."
735,2,lttng-stop,"If
SESSION
is omitted, the LTTng tracers are stopped for the
       current tracing session (see
lttng-create(1)
for more information
       about the current tracing session). Otherwise, they are stopped
       for the existing tracing session named
SESSION
. lttng list
outputs
       all the existing tracing sessions (see
lttng-list(1)
)."
735,3,lttng-stop,"lttng list
outputs
       all the existing tracing sessions (see
lttng-list(1)
). By default, the
lttng stop
command ensures that the tracing
       sessionâs trace data is valid before returning to the prompt. With
       the
--no-wait
option, the command finishes immediately, hence a
       local trace might not be valid when the command is done."
735,4,lttng-stop,"With
       the
--no-wait
option, the command finishes immediately, hence a
       local trace might not be valid when the command is done. In this
       case, there is no way to know when the trace becomes valid. If at least one rotation occurred during the chosen tracing
       sessionâs lifetime (see
lttng-rotate(1)
and
lttng-enable-rotation(1)
), the
lttng stop
command renames the
       current trace chunk subdirectory and prints the renamed path."
735,5,lttng-stop,"In this
       case, there is no way to know when the trace becomes valid. If at least one rotation occurred during the chosen tracing
       sessionâs lifetime (see
lttng-rotate(1)
and
lttng-enable-rotation(1)
), the
lttng stop
command renames the
       current trace chunk subdirectory and prints the renamed path. Although it is safe to read the content of this renamed
       subdirectory while the tracing session remains inactive (until the
       next
lttng-start(1)
), it is NOT a trace chunk archive: you need to
       destroy the tracing session with
lttng-destroy(1)
or make a
       rotation with
lttng-rotate(1)
to archive it."
736,0,lttng-untrack,"The
lttng untrack
commands removes one or more entries from a
       resource tracker. See
lttng-track(1)
to learn more about LTTng trackers. The untrack command removes specific resources from a tracker."
736,1,lttng-untrack,"The untrack command removes specific resources from a tracker. The
       resources to remove must have been precedently added by
lttng-track(1)
. It is also possible to remove all the resources
       from the whitelist using the
--all
option."
736,2,lttng-untrack,"It is also possible to remove all the resources
       from the whitelist using the
--all
option. As of this version, the only available tracker is the PID tracker. Example
One common operation is to create a tracing session (see
lttng-create(1)
), remove all the entries from the PID tracker
       whitelist, start tracing, and then manually track PIDs while
       tracing is active."
736,3,lttng-untrack,"Example
One common operation is to create a tracing session (see
lttng-create(1)
), remove all the entries from the PID tracker
       whitelist, start tracing, and then manually track PIDs while
       tracing is active. Assume the maximum system PID is 7 for this example. Command:

           $ lttng create

       Initial whitelist:

           [0] [1] [2] [3] [4] [5] [6] [7]

       Command:

           $ lttng untrack --userspace --pid --all

       Whitelist:

           [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ]

       Commands:

           $ lttng enable-event --userspace ..."
736,4,lttng-untrack,"Command:

           $ lttng create

       Initial whitelist:

           [0] [1] [2] [3] [4] [5] [6] [7]

       Command:

           $ lttng untrack --userspace --pid --all

       Whitelist:

           [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ]

       Commands:

           $ lttng enable-event --userspace ... $ lttng start
           $ # ... $ lttng track --userspace --pid=3,5

       Whitelist:

           [ ] [ ] [ ] [3] [ ] [5] [ ] [ ]

       Command:

           $ lttng track --userspace --pid=2

       Whitelist:

           [ ] [ ] [2] [3] [ ] [5] [ ] [ ]"
737,0,lttng-track,"The
lttng track
commands adds one or more entries to a resource
       tracker. A resource tracker is a
whitelist
of resources. Tracked resources
       are allowed to emit events, provided those events are targeted by
       enabled event rules (see
lttng-enable-event(1)
)."
737,1,lttng-track,"Tracked resources
       are allowed to emit events, provided those events are targeted by
       enabled event rules (see
lttng-enable-event(1)
). Tracker entries can be removed from the whitelist with
lttng-untrack(1)
. As of this version, the only available tracker is the
PID tracker
."
737,2,lttng-track,"As of this version, the only available tracker is the
PID tracker
. The process ID (PID) tracker follows one or more process IDs; only
       the processes with a tracked PID are allowed to emit events. By
       default, all possible PIDs on the system are tracked: any process
       may emit enabled events (equivalent of
lttng track --pid --all
for
       all domains)."
737,3,lttng-track,"By
       default, all possible PIDs on the system are tracked: any process
       may emit enabled events (equivalent of
lttng track --pid --all
for
       all domains). With the PID tracker, it is possible, for example, to record all
       system calls called by a given process:

           # lttng enable-event --kernel --all --syscall
           # lttng track --kernel --pid=2345
           # lttng start

       If all the PIDs are tracked (i.e. lttng track --pid --all
, which
       is the default state of all domains when creating a tracing
       session), then using the track command with one or more specific
       PIDs has the effect of first removing all the PIDs from the
       whitelist, then adding the specified PIDs."
737,4,lttng-track,"lttng track --pid --all
, which
       is the default state of all domains when creating a tracing
       session), then using the track command with one or more specific
       PIDs has the effect of first removing all the PIDs from the
       whitelist, then adding the specified PIDs. Example
Assume the maximum system PID is 7 for this example. Initial whitelist:

           [0] [1] [2] [3] [4] [5] [6] [7]

       Command:

           $ lttng track --userspace --pid=3,6,7

       Whitelist:

           [ ] [ ] [ ] [3] [ ] [ ] [6] [7]

       Command:

           $ lttng untrack --userspace --pid=7

       Whitelist:

           [ ] [ ] [ ] [3] [ ] [ ] [6] [ ]

       Command:

           $ lttng track --userspace --pid=1,5

       Whitelist:

           [ ] [1] [ ] [3] [ ] [5] [6] [ ]

       It should be noted that the PID tracker tracks the numeric process
       IDs."
737,5,lttng-track,"Initial whitelist:

           [0] [1] [2] [3] [4] [5] [6] [7]

       Command:

           $ lttng track --userspace --pid=3,6,7

       Whitelist:

           [ ] [ ] [ ] [3] [ ] [ ] [6] [7]

       Command:

           $ lttng untrack --userspace --pid=7

       Whitelist:

           [ ] [ ] [ ] [3] [ ] [ ] [6] [ ]

       Command:

           $ lttng track --userspace --pid=1,5

       Whitelist:

           [ ] [1] [ ] [3] [ ] [5] [6] [ ]

       It should be noted that the PID tracker tracks the numeric process
       IDs. Should a process with a given ID exit and another process be
       given this ID, then the latter would also be allowed to emit
       events. See the
lttng-untrack(1)
for more details about removing entries."
738,0,lttng-version,"The
lttng version
command outputs the version of LTTng-tools.

       The output of
lttng version
is broken down into the following
       parts:

       â¢   Major, minor, and patch numbers

       â¢   Git commit information, if available

       â¢   Release name with its description

       â¢   LTTng projectâs website URL

       â¢   License information"
739,0,lttng-view,"The
lttng view
command launches an external trace viewer to view
       the current trace of a tracing session. If
SESSION
is omitted, the viewer is launched for the current
       tracing session (see
lttng-create(1)
for more information about
       the current tracing session). Otherwise, it is launched for the
       existing tracing session named
SESSION
."
739,1,lttng-view,"Otherwise, it is launched for the
       existing tracing session named
SESSION
. lttng list
outputs all the
       existing tracing sessions (see
lttng-list(1)
). By default, the
babeltrace
(1) trace viewer is launched."
739,2,lttng-view,"By default, the
babeltrace
(1) trace viewer is launched. Another
       trace viewer command can be specified using the
--viewer
option. By default, the trace path of the chosen tracing session is given
       as the first positional argument to the trace viewer."
739,3,lttng-view,"Another
       trace viewer command can be specified using the
--viewer
option. By default, the trace path of the chosen tracing session is given
       as the first positional argument to the trace viewer. This path
       can be overridden using the
--trace-path
option."
740,0,lttng,"The
Linux Trace Toolkit: next generation
<
https://lttng.org/
> is
       an open source software package used for correlated tracing of the
       Linux kernel, user applications, and user libraries. LTTng consists of Linux kernel modules (for Linux kernel tracing)
       and dynamically loaded libraries (for user application and library
       tracing). An LTTng
session daemon
,
lttng-sessiond(8)
, receives commands from
       the command-line interface
lttng
to control the LTTng tracers."
740,1,lttng,"An LTTng
session daemon
,
lttng-sessiond(8)
, receives commands from
       the command-line interface
lttng
to control the LTTng tracers. All
       interactions with the LTTng tracers happen through the
lttng
tool
       or through the liblttng-ctl library shipped with the LTTng-tools
       package. A
tracing domain
is a tracer category."
740,2,lttng,"A
tracing domain
is a tracer category. There are five available
       domains. For some commands, the domain needs to be specified with
       a command-line option."
740,3,lttng,"For some commands, the domain needs to be specified with
       a command-line option. The domain options are:
-j
,
--jul
Apply command to the
java.util.logging
(JUL) domain. -k
,
--kernel
Apply command to the Linux kernel domain."
740,4,lttng,"-k
,
--kernel
Apply command to the Linux kernel domain. -l
,
--log4j
Apply command to the Apache log4j 1.2
           <
https://logging.apache.org/log4j/1.2/
> (Java) domain. -p
,
--python
Apply command to the Python <
https://www.python.org/
> domain."
740,5,lttng,"-p
,
--python
Apply command to the Python <
https://www.python.org/
> domain. -u
,
--userspace
Apply command to the user space domain (application using
           liblttng-ust directly; see
lttng-ust(3)
). The LTTng session daemon is a tracing registry which allows the
       user to interact with multiple tracers (kernel and user space)
       within the same container, a
tracing session
."
740,6,lttng,"The LTTng session daemon is a tracing registry which allows the
       user to interact with multiple tracers (kernel and user space)
       within the same container, a
tracing session
. Traces can be
       gathered from the Linux kernel and/or from instrumented
       applications (see
lttng-ust(3)
). You can aggregate and read the
       events of LTTng traces using
babeltrace
(1)."
740,7,lttng,"You can aggregate and read the
       events of LTTng traces using
babeltrace
(1). To trace the Linux kernel, the session daemon needs to be running
       as
root
. LTTng uses a
tracing group
to allow specific users to
       interact with the root session daemon."
740,8,lttng,"LTTng uses a
tracing group
to allow specific users to
       interact with the root session daemon. The default tracing group
       name is
tracing
. You can use the
--group
option to set the tracing
       group name to use."
740,9,lttng,"You can use the
--group
option to set the tracing
       group name to use. Session daemons can coexist. You can have a session daemon running
       as user Alice that can be used to trace her applications alongside
       a root session daemon or a session daemon running as user Bob."
740,10,lttng,"You can have a session daemon running
       as user Alice that can be used to trace her applications alongside
       a root session daemon or a session daemon running as user Bob. Note
It is highly recommended to start the session daemon at boot
           time for stable and long-term tracing. User applications instrumented with LTTng automatically register
       to the root session daemon and to user session daemons."
740,11,lttng,"User applications instrumented with LTTng automatically register
       to the root session daemon and to user session daemons. This
       allows any session daemon to list the available traceable
       applications and event sources (see
lttng-list(1)
). By default, the
lttng-create(1)
command automatically spawns a
       user session daemon if none is currently running."
740,12,lttng,"This
       allows any session daemon to list the available traceable
       applications and event sources (see
lttng-list(1)
). By default, the
lttng-create(1)
command automatically spawns a
       user session daemon if none is currently running. The
--no-
sessiond
general option can be set to avoid this."
741,0,lxc-attach,"lxc-attach
runs the specified
command
inside the container speciâ
       fied by
name
. The container has to be running already. If no
command
is specified, the current default shell of the  user
       running
lxc-attach
will be looked up inside the container and exeâ
       cuted."
741,1,lxc-attach,"If no
command
is specified, the current default shell of the  user
       running
lxc-attach
will be looked up inside the container and exeâ
       cuted. This will fail if no such user exists inside the container
       or the container does not have a working nsswitch mechanism. Previous versions of
lxc-attach
simply attached to  the  specified
       namespaces of a container and ran a shell or the specified command
       without first allocating a pseudo terminal."
741,2,lxc-attach,"Previous versions of
lxc-attach
simply attached to  the  specified
       namespaces of a container and ran a shell or the specified command
       without first allocating a pseudo terminal. This made them vulnerâ
       able  to input faking via a TIOCSTI
ioctl
call after switching beâ
       tween userspace execution contexts with different  privilege  levâ
       els. Newer  versions  of
lxc-attach
will try to allocate a pseudo
       terminal file descriptor pair on the host and attach any  standard
       file  descriptors  which refer to a terminal to the container side
       of the pseudo terminal before executing a shell or command."
741,3,lxc-attach,"Newer  versions  of
lxc-attach
will try to allocate a pseudo
       terminal file descriptor pair on the host and attach any  standard
       file  descriptors  which refer to a terminal to the container side
       of the pseudo terminal before executing a shell or command. Note,
       that  if none of the standard file descriptors refer to a terminal
lxc-attach
will not try to allocate a pseudo terminal. Instead  it
       will simply attach to the containers namespaces and run a shell or
       the specified command."
742,0,lxc-checkconfig,"lxc-checkconfig
check the current kernel for lxc support"
743,0,lxc-cgroup,"lxc-cgroup
gets  or  sets  the  value  of  a
state-object
(e.g.,
       'cpuset.cpus') in the container's  cgroup  for  the  corresponding
       subsystem  (e.g.,  'cpuset'). If no [value] is specified, the curâ
       rent value of the
state-object
is displayed; otherwise it is set.

       Note that
lxc-cgroup
does not check that the
state-object
is valid
       for the running kernel, or that  the  corresponding  subsystem  is
       contained in any mounted cgroup hierarchy."
744,0,lxc-autostart,"lxc-autostart
processes  containers  with  lxc.start.auto set. It
       lets the user start, shutdown, kill,  restart  containers  in  the
       right  order,  waiting  the  right  time. Supports  filtering  by
       lxc.group or just run against all defined containers."
744,1,lxc-autostart,"Supports  filtering  by
       lxc.group or just run against all defined containers. It can  also
       be  used  by  external  tools in list mode where no action will be
       performed and the list of affected containers  (and  if  relevant,
       delays) will be shown. The [-r], [-s] and [-k] options specify the action to perform."
744,2,lxc-autostart,"The [-r], [-s] and [-k] options specify the action to perform. If
       none  is specified, then the containers will be started. [-a] and
       [-g] are used to specify which containers will be affected."
744,3,lxc-autostart,"[-a] and
       [-g] are used to specify which containers will be affected. By deâ
       fault only containers without a lxc.group set  will  be  affected. [-t  TIMEOUT] specifies the maximum amount of time to wait for the
       container to complete the shutdown or reboot."
745,0,lxc-checkpoint,"lxc-checkpoint
checkpoints and restores containers."
746,0,lxc-config,"lxc-config
queries the lxc system configuration and lets you list
       all valid keys or query individual keys for their value."
747,0,lxc-console,"If  the  tty  service has been configured and is available for the
       container specified as parameter, this command will launch a  conâ
       sole allowing to log on the container. The available tty are free slots taken by this command. That means
       if  the container has four ttys available and the command has been
       launched four times each taking a different tty, the fifth command
       will fail because no console will be available."
747,1,lxc-console,"That means
       if  the container has four ttys available and the command has been
       launched four times each taking a different tty, the fifth command
       will fail because no console will be available. The command will connect to a tty. If the connection  is  lost  or
       broken,  the  command  can be launched again and regain the tty at
       the state it was before the disconnection."
747,2,lxc-console,"If the connection  is  lost  or
       broken,  the  command  can be launched again and regain the tty at
       the state it was before the disconnection. A
ttynum
of 0 may be given to attach to the container's  /dev/conâ
       sole instead of its dev/tty<
ttynum
>. A  keyboard escape sequence may be used to disconnect from the tty
       and quit lxc-console."
747,3,lxc-console,"A
ttynum
of 0 may be given to attach to the container's  /dev/conâ
       sole instead of its dev/tty<
ttynum
>. A  keyboard escape sequence may be used to disconnect from the tty
       and quit lxc-console. The default escape sequence is <Ctrl+a q>."
748,0,lxc-copy,"lxc-copy
creates and optionally starts (ephemeral or non-ephemerâ
       al) copies of existing containers. lxc-copy
creates copies of existing containers. Copies can be comâ
       plete clones of the original container."
748,1,lxc-copy,"Copies can be comâ
       plete clones of the original container. In  this  case  the  whole
       root  filesystem of the container is simply copied to the new conâ
       tainer. Or they can be snapshots, i.e."
748,2,lxc-copy,"Or they can be snapshots, i.e. small copy-on-write  copies
       of  the  original  container. In  this case the specified backing
       storage for the copy must support snapshots."
748,3,lxc-copy,"In  this case the specified backing
       storage for the copy must support snapshots. This  currently  inâ
       cludes  btrfs,  lvm (lvm devices do not support snapshots of snapâ
       shots.), overlay, and zfs. The copy's backing storage will be of the same type as the  origiâ
       nal  container."
748,4,lxc-copy,"The copy's backing storage will be of the same type as the  origiâ
       nal  container. overlay  snapshots of directory backed containers
       are exempted from this rule. When the
-e
flag is specified an ephemeral snapshot of the  origiâ
       nal  container  is  created and started."
748,5,lxc-copy,"When the
-e
flag is specified an ephemeral snapshot of the  origiâ
       nal  container  is  created and started. Ephemeral containers will
       have
lxc.ephemeral = 1
set in their config file and  will  be  deâ
       stroyed on shutdown. When
-e
is used in combination with
-D
a non-
       ephemeral snapshot of the original container is created and startâ
       ed."
748,6,lxc-copy,"When
-e
is used in combination with
-D
a non-
       ephemeral snapshot of the original container is created and startâ
       ed. Ephemeral  containers  can also be placed on a tmpfs with
-t
flag. NOTE: If an ephemeral container that is placed on a tmpfs is
       rebooted all changes made to it will currently be lost!"
748,7,lxc-copy,"NOTE: If an ephemeral container that is placed on a tmpfs is
       rebooted all changes made to it will currently be lost! When
-e
is specified and no newname is given via
-N
a random  name
       for the snapshot will be chosen. Containers  created  and  started  with
-e
can have custom mounts."
748,8,lxc-copy,"Containers  created  and  started  with
-e
can have custom mounts. These are specified with the
-m
flag. Currently  two  types  of
       mounts are supported:
bind
, and
overlay
."
748,9,lxc-copy,"Currently  two  types  of
       mounts are supported:
bind
, and
overlay
. Mount types are specified
       as  suboptions  to the
-m
flag and can be specified multiple times
       separated by commas. overlay
mounts are currently specified in the
       format
-m overlay=/src:/dest
."
748,10,lxc-copy,"overlay
mounts are currently specified in the
       format
-m overlay=/src:/dest
. When no destination
dest
is  speciâ
       fied
dest
will  be  identical  to
src
. Read-only
bind
mounts are
       specified
-m bind=/src:/dest:ro
and  read-write
bind
mounts
-m
bind=/src:/dest:rw
."
748,11,lxc-copy,"Read-only
bind
mounts are
       specified
-m bind=/src:/dest:ro
and  read-write
bind
mounts
-m
bind=/src:/dest:rw
. Read-write
bind
mounts are the default and
rw
can be missing when a read-write mount is  wanted. When
dest
is
       missing
dest
will  be  identical to
src
."
748,12,lxc-copy,"When
dest
is
       missing
dest
will  be  identical to
src
. An example for multiple
       mounts  would   be
-m
bind=/src1:/dest1:ro,bind=/src2:ro,overâ
lay=/src3:/dest3
. The  mounts,  their options, and formats supported via the
-m
flag
       are subject to change."
749,0,lxc-create,"lxc-create
creates a system object where is stored the configuraâ
       tion information and where can be  stored  user  information. The
       identifier
name
is used to specify the container to be used with
       the different lxc commands. The object is a directory created in
/var/lib/lxc
and  identified
       by its name."
749,1,lxc-create,"The object is a directory created in
/var/lib/lxc
and  identified
       by its name. The  object is the definition of the different resources an appliâ
       cation can use or can see. The more the  configuration  file  conâ
       tains information, the more the container is isolated and the more
       the application is jailed."
749,2,lxc-create,"The  object is the definition of the different resources an appliâ
       cation can use or can see. The more the  configuration  file  conâ
       tains information, the more the container is isolated and the more
       the application is jailed. If  the  configuration file
config_file
is not specified, the conâ
       tainer will be created with the default isolation: processes, sysv
       ipc and mount points."
750,0,lxc-destroy,"lxc-destroy
destroys  the system object previously created by the
lxc-create
command."
751,0,lxc-device,"lxc-device
manages devices in running container."
752,0,lxc-info,"lxc-info
queries and shows information about a container."
753,0,lxc-execute,"lxc-execute
runs the specified
command
inside the container speciâ
       fied by
name
. It  will setup the container according to the configuration previâ
       ously defined with the lxc-create command or with  the  configuraâ
       tion  file parameter. If no configuration is defined, the default
       isolation is used."
753,1,lxc-execute,"If no configuration is defined, the default
       isolation is used. This command is mainly used when you want to quickly launch an apâ
       plication in an isolated environment. lxc-execute
command will run the specified command into  the  conâ
       tainer via an intermediate process,
lxc-init
."
753,2,lxc-execute,"lxc-execute
command will run the specified command into  the  conâ
       tainer via an intermediate process,
lxc-init
. This lxc-init after
       launching  the  specified  command,  will wait for its end and all
       other reparented processes. (to support daemons in  the  containâ
       er)."
753,3,lxc-execute,"(to support daemons in  the  containâ
       er). In other words, in the container,
lxc-init
has the pid 1 and
       the first process of the application has the pid 2. The  above
lxc-init
is designed to forward received signals to the
       started command."
754,0,lxc-freeze,"lxc-freeze
freezes all the processes running inside the container.
       The  processes will be blocked until they are explicitly thawed by
       the
lxc-unfreeze
command. This command is useful  for  batch  manâ
       agers to schedule a group of processes."
755,0,lxc-ls,"lxc-ls
list the containers existing on the system."
756,0,lxc-snapshot,"lxc-snapshot
creates, lists, and restores container snapshots. Snapshots  are stored as snapshotted containers under the containâ
       er's configuration path. For instance, if the container's configuâ
       ration path is
/var/lib/lxc
and the  container  is
c1
,  then  the
       first  snapshot  will  be stored as container
snap0
under the path
/var/lib/lxc/c1/snaps
."
756,1,lxc-snapshot,"Snapshots  are stored as snapshotted containers under the containâ
       er's configuration path. For instance, if the container's configuâ
       ration path is
/var/lib/lxc
and the  container  is
c1
,  then  the
       first  snapshot  will  be stored as container
snap0
under the path
/var/lib/lxc/c1/snaps
. If
/var/lib/lxcsnaps
, as used by LXC  1.0,
       already exists, then it will continue to be used."
757,0,lxc-monitor,"lxc-monitor
monitors  the  state of containers. The
name
argument
       may be used to specify which containers to monitor. It is a  reguâ
       lar expression, conforming with posix2, so it is possible to moniâ
       tor all the containers, several of them or just one."
757,1,lxc-monitor,"It is a  reguâ
       lar expression, conforming with posix2, so it is possible to moniâ
       tor all the containers, several of them or just one. If not speciâ
       fied,
name
will default to '.*' which will monitor all containers
       in
lxcpath
. The
-P, --lxcpath
=PATH option may be specified multiple  times  to
       monitor more than one container path."
757,2,lxc-monitor,"If not speciâ
       fied,
name
will default to '.*' which will monitor all containers
       in
lxcpath
. The
-P, --lxcpath
=PATH option may be specified multiple  times  to
       monitor more than one container path. Note however that containers
       with  the same name in multiple paths will be indistinguishable in
       the output."
758,0,lxc-start,"lxc-start
runs  the specified
command
inside the container speciâ
       fied by
name
. It will setup the container according to the configuration  previâ
       ously  defined  with the lxc-create command or with the configuraâ
       tion file parameter. If no configuration is defined, the  default
       isolation is used."
758,1,lxc-start,"It will setup the container according to the configuration  previâ
       ously  defined  with the lxc-create command or with the configuraâ
       tion file parameter. If no configuration is defined, the  default
       isolation is used. If no command is specified,
lxc-start
will use the command defined
       in lxc.init.cmd or if not set, the default
""/sbin/init""
command to
       run a system container."
759,0,lxc-stop,"lxc-stop
reboots,  cleanly shuts down, or kills all the processes
       inside the container. By default, it will request a clean shutdown
       of the container by sending
lxc.signal.halt
(defaults  to  SIGPWR)
       to  the container's init process, waiting up to 60 seconds for the
       container to exit, and then returning. If the container  fails  to
       cleanly  exit  in  60 seconds, it will be sent the
lxc.signal.stop
(defaults to SIGKILL) to force it to shut down."
759,1,lxc-stop,"If the container  fails  to
       cleanly  exit  in  60 seconds, it will be sent the
lxc.signal.stop
(defaults to SIGKILL) to force it to shut down. A request  to  reâ
       boot  will  send the
lxc.signal.reboot
(defaults to SIGINT) to the
       container's init process. The [-W], [-r], [-k] and [--nokill] options specify the action  to
       perform."
759,2,lxc-stop,"A request  to  reâ
       boot  will  send the
lxc.signal.reboot
(defaults to SIGINT) to the
       container's init process. The [-W], [-r], [-k] and [--nokill] options specify the action  to
       perform. [-W]  indicates that after performing the specified acâ
       tion,
lxc-stop
should immediately exit, while [-t TIMEOUT]  speciâ
       fies  the maximum amount of time to wait for the container to comâ
       plete the shutdown or reboot."
760,0,lxc-top,"lxc-top
displays container statistics. The output is updated every
delay
seconds, and is ordered according to the
sortby
value given. lxc-top
will display as many containers as can fit in your termiâ
       nal."
760,1,lxc-top,"lxc-top
will display as many containers as can fit in your termiâ
       nal. Press 'q' to quit. Press one of the sort key letters to  sort
       by  that  statistic."
760,2,lxc-top,"Press 'q' to quit. Press one of the sort key letters to  sort
       by  that  statistic. Pressing a sort key letter a second time reâ
       verses the sort order."
761,0,lxc-unfreeze,"lxc-unfreeze
will thaw all the processes previously frozen by the
lxc-freeze
command."
762,0,lxc-unshare,"lxc-unshare
can  be  used  to run a task in a cloned set of nameâ
       spaces. This command is mainly provided for testing purposes. Deâ
       spite its name, it always uses clone rather than unshare to create
       the new task with fresh namespaces."
762,1,lxc-unshare,"This command is mainly provided for testing purposes. Deâ
       spite its name, it always uses clone rather than unshare to create
       the new task with fresh namespaces. Apart from testing kernel  reâ
       gressions this should make no difference."
763,0,lxc-user-nic,"lxc-user-nic
is  a  setuid-root  program  with which unprivileged
       users may manage network interfaces for use by a lxc container. It will consult the configuration file
/etc/lxc/lxc-usernet
to deâ
       termine the number of interfaces which the calling user is allowed
       to create, and which bridge they may attach them to. It tracks the
       number  of  interfaces  each  user  has  created  using  the  file
/run/lxc/nics
."
763,1,lxc-user-nic,"It tracks the
       number  of  interfaces  each  user  has  created  using  the  file
/run/lxc/nics
. It ensures that the calling user is privileged over
       the  network  namespace  to  which the interface will be attached. lxc-user-nic
also allows one to delete network devices."
763,2,lxc-user-nic,"It ensures that the calling user is privileged over
       the  network  namespace  to  which the interface will be attached. lxc-user-nic
also allows one to delete network devices. Currently
       only ovs ports can be deleted."
764,0,lxc-update-config,"lxc-update-config
detects  any  legacy  configuration keys in the
       given
config
file and will replace them with the  appropriate  new
       configuration keys. lxc-update-config
will  first  create  a backup of the old
config
file in the same directory and name it
config.backup
and then  upâ
       date  the  original
config
file in place. In case the update fails
       to apply or leads to an invalid
config
file that cannot be used to
       start a container  users  can  either  compare
config
with
conâ
fig.backup
and  try to manually repair any the invalid configuraâ
       tion keys or simply rollback to the legacy configuration  file  by
       copying
config.backup
to
config
."
764,1,lxc-update-config,"lxc-update-config
will  first  create  a backup of the old
config
file in the same directory and name it
config.backup
and then  upâ
       date  the  original
config
file in place. In case the update fails
       to apply or leads to an invalid
config
file that cannot be used to
       start a container  users  can  either  compare
config
with
conâ
fig.backup
and  try to manually repair any the invalid configuraâ
       tion keys or simply rollback to the legacy configuration  file  by
       copying
config.backup
to
config
. Any  failures  for
lxc-update-config
to generate a useable
config
file are a bug and should be reported upstream."
765,0,lxc-wait,"lxc-wait
waits for a specific container state before exiting, this
       is useful for scripting."
766,0,lxc-usernsexec,"lxc-usernsexec
can  be  used  to run a task as root in a new user
       namespace."
767,0,m4,"The
m4
utility is a macro processor that shall read one or more
       text files, process them according to their included macro
       statements, and write the results to standard output."
768,0,make,"The
make
utility will determine automatically which pieces of a
       large program need to be recompiled, and issue the commands to
       recompile them. The manual describes the GNU implementation of
make
, which was written by Richard Stallman and Roland McGrath,
       and is currently maintained by Paul Smith. Our examples show C
       programs, since they are very common, but you can use
make
with
       any programming language whose compiler can be run with a shell
       command."
768,1,make,"Our examples show C
       programs, since they are very common, but you can use
make
with
       any programming language whose compiler can be run with a shell
       command. In fact,
make
is not limited to programs. You can use
       it to describe any task where some files must be updated
       automatically from others whenever the others change."
768,2,make,"You can use
       it to describe any task where some files must be updated
       automatically from others whenever the others change. To prepare to use
make
, you must write a file called the
makefile
that describes the relationships among files in your program, and
       provides commands for updating each file. In a program, typically
       the executable file is updated from object files, which are in
       turn made by compiling source files."
768,3,make,"In a program, typically
       the executable file is updated from object files, which are in
       turn made by compiling source files. Once a suitable makefile exists, each time you change some source
       files, this simple shell command:
make
suffices to perform all necessary recompilations. The
make
program uses the makefile description and the last-modification
       times of the files to decide which of the files need to be
       updated."
768,4,make,"The
make
program uses the makefile description and the last-modification
       times of the files to decide which of the files need to be
       updated. For each of those files, it issues the commands recorded
       in the makefile. make
executes commands in the
makefile
to update one or more
targets
, where
target
is typically a program."
768,5,make,"make
executes commands in the
makefile
to update one or more
targets
, where
target
is typically a program. If no
-f
option is
       present,
make
will look for the makefiles
GNUmakefile
,
makefile
,
       and
Makefile
, in that order. Normally you should call your makefile either
makefile
or
Makefile
."
768,6,make,"Normally you should call your makefile either
makefile
or
Makefile
. (We recommend
Makefile
because it appears prominently
       near the beginning of a directory listing, right near other
       important files such as
README
.)  The first name checked,
GNUmakefile
, is not recommended for most makefiles. You should
       use this name if you have a makefile that is specific to GNU
make
,
       and will not be understood by other versions of
make
."
768,7,make,"You should
       use this name if you have a makefile that is specific to GNU
make
,
       and will not be understood by other versions of
make
. If
makefile
is '-', the standard input is read. make
updates a target if it depends on prerequisite files that
       have been modified since the target was last modified, or if the
       target does not exist."
769,0,machinectl,"machinectl
may be used to introspect and control the state of the
systemd(1)
virtual machine and container registration manager
systemd-machined.service(8)
. machinectl
may be used to execute operations on machines and
       images. Machines in this sense are considered running instances
       of:

       â¢   Virtual Machines (VMs) that virtualize hardware to run full
           operating system (OS) instances (including their kernels) in a
           virtualized environment on top of the host OS."
769,1,machinectl,"Machines in this sense are considered running instances
       of:

       â¢   Virtual Machines (VMs) that virtualize hardware to run full
           operating system (OS) instances (including their kernels) in a
           virtualized environment on top of the host OS. â¢   Containers that share the hardware and OS kernel with the host
           OS, in order to run OS userspace instances on top the host OS. â¢   The host system itself."
769,2,machinectl,"â¢   The host system itself. Machines are identified by names that follow the same rules as
       UNIX and DNS hostnames. For details, see below."
769,3,machinectl,"For details, see below. Machines are instantiated from disk or file system images that
       frequently â but not necessarily â carry the same name as machines
       running from them. Images in this sense may be:

       â¢   Directory trees containing an OS, including the top-level
           directories /usr/, /etc/, and so on."
769,4,machinectl,"Images in this sense may be:

       â¢   Directory trees containing an OS, including the top-level
           directories /usr/, /etc/, and so on. â¢   btrfs subvolumes containing OS trees, similar to regular
           directory trees. â¢   Binary ""raw"" disk image files containing MBR or GPT partition
           tables and Linux file systems."
769,5,machinectl,"â¢   Binary ""raw"" disk image files containing MBR or GPT partition
           tables and Linux file systems. â¢   Similarly, block devices containing MBR or GPT partition
           tables and file systems. â¢   The file system tree of the host OS itself."
769,6,machinectl,"â¢   Similarly, block devices containing MBR or GPT partition
           tables and file systems. â¢   The file system tree of the host OS itself. Images may be downloaded, imported and exported via the
importctl(1)
tool."
770,0,mailx,"The
mailx
utility provides a message sending and receiving
       facility. It has two major modes, selected by the options used:
       Send Mode and Receive Mode. On systems that do not support the User Portability Utilities
       option, an application using
mailx
shall have the ability to send
       messages in an unspecified manner (Send Mode)."
770,1,mailx,"On systems that do not support the User Portability Utilities
       option, an application using
mailx
shall have the ability to send
       messages in an unspecified manner (Send Mode). Unless the first
       character of one or more lines is <tilde> (
'~'
), all characters in
       the input message shall appear in the delivered message, but
       additional characters may be inserted in the message before it is
       retrieved. On systems supporting the User Portability Utilities option, mail-
       receiving capabilities and other interactive features, Receive
       Mode, described below, also shall be enabled."
770,2,mailx,"On systems supporting the User Portability Utilities option, mail-
       receiving capabilities and other interactive features, Receive
       Mode, described below, also shall be enabled. Send Mode
Send Mode can be used by applications or users to send messages
       from the text in standard input. Receive Mode
Receive Mode is more oriented towards interactive users."
770,3,mailx,"Receive Mode
Receive Mode is more oriented towards interactive users. Mail can
       be read and sent in this interactive mode. When reading mail,
mailx
provides commands to facilitate saving,
       deleting, and responding to messages."
770,4,mailx,"When reading mail,
mailx
provides commands to facilitate saving,
       deleting, and responding to messages. When sending mail,
mailx
allows editing, reviewing, and other modification of the message
       as it is entered. Incoming mail shall be stored in one or more unspecified locations
       for each user, collectively called the system
mailbox
for that
       user."
770,5,mailx,"Incoming mail shall be stored in one or more unspecified locations
       for each user, collectively called the system
mailbox
for that
       user. When
mailx
is invoked in Receive Mode, the system mailbox
       shall be the default place to find new mail. As messages are read,
       they shall be marked to be moved to a secondary file for storage,
       unless specific action is taken."
770,6,mailx,"As messages are read,
       they shall be marked to be moved to a secondary file for storage,
       unless specific action is taken. This secondary file is called the
mbox
and is normally located in the directory referred to by the
HOME
environment variable (see
MBOX
in the ENVIRONMENT VARIABLES
       section for a description of this file). Messages shall remain in
       this file until explicitly removed."
770,7,mailx,"Messages shall remain in
       this file until explicitly removed. When the
-f
option is used to
       read mail messages from secondary files, messages shall be
       retained in those files unless specifically removed. All three of
       these locationsâsystem mailbox,
mbox
, and secondary fileâare
       referred to in this section as simply ``mailboxes'', unless more
       specific identification is required."
771,0,make,"The
make
utility shall update files that are derived from other
       files. A typical case is one where object files are derived from
       the corresponding source files. The
make
utility examines time
       relationships and shall update those derived files (called
       targets) that have modified times earlier than the modified times
       of the files (called prerequisites) from which they are derived."
771,1,make,"The
make
utility examines time
       relationships and shall update those derived files (called
       targets) that have modified times earlier than the modified times
       of the files (called prerequisites) from which they are derived. A description file (makefile) contains a description of the
       relationships between files, and the commands that need to be
       executed to update the targets to reflect changes in their
       prerequisites. Each specification, or rule, shall consist of a
       target, optional prerequisites, and optional commands to be
       executed when a prerequisite is newer than the target."
771,2,make,"Each specification, or rule, shall consist of a
       target, optional prerequisites, and optional commands to be
       executed when a prerequisite is newer than the target. There are
       two types of rule:

        1. Inference rules
, which have one target name with at least one
           <period> (
'.'
)  and no <slash> (
'/'
)

        2."
771,3,make,"Inference rules
, which have one target name with at least one
           <period> (
'.'
)  and no <slash> (
'/'
)

        2. Target rules
, which can have more than one target name

       In addition,
make
shall have a collection of built-in macros and
       inference rules that infer prerequisite relationships to simplify
       maintenance of programs. To receive exactly the behavior described in this section, the
       user shall ensure that a portable makefile shall:

        *  Include the special target
.POSIX
*  Omit any special target reserved for implementations (a
           leading period followed by uppercase letters) that has not
           been specified by this section

       The behavior of
make
is unspecified if either or both of these
       conditions are not met."
772,0,makeconv,"makeconv
converts the ICU converter table
convertertable
into a
       binary file. The binary file has the same base name as
convertertable
but has a
.cnv
extension (instead of the typical
.ucm
extension of the
convertertable
file). This binary file can
       then be read directly by ICU, or used by
pkgdata(1)
for
       incorporation into a larger archive or library."
772,1,makeconv,"This binary file can
       then be read directly by ICU, or used by
pkgdata(1)
for
       incorporation into a larger archive or library. The
convertertable
must be in the ICU ucm (Unicode Codepage
       Mapping) format in order to be understood by
makeconv
. The ICU
       ucm format is similar to the IBM NLTC upmap/tpmap/rpmap files."
772,2,makeconv,"The ICU
       ucm format is similar to the IBM NLTC upmap/tpmap/rpmap files. Comments in the
convertertable
are handled as follows. If a
       comment (starting with a `#' sign) that is after some text does
       contain the fallback indicator `|' then only the text starting
       with the `#' sign, and ending before the `|' sign, is ignored."
772,3,makeconv,"If a
       comment (starting with a `#' sign) that is after some text does
       contain the fallback indicator `|' then only the text starting
       with the `#' sign, and ending before the `|' sign, is ignored. Otherwise, or if the comment is the first thing on the line, the
       comment runs up to the end of the line. This special handling of
       comments is to accommodate the practice of putting fallback
       information in comments in the strict IBM NLTC ucmap format."
772,4,makeconv,"This special handling of
       comments is to accommodate the practice of putting fallback
       information in comments in the strict IBM NLTC ucmap format. Note that new converters will be automatically found by ICU after
       their installation in ICU's data directory. They do not need to be
       listed in the
convrtrs.txt
(5) converters aliases file in order to
       be available to applications using ICU."
772,5,makeconv,"Note that new converters will be automatically found by ICU after
       their installation in ICU's data directory. They do not need to be
       listed in the
convrtrs.txt
(5) converters aliases file in order to
       be available to applications using ICU. They do need to be listed
       there if one wants to give them aliases, or tags, though."
773,0,man-recode,"man-recode
converts multiple manual pages from one encoding to
       another, guessing the appropriate input encoding for each one. It
       is useful when permanently recoding pages written in legacy
       character sets, or in build systems that need to recode a set of
       pages to a single common encoding (usually UTF-8) for
       installation. When converting many manual pages, this program is
       much faster than running
man --recode
or
manconv
on each page."
773,1,man-recode,"When converting many manual pages, this program is
       much faster than running
man --recode
or
manconv
on each page. If an encoding declaration is found on the first line of a manual
       page, then that declaration is used as the input encoding for that
       page. Failing that, the input encoding is guessed based on the
       file name."
773,2,man-recode,"If an encoding declaration is found on the first line of a manual
       page, then that declaration is used as the input encoding for that
       page. Failing that, the input encoding is guessed based on the
       file name. Encoding declarations have the following form:

              '\"" -*- coding: UTF-8 -*-

       or (if manual page preprocessors are also to be declared):

              '\"" t -*- coding: ISO-8859-1 -*-"
774,0,man,"man
is the system's manual pager. Each
page
argument given to
man
is normally the name of a program, utility or function. The
manual page
associated with each of these arguments is then found
       and displayed."
774,1,man,"The
manual page
associated with each of these arguments is then found
       and displayed. A
section
, if provided, will direct
man
to look
       only in that
section
of the manual. The default action is to
       search in all of the available
sections
following a pre-defined
       order (see
DEFAULTS
), and to show only the first
page
found, even
       if
page
exists in several
sections
."
774,2,man,"The default action is to
       search in all of the available
sections
following a pre-defined
       order (see
DEFAULTS
), and to show only the first
page
found, even
       if
page
exists in several
sections
. The table below shows the
section
numbers of the manual followed
       by the types of pages they contain. 1   Executable programs or shell commands
       2   System calls (functions provided by the kernel)
       3   Library calls (functions within program libraries)
       4   Special files (usually found in
/dev
)
       5   File formats and conventions, e.g."
774,3,man,"1   Executable programs or shell commands
       2   System calls (functions provided by the kernel)
       3   Library calls (functions within program libraries)
       4   Special files (usually found in
/dev
)
       5   File formats and conventions, e.g. /etc/passwd
6   Games
       7   Miscellaneous (including macro packages and conventions), e.g. man(7)
,
groff(7)
,
man-pages(7)
8   System administration commands (usually only for root)
       9   Kernel routines [Non standard]

       A manual
page
consists of several sections."
774,4,man,"man(7)
,
groff(7)
,
man-pages(7)
8   System administration commands (usually only for root)
       9   Kernel routines [Non standard]

       A manual
page
consists of several sections. Conventional section names include
NAME
,
SYNOPSIS
,
CONFIGURATION
,
DESCRIPTION
,
OPTIONS
,
EXIT STATUS
,
RETURN VALUE
,
ERRORS
,
ENVIRONMENT
,
FILES
,
VERSIONS
,
STANDARDS
,
NOTES
,
BUGS
,
EXAMPLE
,
AUTHORS
, and
SEE ALSO
. The following conventions apply to the
SYNOPSIS
section and can be
       used as a guide in other sections."
774,5,man,"The following conventions apply to the
SYNOPSIS
section and can be
       used as a guide in other sections. bold text
type exactly as shown. italic text
replace with appropriate argument."
774,6,man,"italic text
replace with appropriate argument. [
-abc
]             any or all arguments within [ ] are optional. -a
|
-b
options delimited by | cannot be used together."
774,7,man,"-a
|
-b
options delimited by | cannot be used together. argument
... argument
is repeatable."
774,8,man,"argument
is repeatable. [
expression
] ... entire
expression
within [ ] is repeatable."
774,9,man,"entire
expression
within [ ] is repeatable. Exact rendering may vary depending on the output device. For
       instance, man will usually not be able to render italics when
       running in a terminal, and will typically use underlined or
       coloured text instead."
774,10,man,"For
       instance, man will usually not be able to render italics when
       running in a terminal, and will typically use underlined or
       coloured text instead. The command or function illustration is a pattern that should
       match all possible invocations. In some cases it is advisable to
       illustrate several exclusive invocations as is shown in the
SYNOPSIS
section of this manual page."
775,0,man,"The
man
utility shall write information about each of the
name
operands. If
name
is the name of a standard utility,
man
at a
       minimum shall write a message describing the syntax used by the
       standard utility, its options, and operands. If more information
       is available, the
man
utility shall provide it in an
       implementation-defined manner."
775,1,man,"If more information
       is available, the
man
utility shall provide it in an
       implementation-defined manner. An implementation may provide information for values of
name
other
       than the standard utilities. Standard utilities that are listed as
       optional and that are not supported by the implementation either
       shall cause a brief message indicating that fact to be displayed
       or shall cause a full display of information as described
       previously."
776,0,mansect,"The
mansect
command prints the source code of the
section
of the
       given manual-page files. If no files are specified, the standard
       input is used. section
is a PCRE2 regular expression."
776,1,mansect,"section
is a PCRE2 regular expression. The
TH
line is unconditionally printed. The output of this program is suitable for piping to the
groff(1)
pipeline."
777,0,manconv,"manconv
converts a manual page from one encoding to another, like
iconv
. Unlike
iconv
, it can try multiple possible input encodings
       in sequence. This is useful for manual pages installed in
       directories without an explicit encoding declaration, since they
       may be in UTF-8 or in a legacy character set."
777,1,manconv,"This is useful for manual pages installed in
       directories without an explicit encoding declaration, since they
       may be in UTF-8 or in a legacy character set. If an encoding declaration is found on the first line of the
       manual page, that declaration overrides any input encodings
       specified on
manconv
's command line. Encoding declarations have
       the following form:

              '\"" -*- coding: UTF-8 -*-

       or (if manual page preprocessors are also to be declared):

              '\"" t -*- coding: ISO-8859-1 -*-"
778,0,manpath,"If $
MANPATH
is set,
manpath
will simply display its contents and
       issue a warning.  If not,
manpath
will determine a suitable manual
       page hierarchy search path and display the results.

       The colon-delimited path is determined using information gained
       from the man-db configuration file â (
/usr/local/etc/man_db.conf
)
       and the user's environment."
779,0,mariadb-access,"mariadb-access
is a diagnostic tool written by Yves Carlier. It
       checks the access privileges for a host name, user name, and
       database combination. Note that
mariadb-access
checks access using
       only the user, db, and host tables."
779,1,mariadb-access,"Note that
mariadb-access
checks access using
       only the user, db, and host tables. It does not check table,
       column, or routine privileges specified in the tables_priv,
       columns_priv, or procs_priv tables. Invoke
mariadb-access
like this:

           shell>
mariadb-access [
host_name
[
user_name
[
db_name
]]] [
options
]
mariadb-access
supports the following options."
779,2,mariadb-access,"Invoke
mariadb-access
like this:

           shell>
mariadb-access [
host_name
[
user_name
[
db_name
]]] [
options
]
mariadb-access
supports the following options. â¢
--help
,
-? Display a help message and exit."
779,3,mariadb-access,"Display a help message and exit. â¢
--brief
,
-b
Generate reports in single-line tabular format. â¢
--commit
Copy the new access privileges from the temporary tables to
           the original grant tables."
779,4,mariadb-access,"â¢
--commit
Copy the new access privileges from the temporary tables to
           the original grant tables. The grant tables must be flushed
           for the new privileges to take effect. (For example, execute a
mariadb-admin reload
command.)

       â¢
--copy
Reload the temporary grant tables from original ones."
779,5,mariadb-access,"(For example, execute a
mariadb-admin reload
command.)

       â¢
--copy
Reload the temporary grant tables from original ones. â¢
--db=
db_name
,
-d
db_name
Specify the database name. â¢
--debug=
N
Specify the debug level."
779,6,mariadb-access,"â¢
--debug=
N
Specify the debug level. N
can be an integer from 0 to 3. â¢
--host=
host_name
,
-h
host_name
The host name to use in the access privileges."
779,7,mariadb-access,"â¢
--host=
host_name
,
-h
host_name
The host name to use in the access privileges. â¢
--howto
Display some examples that show how to use
mariadb-access
. â¢
--old_server
Connect to a very old MySQL server (before MySQL 3.21) that
           does not know how to handle full WHERE clauses."
779,8,mariadb-access,"â¢
--old_server
Connect to a very old MySQL server (before MySQL 3.21) that
           does not know how to handle full WHERE clauses. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you omit
           the
password
value following the
--password
or
-p
option on
           the command line,
mariadb-access
prompts for one."
779,9,mariadb-access,"If you omit
           the
password
value following the
--password
or
-p
option on
           the command line,
mariadb-access
prompts for one. Specifying a password on the command line should be considered
           insecure. See Section 5.3.2.2, âEnd-User Guidelines for
           Password Securityâ."
779,10,mariadb-access,"See Section 5.3.2.2, âEnd-User Guidelines for
           Password Securityâ. â¢
--plan
Display suggestions and ideas for future releases. â¢
--preview
Show the privilege differences after making changes to the
           temporary grant tables."
779,11,mariadb-access,"â¢
--preview
Show the privilege differences after making changes to the
           temporary grant tables. â¢
--relnotes
Display the release notes. â¢
--rhost=
host_name
,
-H
host_name
Connect to the MariaDB server on the given host."
779,12,mariadb-access,"â¢
--rhost=
host_name
,
-H
host_name
Connect to the MariaDB server on the given host. â¢
--rollback
Undo the most recent changes to the temporary grant tables. â¢
--spassword[=
password
]
,
-P[
password
]
The password to use when connecting to the server as the
           superuser."
779,13,mariadb-access,"â¢
--spassword[=
password
]
,
-P[
password
]
The password to use when connecting to the server as the
           superuser. If you omit the
password
value following the
--spassword
or
-p
option on the command line,
mariadb-access
prompts for one. Specifying a password on the command line should be considered
           insecure."
779,14,mariadb-access,"Specifying a password on the command line should be considered
           insecure. See Section 5.3.2.2, âEnd-User Guidelines for
           Password Securityâ. â¢
--superuser=
user_name
,
-U
user_name
Specify the user name for connecting as the superuser."
779,15,mariadb-access,"â¢
--superuser=
user_name
,
-U
user_name
Specify the user name for connecting as the superuser. â¢
--table
,
-t
Generate reports in table format. â¢
--user=
user_name
,
-u
user_name
The user name to use in the access privileges."
779,16,mariadb-access,"â¢
--user=
user_name
,
-u
user_name
The user name to use in the access privileges. â¢
--version
,
-v
Display version information and exit. If your MariaDB distribution is installed in some non-standard
       location, you must change the location where
mariadb-access
expects to find the
mariadb
client."
779,17,mariadb-access,"If your MariaDB distribution is installed in some non-standard
       location, you must change the location where
mariadb-access
expects to find the
mariadb
client. Edit the mariadb-access script
       at approximately line 18. Search for a line that looks like this:

           $MYSQL     = '/usr/local/bin/mariadb';    # path to mariadb executable

       Change the path to reflect the location where
mariadb
actually is
       stored on your system."
779,18,mariadb-access,"Edit the mariadb-access script
       at approximately line 18. Search for a line that looks like this:

           $MYSQL     = '/usr/local/bin/mariadb';    # path to mariadb executable

       Change the path to reflect the location where
mariadb
actually is
       stored on your system. If you do not do this, a Broken pipe error
       will occur when you run
mariadb-access
."
780,0,mariadb-backup,"Use
mariabackup --help
for details on usage.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
781,0,mariadb-backup,"Use
mariabackup --help
for details on usage.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
782,0,mariadb-admin,"mariadb-admin
is a client for performing administrative
       operations. You can use it to check the server's configuration and
       current status, to create and drop databases, and more. Invoke
mariadb-admin
like this:

           shell>
mariadb-admin [
options
]
command
[
command-arg
] [
command
[
command-arg
]] ..."
782,1,mariadb-admin,"Invoke
mariadb-admin
like this:

           shell>
mariadb-admin [
options
]
command
[
command-arg
] [
command
[
command-arg
]] ... mariadb-admin
supports the following commands. Some of the
       commands take an argument following the command name."
782,2,mariadb-admin,"Some of the
       commands take an argument following the command name. â¢   create
db_name
Create a new database named
db_name
. â¢   debug

           Tell the server to write debug information to the error log."
782,3,mariadb-admin,"â¢   debug

           Tell the server to write debug information to the error log. This also includes information about the Event Scheduler. â¢   drop
db_name
Delete the database named
db_name
and all its tables."
782,4,mariadb-admin,"â¢   drop
db_name
Delete the database named
db_name
and all its tables. â¢   extended-status

           Display the server status variables and their values. â¢   flush-all-statistics

           Flush all statistics tables."
782,5,mariadb-admin,"â¢   flush-all-statistics

           Flush all statistics tables. â¢   flush-all-status

           Flush all status and statistics. â¢   flush-binary-log

           Flush the binary log."
782,6,mariadb-admin,"â¢   flush-binary-log

           Flush the binary log. â¢   flush-client-statistics

           Flush client statistics. â¢   flush-engine-log

           Flush engine log."
782,7,mariadb-admin,"â¢   flush-engine-log

           Flush engine log. â¢   flush-error-log

           Flush error log. â¢   flush-general-log

           Flush general query log."
782,8,mariadb-admin,"â¢   flush-general-log

           Flush general query log. â¢   flush-hosts

           Flush all information in the host cache. â¢   flush-index-statistics

           Flush index statistics."
782,9,mariadb-admin,"â¢   flush-index-statistics

           Flush index statistics. â¢   flush-logs

           Flush all logs. â¢   flush-privileges

           Reload the grant tables (same as reload)."
782,10,mariadb-admin,"â¢   flush-privileges

           Reload the grant tables (same as reload). â¢   flush-relay-log

           Flush relay log. â¢   flush-slow-log

           Flush slow query log."
782,11,mariadb-admin,"â¢   flush-slow-log

           Flush slow query log. â¢   flush-ssl

           Flush SSL certificates. â¢   flush-status

           Clear status variables."
782,12,mariadb-admin,"â¢   flush-status

           Clear status variables. â¢   flush-table-statistics

           Flush table statistics. â¢   flush-tables

           Flush all tables."
782,13,mariadb-admin,"â¢   flush-tables

           Flush all tables. â¢   flush-threads

           Flush the thread cache. â¢   flush-user-resources

           Flush user resources."
782,14,mariadb-admin,"â¢   flush-user-resources

           Flush user resources. â¢   kill
id
,
id
,... Kill server threads."
782,15,mariadb-admin,"Kill server threads. If multiple thread ID values are given,
           there must be no spaces in the list. â¢   old-password
new-password
This is like the password command but stores the password
           using the old (pre MySQL 4.1) password-hashing format."
782,16,mariadb-admin,"â¢   old-password
new-password
This is like the password command but stores the password
           using the old (pre MySQL 4.1) password-hashing format. â¢   password
new-password
Set a new password. This changes the password to
new-password
for the account that you use with
mariadb-admin
for connecting
           to the server."
782,17,mariadb-admin,"This changes the password to
new-password
for the account that you use with
mariadb-admin
for connecting
           to the server. Thus, the next time you invoke
mariadb-admin
(or any other client program) using the same account, you will
           need to specify the new password. If the
new-password
value contains spaces or other characters
           that are special to your command interpreter, you need to
           enclose it within quotes."
782,18,mariadb-admin,"If the
new-password
value contains spaces or other characters
           that are special to your command interpreter, you need to
           enclose it within quotes. On Windows, be sure to use double
           quotes rather than single quotes; single quotes are not
           stripped from the password, but rather are interpreted as part
           of the password. For example:

               shell>
mariadb-admin password ""my new password""
Caution
Do not use this command used if the server was started
               with the
--skip-grant-tables
option."
782,19,mariadb-admin,"For example:

               shell>
mariadb-admin password ""my new password""
Caution
Do not use this command used if the server was started
               with the
--skip-grant-tables
option. No password change
               will be applied. This is true even if you precede the
               password command with flush-privileges on the same command
               line to re-enable the grant tables because the flush
               operation occurs after you connect."
782,20,mariadb-admin,"This is true even if you precede the
               password command with flush-privileges on the same command
               line to re-enable the grant tables because the flush
               operation occurs after you connect. However, you can use
mariadb-admin flush-privileges
to re-enable the grant
               table and then use a separate
mariadb-admin password
command to change the password. â¢   ping

           Check whether the server is alive."
782,21,mariadb-admin,"â¢   ping

           Check whether the server is alive. The return status from
mariadb-admin
is 0 if the server is running, 1 if it is not. This is 0 even in case of an error such as Access denied,
           because this means that the server is running but refused the
           connection, which is different from the server not running."
782,22,mariadb-admin,"This is 0 even in case of an error such as Access denied,
           because this means that the server is running but refused the
           connection, which is different from the server not running. â¢   processlist

           Show a list of active server threads. This is like the output
           of the SHOW PROCESSLIST statement."
782,23,mariadb-admin,"This is like the output
           of the SHOW PROCESSLIST statement. If the
--verbose
option is
           given, the output is like that of SHOW FULL PROCESSLIST. â¢   reload

           Reload the grant tables."
782,24,mariadb-admin,"â¢   reload

           Reload the grant tables. â¢   refresh

           Flush all tables and close and open log files. â¢   shutdown

           Stop the server."
782,25,mariadb-admin,"â¢   shutdown

           Stop the server. â¢   start-all-slaves

           Start all slaves. â¢   start-slave

           Start replication on a slave server."
782,26,mariadb-admin,"â¢   start-slave

           Start replication on a slave server. â¢   status

           Display a short server status message. â¢   stop-all-slaves

           Stop all slaves."
782,27,mariadb-admin,"â¢   stop-all-slaves

           Stop all slaves. â¢   stop-slave

           Stop replication on a slave server. â¢   variables

           Display the server system variables and their values."
782,28,mariadb-admin,"â¢   variables

           Display the server system variables and their values. â¢   version

           Display version information from the server. All commands can be shortened to any unique prefix."
782,29,mariadb-admin,"All commands can be shortened to any unique prefix. For example:

           shell>
mariadb-admin proc stat
+----+-------+-----------+----+---------+------+-------+------------------+
           | Id | User  | Host      | db | Command | Time | State | Info             |
           +----+-------+-----------+----+---------+------+-------+------------------+
           | 51 | monty | localhost |    | Query   | 0    |       | show processlist |
           +----+-------+-----------+----+---------+------+-------+------------------+
           Uptime: 1473624  Threads: 1  Questions: 39487
           Slow queries: 0  Opens: 541  Flush tables: 1
           Open tables: 19  Queries per second avg: 0.0268

       The
mariadb-admin status
command result displays the following
       values:

       â¢   Uptime

           The number of seconds the MariaDB server has been running. â¢   Threads

           The number of active threads (clients)."
782,30,mariadb-admin,"â¢   Threads

           The number of active threads (clients). â¢   Questions

           The number of questions (queries) from clients since the
           server was started. â¢   Slow queries

           The number of queries that have taken more than
           log_slow_query_time seconds."
782,31,mariadb-admin,"â¢   Slow queries

           The number of queries that have taken more than
           log_slow_query_time seconds. â¢   Opens

           The number of tables the server has opened. â¢   Flush tables

           The number of flush-*, refresh, and reload commands the server
           has executed."
782,32,mariadb-admin,"â¢   Flush tables

           The number of flush-*, refresh, and reload commands the server
           has executed. â¢   Open tables

           The number of tables that currently are open. â¢   Memory in use

           The amount of memory allocated directly by
mariadbd
."
782,33,mariadb-admin,"â¢   Memory in use

           The amount of memory allocated directly by
mariadbd
. This
           value is displayed only when MariaDB has been compiled with
--with-debug=full
. â¢   Maximum memory used

           The maximum amount of memory allocated directly by
mariadbd
."
782,34,mariadb-admin,"â¢   Maximum memory used

           The maximum amount of memory allocated directly by
mariadbd
. This value is displayed only when MariaDB has been compiled
           with
--with-debug=full
. If you execute
mariadb-admin shutdown
when connecting to a local
       server using a Unix socket file,
mariadb-admin
waits until the
       server's process ID file has been removed, to ensure that the
       server has stopped properly."
782,35,mariadb-admin,"If you execute
mariadb-admin shutdown
when connecting to a local
       server using a Unix socket file,
mariadb-admin
waits until the
       server's process ID file has been removed, to ensure that the
       server has stopped properly. mariadb-admin
supports the following options, which can be
       specified on the command line or in the [mariadb-admin] and
       [client] option file groups. â¢
--help
,
-?"
782,36,mariadb-admin,"â¢
--help
,
-? Display help and exit. â¢
--character-sets-dir=
path
The directory where character sets are installed."
782,37,mariadb-admin,"â¢
--character-sets-dir=
path
The directory where character sets are installed. â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression. â¢
--connect-timeout=
timeout
Equivalent to
--connect_timeout
, see the end of this section."
782,38,mariadb-admin,"â¢
--connect-timeout=
timeout
Equivalent to
--connect_timeout
, see the end of this section. â¢
--count=
N
,
-c
N
The number of iterations to make for repeated command
           execution if the
--sleep
option is given. â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log."
782,39,mariadb-admin,"â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log. A typical
debug_options
string is
           'd:t:o,
file_name
'. The default is 'd:t:o,/tmp/mariadb-
           admin.trace'."
782,40,mariadb-admin,"The default is 'd:t:o,/tmp/mariadb-
           admin.trace'. â¢
--debug-check
Check memory and open file usage at exit.. â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits."
782,41,mariadb-admin,"â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--default-auth
Default authentication client-side plugin to use. â¢
--default-character-set=
charset_name
Use
charset_name
as the default character set."
782,42,mariadb-admin,"â¢
--default-character-set=
charset_name
Use
charset_name
as the default character set. â¢
--defaults-extra-file=
filename
Set
filename
as the file to read default options from after
           the global defaults files has been read. Must be given as
           first option."
782,43,mariadb-admin,"Must be given as
           first option. â¢
--defaults-file=
filename
Set
filename
as the file to read default options from,
           override global defaults files. Must be given as first option."
782,44,mariadb-admin,"Must be given as first option. â¢
--force
,
-f
Do not ask for confirmation for the drop
db_name
command. With
           multiple commands, continue even if an error occurs."
782,45,mariadb-admin,"With
           multiple commands, continue even if an error occurs. â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host. â¢
--local
,
-l
Suppress the SQL command(s) from being written to the binary
           log by using FLUSH LOCAL or enabling sql_log_bin=0 for the
           session."
782,46,mariadb-admin,"â¢
--local
,
-l
Suppress the SQL command(s) from being written to the binary
           log by using FLUSH LOCAL or enabling sql_log_bin=0 for the
           session. â¢
--no-beep
,
-b
Suppress the warning beep that is emitted by default for
           errors such as a failure to connect to the server. â¢
--no-defaults
Do not read default options from any option file."
782,47,mariadb-admin,"â¢
--no-defaults
Do not read default options from any option file. This must be
           given as the first argument. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server."
782,48,mariadb-admin,"â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-admin
prompts for one."
782,49,mariadb-admin,"If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-admin
prompts for one. Specifying a password on the command line should be considered
           insecure. â¢
--pipe
,
-W
On Windows, connect to the server via a named pipe."
782,50,mariadb-admin,"â¢
--pipe
,
-W
On Windows, connect to the server via a named pipe. This
           option applies only if the server supports named-pipe
           connections. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection or 0 for
           default to, in order of preference, my.cnf, $MYSQL_TCP_PORT,
           /etc/services, built-in default (3306)."
782,51,mariadb-admin,"â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection or 0 for
           default to, in order of preference, my.cnf, $MYSQL_TCP_PORT,
           /etc/services, built-in default (3306). Forces --protocol=tcp
           when specified on the command line without other connection
           properties. â¢
--print-defaults
Print the program argument list and exit."
782,52,mariadb-admin,"â¢
--print-defaults
Print the program argument list and exit. This must be given
           as the first argument. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server."
782,53,mariadb-admin,"â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--relative
,
-r
Show the difference between the current and previous values
           when used with the
--sleep
option."
782,54,mariadb-admin,"â¢
--relative
,
-r
Show the difference between the current and previous values
           when used with the
--sleep
option. Currently, this option
           works only with the extended-status command. â¢
--shutdown-timeout
timeout
Equivalent of
--shutdown_timeout
, see the end of this section."
782,55,mariadb-admin,"â¢
--shutdown-timeout
timeout
Equivalent of
--shutdown_timeout
, see the end of this section. â¢
--silent
,
-s
Exit silently if a connection to the server cannot be
           established. â¢
--sleep=
delay
,
-i
delay
Execute commands repeatedly, sleeping for
delay
seconds in
           between."
782,56,mariadb-admin,"â¢
--sleep=
delay
,
-i
delay
Execute commands repeatedly, sleeping for
delay
seconds in
           between. The
--count
option determines the number of
           iterations. If
--count
is not given,
mariadb-admin
executes
           commands indefinitely until interrupted."
782,57,mariadb-admin,"If
--count
is not given,
mariadb-admin
executes
           commands indefinitely until interrupted. â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe."
782,58,mariadb-admin,"Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe. â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags). Disable with
--skip-ssl
."
782,59,mariadb-admin,"Disable with
--skip-ssl
. â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
)."
782,60,mariadb-admin,"â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
)."
782,61,mariadb-admin,"â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
). â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
)."
782,62,mariadb-admin,"â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
). â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting."
782,63,mariadb-admin,"â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting. This option is disabled by default. â¢
--tls-version=
name
,

           Accepts a comma-separated list of TLS protocol versions."
782,64,mariadb-admin,"â¢
--tls-version=
name
,

           Accepts a comma-separated list of TLS protocol versions. A TLS
           protocol version will only be enabled if it is present in this
           list. All other TLS protocol versions will not be permitted."
782,65,mariadb-admin,"All other TLS protocol versions will not be permitted. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
--verbose
,
-v
Verbose mode."
782,66,mariadb-admin,"â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does. â¢
--version
,
-V
Display version information and exit."
782,67,mariadb-admin,"â¢
--version
,
-V
Display version information and exit. â¢
--vertical
,
-E
Print output vertically. This is similar to
--relative
, but
           prints output vertically."
782,68,mariadb-admin,"This is similar to
--relative
, but
           prints output vertically. â¢
--wait[=
count
]
,
-w[
count
]
If the connection cannot be established, wait and retry
           instead of aborting. If a
count
value is given, it indicates
           the number of times to retry."
782,69,mariadb-admin,"If a
count
value is given, it indicates
           the number of times to retry. The default is one time. â¢
--wait-for-all-slaves
Wait for the last binlog event to be sent to all connected
           slaves before shutting down."
782,70,mariadb-admin,"â¢
--wait-for-all-slaves
Wait for the last binlog event to be sent to all connected
           slaves before shutting down. This option is off by default. You can also set the following variables by using
--
var_name
=
value
â¢   connect_timeout

           The maximum number of seconds before connection timeout."
782,71,mariadb-admin,"You can also set the following variables by using
--
var_name
=
value
â¢   connect_timeout

           The maximum number of seconds before connection timeout. The
           default value is 43200 (12 hours). â¢   shutdown_timeout

           The maximum number of seconds to wait for server shutdown."
782,72,mariadb-admin,"The
           default value is 43200 (12 hours). â¢   shutdown_timeout

           The maximum number of seconds to wait for server shutdown. The
           default value is 3600 (1 hour)."
783,0,mariadb-client-test,"The
mariadb-client-test
program is used for testing aspects of the
       MariaDB client API that cannot be tested using
mariadb-test
and
       its test language. mariadb-client-test-embedded
is similar but
       used for testing the embedded server. Both programs are run as
       part of the test suite."
783,1,mariadb-client-test,"Both programs are run as
       part of the test suite. The source code for the programs can be found in in tests/mariadb-
       client-test.c in a source distribution. The program serves as a
       good source of examples illustrating how to use various features
       of the client API."
783,2,mariadb-client-test,"The program serves as a
       good source of examples illustrating how to use various features
       of the client API. mariadb-client-test
is used in a test by the same name in the main
       tests suite of
mariadb-test-run.pl
but may also be run directly. Unlike the other programs listed here, it does not read an
       external description of what tests to run."
783,3,mariadb-client-test,"Unlike the other programs listed here, it does not read an
       external description of what tests to run. Instead, all tests are
       coded into the program, which is written to cover all aspects of
       the C language API. mariadb-client-test
supports the following options:

       â¢
--help
,
-?"
783,4,mariadb-client-test,"mariadb-client-test
supports the following options:

       â¢
--help
,
-? Display a help message and exit. â¢
--basedir=
dir_name
,
-b
dir_name
The base directory for the tests."
783,5,mariadb-client-test,"â¢
--basedir=
dir_name
,
-b
dir_name
The base directory for the tests. â¢
--count=
count
,
-t
count
The number of times to execute the tests. â¢
--database=
db_name
,
-D
db_name
The database to use."
783,6,mariadb-client-test,"â¢
--database=
db_name
,
-D
db_name
The database to use. â¢
--debug[=
debug_options
]
,
-#[
debug_options
]
Write a debugging log if MariaDB is built with debugging
           support. The default
debug_options
value is
           'd:t:o,/tmp/mariadb-client-test.trace'."
783,7,mariadb-client-test,"The default
debug_options
value is
           'd:t:o,/tmp/mariadb-client-test.trace'. â¢
--getopt-ll-test=
option
,
-g
option
Option to use for testing bugs in the getopt library. â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host."
783,8,mariadb-client-test,"â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password."
783,9,mariadb-client-test,"If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line, you
           are prompted for one. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection."
783,10,mariadb-client-test,"â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection. â¢
--server-arg=
arg
,
-A
arg
Argument to send to the embedded server. â¢
--show-tests
,
-T
Show all test names."
783,11,mariadb-client-test,"â¢
--show-tests
,
-T
Show all test names. â¢
--silent
,
-s
Be more silent. â¢
--socket=
path
,
-S
path
The socket file to use when connecting to localhost (which is
           the default host)."
783,12,mariadb-client-test,"â¢
--socket=
path
,
-S
path
The socket file to use when connecting to localhost (which is
           the default host). â¢
--testcase
,
-c
The option is used when called from
mariadb-test-run.pl
, so
           that
mariadb-client-test
may optionally behave in a different
           way than if called manually, for example by skipping some
           tests. Currently, there is no difference in behavior but the
           option is included in order to make this possible."
783,13,mariadb-client-test,"Currently, there is no difference in behavior but the
           option is included in order to make this possible. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
-v
dir_name
,
--vardir=
dir_name
The data directory for tests."
783,14,mariadb-client-test,"â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
-v
dir_name
,
--vardir=
dir_name
The data directory for tests. The default is mariadb-test/var."
784,0,mariadb-client-test,"The
mariadb-client-test
program is used for testing aspects of the
       MariaDB client API that cannot be tested using
mariadb-test
and
       its test language. mariadb-client-test-embedded
is similar but
       used for testing the embedded server. Both programs are run as
       part of the test suite."
784,1,mariadb-client-test,"Both programs are run as
       part of the test suite. The source code for the programs can be found in in tests/mariadb-
       client-test.c in a source distribution. The program serves as a
       good source of examples illustrating how to use various features
       of the client API."
784,2,mariadb-client-test,"The program serves as a
       good source of examples illustrating how to use various features
       of the client API. mariadb-client-test
is used in a test by the same name in the main
       tests suite of
mariadb-test-run.pl
but may also be run directly. Unlike the other programs listed here, it does not read an
       external description of what tests to run."
784,3,mariadb-client-test,"Unlike the other programs listed here, it does not read an
       external description of what tests to run. Instead, all tests are
       coded into the program, which is written to cover all aspects of
       the C language API. mariadb-client-test
supports the following options:

       â¢
--help
,
-?"
784,4,mariadb-client-test,"mariadb-client-test
supports the following options:

       â¢
--help
,
-? Display a help message and exit. â¢
--basedir=
dir_name
,
-b
dir_name
The base directory for the tests."
784,5,mariadb-client-test,"â¢
--basedir=
dir_name
,
-b
dir_name
The base directory for the tests. â¢
--count=
count
,
-t
count
The number of times to execute the tests. â¢
--database=
db_name
,
-D
db_name
The database to use."
784,6,mariadb-client-test,"â¢
--database=
db_name
,
-D
db_name
The database to use. â¢
--debug[=
debug_options
]
,
-#[
debug_options
]
Write a debugging log if MariaDB is built with debugging
           support. The default
debug_options
value is
           'd:t:o,/tmp/mariadb-client-test.trace'."
784,7,mariadb-client-test,"The default
debug_options
value is
           'd:t:o,/tmp/mariadb-client-test.trace'. â¢
--getopt-ll-test=
option
,
-g
option
Option to use for testing bugs in the getopt library. â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host."
784,8,mariadb-client-test,"â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password."
784,9,mariadb-client-test,"If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line, you
           are prompted for one. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection."
784,10,mariadb-client-test,"â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection. â¢
--server-arg=
arg
,
-A
arg
Argument to send to the embedded server. â¢
--show-tests
,
-T
Show all test names."
784,11,mariadb-client-test,"â¢
--show-tests
,
-T
Show all test names. â¢
--silent
,
-s
Be more silent. â¢
--socket=
path
,
-S
path
The socket file to use when connecting to localhost (which is
           the default host)."
784,12,mariadb-client-test,"â¢
--socket=
path
,
-S
path
The socket file to use when connecting to localhost (which is
           the default host). â¢
--testcase
,
-c
The option is used when called from
mariadb-test-run.pl
, so
           that
mariadb-client-test
may optionally behave in a different
           way than if called manually, for example by skipping some
           tests. Currently, there is no difference in behavior but the
           option is included in order to make this possible."
784,13,mariadb-client-test,"Currently, there is no difference in behavior but the
           option is included in order to make this possible. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
-v
dir_name
,
--vardir=
dir_name
The data directory for tests."
784,14,mariadb-client-test,"â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
-v
dir_name
,
--vardir=
dir_name
The data directory for tests. The default is mariadb-test/var."
785,0,mariadb-check,"The
mariadb-check
client performs table maintenance: It checks,
       repairs, optimizes, or analyzes tables. Each table is locked and therefore unavailable to other sessions
       while it is being processed, although for check operations, the
       table is locked with a READ lock only. Table maintenance
       operations can be time-consuming, particularly for large tables."
785,1,mariadb-check,"Table maintenance
       operations can be time-consuming, particularly for large tables. If you use the
--databases
or
--all-databases
option to process
       all tables in one or more databases, an invocation of
mariadb-
check
might take a long time. (This is also true for
mariadb-
upgrade
because that program invokes
mariadb-check
to check all
       tables and repair them if necessary.)
mariadb-check
is similar in function to
myisamchk
, but works
       differently."
785,2,mariadb-check,"(This is also true for
mariadb-
upgrade
because that program invokes
mariadb-check
to check all
       tables and repair them if necessary.)
mariadb-check
is similar in function to
myisamchk
, but works
       differently. The main operational difference is that
mariadb-check
must be used when the
mariadbd
server is running, whereas
myisamchk
should be used when it is not. The benefit of using
mariadb-check
is that you do not have to stop the server to
       perform table maintenance."
785,3,mariadb-check,"The benefit of using
mariadb-check
is that you do not have to stop the server to
       perform table maintenance. mariadb-check
uses the SQL statements CHECK TABLE, REPAIR TABLE,
       ANALYZE TABLE, and OPTIMIZE TABLE in a convenient way for the
       user. It determines which statements to use for the operation you
       want to perform, and then sends the statements to the server to be
       executed."
785,4,mariadb-check,"It determines which statements to use for the operation you
       want to perform, and then sends the statements to the server to be
       executed. The MyISAM storage engine supports all four maintenance
       operations, so
mariadb-check
can be used to perform any of them on
       MyISAM tables. Other storage engines do not necessarily support
       all operations."
785,5,mariadb-check,"Other storage engines do not necessarily support
       all operations. In such cases, an error message is displayed. For
       example, if test.t is a MEMORY table, an attempt to check it
       produces this result:

           shell>
mariadb-check test t
test.t
           note     : The storage engine for the table doesn't support check

       If
mariadb-check
is unable to repair a table, see the MariaDB
       Knowledge Base for manual table repair strategies."
785,6,mariadb-check,"For
       example, if test.t is a MEMORY table, an attempt to check it
       produces this result:

           shell>
mariadb-check test t
test.t
           note     : The storage engine for the table doesn't support check

       If
mariadb-check
is unable to repair a table, see the MariaDB
       Knowledge Base for manual table repair strategies. This will be
       the case, for example, for InnoDB tables, which can be checked
       with CHECK TABLE, but not repaired with REPAIR TABLE. The use of
mariadb-check
with partitioned tables is not supported."
785,7,mariadb-check,"The use of
mariadb-check
with partitioned tables is not supported. Caution
It is best to make a backup of a table before performing a
           table repair operation; under some circumstances the operation
           might cause data loss. Possible causes include but are not
           limited to file system errors."
785,8,mariadb-check,"Possible causes include but are not
           limited to file system errors. There are three general ways to invoke
mariadb-check
:

           shell>
mariadb-check [
options
]
db_name
[
tbl_name
...]
shell>
mariadb-check [
options
] --databases
db_name
... shell>
mariadb-check [
options
] --all-databases
If you do not name any tables following
db_name
or if you use the
--databases
or
--all-databases
option, entire databases are
       checked."
785,9,mariadb-check,"shell>
mariadb-check [
options
] --all-databases
If you do not name any tables following
db_name
or if you use the
--databases
or
--all-databases
option, entire databases are
       checked. mariadb-check
has a special feature compared to other client
       programs. The default behavior of checking tables (
--check
) can be
       changed by renaming the binary."
785,10,mariadb-check,"The default behavior of checking tables (
--check
) can be
       changed by renaming the binary. If you want to have a tool that
       repairs tables by default, you should just make a copy of
mariadb-
check
named
mariadb-repair
, or make a symbolic link to
mariadb-
check
named
mariadb-repair
. If you invoke
mariadb-repair
, it
       repairs tables."
785,11,mariadb-check,"If you invoke
mariadb-repair
, it
       repairs tables. The following names can be used to change
mariadb-check
default
       behavior. ââââââââââââââââââ¬ââââââââââââââââââââââââ
       â
mariadb-repair
â The default option is â
       â                â
--repair
â
       ââââââââââââââââââ¼ââââââââââââââââââââââââ¤
       â
mysqlanalyze
â The default option is â
       â                â
--analyze
â
       ââââââââââââââââââ¼ââââââââââââââââââââââââ¤
       â
mysqloptimize
â The default option is â
       â                â
--optimize
â
       ââââââââââââââââââ´ââââââââââââââââââââââââ
mariadb-check
supports the following options, which can be
       specified on the command line or in the [mariadb-check] and
       [client] option file groups."
785,12,mariadb-check,"ââââââââââââââââââ¬ââââââââââââââââââââââââ
       â
mariadb-repair
â The default option is â
       â                â
--repair
â
       ââââââââââââââââââ¼ââââââââââââââââââââââââ¤
       â
mysqlanalyze
â The default option is â
       â                â
--analyze
â
       ââââââââââââââââââ¼ââââââââââââââââââââââââ¤
       â
mysqloptimize
â The default option is â
       â                â
--optimize
â
       ââââââââââââââââââ´ââââââââââââââââââââââââ
mariadb-check
supports the following options, which can be
       specified on the command line or in the [mariadb-check] and
       [client] option file groups. The
-c
,
-r
,
-a
and
-o
options are
       exclusive to each other. â¢
--help
,
-?"
785,13,mariadb-check,"â¢
--help
,
-? Display a help message and exit. â¢
--all-databases
,
-A
Check all tables in all databases."
785,14,mariadb-check,"â¢
--all-databases
,
-A
Check all tables in all databases. This is the same as using
           the
--databases
option and naming all the databases on the
           command line. â¢
--all-in-1
,
-1
Instead of issuing a statement for each table, execute a
           single statement for each database that names all the tables
           from that database to be processed."
785,15,mariadb-check,"â¢
--all-in-1
,
-1
Instead of issuing a statement for each table, execute a
           single statement for each database that names all the tables
           from that database to be processed. â¢
--analyze
,
-a
Analyze the tables. â¢
--auto-repair
If a checked table is corrupted, automatically fix it."
785,16,mariadb-check,"â¢
--auto-repair
If a checked table is corrupted, automatically fix it. Any
           necessary repairs are done after all tables have been checked. â¢
--character-sets-dir=
path
The directory where character sets are installed."
785,17,mariadb-check,"â¢
--character-sets-dir=
path
The directory where character sets are installed. â¢
--check
,
-c
Check the tables for errors. This is the default operation."
785,18,mariadb-check,"This is the default operation. â¢
--check-only-changed
,
-C
Check only tables that have changed since the last check or
           that have not been closed properly. â¢
--check-upgrade
,
-g
Invoke CHECK TABLE with the FOR UPGRADE option to check tables
           for incompatibilities with the current version of the server."
785,19,mariadb-check,"â¢
--check-upgrade
,
-g
Invoke CHECK TABLE with the FOR UPGRADE option to check tables
           for incompatibilities with the current version of the server. This option automatically enables the
--fix-db-names
and
--fix-table-names
options. â¢
--compress
Compress all information sent between the client and the
           server if both support compression."
785,20,mariadb-check,"â¢
--compress
Compress all information sent between the client and the
           server if both support compression. â¢
--databases
,
-B
Process all tables in the named databases. Normally,
mariadb-
check
treats the first name argument on the command line as a
           database name and following names as table names."
785,21,mariadb-check,"Normally,
mariadb-
check
treats the first name argument on the command line as a
           database name and following names as table names. With this
           option, it treats all name arguments as database names. â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log."
785,22,mariadb-check,"â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log. A typical
debug_options
string is
           'd:t:o,
file_name
'. The default is 'd:t:o'."
785,23,mariadb-check,"The default is 'd:t:o'. â¢
--debug-check
Print some debugging information when the program exits. â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits."
785,24,mariadb-check,"â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--default-auth=
name
Default authentication client-side plugin to use. â¢
--default-character-set=
charset_name
Use
charset_name
as the default character set."
785,25,mariadb-check,"â¢
--default-character-set=
charset_name
Use
charset_name
as the default character set. â¢
--defaults-extra-file=
filename
Set
filename
as the file to read default options from after
           the global defaults files has been read. Must be given as
           first option."
785,26,mariadb-check,"Must be given as
           first option. â¢
--defaults-file=
filename
Set
filename
as the file to read default options from,
           override global defaults files. Must be given as first
           option."
785,27,mariadb-check,"Must be given as first
           option. â¢
--extended
,
-e
If you are using this option to check tables, it ensures that
           they are 100% consistent but takes a long time. If you are using this option to repair tables, it will force
           using the old, slow, repair with keycache method, instead of
           the much faster repair by sorting."
785,28,mariadb-check,"If you are using this option to repair tables, it will force
           using the old, slow, repair with keycache method, instead of
           the much faster repair by sorting. â¢
--fast
,
-F
Check only tables that have not been closed properly. â¢
--fix-db-names
Convert database names to the format used since MySQL 5.1."
785,29,mariadb-check,"â¢
--fix-db-names
Convert database names to the format used since MySQL 5.1. Only database names that contain special characters are
           affected. â¢
--fix-table-names
Convert table names (including views) to the format used since
           MySQL 5.1."
785,30,mariadb-check,"â¢
--fix-table-names
Convert table names (including views) to the format used since
           MySQL 5.1. Only table names that contain special characters
           are affected. â¢
--flush
,

           Flush each table after check."
785,31,mariadb-check,"â¢
--flush
,

           Flush each table after check. This is useful if you don't want
           to have the checked tables take up space in the caches after
           the check. â¢
--force
,
-f
Continue even if an SQL error occurs."
785,32,mariadb-check,"â¢
--force
,
-f
Continue even if an SQL error occurs. â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host. â¢
--medium-check
,
-m
Do a check that is faster than an
--extended
operation."
785,33,mariadb-check,"â¢
--medium-check
,
-m
Do a check that is faster than an
--extended
operation. This
           finds only 99.99% of all errors, which should be good enough
           in most cases. â¢
--no-defaults
Do not read default options from any option file."
785,34,mariadb-check,"â¢
--no-defaults
Do not read default options from any option file. This must be
           given as the first argument. â¢
--optimize
,
-o
Optimize the tables."
785,35,mariadb-check,"â¢
--optimize
,
-o
Optimize the tables. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password."
785,36,mariadb-check,"If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-check
prompts for one. Specifying a password on the command line should be considered
           insecure."
785,37,mariadb-check,"Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line. â¢
--persistent
,
-Z
Used with ANALYZE TABLE to append the option PERSISENT FOR
           ALL."
785,38,mariadb-check,"â¢
--persistent
,
-Z
Used with ANALYZE TABLE to append the option PERSISENT FOR
           ALL. â¢
--pipe
,
-W
On Windows, connect to the server via a named pipe. This
           option applies only if the server supports named-pipe
           connections."
785,39,mariadb-check,"This
           option applies only if the server supports named-pipe
           connections. â¢
--plugin-dir=
name
Directory for client-side plugins. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection."
785,40,mariadb-check,"â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection. Forces
           --protocol=tcp when specified on the command line without
           other connection properties. â¢
--print-defaults
Print the program argument list and exit."
785,41,mariadb-check,"â¢
--print-defaults
Print the program argument list and exit. This must be given
           as the first argument. â¢
--process-tables
Perform the requested operation on tables."
785,42,mariadb-check,"â¢
--process-tables
Perform the requested operation on tables. Defaults to on; use
--skip-process-tables
to disable. â¢
--process-views=
val
Perform the requested operation (only CHECK VIEW or REPAIR
           VIEW)."
785,43,mariadb-check,"â¢
--process-views=
val
Perform the requested operation (only CHECK VIEW or REPAIR
           VIEW). Possible values are NO, YES (correct the checksum, if
           necessary, add the mariadb-version field), UPGRADE_FROM_MYSQL
           (same as YES and toggle the algorithm MERGE<->TEMPTABLE. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server."
785,44,mariadb-check,"â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--quick
,
-q
If you are using this option to check tables, it prevents the
           check from scanning the rows to check for incorrect links."
785,45,mariadb-check,"â¢
--quick
,
-q
If you are using this option to check tables, it prevents the
           check from scanning the rows to check for incorrect links. This is the fastest check method. If you are using this option to repair tables, it tries to
           repair only the index tree."
785,46,mariadb-check,"If you are using this option to repair tables, it tries to
           repair only the index tree. This is the fastest repair method. â¢
--repair
,
-r
Perform a repair that can fix almost anything except unique
           keys that are not unique."
785,47,mariadb-check,"â¢
--repair
,
-r
Perform a repair that can fix almost anything except unique
           keys that are not unique. â¢
--silent
,
-s
Silent mode. Print only error messages."
785,48,mariadb-check,"Print only error messages. â¢
--skip-database=
db_name
Don't process the database (case-sensitive) specified as
           argument. â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use."
785,49,mariadb-check,"â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe. â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags)."
785,50,mariadb-check,"â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags). Disable with
--skip-ssl
. â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
)."
785,51,mariadb-check,"â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
)."
785,52,mariadb-check,"â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
). â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
)."
785,53,mariadb-check,"â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
)."
785,54,mariadb-check,"â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
). â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting. This option is disabled by default."
785,55,mariadb-check,"This option is disabled by default. â¢
--tables
Override the
--databases
or
-B
option. All name arguments
           following the option are regarded as table names."
785,56,mariadb-check,"All name arguments
           following the option are regarded as table names. â¢
--use-frm
For repair operations on MyISAM tables, get the table
           structure from the .frm file so that the table can be repaired
           even if the .MYI header is corrupted. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server."
785,57,mariadb-check,"â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
--verbose
,
-v
Verbose mode. Print information about the various stages of
           program operation."
785,58,mariadb-check,"Print information about the various stages of
           program operation. Using one
--verbose
option will give you
           more information about what mariadb-check is doing. Using two
--verbose
options will also give you connection
           information."
785,59,mariadb-check,"Using two
--verbose
options will also give you connection
           information. Using it 3 times will print out all CHECK, RENAME and ALTER
           TABLE during the check phase. â¢
--version
,
-V
Display version information and exit."
785,60,mariadb-check,"â¢
--version
,
-V
Display version information and exit. â¢
--write-binlog
This option is enabled by default, so that ANALYZE TABLE,
           OPTIMIZE TABLE, and REPAIR TABLE statements generated by
mariadb-check
are written to the binary log. Use
--skip-write-binlog
to cause NO_WRITE_TO_BINLOG to be added to
           the statements so that they are not logged."
785,61,mariadb-check,"â¢
--write-binlog
This option is enabled by default, so that ANALYZE TABLE,
           OPTIMIZE TABLE, and REPAIR TABLE statements generated by
mariadb-check
are written to the binary log. Use
--skip-write-binlog
to cause NO_WRITE_TO_BINLOG to be added to
           the statements so that they are not logged. Use the
--skip-write-binlog
when these statements should not be sent
           to replication slaves or run when using the binary logs for
           recovery from backup."
786,0,mariadb-conv,"mariadb-conv
is a character set conversion utility for MariaDB. mariadb-conv
supports the following options. â¢
--from=
name
,
-f
name
Specifies the encoding of the input."
786,1,mariadb-conv,"â¢
--from=
name
,
-f
name
Specifies the encoding of the input. â¢
--to=
name
,
-t
name
Specifies the encoding of the output. â¢
--continue
,
-c
Silently ignore conversion errors."
786,2,mariadb-conv,"â¢
--to=
name
,
-t
name
Specifies the encoding of the output. â¢
--continue
,
-c
Silently ignore conversion errors. â¢
--delimiter=
name
,

           Treat the specified characters as delimiters."
787,0,mariadb-convert-table-format,"mariadb_convert_table_format
converts the tables in a database to
       use a particular storage engine (MyISAM by default). mariadb-
convert-table-format
is written in Perl and requires that the DBI
       and DBD::MariaDB Perl modules be installed (see Section 2.15,
       âPerl Installation Notesâ). Invoke
mariadb-convert-table-format
like this:

           shell>
mariadb-convert-table-format [
options
]
db_name
The
db_name
argument indicates the database containing the tables
       to be converted."
787,1,mariadb-convert-table-format,"Invoke
mariadb-convert-table-format
like this:

           shell>
mariadb-convert-table-format [
options
]
db_name
The
db_name
argument indicates the database containing the tables
       to be converted. mariadb-convert-table-format
supports the options described in the
       following list. â¢
--help
Display a help message and exit."
787,2,mariadb-convert-table-format,"â¢
--help
Display a help message and exit. â¢
--force
Continue even if errors occur. â¢
--host=
host_name
Connect to the MariaDB server on the given host."
787,3,mariadb-convert-table-format,"â¢
--host=
host_name
Connect to the MariaDB server on the given host. â¢
--password=
password
The password to use when connecting to the server. Note that
           the password value is not optional for this option, unlike for
           other MariaDB programs."
787,4,mariadb-convert-table-format,"Note that
           the password value is not optional for this option, unlike for
           other MariaDB programs. Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line."
787,5,mariadb-convert-table-format,"You can use an option file to avoid giving the
           password on the command line. â¢
--port=
port_num
The TCP/IP port number to use for the connection. â¢
--socket=
path
For connections to localhost, the Unix socket file to use."
787,6,mariadb-convert-table-format,"â¢
--socket=
path
For connections to localhost, the Unix socket file to use. â¢
--type=
engine_name
Specify the storage engine that the tables should be converted
           to use. The default is MyISAM if this option is not given."
787,7,mariadb-convert-table-format,"The default is MyISAM if this option is not given. â¢
--user=
user_name
The MariaDB user name to use when connecting to the server. â¢
--verbose
Verbose mode."
787,8,mariadb-convert-table-format,"â¢
--verbose
Verbose mode. Print more information about what the program
           does. â¢
--version
Display version information and exit."
788,0,mariadb-binlog,"The server's binary log consists of files containing âeventsâ that
       describe modifications to database contents. The server writes
       these files in binary format. To display their contents in text
       format, use the
mariadb-binlog
utility."
788,1,mariadb-binlog,"To display their contents in text
       format, use the
mariadb-binlog
utility. You can also use
mariadb-
binlog
to display the contents of relay log files written by a
       slave server in a replication setup because relay logs have the
       same format as binary logs. Invoke
mariadb-binlog
like this:

           shell>
mariadb-binlog [
options
]
log_file
..."
788,2,mariadb-binlog,"Invoke
mariadb-binlog
like this:

           shell>
mariadb-binlog [
options
]
log_file
... For example, to display the contents of the binary log file named
       binlog.000003, use this command:

           shell>
mariadb-binlog binlog.0000003
The output includes events contained in binlog.000003. For
       statement-based logging, event information includes the SQL
       statement, the ID of the server on which it was executed, the
       timestamp when the statement was executed, how much time it took,
       and so forth."
788,3,mariadb-binlog,"For
       statement-based logging, event information includes the SQL
       statement, the ID of the server on which it was executed, the
       timestamp when the statement was executed, how much time it took,
       and so forth. For row-based logging, the event indicates a row
       change rather than an SQL statement. Events are preceded by header comments that provide additional
       information."
788,4,mariadb-binlog,"Events are preceded by header comments that provide additional
       information. For example:

           # at 141
           #100309  9:28:36 server id 123  end_log_pos 245
             Query thread_id=3350  exec_time=11  error_code=0

       In the first line, the number following at indicates the starting
       position of the event in the binary log file. The second line starts with a date and time indicating when the
       statement started on the server where the event originated."
788,5,mariadb-binlog,"The second line starts with a date and time indicating when the
       statement started on the server where the event originated. For
       replication, this timestamp is propagated to slave servers. server id is the server_id value of the server where the event
       originated."
788,6,mariadb-binlog,"server id is the server_id value of the server where the event
       originated. end_log_pos indicates where the next event starts
       (that is, it is the end position of the current event + 1). thread_id indicates which thread executed the event."
788,7,mariadb-binlog,"thread_id indicates which thread executed the event. exec_time is
       the time spent executing the event, on a master server. On a
       slave, it is the difference of the end execution time on the slave
       minus the beginning execution time on the master."
788,8,mariadb-binlog,"On a
       slave, it is the difference of the end execution time on the slave
       minus the beginning execution time on the master. The difference
       serves as an indicator of how much replication lags behind the
       master. error_code indicates the result from executing the event."
788,9,mariadb-binlog,"error_code indicates the result from executing the event. Zero means that no error occurred. The output from
mariadb-binlog
can be re-executed (for example, by
       using it as input to
mariadb
) to redo the statements in the log."
788,10,mariadb-binlog,"The output from
mariadb-binlog
can be re-executed (for example, by
       using it as input to
mariadb
) to redo the statements in the log. This is useful for recovery operations after a server crash. For
       other usage examples, see the discussion later in this section."
788,11,mariadb-binlog,"For
       other usage examples, see the discussion later in this section. Normally, you use
mariadb-binlog
to read binary log files directly
       and apply them to the local MariaDB server. It is also possible to
       read binary logs from a remote server by using the
--read-from-remote-server
option."
788,12,mariadb-binlog,"It is also possible to
       read binary logs from a remote server by using the
--read-from-remote-server
option. To read remote binary logs, the
       connection parameter options can be given to indicate how to
       connect to the server. These options are
--host
,
--password
,
--port
,
--protocol
,
--socket
, and
--user
; they are ignored except
       when you also use the
--read-from-remote-server
option."
788,13,mariadb-binlog,"These options are
--host
,
--password
,
--port
,
--protocol
,
--socket
, and
--user
; they are ignored except
       when you also use the
--read-from-remote-server
option. mariadb-binlog
supports the following options, which can be
       specified on the command line or in the [mariadb-binlog] and
       [client] option file groups. â¢
--help
,
-?"
788,14,mariadb-binlog,"â¢
--help
,
-? Display a help message and exit. â¢
--base64-output=
value
This option determines when events should be displayed encoded
           as base-64 strings using BINLOG statements."
788,15,mariadb-binlog,"â¢
--base64-output=
value
This option determines when events should be displayed encoded
           as base-64 strings using BINLOG statements. The option has
           these allowable values (not case sensitive):

           â¢   AUTO (""automatic"") or UNSPEC (""unspecified"") displays
               BINLOG statements automatically when necessary (that is,
               for format description events and row events). This is the
               default if no
--base64-output
option is given."
788,16,mariadb-binlog,"This is the
               default if no
--base64-output
option is given. Note
Automatic BINLOG display is the only safe behavior if
                   you intend to use the output of
mariadb-binlog
to
                   re-execute binary log file contents. The other option
                   values are intended only for debugging or testing
                   purposes because they may produce output that does not
                   include all events in executable form."
788,17,mariadb-binlog,"The other option
                   values are intended only for debugging or testing
                   purposes because they may produce output that does not
                   include all events in executable form. â¢   NEVER causes BINLOG statements not to be displayed. mariadb-binlog
exits with an error if a row event is found
               that must be displayed using BINLOG."
788,18,mariadb-binlog,"mariadb-binlog
exits with an error if a row event is found
               that must be displayed using BINLOG. â¢   DECODE-ROWS specifies to
mariadb-binlog
that you intend
               for row events to be decoded and displayed as commented
               SQL statements by also specifying the
--verbose
option. Like NEVER, DECODE-ROWS suppresses display of BINLOG
               statements, but unlike NEVER, it does not exit with an
               error if a row event is found."
788,19,mariadb-binlog,"Like NEVER, DECODE-ROWS suppresses display of BINLOG
               statements, but unlike NEVER, it does not exit with an
               error if a row event is found. The
--base64-output
can be given as
--base64-output
or
--skip-base64-output
(with the sense of AUTO or NEVER). For examples that show the effect of
--base64-output
and
--verbose
on row event output, see the section called
               âMARIADB-BINLOG ROW EVENT DISPLAYâ."
788,20,mariadb-binlog,"For examples that show the effect of
--base64-output
and
--verbose
on row event output, see the section called
               âMARIADB-BINLOG ROW EVENT DISPLAYâ. â¢
--binlog-row-event-max-size=
path
The directory where character sets are installed. â¢
--character-sets-dir=
path
The directory where character sets are installed."
788,21,mariadb-binlog,"â¢
--character-sets-dir=
path
The directory where character sets are installed. â¢
--database=
db_name
,
-d
db_name
This option causes
mariadb-binlog
to output entries from the
           binary log (local log only) that occur while
db_name
has been
           selected as the default database by USE. The
--database
option for
mariadb-binlog
is similar to the
--binlog-do-db
option for
mariadbd
, but can be used to specify
           only one database."
788,22,mariadb-binlog,"The
--database
option for
mariadb-binlog
is similar to the
--binlog-do-db
option for
mariadbd
, but can be used to specify
           only one database. If
--database
is given multiple times, only
           the last instance is used. The effects of this option depend on whether the
           statement-based or row-based logging format is in use, in the
           same way that the effects of
--binlog-do-db
depend on whether
           statement-based or row-based logging is in use."
788,23,mariadb-binlog,"The effects of this option depend on whether the
           statement-based or row-based logging format is in use, in the
           same way that the effects of
--binlog-do-db
depend on whether
           statement-based or row-based logging is in use. Statement-based logging
. The
--database
option works as
           follows:

           â¢   While
db_name
is the default database, statements are
               output whether they modify tables in
db_name
or a
               different database."
788,24,mariadb-binlog,"The
--database
option works as
           follows:

           â¢   While
db_name
is the default database, statements are
               output whether they modify tables in
db_name
or a
               different database. â¢   Unless
db_name
is selected as the default database,
               statements are not output, even if they modify tables in
db_name
. â¢   There is an exception for CREATE DATABASE, ALTER DATABASE,
               and DROP DATABASE."
788,25,mariadb-binlog,"â¢   There is an exception for CREATE DATABASE, ALTER DATABASE,
               and DROP DATABASE. The database being
created, altered, or
dropped
is considered to be the default database when
               determining whether to output the statement. Suppose that the binary log was created by executing these
               statements using statement-based-logging:

                   INSERT INTO test.t1 (i) VALUES(100);
                   INSERT INTO db2.t2 (j)  VALUES(200);
                   USE test;
                   INSERT INTO test.t1 (i) VALUES(101);
                   INSERT INTO t1 (i)      VALUES(102);
                   INSERT INTO db2.t2 (j)  VALUES(201);
                   USE db2;
                   INSERT INTO test.t1 (i) VALUES(103);
                   INSERT INTO db2.t2 (j)  VALUES(202);
                   INSERT INTO t2 (j)      VALUES(203);
mariadb-binlog --database=test
does not output the first
               two INSERT statements because there is no default
               database."
788,26,mariadb-binlog,"Suppose that the binary log was created by executing these
               statements using statement-based-logging:

                   INSERT INTO test.t1 (i) VALUES(100);
                   INSERT INTO db2.t2 (j)  VALUES(200);
                   USE test;
                   INSERT INTO test.t1 (i) VALUES(101);
                   INSERT INTO t1 (i)      VALUES(102);
                   INSERT INTO db2.t2 (j)  VALUES(201);
                   USE db2;
                   INSERT INTO test.t1 (i) VALUES(103);
                   INSERT INTO db2.t2 (j)  VALUES(202);
                   INSERT INTO t2 (j)      VALUES(203);
mariadb-binlog --database=test
does not output the first
               two INSERT statements because there is no default
               database. It outputs the three INSERT statements following
               USE test, but not the three INSERT statements following
               USE db2. mariadb-binlog --database=db2
does not output the first
               two INSERT statements because there is no default
               database."
788,27,mariadb-binlog,"mariadb-binlog --database=db2
does not output the first
               two INSERT statements because there is no default
               database. It does not output the three INSERT statements
               following USE test, but does output the three INSERT
               statements following USE db2. Row-based logging
."
788,28,mariadb-binlog,"Row-based logging
. mariadb-binlog
outputs only entries
               that change tables belonging to
db_name
. The default
               database has no effect on this."
788,29,mariadb-binlog,"The default
               database has no effect on this. Suppose that the binary
               log just described was created using row-based logging
               rather than statement-based logging. mariadb-binlog
--database=test
outputs only those entries that modify t1
               in the test database, regardless of whether USE was issued
               or what the default database is."
788,30,mariadb-binlog,"mariadb-binlog
--database=test
outputs only those entries that modify t1
               in the test database, regardless of whether USE was issued
               or what the default database is. If a server is running
               with binlog_format set to MIXED and you want it to be
               possible to use
mariadb-binlog
with the
--database
option,
               you must ensure that tables that are modified are in the
               database selected by USE. (In particular, no
               cross-database updates should be used.)
Note
This option did not work correctly for
mariadb-binlog
with row-based logging prior to MySQL 5.1.37."
788,31,mariadb-binlog,"(In particular, no
               cross-database updates should be used.)
Note
This option did not work correctly for
mariadb-binlog
with row-based logging prior to MySQL 5.1.37. â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log. A typical
debug_options
string is
           'd:t:o,
file_name
'."
788,32,mariadb-binlog,"A typical
debug_options
string is
           'd:t:o,
file_name
'. The default is 'd:t:o,/tmp/mariadb-
           binlog.trace'. â¢
--debug-check
Print some debugging information when the program exits."
788,33,mariadb-binlog,"â¢
--debug-check
Print some debugging information when the program exits. â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--defaults-extra-file=
name
Read this file after the global files are read."
788,34,mariadb-binlog,"â¢
--defaults-extra-file=
name
Read this file after the global files are read. â¢
--defaults-file=
name
Only read default options from the given file. â¢
--default-auth=
name
Default authentication client-side plugin to use."
788,35,mariadb-binlog,"â¢
--default-auth=
name
Default authentication client-side plugin to use. â¢
--disable-log-bin
,
-D
Disable binary logging. This is useful for avoiding an endless
           loop if you use the
--to-last-log
option and are sending the
           output to the same MariaDB server."
788,36,mariadb-binlog,"This is useful for avoiding an endless
           loop if you use the
--to-last-log
option and are sending the
           output to the same MariaDB server. This option also is useful
           when restoring after a crash to avoid duplication of the
           statements you have logged. This option requires that you have the SUPER privilege."
788,37,mariadb-binlog,"This option requires that you have the SUPER privilege. It
           causes
mariadb-binlog
to include a SET sql_log_bin = 0
           statement in its output to disable binary logging of the
           remaining output. The SET statement is ineffective unless you
           have the SUPER privilege."
788,38,mariadb-binlog,"The SET statement is ineffective unless you
           have the SUPER privilege. â¢
--flashback
,
-B
Support flashback mode. â¢
--force-if-open
Force if binlog was not closed properly."
788,39,mariadb-binlog,"â¢
--force-if-open
Force if binlog was not closed properly. Defaults to on; use
--skip-force-if-open
to disable. â¢
--force-read
,
-f
With this option, if
mariadb-binlog
reads a binary log event
           that it does not recognize, it prints a warning, ignores the
           event, and continues."
788,40,mariadb-binlog,"â¢
--force-read
,
-f
With this option, if
mariadb-binlog
reads a binary log event
           that it does not recognize, it prints a warning, ignores the
           event, and continues. Without this option,
mariadb-binlog
stops if it reads such an event. â¢
--hexdump
,
-H
Display a hex dump of the log in comments, as described in the
           section called âMARIADB-BINLOG HEX DUMP FORMATâ."
788,41,mariadb-binlog,"â¢
--hexdump
,
-H
Display a hex dump of the log in comments, as described in the
           section called âMARIADB-BINLOG HEX DUMP FORMATâ. The hex
           output can be helpful for replication debugging. â¢
--host=
host_name
,
-h
host_name
Get the binary log from the MariaDB server on the given host."
788,42,mariadb-binlog,"â¢
--host=
host_name
,
-h
host_name
Get the binary log from the MariaDB server on the given host. â¢
--local-load=
path
,
-l
path
Prepare local temporary files for LOAD DATA INFILE in the
           specified directory. â¢
--no-defaults
Don't read default options from any option file."
788,43,mariadb-binlog,"â¢
--no-defaults
Don't read default options from any option file. â¢
--offset=
N
,
-o
N
Skip the first
N
entries in the log. â¢
--open-files-limit=
NUM
Sets the open_files_limit variable, which is used to reserve
           file descriptors for
mariadb-binlog
."
788,44,mariadb-binlog,"â¢
--open-files-limit=
NUM
Sets the open_files_limit variable, which is used to reserve
           file descriptors for
mariadb-binlog
. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password."
788,45,mariadb-binlog,"If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-binlog
prompts for one. Specifying a password on the command line should be considered
           insecure."
788,46,mariadb-binlog,"Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line. â¢
--plugin-dir=
dir_name
Directory for client-side plugins."
788,47,mariadb-binlog,"â¢
--plugin-dir=
dir_name
Directory for client-side plugins. â¢
--print-defaults
Print the program argument list from all option files and
           exit. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for connecting to a remote
           server, or
0
for default to, in order of preference,
my.cnf
,
$MYSQL_TCP_PORT
,
/etc/services
, built-in default (3306)."
788,48,mariadb-binlog,"â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for connecting to a remote
           server, or
0
for default to, in order of preference,
my.cnf
,
$MYSQL_TCP_PORT
,
/etc/services
, built-in default (3306). Forces --protocol=tcp when specified on the command line
           without other connection properties. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server."
788,49,mariadb-binlog,"â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--raw
Requires
-R
."
788,50,mariadb-binlog,"â¢
--raw
Requires
-R
. Output raw binlog data instead of SQL statements. Output files named after server logs."
788,51,mariadb-binlog,"Output files named after server logs. â¢
--read-from-remote-server
,
-R
Read the binary log from a MariaDB server rather than reading
           a local log file. Any connection parameter options are ignored
           unless this option is given as well."
788,52,mariadb-binlog,"Any connection parameter options are ignored
           unless this option is given as well. These options are
--host
,
--password
,
--port
,
--protocol
,
--socket
, and
--user
. This option requires that the remote server be running."
788,53,mariadb-binlog,"This option requires that the remote server be running. It
           works only for binary log files on the remote server, not
           relay log files. â¢
--result-file=
name
,
-r
name
Direct output to the given file."
788,54,mariadb-binlog,"â¢
--result-file=
name
,
-r
name
Direct output to the given file. With --raw this is a prefix
           for the file names. â¢
--rewrite-db=
name
,
-r
name
Updates to a database with a different name than the original."
788,55,mariadb-binlog,"â¢
--rewrite-db=
name
,
-r
name
Updates to a database with a different name than the original. Example:
rewrite-db='from->to'
. For events that are binlogged
           as statements, rewriting the database constitutes changing a
           statement's default database from
db1
to
db2
."
788,56,mariadb-binlog,"For events that are binlogged
           as statements, rewriting the database constitutes changing a
           statement's default database from
db1
to
db2
. There is no
           statement analysis or rewrite of any kind, that is, if one
           specifies
""db1.tbl""
in the statement explicitly, that
           occurrence won't be changed to
""db2.tbl""
. Row-based events are
           rewritten correctly to use the new database name."
788,57,mariadb-binlog,"Row-based events are
           rewritten correctly to use the new database name. Filtering
           (e.g. with
--database=name
) happens after the database
           rewrites have been performed."
788,58,mariadb-binlog,"with
--database=name
) happens after the database
           rewrites have been performed. If you use this option on the
           command line and
"">""
has a special meaning to your command
           interpreter, quote the value (e.g. --rewrite-
db=""oldname->newname""
."
788,59,mariadb-binlog,"--rewrite-
db=""oldname->newname""
. â¢
--server-id=
id
Display only those events created by the server having the
           given server ID. â¢
--set-charset=
charset_name
Add a SET NAMES
charset_name
statement to the output to
           specify the character set to be used for processing log files."
788,60,mariadb-binlog,"â¢
--set-charset=
charset_name
Add a SET NAMES
charset_name
statement to the output to
           specify the character set to be used for processing log files. â¢
--short-form
,
-s
Display only the statements contained in the log, no extra
           info and no row-based events. This is for testing only, and
           should not be used in production systems."
788,61,mariadb-binlog,"This is for testing only, and
           should not be used in production systems. If you want to
           suppress base64-output, consider using
--base64-output=never
instead. â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use."
788,62,mariadb-binlog,"â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe. â¢
--start-datetime=
datetime
Start reading the binary log at the first event having a
           timestamp equal to or later than the
datetime
argument."
788,63,mariadb-binlog,"â¢
--start-datetime=
datetime
Start reading the binary log at the first event having a
           timestamp equal to or later than the
datetime
argument. The
datetime
value is relative to the local time zone on the
           machine where you run
mariadb-binlog
. The value should be in a
           format accepted for the DATETIME or TIMESTAMP data types."
788,64,mariadb-binlog,"The value should be in a
           format accepted for the DATETIME or TIMESTAMP data types. For
           example:

               shell>
mariadb-binlog --start-datetime=""2014-12-25 11:25:56"" binlog.000003
This option is useful for point-in-time recovery. â¢
--start-position=
N
,
-j
N
Start reading the binary log at
N
."
788,65,mariadb-binlog,"â¢
--start-position=
N
,
-j
N
Start reading the binary log at
N
. Type can either be a
           positive integer or a GTID list. When using a positive
           integer, the value only applies to the first binlog passed on
           the command line, and the first event that has a position
           equal to or greater than
N
is printed."
788,66,mariadb-binlog,"When using a positive
           integer, the value only applies to the first binlog passed on
           the command line, and the first event that has a position
           equal to or greater than
N
is printed. In GTID mode, multiple
           GTIDs can be passed as a comma separated list, where each must
           have a unique domain id. The list represents the gtid binlog
           state that the client (another ""replica"" server) is aware of."
788,67,mariadb-binlog,"The list represents the gtid binlog
           state that the client (another ""replica"" server) is aware of. Therefore, each GTID is exclusive; only events after a given
           sequence number will be printed to allow users to receive
           events after their current state. This option is useful for point-in-time recovery."
788,68,mariadb-binlog,"This option is useful for point-in-time recovery. â¢
--gtid-strict-mode
Process binlog according to gtid-strict-mode specification. The start, stop positions are verified to satisfy start < stop
comparison condition."
788,69,mariadb-binlog,"The start, stop positions are verified to satisfy start < stop
comparison condition. Sequence numbers of any gtid domain must
comprise monotically growing sequence. â¢   --stop-datetime=
datetime
Stop reading the binary log at the first event having a
           timestamp equal to or later than the
datetime
argument."
788,70,mariadb-binlog,"â¢   --stop-datetime=
datetime
Stop reading the binary log at the first event having a
           timestamp equal to or later than the
datetime
argument. This
           option is useful for point-in-time recovery. See the
           description of the
--start-datetime
option for information
           about the
datetime
value."
788,71,mariadb-binlog,"See the
           description of the
--start-datetime
option for information
           about the
datetime
value. This option is useful for point-in-time recovery. â¢
--stop-never
Wait for more data from the server instead of stopping at the
           end of the last log."
788,72,mariadb-binlog,"â¢
--stop-never
Wait for more data from the server instead of stopping at the
           end of the last log. Implies
--to-last-log
. â¢
--stop-never-slave-server-id
The slave server_id used for
--read-from-remote-server --stop-
never
."
788,73,mariadb-binlog,"â¢
--stop-never-slave-server-id
The slave server_id used for
--read-from-remote-server --stop-
never
. â¢
--stop-position=
N
Stop reading the binary log at the first event having a
           position equal to or greater than
N
. Type can either be a
           positive integer or a GTID list."
788,74,mariadb-binlog,"Type can either be a
           positive integer or a GTID list. When using a positive
           integer, the value only applies to the last log file named on
           the command line. When in GTID mode, multiple GTIDs can be
           passed as a comma separated list, where each must have a
           unique domain id."
788,75,mariadb-binlog,"When in GTID mode, multiple GTIDs can be
           passed as a comma separated list, where each must have a
           unique domain id. Each GTID is inclusive; only events up to
           the given sequence numbers are printed. This option is useful for point-in-time recovery."
788,76,mariadb-binlog,"This option is useful for point-in-time recovery. â¢
--table
,
-T
List entries for just this table (local log only). â¢
--to-last-log
,
-t
Do not stop at the end of the requested binary log from a
           MariaDB server, but rather continue printing until the end of
           the last binary log."
788,77,mariadb-binlog,"â¢
--to-last-log
,
-t
Do not stop at the end of the requested binary log from a
           MariaDB server, but rather continue printing until the end of
           the last binary log. If you send the output to the same
           MariaDB server, this may lead to an endless loop, so this
           option requires
--read-from-remote-server
. â¢
--user=
user_name
,
-u
user_name
The MariaDB username to use when connecting to a remote
           server."
788,78,mariadb-binlog,"â¢
--user=
user_name
,
-u
user_name
The MariaDB username to use when connecting to a remote
           server. â¢
--verbose
,
-v
Reconstruct row events and display them as commented SQL
           statements. If this option is given twice, the output includes
           comments to indicate column data types and some metadata."
788,79,mariadb-binlog,"If this option is given twice, the output includes
           comments to indicate column data types and some metadata. If
           this option is given three times, the output includes
           diagnostic warnings about event integrity before program exit. For examples that show the effect of
--base64-output
and
--verbose
on row event output, see the section called
           âMARIADB-BINLOG ROW EVENT DISPLAYâ."
788,80,mariadb-binlog,"For examples that show the effect of
--base64-output
and
--verbose
on row event output, see the section called
           âMARIADB-BINLOG ROW EVENT DISPLAYâ. â¢
--version
,
-V
Display version information and exit. You can also set the following variable by using
--
var_name
=
value
syntax:

       â¢   open_files_limit

           Specify the number of open file descriptors to reserve."
788,81,mariadb-binlog,"You can also set the following variable by using
--
var_name
=
value
syntax:

       â¢   open_files_limit

           Specify the number of open file descriptors to reserve. You can pipe the output of
mariadb-binlog
into the
mariadb
client
       to execute the events contained in the binary log. This technique
       is used to recover from a crash when you have an old backup."
788,82,mariadb-binlog,"This technique
       is used to recover from a crash when you have an old backup. For
       example:

           shell>
mariadb-binlog binlog.000001 | mariadb -u root -p
Or:

           shell>
mariadb-binlog binlog.[0-9]* | mariadb -u root -p
You can also redirect the output of
mariadb-binlog
to a text file
       instead, if you need to modify the statement log first (for
       example, to remove statements that you do not want to execute for
       some reason). After editing the file, execute the statements that
       it contains by using it as input to the
mariadb
program:

           shell>
mariadb-binlog binlog.000001 > tmpfile
shell> ..."
788,83,mariadb-binlog,"After editing the file, execute the statements that
       it contains by using it as input to the
mariadb
program:

           shell>
mariadb-binlog binlog.000001 > tmpfile
shell> ... edit tmpfile
... shell>
mariadb -u root -p < tmpfile
When
mariadb-binlog
is invoked with the
--start-position
option,
       it displays only those events with an offset in the binary log
       greater than or equal to a given position (the given position must
       match the start of one event)."
788,84,mariadb-binlog,"shell>
mariadb -u root -p < tmpfile
When
mariadb-binlog
is invoked with the
--start-position
option,
       it displays only those events with an offset in the binary log
       greater than or equal to a given position (the given position must
       match the start of one event). It also has options to stop and
       start when it sees an event with a given date and time. This
       enables you to perform point-in-time recovery using the
--stop-datetime
option (to be able to say, for example, âroll
       forward my databases to how they were today at 10:30 a.m.â)."
788,85,mariadb-binlog,"This
       enables you to perform point-in-time recovery using the
--stop-datetime
option (to be able to say, for example, âroll
       forward my databases to how they were today at 10:30 a.m.â). If you have more than one binary log to execute on the MariaDB
       server, the safe method is to process them all using a single
       connection to the server. Here is an example that demonstrates
       what may be
unsafe
:

           shell>
mariadb-binlog binlog.000001 | mariadb -u root -p # DANGER!!"
788,86,mariadb-binlog,"Here is an example that demonstrates
       what may be
unsafe
:

           shell>
mariadb-binlog binlog.000001 | mariadb -u root -p # DANGER!! shell>
mariadb-binlog binlog.000002 | mariadb -u root -p # DANGER!! Processing binary logs this way using different connections to the
       server causes problems if the first log file contains a CREATE
       TEMPORARY TABLE statement and the second log contains a statement
       that uses the temporary table."
788,87,mariadb-binlog,"Processing binary logs this way using different connections to the
       server causes problems if the first log file contains a CREATE
       TEMPORARY TABLE statement and the second log contains a statement
       that uses the temporary table. When the first
mariadb
process
       terminates, the server drops the temporary table. When the second
mariadb
process attempts to use the table, the server reports
       âunknown table.â

       To avoid problems like this, use a
single
mariadb
process to
       execute the contents of all binary logs that you want to process."
788,88,mariadb-binlog,"When the second
mariadb
process attempts to use the table, the server reports
       âunknown table.â

       To avoid problems like this, use a
single
mariadb
process to
       execute the contents of all binary logs that you want to process. Here is one way to do so:

           shell>
mariadb-binlog binlog.000001 binlog.000002 | mariadb -u root -p
Another approach is to write all the logs to a single file and
       then process the file:

           shell>
mariadb-binlog binlog.000001 >  /tmp/statements.sql
shell>
mariadb-binlog binlog.000002 >> /tmp/statements.sql
shell>
mariadb -u root -p -e ""source /tmp/statements.sql""
mariadb-binlog
can produce output that reproduces a LOAD DATA
       INFILE operation without the original data file. mariadb-binlog
copies the data to a temporary file and writes a LOAD DATA LOCAL
       INFILE statement that refers to the file."
788,89,mariadb-binlog,"mariadb-binlog
copies the data to a temporary file and writes a LOAD DATA LOCAL
       INFILE statement that refers to the file. The default location of
       the directory where these files are written is system-specific. To
       specify a directory explicitly, use the
--local-load
option."
788,90,mariadb-binlog,"To
       specify a directory explicitly, use the
--local-load
option. Because
mariadb-binlog
converts LOAD DATA INFILE statements to
       LOAD DATA LOCAL INFILE statements (that is, it adds LOCAL), both
       the client and the server that you use to process the statements
       must be configured with the LOCAL capability enabled. Warning
The temporary files created for LOAD DATA LOCAL statements are
not
automatically deleted because they are needed until you
           actually execute those statements."
788,91,mariadb-binlog,"Warning
The temporary files created for LOAD DATA LOCAL statements are
not
automatically deleted because they are needed until you
           actually execute those statements. You should delete the
           temporary files yourself after you no longer need the
           statement log. The files can be found in the temporary file
           directory and have names like
original_file_name-#-#
."
789,0,mariadb-dumpslow,"The MariaDB slow query log contains information about queries that
       take a long time to execute. mariadb-dumpslow
parses MariaDB slow
       query log files and prints a summary of their contents. Normally,
mariadb-dumpslow
groups queries that are similar except
       for the particular values of number and string data values."
789,1,mariadb-dumpslow,"Normally,
mariadb-dumpslow
groups queries that are similar except
       for the particular values of number and string data values. It
       âabstractsâ these values to N and 'S' when displaying summary
       output. The
-a
and
-n
options can be used to modify value
       abstracting behavior."
789,2,mariadb-dumpslow,"The
-a
and
-n
options can be used to modify value
       abstracting behavior. Invoke
mariadb-dumpslow
like this:

           shell>
mariadb-dumpslow [
options
] [
log_file
...]
mariadb-dumpslow
supports the following options. â¢
--help
Display a help message and exit."
789,3,mariadb-dumpslow,"â¢
--help
Display a help message and exit. â¢
-a
Do not abstract all numbers to N and strings to 'S'. â¢
--debug
,
-d
Run in debug mode."
789,4,mariadb-dumpslow,"â¢
--debug
,
-d
Run in debug mode. â¢
-g
pattern
Consider only queries that match the (
grep
-style) pattern. â¢
-h
host_name
Host name of MariaDB server for *-slow.log file name."
789,5,mariadb-dumpslow,"â¢
-h
host_name
Host name of MariaDB server for *-slow.log file name. The
           value can contain a wildcard. The default is * (match all)."
789,6,mariadb-dumpslow,"The default is * (match all). â¢
-i
name
Name of server instance (if using
mariadb.server
startup
           script). â¢
-l
Do not subtract lock time from total time."
789,7,mariadb-dumpslow,"â¢
-l
Do not subtract lock time from total time. â¢
-n
N
Abstract numbers with at least
N
digits within names. â¢
-r
Reverse the sort order."
789,8,mariadb-dumpslow,"â¢
-r
Reverse the sort order. â¢
-s
sort_type
How to sort the output. The value of
sort_type
should be
           chosen from the following list:

           â¢   t, aa: Sort by rows affected or average rows affected

           â¢   l, ae: Sort by rows examined or aggregate rows examined

           â¢   l, at: Sort by query time or average query time

           â¢   l, al: Sort by lock time or average lock time

           â¢   s, as: Sort by rows sent or average rows sent

           â¢   c: Sort by count

       â¢
-t
N
Display only the first
N
queries in the output."
789,9,mariadb-dumpslow,"The value of
sort_type
should be
           chosen from the following list:

           â¢   t, aa: Sort by rows affected or average rows affected

           â¢   l, ae: Sort by rows examined or aggregate rows examined

           â¢   l, at: Sort by query time or average query time

           â¢   l, al: Sort by lock time or average lock time

           â¢   s, as: Sort by rows sent or average rows sent

           â¢   c: Sort by count

       â¢
-t
N
Display only the first
N
queries in the output. â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does."
789,10,mariadb-dumpslow,"â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does. Example of usage:

           shell>
mariadb-dumpslow
Reading mariadb slow query log from /usr/local/mysql/data/mysqld51-apple-slow.log
           Count: 1  Time=4.32s (4s)  Lock=0.00s (0s)  Rows=0.0 (0), root[root]@localhost
            insert into t2 select * from t1
           Count: 3  Time=2.53s (7s)  Lock=0.00s (0s)  Rows=0.0 (0), root[root]@localhost
            insert into t2 select * from t1 limit N
           Count: 3  Time=2.13s (6s)  Lock=0.00s (0s)  Rows=0.0 (0), root[root]@localhost
            insert into t1 select * from t1"
790,0,mariadb-dump,"The
mariadb-dump
client is a backup program originally written by
       Igor Romanenko. It can be used to dump a database or a collection
       of databases for backup or transfer to another SQL server (not
       necessarily a MariaDB server). The dump typically contains SQL
       statements to create the table, populate it, or both."
790,1,mariadb-dump,"The dump typically contains SQL
       statements to create the table, populate it, or both. However,
mariadb-dump
can also be used to generate files in CSV, other
       delimited text, or XML format. If you are doing a backup on the server and your tables all are
       MyISAM tables, consider using the
mariadb-hotcopy
instead because
       it can accomplish faster backups and faster restores."
790,2,mariadb-dump,"If you are doing a backup on the server and your tables all are
       MyISAM tables, consider using the
mariadb-hotcopy
instead because
       it can accomplish faster backups and faster restores. See
mariadb-hotcopy(1)
. There are four general ways to invoke
mariadb-dump
:

           shell>
mariadb-dump [
options
]
db_name
[
tbl_name
...]
shell>
mariadb-dump [
options
] --databases
db_name
..."
790,3,mariadb-dump,"There are four general ways to invoke
mariadb-dump
:

           shell>
mariadb-dump [
options
]
db_name
[
tbl_name
...]
shell>
mariadb-dump [
options
] --databases
db_name
... shell>
mariadb-dump [
options
] --all-databases
shell>
mariadb-dump [
options
] --system={options}
If you do not name any tables following
db_name
or if you use the
--databases
or
--all-databases
option, entire databases are
       dumped. mariadb-dump
does not dump the INFORMATION_SCHEMA or
       performance_schema databases by default."
790,4,mariadb-dump,"mariadb-dump
does not dump the INFORMATION_SCHEMA or
       performance_schema databases by default. To dump these, name them
       explicitly on the command line, although you must also use the
--skip-lock-tables
option. To see a list of the options your version of
mariadb-dump
supports, execute
mariadb-dump --help
."
790,5,mariadb-dump,"To see a list of the options your version of
mariadb-dump
supports, execute
mariadb-dump --help
. Some
mariadb-dump
options are shorthand for groups of other
       options:

       â¢   Use of
--opt
is the same as specifying
--add-drop-table
,
--add-locks
,
--create-options
,
--disable-keys
,
--extended-insert
,
--lock-tables
,
--quick
, and
--set-charset
. All of the options that
--opt
stands for also are on by
           default because
--opt
is on by default."
790,6,mariadb-dump,"All of the options that
--opt
stands for also are on by
           default because
--opt
is on by default. â¢   Use of
--compact
is the same as specifying
--skip-add-drop-table
,
--skip-add-locks
,
--skip-comments
,
--skip-disable-keys
, and
--skip-set-charset
options. To reverse the effect of a group option, uses its
--skip-
xxx
form
       (
--skip-opt
or
--skip-compact
)."
790,7,mariadb-dump,"To reverse the effect of a group option, uses its
--skip-
xxx
form
       (
--skip-opt
or
--skip-compact
). It is also possible to select only
       part of the effect of a group option by following it with options
       that enable or disable specific features. Here are some examples:

       â¢   To select the effect of
--opt
except for some features, use
           the
--skip
option for each feature."
790,8,mariadb-dump,"Here are some examples:

       â¢   To select the effect of
--opt
except for some features, use
           the
--skip
option for each feature. To disable extended
           inserts and memory buffering, use
--opt --skip-extended-insert
--skip-quick
. (Actually,
--skip-extended-insert --skip-quick
is sufficient because
--opt
is on by default.)

       â¢   To reverse
--opt
for all features except index disabling and
           table locking, use
--skip-opt --disable-keys --lock-tables
."
790,9,mariadb-dump,"(Actually,
--skip-extended-insert --skip-quick
is sufficient because
--opt
is on by default.)

       â¢   To reverse
--opt
for all features except index disabling and
           table locking, use
--skip-opt --disable-keys --lock-tables
. When you selectively enable or disable the effect of a group
       option, order is important because options are processed first to
       last. For example,
--disable-keys --lock-tables --skip-opt
would
       not have the intended effect; it is the same as
--skip-opt
by
       itself."
790,10,mariadb-dump,"For example,
--disable-keys --lock-tables --skip-opt
would
       not have the intended effect; it is the same as
--skip-opt
by
       itself. mariadb-dump
can retrieve and dump table contents row by row, or
       it can retrieve the entire content from a table and buffer it in
       memory before dumping it. Buffering in memory can be a problem if
       you are dumping large tables."
790,11,mariadb-dump,"Buffering in memory can be a problem if
       you are dumping large tables. To dump tables row by row, use the
--quick
option (or
--opt
, which enables
--quick
). The
--opt
option
       (and hence
--quick
) is enabled by default, so to enable memory
       buffering, use
--skip-quick
."
790,12,mariadb-dump,"The
--opt
option
       (and hence
--quick
) is enabled by default, so to enable memory
       buffering, use
--skip-quick
. If you are using a recent version of
mariadb-dump
to generate a
       dump to be reloaded into a very old MySQL server, you should not
       use the
--opt
or
--extended-insert
option. Use
--skip-opt
instead."
790,13,mariadb-dump,"Use
--skip-opt
instead. mariadb-dump
supports the following options, which can be
       specified on the command line or in the [mariadb-dump] and
       [client] option file groups. mariadb-dump
also supports the
       options for processing option file."
790,14,mariadb-dump,"mariadb-dump
also supports the
       options for processing option file. â¢
--help
,
-? Display a help message and exit."
790,15,mariadb-dump,"Display a help message and exit. â¢
--add-drop-database
Add a DROP DATABASE statement before each CREATE DATABASE
           statement. This option is typically used in conjunction with
           the
--all-databases
or
--databases
option because no CREATE
           DATABASE statements are written unless one of those options is
           specified."
790,16,mariadb-dump,"This option is typically used in conjunction with
           the
--all-databases
or
--databases
option because no CREATE
           DATABASE statements are written unless one of those options is
           specified. â¢
--add-drop-table
Add a DROP TABLE statement before each CREATE TABLE statement. â¢
--add-drop-trigger
Add a DROP TRIGGER statement before each CREATE TRIGGER
           statement."
790,17,mariadb-dump,"â¢
--add-drop-trigger
Add a DROP TRIGGER statement before each CREATE TRIGGER
           statement. â¢
--add-locks
Surround each table dump with LOCK TABLES and UNLOCK TABLES
           statements. This results in faster inserts when the dump file
           is reloaded."
790,18,mariadb-dump,"This results in faster inserts when the dump file
           is reloaded. â¢
--all-databases
,
-A
Dump all tables in all databases. This is the same as using
           the
--databases
option and naming all the databases on the
           command line."
790,19,mariadb-dump,"This is the same as using
           the
--databases
option and naming all the databases on the
           command line. â¢
--all-tablespaces
,
-Y
Adds to a table dump all SQL statements needed to create any
           tablespaces used by an NDBCLUSTER table. This information is
           not otherwise included in the output from
mariadb-dump
."
790,20,mariadb-dump,"This information is
           not otherwise included in the output from
mariadb-dump
. This
           option is currently relevant only to MySQL Cluster tables. â¢
--allow-keywords
Allow creation of column names that are keywords."
790,21,mariadb-dump,"â¢
--allow-keywords
Allow creation of column names that are keywords. This works
           by prefixing each column name with the table name. â¢
--apply-slave-statements
Adds 'STOP SLAVE' prior to 'CHANGE MASTER' and 'START SLAVE'
           to bottom of dump."
790,22,mariadb-dump,"â¢
--apply-slave-statements
Adds 'STOP SLAVE' prior to 'CHANGE MASTER' and 'START SLAVE'
           to bottom of dump. â¢
--as-of=
name
Dump system versioned table as of specified timestamp. â¢
--character-sets-dir=
path
The directory where character sets are installed."
790,23,mariadb-dump,"â¢
--character-sets-dir=
path
The directory where character sets are installed. â¢
--comments
,
-i
Write additional information in the dump file such as program
           version, server version, and host. This option is enabled by
           default."
790,24,mariadb-dump,"This option is enabled by
           default. To suppress this additional information, use
--skip-comments
. â¢
--compact
Produce more compact output."
790,25,mariadb-dump,"â¢
--compact
Produce more compact output. This option enables the
--skip-add-drop-table
,
--skip-add-locks
,
--skip-comments
,
--skip-disable-keys
, and
--skip-set-charset
options. â¢
--compatible=
name
Produce output that is more compatible with other database
           systems or with older MySQL servers."
790,26,mariadb-dump,"â¢
--compatible=
name
Produce output that is more compatible with other database
           systems or with older MySQL servers. The value of
name
can be
           ansi, mysql323, mysql40, postgresql, oracle, mssql, db2,
           maxdb, no_key_options, no_table_options, or no_field_options. To use several values, separate them by commas."
790,27,mariadb-dump,"To use several values, separate them by commas. These values
           have the same meaning as the corresponding options for setting
           the server SQL mode. This option does not guarantee compatibility with other
           servers."
790,28,mariadb-dump,"This option does not guarantee compatibility with other
           servers. It only enables those SQL mode values that are
           currently available for making dump output more compatible. For example,
--compatible=oracle
does not map data types to
           Oracle types or use Oracle comment syntax."
790,29,mariadb-dump,"For example,
--compatible=oracle
does not map data types to
           Oracle types or use Oracle comment syntax. â¢
--complete-insert
,
-c
Use complete INSERT statements that include column names. â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression."
790,30,mariadb-dump,"â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression. â¢
--copy-s3-tables
By default S3 tables are ignored. With this option set, the
           result file will contain a CREATE statement for a similar Aria
           table, followed by the table data and ending with an ALTER
           TABLE xxx ENGINE=S3."
790,31,mariadb-dump,"With this option set, the
           result file will contain a CREATE statement for a similar Aria
           table, followed by the table data and ending with an ALTER
           TABLE xxx ENGINE=S3. â¢
--create-options
,
-a
Include all MariaDB-specific table options in the CREATE TABLE
           statements. Use
--skip-create-options
to disable."
790,32,mariadb-dump,"Use
--skip-create-options
to disable. â¢
--databases
,
-B
Dump several databases. Normally,
mariadb-dump
treats the
           first name argument on the command line as a database name and
           following names as table names."
790,33,mariadb-dump,"Normally,
mariadb-dump
treats the
           first name argument on the command line as a database name and
           following names as table names. With this option, it treats
           all name arguments as database names. CREATE DATABASE and USE
           statements are included in the output before each new
           database."
790,34,mariadb-dump,"CREATE DATABASE and USE
           statements are included in the output before each new
           database. â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log. A typical
debug_options
string is
           'd:t:o,
file_name
'."
790,35,mariadb-dump,"A typical
debug_options
string is
           'd:t:o,
file_name
'. The default value is 'd:t:o,/tmp/mariadb-
           dump.trace'. â¢
--debug-check
Print some debugging information when the program exits."
790,36,mariadb-dump,"â¢
--debug-check
Print some debugging information when the program exits. â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--default-auth
Default authentication client-side plugin to use."
790,37,mariadb-dump,"â¢
--default-auth
Default authentication client-side plugin to use. â¢
--default-character-set=
charset_name
Use
charset_name
as the default character set. If no character
           set is specified,
mariadb-dump
uses utf8."
790,38,mariadb-dump,"If no character
           set is specified,
mariadb-dump
uses utf8. â¢
--defaults-extra-file=
filename
Set
filename
as the file to read default options from after
           the global defaults files has been read. Must be given as
           first option."
790,39,mariadb-dump,"Must be given as
           first option. â¢
--defaults-file=
filename
Set
filename
as the file to read default options from,
           override global defaults files. Must be given as first
           option."
790,40,mariadb-dump,"Must be given as first
           option. â¢
--defaults-group-suffix=
str
,

           Also read groups with a suffix of
str
. For example, since
           mariadb-dump normally reads the [client] and [mariadb-dump]
           groups, --defaults-group-suffix=x would cause it to also read
           the groups [mariadb-dump_x] and [client_x]."
790,41,mariadb-dump,"For example, since
           mariadb-dump normally reads the [client] and [mariadb-dump]
           groups, --defaults-group-suffix=x would cause it to also read
           the groups [mariadb-dump_x] and [client_x]. â¢
--delayed-insert
Write INSERT DELAYED statements rather than INSERT statements. â¢
--delete-master-logs
On a master replication server, delete the binary logs by
           sending a PURGE BINARY LOGS statement to the server after
           performing the dump operation."
790,42,mariadb-dump,"â¢
--delete-master-logs
On a master replication server, delete the binary logs by
           sending a PURGE BINARY LOGS statement to the server after
           performing the dump operation. This option automatically
           enables
--master-data
. â¢
--dir
Parallel dump of multiple databases."
790,43,mariadb-dump,"â¢
--dir
Parallel dump of multiple databases. Works just like
--tab
,
           with regard to output (sql file for table definition and tab-
           separated for data, same options, e.g
--parallel
). It also
           allows the
--databases
and
--all-databases
options."
790,44,mariadb-dump,"It also
           allows the
--databases
and
--all-databases
options. When
--dir
is used, it creates the directory structure in the output
           directory pointed to by
--dir
. For every database to be
           dumped, there will be a directory with the database name."
790,45,mariadb-dump,"For every database to be
           dumped, there will be a directory with the database name. All
           options that
--tab
supports are also supported by
--dir
, in
           particular
--parallel
. â¢
--disable-keys
,
-K
For each table, surround the INSERT statements with /*!40000
           ALTER TABLE
tbl_name
DISABLE KEYS */; and /*!40000 ALTER TABLE
tbl_name
ENABLE KEYS */; statements."
790,46,mariadb-dump,"â¢
--disable-keys
,
-K
For each table, surround the INSERT statements with /*!40000
           ALTER TABLE
tbl_name
DISABLE KEYS */; and /*!40000 ALTER TABLE
tbl_name
ENABLE KEYS */; statements. This makes loading the
           dump file faster because the indexes are created after all
           rows are inserted. This option is effective only for nonunique
           indexes of MyISAM tables."
790,47,mariadb-dump,"This option is effective only for nonunique
           indexes of MyISAM tables. â¢
--dump-date
If the
--comments
option is given,
mariadb-dump
produces a
           comment at the end of the dump of the following form:

               -- Dump completed on
DATE
However, the date causes dump files taken at different times
           to appear to be different, even if the data are otherwise
           identical. --dump-date
and
--skip-dump-date
control whether
           the date is added to the comment."
790,48,mariadb-dump,"--dump-date
and
--skip-dump-date
control whether
           the date is added to the comment. The default is
--dump-date
(include the date in the comment). --skip-dump-date
suppresses date printing

       â¢
--dump-history
Dump tables with history."
790,49,mariadb-dump,"--skip-dump-date
suppresses date printing

       â¢
--dump-history
Dump tables with history. Until this option, mariadb-dump
           could not read historical rows from versioned tables, and so
           historical data would not be backed up. â¢
--dump-slave[=
value
]
Used for producing a dump file from a replication slave server
           that can be used to set up another slave server with the same
           master."
790,50,mariadb-dump,"â¢
--dump-slave[=
value
]
Used for producing a dump file from a replication slave server
           that can be used to set up another slave server with the same
           master. Causes the binary log position and filename of the
           master to be appended to the dumped data output. Setting the
           value to 1 (the default) will print it as a CHANGE MASTER
           command in the dumped data output; if set to 2, that command
           will be prefixed with a comment symbol."
790,51,mariadb-dump,"Setting the
           value to 1 (the default) will print it as a CHANGE MASTER
           command in the dumped data output; if set to 2, that command
           will be prefixed with a comment symbol. This option will turn
           --lock-all-tables on, unless --single-transaction is specified
           too (in which case a global read lock is only taken a short
           time at the beginning of the dump - don't forget to read about
           --single-transaction below). In all cases any action on logs
           will happen at the exact moment of the dump."
790,52,mariadb-dump,"In all cases any action on logs
           will happen at the exact moment of the dump. Option
           automatically turns --lock-tables off. Using this option
           causes mariadb-dump to stop the slave SQL thread before
           beginning the dump, and restart it again after completion."
790,53,mariadb-dump,"Using this option
           causes mariadb-dump to stop the slave SQL thread before
           beginning the dump, and restart it again after completion. â¢
--events
,
-E
Include Event Scheduler events for the dumped databases in the
           output. â¢
--extended-insert
,
-e
Use multiple-row INSERT syntax that include several VALUES
           lists."
790,54,mariadb-dump,"â¢
--extended-insert
,
-e
Use multiple-row INSERT syntax that include several VALUES
           lists. This results in a smaller dump file and speeds up
           inserts when the file is reloaded. â¢
--fields-terminated-by=..."
790,55,mariadb-dump,"â¢
--fields-terminated-by=... ,
--fields-enclosed-by=... ,
--fields-optionally-enclosed-by=..."
790,56,mariadb-dump,",
--fields-optionally-enclosed-by=... ,
--fields-escaped-by=... These options are used with the
--tab
option and have the same
           meaning as the corresponding FIELDS clauses for LOAD DATA
           INFILE."
790,57,mariadb-dump,"These options are used with the
--tab
option and have the same
           meaning as the corresponding FIELDS clauses for LOAD DATA
           INFILE. â¢
--first-slave
Removed in MariaDB 5.5. Use
--lock-all-tables
instead."
790,58,mariadb-dump,"Use
--lock-all-tables
instead. â¢
--flush-logs
,
-F
Flush the MariaDB server log files before starting the dump. This option requires the RELOAD privilege."
790,59,mariadb-dump,"This option requires the RELOAD privilege. If you use this
           option in combination with the
--all-databases
option, the
           logs are flushed
for each database dumped
. The exception is
           when using
--lock-all-tables
or
--master-data
: In this case,
           the logs are flushed only once, corresponding to the moment
           that all tables are locked."
790,60,mariadb-dump,"The exception is
           when using
--lock-all-tables
or
--master-data
: In this case,
           the logs are flushed only once, corresponding to the moment
           that all tables are locked. If you want your dump and the log
           flush to happen at exactly the same moment, you should use
--flush-logs
together with either
--lock-all-tables
or
--master-data
. â¢
--flush-privileges
Send a FLUSH PRIVILEGES statement to the server after dumping
           the mysql database."
790,61,mariadb-dump,"â¢
--flush-privileges
Send a FLUSH PRIVILEGES statement to the server after dumping
           the mysql database. This option should be used any time the
           dump contains the mysql database and any other database that
           depends on the data in the mysql database for proper
           restoration. â¢
--force
,
-f
Continue even if an SQL error occurs during a table dump."
790,62,mariadb-dump,"â¢
--force
,
-f
Continue even if an SQL error occurs during a table dump. One use for this option is to cause
mariadb-dump
to continue
           executing even when it encounters a view that has become
           invalid because the definition refers to a table that has been
           dropped. Without
--force
,
mariadb-dump
exits with an error
           message."
790,63,mariadb-dump,"Without
--force
,
mariadb-dump
exits with an error
           message. With
--force
,
mariadb-dump
prints the error message,
           but it also writes an SQL comment containing the view
           definition to the dump output and continues executing. â¢
--gtid
Available from MariaDB 10.0.13, and is used together with
--master-data
and
--dump-slave
to more conveniently set up a
           new GTID slave."
790,64,mariadb-dump,"â¢
--gtid
Available from MariaDB 10.0.13, and is used together with
--master-data
and
--dump-slave
to more conveniently set up a
           new GTID slave. It causes those options to output SQL
           statements that configure the slave to use the global
           transaction ID to connect to the master instead of old-style
           filename/offset positions. The old-style positions are still
           included in comments when
--gtid
is used; likewise the GTID
           position is included in comments even if
--gtid
is not used."
790,65,mariadb-dump,"The old-style positions are still
           included in comments when
--gtid
is used; likewise the GTID
           position is included in comments even if
--gtid
is not used. â¢
--header
Used together with --tab. When enabled, adds header with
           column names to the top of output txt files."
790,66,mariadb-dump,"When enabled, adds header with
           column names to the top of output txt files. â¢
--hex-blob
Dump binary columns using hexadecimal notation (for example,
           'abc' becomes 0x616263). The affected data types are BINARY,
           VARBINARY, the BLOB types, and BIT."
790,67,mariadb-dump,"The affected data types are BINARY,
           VARBINARY, the BLOB types, and BIT. â¢
--host=
host_name
,
-h
host_name
Dump data from the MariaDB server on the given host. The
           default host is localhost."
790,68,mariadb-dump,"The
           default host is localhost. â¢
--ignore-table=
db_name.tbl_name
Do not dump the given table, which must be specified using
           both the database and table names. To ignore multiple tables,
           use this option multiple times."
790,69,mariadb-dump,"To ignore multiple tables,
           use this option multiple times. This option also can be used
           to ignore views. â¢
--include-master-host-port
Add the MASTER_HOST and MASTER_PORT options for the CHANGE
           MASTER TO statement when using the
--dump-slave
option for a
           slave dump."
790,70,mariadb-dump,"â¢
--include-master-host-port
Add the MASTER_HOST and MASTER_PORT options for the CHANGE
           MASTER TO statement when using the
--dump-slave
option for a
           slave dump. â¢
--insert-ignore
Write INSERT IGNORE statements rather than INSERT statements. â¢
--lines-terminated-by=..."
790,71,mariadb-dump,"â¢
--lines-terminated-by=... This option is used with the
--tab
option and has the same
           meaning as the corresponding LINES clause for LOAD DATA
           INFILE. â¢
--lock-all-tables
,
-x
Lock all tables across all databases."
790,72,mariadb-dump,"â¢
--lock-all-tables
,
-x
Lock all tables across all databases. This is achieved by
           acquiring a global read lock for the duration of the whole
           dump. This option automatically turns off
--single-transaction
and
--lock-tables
."
790,73,mariadb-dump,"This option automatically turns off
--single-transaction
and
--lock-tables
. â¢
--lock-tables
,
-l
For each dumped database, lock all tables to be dumped before
           dumping them. The tables are locked with READ LOCAL to allow
           concurrent inserts in the case of MyISAM tables."
790,74,mariadb-dump,"The tables are locked with READ LOCAL to allow
           concurrent inserts in the case of MyISAM tables. For
           transactional tables such as InnoDB,
--single-transaction
is a
           much better option than
--lock-tables
because it does not need
           to lock the tables at all. Because
--lock-tables
locks tables for each database
           separately, this option does not guarantee that the tables in
           the dump file are logically consistent between databases."
790,75,mariadb-dump,"Because
--lock-tables
locks tables for each database
           separately, this option does not guarantee that the tables in
           the dump file are logically consistent between databases. Tables in different databases may be dumped in completely
           different states. Use
--skip-lock-tables
to disable."
790,76,mariadb-dump,"Use
--skip-lock-tables
to disable. â¢
--log-error=
file_name
Log warnings and errors by appending them to the named file. The default is to do no logging."
790,77,mariadb-dump,"The default is to do no logging. â¢
--log-queries
When restoring the dump, the server will, if logging is turned
           on, log the queries to the general and slow query log. Defaults to on; use
--skip-log-queries
to disable."
790,78,mariadb-dump,"Defaults to on; use
--skip-log-queries
to disable. â¢
--master-data[=
value
]
Use this option to dump a master replication server to produce
           a dump file that can be used to set up another server as a
           slave of the master. It causes the dump output to include a
           CHANGE MASTER TO statement that indicates the binary log
           coordinates (file name and position) of the dumped server."
790,79,mariadb-dump,"It causes the dump output to include a
           CHANGE MASTER TO statement that indicates the binary log
           coordinates (file name and position) of the dumped server. These are the master server coordinates from which the slave
           should start replicating after you load the dump file into the
           slave. If the option value is 2, the CHANGE MASTER TO statement is
           written as an SQL comment, and thus is informative only; it
           has no effect when the dump file is reloaded."
790,80,mariadb-dump,"If the option value is 2, the CHANGE MASTER TO statement is
           written as an SQL comment, and thus is informative only; it
           has no effect when the dump file is reloaded. If the option
           value is 1, the statement is not written as a comment and
           takes effect when the dump file is reloaded. If no option
           value is specified, the default value is 1."
790,81,mariadb-dump,"If no option
           value is specified, the default value is 1. This option requires the RELOAD privilege and the binary log
           must be enabled. The
--master-data
option automatically turns off
--lock-tables
."
790,82,mariadb-dump,"The
--master-data
option automatically turns off
--lock-tables
. It also turns on
--lock-all-tables
, unless
--single-transaction
also is specified. In all cases, any
           action on logs happens at the exact moment of the dump."
790,83,mariadb-dump,"In all cases, any
           action on logs happens at the exact moment of the dump. It is also possible to set up a slave by dumping an existing
           slave of the master. To do this, use the following procedure
           on the existing slave:

            1."
790,84,mariadb-dump,"To do this, use the following procedure
           on the existing slave:

            1. Stop the slave's SQL thread and get its current status:

                   mariadb>
STOP SLAVE SQL_THREAD;
mariadb>
SHOW SLAVE STATUS;
2. From the output of the SHOW SLAVE STATUS statement, the
               binary log coordinates of the master server from which the
               new slave should start replicating are the values of the
               Relay_Master_Log_File and Exec_Master_Log_Pos fields."
790,85,mariadb-dump,"From the output of the SHOW SLAVE STATUS statement, the
               binary log coordinates of the master server from which the
               new slave should start replicating are the values of the
               Relay_Master_Log_File and Exec_Master_Log_Pos fields. Denote those values as
file_name
and
file_pos
. 3."
790,86,mariadb-dump,"3. Dump the slave server:

                   shell>
mariadb-dump --master-data=2 --all-databases > dumpfile
4. Restart the slave:

                   mariadb>
START SLAVE;
5."
790,87,mariadb-dump,"Restart the slave:

                   mariadb>
START SLAVE;
5. On the new slave, load the dump file:

                   shell>
mariadb < dumpfile
6. On the new slave, set the replication coordinates to those
               of the master server obtained earlier:

                   mariadb>
CHANGE MASTER TO
->
MASTER_LOG_FILE = '
file_name
', MASTER_LOG_POS =
file_pos
;
The CHANGE MASTER TO statement might also need other
               parameters, such as MASTER_HOST to point the slave to the
               correct master server host."
790,88,mariadb-dump,"On the new slave, set the replication coordinates to those
               of the master server obtained earlier:

                   mariadb>
CHANGE MASTER TO
->
MASTER_LOG_FILE = '
file_name
', MASTER_LOG_POS =
file_pos
;
The CHANGE MASTER TO statement might also need other
               parameters, such as MASTER_HOST to point the slave to the
               correct master server host. Add any such parameters as
               necessary. â¢
--max-allowed-packet=
length
Sets the maximum packet length to send to or receive from
           server."
790,89,mariadb-dump,"â¢
--max-allowed-packet=
length
Sets the maximum packet length to send to or receive from
           server. â¢
--max-statement-time=
seconds
Sets the maximum time any statement can run before being timed
           out by the server. (Default value is 0 (no limit))

       â¢
--net-buffer-length=
length
Sets the buffer size for TCP/IP and socket communication."
790,90,mariadb-dump,"(Default value is 0 (no limit))

       â¢
--net-buffer-length=
length
Sets the buffer size for TCP/IP and socket communication. â¢
--no-autocommit
Enclose the INSERT statements for each dumped table within SET
           autocommit = 0 and COMMIT statements. â¢
--no-create-db
,
-n
This option suppresses the CREATE DATABASE statements that are
           otherwise included in the output if the
--databases
or
--all-databases
option is given."
790,91,mariadb-dump,"â¢
--no-create-db
,
-n
This option suppresses the CREATE DATABASE statements that are
           otherwise included in the output if the
--databases
or
--all-databases
option is given. â¢
--no-create-info
,
-t
Do not write CREATE TABLE statements that re-create each
           dumped table. â¢
--no-data
,
-d
Do not write any table row information (that is, do not dump
           table contents)."
790,92,mariadb-dump,"â¢
--no-data
,
-d
Do not write any table row information (that is, do not dump
           table contents). This is useful if you want to dump only the
           CREATE TABLE statement for the table (for example, to create
           an empty copy of the table by loading the dump file). â¢
--no-defaults
Do not read default options from any option file."
790,93,mariadb-dump,"â¢
--no-defaults
Do not read default options from any option file. This must be
           given as the first argument. â¢
--no-set-names
,
-N
This has the same effect as
--skip-set-charset
."
790,94,mariadb-dump,"â¢
--no-set-names
,
-N
This has the same effect as
--skip-set-charset
. â¢
--opt
This option is shorthand. It is the same as specifying
--add-drop-table --add-locks --create-options --disable-keys
--extended-insert --lock-tables --quick --set-charset
."
790,95,mariadb-dump,"It is the same as specifying
--add-drop-table --add-locks --create-options --disable-keys
--extended-insert --lock-tables --quick --set-charset
. It
           should give you a fast dump operation and produce a dump file
           that can be reloaded into a MariaDB server quickly. The
--opt
option is enabled by default."
790,96,mariadb-dump,"The
--opt
option is enabled by default. Use
--skip-opt
to
           disable it. See the discussion at the beginning of this
           section for information about selectively enabling or
           disabling a subset of the options affected by
--opt
."
790,97,mariadb-dump,"See the discussion at the beginning of this
           section for information about selectively enabling or
           disabling a subset of the options affected by
--opt
. â¢
--order-by-primary
Dump each table's rows sorted by its primary key, or by its
           first unique index, if such an index exists. This is useful
           when dumping a MyISAM table to be loaded into an InnoDB table,
           but will make the dump operation take considerably longer."
790,98,mariadb-dump,"This is useful
           when dumping a MyISAM table to be loaded into an InnoDB table,
           but will make the dump operation take considerably longer. â¢
--order-by-size
Dump each table according to their size, smallest first. Useful when using --single-transaction on tables which get
           truncated/altered often."
790,99,mariadb-dump,"Useful when using --single-transaction on tables which get
           truncated/altered often. The assumption here is that smaller
           tables get truncated more often, and by dumping those first,
           this reduces the chance that a --single-transaction dump will
           fail with with

       â¢
--parallel=#
,
-j
Number of dump table jobs executed in parallel (only for use
           with the --tab option). Initial testing indicates that
           performance can be increased (dump time decreased) up to 4
           times on smaller size dumps, when the database fits into
           memory."
790,100,mariadb-dump,"Initial testing indicates that
           performance can be increased (dump time decreased) up to 4
           times on smaller size dumps, when the database fits into
           memory. There is a point at which disk becomes the bottleneck,
           after which adding more parallel jobs does not bring better
           performance. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server."
790,101,mariadb-dump,"â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-dump
prompts for one."
790,102,mariadb-dump,"If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-dump
prompts for one. Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line."
790,103,mariadb-dump,"You can use an option file to avoid giving the
           password on the command line. â¢
--pipe
,
-W
On Windows, connect to the server via a named pipe. This
           option applies only if the server supports named-pipe
           connections."
790,104,mariadb-dump,"This
           option applies only if the server supports named-pipe
           connections. â¢
--plugin-dir
Directory for client-side plugins. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection."
790,105,mariadb-dump,"â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection. Forces
           --protocol=tcp when specified on the command line without
           other connection properties. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server."
790,106,mariadb-dump,"â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--quick
,
-q
This option is useful for dumping large tables."
790,107,mariadb-dump,"â¢
--quick
,
-q
This option is useful for dumping large tables. It forces
mariadb-dump
to retrieve rows for a table from the server a
           row at a time rather than retrieving the entire row set and
           buffering it in memory before writing it out. â¢
--print-defaults
Print the program argument list and exit."
790,108,mariadb-dump,"â¢
--print-defaults
Print the program argument list and exit. This must be given
           as the first argument. â¢
--quote-names
,
-Q
Quote identifiers (such as database, table, and column names)
           within â`â characters."
790,109,mariadb-dump,"â¢
--quote-names
,
-Q
Quote identifiers (such as database, table, and column names)
           within â`â characters. If the ANSI_QUOTES SQL mode is enabled,
           identifiers are quoted within â""â characters. This option is
           enabled by default."
790,110,mariadb-dump,"This option is
           enabled by default. It can be disabled with
--skip-quote-names
, but this option should be given after any
           option such as
--compatible
that may enable
--quote-names
. â¢
--replace
Write REPLACE statements rather than INSERT statements."
790,111,mariadb-dump,"â¢
--replace
Write REPLACE statements rather than INSERT statements. â¢
--result-file=
file_name
,
-r
file_name
Direct output to a given file. This option should be used on
           Windows to prevent newline â\nâ characters from being
           converted to â\r\nâ carriage return/newline sequences."
790,112,mariadb-dump,"This option should be used on
           Windows to prevent newline â\nâ characters from being
           converted to â\r\nâ carriage return/newline sequences. The
           result file is created and its previous contents overwritten,
           even if an error occurs while generating the dump. â¢
--routines
,
-R
Included stored routines (procedures and functions) for the
           dumped databases in the output."
790,113,mariadb-dump,"â¢
--routines
,
-R
Included stored routines (procedures and functions) for the
           dumped databases in the output. Use of this option requires
           the SELECT privilege for the mysql.proc table. The output
           generated by using
--routines
contains CREATE PROCEDURE and
           CREATE FUNCTION statements to re-create the routines."
790,114,mariadb-dump,"The output
           generated by using
--routines
contains CREATE PROCEDURE and
           CREATE FUNCTION statements to re-create the routines. However,
           these statements do not include attributes such as the routine
           creation and modification timestamps. This means that when the
           routines are reloaded, they will be created with the
           timestamps equal to the reload time."
790,115,mariadb-dump,"This means that when the
           routines are reloaded, they will be created with the
           timestamps equal to the reload time. If you require routines to be re-created with their original
           timestamp attributes, do not use
--routines
. Instead, dump and
           reload the contents of the mysql.proc table directly, using a
           MariaDB account that has appropriate privileges for the mysql
           database."
790,116,mariadb-dump,"Instead, dump and
           reload the contents of the mysql.proc table directly, using a
           MariaDB account that has appropriate privileges for the mysql
           database. â¢
--set-charset
Add SET NAMES
default_character_set
to the output. This option
           is enabled by default."
790,117,mariadb-dump,"This option
           is enabled by default. To suppress the SET NAMES statement,
           use
--skip-set-charset
. â¢
--single-transaction
This option sends a START TRANSACTION SQL statement to the
           server before dumping data."
790,118,mariadb-dump,"â¢
--single-transaction
This option sends a START TRANSACTION SQL statement to the
           server before dumping data. It is useful only with
           transactional tables such as InnoDB, because then it dumps the
           consistent state of the database at the time when BEGIN was
           issued without blocking any applications. When using this option, you should keep in mind that only
           InnoDB tables are dumped in a consistent state."
790,119,mariadb-dump,"When using this option, you should keep in mind that only
           InnoDB tables are dumped in a consistent state. For example,
           any MyISAM or MEMORY tables dumped while using this option may
           still change state. While a
--single-transaction
dump is in process, to ensure a
           valid dump file (correct table contents and binary log
           coordinates), no other connection should use the following
           statements: ALTER TABLE, CREATE TABLE, DROP TABLE, RENAME
           TABLE, TRUNCATE TABLE."
790,120,mariadb-dump,"While a
--single-transaction
dump is in process, to ensure a
           valid dump file (correct table contents and binary log
           coordinates), no other connection should use the following
           statements: ALTER TABLE, CREATE TABLE, DROP TABLE, RENAME
           TABLE, TRUNCATE TABLE. A consistent read is not isolated from
           those statements, so use of them on a table to be dumped can
           cause the SELECT that is performed by
mariadb-dump
to retrieve
           the table contents to obtain incorrect contents or fail. The
--single-transaction
option and the
--lock-tables
option
           are mutually exclusive because LOCK TABLES causes any pending
           transactions to be committed implicitly."
790,121,mariadb-dump,"The
--single-transaction
option and the
--lock-tables
option
           are mutually exclusive because LOCK TABLES causes any pending
           transactions to be committed implicitly. To dump large tables, you should combine the
--single-transaction
option with
--quick
. â¢
--skip-add-drop-table
Disable the
--add-drop-table
option."
790,122,mariadb-dump,"â¢
--skip-add-drop-table
Disable the
--add-drop-table
option. â¢
--skip-add-locks
Disable the
--add-locks
option. â¢
--skip-comments
Disable the
--comments
option."
790,123,mariadb-dump,"â¢
--skip-comments
Disable the
--comments
option. â¢
--skip-compact
Disable the
--compact
option. â¢
--skip-disable-keys
Disable the
--disable-keys
option."
790,124,mariadb-dump,"â¢
--skip-disable-keys
Disable the
--disable-keys
option. â¢
--skip-extended-insert
Disable the
--extended-insert
option. â¢
--skip-opt
Disable the
--opt
option."
790,125,mariadb-dump,"â¢
--skip-opt
Disable the
--opt
option. â¢
--skip-quick
Disable the
--quick
option. â¢
--skip-quote-names
Disable the
--quote-names
option."
790,126,mariadb-dump,"â¢
--skip-quote-names
Disable the
--quote-names
option. â¢
--skip-set-charset
Disable the
--set-charset
option. â¢
--skip-triggers
Disable the
--triggers
option."
790,127,mariadb-dump,"â¢
--skip-triggers
Disable the
--triggers
option. â¢
--skip-tz-utc
Disable the
--tz-utc
option. â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use."
790,128,mariadb-dump,"â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe. â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags)."
790,129,mariadb-dump,"â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags). Disable with
--skip-ssl
. â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
)."
790,130,mariadb-dump,"â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
)."
790,131,mariadb-dump,"â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
). â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
)."
790,132,mariadb-dump,"â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
)."
790,133,mariadb-dump,"â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
). â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting. This option is disabled by default."
790,134,mariadb-dump,"This option is disabled by default. â¢
--system=
{all, users, plugins, udfs, servers, stats,
timezones}
Dump the system tables in the mysql database in a logical
           form. This option is an empty set by default."
790,135,mariadb-dump,"This option is an empty set by default. One or more options can be listed in comma separated list. The options here are:

           â¢   all - an alias to enabling all of the below options."
790,136,mariadb-dump,"The options here are:

           â¢   all - an alias to enabling all of the below options. â¢   users - the users, roles and their grants outputed as
CREATE USER, CREATE ROLE
,
GRANT
, and
SET DEFAULT ROLE
(
ALTER USER
for MySQL-8.0+). â¢   plugins - active plugins of the server outputed as
INSTALL
PLUGIN
."
790,137,mariadb-dump,"â¢   plugins - active plugins of the server outputed as
INSTALL
PLUGIN
. â¢   udfs - user define functions outputed as
CREATE FUNCTION
. â¢   servers - remote (federated) servers as
CREATE SERVER
."
790,138,mariadb-dump,"â¢   servers - remote (federated) servers as
CREATE SERVER
. â¢   stats - statistics tables, InnoDB and Engine Independent
               Table Statistics (EITS), are dumped as
REPLACE INTO
(or
INSERT IGNORE
if
--insert-ignore
is specified) statements
               without (re)creating tables. â¢   timezones - timezone related system tables dumped as
REPLACE INTO
(or
INSERT IGNORE
if
--insert-ignore
is
               specified) statements without (re)creating tables."
790,139,mariadb-dump,"â¢   timezones - timezone related system tables dumped as
REPLACE INTO
(or
INSERT IGNORE
if
--insert-ignore
is
               specified) statements without (re)creating tables. The format of the output is affected by
--replace
and
--insert-ignore
. The
--replace
option will output
CREATE OR
REPLACE
forms of SQL, and also
DROP IF EXISTS
prior to
CREATE
,
           if a
CREATE OR REPLACE
option isn't available."
790,140,mariadb-dump,"The
--replace
option will output
CREATE OR
REPLACE
forms of SQL, and also
DROP IF EXISTS
prior to
CREATE
,
           if a
CREATE OR REPLACE
option isn't available. With
--system=user
(or
all
), and
--replace
, SQL is generated
           to generate an error if attempting to import the dump with a
           connection user that is being replaced within the dump. The
--insert-ignore
option will cause
CREATE IF NOT EXIST
forms of SQL to generated if available."
790,141,mariadb-dump,"The
--insert-ignore
option will cause
CREATE IF NOT EXIST
forms of SQL to generated if available. For stats, and timezones,
--replace
and
--insert-ignore
have
           the usual effects. Enabling specific options here will cause the relevant tables
           in the mysql database to be ignored when dumping the mysql
           database or
--all-databases
."
790,142,mariadb-dump,"Enabling specific options here will cause the relevant tables
           in the mysql database to be ignored when dumping the mysql
           database or
--all-databases
. To help in migrating from MySQL to MariaDB, this option is
           designed to be able to dump system information from MySQL-5.7
           and 8.0 servers. SQL generated is also experimentally
           compatible with MySQL-5.7/8.0."
790,143,mariadb-dump,"SQL generated is also experimentally
           compatible with MySQL-5.7/8.0. Mappings of implementation
           specific grants/plugins isn't always one-to-one however
           between MariaDB and MySQL and will require manual changes. â¢
--tab=
path
,
-T
path
Produce tab-separated text-format data files."
790,144,mariadb-dump,"â¢
--tab=
path
,
-T
path
Produce tab-separated text-format data files. For each dumped
           table,
mariadb-dump
creates a
tbl_name
.sql file that contains
           the CREATE TABLE statement that creates the table, and the
           server writes a
tbl_name
.txt file that contains its data. The
           option value is the directory in which to write the files."
790,145,mariadb-dump,"The
           option value is the directory in which to write the files. Note
This option should be used only when
mariadb-dump
is run
               on the same machine as the
mariadbd
server. You must have
               the FILE privilege, and the server must have permission to
               write files in the directory that you specify."
790,146,mariadb-dump,"You must have
               the FILE privilege, and the server must have permission to
               write files in the directory that you specify. By default, the .txt data files are formatted using tab
           characters between column values and a newline at the end of
           each line. The format can be specified explicitly using the
--fields-
xxx
and
--lines-terminated-by
options."
790,147,mariadb-dump,"The format can be specified explicitly using the
--fields-
xxx
and
--lines-terminated-by
options. Column values are converted to the character set specified by
           the
--default-character-set
option. â¢
--tables
Override the
--databases
or
-B
option."
790,148,mariadb-dump,"â¢
--tables
Override the
--databases
or
-B
option. mariadb-dump
regards
           all name arguments following the option as table names. â¢
--triggers
Include triggers for each dumped table in the output."
790,149,mariadb-dump,"â¢
--triggers
Include triggers for each dumped table in the output. This
           option is enabled by default; disable it with
--skip-triggers
. â¢
--tz-utc
This option enables TIMESTAMP columns to be dumped and
           reloaded between servers in different time zones."
790,150,mariadb-dump,"â¢
--tz-utc
This option enables TIMESTAMP columns to be dumped and
           reloaded between servers in different time zones. mariadb-
dump
sets its connection time zone to UTC and adds SET
           TIME_ZONE='+00:00' to the dump file. Without this option,
           TIMESTAMP columns are dumped and reloaded in the time zones
           local to the source and destination servers, which can cause
           the values to change if the servers are in different time
           zones."
790,151,mariadb-dump,"Without this option,
           TIMESTAMP columns are dumped and reloaded in the time zones
           local to the source and destination servers, which can cause
           the values to change if the servers are in different time
           zones. --tz-utc
also protects against changes due to daylight
           saving time. --tz-utc
is enabled by default."
790,152,mariadb-dump,"--tz-utc
is enabled by default. To disable it,
           use
--skip-tz-utc
. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server."
790,153,mariadb-dump,"â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does."
790,154,mariadb-dump,"Print more information about what the program
           does. â¢
--version
,
-V
Display version information and exit. â¢
--where='
where_condition
'
,
-w '
where_condition
'
Dump only rows selected by the given WHERE condition."
790,155,mariadb-dump,"â¢
--where='
where_condition
'
,
-w '
where_condition
'
Dump only rows selected by the given WHERE condition. Quotes
           around the condition are mandatory if it contains spaces or
           other characters that are special to your command interpreter. Examples:

               --where=""user='jimf'""
               -w""userid>1""
               -w""userid<1""

       â¢
--xml
,
-X
Write dump output as well-formed XML."
790,156,mariadb-dump,"Examples:

               --where=""user='jimf'""
               -w""userid>1""
               -w""userid<1""

       â¢
--xml
,
-X
Write dump output as well-formed XML. NULL, 'NULL', and Empty Values
: For a column named
column_name
, the NULL value, an empty string, and the string
           value 'NULL' are distinguished from one another in the output
           generated by this option as follows. âââââââââââââââââââââââââ¬âââââââââââââââââââââââââââââââââââââ
           â
Value
:                â
XML Representation
:                â
           âââââââââââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââ¤
           â NULL (
unknown value
)  â <field name=""
column_name
""          â
           â                       â xsi:nil=""true"" />                  â
           âââââââââââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââ¤
           â '' (
empty string
)     â <field name=""
column_name
""></field> â
           âââââââââââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââ¤
           â 'NULL' (
string value
) â <field                             â
           â                       â name=""
column_name
"">NULL</field>    â
           âââââââââââââââââââââââââ´âââââââââââââââââââââââââââââââââââââ

           The output from the
mariadb
client when run using the
--xml
option also follows the preceding rules."
790,157,mariadb-dump,"âââââââââââââââââââââââââ¬âââââââââââââââââââââââââââââââââââââ
           â
Value
:                â
XML Representation
:                â
           âââââââââââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââ¤
           â NULL (
unknown value
)  â <field name=""
column_name
""          â
           â                       â xsi:nil=""true"" />                  â
           âââââââââââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââ¤
           â '' (
empty string
)     â <field name=""
column_name
""></field> â
           âââââââââââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââ¤
           â 'NULL' (
string value
) â <field                             â
           â                       â name=""
column_name
"">NULL</field>    â
           âââââââââââââââââââââââââ´âââââââââââââââââââââââââââââââââââââ

           The output from the
mariadb
client when run using the
--xml
option also follows the preceding rules. (See the section
           called âMARIADB OPTIONSâ.)

           XML output from
mariadb-dump
includes the XML namespace, as
           shown here:

               shell>
mariadb-dump --xml -u root world City
<?xml version=""1.0""?>
               <mariadb-dump xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"">
               <database name=""world"">
               <table_structure name=""City"">
               <field Field=""ID"" Type=""int(11)"" Null=""NO"" Key=""PRI"" Extra=""auto_increment"" />
               <field Field=""Name"" Type=""char(35)"" Null=""NO"" Key="""" Default="""" Extra="""" />
               <field Field=""CountryCode"" Type=""char(3)"" Null=""NO"" Key="""" Default="""" Extra="""" />
               <field Field=""District"" Type=""char(20)"" Null=""NO"" Key="""" Default="""" Extra="""" />
               <field Field=""Population"" Type=""int(11)"" Null=""NO"" Key="""" Default=""0"" Extra="""" />
               <key Table=""City"" Non_unique=""0"" Key_name=""PRIMARY"" Seq_in_index=""1"" Column_name=""ID""
               Collation=""A"" Cardinality=""4079"" Null="""" Index_type=""BTREE"" Comment="""" />
               <options Name=""City"" Engine=""MyISAM"" Version=""10"" Row_format=""Fixed"" Rows=""4079""
               Avg_row_length=""67"" Data_length=""273293"" Max_data_length=""18858823439613951""
               Index_length=""43008"" Data_free=""0"" Auto_increment=""4080""
               Create_time=""2007-03-31 01:47:01"" Update_time=""2007-03-31 01:47:02""
               Collation=""latin1_swedish_ci"" Create_options="""" Comment="""" />
               </table_structure>
               <table_data name=""City"">
               <row>
               <field name=""ID"">1</field>
               <field name=""Name"">Kabul</field>
               <field name=""CountryCode"">AFG</field>
               <field name=""District"">Kabol</field>
               <field name=""Population"">1780000</field>
               </row>
... <row>
               <field name=""ID"">4079</field>
               <field name=""Name"">Rafah</field>
               <field name=""CountryCode"">PSE</field>
               <field name=""District"">Rafah</field>
               <field name=""Population"">92020</field>
               </row>
               </table_data>
               </database>
               </mariadb-dump>

       You can also set the following variables by using
--
var_name
=
value
syntax:

       â¢   max_allowed_packet

           The maximum size of the buffer for client/server
           communication."
790,158,mariadb-dump,"<row>
               <field name=""ID"">4079</field>
               <field name=""Name"">Rafah</field>
               <field name=""CountryCode"">PSE</field>
               <field name=""District"">Rafah</field>
               <field name=""Population"">92020</field>
               </row>
               </table_data>
               </database>
               </mariadb-dump>

       You can also set the following variables by using
--
var_name
=
value
syntax:

       â¢   max_allowed_packet

           The maximum size of the buffer for client/server
           communication. The maximum is 1GB. â¢   max_statement_time

           A query that has taken more than max_statement_time seconds
           will be aborted and the backup will fail."
790,159,mariadb-dump,"â¢   max_statement_time

           A query that has taken more than max_statement_time seconds
           will be aborted and the backup will fail. The argument will be
           treated as a decimal value with microsecond precision. A value
           of 0 (default) means no timeout."
790,160,mariadb-dump,"A value
           of 0 (default) means no timeout. The maximum timeout is
           31536000 seconds. â¢   net_buffer_length

           The initial size of the buffer for client/server
           communication."
790,161,mariadb-dump,"â¢   net_buffer_length

           The initial size of the buffer for client/server
           communication. When creating multiple-row INSERT statements
           (as with the
--extended-insert
or
--opt
option),
mariadb-dump
creates rows up to net_buffer_length length. If you increase
           this variable, you should also ensure that the
           net_buffer_length variable in the MariaDB server is at least
           this large."
790,162,mariadb-dump,"If you increase
           this variable, you should also ensure that the
           net_buffer_length variable in the MariaDB server is at least
           this large. A common use of
mariadb-dump
is for making a backup of an entire
       database:

           shell>
mariadb-dump
db_name
>
backup-file.sql
You can load the dump file back into the server like this:

           shell>
mariadb
db_name
<
backup-file.sql
Or like this:

           shell>
mariadb -e ""source
/path-to-backup/backup-file.sql
""
db_name
mariadb-dump
is also very useful for populating databases by
       copying data from one MariaDB server to another:

           shell>
mariadb-dump --opt
db_name
| mariadb --host=
remote_host
-C
db_name
It is possible to dump several databases with one command:

           shell>
mariadb-dump --databases
db_name1
[
db_name2
...] > my_databases.sql
To dump all databases, use the
--all-databases
option:

           shell>
mariadb-dump --all-databases > all_databases.sql
For InnoDB tables,
mariadb-dump
provides a way of making an online
       backup:

           shell>
mariadb-dump --all-databases --single-transaction > all_databases.sql
This backup acquires a global read lock on all tables (using FLUSH
       TABLES WITH READ LOCK) at the beginning of the dump. As soon as
       this lock has been acquired, the binary log coordinates are read
       and the lock is released."
790,163,mariadb-dump,"As soon as
       this lock has been acquired, the binary log coordinates are read
       and the lock is released. If long updating statements are running
       when the FLUSH statement is issued, the MariaDB server may get
       stalled until those statements finish. After that, the dump
       becomes lock free and does not disturb reads and writes on the
       tables."
790,164,mariadb-dump,"After that, the dump
       becomes lock free and does not disturb reads and writes on the
       tables. If the update statements that the MariaDB server receives
       are short (in terms of execution time), the initial lock period
       should not be noticeable, even with many updates. For point-in-time recovery (also known as âroll-forward,â when you
       need to restore an old backup and replay the changes that happened
       since that backup), it is often useful to rotate the binary log or
       at least know the binary log coordinates to which the dump
       corresponds:

           shell>
mariadb-dump --all-databases --master-data=2 > all_databases.sql
Or:

           shell>
mariadb-dump --all-databases --flush-logs --master-data=2
> all_databases.sql
The
--master-data
and
--single-transaction
options can be used
       simultaneously, which provides a convenient way to make an online
       backup suitable for use prior to point-in-time recovery if tables
       are stored using the InnoDB storage engine."
790,165,mariadb-dump,"If the update statements that the MariaDB server receives
       are short (in terms of execution time), the initial lock period
       should not be noticeable, even with many updates. For point-in-time recovery (also known as âroll-forward,â when you
       need to restore an old backup and replay the changes that happened
       since that backup), it is often useful to rotate the binary log or
       at least know the binary log coordinates to which the dump
       corresponds:

           shell>
mariadb-dump --all-databases --master-data=2 > all_databases.sql
Or:

           shell>
mariadb-dump --all-databases --flush-logs --master-data=2
> all_databases.sql
The
--master-data
and
--single-transaction
options can be used
       simultaneously, which provides a convenient way to make an online
       backup suitable for use prior to point-in-time recovery if tables
       are stored using the InnoDB storage engine. If you encounter problems backing up views, please read the
       section that covers restrictions on views which describes a
       workaround for backing up views when this fails due to
       insufficient privileges."
791,0,mariadb-find-rows,"mariadb-find-rows
reads files containing SQL statements and
       extracts statements that match a given regular expression or that
       contain USE
db_name
or SET statements. The utility was written for
       use with update log files (as used prior to MySQL 5.0) and as such
       expects statements to be terminated with semicolon (;) characters. It may be useful with other files that contain SQL statements as
       long as statements are terminated with semicolons."
791,1,mariadb-find-rows,"It may be useful with other files that contain SQL statements as
       long as statements are terminated with semicolons. Invoke
mariadb-find-rows
like this:

           shell>
mariadb-find-rows [
options
] [
file_name
...]
Each
file_name
argument should be the name of file containing SQL
       statements. If no file names are given,
mariadb-find-rows
reads
       the standard input."
791,2,mariadb-find-rows,"If no file names are given,
mariadb-find-rows
reads
       the standard input. Examples:

           mariadb-find-rows --regexp=problem_table --rows=20 < update.log
           mariadb-find-rows --regexp=problem_table  update-log.1 update-log.2
mariadb-find-rows
supports the following options:

       â¢
--help
,
--Information
Display a help message and exit. â¢
--regexp=
pattern
Display queries that match the pattern."
791,3,mariadb-find-rows,"â¢
--regexp=
pattern
Display queries that match the pattern. â¢
--rows=
N
Quit after displaying
N
queries. â¢
--skip-use-db
Do not include USE
db_name
statements in the output."
791,4,mariadb-find-rows,"â¢
--rows=
N
Quit after displaying
N
queries. â¢
--skip-use-db
Do not include USE
db_name
statements in the output. â¢
--start_row=
N
Start output from this row."
792,0,mariadb-hotcopy,"mariadb-hotcopy
is a Perl script that was originally written and
       contributed by Tim Bunce. It uses FLUSH TABLES, LOCK TABLES, and
       cp or scp to make a database backup. It is a fast way to make a
       backup of the database or single tables, but it can be run only on
       the same machine where the database directories are located."
792,1,mariadb-hotcopy,"It is a fast way to make a
       backup of the database or single tables, but it can be run only on
       the same machine where the database directories are located. mariadb-hotcopy
works only for backing up MyISAM and ARCHIVE
       tables. It runs on Unix and NetWare."
792,2,mariadb-hotcopy,"It runs on Unix and NetWare. To use
mariadb-hotcopy
, you must have read access to the files for
       the tables that you are backing up, the SELECT privilege for those
       tables, the RELOAD privilege (to be able to execute FLUSH TABLES),
       and the LOCK TABLES privilege (to be able to lock the tables). shell>
mariadb-hotcopy
db_name
[
/path/to/new_directory
]
shell>
mariadb-hotcopy
db_name_1
..."
792,3,mariadb-hotcopy,"shell>
mariadb-hotcopy
db_name
[
/path/to/new_directory
]
shell>
mariadb-hotcopy
db_name_1
... db_name_n /path/to/new_directory
Back up tables in the given database that match a regular
       expression:

           shell>
mariadb-hotcopy
db_name
./
regex
/
The regular expression for the table name can be negated by
       prefixing it with a tilde (â~â):

           shell>
mariadb-hotcopy
db_name
./~
regex
/
mariadb-hotcopy
supports the following options, which can be
       specified on the command line or in the [mariadb-hotcopy] and
       [client] option file groups. â¢
--help
,
-?"
792,4,mariadb-hotcopy,"â¢
--help
,
-? Display a help message and exit. â¢
--addtodest
Do not rename target directory (if it exists); merely add
           files to it."
792,5,mariadb-hotcopy,"â¢
--addtodest
Do not rename target directory (if it exists); merely add
           files to it. â¢
--allowold
Do not abort if a target exists; rename it by adding an _old
           suffix. â¢
--checkpoint=
db_name
."
792,6,mariadb-hotcopy,"â¢
--checkpoint=
db_name
. tbl_name
Insert checkpoint entries into the specified database
db_name
and table
tbl_name
. â¢
--chroot=
path
Base directory of the
chroot
jail in which
mariadbd
operates."
792,7,mariadb-hotcopy,"â¢
--chroot=
path
Base directory of the
chroot
jail in which
mariadbd
operates. The
path
value should match that of the
--chroot
option given
           to
mariadbd
. â¢
--debug
Enable debug output."
792,8,mariadb-hotcopy,"â¢
--debug
Enable debug output. â¢
--dryrun
,
-n
Report actions without performing them. â¢
--flushlog
Flush logs after all tables are locked."
792,9,mariadb-hotcopy,"â¢
--flushlog
Flush logs after all tables are locked. â¢
--host=
host_name
,
-h
host_name
The host name of the local host to use for making a TCP/IP
           connection to the local server. By default, the connection is
           made to localhost using a Unix socket file."
792,10,mariadb-hotcopy,"By default, the connection is
           made to localhost using a Unix socket file. â¢
--keepold
Do not delete previous (renamed) target when done. â¢
--method=
command
The method for copying files (cp or scp)."
792,11,mariadb-hotcopy,"â¢
--method=
command
The method for copying files (cp or scp). The default is cp. â¢
--noindices
Do not include full index files for MyISAM tables in the
           backup."
792,12,mariadb-hotcopy,"â¢
--noindices
Do not include full index files for MyISAM tables in the
           backup. This makes the backup smaller and faster. The indexes
           for reloaded tables can be reconstructed later with
myisamchk
-rq
."
792,13,mariadb-hotcopy,"The indexes
           for reloaded tables can be reconstructed later with
myisamchk
-rq
. â¢
--old-server
Connect to old MySQL-server (before v5.5) which doesn't have
           FLUSH TABLES WITH READ LOCK fully implemented.. â¢
--password=
password
,
-p
password
The password to use when connecting to the server."
792,14,mariadb-hotcopy,"â¢
--password=
password
,
-p
password
The password to use when connecting to the server. The
           password value is not optional for this option, unlike for
           other MariaDB programs. Specifying a password on the command line should be considered
           insecure."
792,15,mariadb-hotcopy,"Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use when connecting to the local
           server."
792,16,mariadb-hotcopy,"â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use when connecting to the local
           server. â¢
--quiet
,
-q
Be silent except for errors. â¢
--record_log_pos=
db_name
."
792,17,mariadb-hotcopy,"â¢
--record_log_pos=
db_name
. tbl_name
Record master and slave status in the specified database
db_name
and table
tbl_name
. â¢
--regexp=
expr
Copy all databases with names that match the given regular
           expression."
792,18,mariadb-hotcopy,"â¢
--regexp=
expr
Copy all databases with names that match the given regular
           expression. â¢
--resetmaster
Reset the binary log after locking all the tables. â¢
--resetslave
Reset the master.info file after locking all the tables."
792,19,mariadb-hotcopy,"â¢
--resetslave
Reset the master.info file after locking all the tables. â¢
--socket=
path
,
-S
path
The Unix socket file to use for connections to localhost. â¢
--suffix=
str
The suffix to use for names of copied databases."
792,20,mariadb-hotcopy,"â¢
--suffix=
str
The suffix to use for names of copied databases. â¢
--tmpdir=
path
The temporary directory. The default is /tmp."
792,21,mariadb-hotcopy,"The default is /tmp. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. Use perldoc for additional
mariadb-hotcopy
documentation,
       including information about the structure of the tables needed for
       the
--checkpoint
and
--record_log_pos
options:

           shell>
perldoc mariadb-hotcopy"
793,0,mariadb-fix-extensions,"This script is deprecated and will be removed in a later release. mariadb-fix-extensions
converts the extensions for MyISAM (or
       ISAM) table files to their canonical forms. It looks for files
       with extensions matching any lettercase variant of .frm, .myd,
       .myi, .isd, and .ism and renames them to have extensions of .frm,
       .MYD, .MYI, .ISD, and .ISM, respectively."
793,1,mariadb-fix-extensions,"It looks for files
       with extensions matching any lettercase variant of .frm, .myd,
       .myi, .isd, and .ism and renames them to have extensions of .frm,
       .MYD, .MYI, .ISD, and .ISM, respectively. This can be useful after
       transferring the files from a system with case-insensitive file
       names (such as Windows) to a system with case-sensitive file
       names. Invoke
mariadb-fix-extensions
like this, where
data_dir
is the
       path name to the MariaDB data directory."
793,2,mariadb-fix-extensions,"This can be useful after
       transferring the files from a system with case-insensitive file
       names (such as Windows) to a system with case-sensitive file
       names. Invoke
mariadb-fix-extensions
like this, where
data_dir
is the
       path name to the MariaDB data directory. shell>
mariadb-fix-extensions
data_dir"
794,0,mariadb-install-db,"mariadb-install-db
initializes the MariaDB data directory and
       creates the system tables that it contains, if they do not exist. To invoke
mariadb-install-db
, use the following syntax:

           shell>
mariadb-install-db [
options
]
Because the MariaDB server,
mariadbd
, needs to access the data
       directory when it runs later, you should either run
mariadb-
install-db
from the same account that will be used for running
mariadbd
or run it as root and use the
--user
option to indicate
       the user name that
mariadbd
will run as. It might be necessary to
       specify other options such as
--basedir
or
--datadir
if
mariadb-
install-db
does not use the correct locations for the installation
       directory or data directory."
794,1,mariadb-install-db,"It might be necessary to
       specify other options such as
--basedir
or
--datadir
if
mariadb-
install-db
does not use the correct locations for the installation
       directory or data directory. For example:

           shell>
bin/mariadb-install-db --user=mysql \
--basedir=/opt/mysql/mysql \
--datadir=/opt/mysql/mysql/data
mariadb-install-db
needs to invoke
mariadbd
with the
--bootstrap
and
--skip-grant-tables
options (see Section 2.3.2, âTypical
       configure Optionsâ). If MariaDB was configured with the
--disable-grant-options
option,
--bootstrap
and
--skip-grant-tables
will be disabled."
794,2,mariadb-install-db,"If MariaDB was configured with the
--disable-grant-options
option,
--bootstrap
and
--skip-grant-tables
will be disabled. To handle this, set the
       mariadbd_BOOTSTRAP environment variable to the full path name of a
       server that has all options enabled. mariadb-install-db
will use
       that server."
794,3,mariadb-install-db,"mariadb-install-db
will use
       that server. mariadb-install-db
supports the following options, which can be
       specified on the command line or in the [mariadb-install-db] and
       (if they are common to
mariadbd
) [mariadbd] option file groups. â¢
--basedir=
path
The path to the MariaDB installation directory."
794,4,mariadb-install-db,"â¢
--basedir=
path
The path to the MariaDB installation directory. â¢
--builddir=
path
If using
--srcdir
with out-of-directory builds, you will need
           to set this to the location of the build directory where built
           files reside.. â¢
--cross-bootstrap
For internal use."
794,5,mariadb-install-db,"â¢
--cross-bootstrap
For internal use. Used when building the MariaDB system tables
           on a different host than the target.. â¢
--datadir=
path
,
--ldata=
path
The path to the MariaDB data directory."
794,6,mariadb-install-db,"â¢
--datadir=
path
,
--ldata=
path
The path to the MariaDB data directory. â¢
--defaults-extra-file=
filename
Set
filename
as the file to read default options from after
           the global defaults files has been read. Must be given as
           first option."
794,7,mariadb-install-db,"Must be given as
           first option. â¢
--defaults-file=
filename
Set
filename
as the file to read default options from,
           override global defaults files. Must be given as first
           option."
794,8,mariadb-install-db,"Must be given as first
           option. â¢
--defaults-group-suffix=
name
In addition to the given groups, also read groups with this
           suffix. â¢
--force
Cause
mariadb-install-db
to run even if DNS does not work."
794,9,mariadb-install-db,"â¢
--force
Cause
mariadb-install-db
to run even if DNS does not work. In
           that case, grant table entries that normally use host names
           will use IP addresses. â¢
--help
Display a help message and exit."
794,10,mariadb-install-db,"â¢
--help
Display a help message and exit. â¢
--no-defaults
Do not read default options from any option file. This must be
           given as the first argument."
794,11,mariadb-install-db,"This must be
           given as the first argument. â¢
--print-defaults
Print the program argument list and exit. This must be given
           as the first argument."
794,12,mariadb-install-db,"This must be given
           as the first argument. â¢
--rpm
For internal use. This option is used by RPM files during the
           MariaDB installation process."
794,13,mariadb-install-db,"This option is used by RPM files during the
           MariaDB installation process. â¢
--skip-name-resolve
Use IP addresses rather than host names when creating grant
           table entries. This option can be useful if your DNS does not
           work."
794,14,mariadb-install-db,"This option can be useful if your DNS does not
           work. â¢
--srcdir=
path
For internal use. The directory under which
mariadb-install-db
looks for support files such as the error message file and the
           file for populating the help tables.4."
794,15,mariadb-install-db,"The directory under which
mariadb-install-db
looks for support files such as the error message file and the
           file for populating the help tables.4. â¢
--user=
user_name
The login user name to use for running
mariadbd
. Files and
           directories created by
mariadbd
will be owned by this user."
794,16,mariadb-install-db,"Files and
           directories created by
mariadbd
will be owned by this user. You must be root to use this option. By default,
mariadbd
runs
           using your current login name and files and directories that
           it creates will be owned by you."
794,17,mariadb-install-db,"By default,
mariadbd
runs
           using your current login name and files and directories that
           it creates will be owned by you. â¢
--extra-file=
file_path
Add user defined SQL file, to be executed following regular
           database initialization. â¢
--verbose
Verbose mode."
794,18,mariadb-install-db,"â¢
--verbose
Verbose mode. Print more information about what the program
           does. â¢
--windows
For internal use."
794,19,mariadb-install-db,"Print more information about what the program
           does. â¢
--windows
For internal use. This option is used for creating Windows
           distributions."
795,0,mariadb-plugin,"The
mariadb-plugin
utility enables MariaDB administrators to
       manage which plugins a MariaDB server loads. It provides an
       alternative to manually specifying the
--plugin-load
option at
       server startup or using the INSTALL PLUGIN and UNINSTALL PLUGIN
       statements at runtime. Depending on whether
mariadb-plugin
is invoked to enable or
       disable plugins, it inserts or deletes rows in the mysql.plugin
       table that serves as a plugin registry."
795,1,mariadb-plugin,"Depending on whether
mariadb-plugin
is invoked to enable or
       disable plugins, it inserts or deletes rows in the mysql.plugin
       table that serves as a plugin registry. (To perform this
       operation,
mariadb-plugin
invokes the MariaDB server in bootstrap
       mode. This means that the server must not already be running.) For
       normal server startups, the server loads and enables plugins
       listed in mysql.plugin automatically."
795,2,mariadb-plugin,"This means that the server must not already be running.) For
       normal server startups, the server loads and enables plugins
       listed in mysql.plugin automatically. For additional control over
       plugin activation, use
--
plugin_name
options named for specific
       plugins. Each invocation of
mariadb-plugin
reads a configuration file to
       determine how to configure the plugins contained in a single
       plugin library object file."
795,3,mariadb-plugin,"Each invocation of
mariadb-plugin
reads a configuration file to
       determine how to configure the plugins contained in a single
       plugin library object file. To invoke
mariadb-plugin
, use this
       syntax:

           mariadb-plugin [
options
]
plugin
{ENABLE|DISABLE}
plugin
is the name of the plugin to configure. ENABLE or DISABLE
       (not case sensitive) specify whether to enable or disable
       components of the plugin library named in the configuration file."
795,4,mariadb-plugin,"ENABLE or DISABLE
       (not case sensitive) specify whether to enable or disable
       components of the plugin library named in the configuration file. The order of the
plugin
and ENABLE or DISABLE arguments does not
       matter. For example, to configure components of a plugin library file
       named myplugins.so on Linux or myplugins.dll on Windows, specify a
plugin
value of myplugins."
795,5,mariadb-plugin,"For example, to configure components of a plugin library file
       named myplugins.so on Linux or myplugins.dll on Windows, specify a
plugin
value of myplugins. Suppose that this plugin library
       contains three plugins, plugin1, plugin2, and plugin3, all of
       which should be configured under
mariadb-plugin
control. By
       convention, configuration files have a suffix of .ini and the same
       basename as the plugin library, so the default configuration file
       name for this plugin library is myplugins.ini."
795,6,mariadb-plugin,"By
       convention, configuration files have a suffix of .ini and the same
       basename as the plugin library, so the default configuration file
       name for this plugin library is myplugins.ini. The configuration
       file contents look like this:

           myplugins
           plugin1
           plugin2
           plugin3

       The first line in the myplugins.ini file is the name of the
       library object file, without any extension such as .so or .dll. The remaining lines are the names of the components to be enabled
       or disabled."
795,7,mariadb-plugin,"The remaining lines are the names of the components to be enabled
       or disabled. Each value in the file should be on a separate line. Lines on which the first character is '#' are taken as comments
       and ignored."
795,8,mariadb-plugin,"Lines on which the first character is '#' are taken as comments
       and ignored. To enable the plugins listed in the configuration file, invoke
mariadb-plugin
this way:

           shell>
mariadb-plugin myplugins ENABLE
To disable the plugins, use DISABLE rather than ENABLE. An error occurs if
mariadb-plugin
cannot find the configuration
       file or plugin library file, or if
mariadb-plugin
cannot start the
       MariaDB server."
795,9,mariadb-plugin,"An error occurs if
mariadb-plugin
cannot find the configuration
       file or plugin library file, or if
mariadb-plugin
cannot start the
       MariaDB server. mariadb-plugin
supports the following options, which can be
       specified on the command line or in the [mariadbd] group of any
       option file. For options specified in a [mariadbd] group,
mariadb-
plugin
recognizes the
--basedir
,
--datadir
, and
--plugin-dir
options and ignores others."
795,10,mariadb-plugin,"For options specified in a [mariadbd] group,
mariadb-
plugin
recognizes the
--basedir
,
--datadir
, and
--plugin-dir
options and ignores others. mariadb-plugin Options

       â¢
--help
,
-? Display a help message and exit."
795,11,mariadb-plugin,"Display a help message and exit. â¢
--basedir=
path
,
-b
path
The server base directory. â¢
--datadir=
path
,
-d
path
The server data directory."
795,12,mariadb-plugin,"â¢
--datadir=
path
,
-d
path
The server data directory. â¢
--my-print-defaults=
path
,
-b
path
The path to the
my_print_defaults
program. â¢
--mariadbd=
path
,
-b
path
The path to the
mariadbd
server."
795,13,mariadb-plugin,"â¢
--mariadbd=
path
,
-b
path
The path to the
mariadbd
server. â¢
--no-defaults
,
-p
Do not read values from the configuration file. This option
           enables an administrator to skip reading defaults from the
           configuration file."
795,14,mariadb-plugin,"This option
           enables an administrator to skip reading defaults from the
           configuration file. With
mariadb-plugin
, this option need not be given first on
           the command line, unlike most other MariaDB programs that
           support
--no-defaults
. â¢
--plugin-dir=
path
,
-p
path
The server plugin directory."
795,15,mariadb-plugin,"â¢
--plugin-dir=
path
,
-p
path
The server plugin directory. â¢
--plugin-ini=
file_name
,
-i
file_name
The
mariadb-plugin
configuration file. Relative path names are
           interpreted relative to the current directory."
795,16,mariadb-plugin,"Relative path names are
           interpreted relative to the current directory. If this option
           is not given, the default is
plugin
.ini in the plugin
           directory, where
plugin
is the
plugin
argument on the command
           line. â¢
--print-defaults
,
-P
Display the default values from the configuration file."
795,17,mariadb-plugin,"â¢
--print-defaults
,
-P
Display the default values from the configuration file. This
           option causes
mariadb-plugin
to print the defaults for
--basedir
,
--datadir
, and
--plugin-dir
if they are found in
           the configuration file. If no value for a variable is found,
           nothing is shown."
795,18,mariadb-plugin,"If no value for a variable is found,
           nothing is shown. With
mariadb-plugin
, this option need not be given first on
           the command line, unlike most other MariaDB programs that
           support
--print-defaults
. â¢
--verbose
,
-v
Verbose mode."
795,19,mariadb-plugin,"â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does. This option can be used multiple times to increase the
           amount of information."
795,20,mariadb-plugin,"Print more information about what the program
           does. This option can be used multiple times to increase the
           amount of information. â¢
--version
,
-V
Display version information and exit."
796,0,mariadb-import,"The
mariadb-import
client provides a command-line interface to the
       LOAD DATA INFILE SQL statement. Most options to
mariadb-import
correspond directly to clauses of LOAD DATA INFILE syntax. Invoke
mariadb-import
like this:

           shell>
mariadb-import [
options
]
db_name textfile1
[
textfile2
...]
For each text file named on the command line,
mariadb-import
strips any extension from the file name and uses the result to
       determine the name of the table into which to import the file's
       contents."
796,1,mariadb-import,"Invoke
mariadb-import
like this:

           shell>
mariadb-import [
options
]
db_name textfile1
[
textfile2
...]
For each text file named on the command line,
mariadb-import
strips any extension from the file name and uses the result to
       determine the name of the table into which to import the file's
       contents. For example, files named patient.txt, patient.text, and
       patient all would be imported into a table named patient. mariadb-import
supports the following options, which can be
       specified on the command line or in the [mariadb-import] and
       [client] option file groups."
796,2,mariadb-import,"mariadb-import
supports the following options, which can be
       specified on the command line or in the [mariadb-import] and
       [client] option file groups. mariadb-import
also supports the
       options for processing option files. â¢
--help
,
-?"
796,3,mariadb-import,"â¢
--help
,
-? Display a help message and exit. â¢
--character-sets-dir=
path
The directory where character sets are installed."
796,4,mariadb-import,"â¢
--character-sets-dir=
path
The directory where character sets are installed. â¢
--columns=
column_list
,
-c
column_list
This option takes a comma-separated list of column names as
           its value. The order of the column names indicates how to
           match data file columns with table columns."
796,5,mariadb-import,"The order of the column names indicates how to
           match data file columns with table columns. â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression. â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log."
796,6,mariadb-import,"â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log. A typical
debug_options
string is
           'd:t:o,
file_name
'. The default is 'd:t:o'."
796,7,mariadb-import,"The default is 'd:t:o'. â¢
--debug-check
Print some debugging information when the program exits. â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits."
796,8,mariadb-import,"â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--default-auth=
plugin_name
Default authentication client-side plugin to use. â¢
--default-character-set=
charset_name
Use
charset_name
as the default character set."
796,9,mariadb-import,"â¢
--default-character-set=
charset_name
Use
charset_name
as the default character set. â¢
--defaults-extra-file=
filename
Set
filename
as the file to read default options from after
           the global defaults files has been read. Must be given as
           first option."
796,10,mariadb-import,"Must be given as
           first option. â¢
--defaults-file=
filename
Set
filename
as the file to read default options from,
           override global defaults files. Must be given as first
           option."
796,11,mariadb-import,"Must be given as first
           option. â¢
--delete
,
-d
Empty the table before importing the text file. â¢
--fields-terminated-by=..."
796,12,mariadb-import,"â¢
--fields-terminated-by=... ,
--fields-enclosed-by=... ,
--fields-optionally-enclosed-by=..."
796,13,mariadb-import,",
--fields-optionally-enclosed-by=... ,
--fields-escaped-by=... These options have the same meaning as the corresponding
           clauses for LOAD DATA INFILE."
796,14,mariadb-import,"These options have the same meaning as the corresponding
           clauses for LOAD DATA INFILE. â¢
--force
,
-f
Ignore errors. For example, if a table for a text file does
           not exist, continue processing any remaining files."
796,15,mariadb-import,"For example, if a table for a text file does
           not exist, continue processing any remaining files. Without
--force
,
mariadb-import
exits if a table does not exist. â¢
--host=
host_name
,
-h
host_name
Import data to the MariaDB server on the given host."
796,16,mariadb-import,"â¢
--host=
host_name
,
-h
host_name
Import data to the MariaDB server on the given host. The
           default host is localhost. â¢
--ignore
,
-i
See the description for the
--replace
option."
796,17,mariadb-import,"â¢
--ignore
,
-i
See the description for the
--replace
option. â¢
--ignore-foreign-keys
,
-k
Disable foreign key checks while importing the data. â¢
--ignore-lines=
N
Ignore the first
N
lines of the data file."
796,18,mariadb-import,"â¢
--ignore-lines=
N
Ignore the first
N
lines of the data file. â¢
--lines-terminated-by=... This option has the same meaning as the corresponding clause
           for LOAD DATA INFILE."
796,19,mariadb-import,"This option has the same meaning as the corresponding clause
           for LOAD DATA INFILE. For example, to import Windows files
           that have lines terminated with carriage return/linefeed
           pairs, use
--lines-terminated-by=""\r\n""
. (You might have to
           double the backslashes, depending on the escaping conventions
           of your command interpreter.)."
796,20,mariadb-import,"(You might have to
           double the backslashes, depending on the escaping conventions
           of your command interpreter.). â¢
--local
,
-L
Read input files locally from the client host. â¢
--lock-tables
,
-l
Lock
all
tables for writing before processing any text files."
796,21,mariadb-import,"â¢
--lock-tables
,
-l
Lock
all
tables for writing before processing any text files. This ensures that all tables are synchronized on the server. â¢
--low-priority
Use LOW_PRIORITY when loading the table."
796,22,mariadb-import,"â¢
--low-priority
Use LOW_PRIORITY when loading the table. This affects only
           storage engines that use only table-level locking (such as
           MyISAM, MEMORY, and MERGE). â¢
--no-defaults
Do not read default options from any option file."
796,23,mariadb-import,"â¢
--no-defaults
Do not read default options from any option file. This must be
           given as the first argument. â¢
--parallel=
N
,
-j
N
Number of LOAD DATA jobs executed in parallel."
796,24,mariadb-import,"â¢
--parallel=
N
,
-j
N
Number of LOAD DATA jobs executed in parallel. --use-threads
           is a synonym. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server."
796,25,mariadb-import,"â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-import
prompts for one."
796,26,mariadb-import,"If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-import
prompts for one. Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line."
796,27,mariadb-import,"You can use an option file to avoid giving the
           password on the command line. â¢
--pipe
,
-W
On Windows, connect to the server via a named pipe. This
           option applies only if the server supports named-pipe
           connections."
796,28,mariadb-import,"This
           option applies only if the server supports named-pipe
           connections. â¢
--plugin-dir=
name
Directory for client-side plugins. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection."
796,29,mariadb-import,"â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection. Forces
           --protocol=tcp when specified on the command line without
           other connection properties. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server."
796,30,mariadb-import,"â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--print-defaults
Print the program argument list and exit."
796,31,mariadb-import,"â¢
--print-defaults
Print the program argument list and exit. This must be given
           as the first argument. â¢
--replace
,
-r
The
--replace
and
--ignore
options control handling of input
           rows that duplicate existing rows on unique key values."
796,32,mariadb-import,"â¢
--replace
,
-r
The
--replace
and
--ignore
options control handling of input
           rows that duplicate existing rows on unique key values. If you
           specify
--replace
, new rows replace existing rows that have
           the same unique key value. If you specify
--ignore
, input rows
           that duplicate an existing row on a unique key value are
           skipped."
796,33,mariadb-import,"If you specify
--ignore
, input rows
           that duplicate an existing row on a unique key value are
           skipped. If you do not specify either option, an error occurs
           when a duplicate key value is found, and the rest of the text
           file is ignored. â¢
--silent
,
-s
Silent mode."
796,34,mariadb-import,"â¢
--silent
,
-s
Silent mode. Produce output only when errors occur. â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use."
796,35,mariadb-import,"â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe. â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags)."
796,36,mariadb-import,"â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags). Disable with
--skip-ssl
. â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
)."
796,37,mariadb-import,"â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
)."
796,38,mariadb-import,"â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
). â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
)."
796,39,mariadb-import,"â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
)."
796,40,mariadb-import,"â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
). â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting. This option is disabled by default."
796,41,mariadb-import,"This option is disabled by default. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
--use-threads=
N
Load files in parallel using
N
threads."
796,42,mariadb-import,"â¢
--use-threads=
N
Load files in parallel using
N
threads. Synonym for -j,
           --parallel=num

       â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does."
796,43,mariadb-import,"Print more information about what the program
           does. â¢
--version
,
-V
Display version information and exit. Here is a sample session that demonstrates use of
mariadb-import
:

           shell>
mariadb -e 'CREATE TABLE imptest(id INT, n VARCHAR(30))' test
shell>
ed
a
           100     Max Sydow
           101     Count Dracula
           ."
796,44,mariadb-import,"â¢
--version
,
-V
Display version information and exit. Here is a sample session that demonstrates use of
mariadb-import
:

           shell>
mariadb -e 'CREATE TABLE imptest(id INT, n VARCHAR(30))' test
shell>
ed
a
           100     Max Sydow
           101     Count Dracula
           . w imptest.txt
           32
           q
           shell>
od -c imptest.txt
0000000   1   0   0  \t   M   a   x       S   y   d   o   w  \n   1   0
           0000020   1  \t   C   o   u   n   t       D   r   a   c   u   l   a  \n
           0000040
           shell>
mariadb-import --local test imptest.txt
test.imptest: Records: 2  Deleted: 0  Skipped: 0  Warnings: 0
           shell>
mariadb -e 'SELECT * FROM imptest' test
+------+---------------+
           | id   | n             |
           +------+---------------+
           |  100 | Max Sydow     |
           |  101 | Count Dracula |
           +------+---------------+"
797,0,mariadb-secure-installation,"This program enables you to improve the security of your MariaDB
       installation in the following ways:

       â¢   You can set a password for root accounts. â¢   You can remove root accounts that are accessible from outside
           the local host. â¢   You can remove anonymous-user accounts."
797,1,mariadb-secure-installation,"â¢   You can remove anonymous-user accounts. â¢   You can remove the test database, which by default can be
           accessed by anonymous users. mariadb-secure-installation
can be invoked without arguments:

           shell>
mariadb-secure-installation
The script will prompt you to determine which actions to perform."
797,2,mariadb-secure-installation,"mariadb-secure-installation
can be invoked without arguments:

           shell>
mariadb-secure-installation
The script will prompt you to determine which actions to perform. mariadb-secure-installation
accepts some options:

       â¢
--basedir=
dir_name
Base directory. â¢
--defaults-extra-file=
file_name
Additional option file."
797,3,mariadb-secure-installation,"â¢
--defaults-extra-file=
file_name
Additional option file. â¢
--defaults-file=
file_name
Option file. â¢
--no-defaults
Don't read any defaults file."
797,4,mariadb-secure-installation,"â¢
--defaults-file=
file_name
Option file. â¢
--no-defaults
Don't read any defaults file. Other unrecognized options will be passed on to the server."
798,0,mariadb,"mariadb
is a simple SQL shell (with GNU readline capabilities). It
       supports interactive and non-interactive use. When used
       interactively, query results are presented in an ASCII-table
       format."
798,1,mariadb,"When used
       interactively, query results are presented in an ASCII-table
       format. When used non-interactively (for example, as a filter),
       the result is presented in tab-separated format. The output format
       can be changed using command options."
798,2,mariadb,"The output format
       can be changed using command options. If you have problems due to insufficient memory for large result
       sets, use the
--quick
option. This forces
mariadb
to retrieve
       results from the server a row at a time rather than retrieving the
       entire result set and buffering it in memory before displaying it."
798,3,mariadb,"This forces
mariadb
to retrieve
       results from the server a row at a time rather than retrieving the
       entire result set and buffering it in memory before displaying it. This is done by returning the result set using the
       mariadb_use_result() C API function in the client/server library
       rather than mysql_store_result(). Using
mariadb
is very easy."
798,4,mariadb,"Using
mariadb
is very easy. Invoke it from the prompt of your
       command interpreter as follows:

           shell>
mariadb
db_name
Or:

           shell>
mariadb --user=
user_name
--password=
your_password db_name
Then type an SQL statement, end it with â;â, \g, or \G and press
       Enter. Typing Control-C causes
mariadb
to attempt to kill the current
       statement."
798,5,mariadb,"Typing Control-C causes
mariadb
to attempt to kill the current
       statement. If this cannot be done, or Control-C is typed again
       before the statement is killed,
mariadb
exits. You can execute SQL statements in a script file (batch file) like
       this:

           shell>
mariadb
db_name
<
script.sql
>
output.tab"
799,0,mariadb-service-convert,"Use: Generate a mariadb.service file based on the current mariadb
       settings.  This is to assist distro maintainers in migrating to
       systemd service definations from a user mariadbd-safe settings in
       the my.cnf files.

       Redirect output to user directory like
       /etc/systemd/system/mariadb.service.d/migrated-from-my.cnf-
       settings.conf

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
800,0,mariadb-setpermission,"mariadb-setpermission
is a Perl script that was originally written
       and contributed by Luuk de Boer. It interactively sets permissions
       in the MariaDB grant tables. mariadb-setpermission
is written in
       Perl and requires that the DBI and DBD::MariaDB Perl modules be
       installed."
800,1,mariadb-setpermission,"mariadb-setpermission
is written in
       Perl and requires that the DBI and DBD::MariaDB Perl modules be
       installed. Invoke
mariadb-setpermission
like this:

           shell>
mariadb-setpermission [
options
]
options
should be either
--help
to display the help message, or
       options that indicate how to connect to the MariaDB server. The
       account used when you connect determines which permissions you
       have when attempting to modify existing permissions in the grant
       tables."
800,2,mariadb-setpermission,"The
       account used when you connect determines which permissions you
       have when attempting to modify existing permissions in the grant
       tables. mariadb-setpermission
also reads options from the [client] and
       [perl] groups in the .my.cnf file in your home directory, if the
       file exists. mariadb-setpermission
supports the following options:

       â¢
--help
Display a help message and exit."
800,3,mariadb-setpermission,"mariadb-setpermission
supports the following options:

       â¢
--help
Display a help message and exit. â¢
--host=
host_name
Connect to the MariaDB server on the given host. â¢
--password=
password
The password to use when connecting to the server."
800,4,mariadb-setpermission,"â¢
--password=
password
The password to use when connecting to the server. Note that
           the password value is not optional for this option, unlike for
           other MariaDB programs. Specifying a password on the command line should be considered
           insecure."
800,5,mariadb-setpermission,"Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line. â¢
--port=
port_num
The TCP/IP port number to use for the connection."
800,6,mariadb-setpermission,"â¢
--port=
port_num
The TCP/IP port number to use for the connection. â¢
--socket=
path
For connections to localhost, the Unix socket file to use. â¢
--user=
user_name
The MariaDB user name to use when connecting to the server."
801,0,mariadb-show,"The
mariadb-show
client can be used to quickly see which databases
       exist, their tables, or a table's columns or indexes. mariadb-show
provides a command-line interface to several SQL SHOW
       statements. The same information can be obtained by using those
       statements directly."
801,1,mariadb-show,"The same information can be obtained by using those
       statements directly. For example, you can issue them from the
mariadb
client program. Invoke
mariadb-show
like this:

           shell>
mariadb-show [
options
] [
db_name
[
tbl_name
[
col_name
]]]
â¢   If no database is given, a list of database names is shown."
801,2,mariadb-show,"Invoke
mariadb-show
like this:

           shell>
mariadb-show [
options
] [
db_name
[
tbl_name
[
col_name
]]]
â¢   If no database is given, a list of database names is shown. â¢   If no table is given, all matching tables in the database are
           shown. â¢   If no column is given, all matching columns and column types
           in the table are shown."
801,3,mariadb-show,"â¢   If no column is given, all matching columns and column types
           in the table are shown. The output displays only the names of those databases, tables, or
       columns for which you have some privileges. If the last argument contains shell or SQL wildcard characters
       (â*â, â?â, â%â, or â_â), only those names that are matched by the
       wildcard are shown."
801,4,mariadb-show,"If the last argument contains shell or SQL wildcard characters
       (â*â, â?â, â%â, or â_â), only those names that are matched by the
       wildcard are shown. If a database name contains any underscores,
       those should be escaped with a backslash (some Unix shells require
       two) to get a list of the proper tables or columns. â*â and â?â
       characters are converted into SQL â%â and â_â wildcard characters."
801,5,mariadb-show,"â*â and â?â
       characters are converted into SQL â%â and â_â wildcard characters. This might cause some confusion when you try to display the
       columns for a table with a â_â in the name, because in this case,
mariadb-show
shows you only the table names that match the
       pattern. This is easily fixed by adding an extra â%â last on the
       command line as a separate argument."
801,6,mariadb-show,"This is easily fixed by adding an extra â%â last on the
       command line as a separate argument. mariadb-show
supports the following options, which can be
       specified on the command line or in the [mariadb-show] and
       [client] option file groups. mariadb-show
also supports the
       options for processing option files described."
801,7,mariadb-show,"mariadb-show
also supports the
       options for processing option files described. â¢
--help
,
-? Display a help message and exit."
801,8,mariadb-show,"Display a help message and exit. â¢
--character-sets-dir=
path
,
-c
path
The directory where character sets are installed. â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression."
801,9,mariadb-show,"â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression. â¢
--count
Show the number of rows per table. This can be slow for
           non-MyISAM tables."
801,10,mariadb-show,"This can be slow for
           non-MyISAM tables. â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log. A typical
debug_options
string is
           'd:t:o,
file_name
'."
801,11,mariadb-show,"A typical
debug_options
string is
           'd:t:o,
file_name
'. The default is 'd:t:o'. â¢
--debug-check
Print some debugging information when the program exits."
801,12,mariadb-show,"â¢
--debug-check
Print some debugging information when the program exits. â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--default-auth=
name
Default authentication client-side plugin to use."
801,13,mariadb-show,"â¢
--default-auth=
name
Default authentication client-side plugin to use. â¢
--default-character-set=
charset_name
Use
charset_name
as the default character set. â¢
--defaults-extra-file=
filename
Set
filename
as the file to read default options from after
           the global defaults files has been read."
801,14,mariadb-show,"â¢
--defaults-extra-file=
filename
Set
filename
as the file to read default options from after
           the global defaults files has been read. Must be given as
           first option. â¢
--defaults-file=
filename
Set
filename
as the file to read default options from,
           override global defaults files."
801,15,mariadb-show,"â¢
--defaults-file=
filename
Set
filename
as the file to read default options from,
           override global defaults files. Must be given as first
           option. â¢
--defaults-group-suffix=
suffix
In addition to the groups named on the command line, read
           groups that have the given suffix."
801,16,mariadb-show,"â¢
--defaults-group-suffix=
suffix
In addition to the groups named on the command line, read
           groups that have the given suffix. â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host. â¢
--keys
,
-k
Show table indexes."
801,17,mariadb-show,"â¢
--keys
,
-k
Show table indexes. â¢
--no-defaults
Do not read default options from any option file. This must be
           given as the first argument."
801,18,mariadb-show,"This must be
           given as the first argument. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password."
801,19,mariadb-show,"If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-show
prompts for one. Specifying a password on the command line should be considered
           insecure."
801,20,mariadb-show,"Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line. â¢
--pipe
,
-W
On Windows, connect to the server via a named pipe."
801,21,mariadb-show,"â¢
--pipe
,
-W
On Windows, connect to the server via a named pipe. This
           option applies only if the server supports named-pipe
           connections. â¢
--plugin-dir=
dir_name
Directory for client-side plugins."
801,22,mariadb-show,"â¢
--plugin-dir=
dir_name
Directory for client-side plugins. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection. Forces
           --protocol=tcp when specified on the command line without
           other connection properties."
801,23,mariadb-show,"Forces
           --protocol=tcp when specified on the command line without
           other connection properties. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want."
801,24,mariadb-show,"It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--print-defaults
Print the program argument list and exit. This must be given
           as the first argument."
801,25,mariadb-show,"This must be given
           as the first argument. â¢
--show-table-type
,
-t
Show a column indicating the table type, as in SHOW FULL
           TABLES. The type is BASE TABLE or VIEW."
801,26,mariadb-show,"The type is BASE TABLE or VIEW. â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe."
801,27,mariadb-show,"Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe. â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags). Disable with
--skip-ssl
."
801,28,mariadb-show,"Disable with
--skip-ssl
. â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
)."
801,29,mariadb-show,"â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
)."
801,30,mariadb-show,"â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
). â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
)."
801,31,mariadb-show,"â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
). â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting."
801,32,mariadb-show,"â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting. This option is disabled by default. â¢
--status
,
-i
Display extra information about each table."
801,33,mariadb-show,"â¢
--status
,
-i
Display extra information about each table. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
--verbose
,
-v
Verbose mode."
801,34,mariadb-show,"â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does. This option can be used multiple times to increase the
           amount of information."
801,35,mariadb-show,"Print more information about what the program
           does. This option can be used multiple times to increase the
           amount of information. â¢
--version
,
-V
Display version information and exit."
802,0,mariadb-slap,"mariadb-slap
is a diagnostic program designed to emulate client
       load for a MariaDB server and to report the timing of each stage. It works as if multiple clients are accessing the server. Invoke
mariadb-slap
like this:

           shell>
mariadb-slap [
options
]
Some options such as
--create
or
--query
enable you to specify a
       string containing an SQL statement or a file containing
       statements."
802,1,mariadb-slap,"Invoke
mariadb-slap
like this:

           shell>
mariadb-slap [
options
]
Some options such as
--create
or
--query
enable you to specify a
       string containing an SQL statement or a file containing
       statements. If you specify a file, by default it must contain one
       statement per line. (That is, the implicit statement delimiter is
       the newline character.) Use the
--delimiter
option to specify a
       different delimiter, which enables you to specify statements that
       span multiple lines or place multiple statements on a single line."
802,2,mariadb-slap,"(That is, the implicit statement delimiter is
       the newline character.) Use the
--delimiter
option to specify a
       different delimiter, which enables you to specify statements that
       span multiple lines or place multiple statements on a single line. You cannot include comments in a file;
mariadb-slap
does not
       understand them. mariadb-slap
runs in three stages:

        1."
802,3,mariadb-slap,"mariadb-slap
runs in three stages:

        1. Create schema, table, and optionally any stored programs or
           data you want to using for the test. This stage uses a single
           client connection."
802,4,mariadb-slap,"This stage uses a single
           client connection. 2. Run the load test."
802,5,mariadb-slap,Run the load test. This stage can use many client connections. 3.
802,6,mariadb-slap,"3. Clean up (disconnect, drop table if specified). This stage
           uses a single client connection."
802,7,mariadb-slap,"This stage
           uses a single client connection. Examples:

       Supply your own create and query SQL statements, with 50 clients
       querying and 200 selects for each:

           mariadb-slap --delimiter="";"" \
             --create=""CREATE TABLE a (b int);INSERT INTO a VALUES (23)"" \
             --query=""SELECT * FROM a"" --concurrency=50 --iterations=200

       Let
mariadb-slap
build the query SQL statement with a table of two
       INT columns and three VARCHAR columns. Use five clients querying
       20 times each."
802,8,mariadb-slap,"Use five clients querying
       20 times each. Do not create the table or insert the data (that
       is, use the previous test's schema and data):

           mariadb-slap --concurrency=5 --iterations=20 \
             --number-int-cols=2 --number-char-cols=3 \
             --auto-generate-sql

       Tell the program to load the create, insert, and query SQL
       statements from the specified files, where the create.sql file has
       multiple table creation statements delimited by ';' and multiple
       insert statements delimited by ';'. The
--query
file will have
       multiple queries delimited by ';'."
802,9,mariadb-slap,"The
--query
file will have
       multiple queries delimited by ';'. Run all the load statements,
       then run all the queries in the query file with five clients (five
       times each):

           mariadb-slap --concurrency=5 \
             --iterations=5 --query=query.sql --create=create.sql \
             --delimiter="";""
mariadb-slap
supports the following options, which can be
       specified on the command line or in the [mariadb-slap] and
       [client] option file groups. mariadb-slap
also supports the
       options for processing option files."
802,10,mariadb-slap,"mariadb-slap
also supports the
       options for processing option files. â¢
--help
,
-? Display a help message and exit."
802,11,mariadb-slap,"Display a help message and exit. â¢
--auto-generate-sql
,
-a
Generate SQL statements automatically when they are not
           supplied in files or via command options. â¢
--auto-generate-sql-add-autoincrement
Add an AUTO_INCREMENT column to automatically generated
           tables."
802,12,mariadb-slap,"â¢
--auto-generate-sql-add-autoincrement
Add an AUTO_INCREMENT column to automatically generated
           tables. â¢
--auto-generate-sql-execute-number=
N
Specify how many queries to generate automatically. â¢
--auto-generate-sql-guid-primary
Add a GUID-based primary key to automatically generated
           tables."
802,13,mariadb-slap,"â¢
--auto-generate-sql-guid-primary
Add a GUID-based primary key to automatically generated
           tables. â¢
--auto-generate-sql-load-type=
type
Specify the test load type. The allowable values are read
           (scan tables), write (insert into tables), key (read primary
           keys), update (update primary keys), or mixed (half inserts,
           half scanning selects)."
802,14,mariadb-slap,"The allowable values are read
           (scan tables), write (insert into tables), key (read primary
           keys), update (update primary keys), or mixed (half inserts,
           half scanning selects). The default is mixed. â¢
--auto-generate-sql-secondary-indexes=
N
Specify how many secondary indexes to add to automatically
           generated tables."
802,15,mariadb-slap,"â¢
--auto-generate-sql-secondary-indexes=
N
Specify how many secondary indexes to add to automatically
           generated tables. By default, none are added. â¢
--auto-generate-sql-unique-query-number=
N
How many different queries to generate for automatic tests."
802,16,mariadb-slap,"â¢
--auto-generate-sql-unique-query-number=
N
How many different queries to generate for automatic tests. For example, if you run a key test that performs 1000 selects,
           you can use this option with a value of 1000 to run 1000
           unique queries, or with a value of 50 to perform 50 different
           selects. The default is 10."
802,17,mariadb-slap,"The default is 10. â¢
--auto-generate-sql-unique-write-number=
N
How many different queries to generate for
--auto-generate-sql-write-number
. The default is 10."
802,18,mariadb-slap,"The default is 10. â¢
--auto-generate-sql-write-number=
N
How many row inserts to perform on each thread. The default is
           100."
802,19,mariadb-slap,"The default is
           100. â¢
--commit=
N
How many statements to execute before committing. The default
           is 0 (no commits are done)."
802,20,mariadb-slap,"The default
           is 0 (no commits are done). â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression. â¢
--concurrency=
N
,
-c
N
The number of clients to simulate when issuing the SELECT
           statement."
802,21,mariadb-slap,"â¢
--concurrency=
N
,
-c
N
The number of clients to simulate when issuing the SELECT
           statement. â¢
--create=
value
The file or string containing the statement to use for
           creating the table. â¢
--create-schema=
value
The schema in which to run the tests."
802,22,mariadb-slap,"â¢
--create-schema=
value
The schema in which to run the tests. â¢
--csv[=
file_name
]
Generate output in comma-separated values format. The output
           goes to the named file, or to the standard output if no file
           is given."
802,23,mariadb-slap,"The output
           goes to the named file, or to the standard output if no file
           is given. â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log. A typical
debug_options
string is
           'd:t:o,
file_name
'."
802,24,mariadb-slap,"A typical
debug_options
string is
           'd:t:o,
file_name
'. The default is 'd:t:o,/tmp/mariadb-
           slap.trace'. â¢
--debug-check
Print some debugging information when the program exits."
802,25,mariadb-slap,"â¢
--debug-check
Print some debugging information when the program exits. â¢
--debug-info
,
-T
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--default-auth=
name
Default authentication client-side plugin to use."
802,26,mariadb-slap,"â¢
--default-auth=
name
Default authentication client-side plugin to use. â¢
--defaults-extra-file=
filename
Set
filename
as the file to read default options from after
           the global defaults files has been read. Must be given as
           first option."
802,27,mariadb-slap,"Must be given as
           first option. â¢
--defaults-file=
filename
Set
filename
as the file to read default options from,
           override global defaults files. Must be given as first
           option."
802,28,mariadb-slap,"Must be given as first
           option. â¢
--delimiter=
str
,
-F
str
The delimiter to use in SQL statements supplied in files or
           via command options. â¢
--detach=
N
Detach (close and reopen) each connection after each
N
statements."
802,29,mariadb-slap,"â¢
--detach=
N
Detach (close and reopen) each connection after each
N
statements. The default is 0 (connections are not detached). â¢
--engine=
engine_name
,
-e
engine_name
Comma separated list of storage engines to use for creating
           the table."
802,30,mariadb-slap,"â¢
--engine=
engine_name
,
-e
engine_name
Comma separated list of storage engines to use for creating
           the table. The test is run for each engine. You can also
           specify an option for an engine after a colon, for example
memory:max_row=2300
."
802,31,mariadb-slap,"You can also
           specify an option for an engine after a colon, for example
memory:max_row=2300
. â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host. â¢
--init-command=str
SQL Command to execute when connecting to MariaDB server."
802,32,mariadb-slap,"â¢
--init-command=str
SQL Command to execute when connecting to MariaDB server. Will
           automatically be re-executed when reconnecting. â¢
--iterations=
N
,
-i
N
The number of times to run the tests."
802,33,mariadb-slap,"â¢
--iterations=
N
,
-i
N
The number of times to run the tests. â¢
--no-defaults
Do not read default options from any option file. This must be
           given as the first argument."
802,34,mariadb-slap,"This must be
           given as the first argument. â¢
--no-drop
Do not drop any schema created during the test after the test
           is complete. â¢
--number-char-cols=
N
,
-x
N
The number of VARCHAR columns to use if
--auto-generate-sql
is
           specified."
802,35,mariadb-slap,"â¢
--number-char-cols=
N
,
-x
N
The number of VARCHAR columns to use if
--auto-generate-sql
is
           specified. â¢
--number-int-cols=
N
,
-y
N
The number of INT columns to use if
--auto-generate-sql
is
           specified. â¢
--number-of-queries=
N
Limit each client to approximately this many queries."
802,36,mariadb-slap,"â¢
--number-of-queries=
N
Limit each client to approximately this many queries. Query
           counting takes into account the statement delimiter. For
           example, if you invoke
mariadb-slap
as follows, the ;
           delimiter is recognized so that each instance of the query
           string counts as two queries."
802,37,mariadb-slap,"For
           example, if you invoke
mariadb-slap
as follows, the ;
           delimiter is recognized so that each instance of the query
           string counts as two queries. As a result, 5 rows (not 10) are
           inserted. shell>
mariadb-slap --delimiter="";"" --number-of-queries=10
--query=""use test;insert into t values(null)""
â¢
--only-print
Do not connect to databases."
802,38,mariadb-slap,"shell>
mariadb-slap --delimiter="";"" --number-of-queries=10
--query=""use test;insert into t values(null)""
â¢
--only-print
Do not connect to databases. mariadb-slap
only prints what it
           would have done. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server."
802,39,mariadb-slap,"â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-slap
prompts for one."
802,40,mariadb-slap,"If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-slap
prompts for one. Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line."
802,41,mariadb-slap,"You can use an option file to avoid giving the
           password on the command line. â¢
--pipe
,
-W
On Windows, connect to the server via a named pipe. This
           option applies only if the server supports named-pipe
           connections."
802,42,mariadb-slap,"This
           option applies only if the server supports named-pipe
           connections. â¢
--plugin-dir=
dir_name
Directory for client-side plugins. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection."
802,43,mariadb-slap,"â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection. Forces
           --protocol=tcp when specified on the command line without
           other connection properties. â¢
--post-query=
value
The file or string containing the statement to execute after
           the tests have completed."
802,44,mariadb-slap,"â¢
--post-query=
value
The file or string containing the statement to execute after
           the tests have completed. This execution is not counted for
           timing purposes. â¢
--post-system=
str
The string to execute via system() after the tests have
           completed."
802,45,mariadb-slap,"â¢
--post-system=
str
The string to execute via system() after the tests have
           completed. This execution is not counted for timing purposes. â¢
--pre-query=
value
The file or string containing the statement to execute before
           running the tests."
802,46,mariadb-slap,"â¢
--pre-query=
value
The file or string containing the statement to execute before
           running the tests. This execution is not counted for timing
           purposes. â¢
--pre-system=
str
The string to execute via system() before running the tests."
802,47,mariadb-slap,"â¢
--pre-system=
str
The string to execute via system() before running the tests. This execution is not counted for timing purposes. â¢
--print-defaults
Print the program argument list and exit."
802,48,mariadb-slap,"â¢
--print-defaults
Print the program argument list and exit. This must be given
           as the first argument. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server."
802,49,mariadb-slap,"â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--query=
value
,
-q
value
The file or string containing the SELECT statement to use for
           retrieving data."
802,50,mariadb-slap,"â¢
--query=
value
,
-q
value
The file or string containing the SELECT statement to use for
           retrieving data. â¢
--shared-memory-base-name=
name
On Windows, the shared-memory name to use, for connections
           made via shared memory to a local server. This option applies
           only if the server supports shared-memory connections."
802,51,mariadb-slap,"This option applies
           only if the server supports shared-memory connections. â¢
--silent
,
-s
Silent mode. No output."
802,52,mariadb-slap,"No output. â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe."
802,53,mariadb-slap,"Forces
           --protocol=socket when specified on the command line without
           other connection properties; on Windows, forces
           --protocol=pipe. â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags). Disable with
--skip-ssl
."
802,54,mariadb-slap,"Disable with
--skip-ssl
. â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
)."
802,55,mariadb-slap,"â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
)."
802,56,mariadb-slap,"â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
). â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
)."
802,57,mariadb-slap,"â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
). â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting."
802,58,mariadb-slap,"â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting. This option is disabled by default. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server."
802,59,mariadb-slap,"â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does."
802,60,mariadb-slap,"Print more information about what the program
           does. This option can be used multiple times to increase the
           amount of information. â¢
--version
,
-V
Display version information and exit."
803,0,mysql-stress-test.pl,"The
mariadb-stress-test.pl
Perl script performs stress-testing of
       the MariaDB server. mariadb-stress-test.pl
requires a version of Perl that has been
       built with threads support. Invoke
mariadb-stress-test.pl
like this:

           shell>
mariadb-stress-test.pl [
options
]
mariadb-stress-test.pl
supports the following options:

       â¢
--help
Display a help message and exit."
803,1,mysql-stress-test.pl,"Invoke
mariadb-stress-test.pl
like this:

           shell>
mariadb-stress-test.pl [
options
]
mariadb-stress-test.pl
supports the following options:

       â¢
--help
Display a help message and exit. â¢
--abort-on-error=
N
Causes the program to abort if an error with severity less
           than or equal to N was encountered. Set to 1 to abort on any
           error."
803,2,mysql-stress-test.pl,"Set to 1 to abort on any
           error. â¢
--check-tests-file
Periodically check the file that lists the tests to be run. If
           it has been modified, reread the file."
803,3,mysql-stress-test.pl,"If
           it has been modified, reread the file. This can be useful if
           you update the list of tests to be run during a stress test. â¢
--cleanup
Force cleanup of the working directory."
803,4,mysql-stress-test.pl,"â¢
--cleanup
Force cleanup of the working directory. â¢
--log-error-details
Log error details in the global error log file. â¢
--loop-count=
N
In sequential test mode, the number of loops to execute before
           exiting."
803,5,mysql-stress-test.pl,"â¢
--loop-count=
N
In sequential test mode, the number of loops to execute before
           exiting. â¢
--mariadb-test=
path
The path name to the
mariadb-test
program. â¢
--server-database=
db_name
The database to use for the tests."
803,6,mysql-stress-test.pl,"â¢
--server-database=
db_name
The database to use for the tests. The default is test. â¢
--server-host=
host_name
The host name of the local host to use for making a TCP/IP
           connection to the local server."
803,7,mysql-stress-test.pl,"â¢
--server-host=
host_name
The host name of the local host to use for making a TCP/IP
           connection to the local server. By default, the connection is
           made to localhost using a Unix socket file. â¢
--server-logs-dir=
path
This option is required."
803,8,mysql-stress-test.pl,"â¢
--server-logs-dir=
path
This option is required. path
is the directory where all
           client session logs will be stored. Usually this is the shared
           directory that is associated with the server used for testing."
803,9,mysql-stress-test.pl,"Usually this is the shared
           directory that is associated with the server used for testing. â¢
--server-password=
password
The password to use when connecting to the server. â¢
--server-port=
port_num
The TCP/IP port number to use for connecting to the server."
803,10,mysql-stress-test.pl,"â¢
--server-port=
port_num
The TCP/IP port number to use for connecting to the server. The default is 3306. â¢
--server-socket=
file_name
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use."
803,11,mysql-stress-test.pl,"â¢
--server-socket=
file_name
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. The default is
           /tmp/mariadb.sock. â¢
--server-user=
user_name
The MariaDB user name to use when connecting to the server."
803,12,mysql-stress-test.pl,"â¢
--server-user=
user_name
The MariaDB user name to use when connecting to the server. The default is root. â¢
--sleep-time=
N
The delay in seconds between test executions."
803,13,mysql-stress-test.pl,"â¢
--sleep-time=
N
The delay in seconds between test executions. â¢
--stress-basedir=
path
This option is required. path
is the working directory for
           the test run."
803,14,mysql-stress-test.pl,"path
is the working directory for
           the test run. It is used as the temporary location for result
           tracking during testing. â¢
--stress-datadir=
path
The directory of data files to be used during testing."
803,15,mysql-stress-test.pl,"â¢
--stress-datadir=
path
The directory of data files to be used during testing. The
           default location is the data directory under the location
           given by the
--stress-suite-basedir
option. â¢
--stress-init-file[=
path
]
file_name
is the location of the file that contains the list
           of tests to be run once to initialize the database for the
           testing."
803,16,mysql-stress-test.pl,"â¢
--stress-init-file[=
path
]
file_name
is the location of the file that contains the list
           of tests to be run once to initialize the database for the
           testing. If missing, the default file is stress_init.txt in
           the test suite directory. â¢
--stress-mode=
mode
This option indicates the test order in stress-test mode."
803,17,mysql-stress-test.pl,"â¢
--stress-mode=
mode
This option indicates the test order in stress-test mode. The
mode
value is either random to select tests in random order or
           seq to run tests in each thread in the order specified in the
           test list file. The default mode is random."
803,18,mysql-stress-test.pl,"The default mode is random. â¢
--stress-suite-basedir=
path
This option is required. path
is the directory that has the t
           and
r
subdirectories containing the test case and result
           files."
803,19,mysql-stress-test.pl,"path
is the directory that has the t
           and
r
subdirectories containing the test case and result
           files. This directory is also the default location of the
           stress-test.txt file that contains the list of tests. (A
           different location can be specified with the
--stress-tests-file
option.)

       â¢
--stress-tests-file[=
file_name
]
Use this option to run the stress tests."
803,20,mysql-stress-test.pl,"(A
           different location can be specified with the
--stress-tests-file
option.)

       â¢
--stress-tests-file[=
file_name
]
Use this option to run the stress tests. file_name
is the
           location of the file that contains the list of tests. If
file_name
is omitted, the default file is stress-test.txt in
           the stress suite directory."
803,21,mysql-stress-test.pl,"If
file_name
is omitted, the default file is stress-test.txt in
           the stress suite directory. (See
--stress-suite-basedir
.)

       â¢
--suite=
suite_name
Run the named test suite. The default name is main (the
           regular test suite located in the mariadb-test directory)."
803,22,mysql-stress-test.pl,"The default name is main (the
           regular test suite located in the mariadb-test directory). â¢
--test-count=
N
The number of tests to execute before exiting. â¢
--test-duration=
N
The duration of stress testing in seconds."
803,23,mysql-stress-test.pl,"â¢
--test-duration=
N
The duration of stress testing in seconds. â¢
--threads=
N
The number of threads. The default is 1."
803,24,mysql-stress-test.pl,"The default is 1. â¢
--verbose
Verbose mode. Print more information about what the program
           does."
804,0,mariadb-test,"The
mariadb-test
program runs a test case against a MariaDB server
       and optionally compares the output with a result file. This
       program reads input written in a special test language. Typically,
       you invoke
mariadb-test
via
mariadb-test-run.pl
rather than
       invoking it directly."
804,1,mariadb-test,"Typically,
       you invoke
mariadb-test
via
mariadb-test-run.pl
rather than
       invoking it directly. mariadb-test-embedded
is similar but is built with support for the
       libmariadbd embedded server. Features of
mariadb-test
:

       â¢   Can send SQL statements to MariaDB servers for execution

       â¢   Can execute external shell commands

       â¢   Can test whether the result from an SQL statement or shell
           command is as expected

       â¢   Can connect to one or more standalone
mariadbd
servers and
           switch between connections

       â¢   Can connect to an embedded server (libmariadbd), if MariaDB is
           compiled with support for libmariadbd."
804,2,mariadb-test,"Features of
mariadb-test
:

       â¢   Can send SQL statements to MariaDB servers for execution

       â¢   Can execute external shell commands

       â¢   Can test whether the result from an SQL statement or shell
           command is as expected

       â¢   Can connect to one or more standalone
mariadbd
servers and
           switch between connections

       â¢   Can connect to an embedded server (libmariadbd), if MariaDB is
           compiled with support for libmariadbd. (In this case, the
           executable is named
mariadb-test-embedded
rather than
mariadb-
test
.)

       By default,
mariadb-test
reads the test case on the standard
       input. To run
mariadb-test
this way, you normally invoke it like
       this:

           shell>
mariadb-test [
options
] [
db_name
] <
test_file
You can also name the test case file with a
--test-file=
file_name
option."
804,3,mariadb-test,"To run
mariadb-test
this way, you normally invoke it like
       this:

           shell>
mariadb-test [
options
] [
db_name
] <
test_file
You can also name the test case file with a
--test-file=
file_name
option. The exit value from
mariadb-test
is 0 for success, 1 for failure,
       and 62 if it skips the test case (for example, if after checking
       some preconditions it decides not to run the test). mariadb-test
supports the following options:

       â¢
--help
,
-?"
804,4,mariadb-test,"mariadb-test
supports the following options:

       â¢
--help
,
-? Display a help message and exit. â¢
--basedir=
dir_name
,
-b
dir_name
The base directory for tests."
804,5,mariadb-test,"â¢
--basedir=
dir_name
,
-b
dir_name
The base directory for tests. â¢
--character-sets-dir=
path
The directory where character sets are installed. â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression."
804,6,mariadb-test,"â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression. â¢
--connect-timeout=
num
This can be used to set the MYSQL_OPT_CONNECT_TIMEOUT
           parameter of mysql_options to change the number of seconds
           before an unsuccessful connection attempt times out. â¢
--continue-on-error
Continue test even if we got an error."
804,7,mariadb-test,"â¢
--continue-on-error
Continue test even if we got an error. This is mostly useful
           when testing a storage engine to see what from a test file it
           can execute, or to find all syntax errors in a newly created
           big test file. â¢
--cursor-protocol
Use cursors for prepared statements."
804,8,mariadb-test,"â¢
--cursor-protocol
Use cursors for prepared statements. â¢
--database=
db_name
,
-D
db_name
The default database to use. â¢
--debug[=
debug_options
]
,
-#[
debug_options
]
Write a debugging log if MariaDB is built with debugging
           support."
804,9,mariadb-test,"â¢
--debug[=
debug_options
]
,
-#[
debug_options
]
Write a debugging log if MariaDB is built with debugging
           support. The default
debug_options
value is
           'd:t:S:i:O,/tmp/mariadb-test.trace'. â¢
--debug-check
Print some debugging information when the program exits."
804,10,mariadb-test,"â¢
--debug-check
Print some debugging information when the program exits. â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host."
804,11,mariadb-test,"â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host. â¢
--logdir=
dir_name
The directory to use for log files. â¢
--mark-progress
Write the line number and elapsed time to
test_file
.progress."
804,12,mariadb-test,"â¢
--mark-progress
Write the line number and elapsed time to
test_file
.progress. â¢
--max-connect-retries=
num
The maximum number of connection attempts when connecting to
           server. â¢
--max-connections=
num
The maximum number of simultaneous server connections per
           client (that is, per test)."
804,13,mariadb-test,"â¢
--max-connections=
num
The maximum number of simultaneous server connections per
           client (that is, per test). If not set, the maximum is 128. Minimum allowed limit is 8, maximum is 5120."
804,14,mariadb-test,"Minimum allowed limit is 8, maximum is 5120. â¢
--no-defaults
Do not read default options from any option files. If used,
           this must be the first option."
804,15,mariadb-test,"If used,
           this must be the first option. â¢
--non-blocking-api
Use the non-blocking client API for communication. â¢
--overlay-dir=
dir_name
Overlay directory."
804,16,mariadb-test,"â¢
--overlay-dir=
dir_name
Overlay directory. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password."
804,17,mariadb-test,"If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line, you
           are prompted for one. â¢
--plugin-dir=
dir_name
Directory for client-side plugins."
804,18,mariadb-test,"â¢
--plugin-dir=
dir_name
Directory for client-side plugins. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection or 0 for
           default to, in order of preference, my.cnf, $MYSQL_TCP_PORT,
           /etc/services, built-in default (3306). â¢
--prologue=
name
Include the contents of the given file before processing the
           contents of the test file."
804,19,mariadb-test,"â¢
--prologue=
name
Include the contents of the given file before processing the
           contents of the test file. The included file should have the
           same format as other
mariadb-test
test files. This option has
           the same effect as putting a --source
file_name
command as the
           first line of the test file."
804,20,mariadb-test,"This option has
           the same effect as putting a --source
file_name
command as the
           first line of the test file. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want."
804,21,mariadb-test,"It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--ps-protocol
Use the prepared-statement protocol for communication. â¢
--quiet
Suppress all normal output."
804,22,mariadb-test,"â¢
--quiet
Suppress all normal output. This is a synonym for
--silent
. â¢
--record
,
-r
Record the output that results from running the test file into
           the file named by the
--result-file
option, if that option is
           given."
804,23,mariadb-test,"â¢
--record
,
-r
Record the output that results from running the test file into
           the file named by the
--result-file
option, if that option is
           given. It is an error to use this option without also using
--result-file
. â¢
--result-file=
file_name
,
-R
file_name
This option specifies the file for test case expected results."
804,24,mariadb-test,"â¢
--result-file=
file_name
,
-R
file_name
This option specifies the file for test case expected results. --result-file
, together with
--record
, determines how
mariadb-
test
treats the test actual and expected results for a test
           case:

           â¢   If the test produces no results,
mariadb-test
exits with
               an error message to that effect, unless
--result-file
is
               given and the named file is an empty file. â¢   Otherwise, if
--result-file
is not given,
mariadb-test
sends test results to the standard output."
804,25,mariadb-test,"â¢   Otherwise, if
--result-file
is not given,
mariadb-test
sends test results to the standard output. â¢   With
--result-file
but not
--record
,
mariadb-test
reads
               the expected results from the given file and compares them
               with the actual results. If the results do not match,
mariadb-test
writes a .reject file in the same directory
               as the result file, outputs a diff of the two files, and
               exits with an error."
804,26,mariadb-test,"If the results do not match,
mariadb-test
writes a .reject file in the same directory
               as the result file, outputs a diff of the two files, and
               exits with an error. â¢   With both
--result-file
and
--record
,
mariadb-test
updates
               the given file by writing the actual test results to it. â¢
--result-format-version=
#
Version of the result file format to use."
804,27,mariadb-test,"â¢
--result-format-version=
#
Version of the result file format to use. â¢
--server-arg=
value
,
-A
value
Pass the argument as an argument to the embedded server. For
           example,
--server-arg=--tmpdir=/tmp
or
--server-arg=--core
."
804,28,mariadb-test,"For
           example,
--server-arg=--tmpdir=/tmp
or
--server-arg=--core
. Up
           to 64 arguments can be given. â¢
--server-file=
file_name
,
-F
file_name
Read arguments for the embedded server from the given file."
804,29,mariadb-test,"â¢
--server-file=
file_name
,
-F
file_name
Read arguments for the embedded server from the given file. The file should contain one argument per line. â¢
--silent
,
-s
Suppress all normal output."
804,30,mariadb-test,"â¢
--silent
,
-s
Suppress all normal output. â¢
--sleep=
num
,
-T
num
Cause all sleep commands in the test case file to sleep
num
seconds. This option does not affect real_sleep commands."
804,31,mariadb-test,"This option does not affect real_sleep commands. An option value of 0 can be used, which effectively disables
           sleep commands in the test case. â¢
--socket=
path
,
-S
path
The socket file to use when connecting to localhost (which is
           the default host)."
804,32,mariadb-test,"â¢
--socket=
path
,
-S
path
The socket file to use when connecting to localhost (which is
           the default host). â¢
--sp-protocol
Execute DML statements within a stored procedure. For every
           DML statement,
mariadb-test
creates and invokes a stored
           procedure that executes the statement rather than executing
           the statement directly."
804,33,mariadb-test,"For every
           DML statement,
mariadb-test
creates and invokes a stored
           procedure that executes the statement rather than executing
           the statement directly. â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags). Disable with
--skip-ssl
."
804,34,mariadb-test,"Disable with
--skip-ssl
. â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
)."
804,35,mariadb-test,"â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
)."
804,36,mariadb-test,"â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
). â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
)."
804,37,mariadb-test,"â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
). â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting."
804,38,mariadb-test,"â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting. This option is disabled by default. â¢
--suite-dir=
dir_name
Suite directory."
804,39,mariadb-test,"â¢
--suite-dir=
dir_name
Suite directory. â¢
--tail-lines=
nn
Specify how many lines of the result to include in the output
           if the test fails because an SQL statement fails. The default
           is 0, meaning no lines of result printed."
804,40,mariadb-test,"The default
           is 0, meaning no lines of result printed. â¢
--test-file=
file_name
,
-x
file_name
Read test input from this file. The default is to read from
           the standard input."
804,41,mariadb-test,"The default is to read from
           the standard input. â¢
--timer-file=
file_name
,
-m
file_name
If given, the number of microseconds spent running the test
           will be written to this file. This is used by
mariadb-test-run.pl
for its reporting."
804,42,mariadb-test,"This is used by
mariadb-test-run.pl
for its reporting. â¢
--tmpdir=
dir_name
,
-t
dir_name
The temporary directory where socket files are created. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server."
804,43,mariadb-test,"â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
--verbose
,
-v
Verbose mode. Print out more information about what the
           program does."
804,44,mariadb-test,"Print out more information about what the
           program does. â¢
--version
,
-V
Display version information and exit. â¢
--view-protocol
Every SELECT statement is wrapped inside a view."
805,0,mariadb-test,"The
mariadb-test
program runs a test case against a MariaDB server
       and optionally compares the output with a result file. This
       program reads input written in a special test language. Typically,
       you invoke
mariadb-test
via
mariadb-test-run.pl
rather than
       invoking it directly."
805,1,mariadb-test,"Typically,
       you invoke
mariadb-test
via
mariadb-test-run.pl
rather than
       invoking it directly. mariadb-test-embedded
is similar but is built with support for the
       libmariadbd embedded server. Features of
mariadb-test
:

       â¢   Can send SQL statements to MariaDB servers for execution

       â¢   Can execute external shell commands

       â¢   Can test whether the result from an SQL statement or shell
           command is as expected

       â¢   Can connect to one or more standalone
mariadbd
servers and
           switch between connections

       â¢   Can connect to an embedded server (libmariadbd), if MariaDB is
           compiled with support for libmariadbd."
805,2,mariadb-test,"Features of
mariadb-test
:

       â¢   Can send SQL statements to MariaDB servers for execution

       â¢   Can execute external shell commands

       â¢   Can test whether the result from an SQL statement or shell
           command is as expected

       â¢   Can connect to one or more standalone
mariadbd
servers and
           switch between connections

       â¢   Can connect to an embedded server (libmariadbd), if MariaDB is
           compiled with support for libmariadbd. (In this case, the
           executable is named
mariadb-test-embedded
rather than
mariadb-
test
.)

       By default,
mariadb-test
reads the test case on the standard
       input. To run
mariadb-test
this way, you normally invoke it like
       this:

           shell>
mariadb-test [
options
] [
db_name
] <
test_file
You can also name the test case file with a
--test-file=
file_name
option."
805,3,mariadb-test,"To run
mariadb-test
this way, you normally invoke it like
       this:

           shell>
mariadb-test [
options
] [
db_name
] <
test_file
You can also name the test case file with a
--test-file=
file_name
option. The exit value from
mariadb-test
is 0 for success, 1 for failure,
       and 62 if it skips the test case (for example, if after checking
       some preconditions it decides not to run the test). mariadb-test
supports the following options:

       â¢
--help
,
-?"
805,4,mariadb-test,"mariadb-test
supports the following options:

       â¢
--help
,
-? Display a help message and exit. â¢
--basedir=
dir_name
,
-b
dir_name
The base directory for tests."
805,5,mariadb-test,"â¢
--basedir=
dir_name
,
-b
dir_name
The base directory for tests. â¢
--character-sets-dir=
path
The directory where character sets are installed. â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression."
805,6,mariadb-test,"â¢
--compress
,
-C
Compress all information sent between the client and the
           server if both support compression. â¢
--connect-timeout=
num
This can be used to set the MYSQL_OPT_CONNECT_TIMEOUT
           parameter of mysql_options to change the number of seconds
           before an unsuccessful connection attempt times out. â¢
--continue-on-error
Continue test even if we got an error."
805,7,mariadb-test,"â¢
--continue-on-error
Continue test even if we got an error. This is mostly useful
           when testing a storage engine to see what from a test file it
           can execute, or to find all syntax errors in a newly created
           big test file. â¢
--cursor-protocol
Use cursors for prepared statements."
805,8,mariadb-test,"â¢
--cursor-protocol
Use cursors for prepared statements. â¢
--database=
db_name
,
-D
db_name
The default database to use. â¢
--debug[=
debug_options
]
,
-#[
debug_options
]
Write a debugging log if MariaDB is built with debugging
           support."
805,9,mariadb-test,"â¢
--debug[=
debug_options
]
,
-#[
debug_options
]
Write a debugging log if MariaDB is built with debugging
           support. The default
debug_options
value is
           'd:t:S:i:O,/tmp/mariadb-test.trace'. â¢
--debug-check
Print some debugging information when the program exits."
805,10,mariadb-test,"â¢
--debug-check
Print some debugging information when the program exits. â¢
--debug-info
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host."
805,11,mariadb-test,"â¢
--host=
host_name
,
-h
host_name
Connect to the MariaDB server on the given host. â¢
--logdir=
dir_name
The directory to use for log files. â¢
--mark-progress
Write the line number and elapsed time to
test_file
.progress."
805,12,mariadb-test,"â¢
--mark-progress
Write the line number and elapsed time to
test_file
.progress. â¢
--max-connect-retries=
num
The maximum number of connection attempts when connecting to
           server. â¢
--max-connections=
num
The maximum number of simultaneous server connections per
           client (that is, per test)."
805,13,mariadb-test,"â¢
--max-connections=
num
The maximum number of simultaneous server connections per
           client (that is, per test). If not set, the maximum is 128. Minimum allowed limit is 8, maximum is 5120."
805,14,mariadb-test,"Minimum allowed limit is 8, maximum is 5120. â¢
--no-defaults
Do not read default options from any option files. If used,
           this must be the first option."
805,15,mariadb-test,"If used,
           this must be the first option. â¢
--non-blocking-api
Use the non-blocking client API for communication. â¢
--overlay-dir=
dir_name
Overlay directory."
805,16,mariadb-test,"â¢
--overlay-dir=
dir_name
Overlay directory. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password."
805,17,mariadb-test,"If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line, you
           are prompted for one. â¢
--plugin-dir=
dir_name
Directory for client-side plugins."
805,18,mariadb-test,"â¢
--plugin-dir=
dir_name
Directory for client-side plugins. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection or 0 for
           default to, in order of preference, my.cnf, $MYSQL_TCP_PORT,
           /etc/services, built-in default (3306). â¢
--prologue=
name
Include the contents of the given file before processing the
           contents of the test file."
805,19,mariadb-test,"â¢
--prologue=
name
Include the contents of the given file before processing the
           contents of the test file. The included file should have the
           same format as other
mariadb-test
test files. This option has
           the same effect as putting a --source
file_name
command as the
           first line of the test file."
805,20,mariadb-test,"This option has
           the same effect as putting a --source
file_name
command as the
           first line of the test file. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want."
805,21,mariadb-test,"It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--ps-protocol
Use the prepared-statement protocol for communication. â¢
--quiet
Suppress all normal output."
805,22,mariadb-test,"â¢
--quiet
Suppress all normal output. This is a synonym for
--silent
. â¢
--record
,
-r
Record the output that results from running the test file into
           the file named by the
--result-file
option, if that option is
           given."
805,23,mariadb-test,"â¢
--record
,
-r
Record the output that results from running the test file into
           the file named by the
--result-file
option, if that option is
           given. It is an error to use this option without also using
--result-file
. â¢
--result-file=
file_name
,
-R
file_name
This option specifies the file for test case expected results."
805,24,mariadb-test,"â¢
--result-file=
file_name
,
-R
file_name
This option specifies the file for test case expected results. --result-file
, together with
--record
, determines how
mariadb-
test
treats the test actual and expected results for a test
           case:

           â¢   If the test produces no results,
mariadb-test
exits with
               an error message to that effect, unless
--result-file
is
               given and the named file is an empty file. â¢   Otherwise, if
--result-file
is not given,
mariadb-test
sends test results to the standard output."
805,25,mariadb-test,"â¢   Otherwise, if
--result-file
is not given,
mariadb-test
sends test results to the standard output. â¢   With
--result-file
but not
--record
,
mariadb-test
reads
               the expected results from the given file and compares them
               with the actual results. If the results do not match,
mariadb-test
writes a .reject file in the same directory
               as the result file, outputs a diff of the two files, and
               exits with an error."
805,26,mariadb-test,"If the results do not match,
mariadb-test
writes a .reject file in the same directory
               as the result file, outputs a diff of the two files, and
               exits with an error. â¢   With both
--result-file
and
--record
,
mariadb-test
updates
               the given file by writing the actual test results to it. â¢
--result-format-version=
#
Version of the result file format to use."
805,27,mariadb-test,"â¢
--result-format-version=
#
Version of the result file format to use. â¢
--server-arg=
value
,
-A
value
Pass the argument as an argument to the embedded server. For
           example,
--server-arg=--tmpdir=/tmp
or
--server-arg=--core
."
805,28,mariadb-test,"For
           example,
--server-arg=--tmpdir=/tmp
or
--server-arg=--core
. Up
           to 64 arguments can be given. â¢
--server-file=
file_name
,
-F
file_name
Read arguments for the embedded server from the given file."
805,29,mariadb-test,"â¢
--server-file=
file_name
,
-F
file_name
Read arguments for the embedded server from the given file. The file should contain one argument per line. â¢
--silent
,
-s
Suppress all normal output."
805,30,mariadb-test,"â¢
--silent
,
-s
Suppress all normal output. â¢
--sleep=
num
,
-T
num
Cause all sleep commands in the test case file to sleep
num
seconds. This option does not affect real_sleep commands."
805,31,mariadb-test,"This option does not affect real_sleep commands. An option value of 0 can be used, which effectively disables
           sleep commands in the test case. â¢
--socket=
path
,
-S
path
The socket file to use when connecting to localhost (which is
           the default host)."
805,32,mariadb-test,"â¢
--socket=
path
,
-S
path
The socket file to use when connecting to localhost (which is
           the default host). â¢
--sp-protocol
Execute DML statements within a stored procedure. For every
           DML statement,
mariadb-test
creates and invokes a stored
           procedure that executes the statement rather than executing
           the statement directly."
805,33,mariadb-test,"For every
           DML statement,
mariadb-test
creates and invokes a stored
           procedure that executes the statement rather than executing
           the statement directly. â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags). Disable with
--skip-ssl
."
805,34,mariadb-test,"Disable with
--skip-ssl
. â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
)."
805,35,mariadb-test,"â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
)."
805,36,mariadb-test,"â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
). â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
)."
805,37,mariadb-test,"â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
). â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting."
805,38,mariadb-test,"â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting. This option is disabled by default. â¢
--suite-dir=
dir_name
Suite directory."
805,39,mariadb-test,"â¢
--suite-dir=
dir_name
Suite directory. â¢
--tail-lines=
nn
Specify how many lines of the result to include in the output
           if the test fails because an SQL statement fails. The default
           is 0, meaning no lines of result printed."
805,40,mariadb-test,"The default
           is 0, meaning no lines of result printed. â¢
--test-file=
file_name
,
-x
file_name
Read test input from this file. The default is to read from
           the standard input."
805,41,mariadb-test,"The default is to read from
           the standard input. â¢
--timer-file=
file_name
,
-m
file_name
If given, the number of microseconds spent running the test
           will be written to this file. This is used by
mariadb-test-run.pl
for its reporting."
805,42,mariadb-test,"This is used by
mariadb-test-run.pl
for its reporting. â¢
--tmpdir=
dir_name
,
-t
dir_name
The temporary directory where socket files are created. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server."
805,43,mariadb-test,"â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server. â¢
--verbose
,
-v
Verbose mode. Print out more information about what the
           program does."
805,44,mariadb-test,"Print out more information about what the
           program does. â¢
--version
,
-V
Display version information and exit. â¢
--view-protocol
Every SELECT statement is wrapped inside a view."
806,0,mariadb-tzinfo-to-sql,"The
mariadb-tzinfo-to-sql
program loads the time zone tables in
       the mysql database. It is used on systems that have a zoneinfo
       database (the set of files describing time zones). Examples of
       such systems are Linux, FreeBSD, Solaris, and Mac OS X."
806,1,mariadb-tzinfo-to-sql,"Examples of
       such systems are Linux, FreeBSD, Solaris, and Mac OS X. One likely
       location for these files is the /usr/share/zoneinfo directory
       (/usr/share/lib/zoneinfo on Solaris). mariadb-tzinfo-to-sql
can be invoked several ways:

           shell>
mariadb-tzinfo-to-sql
tz_dir
shell>
mariadb-tzinfo-to-sql
tz_file tz_name
shell>
mariadb-tzinfo-to-sql --leap
tz_file
shell>
mariadb-tzinfo-to-sql --skip-write-binlog
tz_dir
For the first invocation syntax, pass the zoneinfo directory path
       name to
mariadb-tzinfo-to-sql
and send the output into the
mariadb
program."
806,2,mariadb-tzinfo-to-sql,"mariadb-tzinfo-to-sql
can be invoked several ways:

           shell>
mariadb-tzinfo-to-sql
tz_dir
shell>
mariadb-tzinfo-to-sql
tz_file tz_name
shell>
mariadb-tzinfo-to-sql --leap
tz_file
shell>
mariadb-tzinfo-to-sql --skip-write-binlog
tz_dir
For the first invocation syntax, pass the zoneinfo directory path
       name to
mariadb-tzinfo-to-sql
and send the output into the
mariadb
program. For example:

           shell>
mariadb-tzinfo-to-sql /usr/share/zoneinfo | mariadb -u root mysql
mariadb-tzinfo-to-sql
reads your system's time zone files and
       generates SQL statements from them. mariadb
processes those
       statements to load the time zone tables."
806,3,mariadb-tzinfo-to-sql,"mariadb
processes those
       statements to load the time zone tables. The second syntax causes
mariadb-tzinfo-to-sql
to load a single
       time zone file
tz_file
that corresponds to a time zone name
tz_name
:

           shell>
mariadb-tzinfo-to-sql
tz_file tz_name
| mariadb -u root mysql
If your time zone needs to account for leap seconds, invoke
mariadb-tzinfo-to-sql
using the third syntax, which initializes
       the leap second information. tz_file
is the name of your time
       zone file:

           shell>
mariadb-tzinfo-to-sql --leap
tz_file
| mariadb -u root mysql
Using the --skip-write-binlog option prevents writing of changes
       to the binary log or to other Galera cluster members."
806,4,mariadb-tzinfo-to-sql,"tz_file
is the name of your time
       zone file:

           shell>
mariadb-tzinfo-to-sql --leap
tz_file
| mariadb -u root mysql
Using the --skip-write-binlog option prevents writing of changes
       to the binary log or to other Galera cluster members. This can be
       used with any form of running
mariadb-tzinfo-to-sql
. After running
mariadb-tzinfo-to-sql
, it is best to restart the
       server so that it does not continue to use any previously cached
       time zone data."
807,0,mariadb-upgrade,"mariadb-upgrade
examines all tables in all databases for
       incompatibilities with the current version of the MariaDB Server. mariadb-upgrade
also upgrades the system tables so that you can
       take advantage of new privileges or capabilities that might have
       been added. mariadb-upgrade
should be executed each time you upgrade MariaDB."
807,1,mariadb-upgrade,"mariadb-upgrade
should be executed each time you upgrade MariaDB. If a table is found to have a possible incompatibility,
mariadb-
upgrade
performs a table check. If any problems are found, a table
       repair is attempted."
807,2,mariadb-upgrade,"If any problems are found, a table
       repair is attempted. Note
On Windows Server 2008 and Windows Vista, you must run
mariadb-upgrade
with administrator privileges. You can do this
           by running a Command Prompt as Administrator and running the
           command."
807,3,mariadb-upgrade,"You can do this
           by running a Command Prompt as Administrator and running the
           command. Failure to do so may result in the upgrade failing to
           execute correctly. Caution
You should always back up your current MariaDB installation
before
performing an upgrade."
807,4,mariadb-upgrade,"Caution
You should always back up your current MariaDB installation
before
performing an upgrade. To use
mariadb-upgrade
, make sure that the server is running, and
       then invoke it like this:

           shell>
mariadb-upgrade [
options
]
After running
mariadb-upgrade
, stop the server and restart it so
       that any changes made to the system tables take effect. mariadb-upgrade
executes the following commands to check and
       repair tables and to upgrade the system tables:

           mariadb-check --all-databases --check-upgrade --auto-repair
           mariadb <
fix_priv_tables
mariadb-check --all-databases --check-upgrade --fix-db-names --fix-table-names

       Notes about the preceding commands:

       â¢   Because
mariadb-upgrade
invokes
mariadb-check
with the
--all-databases
option, it processes all tables in all
           databases, which might take a long time to complete."
807,5,mariadb-upgrade,"mariadb-upgrade
executes the following commands to check and
       repair tables and to upgrade the system tables:

           mariadb-check --all-databases --check-upgrade --auto-repair
           mariadb <
fix_priv_tables
mariadb-check --all-databases --check-upgrade --fix-db-names --fix-table-names

       Notes about the preceding commands:

       â¢   Because
mariadb-upgrade
invokes
mariadb-check
with the
--all-databases
option, it processes all tables in all
           databases, which might take a long time to complete. Each
           table is locked and therefore unavailable to other sessions
           while it is being processed. Check and repair operations can
           be time-consuming, particularly for large tables."
807,6,mariadb-upgrade,"Check and repair operations can
           be time-consuming, particularly for large tables. â¢   For details about what checks the
--check-upgrade
option
           entails, see the description of the FOR UPGRADE option of the
           CHECK TABLE statement. â¢
fix_priv_tables
represents a script generated internally by
mariadb-upgrade
that contains SQL statements to upgrade the
           tables in the mysql database."
807,7,mariadb-upgrade,"â¢
fix_priv_tables
represents a script generated internally by
mariadb-upgrade
that contains SQL statements to upgrade the
           tables in the mysql database. All checked and repaired tables are marked with the current
       MariaDB version number. This ensures that next time you run
mariadb-upgrade
with the same version of the server, it can tell
       whether there is any need to check or repair the table again."
807,8,mariadb-upgrade,"This ensures that next time you run
mariadb-upgrade
with the same version of the server, it can tell
       whether there is any need to check or repair the table again. mariadb-upgrade
also saves the MariaDB version number in a file
       named mariadb-upgrade_info in the data directory. This is used to
       quickly check whether all tables have been checked for this
       release so that table-checking can be skipped."
807,9,mariadb-upgrade,"This is used to
       quickly check whether all tables have been checked for this
       release so that table-checking can be skipped. To ignore this file
       and perform the check regardless, use the
--force
option. For this reason,
mariadb-upgrade
needs to be run as a user with
       write access to the data directory."
807,10,mariadb-upgrade,"For this reason,
mariadb-upgrade
needs to be run as a user with
       write access to the data directory. If you install MariaDB from RPM packages on Linux, you must
       install the server and client RPMs. mariadb-upgrade
is included
       in the server RPM but requires the client RPM because the latter
       includes
mariadb-check
."
807,11,mariadb-upgrade,"mariadb-upgrade
is included
       in the server RPM but requires the client RPM because the latter
       includes
mariadb-check
. mariadb-upgrade
supports the following options, which can be
       specified on the command line or in the [mariadb-upgrade] and
       [client] option file groups. Other options are passed to
mariadb-
check
."
807,12,mariadb-upgrade,"Other options are passed to
mariadb-
check
. For example, it might be necessary to specify the
--password[=
password
]
option. mariadb-upgrade
also supports the
       options for processing option files."
807,13,mariadb-upgrade,"mariadb-upgrade
also supports the
       options for processing option files. â¢
--help
,
-? Display a short help message and exit."
807,14,mariadb-upgrade,"Display a short help message and exit. â¢
--basedir=
path
Old option accepted for backward compatibility but ignored. â¢
--character-sets-dir=
path
Old option accepted for backward compatibility but ignored."
807,15,mariadb-upgrade,"â¢
--character-sets-dir=
path
Old option accepted for backward compatibility but ignored. â¢
--check-if-upgrade-is-needed
Exit with a status code indicating if an upgrade is needed. Returns 0 if upgrade needed or current version couldn't be
           determined, 1 when no action required."
807,16,mariadb-upgrade,"Returns 0 if upgrade needed or current version couldn't be
           determined, 1 when no action required. â¢
--datadir=
path
Old option accepted for backward compatibility but ignored. â¢
--debug=
path
,
-#
path
For debug builds, output debug log."
807,17,mariadb-upgrade,"â¢
--debug=
path
,
-#
path
For debug builds, output debug log. â¢
--debug-check
Print some debugging information when the program exits. â¢
--debug-info
,
-T
Print debugging information and memory and CPU usage
           statistics when the program exits."
807,18,mariadb-upgrade,"â¢
--debug-info
,
-T
Print debugging information and memory and CPU usage
           statistics when the program exits. â¢
--default-character-set=
name
Old option accepted for backward compatibility but ignored. â¢
--force
Ignore the mariadb-upgrade_info file and force execution of
mariadb-check
even if
mariadb-upgrade
has already been
           executed for the current version of MariaDB."
807,19,mariadb-upgrade,"â¢
--force
Ignore the mariadb-upgrade_info file and force execution of
mariadb-check
even if
mariadb-upgrade
has already been
           executed for the current version of MariaDB. â¢
--host
Connect to MariaDB on the given host. â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server."
807,20,mariadb-upgrade,"â¢
--password[=
password
]
,
-p[
password
]
The password to use when connecting to the server. If you use
           the short option form (
-p
), you
cannot
have a space between
           the option and the password. If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-upgrade
prompts for one."
807,21,mariadb-upgrade,"If you omit the
password
value
           following the
--password
or
-p
option on the command line,
mariadb-upgrade
prompts for one. Specifying a password on the command line should be considered
           insecure. You can use an option file to avoid giving the
           password on the command line."
807,22,mariadb-upgrade,"You can use an option file to avoid giving the
           password on the command line. â¢
--port=
port_num
,
-P
port_num
The TCP/IP port number to use for the connection. â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server."
807,23,mariadb-upgrade,"â¢
--protocol={TCP|SOCKET|PIPE|MEMORY}
The connection protocol to use for connecting to the server. It is useful when the other connection parameters normally
           would cause a protocol to be used other than the one you want. â¢
--silent
Print less information."
807,24,mariadb-upgrade,"â¢
--silent
Print less information. â¢
--socket=
path
,
-S
path
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags)."
807,25,mariadb-upgrade,"â¢
--ssl
Enable SSL for connection (automatically enabled with other
           flags). Disable with
--skip-ssl
. â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
)."
807,26,mariadb-upgrade,"â¢
--ssl-ca=
name
CA file in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-capath=
name
CA directory (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
)."
807,27,mariadb-upgrade,"â¢
--ssl-cert=
name
X509 cert in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-cipher=
name
SSL cipher to use (check OpenSSL docs, implies
--ssl
). â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
)."
807,28,mariadb-upgrade,"â¢
--ssl-key=
name
X509 key in PEM format (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crl=
name
Certificate revocation list (check OpenSSL docs, implies
--ssl
). â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
)."
807,29,mariadb-upgrade,"â¢
--ssl-crlpath=
name
Certificate revocation list path (check OpenSSL docs, implies
--ssl
). â¢
--ssl-verify-server-cert
Verify server's ""Common Name"" in its cert against hostname
           used when connecting. This option is disabled by default."
807,30,mariadb-upgrade,"This option is disabled by default. â¢
--tmpdir=
path
,
-t
path
The path name of the directory to use for creating temporary
           files. â¢
--upgrade-system-tables
,
-s
Only upgrade the system tables in the mysql database."
807,31,mariadb-upgrade,"â¢
--upgrade-system-tables
,
-s
Only upgrade the system tables in the mysql database. Tables
           in other databases are not checked or touched. â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server and
           not using the current login."
807,32,mariadb-upgrade,"â¢
--user=
user_name
,
-u
user_name
The MariaDB user name to use when connecting to the server and
           not using the current login. â¢
--verbose
Display more output about the process. Using it twice will
           print connection arguments; using it 3 times will print out
           all CHECK, RENAME and ALTER TABLE commands used during the
           check phase; using it 4 times (added in MariaDB 10.0.14) will
           also write out all mariadb-check commands used; using it 5
           times will print all the mariadb commands used and their
           results while running mariadb-fix-privilege-tables script."
807,33,mariadb-upgrade,"Using it twice will
           print connection arguments; using it 3 times will print out
           all CHECK, RENAME and ALTER TABLE commands used during the
           check phase; using it 4 times (added in MariaDB 10.0.14) will
           also write out all mariadb-check commands used; using it 5
           times will print all the mariadb commands used and their
           results while running mariadb-fix-privilege-tables script. â¢
--version
,
-V
Output version information and exit. â¢
--version-check
,
-k
Run this program only if its 'server version' matches the
           version of the server to which it's connecting."
807,34,mariadb-upgrade,"â¢
--version-check
,
-k
Run this program only if its 'server version' matches the
           version of the server to which it's connecting. Note: the
           'server version' of the program is the version of the MariaDB
           server with which it was built/distributed. Defaults to on;
           use
--skip-version-check
to disable."
807,35,mariadb-upgrade,"Note: the
           'server version' of the program is the version of the MariaDB
           server with which it was built/distributed. Defaults to on;
           use
--skip-version-check
to disable. â¢
--write-binlog
Cause binary logging to be enabled while
mariadb-upgrade
runs."
808,0,mariadb-waitpid,"mariadb-waitpid
signals a process to terminate and waits for the
       process to exit. It uses the kill() system call and Unix signals,
       so it runs on Unix and Unix-like systems. Invoke
mariadb-waitpid
like this:

           shell>
mariadb-waitpid [
options
]
pid wait_time
mariadb-waitpid
sends signal 0 to the process identified by
pid
and waits up to
wait_time
seconds for the process to terminate."
808,1,mariadb-waitpid,"Invoke
mariadb-waitpid
like this:

           shell>
mariadb-waitpid [
options
]
pid wait_time
mariadb-waitpid
sends signal 0 to the process identified by
pid
and waits up to
wait_time
seconds for the process to terminate. pid
and
wait_time
must be positive integers. If process termination occurs within the wait time or the process
       does not exist,
mariadb-waitpid
returns 0."
808,2,mariadb-waitpid,"If process termination occurs within the wait time or the process
       does not exist,
mariadb-waitpid
returns 0. Otherwise, it returns
       1. If the kill() system call cannot handle signal 0,
mariadb-
waitpid()
uses signal 1 instead."
808,3,mariadb-waitpid,"If the kill() system call cannot handle signal 0,
mariadb-
waitpid()
uses signal 1 instead. mariadb-waitpid
supports the following options:

       â¢
--help
,
-? ,
-I
Display a help message and exit."
808,4,mariadb-waitpid,",
-I
Display a help message and exit. â¢
--verbose
,
-v
Verbose mode. Display a warning if signal 0 could not be used
           and signal 1 is used instead."
808,5,mariadb-waitpid,"â¢
--verbose
,
-v
Verbose mode. Display a warning if signal 0 could not be used
           and signal 1 is used instead. â¢
--version
,
-V
Display version information and exit."
809,0,mysql-test-run.pl,"The
mariadb-test-run.pl
Perl script is the main application used
       to run the MariaDB test suite. It invokes
mariadb-test
to run
       individual test cases. Invoke
mariadb-test-run.pl
in the mariadb-test directory like
       this:

           shell>
mariadb-test-run.pl [
options
] [
test_name
] ..."
809,1,mysql-test-run.pl,"Invoke
mariadb-test-run.pl
in the mariadb-test directory like
       this:

           shell>
mariadb-test-run.pl [
options
] [
test_name
] ... Each
test_name
argument names a test case. The test case file that
       corresponds to the test name is t/
test_name
.test."
809,2,mysql-test-run.pl,"The test case file that
       corresponds to the test name is t/
test_name
.test. For each
test_name
argument,
mariadb-test-run.pl
runs the named
       test case. With no
test_name
arguments,
mariadb-test-run.pl
runs
       all .test files in the t subdirectory."
809,3,mysql-test-run.pl,"With no
test_name
arguments,
mariadb-test-run.pl
runs
       all .test files in the t subdirectory. If no suffix is given for the test name, a suffix of .test is
       assumed. Any leading path name is ignored."
809,4,mysql-test-run.pl,"Any leading path name is ignored. These commands are
       equivalent:

           shell>
mariadb-test-run.pl mytest
shell>
mariadb-test-run.pl mytest.test
shell>
mariadb-test-run.pl t/mytest.test
A suite name can be given as part of the test name. That is, the
       syntax for naming a test is:

           [
suite_name
.]
test_name
[."
809,5,mysql-test-run.pl,"That is, the
       syntax for naming a test is:

           [
suite_name
.]
test_name
[. suffix
]

       If a suite name is given,
mariadb-test-run.pl
looks in that suite
       for the test. The test file corresponding to a test named
suite_name.test_name
is found in
       suite/
suite_name
/t/
test_name
.test."
809,6,mysql-test-run.pl,"The test file corresponding to a test named
suite_name.test_name
is found in
       suite/
suite_name
/t/
test_name
.test. There is also an implicit suite
       name main for the tests in the top t directory. With no suite
       name,
mariadb-test-run.pl
looks in the default list of suites for
       a match and runs the test in any suites where it finds the test."
809,7,mysql-test-run.pl,"With no suite
       name,
mariadb-test-run.pl
looks in the default list of suites for
       a match and runs the test in any suites where it finds the test. Suppose that the default suite list is main, binlog, rpl, and that
       a test mytest.test exists in the main and rpl suites. With an
       argument of mytest or mytest.test,
mariadb-test-run.pl
will run
       mytest.test from the main and rpl suites."
809,8,mysql-test-run.pl,"With an
       argument of mytest or mytest.test,
mariadb-test-run.pl
will run
       mytest.test from the main and rpl suites. To run a family of test cases for which the names share a common
       prefix, use the
--do-test=
prefix
option. For example,
--do-test=rpl
runs the replication tests (test cases that have
       names beginning with rpl)."
809,9,mysql-test-run.pl,"For example,
--do-test=rpl
runs the replication tests (test cases that have
       names beginning with rpl). --skip-test
has the opposite effect of
       skipping test cases for which the names share a common prefix. The argument for the
--do-test
and
--skip-test
options also allows
       more flexible specification of which tests to perform or skip."
809,10,mysql-test-run.pl,"The argument for the
--do-test
and
--skip-test
options also allows
       more flexible specification of which tests to perform or skip. If
       the argument contains a pattern metacharacter other than a lone
       period, it is interpreted as a Perl regular expression and applies
       to test names that match the pattern. If the argument contains a
       lone period or does not contain any pattern metacharacters, it is
       interpreted the same way as previously and matches test names that
       begin with the argument value."
809,11,mysql-test-run.pl,"If the argument contains a
       lone period or does not contain any pattern metacharacters, it is
       interpreted the same way as previously and matches test names that
       begin with the argument value. For example,
--do-test=testa
matches tests that begin with testa,
--do-test=main.testa
matches
       tests in the main test suite that begin with testa, and
--do-test=main.*testa
matches test names that contain main
       followed by testa with anything in between. In the latter case,
       the pattern match is not anchored to the beginning of the test
       name, so it also matches names such as xmainytesta."
809,12,mysql-test-run.pl,"In the latter case,
       the pattern match is not anchored to the beginning of the test
       name, so it also matches names such as xmainytesta. To perform setup prior to running tests,
mariadb-test-run.pl
needs
       to invoke
mariadbd
with the
--bootstrap
and
--skip-grant-tables
options. If MariaDB was configured with the
--disable-grant-options
option,
--bootstrap
,
--skip-grant-tables
,
       and
--init-file
will be disabled."
809,13,mysql-test-run.pl,"If MariaDB was configured with the
--disable-grant-options
option,
--bootstrap
,
--skip-grant-tables
,
       and
--init-file
will be disabled. To handle this, set the
       MYSQLD_BOOTSTRAP environment variable to the full path name of a
       server that has all options enabled. mariadb-test-run.pl
will use
       that server to perform setup; it is not used to run the tests."
809,14,mysql-test-run.pl,"mariadb-test-run.pl
will use
       that server to perform setup; it is not used to run the tests. The init_file test will fail if
--init-file
is disabled. This is
       an expected failure that can be handled as follows:

           shell>
export MYSQLD_BOOTSTRAP
shell>
MYSQLD_BOOTSTRAP=/full/path/to/mariadbd
shell>
make test force=""--skip-test=init_file""
To run
mariadb-test-run.pl
on Windows, you'll need either Cygwin
       or ActiveState Perl to run it."
809,15,mysql-test-run.pl,"This is
       an expected failure that can be handled as follows:

           shell>
export MYSQLD_BOOTSTRAP
shell>
MYSQLD_BOOTSTRAP=/full/path/to/mariadbd
shell>
make test force=""--skip-test=init_file""
To run
mariadb-test-run.pl
on Windows, you'll need either Cygwin
       or ActiveState Perl to run it. You may also need to install the
       modules required by the script. To run the test script, change
       location into the mariadb-test directory, set the MTR_VS_CONFIG
       environment variable to the configuration you selected earlier (or
       use the
--vs-config
option), and invoke
mariadb-test-run.pl
."
809,16,mysql-test-run.pl,"To run the test script, change
       location into the mariadb-test directory, set the MTR_VS_CONFIG
       environment variable to the configuration you selected earlier (or
       use the
--vs-config
option), and invoke
mariadb-test-run.pl
. For
       example (using Cygwin and the
bash
shell):

           shell>
cd mariadb-test
shell>
export MTR_VS_CONFIG=debug
shell>
./mariadb-test-run.pl --force --timer
shell>
./mariadb-test-run.pl --force --timer --ps-protocol
mariadb-test-run.pl
uses several environment variables. Some of
       them are listed in the following table."
809,17,mysql-test-run.pl,"Some of
       them are listed in the following table. Some of these are set from
       the outside and used by
mariadb-test-run.pl
, others are set by
mariadb-test-run.pl
instead, and may be referred to in tests. ââââââââââââââââââââ¬âââââââââââââââââââââââââââââ
       â
Variable
â
Meaning
â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_VERSION      â If set to 1, will run      â
       â                  â the older version 1 of     â
       â                  â
mariadb-test-run.pl
."
809,18,mysql-test-run.pl,"ââââââââââââââââââââ¬âââââââââââââââââââââââââââââ
       â
Variable
â
Meaning
â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_VERSION      â If set to 1, will run      â
       â                  â the older version 1 of     â
       â                  â
mariadb-test-run.pl
. â
       â                  â This will affect what      â
       â                  â functionailty is           â
       â                  â available and what         â
       â                  â command line options are   â
       â                  â supported. â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_MEM          â If set to anything, will   â
       â                  â run tests with files in    â
       â                  â ""memory"" using tmpfs or    â
       â                  â                 ramdisk."
809,19,mysql-test-run.pl,"â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_MEM          â If set to anything, will   â
       â                  â run tests with files in    â
       â                  â ""memory"" using tmpfs or    â
       â                  â                 ramdisk. â
       â                  â Not available on           â
       â                  â Windows. Same as           â
       â                  â
--mem
â
       â                  â option                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_PARALLEL     â If set, defines number     â
       â                  â of parallel threads        â
       â                  â executing tests."
809,20,mysql-test-run.pl,"Same as           â
       â                  â
--mem
â
       â                  â option                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_PARALLEL     â If set, defines number     â
       â                  â of parallel threads        â
       â                  â executing tests. Same as   â
       â                  â
--parallel
â
       â                  â option                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_BUILD_THREAD â If set, defines which port â
       â                  â number range is used for   â
       â                  â the server                 â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_PORT_BASE    â If set, defines which port â
       â                  â number range is used for   â
       â                  â the server                 â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_
NAME
_TIMEOUT â Setting of a timeout in    â
       â                  â minutes or seconds,        â
       â                  â corresponding to command   â
       â                  â line option                â
       â                  â
--
name
-timeout
. Available  â
       â                  â timeout names are          â
       â                  â TESTCASE, SUITE (both in   â
       â                  â minutes) and START,        â
       â                  â SHUTDOWN (both in          â
       â                  â seconds)."
809,21,mysql-test-run.pl,"Available  â
       â                  â timeout names are          â
       â                  â TESTCASE, SUITE (both in   â
       â                  â minutes) and START,        â
       â                  â SHUTDOWN (both in          â
       â                  â seconds). These variables  â
       â                  â are supported from MySQL   â
       â                  â 5.1.44. â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TEST       â Path name to
mariadb-test
â
       â                  â binary                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQLD_BOOTSTRAP â Full path name to
mariadbd
â
       â                  â that has all options       â
       â                  â enabled                    â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQLTEST_VARDIR â Path name to the var       â
       â                  â directory that is used for â
       â                  â                 logs,      â
       â                  â temporary files, and so    â
       â                  â forth                      â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TEST_DIR   â Full path to the           â
       â                  â mariadb-test directory     â
       â                  â where tests                â
       â                  â                 are being  â
       â                  â run from                   â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TMP_DIR    â Path to temp directory     â
       â                  â used for temporary files   â
       â                  â during tests               â
       ââââââââââââââââââââ´âââââââââââââââââââââââââââââ

       The variable MTR_PORT_BASE was added in MySQL 5.1.45 as a more
       logical replacement for MTR_BUILD_THREAD."
809,22,mysql-test-run.pl,"â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TEST       â Path name to
mariadb-test
â
       â                  â binary                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQLD_BOOTSTRAP â Full path name to
mariadbd
â
       â                  â that has all options       â
       â                  â enabled                    â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQLTEST_VARDIR â Path name to the var       â
       â                  â directory that is used for â
       â                  â                 logs,      â
       â                  â temporary files, and so    â
       â                  â forth                      â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TEST_DIR   â Full path to the           â
       â                  â mariadb-test directory     â
       â                  â where tests                â
       â                  â                 are being  â
       â                  â run from                   â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TMP_DIR    â Path to temp directory     â
       â                  â used for temporary files   â
       â                  â during tests               â
       ââââââââââââââââââââ´âââââââââââââââââââââââââââââ

       The variable MTR_PORT_BASE was added in MySQL 5.1.45 as a more
       logical replacement for MTR_BUILD_THREAD. It gives the actual port
       number directly (will be rounded down to a multiple of 10). If you
       use MTR_BUILD_THREAD, the port number is found by multiplying this
       by 10 and adding 10000."
809,23,mysql-test-run.pl,"If you
       use MTR_BUILD_THREAD, the port number is found by multiplying this
       by 10 and adding 10000. Tests sometimes rely on certain environment variables being
       defined. For example, certain tests assume that MARIADB-TEST is
       defined so that
mariadb-test
can invoke itself with exec
       $MYSQL_TEST."
809,24,mysql-test-run.pl,"For example, certain tests assume that MARIADB-TEST is
       defined so that
mariadb-test
can invoke itself with exec
       $MYSQL_TEST. Other tests may refer to the last three variables listed in the
       preceding table, to locate files to read or write. For example,
       tests that need to create files will typically put them in
       $MYSQL_TMP_DIR/
file_name
."
809,25,mysql-test-run.pl,"For example,
       tests that need to create files will typically put them in
       $MYSQL_TMP_DIR/
file_name
. If you are running
mariadb-test-run.pl
version 1 by setting
       MTR_VERSION, note that this only affects the test driver, not the
       test client (and its language) or the tests themselves. A few tests might not run with version 1 because they depend on
       some feature of version 2."
809,26,mysql-test-run.pl,"A few tests might not run with version 1 because they depend on
       some feature of version 2. You may have those tests skipped by
       adding the test name to the file lib/v1/incompatible.tests. This
       feature is available from MySQL 5.1.40."
809,27,mysql-test-run.pl,"This
       feature is available from MySQL 5.1.40. mariadb-test-run.pl
supports the options in the following list. An
       argument of
--
tells
mariadb-test-run.pl
not to process any
       following arguments as options."
809,28,mysql-test-run.pl,"An
       argument of
--
tells
mariadb-test-run.pl
not to process any
       following arguments as options. â¢
--help
,
-h
Display a help message and exit. â¢
--big-test
Allow tests marked as ""big"" to run."
809,29,mysql-test-run.pl,"â¢
--big-test
Allow tests marked as ""big"" to run. Tests can be thus marked
           by including the line
--source include/big_test.inc
, and they
           will only be run if this option is given, or if the
           environment variable BIG_TEST is set to 1. Repeat this option
           twice to run only ""big"" tests."
809,30,mysql-test-run.pl,"Repeat this option
           twice to run only ""big"" tests. This is typically used for tests that take a very long to run,
           or that use many resources, so that they are not suitable for
           running as part of a normal test suite run. â¢
--boot-dbx
Run the mariadbd server used for bootstrapping the database
           through the dbx debugger."
809,31,mysql-test-run.pl,"â¢
--boot-dbx
Run the mariadbd server used for bootstrapping the database
           through the dbx debugger. â¢
--boot-ddd
Run the mariadbd server used for bootstrapping the database
           through the ddd debugger. â¢
--boot-gdb
Run the mariadbd server used for bootstrapping the database
           through the gdb debugger."
809,32,mysql-test-run.pl,"â¢
--boot-gdb
Run the mariadbd server used for bootstrapping the database
           through the gdb debugger. â¢
--[mtr-]build-thread=
number
Specify a number to calculate port numbers from. The formula
           is 10 *
build_thread
+ 10000."
809,33,mysql-test-run.pl,"The formula
           is 10 *
build_thread
+ 10000. Instead of a number, it can be
           set to auto, which is also the default value, in which case
mariadb-test-run.pl
will allocate a number unique to this
           host. The value (number or auto) can also be set with the
           MTR_BUILD_THREAD environment variable."
809,34,mysql-test-run.pl,"The value (number or auto) can also be set with the
           MTR_BUILD_THREAD environment variable. The more logical
--port-base
is supported as an alternative. â¢
--callgrind
Instructs
valgrind
to use
callgrind
."
809,35,mysql-test-run.pl,"â¢
--callgrind
Instructs
valgrind
to use
callgrind
. â¢
--check-testcases
Check test cases for side effects. This is done by checking
           system state before and after each test case; if there is any
           difference, a warning to that effect will be written, but the
           test case will not be marked as failed because of it."
809,36,mysql-test-run.pl,"This is done by checking
           system state before and after each test case; if there is any
           difference, a warning to that effect will be written, but the
           test case will not be marked as failed because of it. This
           check is enabled by default. â¢
--client-bindir=
path
The path to the directory where client binaries are located."
809,37,mysql-test-run.pl,"â¢
--client-bindir=
path
The path to the directory where client binaries are located. â¢
--client-dbx
Start
mariadb-test
in the
dbx
debugger. â¢
--client-ddd
Start
mariadb-test
in the
ddd
debugger."
809,38,mysql-test-run.pl,"â¢
--client-ddd
Start
mariadb-test
in the
ddd
debugger. â¢
--client-debugger=
debugger
Start
mariadb-test
in the named debugger. â¢
--client-gdb
Start
mariadb-test
in the
gdb
debugger."
809,39,mysql-test-run.pl,"â¢
--client-gdb
Start
mariadb-test
in the
gdb
debugger. â¢
--client-libdir=
path
The path to the directory where client libraries are located. â¢
--combination=
value
Extra options to pass to
mariadbd
."
809,40,mysql-test-run.pl,"â¢
--combination=
value
Extra options to pass to
mariadbd
. The value should consist of
           one or more comma-separated
mariadbd
options. This option is
           similar to
--mariadbd
but should be given two or more times."
809,41,mysql-test-run.pl,"This option is
           similar to
--mariadbd
but should be given two or more times. mariadb-test-run.pl
executes multiple test runs, using the
           options for each instance of
--combination
in successive runs. If
--combination
is given only once, it has no effect."
809,42,mysql-test-run.pl,"If
--combination
is given only once, it has no effect. For
           test runs specific to a given test suite, an alternative to
           the use of
--combination
is to create a combinations file in
           the suite directory. The file should contain a section of
           options for each test run."
809,43,mysql-test-run.pl,"The file should contain a section of
           options for each test run. â¢
--comment=
str
Write
str
to the output within lines filled with #, as a form
           of banner. â¢
--compress
Compress all information sent between the client and the
           server if both support compression."
809,44,mysql-test-run.pl,"â¢
--compress
Compress all information sent between the client and the
           server if both support compression. â¢
--cursor-protocol
Use the cursor protocol between client and server (implies
--ps-protocol
). â¢
--dbx
Start the
mariadbd(s)
in the
dbx
debugger."
809,45,mysql-test-run.pl,"â¢
--dbx
Start the
mariadbd(s)
in the
dbx
debugger. â¢
--ddd
Start the
mariadbd(s)
in the
ddd
debugger. â¢
--debug
Dump trace output for all clients and servers."
809,46,mysql-test-run.pl,"â¢
--debug
Dump trace output for all clients and servers. â¢
--debug-common
Same as
--debug
, but sets the 'd' debug flags to
           ""query,info,error,enter,exit"". â¢
--debug-server
Use debug version of server, but without turning on tracing."
809,47,mysql-test-run.pl,"â¢
--debug-server
Use debug version of server, but without turning on tracing. â¢
--debugger=
debugger
Start
mariadbd
using the named debugger. â¢
--debug-sync-timeout=
N
Controls whether the Debug Sync facility for testing and
           debugging is enabled."
809,48,mysql-test-run.pl,"â¢
--debug-sync-timeout=
N
Controls whether the Debug Sync facility for testing and
           debugging is enabled. The option value is a timeout in
           seconds. The default value is 300."
809,49,mysql-test-run.pl,"The default value is 300. A value of 0 disables Debug
           Sync. The value of this option also becomes the default
           timeout for individual synchronization points."
809,50,mysql-test-run.pl,"The value of this option also becomes the default
           timeout for individual synchronization points. mariadb-test-run.pl
passes
--loose-debug-sync-timeout=
N
to
mariadbd
. The
--loose
prefix is used so that
mariadbd
does not
           fail if Debug Sync is not compiled in."
809,51,mysql-test-run.pl,"The
--loose
prefix is used so that
mariadbd
does not
           fail if Debug Sync is not compiled in. â¢
--defaults-file=
file_name
Use the named file as fixed config file template for all
           tests. â¢
--defaults_extra_file=
file_name
Add setting from the named file to all generated configs."
809,52,mysql-test-run.pl,"â¢
--defaults_extra_file=
file_name
Add setting from the named file to all generated configs. â¢
--do-test=
prefix
|
regex
Run all test cases having a name that begins with the given
prefix
value, or fulfils the
regex
. This option provides a
           convenient way to run a family of similarly named tests."
809,53,mysql-test-run.pl,"This option provides a
           convenient way to run a family of similarly named tests. The argument for the
--do-test
option also allows more
           flexible specification of which tests to perform. If the
           argument contains a pattern metacharacter other than a lone
           period, it is interpreted as a Perl regular expression and
           applies to test names that match the pattern."
809,54,mysql-test-run.pl,"If the
           argument contains a pattern metacharacter other than a lone
           period, it is interpreted as a Perl regular expression and
           applies to test names that match the pattern. If the argument
           contains a lone period or does not contain any pattern
           metacharacters, it is interpreted the same way as previously
           and matches test names that begin with the argument value. For
           example,
--do-test=testa
matches tests that begin with testa,
--do-test=main.testa
matches tests in the main test suite that
           begin with testa, and
--do-test=main.*testa
matches test names
           that contain main followed by testa with anything in between."
809,55,mysql-test-run.pl,"For
           example,
--do-test=testa
matches tests that begin with testa,
--do-test=main.testa
matches tests in the main test suite that
           begin with testa, and
--do-test=main.*testa
matches test names
           that contain main followed by testa with anything in between. In the latter case, the pattern match is not anchored to the
           beginning of the test name, so it also matches names such as
           xmainytestz. â¢
--dry-run
Don't run any tests, print the list of tests that were
           selected for execution."
809,56,mysql-test-run.pl,"â¢
--dry-run
Don't run any tests, print the list of tests that were
           selected for execution. â¢
--embedded-server
Use a version of
mariadb-test
built with the embedded server. â¢
--enable-disabled
Ignore any disabled.def file, and also run tests marked as
           disabled."
809,57,mysql-test-run.pl,"â¢
--enable-disabled
Ignore any disabled.def file, and also run tests marked as
           disabled. Success or failure of those tests will be reported
           the same way as other tests. â¢
--experimental=
file_name
Specify a file that contains a list of test cases that should
           be displayed with the [ exp-fail ] code rather than [ fail ]
           if they fail."
809,58,mysql-test-run.pl,"â¢
--experimental=
file_name
Specify a file that contains a list of test cases that should
           be displayed with the [ exp-fail ] code rather than [ fail ]
           if they fail. For an example of a file that might be specified via this
           option, see mariadb-test/collections/default.experimental. â¢
--extern
option
=
value
Use an already running server."
809,59,mysql-test-run.pl,"â¢
--extern
option
=
value
Use an already running server. The option/value pair is what
           is needed by the
mariadb
client to connect to the server. Each
--extern
option can only take one option/value pair as an
           argument, so you need to repeat
--extern
for each pair needed."
809,60,mysql-test-run.pl,"Each
--extern
option can only take one option/value pair as an
           argument, so you need to repeat
--extern
for each pair needed. Example:

                     ./mariadb-test-run.pl --extern socket=var/tmp/mariadbd.1.sock alias

           Note: If a test case has an .opt file that requires the server
           to be restarted with specific options, the file will not be
           used. The test case likely will fail as a result."
809,61,mysql-test-run.pl,"The test case likely will fail as a result. â¢
--fast
Do not perform controlled shutdown when servers need to be
           restarted or at the end of the test run. This is equivalent to
           using --shutdown-timeout=0."
809,62,mysql-test-run.pl,"This is equivalent to
           using --shutdown-timeout=0. â¢
--force-restart
Always restart servers between tests. â¢
--force
Normally,
mariadb-test-run.pl
exits if a test case fails."
809,63,mysql-test-run.pl,"â¢
--force
Normally,
mariadb-test-run.pl
exits if a test case fails. --force
causes execution to continue regardless of test case
           failure. â¢
--gcov
Collect coverage information after the test."
809,64,mysql-test-run.pl,"â¢
--gcov
Collect coverage information after the test. The result is a
gcov
file per source and header file. â¢
--gcov-src-dir
Colllect coverage only within the given subdirectory."
809,65,mysql-test-run.pl,"â¢
--gcov-src-dir
Colllect coverage only within the given subdirectory. For
           example, if you're only developing the SQL layer, it makes
           sense to use
--gcov-src-dir=sql
. â¢
--gdb
Start the
mariadbd(s)
in the
gdb
debugger."
809,66,mysql-test-run.pl,"â¢
--gdb
Start the
mariadbd(s)
in the
gdb
debugger. â¢
--gprof
Collect profiling information using the
gprof
profiling tool. â¢
--manual-dbx
Use a server that has already been started by the user in the
dbx
debugger."
809,67,mysql-test-run.pl,"â¢
--manual-dbx
Use a server that has already been started by the user in the
dbx
debugger. â¢
--manual-ddd
Use a server that has already been started by the user in the
ddd
debugger. â¢
--manual-debug
Use a server that has already been started by the user in a
           debugger."
809,68,mysql-test-run.pl,"â¢
--manual-debug
Use a server that has already been started by the user in a
           debugger. â¢
--manual-gdb
Use a server that has already been started by the user in the
gdb
debugger. â¢
--manual-lldb
Use a server that has already been started by the user in the
lldb
debugger."
809,69,mysql-test-run.pl,"â¢
--manual-lldb
Use a server that has already been started by the user in the
lldb
debugger. â¢
--mark-progress
Marks progress with timing (in milliseconds) and line number
           in var/log/
testname
.progress. â¢
--max-connections=
num
The maximum number of simultaneous server connections that may
           be used per test."
809,70,mysql-test-run.pl,"â¢
--max-connections=
num
The maximum number of simultaneous server connections that may
           be used per test. If not set, the maximum is 128. Minimum
           allowed limit is 8, maximum is 5120."
809,71,mysql-test-run.pl,"Minimum
           allowed limit is 8, maximum is 5120. Corresponds to the same
           option for
mariadb-test
. â¢
--max-save-core=
N
Limit the number of core files saved, to avoid filling up
           disks in case of a frequently crashing server."
809,72,mysql-test-run.pl,"â¢
--max-save-core=
N
Limit the number of core files saved, to avoid filling up
           disks in case of a frequently crashing server. Defaults to 5,
           set to 0 for no limit. May also be set with the environment
           variable MTR_MAX_SAVE_CORE

       â¢
--max-save-datadir=
N
Limit the number of data directories saved after failed tests,
           to avoid filling up disks in case of frequent failures."
809,73,mysql-test-run.pl,"May also be set with the environment
           variable MTR_MAX_SAVE_CORE

       â¢
--max-save-datadir=
N
Limit the number of data directories saved after failed tests,
           to avoid filling up disks in case of frequent failures. Defaults to 20, set to 0 for no limit. May also be set with
           the environment variable MTR_MAX_SAVE_DATADIR

       â¢
--max-test-fail=
N
Stop execution after the specified number of tests have
           failed, to avoid using up resources (and time) in case of
           massive failures."
809,74,mysql-test-run.pl,"May also be set with
           the environment variable MTR_MAX_SAVE_DATADIR

       â¢
--max-test-fail=
N
Stop execution after the specified number of tests have
           failed, to avoid using up resources (and time) in case of
           massive failures. retries are not counted, nor are failures of
           tests marked experimental. Defaults to 10, set to 0 for no
           limit."
809,75,mysql-test-run.pl,"Defaults to 10, set to 0 for no
           limit. May also be set with the environment variable
           MTR_MAX_TEST_FAIL

       â¢
--mem
This option is not supported on Windows. Run the test suite in memory, using tmpfs or ramdisk."
809,76,mysql-test-run.pl,"Run the test suite in memory, using tmpfs or ramdisk. This can
           decrease test times significantly, in particular if you would
           otherwise be running over a remote file system. mariadb-test-run.pl
attempts to find a suitable location using
           a built-in list of standard locations for tmpfs and puts the
           var directory there."
809,77,mysql-test-run.pl,"mariadb-test-run.pl
attempts to find a suitable location using
           a built-in list of standard locations for tmpfs and puts the
           var directory there. This option also affects placement of
           temporary files, which are created in var/tmp. The default list includes /dev/shm."
809,78,mysql-test-run.pl,"The default list includes /dev/shm. You can also enable this
           option by setting the environment variable MTR_MEM[=
dir_name
]. If
dir_name
is given, it is added to the beginning of the list
           of locations to search, so it takes precedence over any
           built-in locations."
809,79,mysql-test-run.pl,"If
dir_name
is given, it is added to the beginning of the list
           of locations to search, so it takes precedence over any
           built-in locations. Once you have run tests with
--mem
within a
           mariadb-testdirectory, a soflink var will have been set up to
           the temporary directory, and this will be re-used the next
           time, until the soflink is deleted. Thus, you do not have to
           repeat the
--mem
option next time."
809,80,mysql-test-run.pl,"Thus, you do not have to
           repeat the
--mem
option next time. â¢
--mariadbd=
value
Extra options to pass to
mariadbd
. The value should consist of
           one or more comma-separated
mariadbd
options."
809,81,mysql-test-run.pl,"The value should consist of
           one or more comma-separated
mariadbd
options. â¢
--mariadbd-env=
VAR=VAL
Specify additional environment settings for ""mariadbd"". Use
           additional
--mariadbd-env
options to set more than one
           variable."
809,82,mysql-test-run.pl,"Use
           additional
--mariadbd-env
options to set more than one
           variable. â¢
--nocheck-testcases
Disable the check for test case side effects; see
--check-testcases
for a description. â¢
--noreorder
Do not reorder tests to reduce number of restarts, but run
           them in exactly the order given."
809,83,mysql-test-run.pl,"â¢
--noreorder
Do not reorder tests to reduce number of restarts, but run
           them in exactly the order given. If a whole suite is to be
           run, the tests are run in alphabetical order, though similar
           combinations will be grouped together. If more than one suite
           is listed, the tests are run one suite at a time, in the order
           listed."
809,84,mysql-test-run.pl,"If more than one suite
           is listed, the tests are run one suite at a time, in the order
           listed. â¢
--notimer
Cause
mariadb-test
not to generate a timing file. The effect
           of this is that the report from each test case does not
           include the timing in milliseconds as it normally does."
809,85,mysql-test-run.pl,"The effect
           of this is that the report from each test case does not
           include the timing in milliseconds as it normally does. â¢
--nowarnings
Do not look for and report errors and warning in the server
           logs. â¢
--parallel={
N
|auto}
Run tests using
N
parallel threads."
809,86,mysql-test-run.pl,"â¢
--parallel={
N
|auto}
Run tests using
N
parallel threads. By default, 1 thread is
           used. Use
--parallel=auto
for auto-setting of
N
."
809,87,mysql-test-run.pl,"Use
--parallel=auto
for auto-setting of
N
. â¢
--[mtr-]port-base=
P
Specify base of port numbers to be used; a block of 10 will be
           allocated. P
should be divisible by 10; if it is not, it will
           be rounded down."
809,88,mysql-test-run.pl,"P
should be divisible by 10; if it is not, it will
           be rounded down. If running with more than one parallel test
           thread, thread 2 will use the next block of 10 and so on. If the port number is given as auto, which is also the
           default,
mariadb-test-run.pl
will allocate a number unique to
           this host."
809,89,mysql-test-run.pl,"If the port number is given as auto, which is also the
           default,
mariadb-test-run.pl
will allocate a number unique to
           this host. The value may also be given with the environment
           variable MTR_PORT_BASE. If both
--build-thread
and
--port-base
are used,
--port-base
takes precedence."
809,90,mysql-test-run.pl,"If both
--build-thread
and
--port-base
are used,
--port-base
takes precedence. â¢
--print-testcases
Do not run any tests, but print details about all tests, in
           the order they would have been run. â¢
--ps-protocol
Use the binary protocol between client and server."
809,91,mysql-test-run.pl,"â¢
--ps-protocol
Use the binary protocol between client and server. â¢
--record
Pass the
--record
option to
mariadb-test
. This option requires
           a specific test case to be named on the command line."
809,92,mysql-test-run.pl,"This option requires
           a specific test case to be named on the command line. â¢
--reorder
Reorder tests to minimize the number of server restarts
           needed. This is the default behavior."
809,93,mysql-test-run.pl,"This is the default behavior. There is no guarantee
           that a particular set of tests will always end up in the same
           order. â¢
--repeat=
N
Run each test
N
number of times."
809,94,mysql-test-run.pl,"â¢
--repeat=
N
Run each test
N
number of times. â¢
--report-features
First run a ""test"" that reports MariaDB features, displaying
           the output of SHOW ENGINES and SHOW VARIABLES. This can be
           used to verify that binaries are built with all required
           features."
809,95,mysql-test-run.pl,"This can be
           used to verify that binaries are built with all required
           features. â¢
--report-times
Report how much time has been spent on different phases of
           test execution. â¢
--retry=
N
If a test fails, it is retried up to a maximum of
N
runs
           (default 1)."
809,96,mysql-test-run.pl,"â¢
--retry=
N
If a test fails, it is retried up to a maximum of
N
runs
           (default 1). Retries are also limited by the maximum number of
           failures before stopping, set with the
--retry-failure
option. This option has no effect unless
--force
is also used; without
           it, test execution will terminate after the first failure."
809,97,mysql-test-run.pl,"This option has no effect unless
--force
is also used; without
           it, test execution will terminate after the first failure. The
--retry
and
--retry-failure
options do not affect how many
           times a test repeated with
--repeat
may fail in total, as each
           repetition is considered a new test case, which may in turn be
           retried if it fails. â¢
--retry-failure=
N
When using the
--retry
option to retry failed tests, stop when
           N failures have occurred (default 2)."
809,98,mysql-test-run.pl,"â¢
--retry-failure=
N
When using the
--retry
option to retry failed tests, stop when
           N failures have occurred (default 2). Setting it to 0 or 1
           effectively turns off retries. â¢
--shutdown-timeout=
SECONDS
Max number of seconds to wait for servers to do controlled
           shutdown before killing them."
809,99,mysql-test-run.pl,"â¢
--shutdown-timeout=
SECONDS
Max number of seconds to wait for servers to do controlled
           shutdown before killing them. Default is 10. â¢
--skip-combinations
Do not apply combinations; ignore combinations file or option."
809,100,mysql-test-run.pl,"â¢
--skip-combinations
Do not apply combinations; ignore combinations file or option. â¢
--skip-rpl
Skip replication test cases. â¢
--skip-ssl
Do not start
mariadbd
with support for SSL connections."
809,101,mysql-test-run.pl,"â¢
--skip-ssl
Do not start
mariadbd
with support for SSL connections. â¢
--skip-test=
regex
|
regex
Specify a regular expression to be applied to test case names. Cases with names that match the expression are skipped."
809,102,mysql-test-run.pl,"Cases with names that match the expression are skipped. tests
           to skip. The argument for the
--skip-test
option allows more flexible
           specification of which tests to skip."
809,103,mysql-test-run.pl,"The argument for the
--skip-test
option allows more flexible
           specification of which tests to skip. If the argument contains
           a pattern metacharacter other than a lone period, it is
           interpreted as a Perl regular expression and applies to test
           names that match the pattern. See the description of the
--do-test
option for details."
809,104,mysql-test-run.pl,"See the description of the
--do-test
option for details. â¢
--skip-test-list=
FILE
Skip the tests listed in FILE. Each line in the file is an
           entry and should be formatted as: <TESTNAME> : <COMMENT>

       â¢
--skip-*
--skip-*
options not otherwise recognized by
mariadb-test-run.pl
are passed to the master server."
809,105,mysql-test-run.pl,"Each line in the file is an
           entry and should be formatted as: <TESTNAME> : <COMMENT>

       â¢
--skip-*
--skip-*
options not otherwise recognized by
mariadb-test-run.pl
are passed to the master server. â¢
--sleep=
N
Pass
--sleep=
N
to
mariadb-test
. â¢
--sp-protocol
Create a stored procedure to execute all queries."
809,106,mysql-test-run.pl,"â¢
--sp-protocol
Create a stored procedure to execute all queries. â¢
--ssl
If
mariadb-test-run.pl
is started with the
--ssl
option, it
           sets up a secure connection for all test cases. In this case,
           if
mariadbd
does not support SSL,
mariadb-test-run.pl
exits
           with an error message: Couldn't find support for SSL

       â¢
--staging-run
Run a limited number of tests (no slow tests)."
809,107,mysql-test-run.pl,"In this case,
           if
mariadbd
does not support SSL,
mariadb-test-run.pl
exits
           with an error message: Couldn't find support for SSL

       â¢
--staging-run
Run a limited number of tests (no slow tests). Used for
           running staging trees with valgrind. â¢
--start
Initialize and start servers with the startup settings for the
           specified test case."
809,108,mysql-test-run.pl,"â¢
--start
Initialize and start servers with the startup settings for the
           specified test case. You can use this option to start a server
           to which you can connect later. For example, after building a
           source distribution you can start a server and connect to it
           with the
mariadb
client like this:

               shell>
cd mariadb-test
shell>
./mariadb-test-run.pl --start alias &
shell>
../mariadb -S ./var/tmp/master.sock -h localhost -u root
If no tests are named on the command line, the server(s) will
           be started with settings for the first test that would have
           been run without the
--start
option."
809,109,mysql-test-run.pl,"For example, after building a
           source distribution you can start a server and connect to it
           with the
mariadb
client like this:

               shell>
cd mariadb-test
shell>
./mariadb-test-run.pl --start alias &
shell>
../mariadb -S ./var/tmp/master.sock -h localhost -u root
If no tests are named on the command line, the server(s) will
           be started with settings for the first test that would have
           been run without the
--start
option. mariadb-test-run.pl
will stop once the server has been
           started, but will terminate if the server dies. If killed, it
           will also shut down the server."
809,110,mysql-test-run.pl,"If killed, it
           will also shut down the server. â¢
--start-and-exit
Same
--start
, but mariadb-test-run terminates and leaves just
           the server running. â¢
--start-dirty
This is similar to
--start
, but will skip the database
           initialization phase and assume that database files are
           already available."
809,111,mysql-test-run.pl,"â¢
--start-dirty
This is similar to
--start
, but will skip the database
           initialization phase and assume that database files are
           already available. Usually this means you must have run
           another test first. â¢
--start-from=
test_name
mariadb-test-run.pl
sorts the list of names of the test cases
           to be run, and then begins with
test_name
."
809,112,mysql-test-run.pl,"â¢
--start-from=
test_name
mariadb-test-run.pl
sorts the list of names of the test cases
           to be run, and then begins with
test_name
. â¢
--strace
Run the ""mariadbd"" executables using strace. Default options
           are
-f -o var/log/'mariadbd-name'.strace
."
809,113,mysql-test-run.pl,"Default options
           are
-f -o var/log/'mariadbd-name'.strace
. â¢
--strace-client
Create
strace
output for
mariadb-test
, optionally specifying
           name and path to the trace program to use. Example: ./mariadb-test-run.pl --strace-client=ktrace

       â¢
--strace-option
=
ARGS
Option to give
strace
, replaces default option(s)."
809,114,mysql-test-run.pl,"Example: ./mariadb-test-run.pl --strace-client=ktrace

       â¢
--strace-option
=
ARGS
Option to give
strace
, replaces default option(s). â¢
--stress=
ARGS
Run stress test, providing options to mariadb-stress-test.pl. Options are separated by comma."
809,115,mysql-test-run.pl,"Options are separated by comma. â¢
--suite[s]=
suite_name... Comma separated list of suite names to run."
809,116,mysql-test-run.pl,"Comma separated list of suite names to run. The default is:
           ""main-,archive-,binlog-,csv-,federated-,funcs_1-,funcs_2-,
           handler-,heap-,innodb-,innodb_fts-,innodb_zip-,maria-,
           multi_source-,optimizer_unfixed_bugs-,parts-,perfschema-,
           plugins-,roles-,rpl-,sys_vars-,unit-,vcol-"". â¢
--stop-file=
file
If this file is detected, mariadb-test will not start new
           tests until the file is removed (also MTR_STOP_FILE
           environment variable)."
809,117,mysql-test-run.pl,"â¢
--stop-file=
file
If this file is detected, mariadb-test will not start new
           tests until the file is removed (also MTR_STOP_FILE
           environment variable). â¢
--stop-keep-alive=
sec
Works with
--stop-file
, print messages every
sec
seconds when
           mariadb-test is waiting to remove the file (for buildbot)
           (also MTR_STOP_KEEP_ALIVE environment variable). â¢
--suite-timeout=
minutes
Specify the maximum test suite runtime in minutes."
809,118,mysql-test-run.pl,"â¢
--suite-timeout=
minutes
Specify the maximum test suite runtime in minutes. The default
           is 360. â¢
--testcase-timeout
Specify the maximum test case runtime in minutes."
809,119,mysql-test-run.pl,"â¢
--testcase-timeout
Specify the maximum test case runtime in minutes. The default
           is 15. â¢
--timediff
Used with
--timestamp
, also print time passed since the
           previous test started."
809,120,mysql-test-run.pl,"â¢
--timediff
Used with
--timestamp
, also print time passed since the
           previous test started. â¢
--timer
Cause
mariadb-test
to generate a timing file. The default file
           is named ./var/log/timer."
809,121,mysql-test-run.pl,"The default file
           is named ./var/log/timer. â¢
--timestamp
Prints a timestamp before the test case name in each test
           report line, showing when the test ended. â¢
--tmpdir=
path
The directory where temporary file are stored."
809,122,mysql-test-run.pl,"â¢
--tmpdir=
path
The directory where temporary file are stored. The default
           location is ./var/tmp. The environment variable MYSQL_TMP_DIR
           will be set to the path for this directory, whether it has the
           default value or has been set explicitly."
809,123,mysql-test-run.pl,"The environment variable MYSQL_TMP_DIR
           will be set to the path for this directory, whether it has the
           default value or has been set explicitly. This may be referred
           to in tests. â¢
--user=
user_name
The MariaDB user name to use when connecting to the server
           (default root)."
809,124,mysql-test-run.pl,"â¢
--user=
user_name
The MariaDB user name to use when connecting to the server
           (default root). â¢
--user-args
In combination with
start*
and no test name, drops arguments
           to mariadbd except those specified with
--mariadbd
(if any). â¢
--valgrind[-all]
Run
mariadb-test
and
mariadbd
with
valgrind
."
809,125,mysql-test-run.pl,"â¢
--valgrind[-all]
Run
mariadb-test
and
mariadbd
with
valgrind
. This and the
           following
--valgrind
options require that the executables have
           been built with
valgrind
support. â¢
--valgrind-mariadbd
Run the
mariadbd
server with
valgrind
."
809,126,mysql-test-run.pl,"â¢
--valgrind-mariadbd
Run the
mariadbd
server with
valgrind
. â¢
--valgrind-mariadb-test
Run the
mariadb-test
and
mariadb-client-test
executables with
valgrind
. â¢
--valgrind-option=
str
Option to give
valgrind
."
809,127,mysql-test-run.pl,"â¢
--valgrind-option=
str
Option to give
valgrind
. Replaces default option(s). Can be
           specified more then once&."
809,128,mysql-test-run.pl,"Can be
           specified more then once&. â¢
--valgrind-path=
path
Path to the
valgrind
executable. â¢
--vardir=
path
Specify the path where files generated during the test run are
           stored."
809,129,mysql-test-run.pl,"â¢
--vardir=
path
Specify the path where files generated during the test run are
           stored. The default location is ./var. The environment
           variable MYSQLTEST_VARDIR will be set to the path for this
           directory, whether it has the default value or has been set
           explicitly."
809,130,mysql-test-run.pl,"The environment
           variable MYSQLTEST_VARDIR will be set to the path for this
           directory, whether it has the default value or has been set
           explicitly. This may be referred to in tests. â¢
--verbose
Give more verbose output regarding test execution."
809,131,mysql-test-run.pl,"â¢
--verbose
Give more verbose output regarding test execution. Use the
           option twice to get even more output. Note that the output
           generated within each test case is not affected."
809,132,mysql-test-run.pl,"Note that the output
           generated within each test case is not affected. â¢
--verbose-restart
Write when and why servers are restarted between test cases. â¢
--view-protocol
Create a view to execute all non updating queries."
809,133,mysql-test-run.pl,"â¢
--view-protocol
Create a view to execute all non updating queries. â¢
--vs-config=
config_val
Visual Studio configuration used to create executables
           (default: MTR_VS_CONFIG environment variable) This option is
           for Windows only. â¢
--wait-all
If
--start
or
--start-dirty
is used, wait for all servers to
           exit before termination."
809,134,mysql-test-run.pl,"â¢
--wait-all
If
--start
or
--start-dirty
is used, wait for all servers to
           exit before termination. Otherwise, it will terminate if one
           (of several) servers is restarted. â¢
--warnings
Search the server log for errors or warning after each test
           and report any suspicious ones; if any are found, the test
           will be marked as failed."
809,135,mysql-test-run.pl,"Otherwise, it will terminate if one
           (of several) servers is restarted. â¢
--warnings
Search the server log for errors or warning after each test
           and report any suspicious ones; if any are found, the test
           will be marked as failed. This is the default behavior, it may
           be turned off with
--nowarnings
."
810,0,mariadb_config,"mariadb-dump
provides you with useful information for compiling
       your MariaDB client and connecting it to MariaDB. mariadb-dump
supports the following options. â¢
--cflags
Compiler flags to find include files and critical compiler
           flags and defines used when compiling the libmysqlclient
           library."
810,1,mariadb_config,"â¢
--cflags
Compiler flags to find include files and critical compiler
           flags and defines used when compiling the libmysqlclient
           library. The options returned are tied to the specific
           compiler that was used when the library was created and might
           clash with the settings for your own compiler. Use
--include
for more portable options that contain only include paths."
810,2,mariadb_config,"Use
--include
for more portable options that contain only include paths. â¢
--include
Compiler options to find MariaDB include files. â¢
--libmysqld-libs
,
--embedded
Libraries and options required to link with the MariaDB
           embedded server."
810,3,mariadb_config,"â¢
--libmysqld-libs
,
--embedded
Libraries and options required to link with the MariaDB
           embedded server. â¢
--libs
Libraries and options required to link with the MariaDB client
           library. â¢
--libs_r
Libraries and options required to link with the thread-safe
           MariaDB client library."
810,4,mariadb_config,"â¢
--libs_r
Libraries and options required to link with the thread-safe
           MariaDB client library. â¢
--plugindir
The default plugin directory path name, defined when
           configuring MariaDB. â¢
--port
The default TCP/IP port number, defined when configuring
           MariaDB."
810,5,mariadb_config,"â¢
--port
The default TCP/IP port number, defined when configuring
           MariaDB. â¢
--socket
The default Unix socket file, defined when configuring
           MariaDB. â¢
--variable=VAR
Path to MariaDB include, library and plugin directories."
810,6,mariadb_config,"â¢
--variable=VAR
Path to MariaDB include, library and plugin directories. VAR
is one of `pkgincludedir`, `pkglibdir` and `plugindir`,
           respectively. â¢
--version
Version number for the MariaDB distribution."
810,7,mariadb_config,"â¢
--version
Version number for the MariaDB distribution. If you invoke
mariadb-dump
with no options, it displays a list of
       all options that it supports, and their values:

           shell>
mariadb-dump
Usage: /usr/local/mysql/bin/mariadb-dump [options]
           Options:
             --cflags         [-I/usr/local/mysql/include/mysql -mcpu=pentiumpro]
             --include        [-I/usr/local/mysql/include/mysql]
             --libs           [-L/usr/local/mysql/lib/mysql -lmysqlclient -lz
                               -lcrypt -lnsl -lm -L/usr/lib -lssl -lcrypto]
             --libs_r         [-L/usr/local/mysql/lib/mysql -lmysqlclient_r
                               -lpthread -lz -lcrypt -lnsl -lm -lpthread]
             --socket         [/tmp/mysql.sock]
             --port           [3306]
             --version        [4.0.16]
             --libmysqld-libs [-L/usr/local/mysql/lib/mysql -lmysqld -lpthread -lz
                               -lcrypt -lnsl -lm -lpthread -lrt]

       You can use
mariadb-dump
within a command line to include the
       value that it displays for a particular option. For example, to
       compile a MariaDB client program, use
mariadb-dump
as follows:

           shell>
CFG=/usr/local/mysql/bin/mariadb-dump
shell>
sh -c ""gcc -o progname `$CFG --include` progname.c `$CFG --libs`""
When you use
mariadb-dump
this way, be sure to invoke it within
       backtick (â`â) characters."
810,8,mariadb_config,"If you invoke
mariadb-dump
with no options, it displays a list of
       all options that it supports, and their values:

           shell>
mariadb-dump
Usage: /usr/local/mysql/bin/mariadb-dump [options]
           Options:
             --cflags         [-I/usr/local/mysql/include/mysql -mcpu=pentiumpro]
             --include        [-I/usr/local/mysql/include/mysql]
             --libs           [-L/usr/local/mysql/lib/mysql -lmysqlclient -lz
                               -lcrypt -lnsl -lm -L/usr/lib -lssl -lcrypto]
             --libs_r         [-L/usr/local/mysql/lib/mysql -lmysqlclient_r
                               -lpthread -lz -lcrypt -lnsl -lm -lpthread]
             --socket         [/tmp/mysql.sock]
             --port           [3306]
             --version        [4.0.16]
             --libmysqld-libs [-L/usr/local/mysql/lib/mysql -lmysqld -lpthread -lz
                               -lcrypt -lnsl -lm -lpthread -lrt]

       You can use
mariadb-dump
within a command line to include the
       value that it displays for a particular option. For example, to
       compile a MariaDB client program, use
mariadb-dump
as follows:

           shell>
CFG=/usr/local/mysql/bin/mariadb-dump
shell>
sh -c ""gcc -o progname `$CFG --include` progname.c `$CFG --libs`""
When you use
mariadb-dump
this way, be sure to invoke it within
       backtick (â`â) characters. That tells the shell to execute it and
       substitute its output into the surrounding command."
811,0,mariadbd-multi,"mariadbd-multi
is designed to manage several
mariadbd
processes
       that listen for connections on different Unix socket files and
       TCP/IP ports. It can start or stop servers, or report their
       current status. mariadbd-multi
searches for groups named [mariadbd
N
] in my.cnf (or
       in the file named by the
--config-file
option)."
811,1,mariadbd-multi,"mariadbd-multi
searches for groups named [mariadbd
N
] in my.cnf (or
       in the file named by the
--config-file
option). N
can be any
       positive integer. This number is referred to in the following
       discussion as the option group number, or
GNR
."
811,2,mariadbd-multi,"This number is referred to in the following
       discussion as the option group number, or
GNR
. Group numbers
       distinguish option groups from one another and are used as
       arguments to
mariadbd-multi
to specify which servers you want to
       start, stop, or obtain a status report for. Options listed in
       these groups are the same that you would use in the [mariadbd]
       group used for starting
mariadbd
."
811,3,mariadbd-multi,"Options listed in
       these groups are the same that you would use in the [mariadbd]
       group used for starting
mariadbd
. However, when using multiple
       servers, it is necessary that each one use its own value for
       options such as the Unix socket file and TCP/IP port number. To invoke
mariadbd-multi
, use the following syntax:

           shell>
mariadbd-multi [
options
] {start|stop|report} [
GNR
[,
GNR
] ...]
start, stop, and report indicate which operation to perform."
811,4,mariadbd-multi,"To invoke
mariadbd-multi
, use the following syntax:

           shell>
mariadbd-multi [
options
] {start|stop|report} [
GNR
[,
GNR
] ...]
start, stop, and report indicate which operation to perform. You
       can perform the designated operation for a single server or
       multiple servers, depending on the
GNR
list that follows the
       option name. If there is no list,
mariadbd-multi
performs the
       operation for all servers in the option file."
811,5,mariadbd-multi,"If there is no list,
mariadbd-multi
performs the
       operation for all servers in the option file. Each
GNR
value represents an option group number or range of group
       numbers. The value should be the number at the end of the group
       name in the option file."
811,6,mariadbd-multi,"The value should be the number at the end of the group
       name in the option file. For example, the
GNR
for a group named
       [mariadbd17] is 17. To specify a range of numbers, separate the
       first and last numbers by a dash."
811,7,mariadbd-multi,"To specify a range of numbers, separate the
       first and last numbers by a dash. The
GNR
value 10-13 represents
       groups [mariadbd10] through [mariadbd13]. Multiple groups or group
       ranges can be specified on the command line, separated by commas."
811,8,mariadbd-multi,"Multiple groups or group
       ranges can be specified on the command line, separated by commas. There must be no whitespace characters (spaces or tabs) in the
GNR
list; anything after a whitespace character is ignored. This command starts a single server using option group
       [mariadbd17]:

           shell>
mariadbd-multi start 17
This command stops several servers, using option groups
       [mariadbd8] and [mariadbd10] through [mariadbd13]:

           shell>
mariadbd-multi stop 8,10-13
For an example of how you might set up an option file, use this
       command:

           shell>
mariadbd-multi --example
mariadbd-multi
searches for option files as follows:

       â¢   With
--no-defaults
, no option files are read."
811,9,mariadbd-multi,"This command starts a single server using option group
       [mariadbd17]:

           shell>
mariadbd-multi start 17
This command stops several servers, using option groups
       [mariadbd8] and [mariadbd10] through [mariadbd13]:

           shell>
mariadbd-multi stop 8,10-13
For an example of how you might set up an option file, use this
       command:

           shell>
mariadbd-multi --example
mariadbd-multi
searches for option files as follows:

       â¢   With
--no-defaults
, no option files are read. â¢   With
--defaults-file=
file_name
, only the named file is read. â¢   Otherwise, option files in the standard list of locations are
           read, including any file named by the
--defaults-extra-file=
file_name
option, if one is given."
811,10,mariadbd-multi,"â¢   Otherwise, option files in the standard list of locations are
           read, including any file named by the
--defaults-extra-file=
file_name
option, if one is given. (If
           the option is given multiple times, the last value is used.)

       Option files read are searched for [mariadbd-multi] and
       [mariadbd
N
] option groups. The [mariadbd-multi] group can be used
       for options to
mariadbd-multi
itself."
811,11,mariadbd-multi,"The [mariadbd-multi] group can be used
       for options to
mariadbd-multi
itself. [mariadbd
N
] groups can be
       used for options passed to specific
mariadbd
instances. The [mariadbd] or [mariadbd_safe] groups can be used for common
       options read by all instances of
mariadbd
or
mariadbd_safe
."
811,12,mariadbd-multi,"The [mariadbd] or [mariadbd_safe] groups can be used for common
       options read by all instances of
mariadbd
or
mariadbd_safe
. You
       can specify a
--defaults-file=
file_name
option to use a different
       configuration file for that instance, in which case the [mariadbd]
       or [mariadbd_safe] groups from that file will be used for that
       instance. mariadbd-multi
supports the following options."
811,13,mariadbd-multi,"mariadbd-multi
supports the following options. â¢
--help
Display a help message and exit. â¢
--example
Display a sample option file."
811,14,mariadbd-multi,"â¢
--example
Display a sample option file. â¢
--log=
file_name
Specify the name of the log file. If the file exists, log
           output is appended to it."
811,15,mariadbd-multi,"If the file exists, log
           output is appended to it. â¢
--mariadb-admin=
prog_name
The
mariadb-admin
binary to be used to stop servers. â¢
--mariadbd=
prog_name
The
mariadbd
binary to be used."
811,16,mariadbd-multi,"â¢
--mariadbd=
prog_name
The
mariadbd
binary to be used. Note that you can specify
mariadbd_safe
as the value for this option also. If you use
mariadbd_safe
to start the server, you can include the
           mariadbd or ledir options in the corresponding [mariadbd
N
]
           option group."
811,17,mariadbd-multi,"If you use
mariadbd_safe
to start the server, you can include the
           mariadbd or ledir options in the corresponding [mariadbd
N
]
           option group. These options indicate the name of the server
           that
mariadbd_safe
should start and the path name of the
           directory where the server is located. (See the descriptions
           for these options in
mariadbd_safe
(1).) Example:

               [mariadbd38]
               mariadbd = mariadbd-debug
               ledir  = /opt/local/mysql/libexec

       â¢
--no-log
Print log information to stdout rather than to the log file."
811,18,mariadbd-multi,"(See the descriptions
           for these options in
mariadbd_safe
(1).) Example:

               [mariadbd38]
               mariadbd = mariadbd-debug
               ledir  = /opt/local/mysql/libexec

       â¢
--no-log
Print log information to stdout rather than to the log file. By default, output goes to the log file. â¢
--password=
password
The password of the MariaDB account to use when invoking
mariadb-admin
."
811,19,mariadbd-multi,"â¢
--password=
password
The password of the MariaDB account to use when invoking
mariadb-admin
. Note that the password value is not optional
           for this option, unlike for other MariaDB programs. â¢
--silent
Silent mode; disable warnings."
811,20,mariadbd-multi,"â¢
--silent
Silent mode; disable warnings. â¢
--tcp-ip
Connect to the MariaDB server(s) via the TCP/IP port instead
           of the UNIX socket. This affects stopping and reporting."
811,21,mariadbd-multi,"This affects stopping and reporting. If a
           socket file is missing, the server may still be running, but
           can be accessed only via the TCP/IP port. By default
           connecting is done via the UNIX socket."
811,22,mariadbd-multi,"By default
           connecting is done via the UNIX socket. This option affects
           stop and report operations. â¢
--user=
user_name
The user name of the MariaDB account to use when invoking
mariadb-admin
."
811,23,mariadbd-multi,"â¢
--user=
user_name
The user name of the MariaDB account to use when invoking
mariadb-admin
. â¢
--verbose
Be more verbose. â¢
--version
Display version information and exit."
811,24,mariadbd-multi,"â¢
--version
Display version information and exit. â¢
--wsrep-new-cluster
Bootstrap a cluster. Some notes about
mariadbd-multi
:

       â¢
Most important
: Before using
mariadbd-multi
be sure that you
           understand the meanings of the options that are passed to the
mariadbd
servers and
why
you would want to have separate
mariadbd
processes."
811,25,mariadbd-multi,"Some notes about
mariadbd-multi
:

       â¢
Most important
: Before using
mariadbd-multi
be sure that you
           understand the meanings of the options that are passed to the
mariadbd
servers and
why
you would want to have separate
mariadbd
processes. Beware of the dangers of using multiple
mariadbd
servers with the same data directory. Use separate
           data directories, unless you
know
what you are doing."
811,26,mariadbd-multi,"Use separate
           data directories, unless you
know
what you are doing. Starting
           multiple servers with the same data directory does
not
give
           you extra performance in a threaded system. â¢
Important
: Make sure that the data directory for each server
           is fully accessible to the Unix account that the specific
mariadbd
process is started as."
811,27,mariadbd-multi,"â¢
Important
: Make sure that the data directory for each server
           is fully accessible to the Unix account that the specific
mariadbd
process is started as. Do not
use the Unix
root
account for this, unless you
know
what you are doing. â¢   Make sure that the MariaDB account used for stopping the
mariadbd
servers (with the
mariadbadmin
program) has the same
           user name and password for each server."
811,28,mariadbd-multi,"â¢   Make sure that the MariaDB account used for stopping the
mariadbd
servers (with the
mariadbadmin
program) has the same
           user name and password for each server. Also, make sure that
           the account has the SHUTDOWN privilege. If the servers that
           you want to manage have different user names or passwords for
           the administrative accounts, you might want to create an
           account on each server that has the same user name and
           password."
811,29,mariadbd-multi,"If the servers that
           you want to manage have different user names or passwords for
           the administrative accounts, you might want to create an
           account on each server that has the same user name and
           password. For example, you might set up a common multi_admin
           account by executing the following commands for each server:

               shell>
mariadb -u root -S /tmp/mariadb.sock -p
Enter password:
               mariadb>
GRANT SHUTDOWN ON *.*
->
TO 'multi_admin'@'localhost' IDENTIFIED BY 'multipass';
Change the connection parameters appropriately when connecting
           to each one. Note that the host name part of the account name
           must allow you to connect as multi_admin from the host where
           you want to run
mariadbd-multi
."
811,30,mariadbd-multi,"Note that the host name part of the account name
           must allow you to connect as multi_admin from the host where
           you want to run
mariadbd-multi
. â¢   The Unix socket file and the TCP/IP port number must be
           different for every
mariadbd
. (Alternatively, if the host has
           multiple network addresses, you can use
--bind-address
to
           cause different servers to listen to different interfaces.)

       â¢   The
--pid-file
option is very important if you are using
mariadbd-safe
to start
mariadbd
(for example,
--mariadbd=mariadbd-safe
) Every
mariadbd
should have its own
           process ID file."
811,31,mariadbd-multi,"(Alternatively, if the host has
           multiple network addresses, you can use
--bind-address
to
           cause different servers to listen to different interfaces.)

       â¢   The
--pid-file
option is very important if you are using
mariadbd-safe
to start
mariadbd
(for example,
--mariadbd=mariadbd-safe
) Every
mariadbd
should have its own
           process ID file. The advantage of using
mariadbd-safe
instead
           of
mariadbd
is that
mariadbd-safe
monitors its
mariadbd
process and restarts it if the process terminates due to a
           signal sent using kill -9 or for other reasons, such as a
           segmentation fault. Please note that the
mariadbd-safe
script
           might require that you start it from a certain place."
811,32,mariadbd-multi,"Please note that the
mariadbd-safe
script
           might require that you start it from a certain place. This
           means that you might have to change location to a certain
           directory before running
mariadbd-multi
. If you have problems
           starting, please see the
mariadbd-safe
script."
811,33,mariadbd-multi,"If you have problems
           starting, please see the
mariadbd-safe
script. Check
           especially the lines:

               ----------------------------------------------------------------
               MY_PWD=`pwd`
               # Check if we are starting this relative (for the binary release)
               if test -d $MY_PWD/data/mariadb -a \
                  -f ./share/mariadb/english/errmsg.sys -a \
                  -x ./bin/mariadbd
               ----------------------------------------------------------------

           The test performed by these lines should be successful, or you
           might encounter problems. See
mariadbd-safe(1)
."
811,34,mariadbd-multi,"See
mariadbd-safe(1)
. â¢   You might want to use the
--user
option for
mariadbd
, but to
           do this you need to run the
mariadbd-multi
script as the Unix
           root user. Having the option in the option file doesn't
           matter; you just get a warning if you are not the superuser
           and the
mariadbd
processes are started under your own Unix
           account."
811,35,mariadbd-multi,"Having the option in the option file doesn't
           matter; you just get a warning if you are not the superuser
           and the
mariadbd
processes are started under your own Unix
           account. The following example shows how you might set up an option file
       for use with
mariadbd-multi
. The order in which the
mariadbd
programs are started or stopped depends on the order in which they
       appear in the option file."
811,36,mariadbd-multi,"The order in which the
mariadbd
programs are started or stopped depends on the order in which they
       appear in the option file. Group numbers need not form an unbroken
       sequence. The first and fifth [mariadbd
N
] groups were
       intentionally omitted from the example to illustrate that you can
       have âgapsâ in the option file."
811,37,mariadbd-multi,"The first and fifth [mariadbd
N
] groups were
       intentionally omitted from the example to illustrate that you can
       have âgapsâ in the option file. This gives you more flexibility. # This file should probably be in your home dir (~/.my.cnf)
           # or /etc/my.cnf
           # Version 2.1 by Jani Tolonen
           [mariadbd-multi]
           mariadbd     = /usr/local/bin/mariadbd-safe
           mariadb-admin = /usr/local/bin/mariadb-admin
           user       = multi_admin
           password   = multipass
           [mariadbd2]
           socket     = /tmp/mariadb.sock2
           port       = 3307
           pid-file   = /usr/local/mysql/var2/hostname.pid2
           datadir    = /usr/local/mysql/var2
           language   = /usr/local/share/mariadb/english
           user       = john
           [mariadbd3]
           socket     = /tmp/mysql.sock3
           port       = 3308
           pid-file   = /usr/local/mysql/var3/hostname.pid3
           datadir    = /usr/local/mysql/var3
           language   = /usr/local/share/mariadb/swedish
           user       = monty
           [mariadbd4]
           socket     = /tmp/mysql.sock4
           port       = 3309
           pid-file   = /usr/local/mysql/var4/hostname.pid4
           datadir    = /usr/local/mysql/var4
           language   = /usr/local/share/mariadb/estonia
           user       = tonu
           [mariadbd6]
           socket     = /tmp/mysql.sock6
           port       = 3311
           pid-file   = /usr/local/mysql/var6/hostname.pid6
           datadir    = /usr/local/mysql/var6
           language   = /usr/local/share/mariadb/japanese
           user       = jani"
812,0,mariadbd-safe-helper,"Use: Helper script.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
813,0,mariadb,"mariadb
is a simple SQL shell (with GNU readline capabilities). It
       supports interactive and non-interactive use. When used
       interactively, query results are presented in an ASCII-table
       format."
813,1,mariadb,"When used
       interactively, query results are presented in an ASCII-table
       format. When used non-interactively (for example, as a filter),
       the result is presented in tab-separated format. The output format
       can be changed using command options."
813,2,mariadb,"The output format
       can be changed using command options. If you have problems due to insufficient memory for large result
       sets, use the
--quick
option. This forces
mariadb
to retrieve
       results from the server a row at a time rather than retrieving the
       entire result set and buffering it in memory before displaying it."
813,3,mariadb,"This forces
mariadb
to retrieve
       results from the server a row at a time rather than retrieving the
       entire result set and buffering it in memory before displaying it. This is done by returning the result set using the
       mariadb_use_result() C API function in the client/server library
       rather than mysql_store_result(). Using
mariadb
is very easy."
813,4,mariadb,"Using
mariadb
is very easy. Invoke it from the prompt of your
       command interpreter as follows:

           shell>
mariadb
db_name
Or:

           shell>
mariadb --user=
user_name
--password=
your_password db_name
Then type an SQL statement, end it with â;â, \g, or \G and press
       Enter. Typing Control-C causes
mariadb
to attempt to kill the current
       statement."
813,5,mariadb,"Typing Control-C causes
mariadb
to attempt to kill the current
       statement. If this cannot be done, or Control-C is typed again
       before the statement is killed,
mariadb
exits. You can execute SQL statements in a script file (batch file) like
       this:

           shell>
mariadb
db_name
<
script.sql
>
output.tab"
814,0,mariadbd-safe,"mariadbd-safe
is the recommended way to start a
mariadbd
server on
       Unix. mariadbd-safe
adds some safety features such as restarting
       the server when an error occurs and logging runtime information to
       an error log file. Descriptions of error logging is given later in
       this section."
814,1,mariadbd-safe,"Descriptions of error logging is given later in
       this section. mariadbd-safe
tries to start an executable named
mariadbd
. To
       override the default behavior and specify explicitly the name of
       the server you want to run, specify a
--mariadbd
or
--mariadbd-version
option to
mariadbd-safe
."
814,2,mariadbd-safe,"To
       override the default behavior and specify explicitly the name of
       the server you want to run, specify a
--mariadbd
or
--mariadbd-version
option to
mariadbd-safe
. You can also use
--ledir
to indicate the directory where
mariadbd-safe
should look
       for the server. Many of the options to
mariadbd-safe
are the same as the options
       to
mariadbd
."
814,3,mariadbd-safe,"Many of the options to
mariadbd-safe
are the same as the options
       to
mariadbd
. Options unknown to
mariadbd-safe
are passed to
mariadbd
if they
       are specified on the command line, but ignored if they are
       specified in the [mariadbd-safe] or [mariadbd_safe] groups of an
       option file. mariadbd-safe
reads all options from the [mariadbd], [server],
       [mariadbd-safe] and [mariadbd_safe] sections in option files."
814,4,mariadbd-safe,"mariadbd-safe
reads all options from the [mariadbd], [server],
       [mariadbd-safe] and [mariadbd_safe] sections in option files. For
       example, if you specify a [mariadbd] section like this,
mariadbd-
safe
will find and use the
--log-error
option:

           [mariadbd]
           log-error=error.log

       For backward compatibility,
mariadbd-safe
also reads
       [safe_mariadbd] sections, although you should rename such sections
       to [mariadbd-safe] in current installations. mariadbd-safe
supports the options in the following list."
814,5,mariadbd-safe,"mariadbd-safe
supports the options in the following list. It also
       reads option files and supports the options for processing them. â¢
--help
Display a help message and exit."
814,6,mariadbd-safe,"â¢
--help
Display a help message and exit. â¢
--basedir=
path
The path to the MariaDB installation directory. â¢
--core-file-size=
size
The size of the core file that
mariadbd
should be able to
           create."
814,7,mariadbd-safe,"â¢
--core-file-size=
size
The size of the core file that
mariadbd
should be able to
           create. The option value is passed to
ulimit -c
. â¢
--crash-script=
file
Script to call in the event of mariadbd crashing."
814,8,mariadbd-safe,"â¢
--crash-script=
file
Script to call in the event of mariadbd crashing. â¢
--datadir=
path
The path to the data directory. â¢
--defaults-extra-file=
path
The name of an option file to be read in addition to the usual
           option files."
814,9,mariadbd-safe,"â¢
--defaults-extra-file=
path
The name of an option file to be read in addition to the usual
           option files. This must be the first option on the command
           line if it is used. If the file does not exist or is otherwise
           inaccessible, the server will exit with an error."
814,10,mariadbd-safe,"If the file does not exist or is otherwise
           inaccessible, the server will exit with an error. â¢
--defaults-file=
file_name
The name of an option file to be read instead of the usual
           option files. This must be the first option on the command
           line if it is used."
814,11,mariadbd-safe,"This must be the first option on the command
           line if it is used. â¢
--flush-caches
Flush and purge buffers/caches before starting the server. â¢
--ledir=
path
If
mariadbd-safe
cannot find the server, use this option to
           indicate the path name to the directory where the server is
           located."
814,12,mariadbd-safe,"â¢
--ledir=
path
If
mariadbd-safe
cannot find the server, use this option to
           indicate the path name to the directory where the server is
           located. â¢
--log-error=
file_name
Write the error log to the given file. â¢
--malloc-lib=
lib
Preload shared library lib if available."
814,13,mariadbd-safe,"â¢
--malloc-lib=
lib
Preload shared library lib if available. â¢
--mariadbd=
prog_name
The name of the server program (in the ledir directory) that
           you want to start. This option is needed if you use the
           MariaDB binary distribution but have the data directory
           outside of the binary distribution."
814,14,mariadbd-safe,"This option is needed if you use the
           MariaDB binary distribution but have the data directory
           outside of the binary distribution. If
mariadbd-safe
cannot
           find the server, use the
--ledir
option to indicate the path
           name to the directory where the server is located. â¢
--mariadbd-version=
suffix
This option is similar to the
--mariadbd
option, but you
           specify only the suffix for the server program name."
814,15,mariadbd-safe,"â¢
--mariadbd-version=
suffix
This option is similar to the
--mariadbd
option, but you
           specify only the suffix for the server program name. The
           basename is assumed to be
mariadbd
. For example, if you use
--mariadbd-version=debug
,
mariadbd-safe
starts the
mariadbd-debug
program in the ledir directory."
814,16,mariadbd-safe,"For example, if you use
--mariadbd-version=debug
,
mariadbd-safe
starts the
mariadbd-debug
program in the ledir directory. If the argument
           to
--mariadbd-version
is empty,
mariadbd-safe
uses
mariadbd
in
           the ledir directory. â¢
--nice=
priority
Use the nice program to set the server's scheduling priority
           to the given value."
814,17,mariadbd-safe,"â¢
--nice=
priority
Use the nice program to set the server's scheduling priority
           to the given value. â¢
--no-auto-restart
,
--nowatch
,
--no-watch
Exit after starting mariadbd. â¢
--no-defaults
Do not read any option files."
814,18,mariadbd-safe,"â¢
--no-defaults
Do not read any option files. This must be the first option on
           the command line if it is used. â¢
--numa-interleave
Run mariadbd with its memory interleaved on all NUMA nodes."
814,19,mariadbd-safe,"â¢
--numa-interleave
Run mariadbd with its memory interleaved on all NUMA nodes. â¢
--open-files-limit=
count
The number of files that
mariadbd
should be able to open. The
           option value is passed to
ulimit -n
."
814,20,mariadbd-safe,"The
           option value is passed to
ulimit -n
. Note that you need to
           start
mariadbd-safe
as root for this to work properly! â¢
--pid-file=
file_name
The path name of the process ID file."
814,21,mariadbd-safe,"â¢
--pid-file=
file_name
The path name of the process ID file. â¢
--plugin-dir=
dir_name
Directory for client-side plugins. â¢
--port=
port_num
The port number that the server should use when listening for
           TCP/IP connections."
814,22,mariadbd-safe,"â¢
--port=
port_num
The port number that the server should use when listening for
           TCP/IP connections. The port number must be 1024 or higher
           unless the server is started by the root system user. â¢
--skip-kill-mariadbd
Do not try to kill stray
mariadbd
processes at startup."
814,23,mariadbd-safe,"â¢
--skip-kill-mariadbd
Do not try to kill stray
mariadbd
processes at startup. This
           option works only on Linux. â¢
--socket=
path
The Unix socket file that the server should use when listening
           for local connections."
814,24,mariadbd-safe,"â¢
--socket=
path
The Unix socket file that the server should use when listening
           for local connections. â¢
--syslog
,
--skip-syslog
--syslog
causes error messages to be sent to syslog on systems
           that support the
logger
program. --skip-syslog suppresses the
           use of syslog; messages are written to an error log file."
814,25,mariadbd-safe,"--skip-syslog suppresses the
           use of syslog; messages are written to an error log file. â¢
--syslog-tag=
tag
For logging to syslog, messages from
mariadbd-safe
and
mariadbd
are written with a tag of mariadbd-safe and mariadbd,
           respectively. To specify a suffix for the tag, use
--syslog-tag=
tag
, which modifies the tags to be mariadbd-
           safe-
tag
and mariadbd-
tag
."
814,26,mariadbd-safe,"To specify a suffix for the tag, use
--syslog-tag=
tag
, which modifies the tags to be mariadbd-
           safe-
tag
and mariadbd-
tag
. â¢
--timezone=
timezone
Set the TZ time zone environment variable to the given option
           value. Consult your operating system documentation for legal
           time zone specification formats."
814,27,mariadbd-safe,"Consult your operating system documentation for legal
           time zone specification formats. â¢
--user={
user_name
|
user_id
}
Run the
mariadbd
server as the user having the name
user_name
or the numeric user ID
user_id
. (âUserâ in this context refers
           to a system login account, not a MariaDB user listed in the
           grant tables.)

       If you execute
mariadbd-safe
with the
--defaults-file
or
--defaults-extra-file
option to name an option file, the option
       must be the first one given on the command line or the option file
       will not be used."
814,28,mariadbd-safe,"(âUserâ in this context refers
           to a system login account, not a MariaDB user listed in the
           grant tables.)

       If you execute
mariadbd-safe
with the
--defaults-file
or
--defaults-extra-file
option to name an option file, the option
       must be the first one given on the command line or the option file
       will not be used. For example, this command will not use the named
       option file:

           mariadb>
mariadbd-safe --port=
port_num
--defaults-file=
file_name
Instead, use the following command:

           mariadb>
mariadbd-safe --defaults-file=
file_name
--port=
port_num
The
mariadbd-safe
script is written so that it normally can start
       a server that was installed from either a source or a binary
       distribution of MariaDB, even though these types of distributions
       typically install the server in slightly different locations. mariadbd-safe
expects one of the following conditions to be true:

       â¢   The server and databases can be found relative to the working
           directory (the directory from which
mariadbd-safe
is invoked)."
814,29,mariadbd-safe,"mariadbd-safe
expects one of the following conditions to be true:

       â¢   The server and databases can be found relative to the working
           directory (the directory from which
mariadbd-safe
is invoked). For binary distributions,
mariadbd-safe
looks under its
           working directory for bin and data directories. For source
           distributions, it looks for libexec and var directories."
814,30,mariadbd-safe,"For source
           distributions, it looks for libexec and var directories. This
           condition should be met if you execute
mariadbd-safe
from your
           MariaDB installation directory (for example, /usr/local/mysql
           for a binary distribution). â¢   If the server and databases cannot be found relative to the
           working directory,
mariadbd-safe
attempts to locate them by
           absolute path names."
814,31,mariadbd-safe,"â¢   If the server and databases cannot be found relative to the
           working directory,
mariadbd-safe
attempts to locate them by
           absolute path names. Typical locations are /usr/local/libexec
           and /usr/local/var. The actual locations are determined from
           the values configured into the distribution at the time it was
           built."
814,32,mariadbd-safe,"The actual locations are determined from
           the values configured into the distribution at the time it was
           built. They should be correct if MariaDB is installed in the
           location specified at configuration time. Because
mariadbd-safe
tries to find the server and databases
       relative to its own working directory, you can install a binary
       distribution of MariaDB anywhere, as long as you run
mariadbd-safe
from the MariaDB installation directory:

           shell>
cd
mysql_installation_directory
shell>
bin/mariadbd-safe &
If
mariadbd-safe
fails, even when invoked from the MariaDB
       installation directory, you can specify the
--ledir
and
--datadir
options to indicate the directories in which the server and
       databases are located on your system."
814,33,mariadbd-safe,"Because
mariadbd-safe
tries to find the server and databases
       relative to its own working directory, you can install a binary
       distribution of MariaDB anywhere, as long as you run
mariadbd-safe
from the MariaDB installation directory:

           shell>
cd
mysql_installation_directory
shell>
bin/mariadbd-safe &
If
mariadbd-safe
fails, even when invoked from the MariaDB
       installation directory, you can specify the
--ledir
and
--datadir
options to indicate the directories in which the server and
       databases are located on your system. When you use
mariadbd-safe
to start
mariadbd
,
mariadbd-safe
arranges for error (and notice) messages from itself and from
mariadbd
to go to the same destination. There are several
mariadbd-safe
options for controlling the
       destination of these messages:

       â¢
--syslog
: Write error messages to syslog on systems that
           support the
logger
program."
814,34,mariadbd-safe,"There are several
mariadbd-safe
options for controlling the
       destination of these messages:

       â¢
--syslog
: Write error messages to syslog on systems that
           support the
logger
program. â¢
--skip-syslog
: Do not write error messages to syslog. Messages
           are written to the default error log file (
host_name
.err in
           the data directory), or to a named file if the
--log-error
option is given."
814,35,mariadbd-safe,"Messages
           are written to the default error log file (
host_name
.err in
           the data directory), or to a named file if the
--log-error
option is given. â¢
--log-error=
file_name
: Write error messages to the named error
           file. If none of these options is given, the default is
--skip-syslog
."
814,36,mariadbd-safe,"If none of these options is given, the default is
--skip-syslog
. Note
If
--syslog
and
--log-error
are both given, a warning is issued
       and
--log-error
takes precedence. When
mariadbd-safe
writes a message, notices go to the logging
       destination (syslog or the error log file) and stdout."
814,37,mariadbd-safe,"When
mariadbd-safe
writes a message, notices go to the logging
       destination (syslog or the error log file) and stdout. Errors go
       to the logging destination and stderr. Normally, you should not edit the
mariadbd-safe
script."
814,38,mariadbd-safe,"Normally, you should not edit the
mariadbd-safe
script. Instead,
       configure
mariadbd-safe
by using command-line options or options
       in the [mariadbd-safe] section of a my.cnf option file. In rare
       cases, it might be necessary to edit
mariadbd-safe
to get it to
       start the server properly."
814,39,mariadbd-safe,"In rare
       cases, it might be necessary to edit
mariadbd-safe
to get it to
       start the server properly. However, if you do this, your modified
       version of
mariadbd-safe
might be overwritten if you upgrade
       MariaDB in the future, so you should make a copy of your edited
       version that you can reinstall. On NetWare,
mariadbd-safe
is a NetWare Loadable Module (NLM) that
       is ported from the original Unix shell script."
814,40,mariadbd-safe,"On NetWare,
mariadbd-safe
is a NetWare Loadable Module (NLM) that
       is ported from the original Unix shell script. It starts the
       server as follows:

        1. Runs a number of system and option checks."
814,41,mariadbd-safe,Runs a number of system and option checks. 2. Runs a check on MyISAM tables.
814,42,mariadbd-safe,Runs a check on MyISAM tables. 3. Provides a screen presence for the MariaDB server.
814,43,mariadbd-safe,"Provides a screen presence for the MariaDB server. 4. Starts
mariadbd
, monitors it, and restarts it if it terminates
           in error."
814,44,mariadbd-safe,"Starts
mariadbd
, monitors it, and restarts it if it terminates
           in error. 5. Sends error messages from
mariadbd
to the
host_name
.err file
           in the data directory."
814,45,mariadbd-safe,"Sends error messages from
mariadbd
to the
host_name
.err file
           in the data directory. 6. Sends
mariadbd-safe
screen output to the
host_name
.safe file
           in the data directory."
815,0,mcookie,"mcookie
generates a 128-bit random hexadecimal number for use with
       the X authority system. Typical usage:
xauth add :0 . mcookie

       The ""random"" number generated is actually the MD5 message digest
       of random information coming from one of the sources
getrandom(2)
system call,
/dev/urandom
,
/dev/random
, or the
libc pseudo-random
functions
, in this preference order."
815,1,mcookie,"Typical usage:
xauth add :0 . mcookie

       The ""random"" number generated is actually the MD5 message digest
       of random information coming from one of the sources
getrandom(2)
system call,
/dev/urandom
,
/dev/random
, or the
libc pseudo-random
functions
, in this preference order. See also the option
--file
."
816,0,mbstream,"Use
mbstream --help
for details on usage.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
817,0,mckey,"Establishes a set of RDMA multicast communication paths between
       nodes using the librdmacm, optionally transfers datagrams to
       receiving nodes, then tears down the communication."
818,0,md5sum,"Print or check MD5 (128-bit) checksums. With no FILE, or when FILE is -, read standard input. -b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in RFC 1321."
818,1,md5sum,"-b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in RFC 1321. When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE."
818,2,md5sum,"When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE. There is no difference between binary mode and text mode on GNU
       systems."
819,0,memusage,"memusage
is a
bash(1)
script which profiles memory usage of the
       program,
program
. It preloads the
libmemusage.so
library into the
       caller's environment (via the
LD_PRELOAD
environment variable; see
ld.so(8)
). The
libmemusage.so
library traces memory allocation by
       intercepting calls to
malloc(3)
,
calloc(3)
,
free(3)
, and
realloc(3)
; optionally, calls to
mmap(2)
,
mremap(2)
, and
munmap(2)
can also be intercepted."
819,1,memusage,"The
libmemusage.so
library traces memory allocation by
       intercepting calls to
malloc(3)
,
calloc(3)
,
free(3)
, and
realloc(3)
; optionally, calls to
mmap(2)
,
mremap(2)
, and
munmap(2)
can also be intercepted. memusage
can output the collected data in textual form, or it can
       use
memusagestat(1)
(see the
-p
option,  below) to create a PNG
       file containing graphical representation of the collected data. Memory usage summary
The ""Memory usage summary"" line output by
memusage
contains three
       fields:
heap total
Sum of
size
arguments of all
malloc(3)
calls, products
                  of arguments (
n
*
size
) of all
calloc(3)
calls, and sum
                  of
length
arguments of all
mmap(2)
calls."
819,2,memusage,"Memory usage summary
The ""Memory usage summary"" line output by
memusage
contains three
       fields:
heap total
Sum of
size
arguments of all
malloc(3)
calls, products
                  of arguments (
n
*
size
) of all
calloc(3)
calls, and sum
                  of
length
arguments of all
mmap(2)
calls. In the case
                  of
realloc(3)
and
mremap(2)
, if the new size of an
                  allocation is larger than the previous size, the sum of
                  all such differences (new size minus old size) is
                  added. heap peak
Maximum of all
size
arguments of
malloc(3)
, all
                  products of
n
*
size
of
calloc(3)
, all
size
arguments of
realloc(3)
,
length
arguments of
mmap(2)
, and
new_size
arguments of
mremap(2)
."
819,3,memusage,"heap peak
Maximum of all
size
arguments of
malloc(3)
, all
                  products of
n
*
size
of
calloc(3)
, all
size
arguments of
realloc(3)
,
length
arguments of
mmap(2)
, and
new_size
arguments of
mremap(2)
. stack peak
Before the first call to any monitored function, the
                  stack pointer address (base stack pointer) is saved. After each function call, the actual stack pointer
                  address is read and the difference from the base stack
                  pointer computed."
819,4,memusage,"After each function call, the actual stack pointer
                  address is read and the difference from the base stack
                  pointer computed. The maximum of these differences is
                  then the stack peak. Immediately following this summary line, a table shows the number
       calls, total memory allocated or deallocated, and number of failed
       calls for each intercepted function."
819,5,memusage,"Immediately following this summary line, a table shows the number
       calls, total memory allocated or deallocated, and number of failed
       calls for each intercepted function. For
realloc(3)
and
mremap(2)
, the additional field ""nomove"" shows reallocations that
       changed the address of a block, and the additional ""dec"" field
       shows reallocations that decreased the size of the block. For
realloc(3)
, the additional field ""free"" shows reallocations that
       caused a block to be freed (i.e., the reallocated size was 0)."
819,6,memusage,"For
realloc(3)
, the additional field ""free"" shows reallocations that
       caused a block to be freed (i.e., the reallocated size was 0). The ""realloc/total memory"" of the table output by
memusage
does
       not reflect cases where
realloc(3)
is used to reallocate a block
       of memory to have a smaller size than previously. This can cause
       sum of all ""total memory"" cells (excluding ""free"") to be larger
       than the ""free/total memory"" cell."
819,7,memusage,"The ""realloc/total memory"" of the table output by
memusage
does
       not reflect cases where
realloc(3)
is used to reallocate a block
       of memory to have a smaller size than previously. This can cause
       sum of all ""total memory"" cells (excluding ""free"") to be larger
       than the ""free/total memory"" cell. Histogram for block sizes
The ""Histogram for block sizes"" provides a breakdown of memory
       allocations into various bucket sizes."
820,0,memusagestat,"memusagestat
creates a PNG file containing a graphical
       representation of the memory profiling data in the file
datafile
;
       that file is generated via the
-d
(or
--data
) option of
memusage(1)
.

       The red line in the graph shows the heap usage (allocated memory)
       and the green line shows the stack usage.  The x-scale is either
       the number of memory-handling function calls or (if the
-t
option
       is specified) time."
821,0,mesg,"The
mesg
utility is invoked by a user to control write access
       others have to the terminal device associated with standard error
       output. If write access is allowed, then programs such as
talk
(1)
       and
write
(1) may display messages on the terminal. Traditionally, write access is allowed by default."
821,1,mesg,"Traditionally, write access is allowed by default. However, as
       users become more conscious of various security risks, there is a
       trend to remove write access by default, at least for the primary
       login shell. The initial permissions for the terminal are set by
login(1)
according to TTYPERM and TTYGROUP from /etc/login.defs."
821,2,mesg,"The initial permissions for the terminal are set by
login(1)
according to TTYPERM and TTYGROUP from /etc/login.defs. The
       default is mode
0620
if a tty group is used, and
0600
without the
       group. The default tty group name is ""tty""."
821,3,mesg,"The default tty group name is ""tty"". To ensure that your ttys are set in a portable and independent
       manner from system settings,
mesg
should be executed in your login
       scripts. mesg
modifies the write permissions for a group on the current
       terminal device."
821,4,mesg,"mesg
modifies the write permissions for a group on the current
       terminal device. Since version 2.41,
mesg
can no longer be
       compiled to make the terminal writable for
others
and strictly
       modifies only
group
permissions. The usual setup is to use a ""tty""
       group and add relevant users to this group."
821,5,mesg,"The usual setup is to use a ""tty""
       group and add relevant users to this group. Alternatively, a less
       secure solution is to set utilities like
write
(1) or
wall(1)
to
       setgid for the ""tty"" group. The
mesg
utility silently exits with error status 2 if not
       executed on a terminal."
821,6,mesg,"The
mesg
utility silently exits with error status 2 if not
       executed on a terminal. In this case executing
mesg
is pointless. The command line option
--verbose
forces
mesg
to print a warning
       in this situation."
821,7,mesg,"In this case executing
mesg
is pointless. The command line option
--verbose
forces
mesg
to print a warning
       in this situation. This behaviour has been introduced in version
       2.33."
822,0,mesg,"The
mesg
utility shall control whether other users are allowed to
       send messages via
write
,
talk
, or other utilities to a terminal
       device. The terminal device affected shall be determined by
       searching for the first terminal in the sequence of devices
       associated with standard input, standard output, and standard
       error, respectively. With no arguments,
mesg
shall report the
       current state without changing it."
822,1,mesg,"The terminal device affected shall be determined by
       searching for the first terminal in the sequence of devices
       associated with standard input, standard output, and standard
       error, respectively. With no arguments,
mesg
shall report the
       current state without changing it. Processes with appropriate
       privileges may be able to send messages to the terminal
       independent of the current state."
823,0,mk-ca-bundle,"This tool downloads the
certdata.txt
file from Mozilla's source
       tree over HTTPS, then parses it and extracts the included
       certificates into PEM format. By default, only CA root
       certificates trusted to issue SSL server authentication
       certificates are extracted. These are then processed with the
       OpenSSL command line tool to produce the final ca-bundle output
       file."
823,1,mk-ca-bundle,"These are then processed with the
       OpenSSL command line tool to produce the final ca-bundle output
       file. The default
output
name is
ca-bundle.crt
. By setting it to '-' (a
       single dash) you get the output sent to STDOUT instead of a file."
823,2,mk-ca-bundle,"The default
output
name is
ca-bundle.crt
. By setting it to '-' (a
       single dash) you get the output sent to STDOUT instead of a file. The PEM format this scripts uses for output makes the result
       readily available for use by just about all OpenSSL or GnuTLS
       powered applications, such as curl and others."
824,0,mkdir,"Create the DIRECTORY(ies), if they do not already exist.

       Mandatory arguments to long options are mandatory for short
       options too.
-m
,
--mode
=
MODE
set file mode (as in chmod), not a=rwx - umask
-p
,
--parents
no error if existing, make parent directories as needed,
              with their file modes unaffected by any
-m
option
-v
,
--verbose
print a message for each created directory
-Z
set SELinux security context of each created directory to
              the default type
--context
[=
CTX
]
              like
-Z
, or if CTX is specified then set the SELinux or
              SMACK security context to CTX
--help
display this help and exit
--version
output version information and exit"
825,0,mkaf,"A collection of one or more Performance Co-Pilot (see
PCPIntro(1)
)
       archives may be combined with
mkaf
to produce a PCP archive folio
       and the associated archive folio control file. Some PCP tools use
mkaf
to create archive folios, e.g. the ``record'' facility in the
pmchart(1)
and
pmview(1)
tools, to facilitate playback with
pmafm(1)
."
825,1,mkaf,"the ``record'' facility in the
pmchart(1)
and
pmview(1)
tools, to facilitate playback with
pmafm(1)
. mkaf
processes each
filename
argument, and if this is a component
       file from a PCP archive that archive is added to the folio. If
filename
is a directory, then this is searched recursively
       using
find(1)
."
825,2,mkaf,"If
filename
is a directory, then this is searched recursively
       using
find(1)
. Any
filename
argument beginning with a ``-'' is
       assumed to be a
find(1)
command line option (
findopts
); the
       default is
-follow
if no
findopts
are specified. The first named archive in the folio is assumed to be associated
       with the default host for any tool that tries to replay multiple
       archives from the folio."
825,3,mkaf,"The first named archive in the folio is assumed to be associated
       with the default host for any tool that tries to replay multiple
       archives from the folio. The folio control file is written to standard output, and has the
       following format. 1."
825,4,mkaf,"1. The first line contains the word
PCPFolio
. 2."
825,5,mkaf,"2. The second line contains the tag
Version:
followed by the
          format version number (currently 1). 3."
825,6,mkaf,"3. For subsequent lines, blank lines and lines beginning with
          ``#'' are ignored. 4."
825,7,mkaf,"4. The line beginning with the tag
Created:
documents where and
          when the folio was created. 5."
825,8,mkaf,"5. The line beginning with the tag
Creator:
identifies the tool
          which created the folio (and is assumed to know how to replay
          the archive folio). If present, the second argument is the
          name of a configuration file that the creator tool could use to
          replay the archive folio, e.g."
825,9,mkaf,"If present, the second argument is the
          name of a configuration file that the creator tool could use to
          replay the archive folio, e.g. with the
replay
command for
pmafm(1)
. In the case of
mkaf
(unlike
pmchart(1)
or
pmview(1)
)
          there is no knowledge of the contents of the archives, so the
          ``creator'' cannot replay the archive, however
pmchart(1)
is
          able to replay any archive, and so this tool is identified as
          the
Creator:
for archive folios created by
mkaf(1)
."
825,10,mkaf,"In the case of
mkaf
(unlike
pmchart(1)
or
pmview(1)
)
          there is no knowledge of the contents of the archives, so the
          ``creator'' cannot replay the archive, however
pmchart(1)
is
          able to replay any archive, and so this tool is identified as
          the
Creator:
for archive folios created by
mkaf(1)
. 6. This is then followed by one or more lines beginning with the
          tag
Archive:
followed by the hostname and base name of the
          archive."
825,11,mkaf,"This is then followed by one or more lines beginning with the
          tag
Archive:
followed by the hostname and base name of the
          archive. For example
            $ mkaf mydir/gonzo
       might produce the following folio control file. PCPFolio
       Version: 1
       # use pmafm(1) to process this PCP archive folio
       #
       Created: on gonzo at Tue Jul  2 03:35:54 EST 1996
       Creator: pmchart
       #               Host                    Basename
       #
       Archive:        gonzo                   mydir/gonzo/960627
       Archive:        gonzo                   mydir/gonzo/960628
       Archive:        gonzo                   mydir/gonzo/960629
       Archive:        gonzo                   mydir/gonzo/960630
       Archive:        gonzo                   mydir/gonzo/960701
       Archive:        gonzo                   mydir/gonzo/960701.00.10
       Archive:        gonzo                   mydir/gonzo/960701.05.25
       Archive:        gonzo                   mydir/gonzo/960702.00.10"
826,0,mkfifo,"Create named pipes (FIFOs) with the given NAMEs.

       Mandatory arguments to long options are mandatory for short
       options too.
-m
,
--mode
=
MODE
set file permission bits to MODE, not a=rw - umask
-Z
set the SELinux security context to default type
--context
[=
CTX
]
              like
-Z
, or if CTX is specified then set the SELinux or
              SMACK security context to CTX
--help
display this help and exit
--version
output version information and exit"
827,0,mkfifo,"The
mkfifo
utility shall create the FIFO special files specified
       by the operands, in the order specified. For each
file
operand, the
mkfifo
utility shall perform actions
       equivalent to the
mkfifo
() function defined in the System
       Interfaces volume of POSIX.1â2017, called with the following
       arguments:

        1. The
file
operand is used as the
path
argument."
827,1,mkfifo,"The
file
operand is used as the
path
argument. 2. The value of the bitwise-inclusive OR of S_IRUSR, S_IWUSR,
           S_IRGRP, S_IWGRP, S_IROTH, and S_IWOTH is used as the
mode
argument."
827,2,mkfifo,"2. The value of the bitwise-inclusive OR of S_IRUSR, S_IWUSR,
           S_IRGRP, S_IWGRP, S_IROTH, and S_IWOTH is used as the
mode
argument. (If the
-m
option is specified, the value of the
mkfifo
()
mode
argument is unspecified, but the FIFO shall at
           no time have permissions less restrictive than the
-m
mode
option-argument.)"
828,0,mkdir,"The
mkdir
utility shall create the directories specified by the
       operands, in the order specified. For each
dir
operand, the
mkdir
utility shall perform actions
       equivalent to the
mkdir
() function defined in the System
       Interfaces volume of POSIX.1â2017, called with the following
       arguments:

        1. The
dir
operand is used as the
path
argument."
828,1,mkdir,"The
dir
operand is used as the
path
argument. 2. The value of the bitwise-inclusive OR of S_IRWXU, S_IRWXG, and
           S_IRWXO is used as the
mode
argument."
828,2,mkdir,"2. The value of the bitwise-inclusive OR of S_IRWXU, S_IRWXG, and
           S_IRWXO is used as the
mode
argument. (If the
-m
option is
           specified, the value of the
mkdir
()
mode
argument is
           unspecified, but the directory shall at no time have
           permissions less restrictive than the
-m
mode
option-
           argument.)"
829,0,minicom,"minicom
is a communication program which somewhat resembles the
       shareware program TELIX but is free with source code and runs
       under most Unices.  Features include dialing directory with auto-
       redial, support for UUCP-style lock files on serial devices, a
       separate script language interpreter, capture to file, multiple
       users with individual configurations, and more."
830,0,mknod,"Create the special file NAME of the given TYPE. Mandatory arguments to long options are mandatory for short
       options too. -m
,
--mode
=
MODE
set file permission bits to MODE, not a=rw - umask
-Z
set the SELinux security context to default type
--context
[=
CTX
]
              like
-Z
, or if CTX is specified then set the SELinux or
              SMACK security context to CTX
--help
display this help and exit
--version
output version information and exit

       Both MAJOR and MINOR must be specified when TYPE is b, c, or u,
       and they must be omitted when TYPE is p."
830,1,mknod,"-m
,
--mode
=
MODE
set file permission bits to MODE, not a=rw - umask
-Z
set the SELinux security context to default type
--context
[=
CTX
]
              like
-Z
, or if CTX is specified then set the SELinux or
              SMACK security context to CTX
--help
display this help and exit
--version
output version information and exit

       Both MAJOR and MINOR must be specified when TYPE is b, c, or u,
       and they must be omitted when TYPE is p. If MAJOR or MINOR begins
       with 0x or 0X, it is interpreted as hexadecimal; otherwise, if it
       begins with 0, as octal; otherwise, as decimal. TYPE may be:

       b      create a block (buffered) special file

       c, u   create a character (unbuffered) special file

       p      create a FIFO

       Your shell may have its own version of mknod, which usually
       supersedes the version described here."
830,2,mknod,"If MAJOR or MINOR begins
       with 0x or 0X, it is interpreted as hexadecimal; otherwise, if it
       begins with 0, as octal; otherwise, as decimal. TYPE may be:

       b      create a block (buffered) special file

       c, u   create a character (unbuffered) special file

       p      create a FIFO

       Your shell may have its own version of mknod, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports."
831,0,mktemp,"Create a temporary file or directory, safely, and print its name. TEMPLATE must contain at least 3 consecutive 'X's in last
       component. If TEMPLATE is not specified, use tmp.XXXXXXXXXX, and
--tmpdir
is implied."
831,1,mktemp,"If TEMPLATE is not specified, use tmp.XXXXXXXXXX, and
--tmpdir
is implied. Files are created u+rw, and directories
       u+rwx, minus umask restrictions. -d
,
--directory
create a directory, not a file
-u
,
--dry-run
do not create anything; merely print a name (unsafe)
-q
,
--quiet
suppress diagnostics about file/dir-creation failure
--suffix
=
SUFF
append SUFF to TEMPLATE; SUFF must not contain a slash."
831,2,mktemp,"-d
,
--directory
create a directory, not a file
-u
,
--dry-run
do not create anything; merely print a name (unsafe)
-q
,
--quiet
suppress diagnostics about file/dir-creation failure
--suffix
=
SUFF
append SUFF to TEMPLATE; SUFF must not contain a slash. This option is implied if TEMPLATE does not end in X
-p
DIR,
--tmpdir
[=
DIR
]
              interpret TEMPLATE relative to DIR; if DIR is not
              specified, use $TMPDIR if set, else
/tmp
. With this
              option, TEMPLATE must not be an absolute name; unlike with
-t
, TEMPLATE may contain slashes, but mktemp creates only
              the final component
-t
interpret TEMPLATE as a single file name component,
              relative to a directory: $TMPDIR, if set; else the
              directory specified via
-p
; else
/tmp
[deprecated]
--help
display this help and exit
--version
output version information and exit"
832,0,mmroff,nan
833,0,more,"more
is a filter for paging through text one screenful at a time.
       This version is especially primitive. Users should realize that
less(1)
provides
more(1)
emulation plus extensive enhancements."
834,0,systemd-dissect,"systemd-dissect
is a tool for introspecting and interacting with
       file system OS disk images, specifically Discoverable Disk Images
       (DDIs). It supports four different operations:

        1. Show general OS image information, including the image's
os-release(5)
data, machine ID, partition information and
           more."
834,1,systemd-dissect,"Show general OS image information, including the image's
os-release(5)
data, machine ID, partition information and
           more. 2. Mount an OS image to a local directory."
834,2,systemd-dissect,"Mount an OS image to a local directory. In this mode it will
           dissect the OS image and mount the included partitions
           according to their designation onto a directory and possibly
           sub-directories. 3."
834,3,systemd-dissect,"3. Unmount an OS image from a local directory. In this mode it
           will recursively unmount the mounted partitions and remove the
           underlying loop device, including all the partition
           sub-devices."
834,4,systemd-dissect,"In this mode it
           will recursively unmount the mounted partitions and remove the
           underlying loop device, including all the partition
           sub-devices. 4. Copy files and directories in and out of an OS image."
834,5,systemd-dissect,"Copy files and directories in and out of an OS image. The tool may operate on three types of OS images:

        1. OS disk images containing a GPT partition table envelope, with
           partitions marked according to the
Discoverable Partitions
Specification
[1]."
834,6,systemd-dissect,"OS disk images containing a GPT partition table envelope, with
           partitions marked according to the
Discoverable Partitions
Specification
[1]. 2. OS disk images containing just a plain file-system without an
           enveloping partition table."
834,7,systemd-dissect,"OS disk images containing just a plain file-system without an
           enveloping partition table. (This file system is assumed to be
           the root file system of the OS.)

        3. OS disk images containing a GPT or MBR partition table, with a
           single partition only."
834,8,systemd-dissect,"OS disk images containing a GPT or MBR partition table, with a
           single partition only. (This partition is assumed to contain
           the root file system of the OS.)

       OS images may use any kind of Linux-supported file systems. In
       addition they may make use of LUKS disk encryption, and contain
       Verity integrity information."
834,9,systemd-dissect,"In
       addition they may make use of LUKS disk encryption, and contain
       Verity integrity information. Note that qualifying OS images may
       be booted with
systemd-nspawn(1)
's
--image=
switch, and be used as
       root file system for system service using the
RootImage=
unit file
       setting, see
systemd.exec(5)
. Note that the partition table shown when invoked without command
       switch (as listed below) does not necessarily show all partitions
       included in the image, but just the partitions that are understood
       and considered part of an OS disk image."
834,10,systemd-dissect,"Note that the partition table shown when invoked without command
       switch (as listed below) does not necessarily show all partitions
       included in the image, but just the partitions that are understood
       and considered part of an OS disk image. Specifically, partitions
       of unknown types are ignored, as well as duplicate partitions
       (i.e. more than one per partition type), as are root and /usr/
       partitions of architectures not compatible with the local system."
834,11,systemd-dissect,"more than one per partition type), as are root and /usr/
       partitions of architectures not compatible with the local system. In other words: this tool will display what it operates with when
       mounting the image. To display the complete list of partitions use
       a tool such as
fdisk(8)
."
834,12,systemd-dissect,"To display the complete list of partitions use
       a tool such as
fdisk(8)
. The
systemd-dissect
command may be invoked as
mount.ddi
in which
       case it implements the
mount(8)
""external helper"" interface. This
       ensures disk images compatible with
systemd-dissect
can be mounted
       directly by
mount
and
fstab(5)
."
834,13,systemd-dissect,"This
       ensures disk images compatible with
systemd-dissect
can be mounted
       directly by
mount
and
fstab(5)
. For details see below. In place of the image path a "".v/"" versioned directory may be
       specified, see
systemd.v(7)
for details."
835,0,mrtg2pcp,"mrtg2pcp
is intended to read an MRTG log file as created by
mrtg
(1) and translate this into a Performance Co-Pilot (PCP)
       archive with the basename
outfile
. The
hostname
,
devname
, and
timezone
arguments specify information about the system for which
       the statistics were gathered. The resultant PCP archive may be used with all PCP client tools to
       graph subsets of the data using
pmchart(1)
, perform data reduction
       and reporting, filter with the PCP inference engine
pmie(1)
, etc."
835,1,mrtg2pcp,"The resultant PCP archive may be used with all PCP client tools to
       graph subsets of the data using
pmchart(1)
, perform data reduction
       and reporting, filter with the PCP inference engine
pmie(1)
, etc. A series of physical files will be created with the prefix
outfile
. These are
outfile
.0
(the performance data),
outfile
.meta
(the metadata that describes the performance data) and
outfile
.index
(a temporal index to improve efficiency of replay
       operations for the archive)."
835,2,mrtg2pcp,"A series of physical files will be created with the prefix
outfile
. These are
outfile
.0
(the performance data),
outfile
.meta
(the metadata that describes the performance data) and
outfile
.index
(a temporal index to improve efficiency of replay
       operations for the archive). If any of these files exists
       already, then
mrtg2pcp
will
not
overwrite them and will exit with
       an error message of the form

       __pmLogNewFile: ``blah.0'' already exists, not over-written
mrtg2pcp
is a Perl script that uses the PCP::LogImport Perl
       wrapper around the PCP
libpcp_import
library, and as such could be
       used as an example to develop new tools to import other types of
       performance data and create PCP archives."
836,0,mountpoint,"mountpoint
checks whether the given
directory
or
file
is mentioned
       in the
/proc/self/mountinfo
file."
837,0,mpvis,"mpvis
displays a three dimensional bar chart of CPU utilization. The display is updated with new values retrieved from the target
host
or
archive
every
interval
seconds (default is 2 seconds). The height of the bars is proportional to the CPU utilization in
       each of the modes
idle
(with no I/O pending),
wait
(idle, but
       waiting for I/O - only visible in IRIX),
intr
(interrupt
       processing - only visible in IRIX),
nice
(nice state - only
       visible in Linux),
sys
(in the kernel) and
user
."
837,1,mpvis,"The height of the bars is proportional to the CPU utilization in
       each of the modes
idle
(with no I/O pending),
wait
(idle, but
       waiting for I/O - only visible in IRIX),
intr
(interrupt
       processing - only visible in IRIX),
nice
(nice state - only
       visible in Linux),
sys
(in the kernel) and
user
. The number of CPUs per row in the scene is governed by the default
       maximum row length, and the options
-b
,
-r
and
-R
. If none of
       these flags are specified,
mpvis
uses the default maximum row
       length to calculate the actual number of rows and columns in the
       view, according to:

            nrows = (ncpus + maxrowlen - 1) / maxrowlen
            ncols = (ncpus + nrows - 1) / nrows."
837,2,mpvis,"If none of
       these flags are specified,
mpvis
uses the default maximum row
       length to calculate the actual number of rows and columns in the
       view, according to:

            nrows = (ncpus + maxrowlen - 1) / maxrowlen
            ncols = (ncpus + nrows - 1) / nrows. The
-r
option uses the above algorithm, but allows the user to
       override the maximum row length. The CPUs are sorted in ascending order."
837,3,mpvis,"The CPUs are sorted in ascending order. They are displayed from
       left to right, and front to back (in the case where there is more
       than one row of CPUs). The user can specify a list of CPUs as
cpuid
arguments using the
       naming scheme reported by
          $ pminfo -f kernel.percpu.cpu.user
       i.e."
837,4,mpvis,"The user can specify a list of CPUs as
cpuid
arguments using the
       naming scheme reported by
          $ pminfo -f kernel.percpu.cpu.user
       i.e. cpu
N
or
cpu
A
:
B
depending on the operating system version and
       platform. Alternatively, if the
cpuid
argument contains one of
       the characters
^
or
."
837,5,mpvis,"Alternatively, if the
cpuid
argument contains one of
       the characters
^
or
. or
[
then
cpuid
will be treated as a
       regular expression in the style of
egrep
(1) and the matching set
       of CPU names will be used instead of
cpuid
. If one or more
cpuid
arguments is specified, then only the CPUs in
       this list are displayed in the view."
837,6,mpvis,"If one or more
cpuid
arguments is specified, then only the CPUs in
       this list are displayed in the view. The list of CPUs is sorted
       into ascending CPU number and they are displayed from left to
       right, and front to back (in the case where there is more than one
       row of CPUs). mpvis
generates a
pmview(1)
configuration file, and passes most
       command line options to
pmview(1)
."
837,7,mpvis,"The list of CPUs is sorted
       into ascending CPU number and they are displayed from left to
       right, and front to back (in the case where there is more than one
       row of CPUs). mpvis
generates a
pmview(1)
configuration file, and passes most
       command line options to
pmview(1)
. Therefore, the command line
       options
-A
,
-a
,
-C
,
-h
,
-n
,
-O
,
-p
,
-S
,
-t
,
-T
,
-Z
and
-z
, and the
       user interface are described in the
pmview(1)
man page."
838,0,mpstat,"The
mpstat
command writes to standard output activities for each
       available processor, processor 0 being the first one. Global
       average activities among all processors are also reported. The
mpstat
command can be used on both SMP and UP machines, but in the
       latter, only global average activities will be printed."
838,1,mpstat,"The
mpstat
command can be used on both SMP and UP machines, but in the
       latter, only global average activities will be printed. If no
       activity has been selected, then the default report is the CPU
       utilization report. The
interval
parameter specifies the amount of time in seconds
       between each report."
838,2,mpstat,"The
interval
parameter specifies the amount of time in seconds
       between each report. A value of 0 (or no parameters at all)
       indicates that processors statistics are to be reported for the
       time since system startup (boot). The
count
parameter can be
       specified in conjunction with the
interval
parameter if this one
       is not set to zero."
838,3,mpstat,"The
count
parameter can be
       specified in conjunction with the
interval
parameter if this one
       is not set to zero. The value of
count
determines the number of
       reports generated at
interval
seconds apart. If the
interval
parameter is specified without the
count
parameter, the
mpstat
command generates reports continuously."
839,0,msgcat,"Concatenates and merges the specified PO files. Find messages
       which are common to two or more of the specified PO files. By
       using the
--more-than
option, greater commonality may be requested
       before messages are printed."
839,1,msgcat,"By
       using the
--more-than
option, greater commonality may be requested
       before messages are printed. Conversely, the
--less-than
option
       may be used to specify less commonality before messages are
       printed (i.e. --less-than
=
2
will only print the unique messages)."
839,2,msgcat,"--less-than
=
2
will only print the unique messages). Translations, comments, extracted comments, and file positions
       will be cumulated, except that if
--use-first
is specified, they
       will be taken from the first PO file to define them. Mandatory arguments to long options are mandatory for short
       options too."
839,3,msgcat,"Mandatory arguments to long options are mandatory for short
       options too. Input file location:
INPUTFILE ... input files
-f
,
--files-from
=
FILE
get list of input files from FILE
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read."
839,4,msgcat,"input files
-f
,
--files-from
=
FILE
get list of input files from FILE
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read. Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. Message selection:
-<,
--less-than
=
NUMBER
print messages with less than this many definitions,
              defaults to infinite if not set

       ->,
--more-than
=
NUMBER
print messages with more than this many definitions,
              defaults to 0 if not set
-u
,
--unique
shorthand for
--less-than
=
2
, requests that only unique
              messages be printed
Input file syntax:
-P
,
--properties-input
input files are in Java .properties syntax
--stringtable-input
input files are in NeXTstep/GNUstep .strings syntax
Output details:
-t
,
--to-code
=
NAME
encoding for output
--use-first
use first available translation for each message, don't
              merge several translations
--lang
=
CATALOGNAME
set 'Language' field in the header entry
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN."
839,5,msgcat,"Message selection:
-<,
--less-than
=
NUMBER
print messages with less than this many definitions,
              defaults to infinite if not set

       ->,
--more-than
=
NUMBER
print messages with more than this many definitions,
              defaults to 0 if not set
-u
,
--unique
shorthand for
--less-than
=
2
, requests that only unique
              messages be printed
Input file syntax:
-P
,
--properties-input
input files are in Java .properties syntax
--stringtable-input
input files are in NeXTstep/GNUstep .strings syntax
Output details:
-t
,
--to-code
=
NAME
encoding for output
--use-first
use first available translation for each message, don't
              merge several translations
--lang
=
CATALOGNAME
set 'Language' field in the header entry
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-e
,
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
-i
,
--indent
write the .po file using indented style
--no-location
do not write '#: filename:line' lines
-n
,
--add-location
generate '#: filename:line' lines (default)
--strict
write out strict Uniforum conforming .po file
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output
-F
,
--sort-by-file
sort output by file location
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
840,0,msgattrib,"Filters the messages of a translation catalog according to their
       attributes, and manipulates the attributes. Mandatory arguments to long options are mandatory for short
       options too. Input file location:
INPUTFILE
              input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read."
840,1,msgattrib,"Input file location:
INPUTFILE
              input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read. Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. Message selection:
--translated
keep translated, remove untranslated messages
--untranslated
keep untranslated, remove translated messages
--no-fuzzy
remove 'fuzzy' marked messages
--only-fuzzy
keep 'fuzzy' marked messages
--no-obsolete
remove obsolete #~ messages
--only-obsolete
keep obsolete #~ messages
Attribute manipulation:
--set-fuzzy
set all messages 'fuzzy'
--clear-fuzzy
set all messages non-'fuzzy'
--set-obsolete
set all messages obsolete
--clear-obsolete
set all messages non-obsolete
--previous
when setting 'fuzzy', keep previous msgids of translated
              messages."
840,2,msgattrib,"Message selection:
--translated
keep translated, remove untranslated messages
--untranslated
keep untranslated, remove translated messages
--no-fuzzy
remove 'fuzzy' marked messages
--only-fuzzy
keep 'fuzzy' marked messages
--no-obsolete
remove obsolete #~ messages
--only-obsolete
keep obsolete #~ messages
Attribute manipulation:
--set-fuzzy
set all messages 'fuzzy'
--clear-fuzzy
set all messages non-'fuzzy'
--set-obsolete
set all messages obsolete
--clear-obsolete
set all messages non-obsolete
--previous
when setting 'fuzzy', keep previous msgids of translated
              messages. --clear-previous
remove the ""previous msgid"" from all messages
--empty
when removing 'fuzzy', also set msgstr empty
--only-file
=
FILE
.po
              manipulate only entries listed in FILE.po
--ignore-file
=
FILE
.po
              manipulate only entries not listed in FILE.po
--fuzzy
synonym for
--only-fuzzy --clear-fuzzy
--obsolete
synonym for
--only-obsolete --clear-obsolete
Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'."
840,3,msgattrib,"--clear-previous
remove the ""previous msgid"" from all messages
--empty
when removing 'fuzzy', also set msgstr empty
--only-file
=
FILE
.po
              manipulate only entries listed in FILE.po
--ignore-file
=
FILE
.po
              manipulate only entries not listed in FILE.po
--fuzzy
synonym for
--only-fuzzy --clear-fuzzy
--obsolete
synonym for
--only-obsolete --clear-obsolete
Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-e
,
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
-i
,
--indent
write the .po file using indented style
--no-location
do not write '#: filename:line' lines
-n
,
--add-location
generate '#: filename:line' lines (default)
--strict
write out strict Uniforum conforming .po file
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output
-F
,
--sort-by-file
sort output by file location
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
841,0,more,"The
more
utility shall read files and either write them to the
       terminal on a page-by-page basis or filter them to standard
       output. If standard output is not a terminal device, all input
       files shall be copied to standard output in their entirety,
       without modification, except as specified for the
-s
option. If
       standard output is a terminal device, the files shall be written a
       number of lines (one screenful) at a time under the control of
       user commands."
841,1,more,"If
       standard output is a terminal device, the files shall be written a
       number of lines (one screenful) at a time under the control of
       user commands. See the EXTENDED DESCRIPTION section. Certain block-mode terminals do not have all the capabilities
       necessary to support the complete
more
definition; they are
       incapable of accepting commands that are not terminated with a
       <newline>."
841,2,more,"Certain block-mode terminals do not have all the capabilities
       necessary to support the complete
more
definition; they are
       incapable of accepting commands that are not terminated with a
       <newline>. Implementations that support such terminals shall
       provide an operating mode to
more
in which all commands can be
       terminated with a <newline> on those terminals. This mode:

        *  Shall be documented in the system documentation

        *  Shall, at invocation, inform the user of the terminal
           deficiency that requires the <newline> usage and provide
           instructions on how this warning can be suppressed in future
           invocations

        *  Shall not be required for implementations supporting only
           fully capable terminals

        *  Shall not affect commands already requiring <newline>
           characters

        *  Shall not affect users on the capable terminals from using
more
as described in this volume of POSIX.1â2017"
842,0,msgcmp,"Compare two Uniforum style .po files to check that both contain
       the same set of msgid strings. The def.po file is an existing PO
       file with the translations. The ref.pot file is the last created
       PO file, or a PO Template file (generally created by xgettext)."
842,1,msgcmp,"The ref.pot file is the last created
       PO file, or a PO Template file (generally created by xgettext). This is useful for checking that you have translated each and
       every message in your program. Where an exact match cannot be
       found, fuzzy matching is used to produce better diagnostics."
842,2,msgcmp,"Where an exact match cannot be
       found, fuzzy matching is used to produce better diagnostics. Mandatory arguments to long options are mandatory for short
       options too. Input file location:
def.po translations

       ref.pot
              references to the sources
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search
Operation modifiers:
-m
,
--multi-domain
apply ref.pot to each of the domains in def.po
-N
,
--no-fuzzy-matching
do not use fuzzy matching
--use-fuzzy
consider fuzzy entries
--use-untranslated
consider untranslated entries
Input file syntax:
-P
,
--properties-input
input files are in Java .properties syntax
--stringtable-input
input files are in NeXTstep/GNUstep .strings syntax
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
843,0,msgcomm,"Find messages which are common to two or more of the specified PO
       files. By using the
--more-than
option, greater commonality may
       be requested before messages are printed. Conversely, the
--less-than
option may be used to specify less commonality before
       messages are printed (i.e."
843,1,msgcomm,"Conversely, the
--less-than
option may be used to specify less commonality before
       messages are printed (i.e. --less-than
=
2
will only print the
       unique messages). Translations, comments and extracted comments
       will be preserved, but only from the first PO file to define them."
843,2,msgcomm,"Translations, comments and extracted comments
       will be preserved, but only from the first PO file to define them. File positions from all PO files will be cumulated. Mandatory arguments to long options are mandatory for short
       options too."
843,3,msgcomm,"Mandatory arguments to long options are mandatory for short
       options too. Input file location:
INPUTFILE ... input files
-f
,
--files-from
=
FILE
get list of input files from FILE
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read."
843,4,msgcomm,"input files
-f
,
--files-from
=
FILE
get list of input files from FILE
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read. Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. Message selection:
-<,
--less-than
=
NUMBER
print messages with less than this many definitions,
              defaults to infinite if not set

       ->,
--more-than
=
NUMBER
print messages with more than this many definitions,
              defaults to 1 if not set
-u
,
--unique
shorthand for
--less-than
=
2
, requests that only unique
              messages be printed
Input file syntax:
-P
,
--properties-input
input files are in Java .properties syntax
--stringtable-input
input files are in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN."
843,5,msgcomm,"Message selection:
-<,
--less-than
=
NUMBER
print messages with less than this many definitions,
              defaults to infinite if not set

       ->,
--more-than
=
NUMBER
print messages with more than this many definitions,
              defaults to 1 if not set
-u
,
--unique
shorthand for
--less-than
=
2
, requests that only unique
              messages be printed
Input file syntax:
-P
,
--properties-input
input files are in Java .properties syntax
--stringtable-input
input files are in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-e
,
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
-i
,
--indent
write the .po file using indented style
--no-location
do not write '#: filename:line' lines
-n
,
--add-location
generate '#: filename:line' lines (default)
--strict
write out strict Uniforum conforming .po file
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output
-F
,
--sort-by-file
sort output by file location
--omit-header
don't write header with 'msgid """"' entry
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
844,0,msgconv,"Converts a translation catalog to a different character encoding. Mandatory arguments to long options are mandatory for short
       options too. Input file location:
INPUTFILE
              input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read."
844,1,msgconv,"Input file location:
INPUTFILE
              input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read. Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. Conversion target:
-t
,
--to-code
=
NAME
encoding for output

       The default encoding is the current locale's encoding."
844,2,msgconv,"Conversion target:
-t
,
--to-code
=
NAME
encoding for output

       The default encoding is the current locale's encoding. Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'."
844,3,msgconv,"Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-e
,
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
-i
,
--indent
indented output style
--no-location
suppress '#: filename:line' lines
-n
,
--add-location
preserve '#: filename:line' lines (default)
--strict
strict Uniforum output style
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output
-F
,
--sort-by-file
sort output by file location
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
845,0,msgen,"Creates an English translation catalog. The input file is the
       last created English PO file, or a PO Template file (generally
       created by xgettext). Untranslated entries are assigned a
       translation that is identical to the msgid."
845,1,msgen,"Untranslated entries are assigned a
       translation that is identical to the msgid. Mandatory arguments to long options are mandatory for short
       options too. Input file location:
INPUTFILE
              input PO or POT file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read."
845,2,msgen,"Input file location:
INPUTFILE
              input PO or POT file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read. Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--lang
=
CATALOGNAME
set 'Language' field in the header entry
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN."
845,3,msgen,"Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--lang
=
CATALOGNAME
set 'Language' field in the header entry
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-e
,
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
-i
,
--indent
indented output style
--no-location
suppress '#: filename:line' lines
-n
,
--add-location
preserve '#: filename:line' lines (default)
--strict
strict Uniforum output style
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output
-F
,
--sort-by-file
sort output by file location
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
846,0,msgexec,"Applies a command to all translations of a translation catalog. The COMMAND can be any program that reads a translation from
       standard input. It is invoked once for each translation."
846,1,msgexec,"It is invoked once for each translation. Its
       output becomes msgexec's output. msgexec's return code is the
       maximum return code across all invocations."
846,2,msgexec,"msgexec's return code is the
       maximum return code across all invocations. A special builtin command called '0' outputs the translation,
       followed by a null byte. The output of ""msgexec 0"" is suitable as
       input for ""xargs
-0
""."
846,3,msgexec,"The output of ""msgexec 0"" is suitable as
       input for ""xargs
-0
"". Command input:
--newline
add newline at the end of input

       Mandatory arguments to long options are mandatory for short
       options too. Input file location:
-i
,
--input
=
INPUTFILE
input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read."
846,4,msgexec,"Command input:
--newline
add newline at the end of input

       Mandatory arguments to long options are mandatory for short
       options too. Input file location:
-i
,
--input
=
INPUTFILE
input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read. Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
847,0,msgfilter,"Applies a filter to all translations of a translation catalog. Mandatory arguments to long options are mandatory for short
       options too. Input file location:
-i
,
--input
=
INPUTFILE
input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read."
847,1,msgfilter,"Input file location:
-i
,
--input
=
INPUTFILE
input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read. Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. The FILTER can be any program that reads a translation from
       standard input and writes a modified translation to standard
       output."
847,2,msgfilter,"The FILTER can be any program that reads a translation from
       standard input and writes a modified translation to standard
       output. Filter input and output:
--newline
add a newline at the end of input and remove a newline from
              the end of output
Useful FILTER-OPTIONs when the FILTER is 'sed':
-e
,
--expression
=
SCRIPT
add SCRIPT to the commands to be executed
-f
,
--file
=
SCRIPTFILE
add the contents of SCRIPTFILE to the commands to be
              executed
-n
,
--quiet
,
--silent
suppress automatic printing of pattern space
Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'."
847,3,msgfilter,"Filter input and output:
--newline
add a newline at the end of input and remove a newline from
              the end of output
Useful FILTER-OPTIONs when the FILTER is 'sed':
-e
,
--expression
=
SCRIPT
add SCRIPT to the commands to be executed
-f
,
--file
=
SCRIPTFILE
add the contents of SCRIPTFILE to the commands to be
              executed
-n
,
--quiet
,
--silent
suppress automatic printing of pattern space
Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
--indent
indented output style
--keep-header
keep header entry unmodified, don't filter it
--no-location
suppress '#: filename:line' lines
-n
,
--add-location
preserve '#: filename:line' lines (default)
--strict
strict Uniforum output style
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output
-F
,
--sort-by-file
sort output by file location
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
848,0,msgfmt,"Generate binary message catalog from textual translation
       description. Mandatory arguments to long options are mandatory for short
       options too. Similarly for optional arguments."
848,1,msgfmt,"Similarly for optional arguments. Input file location:
filename.po ... input files
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read."
848,2,msgfmt,"input files
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read. Operation mode:
-j
,
--java
Java mode: generate a Java ResourceBundle class
--java2
like
--java
, and assume Java2 (JDK 1.2 or higher)
--csharp
C# mode: generate a .NET .dll file
--csharp-resources
C# resources mode: generate a .NET .resources file
--tcl
Tcl mode: generate a tcl/msgcat .msg file
--qt
Qt mode: generate a Qt .qm file
--desktop
Desktop Entry mode: generate a .desktop file
--xml
XML mode: generate XML file
Output file location:
-o
,
--output-file
=
FILE
write output to specified file
--strict
enable strict Uniforum mode

       If output file is -, output is written to standard output. Output file location in Java mode:
-r
,
--resource
=
RESOURCE
resource name
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
--source
produce a .java file, instead of a .class file
-d
DIRECTORY
              base directory of classes directory hierarchy

       The class name is determined by appending the locale name to the
       resource name, separated with an underscore."
848,3,msgfmt,"Output file location in Java mode:
-r
,
--resource
=
RESOURCE
resource name
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
--source
produce a .java file, instead of a .class file
-d
DIRECTORY
              base directory of classes directory hierarchy

       The class name is determined by appending the locale name to the
       resource name, separated with an underscore. The
-d
option is
       mandatory. The class is written under the specified directory."
848,4,msgfmt,"The class is written under the specified directory. Output file location in C# mode:
-r
,
--resource
=
RESOURCE
resource name
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
-d
DIRECTORY
              base directory for locale dependent .dll files

       The
-l
and
-d
options are mandatory. The .dll file is written in
       a subdirectory of the specified directory whose name depends on
       the locale."
848,5,msgfmt,"The .dll file is written in
       a subdirectory of the specified directory whose name depends on
       the locale. Output file location in Tcl mode:
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
-d
DIRECTORY
              base directory of .msg message catalogs

       The
-l
and
-d
options are mandatory. The .msg file is written in
       the specified directory."
848,6,msgfmt,"The .msg file is written in
       the specified directory. Desktop Entry mode options:
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
-o
,
--output-file
=
FILE
write output to specified file
--template
=
TEMPLATE
a .desktop file used as a template
-d
DIRECTORY
              base directory of .po files
-kWORD
,
--keyword
=
WORD
look for WORD as an additional keyword
-k
,
--keyword
do not to use default keywords

       The
-l
,
-o
, and
--template
options are mandatory. If
-D
is
       specified, input files are read from the directory instead of the
       command line arguments."
848,7,msgfmt,"If
-D
is
       specified, input files are read from the directory instead of the
       command line arguments. XML mode options:
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
-L
,
--language
=
NAME
recognise the specified XML language
-o
,
--output-file
=
FILE
write output to specified file
--template
=
TEMPLATE
an XML file used as a template
-d
DIRECTORY
              base directory of .po files
--replace-text
output XML with translated text replacing the original
              text, not augmenting the original text

       The
-l
,
-o
, and
--template
options are mandatory. If
-D
is
       specified, input files are read from the directory instead of the
       command line arguments."
848,8,msgfmt,"XML mode options:
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
-L
,
--language
=
NAME
recognise the specified XML language
-o
,
--output-file
=
FILE
write output to specified file
--template
=
TEMPLATE
an XML file used as a template
-d
DIRECTORY
              base directory of .po files
--replace-text
output XML with translated text replacing the original
              text, not augmenting the original text

       The
-l
,
-o
, and
--template
options are mandatory. If
-D
is
       specified, input files are read from the directory instead of the
       command line arguments. Input file syntax:
-P
,
--properties-input
input files are in Java .properties syntax
--stringtable-input
input files are in NeXTstep/GNUstep .strings syntax
Input file interpretation:
-c
,
--check
perform all the checks implied by
--check-format
,
--check-header
,
--check-domain
--check-format
check language dependent format strings
--check-header
verify presence and contents of the header entry
--check-domain
check for conflicts between domain directives and the
--output-file
option
-C
,
--check-compatibility
check that GNU msgfmt behaves like X/Open msgfmt
--check-accelerators
[=
CHAR
]
              check presence of keyboard accelerators for menu items
-f
,
--use-fuzzy
use fuzzy entries in output
Output details:
--no-convert
don't convert the messages to UTF-8 encoding
--no-redundancy
don't pre-expand ISO C 99 <inttypes.h> format string
              directive macros
-a
,
--alignment
=
NUMBER
align strings to NUMBER bytes (default: 1)
--endianness
=
BYTEORDER
write out 32-bit numbers in the given byte order (big or
              little, default depends on platform)
--no-hash
binary file will not include the hash table
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit
--statistics
print statistics about translations
-v
,
--verbose
increase verbosity level"
849,0,msggrep,"Extracts all messages of a translation catalog that match a given
       pattern or belong to some given source files. Mandatory arguments to long options are mandatory for short
       options too. Input file location:
INPUTFILE
              input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read."
849,1,msggrep,"Input file location:
INPUTFILE
              input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read. Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. Message selection:
[-N SOURCEFILE]..."
849,2,msggrep,"Message selection:
[-N SOURCEFILE]... [-M DOMAINNAME]... [-J MSGCTXT-PATTERN]
              [-K MSGID-PATTERN] [-T MSGSTR-PATTERN] [-C COMMENT-PATTERN]
              [-X EXTRACTED-COMMENT-PATTERN]

       A message is selected if it comes from one of the specified source
       files, or if it comes from one of the specified domains, or if
-J
is given and its context (msgctxt) matches MSGCTXT-PATTERN, or if
-K
is given and its key (msgid or msgid_plural) matches
       MSGID-PATTERN, or if
-T
is given and its translation (msgstr)
       matches MSGSTR-PATTERN, or if
-C
is given and the translator's
       comment matches COMMENT-PATTERN, or if
-X
is given and the
       extracted comment matches EXTRACTED-COMMENT-PATTERN."
849,3,msggrep,"[-J MSGCTXT-PATTERN]
              [-K MSGID-PATTERN] [-T MSGSTR-PATTERN] [-C COMMENT-PATTERN]
              [-X EXTRACTED-COMMENT-PATTERN]

       A message is selected if it comes from one of the specified source
       files, or if it comes from one of the specified domains, or if
-J
is given and its context (msgctxt) matches MSGCTXT-PATTERN, or if
-K
is given and its key (msgid or msgid_plural) matches
       MSGID-PATTERN, or if
-T
is given and its translation (msgstr)
       matches MSGSTR-PATTERN, or if
-C
is given and the translator's
       comment matches COMMENT-PATTERN, or if
-X
is given and the
       extracted comment matches EXTRACTED-COMMENT-PATTERN. When more than one selection criterion is specified, the set of
       selected messages is the union of the selected messages of each
       criterion. MSGCTXT-PATTERN or MSGID-PATTERN or MSGSTR-PATTERN or
       COMMENT-PATTERN or EXTRACTED-COMMENT-PATTERN syntax:

              [-E |
-F]
[-e PATTERN |
-f
FILE]..."
849,4,msggrep,"MSGCTXT-PATTERN or MSGID-PATTERN or MSGSTR-PATTERN or
       COMMENT-PATTERN or EXTRACTED-COMMENT-PATTERN syntax:

              [-E |
-F]
[-e PATTERN |
-f
FILE]... PATTERNs are basic regular expressions by default, or extended
       regular expressions if
-E
is given, or fixed strings if
-F
is
       given. -N
,
--location
=
SOURCEFILE
select messages extracted from SOURCEFILE
-M
,
--domain
=
DOMAINNAME
select messages belonging to domain DOMAINNAME
-J
,
--msgctxt
start of patterns for the msgctxt
-K
,
--msgid
start of patterns for the msgid
-T
,
--msgstr
start of patterns for the msgstr
-C
,
--comment
start of patterns for the translator's comment
-X
,
--extracted-comment
start of patterns for the extracted comment
-E
,
--extended-regexp
PATTERN is an extended regular expression
-F
,
--fixed-strings
PATTERN is a set of newline-separated strings
-e
,
--regexp
=
PATTERN
use PATTERN as a regular expression
-f
,
--file
=
FILE
obtain PATTERN from FILE
-i
,
--ignore-case
ignore case distinctions
-v
,
--invert-match
output only the messages that do not match any selection
              criterion
Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN."
849,5,msggrep,"-N
,
--location
=
SOURCEFILE
select messages extracted from SOURCEFILE
-M
,
--domain
=
DOMAINNAME
select messages belonging to domain DOMAINNAME
-J
,
--msgctxt
start of patterns for the msgctxt
-K
,
--msgid
start of patterns for the msgid
-T
,
--msgstr
start of patterns for the msgstr
-C
,
--comment
start of patterns for the translator's comment
-X
,
--extracted-comment
start of patterns for the extracted comment
-E
,
--extended-regexp
PATTERN is an extended regular expression
-F
,
--fixed-strings
PATTERN is a set of newline-separated strings
-e
,
--regexp
=
PATTERN
use PATTERN as a regular expression
-f
,
--file
=
FILE
obtain PATTERN from FILE
-i
,
--ignore-case
ignore case distinctions
-v
,
--invert-match
output only the messages that do not match any selection
              criterion
Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
--no-escape
do not use C escapes in output (default)
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
--indent
indented output style
--no-location
suppress '#: filename:line' lines
-n
,
--add-location
preserve '#: filename:line' lines (default)
--strict
strict Uniforum output style
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
--sort-output
generate sorted output
--sort-by-file
sort output by file location
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
850,0,msgmerge,"Merges two Uniforum style .po files together. The def.po file is
       an existing PO file with translations which will be taken over to
       the newly created file as long as they still match; comments will
       be preserved, but extracted comments and file positions will be
       discarded. The ref.pot file is the last created PO file with
       up-to-date source references but old translations, or a PO
       Template file (generally created by xgettext); any translations or
       comments in the file will be discarded, however dot comments and
       file positions will be preserved."
850,1,msgmerge,"The ref.pot file is the last created PO file with
       up-to-date source references but old translations, or a PO
       Template file (generally created by xgettext); any translations or
       comments in the file will be discarded, however dot comments and
       file positions will be preserved. Where an exact match cannot be
       found, fuzzy matching is used to produce better results. Mandatory arguments to long options are mandatory for short
       options too."
850,2,msgmerge,"Mandatory arguments to long options are mandatory for short
       options too. Input file location:
def.po translations referring to old sources

       ref.pot
              references to new sources
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search
-C
,
--compendium
=
FILE
additional library of message translations, may be
              specified more than once
Operation mode:
-U
,
--update
update def.po, do nothing if def.po already up to date
Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. Output file location in update mode: The result is written back to
       def.po."
850,3,msgmerge,"Output file location in update mode: The result is written back to
       def.po. --backup
=
CONTROL
make a backup of def.po
--suffix
=
SUFFIX
override the usual backup suffix

       The version control method may be selected via the
--backup
option
       or through the VERSION_CONTROL environment variable. Here are the
       values:

       none, off
              never make backups (even if
--backup
is given)

       numbered, t
              make numbered backups

       existing, nil
              numbered if numbered backups exist, simple otherwise

       simple, never
              always make simple backups

       The backup suffix is '~', unless set with
--suffix
or the
       SIMPLE_BACKUP_SUFFIX environment variable."
850,4,msgmerge,"Here are the
       values:

       none, off
              never make backups (even if
--backup
is given)

       numbered, t
              make numbered backups

       existing, nil
              numbered if numbered backups exist, simple otherwise

       simple, never
              always make simple backups

       The backup suffix is '~', unless set with
--suffix
or the
       SIMPLE_BACKUP_SUFFIX environment variable. Operation modifiers:
-m
,
--multi-domain
apply ref.pot to each of the domains in def.po
--for-msgfmt
produce output for 'msgfmt', not for a translator
-N
,
--no-fuzzy-matching
do not use fuzzy matching
--previous
keep previous msgids of translated messages
Input file syntax:
-P
,
--properties-input
input files are in Java .properties syntax
--stringtable-input
input files are in NeXTstep/GNUstep .strings syntax
Output details:
--lang
=
CATALOGNAME
set 'Language' field in the header entry
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'."
850,5,msgmerge,"Operation modifiers:
-m
,
--multi-domain
apply ref.pot to each of the domains in def.po
--for-msgfmt
produce output for 'msgfmt', not for a translator
-N
,
--no-fuzzy-matching
do not use fuzzy matching
--previous
keep previous msgids of translated messages
Input file syntax:
-P
,
--properties-input
input files are in Java .properties syntax
--stringtable-input
input files are in NeXTstep/GNUstep .strings syntax
Output details:
--lang
=
CATALOGNAME
set 'Language' field in the header entry
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-e
,
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
-i
,
--indent
indented output style
--no-location
suppress '#: filename:line' lines
-n
,
--add-location
preserve '#: filename:line' lines (default)
--strict
strict Uniforum output style
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output (deprecated)
-F
,
--sort-by-file
sort output by file location
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit
-v
,
--verbose
increase verbosity level
-q
,
--quiet
,
--silent
suppress progress indicators"
851,0,msginit,"Creates a new PO file, initializing the meta information with
       values from the user's environment. Mandatory arguments to long options are mandatory for short
       options too. Input file location:
-i
,
--input
=
INPUTFILE
input POT file

       If no input file is given, the current directory is searched for
       the POT file."
851,1,msginit,"Input file location:
-i
,
--input
=
INPUTFILE
input POT file

       If no input file is given, the current directory is searched for
       the POT file. If it is -, standard input is read. Output file location:
-o
,
--output-file
=
FILE
write output to specified PO file

       If no output file is given, it depends on the
--locale
option or
       the user's locale setting."
851,2,msginit,"Output file location:
-o
,
--output-file
=
FILE
write output to specified PO file

       If no output file is given, it depends on the
--locale
option or
       the user's locale setting. If it is -, the results are written to
       standard output. Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
-l
,
--locale
=
LL_CC[
.ENCODING]
              set target locale
--no-translator
assume the PO file is automatically generated
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN."
851,3,msginit,"Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
-l
,
--locale
=
LL_CC[
.ENCODING]
              set target locale
--no-translator
assume the PO file is automatically generated
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
852,0,msgunfmt,"Convert binary message catalog to Uniforum style .po file. Mandatory arguments to long options are mandatory for short
       options too. Operation mode:
-j
,
--java
Java mode: input is a Java ResourceBundle class
--csharp
C# mode: input is a .NET .dll file
--csharp-resources
C# resources mode: input is a .NET .resources file
--tcl
Tcl mode: input is a tcl/msgcat .msg file
Input file location:
FILE ..."
852,1,msgunfmt,"Operation mode:
-j
,
--java
Java mode: input is a Java ResourceBundle class
--csharp
C# mode: input is a .NET .dll file
--csharp-resources
C# resources mode: input is a .NET .resources file
--tcl
Tcl mode: input is a tcl/msgcat .msg file
Input file location:
FILE ... input .mo files

       If no input file is given or if it is -, standard input is read. Input file location in Java mode:
-r
,
--resource
=
RESOURCE
resource name
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY

       The class name is determined by appending the locale name to the
       resource name, separated with an underscore."
852,2,msgunfmt,"Input file location in Java mode:
-r
,
--resource
=
RESOURCE
resource name
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY

       The class name is determined by appending the locale name to the
       resource name, separated with an underscore. The class is located
       using the CLASSPATH. Input file location in C# mode:
-r
,
--resource
=
RESOURCE
resource name
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
-d
DIRECTORY
              base directory for locale dependent .dll files

       The
-l
and
-d
options are mandatory."
852,3,msgunfmt,"Input file location in C# mode:
-r
,
--resource
=
RESOURCE
resource name
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
-d
DIRECTORY
              base directory for locale dependent .dll files

       The
-l
and
-d
options are mandatory. The .dll file is located in
       a subdirectory of the specified directory whose name depends on
       the locale. Input file location in Tcl mode:
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
-d
DIRECTORY
              base directory of .msg message catalogs

       The
-l
and
-d
options are mandatory."
852,4,msgunfmt,"Input file location in Tcl mode:
-l
,
--locale
=
LOCALE
locale name, either language or language_COUNTRY
-d
DIRECTORY
              base directory of .msg message catalogs

       The
-l
and
-d
options are mandatory. The .msg file is located in
       the specified directory. Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -."
852,5,msgunfmt,"Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'."
852,6,msgunfmt,"Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-e
,
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
-i
,
--indent
write indented output style
--strict
write strict uniforum style
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit
-v
,
--verbose
increase verbosity level"
853,0,msguniq,"Unifies duplicate translations in a translation catalog. Finds
       duplicate translations of the same message ID. Such duplicates
       are invalid input for other programs like msgfmt, msgmerge or
       msgcat."
853,1,msguniq,"Such duplicates
       are invalid input for other programs like msgfmt, msgmerge or
       msgcat. By default, duplicates are merged together. When using
       the
--repeated
option, only duplicates are output, and all other
       messages are discarded."
853,2,msguniq,"When using
       the
--repeated
option, only duplicates are output, and all other
       messages are discarded. Comments and extracted comments will be
       cumulated, except that if
--use-first
is specified, they will be
       taken from the first translation. File positions will be
       cumulated."
853,3,msguniq,"File positions will be
       cumulated. When using the
--unique
option, duplicates are
       discarded. Mandatory arguments to long options are mandatory for short
       options too."
853,4,msguniq,"Mandatory arguments to long options are mandatory for short
       options too. Input file location:
INPUTFILE
              input PO file
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If no input file is given or if it is -, standard input is read. Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -."
853,5,msguniq,"Output file location:
-o
,
--output-file
=
FILE
write output to specified file

       The results are written to standard output if no output file is
       specified or if it is -. Message selection:
-d
,
--repeated
print only duplicates
-u
,
--unique
print only unique messages, discard duplicates
Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
-t
,
--to-code
=
NAME
encoding for output
--use-first
use first available translation for each message, don't
              merge several translations
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'."
853,6,msguniq,"Message selection:
-d
,
--repeated
print only duplicates
-u
,
--unique
print only unique messages, discard duplicates
Input file syntax:
-P
,
--properties-input
input file is in Java .properties syntax
--stringtable-input
input file is in NeXTstep/GNUstep .strings syntax
Output details:
-t
,
--to-code
=
NAME
encoding for output
--use-first
use first available translation for each message, don't
              merge several translations
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-e
,
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
-i
,
--indent
write the .po file using indented style
--no-location
do not write '#: filename:line' lines
-n
,
--add-location
generate '#: filename:line' lines (default)
--strict
write out strict Uniforum conforming .po file
-p
,
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output
-F
,
--sort-by-file
sort output by file location
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
854,0,ms_print,"ms_print
takes an output file produced by the Valgrind tool Massif
       and prints the information in an easy-to-read form."
855,0,msql2mysql,"Initially, the MySQL C API was developed to be very similar to
       that for the mSQL database system. Because of this, mSQL programs
       often can be converted relatively easily for use with MariaDB by
       changing the names of the C API functions. The
msql2mysql
utility performs the conversion of mSQL C API
       function calls to their MariaDB equivalents."
855,1,msql2mysql,"The
msql2mysql
utility performs the conversion of mSQL C API
       function calls to their MariaDB equivalents. msql2mysql
converts
       the input file in place, so make a copy of the original before
       converting it. For example, use
msql2mysql
like this:

           shell>
cp client-prog.c client-prog.c.orig
shell>
msql2mysql client-prog.c
client-prog.c converted

       Then examine client-prog.c and make any post-conversion revisions
       that may be necessary."
855,2,msql2mysql,"For example, use
msql2mysql
like this:

           shell>
cp client-prog.c client-prog.c.orig
shell>
msql2mysql client-prog.c
client-prog.c converted

       Then examine client-prog.c and make any post-conversion revisions
       that may be necessary. msql2mysql
uses the
replace
utility to make the function name
       substitutions. See
replace(1)
."
856,0,mtrace,"mtrace
is a Perl script used to interpret and provide human
       readable output of the trace log contained in the file
mtracedata
,
       whose contents were produced by
mtrace(3)
.  If
binary
is provided,
       the output of
mtrace
also contains the source file name with line
       number information for problem locations (assuming that
binary
was
       compiled with debugging information).

       For more information about the
mtrace(3)
function and
mtrace
script usage, see
mtrace(3)
."
857,0,mv,"Rename SOURCE to DEST, or move SOURCE(s) to DIRECTORY. Mandatory arguments to long options are mandatory for short
       options too. --backup
[=
CONTROL
]
              make a backup of each existing destination file
-b
like
--backup
but does not accept an argument
--debug
explain how a file is copied."
857,1,mv,"--backup
[=
CONTROL
]
              make a backup of each existing destination file
-b
like
--backup
but does not accept an argument
--debug
explain how a file is copied. Implies
-v
--exchange
exchange source and destination
-f
,
--force
do not prompt before overwriting
-i
,
--interactive
prompt before overwrite
-n
,
--no-clobber
do not overwrite an existing file

       If you specify more than one of
-i
,
-f
,
-n
, only the final one
       takes effect. --no-copy
do not copy if renaming fails
--strip-trailing-slashes
remove any trailing slashes from each SOURCE argument
-S
,
--suffix
=
SUFFIX
override the usual backup suffix
-t
,
--target-directory
=
DIRECTORY
move all SOURCE arguments into DIRECTORY
-T
,
--no-target-directory
treat DEST as a normal file
--update
[=
UPDATE
]
              control which existing files are updated;
              UPDATE={all,none,none-fail,older(default)}
-u
equivalent to
--update
[=
older
]."
857,2,mv,"--no-copy
do not copy if renaming fails
--strip-trailing-slashes
remove any trailing slashes from each SOURCE argument
-S
,
--suffix
=
SUFFIX
override the usual backup suffix
-t
,
--target-directory
=
DIRECTORY
move all SOURCE arguments into DIRECTORY
-T
,
--no-target-directory
treat DEST as a normal file
--update
[=
UPDATE
]
              control which existing files are updated;
              UPDATE={all,none,none-fail,older(default)}
-u
equivalent to
--update
[=
older
]. See below
-v
,
--verbose
explain what is being done
-Z
,
--context
set SELinux security context of destination file to default
              type
--help
display this help and exit
--version
output version information and exit

       UPDATE controls which existing files in the destination are
       replaced. 'all' is the default operation when an
--update
option
       is not specified, and results in all existing files in the
       destination being replaced."
857,3,mv,"'all' is the default operation when an
--update
option
       is not specified, and results in all existing files in the
       destination being replaced. 'none' is like the
--no-clobber
option, in that no files in the destination are replaced, and
       skipped files do not induce a failure. 'none-fail' also ensures
       no files are replaced in the destination, but any skipped files
       are diagnosed and induce a failure."
857,4,mv,"'none-fail' also ensures
       no files are replaced in the destination, but any skipped files
       are diagnosed and induce a failure. 'older' is the default
       operation when
--update
is specified, and results in files being
       replaced if they're older than the corresponding source file. The backup suffix is '~', unless set with
--suffix
or
       SIMPLE_BACKUP_SUFFIX."
857,5,mv,"The backup suffix is '~', unless set with
--suffix
or
       SIMPLE_BACKUP_SUFFIX. The version control method may be selected
       via the
--backup
option or through the VERSION_CONTROL environment
       variable. Here are the values:

       none, off
              never make backups (even if
--backup
is given)

       numbered, t
              make numbered backups

       existing, nil
              numbered if numbered backups exist, simple otherwise

       simple, never
              always make simple backups"
858,0,myisamlog,"myisamlog
processes the contents of a MyISAM log file. Invoke
myisamlog
like this:

           shell>
myisamlog [
options
] [
log_file
[
tbl_name
] ...]
shell>
isamlog [
options
] [
log_file
[
tbl_name
] ...]
The default operation is update (
-u
). If a recovery is done (
-r
),
       all writes and possibly updates and deletes are done and errors
       are only counted."
858,1,myisamlog,"If a recovery is done (
-r
),
       all writes and possibly updates and deletes are done and errors
       are only counted. The default log file name is myisam.log for
myisamlog
and isam.log for
isamlog
if no
log_file
argument is
       given. If tables are named on the command line, only those tables
       are updated."
858,2,myisamlog,"If tables are named on the command line, only those tables
       are updated. myisamlog
supports the following options:

       â¢
-? ,
-I
Display a help message and exit."
858,3,myisamlog,",
-I
Display a help message and exit. â¢
-c
N
Execute only
N
commands. â¢
-f
N
Specify the maximum number of open files."
858,4,myisamlog,"â¢
-f
N
Specify the maximum number of open files. â¢
-i
Display extra information before exiting. â¢
-o
offset
Specify the starting offset."
858,5,myisamlog,"â¢
-o
offset
Specify the starting offset. â¢
-p
N
Remove
N
components from path. â¢
-r
Perform a recovery operation."
858,6,myisamlog,"â¢
-r
Perform a recovery operation. â¢
-R
record_pos_file record_pos
Specify record position file and record position. â¢
-u
Perform an update operation."
858,7,myisamlog,"â¢
-u
Perform an update operation. â¢
-v
Verbose mode. Print more output about what the program does."
858,8,myisamlog,"Print more output about what the program does. This option can be given multiple times to produce more and
           more output. â¢
-w
write_file
Specify the write file."
858,9,myisamlog,"This option can be given multiple times to produce more and
           more output. â¢
-w
write_file
Specify the write file. â¢
-V
Display version information."
859,0,myisam_ftdump,"myisam_ftdump
displays information about FULLTEXT indexes in
       MyISAM tables. It reads the MyISAM index file directly, so it must
       be run on the server host where the table is located. Before using
myisam_ftdump
, be sure to issue a FLUSH TABLES statement first if
       the server is running."
859,1,myisam_ftdump,"Before using
myisam_ftdump
, be sure to issue a FLUSH TABLES statement first if
       the server is running. myisam_ftdump
scans and dumps the entire index, which is not
       particularly fast. On the other hand, the distribution of words
       changes infrequently, so it need not be run often."
859,2,myisam_ftdump,"On the other hand, the distribution of words
       changes infrequently, so it need not be run often. Invoke
myisam_ftdump
like this:

           shell>
myisam_ftdump [
options
]
tbl_name index_num
The
tbl_name
argument should be the name of a MyISAM table. You
       can also specify a table by naming its index file (the file with
       the .MYI suffix)."
859,3,myisam_ftdump,"You
       can also specify a table by naming its index file (the file with
       the .MYI suffix). If you do not invoke
myisam_ftdump
in the
       directory where the table files are located, the table or index
       file name must be preceded by the path name to the table's
       database directory. Index numbers begin with 0."
859,4,myisam_ftdump,"Index numbers begin with 0. Example: Suppose that the test database contains a table named
       mytexttablel that has the following definition:

           CREATE TABLE mytexttable
           (
             id   INT NOT NULL,
             txt  TEXT NOT NULL,
             PRIMARY KEY (id),
             FULLTEXT (txt)
           );

       The index on id is index 0 and the FULLTEXT index on txt is index
       1. If your working directory is the test database directory,
       invoke
myisam_ftdump
as follows:

           shell>
myisam_ftdump mytexttable 1
If the path name to the test database directory is
       /usr/local/mysql/data/test, you can also specify the table name
       argument using that path name."
859,5,myisam_ftdump,"If your working directory is the test database directory,
       invoke
myisam_ftdump
as follows:

           shell>
myisam_ftdump mytexttable 1
If the path name to the test database directory is
       /usr/local/mysql/data/test, you can also specify the table name
       argument using that path name. This is useful if you do not invoke
myisam_ftdump
in the database directory:

           shell>
myisam_ftdump /usr/local/mysql/data/test/mytexttable 1
You can use
myisam_ftdump
to generate a list of index entries in
       order of frequency of occurrence like this:

           shell>
myisam_ftdump -c mytexttable 1 | sort -r
myisam_ftdump
supports the following options:

       â¢
--help
,
-h -? Display a help message and exit."
859,6,myisam_ftdump,"Display a help message and exit. â¢
--count
,
-c
Calculate per-word statistics (counts and global weights). â¢
--dump
,
-d
Dump the index, including data offsets and word weights."
859,7,myisam_ftdump,"â¢
--dump
,
-d
Dump the index, including data offsets and word weights. â¢
--length
,
-l
Report the length distribution. â¢
--stats
,
-s
Report global index statistics."
859,8,myisam_ftdump,"â¢
--stats
,
-s
Report global index statistics. This is the default operation
           if no other operation is specified. â¢
--verbose
,
-v
Verbose mode."
859,9,myisam_ftdump,"This is the default operation
           if no other operation is specified. â¢
--verbose
,
-v
Verbose mode. Print more output about what the program does."
860,0,mv,"In the first synopsis form, the
mv
utility shall move the file
       named by the
source_file
operand to the destination specified by
       the
target_file
. This first synopsis form is assumed when the
       final operand does not name an existing directory and is not a
       symbolic link referring to an existing directory. In this case, if
source_file
names a non-directory file and
target_file
ends with a
       trailing <slash> character,
mv
shall treat this as an error and no
source_file
operands will be processed."
860,1,mv,"In this case, if
source_file
names a non-directory file and
target_file
ends with a
       trailing <slash> character,
mv
shall treat this as an error and no
source_file
operands will be processed. In the second synopsis form,
mv
shall move each file named by a
source_file
operand to a destination file in the existing
       directory named by the
target_dir
operand, or referenced if
target_dir
is a symbolic link referring to an existing directory. The destination path for each
source_file
shall be the
       concatenation of the target directory, a single <slash> character
       if the target did not end in a <slash>, and the last pathname
       component of the
source_file
."
860,2,mv,"The destination path for each
source_file
shall be the
       concatenation of the target directory, a single <slash> character
       if the target did not end in a <slash>, and the last pathname
       component of the
source_file
. This second form is assumed when
       the final operand names an existing directory. If any operand specifies an existing file of a type not specified
       by the System Interfaces volume of POSIX.1â2017, the behavior is
       implementation-defined."
860,3,mv,"If any operand specifies an existing file of a type not specified
       by the System Interfaces volume of POSIX.1â2017, the behavior is
       implementation-defined. For each
source_file
the following steps shall be taken:

        1. If the destination path exists, the
-f
option is not
           specified, and either of the following conditions is true:

            a."
860,4,mv,"If the destination path exists, the
-f
option is not
           specified, and either of the following conditions is true:

            a. The permissions of the destination path do not permit
               writing and the standard input is a terminal. b."
860,5,mv,"b. The
-i
option is specified. the
mv
utility shall write a prompt to standard error and read
           a line from standard input."
860,6,mv,"the
mv
utility shall write a prompt to standard error and read
           a line from standard input. If the response is not
           affirmative,
mv
shall do nothing more with the current
source_file
and go on to any remaining
source_file
s. 2."
860,7,mv,"2. If the
source_file
operand and destination path resolve to
           either the same existing directory entry or different
           directory entries for the same existing file, then the
           destination path shall not be removed, and one of the
           following shall occur:

            a. No change is made to
source_file
, no error occurs, and no
               diagnostic is issued."
860,8,mv,"No change is made to
source_file
, no error occurs, and no
               diagnostic is issued. b. No change is made to
source_file
, a diagnostic is issued
               to standard error identifying the two names, and the exit
               status is affected."
860,9,mv,"No change is made to
source_file
, a diagnostic is issued
               to standard error identifying the two names, and the exit
               status is affected. c. If the
source_file
operand and destination path name
               distinct directory entries, then the
source_file
operand
               is removed, no error occurs, and no diagnostic is issued."
860,10,mv,"If the
source_file
operand and destination path name
               distinct directory entries, then the
source_file
operand
               is removed, no error occurs, and no diagnostic is issued. The
mv
utility shall do nothing more with the current
source_file
, and go on to any remaining
source_file
s. 3."
860,11,mv,"3. The
mv
utility shall perform actions equivalent to the
rename
() function defined in the System Interfaces volume of
           POSIX.1â2017, called with the following arguments:

            a. The
source_file
operand is used as the
old
argument."
860,12,mv,"The
source_file
operand is used as the
old
argument. b. The destination path is used as the
new
argument."
860,13,mv,"The destination path is used as the
new
argument. If this succeeds,
mv
shall do nothing more with the current
source_file
and go on to any remaining
source_file
s. If this
           fails for any reasons other than those described for the
errno
[EXDEV]
in the System Interfaces volume of POSIX.1â2017,
mv
shall write a diagnostic message to standard error, do nothing
           more with the current
source_file
, and go on to any remaining
source_file
s."
860,14,mv,"If this
           fails for any reasons other than those described for the
errno
[EXDEV]
in the System Interfaces volume of POSIX.1â2017,
mv
shall write a diagnostic message to standard error, do nothing
           more with the current
source_file
, and go on to any remaining
source_file
s. 4. If the destination path exists, and it is a file of type
           directory and
source_file
is not a file of type directory, or
           it is a file not of type directory and
source_file
is a file
           of type directory,
mv
shall write a diagnostic message to
           standard error, do nothing more with the current
source_file
,
           and go on to any remaining
source_file
s."
860,15,mv,"If the destination path exists, and it is a file of type
           directory and
source_file
is not a file of type directory, or
           it is a file not of type directory and
source_file
is a file
           of type directory,
mv
shall write a diagnostic message to
           standard error, do nothing more with the current
source_file
,
           and go on to any remaining
source_file
s. If the destination
           path exists and was created by a previous step, it is
           unspecified whether this will treated as an error or the
           destination path will be overwritten. 5."
860,16,mv,"5. If the destination path exists,
mv
shall attempt to remove it. If this fails for any reason,
mv
shall write a diagnostic
           message to standard error, do nothing more with the current
source_file
, and go on to any remaining
source_file
s."
860,17,mv,"If this fails for any reason,
mv
shall write a diagnostic
           message to standard error, do nothing more with the current
source_file
, and go on to any remaining
source_file
s. 6. The file hierarchy rooted in
source_file
shall be duplicated
           as a file hierarchy rooted in the destination path."
860,18,mv,"The file hierarchy rooted in
source_file
shall be duplicated
           as a file hierarchy rooted in the destination path. If
source_file
or any of the files below it in the hierarchy are
           symbolic links, the links themselves shall be duplicated,
           including their contents, rather than any files to which they
           refer. The following characteristics of each file in the file
           hierarchy shall be duplicated:

            *  The time of last data modification and time of last access

            *  The user ID and group ID

            *  The file mode

           If the user ID, group ID, or file mode of a regular file
           cannot be duplicated, the file mode bits S_ISUID and S_ISGID
           shall not be duplicated."
860,19,mv,"The following characteristics of each file in the file
           hierarchy shall be duplicated:

            *  The time of last data modification and time of last access

            *  The user ID and group ID

            *  The file mode

           If the user ID, group ID, or file mode of a regular file
           cannot be duplicated, the file mode bits S_ISUID and S_ISGID
           shall not be duplicated. When files are duplicated to another file system, the
           implementation may require that the process invoking
mv
has
           read access to each file being duplicated. If files being duplicated to another file system have hard
           links to other files, it is unspecified whether the files
           copied to the new file system have the hard links preserved or
           separate copies are created for the linked files."
860,20,mv,"If files being duplicated to another file system have hard
           links to other files, it is unspecified whether the files
           copied to the new file system have the hard links preserved or
           separate copies are created for the linked files. If the duplication of the file hierarchy fails for any reason,
mv
shall write a diagnostic message to standard error, do
           nothing more with the current
source_file
, and go on to any
           remaining
source_file
s. If the duplication of the file characteristics fails for any
           reason,
mv
shall write a diagnostic message to standard error,
           but this failure shall not cause
mv
to modify its exit status."
860,21,mv,"If the duplication of the file characteristics fails for any
           reason,
mv
shall write a diagnostic message to standard error,
           but this failure shall not cause
mv
to modify its exit status. 7. The file hierarchy rooted in
source_file
shall be removed."
860,22,mv,"7. The file hierarchy rooted in
source_file
shall be removed. If
           this fails for any reason,
mv
shall write a diagnostic message
           to the standard error, do nothing more with the current
source_file
, and go on to any remaining
source_file
s."
861,0,myisampack,"The
myisampack
utility compresses MyISAM tables. myisampack
works
       by compressing each column in the table separately. Usually,
myisampack
packs the data file 40%â70%."
861,1,myisampack,"Usually,
myisampack
packs the data file 40%â70%. When the table is used later, the server reads into memory the
       information needed to decompress columns. This results in much
       better performance when accessing individual rows, because you
       only have to uncompress exactly one row."
861,2,myisampack,"This results in much
       better performance when accessing individual rows, because you
       only have to uncompress exactly one row. MariaDB uses mmap() when possible to perform memory mapping on
       compressed tables. If mmap() does not work, MariaDB falls back to
       normal read/write file operations."
861,3,myisampack,"If mmap() does not work, MariaDB falls back to
       normal read/write file operations. Please note the following:

       â¢   If the
mariadbd
server was invoked with external locking
           disabled, it is not a good idea to invoke
myisampack
if the
           table might be updated by the server during the packing
           process. It is safest to compress tables with the server
           stopped."
861,4,myisampack,"It is safest to compress tables with the server
           stopped. â¢   After packing a table, it becomes read only. This is generally
           intended (such as when accessing packed tables on a CD)."
861,5,myisampack,"This is generally
           intended (such as when accessing packed tables on a CD). Invoke
myisampack
like this:

           shell>
myisampack [
options
]
file_name
... Each file name argument should be the name of an index (.MYI)
       file."
861,6,myisampack,"Each file name argument should be the name of an index (.MYI)
       file. If you are not in the database directory, you should specify
       the path name to the file. It is permissible to omit the .MYI
       extension."
861,7,myisampack,"It is permissible to omit the .MYI
       extension. After you compress a table with
myisampack
, you should use
myisamchk -rq
to rebuild its indexes. myisamchk(1)
."
861,8,myisampack,"myisamchk(1)
. myisampack
supports the following options. It also reads option
       files and supports the options for processing them described at
       Section 4.2.3.3.1, âCommand-Line Options that Affect Option-File
       Handlingâ."
861,9,myisampack,"It also reads option
       files and supports the options for processing them described at
       Section 4.2.3.3.1, âCommand-Line Options that Affect Option-File
       Handlingâ. â¢
--help
,
-? Display a help message and exit."
861,10,myisampack,"Display a help message and exit. â¢
--backup
,
-b
Make a backup of each table's data file using the name
tbl_name
.OLD. â¢
--character-sets-dir=
path
The directory where character sets are installed."
861,11,myisampack,"â¢
--character-sets-dir=
path
The directory where character sets are installed. See
           Section 9.5, âCharacter Set Configurationâ. â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log."
861,12,myisampack,"â¢
--debug[=
debug_options
]
,
-# [
debug_options
]
Write a debugging log. A typical
debug_options
string is
           'd:t:o,
file_name
'. The default is 'd:t:o'."
861,13,myisampack,"The default is 'd:t:o'. â¢
--force
,
-f
Produce a packed table even if it becomes larger than the
           original or if the intermediate file from an earlier
           invocation of
myisampack
exists. (
myisampack
creates an
           intermediate file named
tbl_name
.TMD in the database directory
           while it compresses the table."
861,14,myisampack,"(
myisampack
creates an
           intermediate file named
tbl_name
.TMD in the database directory
           while it compresses the table. If you kill
myisampack
, the
           .TMD file might not be deleted.) Normally,
myisampack
exits
           with an error if it finds that
tbl_name
.TMD exists. With
--force
,
myisampack
packs the table anyway."
861,15,myisampack,"With
--force
,
myisampack
packs the table anyway. â¢
--join=
big_tbl_name
,
-j
big_tbl_name
Join all tables named on the command line into a single packed
           table
big_tbl_name
. All tables that are to be combined
must
have identical structure (same column names and types, same
           indexes, and so forth)."
861,16,myisampack,"All tables that are to be combined
must
have identical structure (same column names and types, same
           indexes, and so forth). big_tbl_name
must not exist prior to the join operation. All
           source tables named on the command line to be merged into
big_tbl_name
must exist."
861,17,myisampack,"All
           source tables named on the command line to be merged into
big_tbl_name
must exist. The source tables are read for the
           join operation but not modified. The join operation does not
           create a .frm file for
big_tbl_name
, so after the join
           operation finishes, copy the .frm file from one of the source
           tables and name it
big_tbl_name
.frm."
861,18,myisampack,"The join operation does not
           create a .frm file for
big_tbl_name
, so after the join
           operation finishes, copy the .frm file from one of the source
           tables and name it
big_tbl_name
.frm. â¢
--silent
,
-s
Silent mode. Write output only when errors occur."
861,19,myisampack,"Write output only when errors occur. â¢
--test
,
-t
Do not actually pack the table, just test packing it. â¢
--tmpdir=
path
,
-T
path
Use the named directory as the location where
myisampack
creates temporary files."
861,20,myisampack,"â¢
--tmpdir=
path
,
-T
path
Use the named directory as the location where
myisampack
creates temporary files. â¢
--verbose
,
-v
Verbose mode. Write information about the progress of the
           packing operation and its result."
861,21,myisampack,"Write information about the progress of the
           packing operation and its result. â¢
--version
,
-V
Display version information and exit. â¢
--wait
,
-w
Wait and retry if the table is in use."
861,22,myisampack,"â¢
--wait
,
-w
Wait and retry if the table is in use. If the
mariadbd
server
           was invoked with external locking disabled, it is not a good
           idea to invoke
myisampack
if the table might be updated by the
           server during the packing process. The following sequence of commands illustrates a typical table
       compression session:

           shell>
ls -l station.*
-rw-rw-r--   1 monty    my         994128 Apr 17 19:00 station.MYD
           -rw-rw-r--   1 monty    my          53248 Apr 17 19:00 station.MYI
           -rw-rw-r--   1 monty    my           5767 Apr 17 19:00 station.frm
           shell>
myisamchk -dvv station
MyISAM file:     station
           Isam-version:  2
           Creation time: 1996-03-13 10:08:58
           Recover time:  1997-02-02  3:06:43
           Data records:              1192  Deleted blocks:              0
           Datafile parts:            1192  Deleted data:                0
           Datafile pointer (bytes):     2  Keyfile pointer (bytes):     2
           Max datafile length:   54657023  Max keyfile length:   33554431
           Recordlength:               834
           Record format: Fixed length
           table description:
           Key Start Len Index   Type                 Root  Blocksize    Rec/key
           1   2     4   unique  unsigned long        1024       1024          1
           2   32    30  multip."
861,23,myisampack,"The following sequence of commands illustrates a typical table
       compression session:

           shell>
ls -l station.*
-rw-rw-r--   1 monty    my         994128 Apr 17 19:00 station.MYD
           -rw-rw-r--   1 monty    my          53248 Apr 17 19:00 station.MYI
           -rw-rw-r--   1 monty    my           5767 Apr 17 19:00 station.frm
           shell>
myisamchk -dvv station
MyISAM file:     station
           Isam-version:  2
           Creation time: 1996-03-13 10:08:58
           Recover time:  1997-02-02  3:06:43
           Data records:              1192  Deleted blocks:              0
           Datafile parts:            1192  Deleted data:                0
           Datafile pointer (bytes):     2  Keyfile pointer (bytes):     2
           Max datafile length:   54657023  Max keyfile length:   33554431
           Recordlength:               834
           Record format: Fixed length
           table description:
           Key Start Len Index   Type                 Root  Blocksize    Rec/key
           1   2     4   unique  unsigned long        1024       1024          1
           2   32    30  multip. text                10240       1024          1
           Field Start Length Type
           1     1     1
           2     2     4
           3     6     4
           4     10    1
           5     11    20
           6     31    1
           7     32    30
           8     62    35
           9     97    35
           10    132   35
           11    167   4
           12    171   16
           13    187   35
           14    222   4
           15    226   16
           16    242   20
           17    262   20
           18    282   20
           19    302   30
           20    332   4
           21    336   4
           22    340   1
           23    341   8
           24    349   8
           25    357   8
           26    365   2
           27    367   2
           28    369   4
           29    373   4
           30    377   1
           31    378   2
           32    380   8
           33    388   4
           34    392   4
           35    396   4
           36    400   4
           37    404   1
           38    405   4
           39    409   4
           40    413   4
           41    417   4
           42    421   4
           43    425   4
           44    429   20
           45    449   30
           46    479   1
           47    480   1
           48    481   79
           49    560   79
           50    639   79
           51    718   79
           52    797   8
           53    805   1
           54    806   1
           55    807   20
           56    827   4
           57    831   4
           shell>
myisampack station.MYI
Compressing station.MYI: (1192 records)
           - Calculating statistics
           normal:     20  empty-space:   16  empty-zero:     12  empty-fill:  11
           pre-space:   0  end-space:     12  table-lookups:   5  zero:         7
           Original trees:  57  After join: 17
           - Compressing file
           87.14%
           Remember to run myisamchk -rq on compressed tables
           shell>
ls -l station.*
-rw-rw-r--   1 monty    my         127874 Apr 17 19:00 station.MYD
           -rw-rw-r--   1 monty    my          55296 Apr 17 19:04 station.MYI
           -rw-rw-r--   1 monty    my           5767 Apr 17 19:00 station.frm
           shell>
myisamchk -dvv station
MyISAM file:     station
           Isam-version:  2
           Creation time: 1996-03-13 10:08:58
           Recover time:  1997-04-17 19:04:26
           Data records:               1192  Deleted blocks:              0
           Datafile parts:             1192  Deleted data:                0
           Datafile pointer (bytes):      3  Keyfile pointer (bytes):     1
           Max datafile length:    16777215  Max keyfile length:     131071
           Recordlength:                834
           Record format: Compressed
           table description:
           Key Start Len Index   Type                 Root  Blocksize    Rec/key
           1   2     4   unique  unsigned long       10240       1024          1
           2   32    30  multip. text                54272       1024          1
           Field Start Length Type                         Huff tree  Bits
           1     1     1      constant                             1     0
           2     2     4      zerofill(1)                          2     9
           3     6     4      no zeros, zerofill(1)                2     9
           4     10    1                                           3     9
           5     11    20     table-lookup                         4     0
           6     31    1                                           3     9
           7     32    30     no endspace, not_always              5     9
           8     62    35     no endspace, not_always, no empty    6     9
           9     97    35     no empty                             7     9
           10    132   35     no endspace, not_always, no empty    6     9
           11    167   4      zerofill(1)                          2     9
           12    171   16     no endspace, not_always, no empty    5     9
           13    187   35     no endspace, not_always, no empty    6     9
           14    222   4      zerofill(1)                          2     9
           15    226   16     no endspace, not_always, no empty    5     9
           16    242   20     no endspace, not_always              8     9
           17    262   20     no endspace, no empty                8     9
           18    282   20     no endspace, no empty                5     9
           19    302   30     no endspace, no empty                6     9
           20    332   4      always zero                          2     9
           21    336   4      always zero                          2     9
           22    340   1                                           3     9
           23    341   8      table-lookup                         9     0
           24    349   8      table-lookup                        10     0
           25    357   8      always zero                          2     9
           26    365   2                                           2     9
           27    367   2      no zeros, zerofill(1)                2     9
           28    369   4      no zeros, zerofill(1)                2     9
           29    373   4      table-lookup                        11     0
           30    377   1                                           3     9
           31    378   2      no zeros, zerofill(1)                2     9
           32    380   8      no zeros                             2     9
           33    388   4      always zero                          2     9
           34    392   4      table-lookup                        12     0
           35    396   4      no zeros, zerofill(1)               13     9
           36    400   4      no zeros, zerofill(1)                2     9
           37    404   1                                           2     9
           38    405   4      no zeros                             2     9
           39    409   4      always zero                          2     9
           40    413   4      no zeros                             2     9
           41    417   4      always zero                          2     9
           42    421   4      no zeros                             2     9
           43    425   4      always zero                          2     9
           44    429   20     no empty                             3     9
           45    449   30     no empty                             3     9
           46    479   1                                          14     4
           47    480   1                                          14     4
           48    481   79     no endspace, no empty               15     9
           49    560   79     no empty                             2     9
           50    639   79     no empty                             2     9
           51    718   79     no endspace                         16     9
           52    797   8      no empty                             2     9
           53    805   1                                          17     1
           54    806   1                                           3     9
           55    807   20     no empty                             3     9
           56    827   4      no zeros, zerofill(2)                2     9
           57    831   4      no zeros, zerofill(1)                2     9
myisampack
displays the following kinds of information:

       â¢   normal

           The number of columns for which no extra packing is used."
861,24,myisampack,"text                54272       1024          1
           Field Start Length Type                         Huff tree  Bits
           1     1     1      constant                             1     0
           2     2     4      zerofill(1)                          2     9
           3     6     4      no zeros, zerofill(1)                2     9
           4     10    1                                           3     9
           5     11    20     table-lookup                         4     0
           6     31    1                                           3     9
           7     32    30     no endspace, not_always              5     9
           8     62    35     no endspace, not_always, no empty    6     9
           9     97    35     no empty                             7     9
           10    132   35     no endspace, not_always, no empty    6     9
           11    167   4      zerofill(1)                          2     9
           12    171   16     no endspace, not_always, no empty    5     9
           13    187   35     no endspace, not_always, no empty    6     9
           14    222   4      zerofill(1)                          2     9
           15    226   16     no endspace, not_always, no empty    5     9
           16    242   20     no endspace, not_always              8     9
           17    262   20     no endspace, no empty                8     9
           18    282   20     no endspace, no empty                5     9
           19    302   30     no endspace, no empty                6     9
           20    332   4      always zero                          2     9
           21    336   4      always zero                          2     9
           22    340   1                                           3     9
           23    341   8      table-lookup                         9     0
           24    349   8      table-lookup                        10     0
           25    357   8      always zero                          2     9
           26    365   2                                           2     9
           27    367   2      no zeros, zerofill(1)                2     9
           28    369   4      no zeros, zerofill(1)                2     9
           29    373   4      table-lookup                        11     0
           30    377   1                                           3     9
           31    378   2      no zeros, zerofill(1)                2     9
           32    380   8      no zeros                             2     9
           33    388   4      always zero                          2     9
           34    392   4      table-lookup                        12     0
           35    396   4      no zeros, zerofill(1)               13     9
           36    400   4      no zeros, zerofill(1)                2     9
           37    404   1                                           2     9
           38    405   4      no zeros                             2     9
           39    409   4      always zero                          2     9
           40    413   4      no zeros                             2     9
           41    417   4      always zero                          2     9
           42    421   4      no zeros                             2     9
           43    425   4      always zero                          2     9
           44    429   20     no empty                             3     9
           45    449   30     no empty                             3     9
           46    479   1                                          14     4
           47    480   1                                          14     4
           48    481   79     no endspace, no empty               15     9
           49    560   79     no empty                             2     9
           50    639   79     no empty                             2     9
           51    718   79     no endspace                         16     9
           52    797   8      no empty                             2     9
           53    805   1                                          17     1
           54    806   1                                           3     9
           55    807   20     no empty                             3     9
           56    827   4      no zeros, zerofill(2)                2     9
           57    831   4      no zeros, zerofill(1)                2     9
myisampack
displays the following kinds of information:

       â¢   normal

           The number of columns for which no extra packing is used. â¢   empty-space

           The number of columns containing values that are only spaces. These occupy one bit."
861,25,myisampack,"These occupy one bit. â¢   empty-zero

           The number of columns containing values that are only binary
           zeros. These occupy one bit."
861,26,myisampack,"These occupy one bit. â¢   empty-fill

           The number of integer columns that do not occupy the full byte
           range of their type. These are changed to a smaller type."
861,27,myisampack,"These are changed to a smaller type. For
           example, a BIGINT column (eight bytes) can be stored as a
           TINYINT column (one byte) if all its values are in the range
           from -128 to 127. â¢   pre-space

           The number of decimal columns that are stored with leading
           spaces."
861,28,myisampack,"â¢   pre-space

           The number of decimal columns that are stored with leading
           spaces. In this case, each value contains a count for the
           number of leading spaces. â¢   end-space

           The number of columns that have a lot of trailing spaces."
861,29,myisampack,"â¢   end-space

           The number of columns that have a lot of trailing spaces. In
           this case, each value contains a count for the number of
           trailing spaces. â¢   table-lookup

           The column had only a small number of different values, which
           were converted to an ENUM before Huffman compression."
861,30,myisampack,"â¢   table-lookup

           The column had only a small number of different values, which
           were converted to an ENUM before Huffman compression. â¢   zero

           The number of columns for which all values are zero. â¢   Original trees

           The initial number of Huffman trees."
861,31,myisampack,"â¢   Original trees

           The initial number of Huffman trees. â¢   After join

           The number of distinct Huffman trees left after joining trees
           to save some header space. After a table has been compressed, the Field lines displayed by
myisamchk -dvv
include additional information about each column:

       â¢   Type

           The data type."
861,32,myisampack,"After a table has been compressed, the Field lines displayed by
myisamchk -dvv
include additional information about each column:

       â¢   Type

           The data type. The value may contain any of the following
           descriptors:

           â¢   constant

               All rows have the same value. â¢   no endspace

               Do not store endspace."
861,33,myisampack,"â¢   no endspace

               Do not store endspace. â¢   no endspace, not_always

               Do not store endspace and do not do endspace compression
               for all values. â¢   no endspace, no empty

               Do not store endspace."
861,34,myisampack,"â¢   no endspace, no empty

               Do not store endspace. Do not store empty values. â¢   table-lookup

               The column was converted to an ENUM."
861,35,myisampack,"â¢   table-lookup

               The column was converted to an ENUM. â¢   zerofill(
N
)

               The most significant
N
bytes in the value are always 0 and
               are not stored. â¢   no zeros

               Do not store zeros."
861,36,myisampack,"â¢   no zeros

               Do not store zeros. â¢   always zero

               Zero values are stored using one bit. â¢   Huff tree

           The number of the Huffman tree associated with the column."
861,37,myisampack,"â¢   Huff tree

           The number of the Huffman tree associated with the column. â¢   Bits

           The number of bits used in the Huffman tree. After you run
myisampack
, you must run
myisamchk
to re-create any
       indexes."
861,38,myisampack,"After you run
myisampack
, you must run
myisamchk
to re-create any
       indexes. At this time, you can also sort the index blocks and
       create statistics needed for the MariaDB optimizer to work more
       efficiently:

           shell>
myisamchk -rq --sort-index --analyze
tbl_name
.MYI
After you have installed the packed table into the MariaDB
       database directory, you should execute
mariadb-admin flush-tables
to force
mariadbd
to start using the new table. To unpack a packed table, use the
--unpack
option to
myisamchk
."
862,0,my_print_defaults,"my_print_defaults
displays the options that are present in option
       groups of option files. The output indicates what options will be
       used by programs that read the specified option groups. For
       example, the
mariadb-check
program reads the [mariadb-check] and
       [client] option groups."
862,1,my_print_defaults,"For
       example, the
mariadb-check
program reads the [mariadb-check] and
       [client] option groups. To see what options are present in those
       groups in the standard option files, invoke
my_print_defaults
like
       this:

           shell>
my_print_defaults mariadb-check client
--user=myusername
           --password=secret
           --host=localhost

       The output consists of options, one per line, in the form that
       they would be specified on the command line. my_print_defaults
supports the following options."
862,2,my_print_defaults,"my_print_defaults
supports the following options. â¢
--help
,
-? Display a help message and exit."
862,3,my_print_defaults,"Display a help message and exit. â¢
--defaults-file=
file_name
,
-c
file_name
Read only the given option file. If no extension is given,
           default extension(.ini or .cnf) will be used."
862,4,my_print_defaults,"If no extension is given,
           default extension(.ini or .cnf) will be used. If
--defaults-file
is the first option, then read this file only,
           do not read global or per-user config files; should be the
           first option. â¢
--debug=
debug_options
,
-#
debug_options
Write a debugging log."
862,5,my_print_defaults,"â¢
--debug=
debug_options
,
-#
debug_options
Write a debugging log. A typical
debug_options
string is
           'd:t:o,
file_name
'. The default is
           'd:t:o,/tmp/my_print_defaults.trace'."
862,6,my_print_defaults,"The default is
           'd:t:o,/tmp/my_print_defaults.trace'. â¢
--defaults-extra-file=
file_name
,
-e
file_name
Read this option file after the global option file but (on
           Unix) before the user option file. Should be the first option."
862,7,my_print_defaults,"Should be the first option. â¢
--defaults-group-suffix=
suffix
,
-g
suffix
In addition to the groups named on the command line, read
           groups that have the given suffix. â¢
--mariadbd
Read the same set of groups that the mariadbd binary does."
862,8,my_print_defaults,"â¢
--mariadbd
Read the same set of groups that the mariadbd binary does. â¢
--mariadbd
Read the same set of groups that the mariadbd binary does. â¢
--no-defaults
,
-n
Return an empty string (useful for scripts)."
862,9,my_print_defaults,"â¢
--no-defaults
,
-n
Return an empty string (useful for scripts). â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does."
862,10,my_print_defaults,"â¢
--verbose
,
-v
Verbose mode. Print more information about what the program
           does. â¢
--version
,
-V
Display version information and exit."
863,0,myisamchk,"The
myisamchk
utility gets information about your database tables
       or checks, repairs, or optimizes them. myisamchk
works with
       MyISAM tables (tables that have .MYD and .MYI files for storing
       data and indexes). The use of
myisamchk
with partitioned tables is not supported."
863,1,myisamchk,"The use of
myisamchk
with partitioned tables is not supported. Caution
It is best to make a backup of a table before performing a
           table repair operation; under some circumstances the operation
           might cause data loss. Possible causes include but are not
           limited to file system errors."
863,2,myisamchk,"Possible causes include but are not
           limited to file system errors. Invoke
myisamchk
like this:

           shell>
myisamchk [
options
]
tbl_name
... The
options
specify what you want
myisamchk
to do."
863,3,myisamchk,"The
options
specify what you want
myisamchk
to do. They are
       described in the following sections. You can also get a list of
       options by invoking
myisamchk --help
."
863,4,myisamchk,"You can also get a list of
       options by invoking
myisamchk --help
. With no options,
myisamchk
simply checks your table as the default
       operation. To get more information or to tell
myisamchk
to take
       corrective action, specify options as described in the following
       discussion."
863,5,myisamchk,"To get more information or to tell
myisamchk
to take
       corrective action, specify options as described in the following
       discussion. tbl_name
is the database table you want to check or repair. If you
       run
myisamchk
somewhere other than in the database directory, you
       must specify the path to the database directory, because
myisamchk
has no idea where the database is located."
863,6,myisamchk,"If you
       run
myisamchk
somewhere other than in the database directory, you
       must specify the path to the database directory, because
myisamchk
has no idea where the database is located. In fact,
myisamchk
does
       not actually care whether the files you are working on are located
       in a database directory. You can copy the files that correspond to
       a database table into some other location and perform recovery
       operations on them there."
863,7,myisamchk,"You can copy the files that correspond to
       a database table into some other location and perform recovery
       operations on them there. You can name several tables on the
myisamchk
command line if you
       wish. You can also specify a table by naming its index file (the
       file with the .MYI suffix)."
863,8,myisamchk,"You can also specify a table by naming its index file (the
       file with the .MYI suffix). This allows you to specify all tables
       in a directory by using the pattern *.MYI. For example, if you are
       in a database directory, you can check all the MyISAM tables in
       that directory like this:

           shell>
myisamchk *.MYI
If you are not in the database directory, you can check all the
       tables there by specifying the path to the directory:

           shell>
myisamchk
/path/to/database_dir/
*.MYI
You can even check all tables in all databases by specifying a
       wildcard with the path to the MariaDB data directory:

           shell>
myisamchk
/path/to/datadir/*/*
.MYI
The recommended way to quickly check all MyISAM tables is:

           shell>
myisamchk --silent --fast
/path/to/datadir/*/*
.MYI
If you want to check all MyISAM tables and repair any that are
       corrupted, you can use the following command:

           shell>
myisamchk --silent --force --fast --update-state \
--key_buffer_size=64M --sort_buffer_size=64M \
--read_buffer_size=1M --write_buffer_size=1M \
/path/to/datadir/*/*
.MYI
This command assumes that you have more than 64MB free."
863,9,myisamchk,"For example, if you are
       in a database directory, you can check all the MyISAM tables in
       that directory like this:

           shell>
myisamchk *.MYI
If you are not in the database directory, you can check all the
       tables there by specifying the path to the directory:

           shell>
myisamchk
/path/to/database_dir/
*.MYI
You can even check all tables in all databases by specifying a
       wildcard with the path to the MariaDB data directory:

           shell>
myisamchk
/path/to/datadir/*/*
.MYI
The recommended way to quickly check all MyISAM tables is:

           shell>
myisamchk --silent --fast
/path/to/datadir/*/*
.MYI
If you want to check all MyISAM tables and repair any that are
       corrupted, you can use the following command:

           shell>
myisamchk --silent --force --fast --update-state \
--key_buffer_size=64M --sort_buffer_size=64M \
--read_buffer_size=1M --write_buffer_size=1M \
/path/to/datadir/*/*
.MYI
This command assumes that you have more than 64MB free. For more
       information about memory allocation with
myisamchk
, see the
       section called âMYISAMCHK MEMORY USAGEâ. Important
You must ensure that no other program is using the tables
while you are running
myisamchk
."
863,10,myisamchk,"Important
You must ensure that no other program is using the tables
while you are running
myisamchk
. The most effective means of
           doing so is to shut down the MariaDB server while running
myisamchk
, or to lock all tables that
myisamchk
is being used
           on. Otherwise, when you run
myisamchk
, it may display the
           following error message:

               warning: clients are using or haven't closed the table properly

           This means that you are trying to check a table that has been
           updated by another program (such as the
mariadbd
server) that
           hasn't yet closed the file or that has died without closing
           the file properly, which can sometimes lead to the corruption
           of one or more MyISAM tables."
863,11,myisamchk,"Otherwise, when you run
myisamchk
, it may display the
           following error message:

               warning: clients are using or haven't closed the table properly

           This means that you are trying to check a table that has been
           updated by another program (such as the
mariadbd
server) that
           hasn't yet closed the file or that has died without closing
           the file properly, which can sometimes lead to the corruption
           of one or more MyISAM tables. If
mariadbd
is running, you must force it to flush any table
           modifications that are still buffered in memory by using FLUSH
           TABLES. You should then ensure that no one is using the tables
           while you are running
myisamchk
However, the easiest way to avoid this problem is to use CHECK
           TABLE instead of
myisamchk
to check tables."
863,12,myisamchk,"If
mariadbd
is running, you must force it to flush any table
           modifications that are still buffered in memory by using FLUSH
           TABLES. You should then ensure that no one is using the tables
           while you are running
myisamchk
However, the easiest way to avoid this problem is to use CHECK
           TABLE instead of
myisamchk
to check tables. myisamchk
supports the following options, which can be specified
       on the command line or in the [myisamchk] option file group."
864,0,my_safe_process,"Use: safe_process [options to safe_process] -- progname arg1 ...
       argn.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
865,0,mysql.server,"MariaDB distributions on Unix include a script named
mysql.server
. It can be used on systems such as Linux and Solaris that use
       System V-style run directories to start and stop system services. It is also used by the Mac OS X Startup Item for MariaDB."
865,1,mysql.server,"It is also used by the Mac OS X Startup Item for MariaDB. mysql.server
can be found in the support-files directory under
       your MariaDB installation directory or in a MariaDB source
       distribution. If you use the Linux server RPM package
       (MySQL-server-
VERSION
.rpm), the
mysql.server
script will be
       installed in the /etc/init.d directory with the name mysql."
865,2,mysql.server,"If you use the Linux server RPM package
       (MySQL-server-
VERSION
.rpm), the
mysql.server
script will be
       installed in the /etc/init.d directory with the name mysql. You
       need not install it manually. Some vendors provide RPM packages that install a startup script
       under a different name such as
mariadbd
."
865,3,mysql.server,"Some vendors provide RPM packages that install a startup script
       under a different name such as
mariadbd
. If you install MariaDB from a source distribution or using a
       binary distribution format that does not install
mysql.server
automatically, you can install it manually. mysql.server
reads options from the [mysql.server] and [mariadbd]
       sections of option files."
865,4,mysql.server,"mysql.server
reads options from the [mysql.server] and [mariadbd]
       sections of option files. For backward compatibility, it also
       reads [mysql_server] sections, although you should rename such
       sections to [mysql.server]&. mysql.server
supports the following options."
865,5,mysql.server,"mysql.server
supports the following options. â¢
--basedir=
path
The path to the MariaDB installation directory. â¢
--datadir=
path
The path to the MariaDB data directory."
865,6,mysql.server,"â¢
--datadir=
path
The path to the MariaDB data directory. â¢
--pid-file=
file_name
The path name of the file in which the server should write its
           process ID. If not provided, the default, ""host_name.pid"" is
           used."
865,7,mysql.server,"If not provided, the default, ""host_name.pid"" is
           used. â¢
--service-startup-timeout=
file_name
How long in seconds to wait for confirmation of server
           startup. If the server does not start within this time,
mysql.server
exits with an error."
865,8,mysql.server,"If the server does not start within this time,
mysql.server
exits with an error. The default value is 900. A
           value of 0 means not to wait at all for startup."
865,9,mysql.server,"A
           value of 0 means not to wait at all for startup. Negative
           values mean to wait forever (no timeout). â¢
--use-mariadbd_safe
Use
mariadbd_safe
to start the server."
865,10,mysql.server,"â¢
--use-mariadbd_safe
Use
mariadbd_safe
to start the server. This is the default. â¢
--use-manager
Use Instance Manager to start the server."
865,11,mysql.server,"This is the default. â¢
--use-manager
Use Instance Manager to start the server. â¢
--user=
user_name
The login user name to use for running
mariadbd
."
866,0,mysql-stress-test.pl,"The
mariadb-stress-test.pl
Perl script performs stress-testing of
       the MariaDB server. mariadb-stress-test.pl
requires a version of Perl that has been
       built with threads support. Invoke
mariadb-stress-test.pl
like this:

           shell>
mariadb-stress-test.pl [
options
]
mariadb-stress-test.pl
supports the following options:

       â¢
--help
Display a help message and exit."
866,1,mysql-stress-test.pl,"Invoke
mariadb-stress-test.pl
like this:

           shell>
mariadb-stress-test.pl [
options
]
mariadb-stress-test.pl
supports the following options:

       â¢
--help
Display a help message and exit. â¢
--abort-on-error=
N
Causes the program to abort if an error with severity less
           than or equal to N was encountered. Set to 1 to abort on any
           error."
866,2,mysql-stress-test.pl,"Set to 1 to abort on any
           error. â¢
--check-tests-file
Periodically check the file that lists the tests to be run. If
           it has been modified, reread the file."
866,3,mysql-stress-test.pl,"If
           it has been modified, reread the file. This can be useful if
           you update the list of tests to be run during a stress test. â¢
--cleanup
Force cleanup of the working directory."
866,4,mysql-stress-test.pl,"â¢
--cleanup
Force cleanup of the working directory. â¢
--log-error-details
Log error details in the global error log file. â¢
--loop-count=
N
In sequential test mode, the number of loops to execute before
           exiting."
866,5,mysql-stress-test.pl,"â¢
--loop-count=
N
In sequential test mode, the number of loops to execute before
           exiting. â¢
--mariadb-test=
path
The path name to the
mariadb-test
program. â¢
--server-database=
db_name
The database to use for the tests."
866,6,mysql-stress-test.pl,"â¢
--server-database=
db_name
The database to use for the tests. The default is test. â¢
--server-host=
host_name
The host name of the local host to use for making a TCP/IP
           connection to the local server."
866,7,mysql-stress-test.pl,"â¢
--server-host=
host_name
The host name of the local host to use for making a TCP/IP
           connection to the local server. By default, the connection is
           made to localhost using a Unix socket file. â¢
--server-logs-dir=
path
This option is required."
866,8,mysql-stress-test.pl,"â¢
--server-logs-dir=
path
This option is required. path
is the directory where all
           client session logs will be stored. Usually this is the shared
           directory that is associated with the server used for testing."
866,9,mysql-stress-test.pl,"Usually this is the shared
           directory that is associated with the server used for testing. â¢
--server-password=
password
The password to use when connecting to the server. â¢
--server-port=
port_num
The TCP/IP port number to use for connecting to the server."
866,10,mysql-stress-test.pl,"â¢
--server-port=
port_num
The TCP/IP port number to use for connecting to the server. The default is 3306. â¢
--server-socket=
file_name
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use."
866,11,mysql-stress-test.pl,"â¢
--server-socket=
file_name
For connections to localhost, the Unix socket file to use, or,
           on Windows, the name of the named pipe to use. The default is
           /tmp/mariadb.sock. â¢
--server-user=
user_name
The MariaDB user name to use when connecting to the server."
866,12,mysql-stress-test.pl,"â¢
--server-user=
user_name
The MariaDB user name to use when connecting to the server. The default is root. â¢
--sleep-time=
N
The delay in seconds between test executions."
866,13,mysql-stress-test.pl,"â¢
--sleep-time=
N
The delay in seconds between test executions. â¢
--stress-basedir=
path
This option is required. path
is the working directory for
           the test run."
866,14,mysql-stress-test.pl,"path
is the working directory for
           the test run. It is used as the temporary location for result
           tracking during testing. â¢
--stress-datadir=
path
The directory of data files to be used during testing."
866,15,mysql-stress-test.pl,"â¢
--stress-datadir=
path
The directory of data files to be used during testing. The
           default location is the data directory under the location
           given by the
--stress-suite-basedir
option. â¢
--stress-init-file[=
path
]
file_name
is the location of the file that contains the list
           of tests to be run once to initialize the database for the
           testing."
866,16,mysql-stress-test.pl,"â¢
--stress-init-file[=
path
]
file_name
is the location of the file that contains the list
           of tests to be run once to initialize the database for the
           testing. If missing, the default file is stress_init.txt in
           the test suite directory. â¢
--stress-mode=
mode
This option indicates the test order in stress-test mode."
866,17,mysql-stress-test.pl,"â¢
--stress-mode=
mode
This option indicates the test order in stress-test mode. The
mode
value is either random to select tests in random order or
           seq to run tests in each thread in the order specified in the
           test list file. The default mode is random."
866,18,mysql-stress-test.pl,"The default mode is random. â¢
--stress-suite-basedir=
path
This option is required. path
is the directory that has the t
           and
r
subdirectories containing the test case and result
           files."
866,19,mysql-stress-test.pl,"path
is the directory that has the t
           and
r
subdirectories containing the test case and result
           files. This directory is also the default location of the
           stress-test.txt file that contains the list of tests. (A
           different location can be specified with the
--stress-tests-file
option.)

       â¢
--stress-tests-file[=
file_name
]
Use this option to run the stress tests."
866,20,mysql-stress-test.pl,"(A
           different location can be specified with the
--stress-tests-file
option.)

       â¢
--stress-tests-file[=
file_name
]
Use this option to run the stress tests. file_name
is the
           location of the file that contains the list of tests. If
file_name
is omitted, the default file is stress-test.txt in
           the stress suite directory."
866,21,mysql-stress-test.pl,"If
file_name
is omitted, the default file is stress-test.txt in
           the stress suite directory. (See
--stress-suite-basedir
.)

       â¢
--suite=
suite_name
Run the named test suite. The default name is main (the
           regular test suite located in the mariadb-test directory)."
866,22,mysql-stress-test.pl,"The default name is main (the
           regular test suite located in the mariadb-test directory). â¢
--test-count=
N
The number of tests to execute before exiting. â¢
--test-duration=
N
The duration of stress testing in seconds."
866,23,mysql-stress-test.pl,"â¢
--test-duration=
N
The duration of stress testing in seconds. â¢
--threads=
N
The number of threads. The default is 1."
866,24,mysql-stress-test.pl,"The default is 1. â¢
--verbose
Verbose mode. Print more information about what the program
           does."
867,0,namei,"namei
interprets its arguments as pathnames to any type of Unix
       file (symlinks, files, directories, and so forth). namei
then
       follows each pathname until an endpoint is found (a file, a
       directory, a device node, etc). If it finds a symbolic link, it
       shows the link, and starts following it, indenting the output to
       show the context."
867,1,namei,"If it finds a symbolic link, it
       shows the link, and starts following it, indenting the output to
       show the context. This program is useful for finding ""too many levels of symbolic
       links"" problems. For each line of output,
namei
uses the following characters to
       identify the file type found:

              f: = the pathname currently being resolved
               d = directory
               l = symbolic link (both the link and its contents are output)
               s = socket
               b = block device
               c = character device
               p = FIFO (named pipe)
               - = regular file
               ?"
867,2,namei,"This program is useful for finding ""too many levels of symbolic
       links"" problems. For each line of output,
namei
uses the following characters to
       identify the file type found:

              f: = the pathname currently being resolved
               d = directory
               l = symbolic link (both the link and its contents are output)
               s = socket
               b = block device
               c = character device
               p = FIFO (named pipe)
               - = regular file
               ? = an error of some kind
namei
prints an informative message when the maximum number of
       symbolic links this system can have has been exceeded."
868,0,mytop,nan
869,0,mysql-test-run.pl,"The
mariadb-test-run.pl
Perl script is the main application used
       to run the MariaDB test suite. It invokes
mariadb-test
to run
       individual test cases. Invoke
mariadb-test-run.pl
in the mariadb-test directory like
       this:

           shell>
mariadb-test-run.pl [
options
] [
test_name
] ..."
869,1,mysql-test-run.pl,"Invoke
mariadb-test-run.pl
in the mariadb-test directory like
       this:

           shell>
mariadb-test-run.pl [
options
] [
test_name
] ... Each
test_name
argument names a test case. The test case file that
       corresponds to the test name is t/
test_name
.test."
869,2,mysql-test-run.pl,"The test case file that
       corresponds to the test name is t/
test_name
.test. For each
test_name
argument,
mariadb-test-run.pl
runs the named
       test case. With no
test_name
arguments,
mariadb-test-run.pl
runs
       all .test files in the t subdirectory."
869,3,mysql-test-run.pl,"With no
test_name
arguments,
mariadb-test-run.pl
runs
       all .test files in the t subdirectory. If no suffix is given for the test name, a suffix of .test is
       assumed. Any leading path name is ignored."
869,4,mysql-test-run.pl,"Any leading path name is ignored. These commands are
       equivalent:

           shell>
mariadb-test-run.pl mytest
shell>
mariadb-test-run.pl mytest.test
shell>
mariadb-test-run.pl t/mytest.test
A suite name can be given as part of the test name. That is, the
       syntax for naming a test is:

           [
suite_name
.]
test_name
[."
869,5,mysql-test-run.pl,"That is, the
       syntax for naming a test is:

           [
suite_name
.]
test_name
[. suffix
]

       If a suite name is given,
mariadb-test-run.pl
looks in that suite
       for the test. The test file corresponding to a test named
suite_name.test_name
is found in
       suite/
suite_name
/t/
test_name
.test."
869,6,mysql-test-run.pl,"The test file corresponding to a test named
suite_name.test_name
is found in
       suite/
suite_name
/t/
test_name
.test. There is also an implicit suite
       name main for the tests in the top t directory. With no suite
       name,
mariadb-test-run.pl
looks in the default list of suites for
       a match and runs the test in any suites where it finds the test."
869,7,mysql-test-run.pl,"With no suite
       name,
mariadb-test-run.pl
looks in the default list of suites for
       a match and runs the test in any suites where it finds the test. Suppose that the default suite list is main, binlog, rpl, and that
       a test mytest.test exists in the main and rpl suites. With an
       argument of mytest or mytest.test,
mariadb-test-run.pl
will run
       mytest.test from the main and rpl suites."
869,8,mysql-test-run.pl,"With an
       argument of mytest or mytest.test,
mariadb-test-run.pl
will run
       mytest.test from the main and rpl suites. To run a family of test cases for which the names share a common
       prefix, use the
--do-test=
prefix
option. For example,
--do-test=rpl
runs the replication tests (test cases that have
       names beginning with rpl)."
869,9,mysql-test-run.pl,"For example,
--do-test=rpl
runs the replication tests (test cases that have
       names beginning with rpl). --skip-test
has the opposite effect of
       skipping test cases for which the names share a common prefix. The argument for the
--do-test
and
--skip-test
options also allows
       more flexible specification of which tests to perform or skip."
869,10,mysql-test-run.pl,"The argument for the
--do-test
and
--skip-test
options also allows
       more flexible specification of which tests to perform or skip. If
       the argument contains a pattern metacharacter other than a lone
       period, it is interpreted as a Perl regular expression and applies
       to test names that match the pattern. If the argument contains a
       lone period or does not contain any pattern metacharacters, it is
       interpreted the same way as previously and matches test names that
       begin with the argument value."
869,11,mysql-test-run.pl,"If the argument contains a
       lone period or does not contain any pattern metacharacters, it is
       interpreted the same way as previously and matches test names that
       begin with the argument value. For example,
--do-test=testa
matches tests that begin with testa,
--do-test=main.testa
matches
       tests in the main test suite that begin with testa, and
--do-test=main.*testa
matches test names that contain main
       followed by testa with anything in between. In the latter case,
       the pattern match is not anchored to the beginning of the test
       name, so it also matches names such as xmainytesta."
869,12,mysql-test-run.pl,"In the latter case,
       the pattern match is not anchored to the beginning of the test
       name, so it also matches names such as xmainytesta. To perform setup prior to running tests,
mariadb-test-run.pl
needs
       to invoke
mariadbd
with the
--bootstrap
and
--skip-grant-tables
options. If MariaDB was configured with the
--disable-grant-options
option,
--bootstrap
,
--skip-grant-tables
,
       and
--init-file
will be disabled."
869,13,mysql-test-run.pl,"If MariaDB was configured with the
--disable-grant-options
option,
--bootstrap
,
--skip-grant-tables
,
       and
--init-file
will be disabled. To handle this, set the
       MYSQLD_BOOTSTRAP environment variable to the full path name of a
       server that has all options enabled. mariadb-test-run.pl
will use
       that server to perform setup; it is not used to run the tests."
869,14,mysql-test-run.pl,"mariadb-test-run.pl
will use
       that server to perform setup; it is not used to run the tests. The init_file test will fail if
--init-file
is disabled. This is
       an expected failure that can be handled as follows:

           shell>
export MYSQLD_BOOTSTRAP
shell>
MYSQLD_BOOTSTRAP=/full/path/to/mariadbd
shell>
make test force=""--skip-test=init_file""
To run
mariadb-test-run.pl
on Windows, you'll need either Cygwin
       or ActiveState Perl to run it."
869,15,mysql-test-run.pl,"This is
       an expected failure that can be handled as follows:

           shell>
export MYSQLD_BOOTSTRAP
shell>
MYSQLD_BOOTSTRAP=/full/path/to/mariadbd
shell>
make test force=""--skip-test=init_file""
To run
mariadb-test-run.pl
on Windows, you'll need either Cygwin
       or ActiveState Perl to run it. You may also need to install the
       modules required by the script. To run the test script, change
       location into the mariadb-test directory, set the MTR_VS_CONFIG
       environment variable to the configuration you selected earlier (or
       use the
--vs-config
option), and invoke
mariadb-test-run.pl
."
869,16,mysql-test-run.pl,"To run the test script, change
       location into the mariadb-test directory, set the MTR_VS_CONFIG
       environment variable to the configuration you selected earlier (or
       use the
--vs-config
option), and invoke
mariadb-test-run.pl
. For
       example (using Cygwin and the
bash
shell):

           shell>
cd mariadb-test
shell>
export MTR_VS_CONFIG=debug
shell>
./mariadb-test-run.pl --force --timer
shell>
./mariadb-test-run.pl --force --timer --ps-protocol
mariadb-test-run.pl
uses several environment variables. Some of
       them are listed in the following table."
869,17,mysql-test-run.pl,"Some of
       them are listed in the following table. Some of these are set from
       the outside and used by
mariadb-test-run.pl
, others are set by
mariadb-test-run.pl
instead, and may be referred to in tests. ââââââââââââââââââââ¬âââââââââââââââââââââââââââââ
       â
Variable
â
Meaning
â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_VERSION      â If set to 1, will run      â
       â                  â the older version 1 of     â
       â                  â
mariadb-test-run.pl
."
869,18,mysql-test-run.pl,"ââââââââââââââââââââ¬âââââââââââââââââââââââââââââ
       â
Variable
â
Meaning
â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_VERSION      â If set to 1, will run      â
       â                  â the older version 1 of     â
       â                  â
mariadb-test-run.pl
. â
       â                  â This will affect what      â
       â                  â functionailty is           â
       â                  â available and what         â
       â                  â command line options are   â
       â                  â supported. â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_MEM          â If set to anything, will   â
       â                  â run tests with files in    â
       â                  â ""memory"" using tmpfs or    â
       â                  â                 ramdisk."
869,19,mysql-test-run.pl,"â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_MEM          â If set to anything, will   â
       â                  â run tests with files in    â
       â                  â ""memory"" using tmpfs or    â
       â                  â                 ramdisk. â
       â                  â Not available on           â
       â                  â Windows. Same as           â
       â                  â
--mem
â
       â                  â option                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_PARALLEL     â If set, defines number     â
       â                  â of parallel threads        â
       â                  â executing tests."
869,20,mysql-test-run.pl,"Same as           â
       â                  â
--mem
â
       â                  â option                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_PARALLEL     â If set, defines number     â
       â                  â of parallel threads        â
       â                  â executing tests. Same as   â
       â                  â
--parallel
â
       â                  â option                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_BUILD_THREAD â If set, defines which port â
       â                  â number range is used for   â
       â                  â the server                 â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_PORT_BASE    â If set, defines which port â
       â                  â number range is used for   â
       â                  â the server                 â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MTR_
NAME
_TIMEOUT â Setting of a timeout in    â
       â                  â minutes or seconds,        â
       â                  â corresponding to command   â
       â                  â line option                â
       â                  â
--
name
-timeout
. Available  â
       â                  â timeout names are          â
       â                  â TESTCASE, SUITE (both in   â
       â                  â minutes) and START,        â
       â                  â SHUTDOWN (both in          â
       â                  â seconds)."
869,21,mysql-test-run.pl,"Available  â
       â                  â timeout names are          â
       â                  â TESTCASE, SUITE (both in   â
       â                  â minutes) and START,        â
       â                  â SHUTDOWN (both in          â
       â                  â seconds). These variables  â
       â                  â are supported from MySQL   â
       â                  â 5.1.44. â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TEST       â Path name to
mariadb-test
â
       â                  â binary                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQLD_BOOTSTRAP â Full path name to
mariadbd
â
       â                  â that has all options       â
       â                  â enabled                    â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQLTEST_VARDIR â Path name to the var       â
       â                  â directory that is used for â
       â                  â                 logs,      â
       â                  â temporary files, and so    â
       â                  â forth                      â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TEST_DIR   â Full path to the           â
       â                  â mariadb-test directory     â
       â                  â where tests                â
       â                  â                 are being  â
       â                  â run from                   â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TMP_DIR    â Path to temp directory     â
       â                  â used for temporary files   â
       â                  â during tests               â
       ââââââââââââââââââââ´âââââââââââââââââââââââââââââ

       The variable MTR_PORT_BASE was added in MySQL 5.1.45 as a more
       logical replacement for MTR_BUILD_THREAD."
869,22,mysql-test-run.pl,"â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TEST       â Path name to
mariadb-test
â
       â                  â binary                     â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQLD_BOOTSTRAP â Full path name to
mariadbd
â
       â                  â that has all options       â
       â                  â enabled                    â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQLTEST_VARDIR â Path name to the var       â
       â                  â directory that is used for â
       â                  â                 logs,      â
       â                  â temporary files, and so    â
       â                  â forth                      â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TEST_DIR   â Full path to the           â
       â                  â mariadb-test directory     â
       â                  â where tests                â
       â                  â                 are being  â
       â                  â run from                   â
       ââââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤
       â MYSQL_TMP_DIR    â Path to temp directory     â
       â                  â used for temporary files   â
       â                  â during tests               â
       ââââââââââââââââââââ´âââââââââââââââââââââââââââââ

       The variable MTR_PORT_BASE was added in MySQL 5.1.45 as a more
       logical replacement for MTR_BUILD_THREAD. It gives the actual port
       number directly (will be rounded down to a multiple of 10). If you
       use MTR_BUILD_THREAD, the port number is found by multiplying this
       by 10 and adding 10000."
869,23,mysql-test-run.pl,"If you
       use MTR_BUILD_THREAD, the port number is found by multiplying this
       by 10 and adding 10000. Tests sometimes rely on certain environment variables being
       defined. For example, certain tests assume that MARIADB-TEST is
       defined so that
mariadb-test
can invoke itself with exec
       $MYSQL_TEST."
869,24,mysql-test-run.pl,"For example, certain tests assume that MARIADB-TEST is
       defined so that
mariadb-test
can invoke itself with exec
       $MYSQL_TEST. Other tests may refer to the last three variables listed in the
       preceding table, to locate files to read or write. For example,
       tests that need to create files will typically put them in
       $MYSQL_TMP_DIR/
file_name
."
869,25,mysql-test-run.pl,"For example,
       tests that need to create files will typically put them in
       $MYSQL_TMP_DIR/
file_name
. If you are running
mariadb-test-run.pl
version 1 by setting
       MTR_VERSION, note that this only affects the test driver, not the
       test client (and its language) or the tests themselves. A few tests might not run with version 1 because they depend on
       some feature of version 2."
869,26,mysql-test-run.pl,"A few tests might not run with version 1 because they depend on
       some feature of version 2. You may have those tests skipped by
       adding the test name to the file lib/v1/incompatible.tests. This
       feature is available from MySQL 5.1.40."
869,27,mysql-test-run.pl,"This
       feature is available from MySQL 5.1.40. mariadb-test-run.pl
supports the options in the following list. An
       argument of
--
tells
mariadb-test-run.pl
not to process any
       following arguments as options."
869,28,mysql-test-run.pl,"An
       argument of
--
tells
mariadb-test-run.pl
not to process any
       following arguments as options. â¢
--help
,
-h
Display a help message and exit. â¢
--big-test
Allow tests marked as ""big"" to run."
869,29,mysql-test-run.pl,"â¢
--big-test
Allow tests marked as ""big"" to run. Tests can be thus marked
           by including the line
--source include/big_test.inc
, and they
           will only be run if this option is given, or if the
           environment variable BIG_TEST is set to 1. Repeat this option
           twice to run only ""big"" tests."
869,30,mysql-test-run.pl,"Repeat this option
           twice to run only ""big"" tests. This is typically used for tests that take a very long to run,
           or that use many resources, so that they are not suitable for
           running as part of a normal test suite run. â¢
--boot-dbx
Run the mariadbd server used for bootstrapping the database
           through the dbx debugger."
869,31,mysql-test-run.pl,"â¢
--boot-dbx
Run the mariadbd server used for bootstrapping the database
           through the dbx debugger. â¢
--boot-ddd
Run the mariadbd server used for bootstrapping the database
           through the ddd debugger. â¢
--boot-gdb
Run the mariadbd server used for bootstrapping the database
           through the gdb debugger."
869,32,mysql-test-run.pl,"â¢
--boot-gdb
Run the mariadbd server used for bootstrapping the database
           through the gdb debugger. â¢
--[mtr-]build-thread=
number
Specify a number to calculate port numbers from. The formula
           is 10 *
build_thread
+ 10000."
869,33,mysql-test-run.pl,"The formula
           is 10 *
build_thread
+ 10000. Instead of a number, it can be
           set to auto, which is also the default value, in which case
mariadb-test-run.pl
will allocate a number unique to this
           host. The value (number or auto) can also be set with the
           MTR_BUILD_THREAD environment variable."
869,34,mysql-test-run.pl,"The value (number or auto) can also be set with the
           MTR_BUILD_THREAD environment variable. The more logical
--port-base
is supported as an alternative. â¢
--callgrind
Instructs
valgrind
to use
callgrind
."
869,35,mysql-test-run.pl,"â¢
--callgrind
Instructs
valgrind
to use
callgrind
. â¢
--check-testcases
Check test cases for side effects. This is done by checking
           system state before and after each test case; if there is any
           difference, a warning to that effect will be written, but the
           test case will not be marked as failed because of it."
869,36,mysql-test-run.pl,"This is done by checking
           system state before and after each test case; if there is any
           difference, a warning to that effect will be written, but the
           test case will not be marked as failed because of it. This
           check is enabled by default. â¢
--client-bindir=
path
The path to the directory where client binaries are located."
869,37,mysql-test-run.pl,"â¢
--client-bindir=
path
The path to the directory where client binaries are located. â¢
--client-dbx
Start
mariadb-test
in the
dbx
debugger. â¢
--client-ddd
Start
mariadb-test
in the
ddd
debugger."
869,38,mysql-test-run.pl,"â¢
--client-ddd
Start
mariadb-test
in the
ddd
debugger. â¢
--client-debugger=
debugger
Start
mariadb-test
in the named debugger. â¢
--client-gdb
Start
mariadb-test
in the
gdb
debugger."
869,39,mysql-test-run.pl,"â¢
--client-gdb
Start
mariadb-test
in the
gdb
debugger. â¢
--client-libdir=
path
The path to the directory where client libraries are located. â¢
--combination=
value
Extra options to pass to
mariadbd
."
869,40,mysql-test-run.pl,"â¢
--combination=
value
Extra options to pass to
mariadbd
. The value should consist of
           one or more comma-separated
mariadbd
options. This option is
           similar to
--mariadbd
but should be given two or more times."
869,41,mysql-test-run.pl,"This option is
           similar to
--mariadbd
but should be given two or more times. mariadb-test-run.pl
executes multiple test runs, using the
           options for each instance of
--combination
in successive runs. If
--combination
is given only once, it has no effect."
869,42,mysql-test-run.pl,"If
--combination
is given only once, it has no effect. For
           test runs specific to a given test suite, an alternative to
           the use of
--combination
is to create a combinations file in
           the suite directory. The file should contain a section of
           options for each test run."
869,43,mysql-test-run.pl,"The file should contain a section of
           options for each test run. â¢
--comment=
str
Write
str
to the output within lines filled with #, as a form
           of banner. â¢
--compress
Compress all information sent between the client and the
           server if both support compression."
869,44,mysql-test-run.pl,"â¢
--compress
Compress all information sent between the client and the
           server if both support compression. â¢
--cursor-protocol
Use the cursor protocol between client and server (implies
--ps-protocol
). â¢
--dbx
Start the
mariadbd(s)
in the
dbx
debugger."
869,45,mysql-test-run.pl,"â¢
--dbx
Start the
mariadbd(s)
in the
dbx
debugger. â¢
--ddd
Start the
mariadbd(s)
in the
ddd
debugger. â¢
--debug
Dump trace output for all clients and servers."
869,46,mysql-test-run.pl,"â¢
--debug
Dump trace output for all clients and servers. â¢
--debug-common
Same as
--debug
, but sets the 'd' debug flags to
           ""query,info,error,enter,exit"". â¢
--debug-server
Use debug version of server, but without turning on tracing."
869,47,mysql-test-run.pl,"â¢
--debug-server
Use debug version of server, but without turning on tracing. â¢
--debugger=
debugger
Start
mariadbd
using the named debugger. â¢
--debug-sync-timeout=
N
Controls whether the Debug Sync facility for testing and
           debugging is enabled."
869,48,mysql-test-run.pl,"â¢
--debug-sync-timeout=
N
Controls whether the Debug Sync facility for testing and
           debugging is enabled. The option value is a timeout in
           seconds. The default value is 300."
869,49,mysql-test-run.pl,"The default value is 300. A value of 0 disables Debug
           Sync. The value of this option also becomes the default
           timeout for individual synchronization points."
869,50,mysql-test-run.pl,"The value of this option also becomes the default
           timeout for individual synchronization points. mariadb-test-run.pl
passes
--loose-debug-sync-timeout=
N
to
mariadbd
. The
--loose
prefix is used so that
mariadbd
does not
           fail if Debug Sync is not compiled in."
869,51,mysql-test-run.pl,"The
--loose
prefix is used so that
mariadbd
does not
           fail if Debug Sync is not compiled in. â¢
--defaults-file=
file_name
Use the named file as fixed config file template for all
           tests. â¢
--defaults_extra_file=
file_name
Add setting from the named file to all generated configs."
869,52,mysql-test-run.pl,"â¢
--defaults_extra_file=
file_name
Add setting from the named file to all generated configs. â¢
--do-test=
prefix
|
regex
Run all test cases having a name that begins with the given
prefix
value, or fulfils the
regex
. This option provides a
           convenient way to run a family of similarly named tests."
869,53,mysql-test-run.pl,"This option provides a
           convenient way to run a family of similarly named tests. The argument for the
--do-test
option also allows more
           flexible specification of which tests to perform. If the
           argument contains a pattern metacharacter other than a lone
           period, it is interpreted as a Perl regular expression and
           applies to test names that match the pattern."
869,54,mysql-test-run.pl,"If the
           argument contains a pattern metacharacter other than a lone
           period, it is interpreted as a Perl regular expression and
           applies to test names that match the pattern. If the argument
           contains a lone period or does not contain any pattern
           metacharacters, it is interpreted the same way as previously
           and matches test names that begin with the argument value. For
           example,
--do-test=testa
matches tests that begin with testa,
--do-test=main.testa
matches tests in the main test suite that
           begin with testa, and
--do-test=main.*testa
matches test names
           that contain main followed by testa with anything in between."
869,55,mysql-test-run.pl,"For
           example,
--do-test=testa
matches tests that begin with testa,
--do-test=main.testa
matches tests in the main test suite that
           begin with testa, and
--do-test=main.*testa
matches test names
           that contain main followed by testa with anything in between. In the latter case, the pattern match is not anchored to the
           beginning of the test name, so it also matches names such as
           xmainytestz. â¢
--dry-run
Don't run any tests, print the list of tests that were
           selected for execution."
869,56,mysql-test-run.pl,"â¢
--dry-run
Don't run any tests, print the list of tests that were
           selected for execution. â¢
--embedded-server
Use a version of
mariadb-test
built with the embedded server. â¢
--enable-disabled
Ignore any disabled.def file, and also run tests marked as
           disabled."
869,57,mysql-test-run.pl,"â¢
--enable-disabled
Ignore any disabled.def file, and also run tests marked as
           disabled. Success or failure of those tests will be reported
           the same way as other tests. â¢
--experimental=
file_name
Specify a file that contains a list of test cases that should
           be displayed with the [ exp-fail ] code rather than [ fail ]
           if they fail."
869,58,mysql-test-run.pl,"â¢
--experimental=
file_name
Specify a file that contains a list of test cases that should
           be displayed with the [ exp-fail ] code rather than [ fail ]
           if they fail. For an example of a file that might be specified via this
           option, see mariadb-test/collections/default.experimental. â¢
--extern
option
=
value
Use an already running server."
869,59,mysql-test-run.pl,"â¢
--extern
option
=
value
Use an already running server. The option/value pair is what
           is needed by the
mariadb
client to connect to the server. Each
--extern
option can only take one option/value pair as an
           argument, so you need to repeat
--extern
for each pair needed."
869,60,mysql-test-run.pl,"Each
--extern
option can only take one option/value pair as an
           argument, so you need to repeat
--extern
for each pair needed. Example:

                     ./mariadb-test-run.pl --extern socket=var/tmp/mariadbd.1.sock alias

           Note: If a test case has an .opt file that requires the server
           to be restarted with specific options, the file will not be
           used. The test case likely will fail as a result."
869,61,mysql-test-run.pl,"The test case likely will fail as a result. â¢
--fast
Do not perform controlled shutdown when servers need to be
           restarted or at the end of the test run. This is equivalent to
           using --shutdown-timeout=0."
869,62,mysql-test-run.pl,"This is equivalent to
           using --shutdown-timeout=0. â¢
--force-restart
Always restart servers between tests. â¢
--force
Normally,
mariadb-test-run.pl
exits if a test case fails."
869,63,mysql-test-run.pl,"â¢
--force
Normally,
mariadb-test-run.pl
exits if a test case fails. --force
causes execution to continue regardless of test case
           failure. â¢
--gcov
Collect coverage information after the test."
869,64,mysql-test-run.pl,"â¢
--gcov
Collect coverage information after the test. The result is a
gcov
file per source and header file. â¢
--gcov-src-dir
Colllect coverage only within the given subdirectory."
869,65,mysql-test-run.pl,"â¢
--gcov-src-dir
Colllect coverage only within the given subdirectory. For
           example, if you're only developing the SQL layer, it makes
           sense to use
--gcov-src-dir=sql
. â¢
--gdb
Start the
mariadbd(s)
in the
gdb
debugger."
869,66,mysql-test-run.pl,"â¢
--gdb
Start the
mariadbd(s)
in the
gdb
debugger. â¢
--gprof
Collect profiling information using the
gprof
profiling tool. â¢
--manual-dbx
Use a server that has already been started by the user in the
dbx
debugger."
869,67,mysql-test-run.pl,"â¢
--manual-dbx
Use a server that has already been started by the user in the
dbx
debugger. â¢
--manual-ddd
Use a server that has already been started by the user in the
ddd
debugger. â¢
--manual-debug
Use a server that has already been started by the user in a
           debugger."
869,68,mysql-test-run.pl,"â¢
--manual-debug
Use a server that has already been started by the user in a
           debugger. â¢
--manual-gdb
Use a server that has already been started by the user in the
gdb
debugger. â¢
--manual-lldb
Use a server that has already been started by the user in the
lldb
debugger."
869,69,mysql-test-run.pl,"â¢
--manual-lldb
Use a server that has already been started by the user in the
lldb
debugger. â¢
--mark-progress
Marks progress with timing (in milliseconds) and line number
           in var/log/
testname
.progress. â¢
--max-connections=
num
The maximum number of simultaneous server connections that may
           be used per test."
869,70,mysql-test-run.pl,"â¢
--max-connections=
num
The maximum number of simultaneous server connections that may
           be used per test. If not set, the maximum is 128. Minimum
           allowed limit is 8, maximum is 5120."
869,71,mysql-test-run.pl,"Minimum
           allowed limit is 8, maximum is 5120. Corresponds to the same
           option for
mariadb-test
. â¢
--max-save-core=
N
Limit the number of core files saved, to avoid filling up
           disks in case of a frequently crashing server."
869,72,mysql-test-run.pl,"â¢
--max-save-core=
N
Limit the number of core files saved, to avoid filling up
           disks in case of a frequently crashing server. Defaults to 5,
           set to 0 for no limit. May also be set with the environment
           variable MTR_MAX_SAVE_CORE

       â¢
--max-save-datadir=
N
Limit the number of data directories saved after failed tests,
           to avoid filling up disks in case of frequent failures."
869,73,mysql-test-run.pl,"May also be set with the environment
           variable MTR_MAX_SAVE_CORE

       â¢
--max-save-datadir=
N
Limit the number of data directories saved after failed tests,
           to avoid filling up disks in case of frequent failures. Defaults to 20, set to 0 for no limit. May also be set with
           the environment variable MTR_MAX_SAVE_DATADIR

       â¢
--max-test-fail=
N
Stop execution after the specified number of tests have
           failed, to avoid using up resources (and time) in case of
           massive failures."
869,74,mysql-test-run.pl,"May also be set with
           the environment variable MTR_MAX_SAVE_DATADIR

       â¢
--max-test-fail=
N
Stop execution after the specified number of tests have
           failed, to avoid using up resources (and time) in case of
           massive failures. retries are not counted, nor are failures of
           tests marked experimental. Defaults to 10, set to 0 for no
           limit."
869,75,mysql-test-run.pl,"Defaults to 10, set to 0 for no
           limit. May also be set with the environment variable
           MTR_MAX_TEST_FAIL

       â¢
--mem
This option is not supported on Windows. Run the test suite in memory, using tmpfs or ramdisk."
869,76,mysql-test-run.pl,"Run the test suite in memory, using tmpfs or ramdisk. This can
           decrease test times significantly, in particular if you would
           otherwise be running over a remote file system. mariadb-test-run.pl
attempts to find a suitable location using
           a built-in list of standard locations for tmpfs and puts the
           var directory there."
869,77,mysql-test-run.pl,"mariadb-test-run.pl
attempts to find a suitable location using
           a built-in list of standard locations for tmpfs and puts the
           var directory there. This option also affects placement of
           temporary files, which are created in var/tmp. The default list includes /dev/shm."
869,78,mysql-test-run.pl,"The default list includes /dev/shm. You can also enable this
           option by setting the environment variable MTR_MEM[=
dir_name
]. If
dir_name
is given, it is added to the beginning of the list
           of locations to search, so it takes precedence over any
           built-in locations."
869,79,mysql-test-run.pl,"If
dir_name
is given, it is added to the beginning of the list
           of locations to search, so it takes precedence over any
           built-in locations. Once you have run tests with
--mem
within a
           mariadb-testdirectory, a soflink var will have been set up to
           the temporary directory, and this will be re-used the next
           time, until the soflink is deleted. Thus, you do not have to
           repeat the
--mem
option next time."
869,80,mysql-test-run.pl,"Thus, you do not have to
           repeat the
--mem
option next time. â¢
--mariadbd=
value
Extra options to pass to
mariadbd
. The value should consist of
           one or more comma-separated
mariadbd
options."
869,81,mysql-test-run.pl,"The value should consist of
           one or more comma-separated
mariadbd
options. â¢
--mariadbd-env=
VAR=VAL
Specify additional environment settings for ""mariadbd"". Use
           additional
--mariadbd-env
options to set more than one
           variable."
869,82,mysql-test-run.pl,"Use
           additional
--mariadbd-env
options to set more than one
           variable. â¢
--nocheck-testcases
Disable the check for test case side effects; see
--check-testcases
for a description. â¢
--noreorder
Do not reorder tests to reduce number of restarts, but run
           them in exactly the order given."
869,83,mysql-test-run.pl,"â¢
--noreorder
Do not reorder tests to reduce number of restarts, but run
           them in exactly the order given. If a whole suite is to be
           run, the tests are run in alphabetical order, though similar
           combinations will be grouped together. If more than one suite
           is listed, the tests are run one suite at a time, in the order
           listed."
869,84,mysql-test-run.pl,"If more than one suite
           is listed, the tests are run one suite at a time, in the order
           listed. â¢
--notimer
Cause
mariadb-test
not to generate a timing file. The effect
           of this is that the report from each test case does not
           include the timing in milliseconds as it normally does."
869,85,mysql-test-run.pl,"The effect
           of this is that the report from each test case does not
           include the timing in milliseconds as it normally does. â¢
--nowarnings
Do not look for and report errors and warning in the server
           logs. â¢
--parallel={
N
|auto}
Run tests using
N
parallel threads."
869,86,mysql-test-run.pl,"â¢
--parallel={
N
|auto}
Run tests using
N
parallel threads. By default, 1 thread is
           used. Use
--parallel=auto
for auto-setting of
N
."
869,87,mysql-test-run.pl,"Use
--parallel=auto
for auto-setting of
N
. â¢
--[mtr-]port-base=
P
Specify base of port numbers to be used; a block of 10 will be
           allocated. P
should be divisible by 10; if it is not, it will
           be rounded down."
869,88,mysql-test-run.pl,"P
should be divisible by 10; if it is not, it will
           be rounded down. If running with more than one parallel test
           thread, thread 2 will use the next block of 10 and so on. If the port number is given as auto, which is also the
           default,
mariadb-test-run.pl
will allocate a number unique to
           this host."
869,89,mysql-test-run.pl,"If the port number is given as auto, which is also the
           default,
mariadb-test-run.pl
will allocate a number unique to
           this host. The value may also be given with the environment
           variable MTR_PORT_BASE. If both
--build-thread
and
--port-base
are used,
--port-base
takes precedence."
869,90,mysql-test-run.pl,"If both
--build-thread
and
--port-base
are used,
--port-base
takes precedence. â¢
--print-testcases
Do not run any tests, but print details about all tests, in
           the order they would have been run. â¢
--ps-protocol
Use the binary protocol between client and server."
869,91,mysql-test-run.pl,"â¢
--ps-protocol
Use the binary protocol between client and server. â¢
--record
Pass the
--record
option to
mariadb-test
. This option requires
           a specific test case to be named on the command line."
869,92,mysql-test-run.pl,"This option requires
           a specific test case to be named on the command line. â¢
--reorder
Reorder tests to minimize the number of server restarts
           needed. This is the default behavior."
869,93,mysql-test-run.pl,"This is the default behavior. There is no guarantee
           that a particular set of tests will always end up in the same
           order. â¢
--repeat=
N
Run each test
N
number of times."
869,94,mysql-test-run.pl,"â¢
--repeat=
N
Run each test
N
number of times. â¢
--report-features
First run a ""test"" that reports MariaDB features, displaying
           the output of SHOW ENGINES and SHOW VARIABLES. This can be
           used to verify that binaries are built with all required
           features."
869,95,mysql-test-run.pl,"This can be
           used to verify that binaries are built with all required
           features. â¢
--report-times
Report how much time has been spent on different phases of
           test execution. â¢
--retry=
N
If a test fails, it is retried up to a maximum of
N
runs
           (default 1)."
869,96,mysql-test-run.pl,"â¢
--retry=
N
If a test fails, it is retried up to a maximum of
N
runs
           (default 1). Retries are also limited by the maximum number of
           failures before stopping, set with the
--retry-failure
option. This option has no effect unless
--force
is also used; without
           it, test execution will terminate after the first failure."
869,97,mysql-test-run.pl,"This option has no effect unless
--force
is also used; without
           it, test execution will terminate after the first failure. The
--retry
and
--retry-failure
options do not affect how many
           times a test repeated with
--repeat
may fail in total, as each
           repetition is considered a new test case, which may in turn be
           retried if it fails. â¢
--retry-failure=
N
When using the
--retry
option to retry failed tests, stop when
           N failures have occurred (default 2)."
869,98,mysql-test-run.pl,"â¢
--retry-failure=
N
When using the
--retry
option to retry failed tests, stop when
           N failures have occurred (default 2). Setting it to 0 or 1
           effectively turns off retries. â¢
--shutdown-timeout=
SECONDS
Max number of seconds to wait for servers to do controlled
           shutdown before killing them."
869,99,mysql-test-run.pl,"â¢
--shutdown-timeout=
SECONDS
Max number of seconds to wait for servers to do controlled
           shutdown before killing them. Default is 10. â¢
--skip-combinations
Do not apply combinations; ignore combinations file or option."
869,100,mysql-test-run.pl,"â¢
--skip-combinations
Do not apply combinations; ignore combinations file or option. â¢
--skip-rpl
Skip replication test cases. â¢
--skip-ssl
Do not start
mariadbd
with support for SSL connections."
869,101,mysql-test-run.pl,"â¢
--skip-ssl
Do not start
mariadbd
with support for SSL connections. â¢
--skip-test=
regex
|
regex
Specify a regular expression to be applied to test case names. Cases with names that match the expression are skipped."
869,102,mysql-test-run.pl,"Cases with names that match the expression are skipped. tests
           to skip. The argument for the
--skip-test
option allows more flexible
           specification of which tests to skip."
869,103,mysql-test-run.pl,"The argument for the
--skip-test
option allows more flexible
           specification of which tests to skip. If the argument contains
           a pattern metacharacter other than a lone period, it is
           interpreted as a Perl regular expression and applies to test
           names that match the pattern. See the description of the
--do-test
option for details."
869,104,mysql-test-run.pl,"See the description of the
--do-test
option for details. â¢
--skip-test-list=
FILE
Skip the tests listed in FILE. Each line in the file is an
           entry and should be formatted as: <TESTNAME> : <COMMENT>

       â¢
--skip-*
--skip-*
options not otherwise recognized by
mariadb-test-run.pl
are passed to the master server."
869,105,mysql-test-run.pl,"Each line in the file is an
           entry and should be formatted as: <TESTNAME> : <COMMENT>

       â¢
--skip-*
--skip-*
options not otherwise recognized by
mariadb-test-run.pl
are passed to the master server. â¢
--sleep=
N
Pass
--sleep=
N
to
mariadb-test
. â¢
--sp-protocol
Create a stored procedure to execute all queries."
869,106,mysql-test-run.pl,"â¢
--sp-protocol
Create a stored procedure to execute all queries. â¢
--ssl
If
mariadb-test-run.pl
is started with the
--ssl
option, it
           sets up a secure connection for all test cases. In this case,
           if
mariadbd
does not support SSL,
mariadb-test-run.pl
exits
           with an error message: Couldn't find support for SSL

       â¢
--staging-run
Run a limited number of tests (no slow tests)."
869,107,mysql-test-run.pl,"In this case,
           if
mariadbd
does not support SSL,
mariadb-test-run.pl
exits
           with an error message: Couldn't find support for SSL

       â¢
--staging-run
Run a limited number of tests (no slow tests). Used for
           running staging trees with valgrind. â¢
--start
Initialize and start servers with the startup settings for the
           specified test case."
869,108,mysql-test-run.pl,"â¢
--start
Initialize and start servers with the startup settings for the
           specified test case. You can use this option to start a server
           to which you can connect later. For example, after building a
           source distribution you can start a server and connect to it
           with the
mariadb
client like this:

               shell>
cd mariadb-test
shell>
./mariadb-test-run.pl --start alias &
shell>
../mariadb -S ./var/tmp/master.sock -h localhost -u root
If no tests are named on the command line, the server(s) will
           be started with settings for the first test that would have
           been run without the
--start
option."
869,109,mysql-test-run.pl,"For example, after building a
           source distribution you can start a server and connect to it
           with the
mariadb
client like this:

               shell>
cd mariadb-test
shell>
./mariadb-test-run.pl --start alias &
shell>
../mariadb -S ./var/tmp/master.sock -h localhost -u root
If no tests are named on the command line, the server(s) will
           be started with settings for the first test that would have
           been run without the
--start
option. mariadb-test-run.pl
will stop once the server has been
           started, but will terminate if the server dies. If killed, it
           will also shut down the server."
869,110,mysql-test-run.pl,"If killed, it
           will also shut down the server. â¢
--start-and-exit
Same
--start
, but mariadb-test-run terminates and leaves just
           the server running. â¢
--start-dirty
This is similar to
--start
, but will skip the database
           initialization phase and assume that database files are
           already available."
869,111,mysql-test-run.pl,"â¢
--start-dirty
This is similar to
--start
, but will skip the database
           initialization phase and assume that database files are
           already available. Usually this means you must have run
           another test first. â¢
--start-from=
test_name
mariadb-test-run.pl
sorts the list of names of the test cases
           to be run, and then begins with
test_name
."
869,112,mysql-test-run.pl,"â¢
--start-from=
test_name
mariadb-test-run.pl
sorts the list of names of the test cases
           to be run, and then begins with
test_name
. â¢
--strace
Run the ""mariadbd"" executables using strace. Default options
           are
-f -o var/log/'mariadbd-name'.strace
."
869,113,mysql-test-run.pl,"Default options
           are
-f -o var/log/'mariadbd-name'.strace
. â¢
--strace-client
Create
strace
output for
mariadb-test
, optionally specifying
           name and path to the trace program to use. Example: ./mariadb-test-run.pl --strace-client=ktrace

       â¢
--strace-option
=
ARGS
Option to give
strace
, replaces default option(s)."
869,114,mysql-test-run.pl,"Example: ./mariadb-test-run.pl --strace-client=ktrace

       â¢
--strace-option
=
ARGS
Option to give
strace
, replaces default option(s). â¢
--stress=
ARGS
Run stress test, providing options to mariadb-stress-test.pl. Options are separated by comma."
869,115,mysql-test-run.pl,"Options are separated by comma. â¢
--suite[s]=
suite_name... Comma separated list of suite names to run."
869,116,mysql-test-run.pl,"Comma separated list of suite names to run. The default is:
           ""main-,archive-,binlog-,csv-,federated-,funcs_1-,funcs_2-,
           handler-,heap-,innodb-,innodb_fts-,innodb_zip-,maria-,
           multi_source-,optimizer_unfixed_bugs-,parts-,perfschema-,
           plugins-,roles-,rpl-,sys_vars-,unit-,vcol-"". â¢
--stop-file=
file
If this file is detected, mariadb-test will not start new
           tests until the file is removed (also MTR_STOP_FILE
           environment variable)."
869,117,mysql-test-run.pl,"â¢
--stop-file=
file
If this file is detected, mariadb-test will not start new
           tests until the file is removed (also MTR_STOP_FILE
           environment variable). â¢
--stop-keep-alive=
sec
Works with
--stop-file
, print messages every
sec
seconds when
           mariadb-test is waiting to remove the file (for buildbot)
           (also MTR_STOP_KEEP_ALIVE environment variable). â¢
--suite-timeout=
minutes
Specify the maximum test suite runtime in minutes."
869,118,mysql-test-run.pl,"â¢
--suite-timeout=
minutes
Specify the maximum test suite runtime in minutes. The default
           is 360. â¢
--testcase-timeout
Specify the maximum test case runtime in minutes."
869,119,mysql-test-run.pl,"â¢
--testcase-timeout
Specify the maximum test case runtime in minutes. The default
           is 15. â¢
--timediff
Used with
--timestamp
, also print time passed since the
           previous test started."
869,120,mysql-test-run.pl,"â¢
--timediff
Used with
--timestamp
, also print time passed since the
           previous test started. â¢
--timer
Cause
mariadb-test
to generate a timing file. The default file
           is named ./var/log/timer."
869,121,mysql-test-run.pl,"The default file
           is named ./var/log/timer. â¢
--timestamp
Prints a timestamp before the test case name in each test
           report line, showing when the test ended. â¢
--tmpdir=
path
The directory where temporary file are stored."
869,122,mysql-test-run.pl,"â¢
--tmpdir=
path
The directory where temporary file are stored. The default
           location is ./var/tmp. The environment variable MYSQL_TMP_DIR
           will be set to the path for this directory, whether it has the
           default value or has been set explicitly."
869,123,mysql-test-run.pl,"The environment variable MYSQL_TMP_DIR
           will be set to the path for this directory, whether it has the
           default value or has been set explicitly. This may be referred
           to in tests. â¢
--user=
user_name
The MariaDB user name to use when connecting to the server
           (default root)."
869,124,mysql-test-run.pl,"â¢
--user=
user_name
The MariaDB user name to use when connecting to the server
           (default root). â¢
--user-args
In combination with
start*
and no test name, drops arguments
           to mariadbd except those specified with
--mariadbd
(if any). â¢
--valgrind[-all]
Run
mariadb-test
and
mariadbd
with
valgrind
."
869,125,mysql-test-run.pl,"â¢
--valgrind[-all]
Run
mariadb-test
and
mariadbd
with
valgrind
. This and the
           following
--valgrind
options require that the executables have
           been built with
valgrind
support. â¢
--valgrind-mariadbd
Run the
mariadbd
server with
valgrind
."
869,126,mysql-test-run.pl,"â¢
--valgrind-mariadbd
Run the
mariadbd
server with
valgrind
. â¢
--valgrind-mariadb-test
Run the
mariadb-test
and
mariadb-client-test
executables with
valgrind
. â¢
--valgrind-option=
str
Option to give
valgrind
."
869,127,mysql-test-run.pl,"â¢
--valgrind-option=
str
Option to give
valgrind
. Replaces default option(s). Can be
           specified more then once&."
869,128,mysql-test-run.pl,"Can be
           specified more then once&. â¢
--valgrind-path=
path
Path to the
valgrind
executable. â¢
--vardir=
path
Specify the path where files generated during the test run are
           stored."
869,129,mysql-test-run.pl,"â¢
--vardir=
path
Specify the path where files generated during the test run are
           stored. The default location is ./var. The environment
           variable MYSQLTEST_VARDIR will be set to the path for this
           directory, whether it has the default value or has been set
           explicitly."
869,130,mysql-test-run.pl,"The environment
           variable MYSQLTEST_VARDIR will be set to the path for this
           directory, whether it has the default value or has been set
           explicitly. This may be referred to in tests. â¢
--verbose
Give more verbose output regarding test execution."
869,131,mysql-test-run.pl,"â¢
--verbose
Give more verbose output regarding test execution. Use the
           option twice to get even more output. Note that the output
           generated within each test case is not affected."
869,132,mysql-test-run.pl,"Note that the output
           generated within each test case is not affected. â¢
--verbose-restart
Write when and why servers are restarted between test cases. â¢
--view-protocol
Create a view to execute all non updating queries."
869,133,mysql-test-run.pl,"â¢
--view-protocol
Create a view to execute all non updating queries. â¢
--vs-config=
config_val
Visual Studio configuration used to create executables
           (default: MTR_VS_CONFIG environment variable) This option is
           for Windows only. â¢
--wait-all
If
--start
or
--start-dirty
is used, wait for all servers to
           exit before termination."
869,134,mysql-test-run.pl,"â¢
--wait-all
If
--start
or
--start-dirty
is used, wait for all servers to
           exit before termination. Otherwise, it will terminate if one
           (of several) servers is restarted. â¢
--warnings
Search the server log for errors or warning after each test
           and report any suspicious ones; if any are found, the test
           will be marked as failed."
869,135,mysql-test-run.pl,"Otherwise, it will terminate if one
           (of several) servers is restarted. â¢
--warnings
Search the server log for errors or warning after each test
           and report any suspicious ones; if any are found, the test
           will be marked as failed. This is the default behavior, it may
           be turned off with
--nowarnings
."
870,0,ncurses6-config,"This is a shell script which simplifies configuring applications
       against a particular set of ncurses libraries."
871,0,needs-restarting,"needs-restarting
is a program that reports a list of process ids
       that started running before they or some component that they use
       were updated."
872,0,ndiff,"Ndiff is a tool to aid in the comparison of Nmap scans. It takes
       two Nmap XML output files and prints the differences between them. The differences observed are:

       â¢   Host states (e.g."
872,1,ndiff,"The differences observed are:

       â¢   Host states (e.g. up to down)

       â¢   Port states (e.g. open to closed)

       â¢   Service versions (from
-sV
)

       â¢   OS matches (from
-O
)

       â¢   Script output

       Ndiff, like the standard
diff
utility, compares two scans at a
       time."
873,0,neqn,nan
874,0,ncat,"Ncat is a feature-packed networking utility which reads and writes
       data across networks from the command line. Ncat was written for
       the Nmap Project and is the culmination of the currently
       splintered family of Netcat incarnations. It is designed to be a
       reliable back-end tool to instantly provide network connectivity
       to other applications and users."
874,1,ncat,"It is designed to be a
       reliable back-end tool to instantly provide network connectivity
       to other applications and users. Ncat will not only work with IPv4
       and IPv6 but provides the user with a virtually limitless number
       of potential uses. Among Ncat's vast number of features there is the ability to chain
       Ncats together; redirection of TCP, UDP, and SCTP ports to other
       sites; SSL support; and proxy connections via SOCKS4, SOCKS5 or
       HTTP proxies (with optional proxy authentication as well)."
874,2,ncat,"Ncat will not only work with IPv4
       and IPv6 but provides the user with a virtually limitless number
       of potential uses. Among Ncat's vast number of features there is the ability to chain
       Ncats together; redirection of TCP, UDP, and SCTP ports to other
       sites; SSL support; and proxy connections via SOCKS4, SOCKS5 or
       HTTP proxies (with optional proxy authentication as well). Some
       general principles apply to most applications and thus give you
       the capability of instantly adding networking support to software
       that would normally never support it."
875,0,newgidmap,"The
newgidmap
sets /proc/[pid]/gid_map based on its command line
       arguments and the gids allowed. Subgid delegation can either be
       managed via /etc/subgid or through the configured NSS subid
       module. These options are mutually exclusive."
875,1,newgidmap,"These options are mutually exclusive. Note that the root group is not exempted from the requirement for
       a valid /etc/subgid entry. After the pid argument,
newgidmap
expects sets of 3 integers:

       gid
           Beginning of the range of GIDs inside the user namespace."
875,2,newgidmap,"After the pid argument,
newgidmap
expects sets of 3 integers:

       gid
           Beginning of the range of GIDs inside the user namespace. lowergid
           Beginning of the range of GIDs outside the user namespace. count
           Length of the ranges (both inside and outside the user
           namespace)."
875,3,newgidmap,"count
           Length of the ranges (both inside and outside the user
           namespace). newgidmap
verifies that the caller is the owner of the process
       indicated by
pid
and that for each of the above sets, each of the
       GIDs in the range [lowergid, lowergid+count) is allowed to the
       caller according to /etc/subgid before setting
       /proc/[pid]/gid_map. Note that newgidmap may be used only once for a given process."
875,4,newgidmap,"Note that newgidmap may be used only once for a given process. Instead of an integer process id, the first argument may be
       specified as
fd:N
, where the integer N is the file descriptor
       number for the calling process's opened file descriptor for the
       directory /proc/[pid]. In this case,
newgidmap
will use openat(2)
       to open the gid_map file under that directory, avoiding a TOCTTOU
       in case the process exits and the pid is immediately reused."
876,0,networkctl,"networkctl
may be used to query or modify the state of the network
       links as seen by
systemd-networkd
. Please refer to
systemd-networkd.service(8)
for an introduction to the basic
       concepts, functionality, and configuration syntax."
877,0,newgrp,"The
newgrp
utility shall create a new shell execution environment
       with a new real and effective group identification. Of the
       attributes listed in
Section 2.12
,
Shell Execution Environment
,
       the new shell execution environment shall retain the working
       directory, file creation mask, and exported variables from the
       previous environment (that is, open files, traps, unexported
       variables, alias definitions, shell functions, and
set
options may
       be lost). All other aspects of the process environment that are
       preserved by the
exec
family of functions defined in the System
       Interfaces volume of POSIX.1â2017 shall also be preserved by
newgrp
; whether other aspects are preserved is unspecified."
877,1,newgrp,"All other aspects of the process environment that are
       preserved by the
exec
family of functions defined in the System
       Interfaces volume of POSIX.1â2017 shall also be preserved by
newgrp
; whether other aspects are preserved is unspecified. A failure to assign the new group identifications (for example,
       for security or password-related reasons) shall not prevent the
       new shell execution environment from being created. The
newgrp
utility shall affect the supplemental groups for the
       process as follows:

        *  On systems where the effective group ID is normally in the
           supplementary group list (or whenever the old effective group
           ID actually is in the supplementary group list):

           --  If the new effective group ID is also in the supplementary
               group list,
newgrp
shall change the effective group ID."
877,2,newgrp,"The
newgrp
utility shall affect the supplemental groups for the
       process as follows:

        *  On systems where the effective group ID is normally in the
           supplementary group list (or whenever the old effective group
           ID actually is in the supplementary group list):

           --  If the new effective group ID is also in the supplementary
               group list,
newgrp
shall change the effective group ID. --  If the new effective group ID is not in the supplementary
               group list,
newgrp
shall add the new effective group ID to
               the list, if there is room to add it. *  On systems where the effective group ID is not normally in the
           supplementary group list (or whenever the old effective group
           ID is not in the supplementary group list):

           --  If the new effective group ID is in the supplementary
               group list,
newgrp
shall delete it."
877,3,newgrp,"*  On systems where the effective group ID is not normally in the
           supplementary group list (or whenever the old effective group
           ID is not in the supplementary group list):

           --  If the new effective group ID is in the supplementary
               group list,
newgrp
shall delete it. --  If the old effective group ID is not in the supplementary
               list,
newgrp
shall add it if there is room. Note:
The System Interfaces volume of POSIX.1â2017 does not specify
           whether the effective group ID of a process is included in its
           supplementary group list."
877,4,newgrp,"Note:
The System Interfaces volume of POSIX.1â2017 does not specify
           whether the effective group ID of a process is included in its
           supplementary group list. With no operands,
newgrp
shall change the effective group back to
       the groups identified in the user's user entry, and shall set the
       list of supplementary groups to that set in the user's group
       database entries. If the first argument is
'-'
, the results are unspecified."
877,5,newgrp,"If the first argument is
'-'
, the results are unspecified. If a password is required for the specified group, and the user is
       not listed as a member of that group in the group database, the
       user shall be prompted to enter the correct password for that
       group. If the user is listed as a member of that group, no
       password shall be requested."
877,6,newgrp,"If the user is listed as a member of that group, no
       password shall be requested. If no password is required for the
       specified group, it is implementation-defined whether users not
       listed as members of that group can change to that group. Whether
       or not a password is required, implementation-defined system
       accounting or security mechanisms may impose additional
       authorization restrictions that may cause
newgrp
to write a
       diagnostic message and suppress the changing of the group
       identification."
878,0,newgrp,"The
newgrp
command is used to change the current group ID during a
       login session. If the optional
-
flag is given, the user's
       environment will be reinitialized as though the user had logged
       in, otherwise the current environment, including current working
       directory, remains unchanged. newgrp
changes the current real group ID to the named group, or to
       the default group listed in /etc/passwd if no group name is given."
878,1,newgrp,"newgrp
changes the current real group ID to the named group, or to
       the default group listed in /etc/passwd if no group name is given. newgrp
also tries to add the group to the user groupset. If not
       root, the user will be prompted for a password if she does not
       have a password (in /etc/shadow if this user has an entry in the
       shadowed password file, or in /etc/passwd otherwise) and the group
       does, or if the user is not listed as a member and the group has a
       password."
878,2,newgrp,"If not
       root, the user will be prompted for a password if she does not
       have a password (in /etc/shadow if this user has an entry in the
       shadowed password file, or in /etc/passwd otherwise) and the group
       does, or if the user is not listed as a member and the group has a
       password. The user will be denied access if the group password is
       empty and the user is not listed as a member. If there is an entry for this group in /etc/gshadow, then the list
       of members and the password of this group will be taken from this
       file, otherwise, the entry in /etc/group is considered."
879,0,newhelp,"newhelp
generates the Performance Co-Pilot help text files used by
       Performance Metric Domain Agents (PMDAs). Normally
newhelp
operates on the default Performance Metrics Name
       Space (PMNS), however if the
-n
option is specified an alternative
       namespace is loaded from the file
pmnsfile
. When there is only one input file, the base name of the new
       database is derived from the name of the input
file
, otherwise the
-o
flag must be given to explicitly name the database."
879,1,newhelp,"When there is only one input file, the base name of the new
       database is derived from the name of the input
file
, otherwise the
-o
flag must be given to explicitly name the database. If no
       input files are supplied,
newhelp
reads from the standard input
       stream, in which case the
-o
flag must be given. If the output file name is determined to be
foo
,
newhelp
will
       create
foo.dir
and
foo.pag
."
879,2,newhelp,"If the output file name is determined to be
foo
,
newhelp
will
       create
foo.dir
and
foo.pag
. The
-V
flag causes verbose messages to be printed while
newhelp
is
       parsing its input. The first line of each entry in a help source file consists of an
       ``@'' character beginning the line followed by a space and then
       the performance metric name and a one line description of the
       metric."
879,3,newhelp,"The first line of each entry in a help source file consists of an
       ``@'' character beginning the line followed by a space and then
       the performance metric name and a one line description of the
       metric. Following lines (up to the next line beginning with ``@''
       or end of file) may contain a verbose help description. E.g."
879,4,newhelp,"E.g. #
            # This is an example of newhelp's input syntax
            #
            @ kernel.all.cpu.idle CPU idle time
            A cumulative count of the number of milliseconds
            of CPU idle time, summed over all processors. Three-part numeric metric identifiers (PMIDs) may be used in place
       of metric names, e.g."
879,5,newhelp,"Three-part numeric metric identifiers (PMIDs) may be used in place
       of metric names, e.g. 60.0.23 rather than kernel.all.cpu.idle in
       the example above. Other than for dynamic metrics (where the
       existence of a metric is known to a PMDA, but not visible in the
       PMNS and hence has no name that could be known to
newhelp
) use of
       this syntactic variant is not encouraged."
879,6,newhelp,"Other than for dynamic metrics (where the
       existence of a metric is known to a PMDA, but not visible in the
       PMNS and hence has no name that could be known to
newhelp
) use of
       this syntactic variant is not encouraged. Lines beginning with ``#'' are ignored, as are blank lines in the
       file before the first ``@''. The verbose help text is optional."
879,7,newhelp,"Lines beginning with ``#'' are ignored, as are blank lines in the
       file before the first ``@''. The verbose help text is optional. As a special case, a ``metric'' name of the form
NNN.MM
(for
       numeric
NNN
and
MM
) is interpreted as an instance domain
       identification, and the text describes the instance domain."
880,0,newrole,"Run a new shell in a new context. The new context is derived from
       the old context in which
newrole
is originally executed. If the
-r
or
--role
option is specified, then the new context will have
       the role specified by
ROLE
."
880,1,newrole,"If the
-r
or
--role
option is specified, then the new context will have
       the role specified by
ROLE
. If the
-t
or
--type
option is
       specified, then the new context will have the type (domain)
       specified by
TYPE
. If a role is specified, but no type is
       specified, the default type is derived from the specified role."
880,2,newrole,"If a role is specified, but no type is
       specified, the default type is derived from the specified role. If the
-l
or
--level
option is specified, then the new context
       will have the sensitivity level specified by
LEVEL
. If
LEVEL
is a
       range, the new context will have the sensitivity level and
       clearance specified by that range."
880,3,newrole,"If
LEVEL
is a
       range, the new context will have the sensitivity level and
       clearance specified by that range. If the
-p
or
--preserve-
environment
option is specified, the shell with the new SELinux
       context will preserve environment variables, otherwise a new
       minimal environment is created. Additional arguments
ARGS
may be provided after a -- option, in
       which case they are supplied to the new shell."
880,4,newrole,"Additional arguments
ARGS
may be provided after a -- option, in
       which case they are supplied to the new shell. In particular, an
       argument of -- -c will cause the next argument to be treated as a
       command by most command interpreters. If a command argument is specified to newrole and the command name
       is found in /etc/selinux/newrole_pam.conf, then the pam service
       name listed in that file for the command will be used rather than
       the normal newrole pam configuration."
880,5,newrole,"If a command argument is specified to newrole and the command name
       is found in /etc/selinux/newrole_pam.conf, then the pam service
       name listed in that file for the command will be used rather than
       the normal newrole pam configuration. This allows for per-command
       pam configuration when invoked via newrole, e.g. to skip the
       interactive re-authentication phase."
880,6,newrole,"to skip the
       interactive re-authentication phase. The new shell will be the shell specified in the user's entry in
       the
/etc/passwd
file. The
-V
or
--version
shows the current version of newrole"
881,0,newuidmap,"The
newuidmap
sets /proc/[pid]/uid_map based on its command line
       arguments and the uids allowed. Subuid delegation can either be
       managed via /etc/subuid or through the configured NSS subid
       module. These options are mutually exclusive."
881,1,newuidmap,"These options are mutually exclusive. Note that the root user is not exempted from the requirement for a
       valid /etc/subuid entry. After the pid argument,
newuidmap
expects sets of 3 integers:

       uid
           Beginning of the range of UIDs inside the user namespace."
881,2,newuidmap,"After the pid argument,
newuidmap
expects sets of 3 integers:

       uid
           Beginning of the range of UIDs inside the user namespace. loweruid
           Beginning of the range of UIDs outside the user namespace. count
           Length of the ranges (both inside and outside the user
           namespace)."
881,3,newuidmap,"count
           Length of the ranges (both inside and outside the user
           namespace). newuidmap
verifies that the caller is the owner of the process
       indicated by
pid
and that for each of the above sets, each of the
       UIDs in the range [loweruid, loweruid+count) is allowed to the
       caller according to /etc/subuid before setting
       /proc/[pid]/uid_map. Note that newuidmap may be used only once for a given process."
881,4,newuidmap,"Note that newuidmap may be used only once for a given process. Instead of an integer process id, the first argument may be
       specified as
fd:N
, where the integer N is the file descriptor
       number for the calling process's opened file descriptor for the
       directory /proc/[pid]. In this case,
newuidmap
will use openat(2)
       to open the uid_map file under that directory, avoiding a TOCTTOU
       in case the process exits and the pid is immediately reused."
882,0,nfs4_getfacl,"nfs4_getfacl
will display the NFSv4 Access Control List (ACL) for
       the files given as arguments, provided they are on mounted NFSv4
       filesystems which support ACLs. If the
-H
/
--more-help
flag is specified,
nfs4_getfacl
will print
       some information about NFSv4 ACLs and the fields used in ACEs. If the
-R
/
--recursive
flag is specified,
nfs4_getfacl
will list
       the NFSv4 ACLs of all files and directories recursively."
882,1,nfs4_getfacl,"If the
-R
/
--recursive
flag is specified,
nfs4_getfacl
will list
       the NFSv4 ACLs of all files and directories recursively. If the
-c
/
--omit-header
flag is specified,
nfs4_getfacl
will not
       display the comment header (Do not print filename). If the
--dacl
flag is specified,
nfs4_getfacl
will retrieve the
       dacl."
882,2,nfs4_getfacl,"If the
--dacl
flag is specified,
nfs4_getfacl
will retrieve the
       dacl. This functionality is only available if the server supports
       NFSv4 minor version 1 or newer. If the
--sacl
flag is specified,
nfs4_getfacl
will retrieve the
       sacl."
882,3,nfs4_getfacl,"If the
--sacl
flag is specified,
nfs4_getfacl
will retrieve the
       sacl. This functionality is only available if the server supports
       NFSv4 minor version 1 or newer. The output format for an NFSv4 file ACL, e.g., is:

              # file: /somedir
              A::OWNER@:rwatTnNcCy
              A::alice@nfsdomain.org:rxtncy
              A::bob@nfsdomain.org:rwadtTnNcCy
              A:g:GROUP@:rtncy
              D:g:GROUP@:waxTC
              A::EVERYONE@:rtncy
              D::EVERYONE@:waxTC

       In the example output above, the user `alice@nfsdomain.org' has
       the equivalent of ""read"" and ""execute"" permissions,
       `bob@nfsdomain.org' has ""read"" and ""write"", and both `GROUP@' and
       `EVERYONE@' have ""read""."
882,4,nfs4_getfacl,"The output format for an NFSv4 file ACL, e.g., is:

              # file: /somedir
              A::OWNER@:rwatTnNcCy
              A::alice@nfsdomain.org:rxtncy
              A::bob@nfsdomain.org:rwadtTnNcCy
              A:g:GROUP@:rtncy
              D:g:GROUP@:waxTC
              A::EVERYONE@:rtncy
              D::EVERYONE@:waxTC

       In the example output above, the user `alice@nfsdomain.org' has
       the equivalent of ""read"" and ""execute"" permissions,
       `bob@nfsdomain.org' has ""read"" and ""write"", and both `GROUP@' and
       `EVERYONE@' have ""read"". The ACL listings of multiple files are separated by blank lines. Refer to the
nfs4_acl(5)
manpage for detailed information about
       NFSv4 ACL terminology and syntax."
883,0,nfs4_setfacl,"nfs4_setfacl
manipulates the NFSv4 Access Control List (ACL) of
       one or more
files
(or directories), provided they are on a mounted
       NFSv4 filesystem which supports ACLs. nfs4_editfacl
is equivalent to
nfs4_setfacl -e
. Refer to the
nfs4_acl(5)
manpage for information about NFSv4 ACL
       terminology and syntax."
883,1,nfs4_setfacl,"Refer to the
nfs4_acl(5)
manpage for information about NFSv4 ACL
       terminology and syntax. COMMANDS
-a
acl_spec
add the ACEs from
acl_spec
to
file
's ACL. ACEs are
              inserted starting at the default position 1 of
file
's ACL."
883,2,nfs4_setfacl,"ACEs are
              inserted starting at the default position 1 of
file
's ACL. -A
acl_file
add the ACEs from the acl_spec in
acl_file
to
file
's ACL. ACEs are inserted starting at the default position 1 of
file
's ACL."
883,3,nfs4_setfacl,"ACEs are inserted starting at the default position 1 of
file
's ACL. -x
acl_spec
delete ACEs matched from
acl_spec
from
file
's ACL. Note
              that the ordering of the ACEs in
acl_spec
does not matter."
883,4,nfs4_setfacl,"Note
              that the ordering of the ACEs in
acl_spec
does not matter. -X
acl_file
delete ACEs matched from the acl_spec in
acl_file
from
file
's ACL. Note that the ordering of the ACEs in the
              acl_spec does not matter."
883,5,nfs4_setfacl,"Note that the ordering of the ACEs in the
              acl_spec does not matter. -i
index
ACEs are inserted or deleted starting at the
index
th
              position (DEFAULT: 1) of file's ACL. It can be used only
              with the add or delete action."
883,6,nfs4_setfacl,"It can be used only
              with the add or delete action. -s
acl_spec
set
file
's ACL to
acl_spec
. -S
acl_file
set
file
's ACL to the acl_spec in
acl_file
."
883,7,nfs4_setfacl,"-S
acl_file
set
file
's ACL to the acl_spec in
acl_file
. -e
,
--edit
edit
file
's ACL in the editor defined in the EDITOR
              environment variable (DEFAULT:
vi
(1)) and set the resulting
              ACL upon a clean exit, assuming changes made in the editor
              were saved. Note that if multiple
files
are specified, the
              editor will be serially invoked once per
file
."
883,8,nfs4_setfacl,"Note that if multiple
files
are specified, the
              editor will be serially invoked once per
file
. -m
from_ace to_ace
modify
file
's ACL in-place by replacing
from_ace
with
to_ace
. -?"
883,9,nfs4_setfacl,"-? ,
-h
,
--help
display help text and exit. --version
display this program's version and exit."
883,10,nfs4_setfacl,"--version
display this program's version and exit. NOTE: if '-' is given as the
acl_file
with the
-A
/
-X
/
-S
flags, the
       acl_spec will be read from stdin. OPTIONS
-R
,
--recursive
recursively apply to a directory's files and
              subdirectories."
883,11,nfs4_setfacl,"OPTIONS
-R
,
--recursive
recursively apply to a directory's files and
              subdirectories. Similar to
setfacl(1)
, the default
              behavior is to follow symlinks given on the command line
              and to skip symlinks encountered while recursing through
              directories. -L
,
--logical
in conjunction with
-R
/
--recursive
, a logical walk follows
              all symbolic links."
883,12,nfs4_setfacl,"-L
,
--logical
in conjunction with
-R
/
--recursive
, a logical walk follows
              all symbolic links. -P
,
--physical
in conjunction with
-R
/
--recursive
, a physical walk skips
              all symbolic links. --dacl
acts on the dacl only."
883,13,nfs4_setfacl,"--dacl
acts on the dacl only. This functionality is only available
              if the server supports NFSv4 minor version 1 or newer. --sacl
acts on the sacl only."
883,14,nfs4_setfacl,"--sacl
acts on the sacl only. This functionality is only available
              if the server supports NFSv4 minor version 1 or newer. --test
display results of
COMMAND
, but do not save changes."
884,0,nfs4_setfacl,"nfs4_setfacl
manipulates the NFSv4 Access Control List (ACL) of
       one or more
files
(or directories), provided they are on a mounted
       NFSv4 filesystem which supports ACLs. nfs4_editfacl
is equivalent to
nfs4_setfacl -e
. Refer to the
nfs4_acl(5)
manpage for information about NFSv4 ACL
       terminology and syntax."
884,1,nfs4_setfacl,"Refer to the
nfs4_acl(5)
manpage for information about NFSv4 ACL
       terminology and syntax. COMMANDS
-a
acl_spec
add the ACEs from
acl_spec
to
file
's ACL. ACEs are
              inserted starting at the default position 1 of
file
's ACL."
884,2,nfs4_setfacl,"ACEs are
              inserted starting at the default position 1 of
file
's ACL. -A
acl_file
add the ACEs from the acl_spec in
acl_file
to
file
's ACL. ACEs are inserted starting at the default position 1 of
file
's ACL."
884,3,nfs4_setfacl,"ACEs are inserted starting at the default position 1 of
file
's ACL. -x
acl_spec
delete ACEs matched from
acl_spec
from
file
's ACL. Note
              that the ordering of the ACEs in
acl_spec
does not matter."
884,4,nfs4_setfacl,"Note
              that the ordering of the ACEs in
acl_spec
does not matter. -X
acl_file
delete ACEs matched from the acl_spec in
acl_file
from
file
's ACL. Note that the ordering of the ACEs in the
              acl_spec does not matter."
884,5,nfs4_setfacl,"Note that the ordering of the ACEs in the
              acl_spec does not matter. -i
index
ACEs are inserted or deleted starting at the
index
th
              position (DEFAULT: 1) of file's ACL. It can be used only
              with the add or delete action."
884,6,nfs4_setfacl,"It can be used only
              with the add or delete action. -s
acl_spec
set
file
's ACL to
acl_spec
. -S
acl_file
set
file
's ACL to the acl_spec in
acl_file
."
884,7,nfs4_setfacl,"-S
acl_file
set
file
's ACL to the acl_spec in
acl_file
. -e
,
--edit
edit
file
's ACL in the editor defined in the EDITOR
              environment variable (DEFAULT:
vi
(1)) and set the resulting
              ACL upon a clean exit, assuming changes made in the editor
              were saved. Note that if multiple
files
are specified, the
              editor will be serially invoked once per
file
."
884,8,nfs4_setfacl,"Note that if multiple
files
are specified, the
              editor will be serially invoked once per
file
. -m
from_ace to_ace
modify
file
's ACL in-place by replacing
from_ace
with
to_ace
. -?"
884,9,nfs4_setfacl,"-? ,
-h
,
--help
display help text and exit. --version
display this program's version and exit."
884,10,nfs4_setfacl,"--version
display this program's version and exit. NOTE: if '-' is given as the
acl_file
with the
-A
/
-X
/
-S
flags, the
       acl_spec will be read from stdin. OPTIONS
-R
,
--recursive
recursively apply to a directory's files and
              subdirectories."
884,11,nfs4_setfacl,"OPTIONS
-R
,
--recursive
recursively apply to a directory's files and
              subdirectories. Similar to
setfacl(1)
, the default
              behavior is to follow symlinks given on the command line
              and to skip symlinks encountered while recursing through
              directories. -L
,
--logical
in conjunction with
-R
/
--recursive
, a logical walk follows
              all symbolic links."
884,12,nfs4_setfacl,"-L
,
--logical
in conjunction with
-R
/
--recursive
, a logical walk follows
              all symbolic links. -P
,
--physical
in conjunction with
-R
/
--recursive
, a physical walk skips
              all symbolic links. --dacl
acts on the dacl only."
884,13,nfs4_setfacl,"--dacl
acts on the dacl only. This functionality is only available
              if the server supports NFSv4 minor version 1 or newer. --sacl
acts on the sacl only."
884,14,nfs4_setfacl,"--sacl
acts on the sacl only. This functionality is only available
              if the server supports NFSv4 minor version 1 or newer. --test
display results of
COMMAND
, but do not save changes."
885,0,ngettext,"The
ngettext
program translates a natural language message into
       the user's language, by looking up the translation in a message
       catalog, and chooses the appropriate plural form, which depends on
       the number
COUNT
and the language of the message catalog where the
       translation was found. Display native language translation of a textual message whose
       grammatical form depends on a number. -d
,
--domain
=
TEXTDOMAIN
retrieve translated message from TEXTDOMAIN
-c
,
--context
=
CONTEXT
specify context for MSGID
-e
enable expansion of some escape sequences
-E
(ignored for compatibility)

       [TEXTDOMAIN]
              retrieve translated message from TEXTDOMAIN

       MSGID MSGID-PLURAL
              translate MSGID (singular) / MSGID-PLURAL (plural)

       COUNT  choose singular/plural form based on this value
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
display version information and exit

       If the TEXTDOMAIN parameter is not given, the domain is determined
       from the environment variable TEXTDOMAIN."
885,1,ngettext,"-d
,
--domain
=
TEXTDOMAIN
retrieve translated message from TEXTDOMAIN
-c
,
--context
=
CONTEXT
specify context for MSGID
-e
enable expansion of some escape sequences
-E
(ignored for compatibility)

       [TEXTDOMAIN]
              retrieve translated message from TEXTDOMAIN

       MSGID MSGID-PLURAL
              translate MSGID (singular) / MSGID-PLURAL (plural)

       COUNT  choose singular/plural form based on this value
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
display version information and exit

       If the TEXTDOMAIN parameter is not given, the domain is determined
       from the environment variable TEXTDOMAIN. If the message catalog
       is not found in the regular directory, another location can be
       specified with the environment variable TEXTDOMAINDIR. Standard
       search directory: /usr/local/share/locale"
886,0,nfsvis,"nfsvis
displays a three dimensional bar chart of NFS request
       statistics. The display is updated with new values retrieved from
       the target
host
or
archive
every
interval
seconds (default is 2
       seconds). Two blocks of statistics are displayed - one for the NFS server
       and one for the NFS client requests."
886,1,nfsvis,"Two blocks of statistics are displayed - one for the NFS server
       and one for the NFS client requests. The height of the bars is
       proportional to the rate at which the various request types are
       processed. nfsvis
generates a
pmview(1)
configuration file, and passes most
       command line options to
pmview(1)
."
886,2,nfsvis,"The height of the bars is
       proportional to the rate at which the various request types are
       processed. nfsvis
generates a
pmview(1)
configuration file, and passes most
       command line options to
pmview(1)
. Therefore, the command line
       options
-A
,
-a
,
-C
,
-h
,
-n
,
-O
,
-p
,
-S
,
-t
,
-T
,
-Z
and
-z
, and the
       user interface are described in the
pmview(1)
man page."
887,0,nice,"Run COMMAND with an adjusted niceness, which affects process
       scheduling. With no COMMAND, print the current niceness. Niceness values range from
-20
(most favorable to the process) to
       19 (least favorable to the process)."
887,1,nice,"Niceness values range from
-20
(most favorable to the process) to
       19 (least favorable to the process). Mandatory arguments to long options are mandatory for short
       options too. -n
,
--adjustment
=
N
add integer N to the niceness (default 10)
--help
display this help and exit
--version
output version information and exit

       Your shell may have its own version of nice, which usually
       supersedes the version described here."
887,2,nice,"-n
,
--adjustment
=
N
add integer N to the niceness (default 10)
--help
display this help and exit
--version
output version information and exit

       Your shell may have its own version of nice, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports. Exit status:
125    if the nice command itself fails

       126    if COMMAND is found but cannot be invoked

       127    if COMMAND cannot be found

       -      the exit status of COMMAND otherwise"
888,0,hostname,"Hostname
is the program that is used to either set or display the
       current host, domain or node name of the system. These names are
       used by many of the networking programs to identify the machine. The domain name is also used by NIS/YP."
888,1,hostname,"The domain name is also used by NIS/YP. GET NAME
When called without any arguments, the program displays the
       current names:
hostname
will print the name of the system as returned by the
gethostname(2)
function. domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function."
888,2,hostname,"domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function. This is also
       known as the YP/NIS domain name of the system. nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function."
888,3,hostname,"nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function. dnsdomainname
will print the domain part of the FQDN (Fully
       Qualified Domain Name). The complete FQDN of the system is
       returned with
hostname --fqdn
."
888,4,hostname,"The complete FQDN of the system is
       returned with
hostname --fqdn
. SET NAME
When called with one argument or with the
--file
option, the
       commands set the host name, the NIS/YP domain name or the node
       name. Note, that only the super-user can change the names."
888,5,hostname,"Note, that only the super-user can change the names. It is not possible to set the FQDN or the DNS domain name with the
dnsdomainname
command (see
THE FQDN
below). The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g."
888,6,hostname,"The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g. /etc/hostname
). THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command."
888,7,hostname,"THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command. The FQDN of the system is the name that the
resolver(3)
returns
       for the host name. Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name."
888,8,hostname,"Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name. The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it."
888,9,hostname,"The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it. If
hosts
is the first
       lookup method, you can change the FQDN in
/etc/hosts
."
889,0,nl,"Write each FILE to standard output, with line numbers added. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
889,1,nl,"Mandatory arguments to long options are mandatory for short
       options too. -b
,
--body-numbering
=
STYLE
use STYLE for numbering body lines
-d
,
--section-delimiter
=
CC
use CC for logical page delimiters
-f
,
--footer-numbering
=
STYLE
use STYLE for numbering footer lines
-h
,
--header-numbering
=
STYLE
use STYLE for numbering header lines
-i
,
--line-increment
=
NUMBER
line number increment at each line
-l
,
--join-blank-lines
=
NUMBER
group of NUMBER empty lines counted as one
-n
,
--number-format
=
FORMAT
insert line numbers according to FORMAT
-p
,
--no-renumber
do not reset line numbers for each section
-s
,
--number-separator
=
STRING
add STRING after (possible) line number
-v
,
--starting-line-number
=
NUMBER
first line number for each section
-w
,
--number-width
=
NUMBER
use NUMBER columns for line numbers
--help
display this help and exit
--version
output version information and exit

       Default options are:
-bt -d
'\:'
-fn -hn -i1 -l1 -n
'rn'
-s
<TAB>
-v1
-w6
CC are two delimiter characters used to construct logical page
       delimiters; a missing second character implies ':'. As a GNU
       extension one can specify more than two characters, and also
       specifying the empty string (
-d
'') disables section matching."
889,2,nl,"-b
,
--body-numbering
=
STYLE
use STYLE for numbering body lines
-d
,
--section-delimiter
=
CC
use CC for logical page delimiters
-f
,
--footer-numbering
=
STYLE
use STYLE for numbering footer lines
-h
,
--header-numbering
=
STYLE
use STYLE for numbering header lines
-i
,
--line-increment
=
NUMBER
line number increment at each line
-l
,
--join-blank-lines
=
NUMBER
group of NUMBER empty lines counted as one
-n
,
--number-format
=
FORMAT
insert line numbers according to FORMAT
-p
,
--no-renumber
do not reset line numbers for each section
-s
,
--number-separator
=
STRING
add STRING after (possible) line number
-v
,
--starting-line-number
=
NUMBER
first line number for each section
-w
,
--number-width
=
NUMBER
use NUMBER columns for line numbers
--help
display this help and exit
--version
output version information and exit

       Default options are:
-bt -d
'\:'
-fn -hn -i1 -l1 -n
'rn'
-s
<TAB>
-v1
-w6
CC are two delimiter characters used to construct logical page
       delimiters; a missing second character implies ':'. As a GNU
       extension one can specify more than two characters, and also
       specifying the empty string (
-d
'') disables section matching. STYLE is one of:

       a      number all lines

       t      number only nonempty lines

       n      number no lines

       pBRE   number only lines that contain a match for the basic
              regular expression, BRE

       FORMAT is one of:

       ln     left justified, no leading zeros

       rn     right justified, no leading zeros

       rz     right justified, leading zeros"
890,0,nice,"The
nice
utility shall invoke a utility, requesting that it be run
       with a different nice value (see the Base Definitions volume of
       POSIX.1â2017,
Section 3.244
,
Nice Value
).  With no options, the
       executed utility shall be run with a nice value that is some
       implementation-defined quantity greater than or equal to the nice
       value of the current process. If the user lacks appropriate
       privileges to affect the nice value in the requested manner, the
nice
utility shall not affect the nice value; in this case, a
       warning message may be written to standard error, but this shall
       not prevent the invocation of
utility
or affect the exit status."
891,0,nitrocli,"nitrocli
provides access to Nitrokey devices. It supports the
       Nitrokey Pro, the Nitrokey Storage, and the Librem Key. It can be
       used to access the encrypted volume, the one-time password
       generator, and the password safe."
891,1,nitrocli,"It can be
       used to access the encrypted volume, the one-time password
       generator, and the password safe. Device selection
Per default,
nitrocli
connects to any attached Nitrokey device. You can use the
--model
,
--serial-number
and
--usb-path
options to
       select the device to connect to."
891,2,nitrocli,"You can use the
--model
,
--serial-number
and
--usb-path
options to
       select the device to connect to. nitrocli
fails if more than one
       attached Nitrokey device matches this filter or if multiple
       Nitrokey devices are attached and none of the filter options is
       set. Use the
list
command to list all attached devices with their
       USB path, model, and serial number (if available)."
892,0,nl,"The
nl
utility shall read lines from the named
file
or the
       standard input if no
file
is named and shall reproduce the lines
       to standard output. Lines shall be numbered on the left. Additional functionality may be provided in accordance with the
       command options in effect."
892,1,nl,"Additional functionality may be provided in accordance with the
       command options in effect. The
nl
utility views the text it reads in terms of logical pages. Line numbering shall be reset at the start of each logical page."
892,2,nl,"Line numbering shall be reset at the start of each logical page. A
       logical page consists of a header, a body, and a footer section. Empty sections are valid."
892,3,nl,"Empty sections are valid. Different line numbering options are
       independently available for header, body, and footer (for example,
       no numbering of header and footer lines while numbering blank
       lines only in the body). The starts of logical page sections shall be signaled by input
       lines containing nothing but the following delimiter characters:
                          ââââââââââââââ¬âââââââââââââ
                          â
Line
â
Start of
â
                          ââââââââââââââ¼âââââââââââââ¤
                          â \:\:\:     â Header     â
                          â \:\:       â Body       â
                          â \:         â Footer     â
                          ââââââââââââââ´âââââââââââââ

       Unless otherwise specified,
nl
shall assume the text being read is
       in a single logical page body."
893,0,nm,"The
nm
utility shall display symbolic information appearing in the
       object file, executable file, or object-file library named by
file
. If no symbolic information is available for a valid input
       file, the
nm
utility shall report that fact, but not consider it
       an error condition. The default base used when numeric values are written is
       unspecified."
893,1,nm,"If no symbolic information is available for a valid input
       file, the
nm
utility shall report that fact, but not consider it
       an error condition. The default base used when numeric values are written is
       unspecified. On XSI-conformant systems, it shall be decimal if
       the
-P
option is not specified."
894,0,nm,"GNU
nm
lists the symbols from object files
objfile
.... If no
       object files are listed as arguments,
nm
assumes the file
a.out
. For each symbol,
nm
shows:

       â¢   The symbol value, in the radix selected by options (see
           below), or hexadecimal by default."
894,1,nm,"For each symbol,
nm
shows:

       â¢   The symbol value, in the radix selected by options (see
           below), or hexadecimal by default. â¢   The symbol type. At least the following types are used;
           others are, as well, depending on the object file format."
894,2,nm,"At least the following types are used;
           others are, as well, depending on the object file format. If
           lowercase, the symbol is usually local; if uppercase, the
           symbol is global (external). There are however a few
           lowercase symbols that are shown for special global symbols
           (""u"", ""v"" and ""w"")."
894,3,nm,"There are however a few
           lowercase symbols that are shown for special global symbols
           (""u"", ""v"" and ""w""). ""A"" The symbol's value is absolute, and will not be changed by
               further linking. ""B""
           ""b"" The symbol is in the BSS data section."
894,4,nm,"""B""
           ""b"" The symbol is in the BSS data section. This section
               typically contains zero-initialized or uninitialized data,
               although the exact behavior is system dependent. ""C""
           ""c"" The symbol is common."
894,5,nm,"""C""
           ""c"" The symbol is common. Common symbols are uninitialized
               data. When linking, multiple common symbols may appear
               with the same name."
894,6,nm,"When linking, multiple common symbols may appear
               with the same name. If the symbol is defined anywhere,
               the common symbols are treated as undefined references. The lower case
c
character is used when the symbol is in a
               special section for small commons."
894,7,nm,"The lower case
c
character is used when the symbol is in a
               special section for small commons. ""D""
           ""d"" The symbol is in the initialized data section. ""G""
           ""g"" The symbol is in an initialized data section for small
               objects."
894,8,nm,"""G""
           ""g"" The symbol is in an initialized data section for small
               objects. Some object file formats permit more efficient
               access to small data objects, such as a global int
               variable as opposed to a large global array. ""i"" For PE format files this indicates that the symbol is in a
               section specific to the implementation of DLLs."
894,9,nm,"""i"" For PE format files this indicates that the symbol is in a
               section specific to the implementation of DLLs. For ELF format files this indicates that the symbol is an
               indirect function. This is a GNU extension to the
               standard set of ELF symbol types."
894,10,nm,"This is a GNU extension to the
               standard set of ELF symbol types. It indicates a symbol
               which if referenced by a relocation does not evaluate to
               its address, but instead must be invoked at runtime. The
               runtime execution will then return the value to be used in
               the relocation."
894,11,nm,"The
               runtime execution will then return the value to be used in
               the relocation. Note - the actual symbols display for GNU indirect symbols
               is controlled by the
--ifunc-chars
command line option. If this option has been provided then the first character
               in the string will be used for global indirect function
               symbols."
894,12,nm,"If this option has been provided then the first character
               in the string will be used for global indirect function
               symbols. If the string contains a second character then
               that will be used for local indirect function symbols. ""I"" The symbol is an indirect reference to another symbol."
894,13,nm,"""I"" The symbol is an indirect reference to another symbol. ""N"" The symbol is a debugging symbol. ""n"" The symbol is in a non-data, non-code, non-debug read-only
               section."
894,14,nm,"""n"" The symbol is in a non-data, non-code, non-debug read-only
               section. ""p"" The symbol is in a stack unwind section. ""R""
           ""r"" The symbol is in a read only data section."
894,15,nm,"""R""
           ""r"" The symbol is in a read only data section. ""S""
           ""s"" The symbol is in an uninitialized or zero-initialized data
               section for small objects. ""T""
           ""t"" The symbol is in the text (code) section."
894,16,nm,"""T""
           ""t"" The symbol is in the text (code) section. ""U"" The symbol is undefined. ""u"" The symbol is a unique global symbol."
894,17,nm,"""u"" The symbol is a unique global symbol. This is a GNU
               extension to the standard set of ELF symbol bindings. For
               such a symbol the dynamic linker will make sure that in
               the entire process there is just one symbol with this name
               and type in use."
894,18,nm,"For
               such a symbol the dynamic linker will make sure that in
               the entire process there is just one symbol with this name
               and type in use. ""V""
           ""v"" The symbol is a weak object. When a weak defined symbol
               is linked with a normal defined symbol, the normal defined
               symbol is used with no error."
894,19,nm,"When a weak defined symbol
               is linked with a normal defined symbol, the normal defined
               symbol is used with no error. When a weak undefined
               symbol is linked and the symbol is not defined, the value
               of the weak symbol becomes zero with no error. On some
               systems, uppercase indicates that a default value has been
               specified."
894,20,nm,"On some
               systems, uppercase indicates that a default value has been
               specified. ""W""
           ""w"" The symbol is a weak symbol that has not been specifically
               tagged as a weak object symbol. When a weak defined
               symbol is linked with a normal defined symbol, the normal
               defined symbol is used with no error."
894,21,nm,"When a weak defined
               symbol is linked with a normal defined symbol, the normal
               defined symbol is used with no error. When a weak
               undefined symbol is linked and the symbol is not defined,
               the value of the symbol is determined in a system-specific
               manner without error. On some systems, uppercase
               indicates that a default value has been specified."
894,22,nm,"On some systems, uppercase
               indicates that a default value has been specified. ""-"" The symbol is a stabs symbol in an a.out object file. In
               this case, the next values printed are the stabs other
               field, the stabs desc field, and the stab type."
894,23,nm,"In
               this case, the next values printed are the stabs other
               field, the stabs desc field, and the stab type. Stabs
               symbols are used to hold debugging information. ""?"" The symbol type is unknown, or object file format
               specific."
894,24,nm,"""?"" The symbol type is unknown, or object file format
               specific. â¢   The symbol name. If a symbol has version information
           associated with it, then the version information is displayed
           as well."
894,25,nm,"If a symbol has version information
           associated with it, then the version information is displayed
           as well. If the versioned symbol is undefined or hidden from
           linker, the version string is displayed as a suffix to the
           symbol name, preceded by an @ character. For example
foo@VER_1
."
894,26,nm,"For example
foo@VER_1
. If the version is the default version to be used
           when resolving unversioned references to the symbol, then it
           is displayed as a suffix preceded by two @ characters. For
           example
foo@@VER_2
."
895,0,hostname,"Hostname
is the program that is used to either set or display the
       current host, domain or node name of the system. These names are
       used by many of the networking programs to identify the machine. The domain name is also used by NIS/YP."
895,1,hostname,"The domain name is also used by NIS/YP. GET NAME
When called without any arguments, the program displays the
       current names:
hostname
will print the name of the system as returned by the
gethostname(2)
function. domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function."
895,2,hostname,"domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function. This is also
       known as the YP/NIS domain name of the system. nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function."
895,3,hostname,"nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function. dnsdomainname
will print the domain part of the FQDN (Fully
       Qualified Domain Name). The complete FQDN of the system is
       returned with
hostname --fqdn
."
895,4,hostname,"The complete FQDN of the system is
       returned with
hostname --fqdn
. SET NAME
When called with one argument or with the
--file
option, the
       commands set the host name, the NIS/YP domain name or the node
       name. Note, that only the super-user can change the names."
895,5,hostname,"Note, that only the super-user can change the names. It is not possible to set the FQDN or the DNS domain name with the
dnsdomainname
command (see
THE FQDN
below). The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g."
895,6,hostname,"The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g. /etc/hostname
). THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command."
895,7,hostname,"THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command. The FQDN of the system is the name that the
resolver(3)
returns
       for the host name. Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name."
895,8,hostname,"Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name. The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it."
895,9,hostname,"The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it. If
hosts
is the first
       lookup method, you can change the FQDN in
/etc/hosts
."
896,0,nohup,"Run COMMAND, ignoring hangup signals. --help
display this help and exit
--version
output version information and exit

       If standard input is a terminal, redirect it from an unreadable
       file. If standard output is a terminal, append output to
       'nohup.out' if possible, '$HOME/nohup.out' otherwise."
896,1,nohup,"If standard output is a terminal, append output to
       'nohup.out' if possible, '$HOME/nohup.out' otherwise. If standard
       error is a terminal, redirect it to standard output. To save
       output to FILE, use 'nohup COMMAND > FILE'."
896,2,nohup,"To save
       output to FILE, use 'nohup COMMAND > FILE'. Your shell may have its own version of nohup, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports."
896,3,nohup,"Your shell may have its own version of nohup, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports. Exit status:
125    if the nohup command itself fails

       126    if COMMAND is found but cannot be invoked

       127    if COMMAND cannot be found

       -      the exit status of COMMAND otherwise"
897,0,nohup,"The
nohup
utility shall invoke the utility named by the
utility
operand with arguments supplied as the
argument
operands. At the
       time the named
utility
is invoked, the SIGHUP signal shall be set
       to be ignored. If standard input is associated with a terminal, the
nohup
utility
       may redirect standard input from an unspecified file."
897,1,nohup,"If standard input is associated with a terminal, the
nohup
utility
       may redirect standard input from an unspecified file. If the standard output is a terminal, all output written by the
       named
utility
to its standard output shall be appended to the end
       of the file
nohup.out
in the current directory. If
nohup.out
cannot be created or opened for appending, the output shall be
       appended to the end of the file
nohup.out
in the directory
       specified by the
HOME
environment variable."
897,2,nohup,"If
nohup.out
cannot be created or opened for appending, the output shall be
       appended to the end of the file
nohup.out
in the directory
       specified by the
HOME
environment variable. If neither file can be
       created or opened for appending,
utility
shall not be invoked. If
       a file is created, the file's permission bits shall be set to
       S_IRUSR | S_IWUSR."
897,3,nohup,"If
       a file is created, the file's permission bits shall be set to
       S_IRUSR | S_IWUSR. If standard error is a terminal and standard output is open but is
       not a terminal, all output written by the named utility to its
       standard error shall be redirected to the same open file
       description as the standard output. If standard error is a
       terminal and standard output either is a terminal or is closed,
       the same output shall instead be appended to the end of the
nohup.out
file as described above."
898,0,nmap,"Nmap (âNetwork Mapperâ) is an open source tool for network
       exploration and security auditing. It was designed to rapidly scan
       large networks, although it works fine against single hosts. Nmap
       uses raw IP packets in novel ways to determine what hosts are
       available on the network, what services (application name and
       version) those hosts are offering, what operating systems (and OS
       versions) they are running, what type of packet filters/firewalls
       are in use, and dozens of other characteristics."
898,1,nmap,"Nmap
       uses raw IP packets in novel ways to determine what hosts are
       available on the network, what services (application name and
       version) those hosts are offering, what operating systems (and OS
       versions) they are running, what type of packet filters/firewalls
       are in use, and dozens of other characteristics. While Nmap is
       commonly used for security audits, many systems and network
       administrators find it useful for routine tasks such as network
       inventory, managing service upgrade schedules, and monitoring host
       or service uptime. The output from Nmap is a list of scanned targets, with
       supplemental information on each depending on the options used."
898,2,nmap,"The output from Nmap is a list of scanned targets, with
       supplemental information on each depending on the options used. Key among that information is the âinteresting ports tableâ. That
       table lists the port number and protocol, service name, and state."
898,3,nmap,"That
       table lists the port number and protocol, service name, and state. The state is either open, filtered, closed, or unfiltered. Open
       means that an application on the target machine is listening for
       connections/packets on that port."
898,4,nmap,"Open
       means that an application on the target machine is listening for
       connections/packets on that port. Filtered means that a firewall,
       filter, or other network obstacle is blocking the port so that
       Nmap cannot tell whether it is open or closed. Closed ports have
       no application listening on them, though they could open up at any
       time."
898,5,nmap,"Closed ports have
       no application listening on them, though they could open up at any
       time. Ports are classified as unfiltered when they are responsive
       to Nmap's probes, but Nmap cannot determine whether they are open
       or closed. Nmap reports the state combinations open|filtered and
       closed|filtered when it cannot determine which of the two states
       describe a port."
898,6,nmap,"Nmap reports the state combinations open|filtered and
       closed|filtered when it cannot determine which of the two states
       describe a port. The port table may also include software version
       details when version detection has been requested. When an IP
       protocol scan is requested (
-sO
), Nmap provides information on
       supported IP protocols rather than listening ports."
898,7,nmap,"When an IP
       protocol scan is requested (
-sO
), Nmap provides information on
       supported IP protocols rather than listening ports. In addition to the interesting ports table, Nmap can provide
       further information on targets, including reverse DNS names,
       operating system guesses, device types, and MAC addresses. A typical Nmap scan is shown in Example 1."
898,8,nmap,"A typical Nmap scan is shown in Example 1. The only Nmap arguments
       used in this example are
-A
, to enable OS and version detection,
       script scanning, and traceroute;
-T4
for faster execution; and
       then the hostname. Example 1."
898,9,nmap,"Example 1. A representative Nmap scan
#
nmap -A -T4 scanme.nmap.org
Nmap scan report for scanme.nmap.org (74.207.244.221)
           Host is up (0.029s latency). rDNS record for 74.207.244.221: li86-221.members.linode.com
           Not shown: 995 closed ports
           PORT     STATE    SERVICE     VERSION
           22/tcp   open     ssh         OpenSSH 5.3p1 Debian 3ubuntu7 (protocol 2.0)
           | ssh-hostkey: 1024 8d:60:f1:7c:ca:b7:3d:0a:d6:67:54:9d:69:d9:b9:dd (DSA)
           |_2048 79:f8:09:ac:d4:e2:32:42:10:49:d3:bd:20:82:85:ec (RSA)
           80/tcp   open     http        Apache httpd 2.2.14 ((Ubuntu))
           |_http-title: Go ahead and ScanMe!"
898,10,nmap,"rDNS record for 74.207.244.221: li86-221.members.linode.com
           Not shown: 995 closed ports
           PORT     STATE    SERVICE     VERSION
           22/tcp   open     ssh         OpenSSH 5.3p1 Debian 3ubuntu7 (protocol 2.0)
           | ssh-hostkey: 1024 8d:60:f1:7c:ca:b7:3d:0a:d6:67:54:9d:69:d9:b9:dd (DSA)
           |_2048 79:f8:09:ac:d4:e2:32:42:10:49:d3:bd:20:82:85:ec (RSA)
           80/tcp   open     http        Apache httpd 2.2.14 ((Ubuntu))
           |_http-title: Go ahead and ScanMe! 646/tcp  filtered ldp
           1720/tcp filtered H.323/Q.931
           9929/tcp open     nping-echo  Nping echo
           Device type: general purpose
           Running: Linux 2.6.X
           OS CPE: cpe:/o:linux:linux_kernel:2.6.39
           OS details: Linux 2.6.39
           Network Distance: 11 hops
           Service Info: OS: Linux; CPE: cpe:/o:linux:kernel

           TRACEROUTE (using port 53/tcp)
           HOP RTT      ADDRESS
           [Cut first 10 hops for brevity]
           11  17.65 ms li86-221.members.linode.com (74.207.244.221)

           Nmap done: 1 IP address (1 host up) scanned in 14.40 seconds

       The newest version of Nmap can be obtained from
https://nmap.org
. The newest version of this man page is available at
https://nmap.org/book/man.html
."
898,11,nmap,"646/tcp  filtered ldp
           1720/tcp filtered H.323/Q.931
           9929/tcp open     nping-echo  Nping echo
           Device type: general purpose
           Running: Linux 2.6.X
           OS CPE: cpe:/o:linux:linux_kernel:2.6.39
           OS details: Linux 2.6.39
           Network Distance: 11 hops
           Service Info: OS: Linux; CPE: cpe:/o:linux:kernel

           TRACEROUTE (using port 53/tcp)
           HOP RTT      ADDRESS
           [Cut first 10 hops for brevity]
           11  17.65 ms li86-221.members.linode.com (74.207.244.221)

           Nmap done: 1 IP address (1 host up) scanned in 14.40 seconds

       The newest version of Nmap can be obtained from
https://nmap.org
. The newest version of this man page is available at
https://nmap.org/book/man.html
. It is also included as a chapter
       of Nmap Network Scanning: The Official Nmap Project Guide to
       Network Discovery and Security Scanning (see
https://nmap.org/book/
)."
899,0,nproc,"Print the number of processing units available to the current
       process, which may be less than the number of online processors
--all
print the number of installed processors
--ignore
=
N
if possible, exclude N processing units
--help
display this help and exit
--version
output version information and exit"
900,0,nroff,nan
901,0,nping,"Nping is an open-source tool for network packet generation,
       response analysis and response time measurement. Nping allows
       users to generate network packets of a wide range of protocols,
       letting them tune virtually any field of the protocol headers. While Nping can be used as a simple ping utility to detect active
       hosts, it can also be used as a raw packet generator for network
       stack stress tests, ARP poisoning, Denial of Service attacks,
       route tracing, and other purposes."
901,1,nping,"While Nping can be used as a simple ping utility to detect active
       hosts, it can also be used as a raw packet generator for network
       stack stress tests, ARP poisoning, Denial of Service attacks,
       route tracing, and other purposes. Additionally, Nping offers a special mode of operation called the
       ""Echo Mode"", that lets users see how the generated probes change
       in transit, revealing the differences between the transmitted
       packets and the packets received at the other end. See section
       ""Echo Mode"" for details."
901,2,nping,"See section
       ""Echo Mode"" for details. The output from Nping is a list of the packets that are being sent
       and received. The level of detail depends on the options used."
901,3,nping,"The level of detail depends on the options used. A typical Nping execution is shown in Example 1. The only Nping
       arguments used in this example are
-c
, to specify the number of
       times to target each host,
--tcp
to specify TCP Probe Mode,
-p
80,433
to specify the target ports; and then the two target
       hostnames."
901,4,nping,"The only Nping
       arguments used in this example are
-c
, to specify the number of
       times to target each host,
--tcp
to specify TCP Probe Mode,
-p
80,433
to specify the target ports; and then the two target
       hostnames. Example 1. A representative Nping execution
#
nping -c 1 --tcp -p 80,433 scanme.nmap.org google.com
Starting Nping (
https://nmap.org/nping
)
           SENT (0.0120s) TCP 96.16.226.135:50091 > 64.13.134.52:80 S ttl=64 id=52072 iplen=40  seq=1077657388 win=1480
           RCVD (0.1810s) TCP 64.13.134.52:80 > 96.16.226.135:50091 SA ttl=53 id=0 iplen=44  seq=4158134847 win=5840 <mss 1460>
           SENT (1.0140s) TCP 96.16.226.135:50091 > 74.125.45.100:80 S ttl=64 id=13932 iplen=40  seq=1077657388 win=1480
           RCVD (1.1370s) TCP 74.125.45.100:80 > 96.16.226.135:50091 SA ttl=52 id=52913 iplen=44  seq=2650443864 win=5720 <mss 1430>
           SENT (2.0140s) TCP 96.16.226.135:50091 > 64.13.134.52:433 S ttl=64 id=8373 iplen=40  seq=1077657388 win=1480
           SENT (3.0140s) TCP 96.16.226.135:50091 > 74.125.45.100:433 S ttl=64 id=23624 iplen=40  seq=1077657388 win=1480

           Statistics for host scanme.nmap.org (64.13.134.52):
            |  Probes Sent: 2 | Rcvd: 1 | Lost: 1  (50.00%)
            |_ Max rtt: 169.720ms | Min rtt: 169.720ms | Avg rtt: 169.720ms
           Statistics for host google.com (74.125.45.100):
            |  Probes Sent: 2 | Rcvd: 1 | Lost: 1  (50.00%)
            |_ Max rtt: 122.686ms | Min rtt: 122.686ms | Avg rtt: 122.686ms
           Raw packets sent: 4 (160B) | Rcvd: 2 (92B) | Lost: 2 (50.00%)
           Tx time: 3.00296s | Tx bytes/s: 53.28 | Tx pkts/s: 1.33
           Rx time: 3.00296s | Rx bytes/s: 30.64 | Rx pkts/s: 0.67
           Nping done: 2 IP addresses pinged in 4.01 seconds

       The newest version of Nping can be obtained with Nmap at
https://nmap.org
."
901,5,nping,"A representative Nping execution
#
nping -c 1 --tcp -p 80,433 scanme.nmap.org google.com
Starting Nping (
https://nmap.org/nping
)
           SENT (0.0120s) TCP 96.16.226.135:50091 > 64.13.134.52:80 S ttl=64 id=52072 iplen=40  seq=1077657388 win=1480
           RCVD (0.1810s) TCP 64.13.134.52:80 > 96.16.226.135:50091 SA ttl=53 id=0 iplen=44  seq=4158134847 win=5840 <mss 1460>
           SENT (1.0140s) TCP 96.16.226.135:50091 > 74.125.45.100:80 S ttl=64 id=13932 iplen=40  seq=1077657388 win=1480
           RCVD (1.1370s) TCP 74.125.45.100:80 > 96.16.226.135:50091 SA ttl=52 id=52913 iplen=44  seq=2650443864 win=5720 <mss 1430>
           SENT (2.0140s) TCP 96.16.226.135:50091 > 64.13.134.52:433 S ttl=64 id=8373 iplen=40  seq=1077657388 win=1480
           SENT (3.0140s) TCP 96.16.226.135:50091 > 74.125.45.100:433 S ttl=64 id=23624 iplen=40  seq=1077657388 win=1480

           Statistics for host scanme.nmap.org (64.13.134.52):
            |  Probes Sent: 2 | Rcvd: 1 | Lost: 1  (50.00%)
            |_ Max rtt: 169.720ms | Min rtt: 169.720ms | Avg rtt: 169.720ms
           Statistics for host google.com (74.125.45.100):
            |  Probes Sent: 2 | Rcvd: 1 | Lost: 1  (50.00%)
            |_ Max rtt: 122.686ms | Min rtt: 122.686ms | Avg rtt: 122.686ms
           Raw packets sent: 4 (160B) | Rcvd: 2 (92B) | Lost: 2 (50.00%)
           Tx time: 3.00296s | Tx bytes/s: 53.28 | Tx pkts/s: 1.33
           Rx time: 3.00296s | Rx bytes/s: 30.64 | Rx pkts/s: 0.67
           Nping done: 2 IP addresses pinged in 4.01 seconds

       The newest version of Nping can be obtained with Nmap at
https://nmap.org
. The newest version of this man page is available
       at
https://nmap.org/book/nping-man.html
. -->
         .SH ""OPTIONS SUMMARY""

       This options summary is printed when Nping is run with no
       arguments."
901,6,nping,"-->
         .SH ""OPTIONS SUMMARY""

       This options summary is printed when Nping is run with no
       arguments. It helps people remember the most common options, but
       is no substitute for the in-depth documentation in the rest of
       this manual. Some obscure options aren't even included here."
901,7,nping,"Some obscure options aren't even included here. Nping 0.7.92SVN (
https://nmap.org/nping
)
           Usage: nping [Probe mode] [Options] {target specification}

           TARGET SPECIFICATION:
             Targets may be specified as hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.*.1-24
           PROBE MODES:
             --tcp-connect                    : Unprivileged TCP connect probe mode."
901,8,nping,"Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.*.1-24
           PROBE MODES:
             --tcp-connect                    : Unprivileged TCP connect probe mode. --tcp                            : TCP probe mode. --udp                            : UDP probe mode."
901,9,nping,--udp                            : UDP probe mode. --icmp                           : ICMP probe mode. --arp                            : ARP/RARP probe mode.
901,10,nping,"--arp                            : ARP/RARP probe mode. --tr, --traceroute               : Traceroute mode (can only be used with
                                                TCP/UDP/ICMP modes). TCP CONNECT MODE:
              -p, --dest-port <port spec>     : Set destination port(s)."
901,11,nping,"TCP CONNECT MODE:
              -p, --dest-port <port spec>     : Set destination port(s). -g, --source-port <portnumber>  : Try to use a custom source port. TCP PROBE MODE:
              -g, --source-port <portnumber>  : Set source port."
901,12,nping,"TCP PROBE MODE:
              -g, --source-port <portnumber>  : Set source port. -p, --dest-port <port spec>     : Set destination port(s). --seq <seqnumber>               : Set sequence number."
901,13,nping,"--seq <seqnumber>               : Set sequence number. --flags <flag list>             : Set TCP flags (ACK,PSH,RST,SYN,FIN...)
              --ack <acknumber>               : Set ACK number. --win <size>                    : Set window size."
901,14,nping,"--win <size>                    : Set window size. --badsum                        : Use a random invalid checksum. UDP PROBE MODE:
              -g, --source-port <portnumber>  : Set source port."
901,15,nping,"UDP PROBE MODE:
              -g, --source-port <portnumber>  : Set source port. -p, --dest-port <port spec>     : Set destination port(s). --badsum                        : Use a random invalid checksum."
901,16,nping,"--badsum                        : Use a random invalid checksum. ICMP PROBE MODE:
             --icmp-type <type>               : ICMP type. --icmp-code <code>               : ICMP code."
901,17,nping,--icmp-code <code>               : ICMP code. --icmp-id <id>                   : Set identifier. --icmp-seq <n>                   : Set sequence number.
901,18,nping,--icmp-seq <n>                   : Set sequence number. --icmp-redirect-addr <addr>      : Set redirect address. --icmp-param-pointer <pnt>       : Set parameter problem pointer.
901,19,nping,"--icmp-param-pointer <pnt>       : Set parameter problem pointer. --icmp-advert-lifetime <time>    : Set router advertisement lifetime. --icmp-advert-entry <IP,pref>    : Add router advertisement entry."
901,20,nping,"--icmp-advert-entry <IP,pref>    : Add router advertisement entry. --icmp-orig-time  <timestamp>    : Set originate timestamp. --icmp-recv-time  <timestamp>    : Set receive timestamp."
901,21,nping,"--icmp-recv-time  <timestamp>    : Set receive timestamp. --icmp-trans-time <timestamp>    : Set transmit timestamp. ARP/RARP PROBE MODE:
             --arp-type <type>                : Type: ARP, ARP-reply, RARP, RARP-reply."
901,22,nping,"ARP/RARP PROBE MODE:
             --arp-type <type>                : Type: ARP, ARP-reply, RARP, RARP-reply. --arp-sender-mac <mac>           : Set sender MAC address. --arp-sender-ip  <addr>          : Set sender IP address."
901,23,nping,--arp-sender-ip  <addr>          : Set sender IP address. --arp-target-mac <mac>           : Set target MAC address. --arp-target-ip  <addr>          : Set target IP address.
901,24,nping,"--arp-target-ip  <addr>          : Set target IP address. IPv4 OPTIONS:
             -S, --source-ip                  : Set source IP address. --dest-ip <addr>                 : Set destination IP address (used as an
                                                alternative to {target specification} )."
901,25,nping,"--dest-ip <addr>                 : Set destination IP address (used as an
                                                alternative to {target specification} ). --tos <tos>                      : Set type of service field (8bits). --id  <id>                       : Set identification field (16 bits)."
901,26,nping,--id  <id>                       : Set identification field (16 bits). --df                             : Set Don't Fragment flag. --mf                             : Set More Fragments flag.
901,27,nping,--mf                             : Set More Fragments flag. --evil                           : Set Reserved / Evil flag. --ttl <hops>                     : Set time to live [0-255].
901,28,nping,"--ttl <hops>                     : Set time to live [0-255]. --badsum-ip                      : Use a random invalid checksum. --ip-options <S|R [route]|L [route]|T|U ...> : Set IP options
             --ip-options <hex string>                    : Set IP options
             --mtu <size>                     : Set MTU."
901,29,nping,"--ip-options <S|R [route]|L [route]|T|U ...> : Set IP options
             --ip-options <hex string>                    : Set IP options
             --mtu <size>                     : Set MTU. Packets get fragmented if MTU is
                                                small enough. IPv6 OPTIONS:
             -6, --IPv6                       : Use IP version 6."
901,30,nping,"IPv6 OPTIONS:
             -6, --IPv6                       : Use IP version 6. --dest-ip                        : Set destination IP address (used as an
                                                alternative to {target specification}). --hop-limit                      : Set hop limit (same as IPv4 TTL)."
901,31,nping,--hop-limit                      : Set hop limit (same as IPv4 TTL). --traffic-class <class> :        : Set traffic class. --flow <label>                   : Set flow label.
901,32,nping,"--flow <label>                   : Set flow label. ETHERNET OPTIONS:
             --dest-mac <mac>                 : Set destination mac address. (Disables
                                                ARP resolution)
             --source-mac <mac>               : Set source MAC address."
901,33,nping,"(Disables
                                                ARP resolution)
             --source-mac <mac>               : Set source MAC address. --ether-type <type>              : Set EtherType value. PAYLOAD OPTIONS:
             --data <hex string>              : Include a custom payload."
901,34,nping,"PAYLOAD OPTIONS:
             --data <hex string>              : Include a custom payload. --data-string <text>             : Include a custom ASCII text. --data-length <len>              : Include len random bytes as payload."
901,35,nping,"--data-length <len>              : Include len random bytes as payload. ECHO CLIENT/SERVER:
             --echo-client <passphrase>       : Run Nping in client mode. --echo-server <passphrase>       : Run Nping in server mode."
901,36,nping,--echo-server <passphrase>       : Run Nping in server mode. --echo-port <port>               : Use custom <port> to listen or connect. --no-crypto                      : Disable encryption and authentication.
901,37,nping,--no-crypto                      : Disable encryption and authentication. --once                           : Stop the server after one connection. --safe-payloads                  : Erase application data in echoed packets.
901,38,nping,"--safe-payloads                  : Erase application data in echoed packets. TIMING AND PERFORMANCE:
             Options which take <time> are in seconds, or append 'ms' (milliseconds),
             's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m, 0.25h)."
901,39,nping,"30m, 0.25h). --delay <time>                   : Adjust delay between probes. --rate  <rate>                   : Send num packets per second."
901,40,nping,"--rate  <rate>                   : Send num packets per second. MISC:
             -h, --help                       : Display help information. -V, --version                    : Display current version number."
901,41,nping,"-V, --version                    : Display current version number. -c, --count <n>                  : Stop after <n> rounds. -e, --interface <name>           : Use supplied network interface."
901,42,nping,"-e, --interface <name>           : Use supplied network interface. -H, --hide-sent                  : Do not display sent packets. -N, --no-capture                 : Do not try to capture replies."
901,43,nping,"-N, --no-capture                 : Do not try to capture replies. --privileged                     : Assume user is fully privileged. --unprivileged                   : Assume user lacks raw socket privileges."
901,44,nping,--unprivileged                   : Assume user lacks raw socket privileges. --send-eth                       : Send packets at the raw Ethernet layer. --send-ip                        : Send packets using raw IP sockets.
901,45,nping,"--send-ip                        : Send packets using raw IP sockets. --bpf-filter <filter spec>       : Specify custom BPF filter. OUTPUT:
             -v                               : Increment verbosity level by one."
901,46,nping,"OUTPUT:
             -v                               : Increment verbosity level by one. -v[level]                        : Set verbosity level. E.g: -v4
             -d                               : Increment debugging level by one."
901,47,nping,"E.g: -v4
             -d                               : Increment debugging level by one. -d[level]                        : Set debugging level. E.g: -d3
             -q                               : Decrease verbosity level by one."
901,48,nping,"E.g: -d3
             -q                               : Decrease verbosity level by one. -q[N]                            : Decrease verbosity level N times
             --quiet                          : Set verbosity and debug level to minimum. --debug                          : Set verbosity and debug to the max level."
901,49,nping,"-q[N]                            : Decrease verbosity level N times
             --quiet                          : Set verbosity and debug level to minimum. --debug                          : Set verbosity and debug to the max level. EXAMPLES:
             nping scanme.nmap.org
             nping --tcp -p 80 --flags rst --ttl 2 192.168.1.1
             nping --icmp --icmp-type time --delay 500ms 192.168.254.254
             nping --echo-server ""public"" -e wlan0 -vvv
             nping --echo-client ""public"" echo.nmap.org --tcp -p1-1024 --flags ack

           SEE THE MAN PAGE FOR MANY MORE OPTIONS, DESCRIPTIONS, AND EXAMPLES"
902,0,nsenter,"The
nsenter
command executes
program
in the namespace(s) that are
       specified in the command-line options (described below). If
program
is not given, then ""${SHELL}"" is run (default:
/bin/sh
). Enterable namespaces are:
mount namespace
Mounting and unmounting filesystems will not affect the rest
           of the system, except for filesystems which are explicitly
           marked as shared (with
mount --make-shared
; see
/proc/self/mountinfo
for the
shared
flag)."
902,1,nsenter,"Enterable namespaces are:
mount namespace
Mounting and unmounting filesystems will not affect the rest
           of the system, except for filesystems which are explicitly
           marked as shared (with
mount --make-shared
; see
/proc/self/mountinfo
for the
shared
flag). For further
           details, see
mount_namespaces(7)
and the discussion of the
CLONE_NEWNS
flag in
clone(2)
. UTS namespace
Setting hostname or domainname will not affect the rest of the
           system."
902,2,nsenter,"UTS namespace
Setting hostname or domainname will not affect the rest of the
           system. For further details, see
uts_namespaces(7)
. IPC namespace
The process will have an independent namespace for POSIX
           message queues as well as System V message queues, semaphore
           sets and shared memory segments."
902,3,nsenter,"IPC namespace
The process will have an independent namespace for POSIX
           message queues as well as System V message queues, semaphore
           sets and shared memory segments. For further details, see
ipc_namespaces(7)
. network namespace
The process will have independent IPv4 and IPv6 stacks, IP
           routing tables, firewall rules, the
/proc/net
and
/sys/class/net
directory trees, sockets, etc."
902,4,nsenter,"network namespace
The process will have independent IPv4 and IPv6 stacks, IP
           routing tables, firewall rules, the
/proc/net
and
/sys/class/net
directory trees, sockets, etc. For further
           details, see
network_namespaces(7)
. PID namespace
Children will have a set of PID to process mappings separate
           from the
nsenter
process."
902,5,nsenter,"PID namespace
Children will have a set of PID to process mappings separate
           from the
nsenter
process. nsenter
will fork by default if
           changing the PID namespace, so that the new program and its
           children share the same PID namespace and are visible to each
           other. If
--no-fork
is used, the new program will be execâed
           without forking."
902,6,nsenter,"If
--no-fork
is used, the new program will be execâed
           without forking. For further details, see
pid_namespaces(7)
. user namespace
The process will have a distinct set of UIDs, GIDs and
           capabilities."
902,7,nsenter,"user namespace
The process will have a distinct set of UIDs, GIDs and
           capabilities. For further details, see
user_namespaces(7)
. cgroup namespace
The process will have a virtualized view of
/proc/self/cgroup
,
           and new cgroup mounts will be rooted at the namespace cgroup
           root."
902,8,nsenter,"cgroup namespace
The process will have a virtualized view of
/proc/self/cgroup
,
           and new cgroup mounts will be rooted at the namespace cgroup
           root. For further details, see
cgroup_namespaces(7)
. time namespace
The process can have a distinct view of
CLOCK_MONOTONIC
and/or
CLOCK_BOOTTIME
which can be changed using
/proc/self/timens_offsets
."
902,9,nsenter,"For further details, see
cgroup_namespaces(7)
. time namespace
The process can have a distinct view of
CLOCK_MONOTONIC
and/or
CLOCK_BOOTTIME
which can be changed using
/proc/self/timens_offsets
. For further details, see
time_namespaces(7)
."
903,0,numfmt,"Reformat NUMBER(s), or the numbers from standard input if none are
       specified. Mandatory arguments to long options are mandatory for short
       options too. --debug
print warnings about invalid input
-d
,
--delimiter
=
X
use X instead of whitespace for field delimiter
--field
=
FIELDS
replace the numbers in these input fields (default=1); see
              FIELDS below
--format
=
FORMAT
use printf style floating-point FORMAT; see FORMAT below
              for details
--from
=
UNIT
auto-scale input numbers to UNITs; default is 'none'; see
              UNIT below
--from-unit
=
N
specify the input unit size (instead of the default 1)
--grouping
use locale-defined grouping of digits, e.g."
903,1,numfmt,"--debug
print warnings about invalid input
-d
,
--delimiter
=
X
use X instead of whitespace for field delimiter
--field
=
FIELDS
replace the numbers in these input fields (default=1); see
              FIELDS below
--format
=
FORMAT
use printf style floating-point FORMAT; see FORMAT below
              for details
--from
=
UNIT
auto-scale input numbers to UNITs; default is 'none'; see
              UNIT below
--from-unit
=
N
specify the input unit size (instead of the default 1)
--grouping
use locale-defined grouping of digits, e.g. 1,000,000
              (which means it has no effect in the C/POSIX locale)
--header
[=
N
]
              print (without converting) the first N header lines; N
              defaults to 1 if not specified
--invalid
=
MODE
failure mode for invalid numbers: MODE can be: abort
              (default), fail, warn, ignore
--padding
=
N
pad the output to N characters; positive N will
              right-align; negative N will left-align; padding is ignored
              if the output is wider than N; the default is to
              automatically pad if a whitespace is found
--round
=
METHOD
use METHOD for rounding when scaling; METHOD can be: up,
              down, from-zero (default), towards-zero, nearest
--suffix
=
SUFFIX
add SUFFIX to output numbers, and accept optional SUFFIX in
              input numbers
--to
=
UNIT
auto-scale output numbers to UNITs; see UNIT below
--to-unit
=
N
the output unit size (instead of the default 1)
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit
UNIT options:
none   no auto-scaling is done; suffixes will trigger an error

       auto   accept optional single/two letter suffix:

              1K = 1000, 1k = 1000, 1Ki = 1024, 1M = 1000000, 1Mi =
              1048576,

       si     accept optional single letter suffix:

              1k = 1000, 1K = 1000, 1M = 1000000, ... iec    accept optional single letter suffix:

              1K = 1024, 1k = 1024, 1M = 1048576, ..."
903,2,numfmt,"iec    accept optional single letter suffix:

              1K = 1024, 1k = 1024, 1M = 1048576, ... iec-i  accept optional two-letter suffix:

              1Ki = 1024, 1ki = 1024, 1Mi = 1048576, ... FIELDS supports cut(1) style field ranges:
N      N'th field, counted from 1

       N-     from N'th field, to end of line

       N-M    from N'th to M'th field (inclusive)
-M
from first to M'th field (inclusive)

       -      all fields

       Multiple fields/ranges can be separated with commas

       FORMAT must be suitable for printing one floating-point argument
       '%f'."
903,3,numfmt,"FIELDS supports cut(1) style field ranges:
N      N'th field, counted from 1

       N-     from N'th field, to end of line

       N-M    from N'th to M'th field (inclusive)
-M
from first to M'th field (inclusive)

       -      all fields

       Multiple fields/ranges can be separated with commas

       FORMAT must be suitable for printing one floating-point argument
       '%f'. Optional quote (%'f) will enable
--grouping
(if supported
       by current locale). Optional width value (%10f) will pad output."
903,4,numfmt,"Optional width value (%10f) will pad output. Optional zero (%010f) width will zero pad the number. Optional
       negative values (%-10f) will left align."
903,5,numfmt,"Optional
       negative values (%-10f) will left align. Optional precision
       (%.1f) will override the input determined precision. Exit status is 0 if all input numbers were successfully converted."
903,6,numfmt,"Exit status is 0 if all input numbers were successfully converted. By default, numfmt will stop at the first conversion error with
       exit status 2. With
--invalid=
'fail' a warning is printed for
       each conversion error and the exit status is 2."
903,7,numfmt,"With
--invalid=
'fail' a warning is printed for
       each conversion error and the exit status is 2. With
--invalid=
'warn' each conversion error is diagnosed, but the exit
       status is 0. With
--invalid=
'ignore' conversion errors are not
       diagnosed and the exit status is 0."
904,0,objcopy,"The GNU
objcopy
utility copies the contents of an object file to
       another. objcopy
uses the GNU BFD Library to read and write the
       object files. It can write the destination object file in a
       format different from that of the source object file."
904,1,objcopy,"It can write the destination object file in a
       format different from that of the source object file. The exact
       behavior of
objcopy
is controlled by command-line options. Note
       that
objcopy
should be able to copy a fully linked file between
       any two formats."
904,2,objcopy,"Note
       that
objcopy
should be able to copy a fully linked file between
       any two formats. However, copying a relocatable object file
       between any two formats may not work as expected. objcopy
creates temporary files to do its translations and deletes
       them afterward."
904,3,objcopy,"objcopy
creates temporary files to do its translations and deletes
       them afterward. objcopy
uses BFD to do all its translation work;
       it has access to all the formats described in BFD and thus is able
       to recognize most formats without being told explicitly. objcopy
can be used to generate S-records by using an output
       target of
srec
(e.g., use
-O srec
)."
904,4,objcopy,"objcopy
can be used to generate S-records by using an output
       target of
srec
(e.g., use
-O srec
). objcopy
can be used to generate a raw binary file by using an
       output target of
binary
(e.g., use
-O binary
). When
objcopy
generates a raw binary file, it will essentially produce a memory
       dump of the contents of the input object file."
904,5,objcopy,"When
objcopy
generates a raw binary file, it will essentially produce a memory
       dump of the contents of the input object file. All symbols and
       relocation information will be discarded. The memory dump will
       start at the load address of the lowest section copied into the
       output file."
904,6,objcopy,"The memory dump will
       start at the load address of the lowest section copied into the
       output file. When generating an S-record or a raw binary file, it may be
       helpful to use
-S
to remove sections containing debugging
       information. In some cases
-R
will be useful to remove sections
       which contain information that is not needed by the binary file."
904,7,objcopy,"In some cases
-R
will be useful to remove sections
       which contain information that is not needed by the binary file. Note---
objcopy
is not able to change the endianness of its input
       files. If the input format has an endianness (some formats do
       not),
objcopy
can only copy the inputs into file formats that have
       the same endianness or which have no endianness (e.g.,
srec
)."
904,8,objcopy,"Note---
objcopy
is not able to change the endianness of its input
       files. If the input format has an endianness (some formats do
       not),
objcopy
can only copy the inputs into file formats that have
       the same endianness or which have no endianness (e.g.,
srec
). (However, see the
--reverse-bytes
option.)"
905,0,ocount,"ocount
is an OProfile tool that can be used to count native
       hardware events occurring in either a given application, a set of
       processes or threads, a subset of active system processors, or the
       entire system. The data collected during a counting session is
       displayed to stdout by default or, optionally, to a file. When counting multiple events, the kernel may not be able to count
       all events simultaneously and, thus, may need to multiplex the
       counting of the events."
905,1,ocount,"The data collected during a counting session is
       displayed to stdout by default or, optionally, to a file. When counting multiple events, the kernel may not be able to count
       all events simultaneously and, thus, may need to multiplex the
       counting of the events. If this happens, the ""Percent time
       enabled"" column in the
ocount
output will be less than 100, but
       counts are scaled up to a 100% estimated value."
906,0,ocsptool,"On verification
Responses are typically signed/issued by designated certificates
       or certificate authorities and thus this tool requires on
       verification the certificate of the issuer or the full certificate
       chain in order to determine the appropriate signing authority. The
       specified certificate of the issuer is assumed trusted."
907,0,od,"Write an unambiguous representation, octal bytes by default, of
       FILE to standard output. With more than one FILE argument,
       concatenate them in the listed order to form the input. With no FILE, or when FILE is -, read standard input."
907,1,od,"With no FILE, or when FILE is -, read standard input. If first and second call formats both apply, the second format is
       assumed if the last operand begins with + or (if there are 2
       operands) a digit. An OFFSET operand means
-j
OFFSET."
907,2,od,"An OFFSET operand means
-j
OFFSET. LABEL is
       the pseudo-address at first byte printed, incremented when dump is
       progressing. For OFFSET and LABEL, a 0x or 0X prefix indicates
       hexadecimal; suffixes may be ."
907,3,od,"For OFFSET and LABEL, a 0x or 0X prefix indicates
       hexadecimal; suffixes may be . for octal and b for multiply by
       512. Mandatory arguments to long options are mandatory for short
       options too."
907,4,od,"Mandatory arguments to long options are mandatory for short
       options too. -A
,
--address-radix
=
RADIX
output format for file offsets; RADIX is one of [doxn], for
              Decimal, Octal, Hex or None
--endian=
{big|little}
              swap input bytes according the specified order
-j
,
--skip-bytes
=
BYTES
skip BYTES input bytes first
-N
,
--read-bytes
=
BYTES
limit dump to BYTES input bytes
-S
BYTES,
--strings
[=
BYTES
]
              show only NUL terminated strings of at least BYTES (3)
              printable characters
-t
,
--format
=
TYPE
select output format or formats
-v
,
--output-duplicates
do not use * to mark line suppression
-w[BYTES]
,
--width
[=
BYTES
]
              output BYTES bytes per output line; 32 is implied when
              BYTES is not specified
--traditional
accept arguments in third form above
--help
display this help and exit
--version
output version information and exit
Traditional format specifications may be intermixed; they accumulate:
-a
same as
-t
a,  select named characters, ignoring high-order
              bit
-b
same as
-t
o1, select octal bytes
-c
same as
-t
c,  select printable characters or backslash
              escapes
-d
same as
-t
u2, select unsigned decimal 2-byte units
-f
same as
-t
fF, select floats
-i
same as
-t
dI, select decimal ints
-l
same as
-t
dL, select decimal longs
-o
same as
-t
o2, select octal 2-byte units
-s
same as
-t
d2, select decimal 2-byte units
-x
same as
-t
x2, select hexadecimal 2-byte units
TYPE is made up of one or more of these specifications:
a      named character, ignoring high-order bit

       c      printable character or backslash escape

       d[SIZE]
              signed decimal, SIZE bytes per integer

       f[SIZE]
              floating point, SIZE bytes per float

       o[SIZE]
              octal, SIZE bytes per integer

       u[SIZE]
              unsigned decimal, SIZE bytes per integer

       x[SIZE]
              hexadecimal, SIZE bytes per integer

       SIZE is a number. For TYPE in [doux], SIZE may also be C for
       sizeof(char), S for sizeof(short), I for sizeof(int) or L for
       sizeof(long)."
907,5,od,"For TYPE in [doux], SIZE may also be C for
       sizeof(char), S for sizeof(short), I for sizeof(int) or L for
       sizeof(long). If TYPE is f, SIZE may also be B for Brain 16 bit,
       H for Half precision float, F for sizeof(float), D for
       sizeof(double), or L for sizeof(long double). Adding a z suffix to any type displays printable characters at the
       end of each output line."
907,6,od,"Adding a z suffix to any type displays printable characters at the
       end of each output line. BYTES is hex with 0x or 0X prefix, and may have a multiplier suffix:
b      512

       KB     1000

       K      1024

       MB     1000*1000

       M      1024*1024

       and so on for G, T, P, E, Z, Y, R, Q. Binary prefixes can be
       used, too: KiB=K, MiB=M, and so on."
908,0,oomctl,"oomctl
may be used to get information about the various contexts
       read in by the
systemd(1)
userspace out-of-memory (OOM) killer,
systemd-oomd(8)
."
909,0,objdump,"objdump
displays information about one or more object files. The
       options control what particular information to display. This
       information is mostly useful to programmers who are working on the
       compilation tools, as opposed to programmers who just want their
       program to compile and work."
909,1,objdump,"This
       information is mostly useful to programmers who are working on the
       compilation tools, as opposed to programmers who just want their
       program to compile and work. objfile
... are the object files to be examined."
909,2,objdump,"objfile
... are the object files to be examined. When you specify
       archives,
objdump
shows information on each of the member object
       files."
910,0,od,"The
od
utility shall write the contents of its input files to
       standard output in a user-specified format."
911,0,opannotate,"opannotate
outputs annotated source and/or assembly from profile
       data of an OProfile session. See oprofile(1) for how to write
       profile specifications."
912,0,op-check-perfevents,"The small helper program
op-check-perfevents
determines whether
       the kernel supports the perf interface and returns a zero exit
       status if the perf pmu support is available."
913,0,oparchive,"The
oparchive
utility is commonly used for collecting profile data
       on a ""target"" system for future offline analysis on a different
       (""host"") machine. oparchive
creates a directory populated with
       executables, libraries, debuginfo files, and oprofile sample
       files. This directory can be tar'ed up and moved to another
       machine to be analyzed without further use of the target machine."
913,1,oparchive,"This directory can be tar'ed up and moved to another
       machine to be analyzed without further use of the target machine. Using
opreport
and other post-profiling tools against archived
       data requires the use of the
archive:<archived-dir>
specification. See oprofile(1) for how to write profile specifications."
913,2,oparchive,"See oprofile(1) for how to write profile specifications. A
       complete description of offline analysis can be found in the
       chapter titled
Analyzing profile data on another system
(oparchive)
of the OProfile user manual. (See the user manual URL
       in the ""SEE ALSO"" section below.)"
914,0,openvt,"openvt
will find the first available VT, and run on it the given
command
with the given
command options ,
standard input, output
       and error are directed to that terminal. The current search path
       ($PATH) is used to find the requested command. If no command is
       specified then the environment variable $SHELL is used."
914,1,openvt,"If no command is
       specified then the environment variable $SHELL is used. OPTIONS
-c
,
--console
=
VTNUMBER
Use the given VT number and not the first available. Note
              you must have write access to the supplied VT for this to
              work."
914,2,openvt,"Note
              you must have write access to the supplied VT for this to
              work. -f
,
--force
Force opening a VT without checking whether it is already
              in use. -e
,
--exec
Directly execute the given command, without forking."
914,3,openvt,"-e
,
--exec
Directly execute the given command, without forking. This
              option is meant for use in
/etc/inittab
. -s
,
--switch
Switch to the new VT when starting the command."
914,4,openvt,"-s
,
--switch
Switch to the new VT when starting the command. The VT of
              the new command will be made the new current VT. -u
,
--user
Figure out the owner of the current VT, and run login as
              that user."
914,5,openvt,"-u
,
--user
Figure out the owner of the current VT, and run login as
              that user. Suitable to be called by init. Shouldn't be
              used with
-c
or
-l
."
914,6,openvt,"Shouldn't be
              used with
-c
or
-l
. -l
,
--login
Make the command a login shell. A - is prepended to the
              name of the command to be executed."
914,7,openvt,"A - is prepended to the
              name of the command to be executed. -v
,
--verbose
Be a bit more verbose. -w
,
--wait
wait for command to complete."
914,8,openvt,"-w
,
--wait
wait for command to complete. If -w and -s are used
              together then
openvt
will switch back to the controlling
              terminal when the command completes. -V
,
--version
print program version and exit."
914,9,openvt,"-V
,
--version
print program version and exit. -h
,
--help
show this text and exit. --
end of options to
openvt
."
915,0,ophelp,"By default,
ophelp
lists the available performance counter
       options. If you give it a symbolic event name, it will return the
       hardware value (e.g. ""ophelp DATA_MEM_REFS"")."
916,0,opjitconv,Convert a jit dump file to an ELF file
917,0,operf,"Operf is the profiler tool provided with OProfile. Operf uses the
       Linux Performance Events Subsystem and, thus, does not require the
       obsolete oprofile kernel driver. By default, operf uses <current_dir>/oprofile_data as the session-
       dir and stores profiling data there."
917,1,operf,"By default, operf uses <current_dir>/oprofile_data as the session-
       dir and stores profiling data there. You can change this by way
       of the
--session-dir
option. The usual post-profiling analysis
       tools such as
opreport(1)
and
opannotate(1)
can be used to
       generate profile reports."
917,2,operf,"The usual post-profiling analysis
       tools such as
opreport(1)
and
opannotate(1)
can be used to
       generate profile reports. Unless a
session-dir
is specified, the
       post-processing analysis tools will search for samples in
       <current_dir>/oprofile_data first. If that directory does not
       exist, the post-processing tools use the standard session-dir of
       /var/lib/oprofile."
917,3,operf,"Unless a
session-dir
is specified, the
       post-processing analysis tools will search for samples in
       <current_dir>/oprofile_data first. If that directory does not
       exist, the post-processing tools use the standard session-dir of
       /var/lib/oprofile. Statistics, such as total samples received and lost samples, are
       written to the operf.log file that can be found in the
       <session_dir>/samples directory."
918,0,opimport,"opimport
converts sample database files from a foreign binary
       format (abi) to the native format."
919,0,opgprof,"opgprof
outputs gprof-format profile data for a given binary
       image, from an OProfile session. See oprofile(1) for how to write
       profile specifications."
920,0,opreport,"opreport
outputs binary image summaries, or per-symbol data, from
       OProfile profiling sessions. See oprofile(1) for how to write
       profile specifications."
921,0,osvis,"osvis
displays an high-level overview of performance statistics
       collected from the Performance Co-Pilot (
PCP(1)
) infrastructure. The display is modulated by the values of the performance metrics
       retrieved from the target
host
(which is running
pmcd(1)
) or from
       the PCP archive log identified by
archive
. The display is updated
       every
interval
seconds (default 2 seconds)."
921,1,osvis,"The display is updated
       every
interval
seconds (default 2 seconds). As in all
pmview(1)
scenes, when the mouse is moved over one of
       the bars, the current value and metric information for that bar
       will be shown in the text box near the top of the display. The
       height and/or color of the bars is proportional to the performance
       metric values relative to the maximum expected activity, as
       controlled by the
-d
,
-i
and
-m
options (see below)."
921,2,osvis,"The
       height and/or color of the bars is proportional to the performance
       metric values relative to the maximum expected activity, as
       controlled by the
-d
,
-i
and
-m
options (see below). The bars in the
osvis
scene represent the following information:
CPU
This column shows CPU utilization, aggregated over all CPUs. Disk
The first stack is the rate of disk read and write operations
           aggregated over all disk spindles."
921,3,osvis,"Disk
The first stack is the rate of disk read and write operations
           aggregated over all disk spindles. The second bar is the
           average time the disks are busy, which approximates average
           time utilization of all disks. Disk Controllers
The average time the disks were busy on each controller, which
           approximates the average time utilization of all disks on each
           controller."
921,4,osvis,"Disk Controllers
The average time the disks were busy on each controller, which
           approximates the average time utilization of all disks on each
           controller. Load
The three bars represent the average load for the past 1, 5
           and 15 minutes. This is normalized by twice the number of
           CPUs on the machine."
921,5,osvis,"This is normalized by twice the number of
           CPUs on the machine. Mem
The stack shows memory utilization by breaking down real
           memory into kernel, file system and user usage. The memory
           utilization metrics (
mem.util
) may not be available on all
           hosts, so
Mem
may only show the amount of free memory as a
           single bar on some hosts."
921,6,osvis,"The memory
           utilization metrics (
mem.util
) may not be available on all
           hosts, so
Mem
may only show the amount of free memory as a
           single bar on some hosts. Network Input
The two rows of bars show the input byte rate and the input
           packet rate for each network interface, except loopback and
           slip interfaces. Network Output
The two rows of bars show the output byte rate and the output
           packet rate for each network interface, except for loopback
           and slip interfaces."
922,0,ovn-detrace,"The
ovn-detrace
program reads
ovs-appctl ofproto/trace
output on
       stdin, looking for flow cookies, and displays for each cookie the
       OVN south-bound records that contributed to its creation. It
       further displays the related north-bound information when
       applicable, e.g., the ACL that generated the logical flow that
       gets translated to an OpenFlow rule with a given cookie."
923,0,oprofile,"OProfile is a profiling system for systems running Linux 2.6.31
       and greater. OProfile makes use of the hardware performance
       counters provided on Intel, AMD, and other processors. OProfile
       can profile a selected program or process or the whole system."
923,1,oprofile,"OProfile
       can profile a selected program or process or the whole system. OProfile can also be used to collect cumulative event counts at
       the application, process, or system level. For a gentle guide to using OProfile, please read the HTML
       documentation listed in SEE ALSO."
924,0,ovn-sim,"ovn-sim
is a wrapper script that adds ovn related commands on top
       of
ovs-sim
. ovs-sim
provides a convenient environment for running one or more
       Open vSwitch instances and related software in a sandboxed
       simulation environment. To use
ovn-sim
, first build Open vSwitch, then invoke it directly
       from the build directory, e.g.:

          git clone
https://github.com/openvswitch/ovs.git
cd ovs
          ./boot.sh && ./configure && make
          cd .."
924,1,ovn-sim,"To use
ovn-sim
, first build Open vSwitch, then invoke it directly
       from the build directory, e.g.:

          git clone
https://github.com/openvswitch/ovs.git
cd ovs
          ./boot.sh && ./configure && make
          cd .. git clone
https://github.com/ovn-org/ovn.git
cd ovn
          ./boot.sh && ./configure --with-ovs-source=${PWD}/../ovs
          make
          utilities/ovn-sim

       See documentation on
ovs-sim
for info on simulator, including the
       parameters you can use. OVN Commands
These commands interact with OVN, the Open Virtual Network."
924,2,ovn-sim,"OVN Commands
These commands interact with OVN, the Open Virtual Network. ovn_start [
options
]
Creates and initializes the central OVN databases (both
ovn-sb(5)
and
ovn-nb(5)
) and starts an instance of
ovsdb-server
for each one. Also starts an instance of
ovn-northd
."
924,3,ovn-sim,"Also starts an instance of
ovn-northd
. The following options are available:
--nbdb-model
model
Uses the given database model for the northbound
                        database. The
model
may be
standalone
(the
                        default),
backup
, or
clustered
."
924,4,ovn-sim,"The
model
may be
standalone
(the
                        default),
backup
, or
clustered
. --nbdb-servers
n
For a clustered northbound database, the number
                        of servers in the cluster. The default is 3."
924,5,ovn-sim,"The default is 3. --sbdb-model
model
Uses the given database model for the southbound
                        database. The
model
may be
standalone
(the
                        default),
backup
, or
clustered
."
924,6,ovn-sim,"The
model
may be
standalone
(the
                        default),
backup
, or
clustered
. --sbdb-servers
n
For a clustered southbound database, the number
                        of servers in the cluster. The default is 3."
924,7,ovn-sim,"The default is 3. ovn_attach
network bridge ip
[
masklen
]
First, this command attaches bridge to interconnection
              network network, just like
net_attach
network bridge
. Second, it configures (simulated) IP address
ip
(with
              network mask length
masklen
, which defaults to 24) on
bridge
."
924,8,ovn-sim,"ovn_attach
network bridge ip
[
masklen
]
First, this command attaches bridge to interconnection
              network network, just like
net_attach
network bridge
. Second, it configures (simulated) IP address
ip
(with
              network mask length
masklen
, which defaults to 24) on
bridge
. Finally, it configures the Open vSwitch database to
              work with OVN and starts
ovn-controller
."
925,0,ovs-pcap,"The
ovs-pcap
program reads the pcap
file
named on the command line
       and prints each packet's contents as a sequence of hex digits on a
       line of its own.  This format is suitable for use with the
ofproto/trace
command supported by
ovs-vswitchd(8)
."
926,0,ovsdb-idlc,"The
ovsdb-idlc
program is a command-line tool for translating Open
       vSwitch database interface definition language (IDL) schemas into
       other formats. It is used while building Open vSwitch, not at
       installation or configuration time. Thus, it is not normally
       installed as part of Open vSwitch."
926,1,ovsdb-idlc,"Thus, it is not normally
       installed as part of Open vSwitch. The
idl
files used as input for most
ovsdb-idlc
commands have the
       same format as the OVSDB schemas, specified in the OVSDB
       specification, with a few additions:

       ""
idlPrefix
"" member of <database-schema>
              This member, which is required, specifies a string that is
              prefixed to top-level names in C bindings. It should
              probably end in an underscore."
926,2,ovsdb-idlc,"It should
              probably end in an underscore. ""
idlHeader
"" member of <database-schema>
              This member, which is required, specifies the name of the
              IDL header. It will be output on an
#include
line in the
              source file generated by the C bindings."
926,3,ovsdb-idlc,"It will be output on an
#include
line in the
              source file generated by the C bindings. It should include
              the bracketing
""""
or
<>
. ""
cDecls
"" member of <database-schema>
       ""
hDecls
"" member of <database-schema>
              These optional members may specify arbitrary code to
              include in the generated
.c
or
.h
file, respectively, in
              each case just after the
#include
directives in those
              files."
926,4,ovsdb-idlc,"""
cDecls
"" member of <database-schema>
       ""
hDecls
"" member of <database-schema>
              These optional members may specify arbitrary code to
              include in the generated
.c
or
.h
file, respectively, in
              each case just after the
#include
directives in those
              files. ""
extensions
"" member of <table-schema>
       ""
extensions
"" member of <column-schema>
              This member is optional. If specified, it is an object
              whose contents describes extensions to the OVSDB schema
              language, for the purpose of specifying interpretation by
              the IDL."
926,5,ovsdb-idlc,"If specified, it is an object
              whose contents describes extensions to the OVSDB schema
              language, for the purpose of specifying interpretation by
              the IDL. ""
synthetic
"" member of <column-schema> ""
extensions
"" object
              If this optional member is set to
true
, then it indicates
              that the column is not expected to be found in the actual
              database. Instead, code supplied by the IDL's client fills
              in the desired structure members based on the value of one
              or more other database columns."
926,6,ovsdb-idlc,"Instead, code supplied by the IDL's client fills
              in the desired structure members based on the value of one
              or more other database columns. This can be used to cache
              the result of a calculation, for example. ""
parse
"" member of <column-schema> ""
extensions
"" object
              This member should be present if and only if the column is
              synthetic."
926,7,ovsdb-idlc,"""
parse
"" member of <column-schema> ""
extensions
"" object
              This member should be present if and only if the column is
              synthetic. It should be a string that contains C code to
              set the value of the column's member in an object named
row
, e.g. ""
row->column = 1;
"" if the column's name is
column
and has integer type."
926,8,ovsdb-idlc,"""
row->column = 1;
"" if the column's name is
column
and has integer type. The code may rely on the columns
              named in
dependencies
to be initialized. The function can
              get called for rows that do not satisfy the constraints in
              the schema, e.g."
926,9,ovsdb-idlc,"The function can
              get called for rows that do not satisfy the constraints in
              the schema, e.g. that a pointer to another is nonnull, so
              it must not rely on those constraints. ""
unparse
"" member of <column-schema> ""
extensions
"" object
              This member is honored only if the column is synthetic."
926,10,ovsdb-idlc,"""
unparse
"" member of <column-schema> ""
extensions
"" object
              This member is honored only if the column is synthetic. It
              should be a string that contains C code to free the data in
              the column's member in an object named
row
, e.g. ""
free(row->column);
"" if the column's name is
column
and
              points to data that was allocated by the
parse
function and
              needs to be freed."
926,11,ovsdb-idlc,"""
free(row->column);
"" if the column's name is
column
and
              points to data that was allocated by the
parse
function and
              needs to be freed. ""
dependencies
"" member of <column-schema> ""
extensions
"" object
              This member should be a list of the names of columns whose
              values are used by the code in
parse
and
unparse
. The IDL
              ensures that dependencies are parsed before the columns
              that depends on them, and vice versa for unparsing."
926,12,ovsdb-idlc,"The IDL
              ensures that dependencies are parsed before the columns
              that depends on them, and vice versa for unparsing. Commands
annotate
schema annotations
Reads
schema
, which should be a file in JSON format
              (ordinarily an OVSDB schema file), then reads and executes
              the Python syntax fragment in
annotations
. The Python
              syntax fragment is passed the JSON object as a local
              variable named
s
."
926,13,ovsdb-idlc,"The Python
              syntax fragment is passed the JSON object as a local
              variable named
s
. It may modify this data in any way. After the Python code returns, the object as modified is
              re-serialized as JSON on standard output."
926,14,ovsdb-idlc,"After the Python code returns, the object as modified is
              re-serialized as JSON on standard output. c-idl-header
idl
Reads
idl
and prints on standard output a C header file
              that defines a structure for each table defined by the
              schema. If a column name in
idl
is a C or C++ keyword, it
              will be appended with an underscore."
926,15,ovsdb-idlc,"If a column name in
idl
is a C or C++ keyword, it
              will be appended with an underscore. c-idl-source
idl
Reads
idl
and prints on standard output a C source file
              that implements C bindings for the database defined by the
              schema. If a column name in
idl
is a C or C++ keyword, it
              will be appended with an underscore."
926,16,ovsdb-idlc,"c-idl-source
idl
Reads
idl
and prints on standard output a C source file
              that implements C bindings for the database defined by the
              schema. If a column name in
idl
is a C or C++ keyword, it
              will be appended with an underscore. Options"
927,0,ovs-tcpundump,nan
928,0,ovs-sim,"ovs-sim
provides a convenient environment for running one or more
       Open vSwitch instances and related software in a sandboxed
       simulation environment. To use
ovs-sim
, first build Open vSwitch, then invoke it directly
       from the build directory, e.g.:

          git clone
https://github.com/openvswitch/ovs.git
cd ovs
          ./configure
          make
          utilities/ovs-sim

       When invoked in the most ordinary way as shown above, ovs-sim does
       the following:

       1. Creates a directory
sandbox
as a subdirectory of the current
          directory (first destroying such a directory if it already
          exists) and makes it the current directory."
928,1,ovs-sim,"Creates a directory
sandbox
as a subdirectory of the current
          directory (first destroying such a directory if it already
          exists) and makes it the current directory. 2. Installs all of the Open vSwitch manpages into a
man
subdirectory of sandbox and adjusts the
MANPATH
environment
          variable so that
man
and other manpage viewers can find them."
928,2,ovs-sim,"Installs all of the Open vSwitch manpages into a
man
subdirectory of sandbox and adjusts the
MANPATH
environment
          variable so that
man
and other manpage viewers can find them. 3. Creates a simulated Open vSwitch named
main
and sets it up as
          the default target for OVS commands, as if the following
ovs-sim
commands had been run:

             sim_add main
             as main
          See
Commands
, below, for an explanation."
928,3,ovs-sim,"Creates a simulated Open vSwitch named
main
and sets it up as
          the default target for OVS commands, as if the following
ovs-sim
commands had been run:

             sim_add main
             as main
          See
Commands
, below, for an explanation. 4. Runs  any  scripts  specified on the command line (see
Options
,
          below)."
928,4,ovs-sim,"Runs  any  scripts  specified on the command line (see
Options
,
          below). The scripts can use arbitrary Bash  syntax,  plus  the
          additional commands described under
Commands
, below. 5."
928,5,ovs-sim,"5. If no scripts were specified, or if
-i
or
--interactive
was
          specified, invokes an interactive Bash subshell. The user can
          use arbitrary Bash commands, plus the additional commands
          described under
Commands
, below."
928,6,ovs-sim,"The user can
          use arbitrary Bash commands, plus the additional commands
          described under
Commands
, below. ovs-sim
and the sandbox environment that it creates does not
       require superuser or other special privileges. Generally, it
       should not be run with such privileges."
929,0,ovsdb-client,"The
ovsdb-client
program is a command-line client for interacting
       with a running
ovsdb-server
process. Each command connects to the
       specified OVSDB
server
, which may be an OVSDB active or passive
       connection method, as described in
ovsdb(7)
. The default server
       is
unix:/usr/local/var/run/openvswitch/db.sock
and the default
database
is
Open_vSwitch
."
929,1,ovsdb-client,"The default server
       is
unix:/usr/local/var/run/openvswitch/db.sock
and the default
database
is
Open_vSwitch
. ovsdb-client
supports the
method1
,
method2
,
... ,
methodN
syntax
       described in
ovsdb(7)
for connecting to a cluster."
929,2,ovsdb-client,",
methodN
syntax
       described in
ovsdb(7)
for connecting to a cluster. When this
       syntax is used,
ovsdb-client
tries the cluster members in random
       order until it finds the cluster leader. Specify the
--no-leader-only
option to instead accept any server that is
       connected to the cluster."
929,3,ovsdb-client,"Specify the
--no-leader-only
option to instead accept any server that is
       connected to the cluster. For an introduction to OVSDB and its implementation in Open
       vSwitch, see
ovsdb(7)
. The following sections describe the commands that
ovsdb-client
supports."
929,4,ovsdb-client,"The following sections describe the commands that
ovsdb-client
supports. Server-Level Commands
Most
ovsdb-client
commands work with an individual database, but
       these commands apply to an entire database server. list-dbs
[
server
]
              Connects to
server
, retrieves the list of known databases,
              and prints them one per line."
929,5,ovsdb-client,"list-dbs
[
server
]
              Connects to
server
, retrieves the list of known databases,
              and prints them one per line. These database names are the
              ones that other commands may use for
database
. Database Schema Commands
These commands obtain the schema from a database and print it or
       part of it."
929,6,ovsdb-client,"Database Schema Commands
These commands obtain the schema from a database and print it or
       part of it. get-schema
[
server
] [
database
]
              Connects to
server
, retrieves the schema for
database
, and
              prints it in JSON format. list-tables
[
server
] [
database
]
              Connects to
server
, retrieves the schema for
database
, and
              prints a table listing the name of each table within the
              database."
929,7,ovsdb-client,"list-tables
[
server
] [
database
]
              Connects to
server
, retrieves the schema for
database
, and
              prints a table listing the name of each table within the
              database. list-columns
[
server
] [
database
]
table
Connects to
server
, retrieves the schema for
database
, and
              prints a table listing the name and type of each column. If
table
is specified, only columns in that table are
              listed; otherwise, the tables include columns in all
              tables."
929,8,ovsdb-client,"If
table
is specified, only columns in that table are
              listed; otherwise, the tables include columns in all
              tables. Database Version Management Commands
An OVSDB schema has a schema version number, and an OVSDB database
       embeds a particular version of an OVSDB schema. These version
       numbers take the form
x
."
929,9,ovsdb-client,"These version
       numbers take the form
x
. y
. z
, e.g."
929,10,ovsdb-client,"z
, e.g. 1.2.3
. The OVSDB implementation
       does not enforce a particular version numbering scheme, but
       schemas managed within the Open vSwitch project use the following
       approach."
929,11,ovsdb-client,"The OVSDB implementation
       does not enforce a particular version numbering scheme, but
       schemas managed within the Open vSwitch project use the following
       approach. Whenever the database schema is changed in a non-
       backward compatible way (e.g. deleting a column or a table),
x
is
       incremented (and
y
and
z
are reset to 0)."
929,12,ovsdb-client,"deleting a column or a table),
x
is
       incremented (and
y
and
z
are reset to 0). When the database
       schema is changed in a backward compatible way (e.g. adding a new
       column),
y
is incremented (and
z
is reset to 0)."
929,13,ovsdb-client,"adding a new
       column),
y
is incremented (and
z
is reset to 0). When the
       database schema is changed cosmetically (e.g. reindenting its
       syntax),
z
is incremented."
929,14,ovsdb-client,"reindenting its
       syntax),
z
is incremented. Some OVSDB databases and schemas, especially very old ones, do not
       have a version number. Schema version numbers and Open vSwitch version numbers are
       independent."
929,15,ovsdb-client,"Schema version numbers and Open vSwitch version numbers are
       independent. These commands work with different versions of OVSDB schemas and
       databases. convert
[
server
]
schema
Reads an OVSDB schema in JSON format, as specified in the
              OVSDB specification, from
schema
, then connects to
server
and requests the server to convert the database whose name
              is specified in
schema
to the schema also specified in
schema
."
929,16,ovsdb-client,"convert
[
server
]
schema
Reads an OVSDB schema in JSON format, as specified in the
              OVSDB specification, from
schema
, then connects to
server
and requests the server to convert the database whose name
              is specified in
schema
to the schema also specified in
schema
. The conversion is atomic, consistent, isolated, and
              durable. Following the schema change, the server notifies
              clients that use the
set_db_change_aware
RPC introduced in
              Open vSwitch 2.9 and cancels their outstanding transactions
              and monitors."
929,17,ovsdb-client,"Following the schema change, the server notifies
              clients that use the
set_db_change_aware
RPC introduced in
              Open vSwitch 2.9 and cancels their outstanding transactions
              and monitors. The server disconnects other clients,
              enabling them to notice the change when they reconnect. This command can do simple ``upgrades'' and ``downgrades''
              on a database's schema."
929,18,ovsdb-client,"This command can do simple ``upgrades'' and ``downgrades''
              on a database's schema. The data in the database must be
              valid when interpreted under
schema
, with only one
              exception: data for tables and columns that do not exist in
schema
are ignored. Columns that exist in
schema
but not
              in the database are set to their default values."
929,19,ovsdb-client,"Columns that exist in
schema
but not
              in the database are set to their default values. All of
schema
's constraints apply in full. Some uses of this command can cause unrecoverable data
              loss."
929,20,ovsdb-client,"Some uses of this command can cause unrecoverable data
              loss. For example, converting a database from a schema
              that has a given column or table to one that does not will
              delete all data in that column or table. Back up critical
              databases before converting them."
929,21,ovsdb-client,"Back up critical
              databases before converting them. This command works with clustered and standalone databases. Standalone databases may also be converted (offline) with
ovsdb-tool
's
convert
command."
929,22,ovsdb-client,"Standalone databases may also be converted (offline) with
ovsdb-tool
's
convert
command. needs-conversion
[
server
]
schema
Reads the schema from
schema
, then connects to
server
and
              requests the schema from the database whose name is
              specified in
schema
. If the two schemas are the same,
              prints
no
on stdout; if they differ, prints
yes
."
929,23,ovsdb-client,"If the two schemas are the same,
              prints
no
on stdout; if they differ, prints
yes
. get-schema-version
[
server
] [
database
]
              Connects to
server
, retrieves the schema for
database
, and
              prints its version number on stdout. If
database
was
              created before schema versioning was introduced, then it
              will not have a version number and this command will print
              a blank line."
929,24,ovsdb-client,"If
database
was
              created before schema versioning was introduced, then it
              will not have a version number and this command will print
              a blank line. get-schema-cksum
[
server
] [
database
]
              Connects to
server
, retrieves the schema for
database
, and
              prints its checksum on stdout. If
database
does not
              include a checksum, prints a blank line."
929,25,ovsdb-client,"If
database
does not
              include a checksum, prints a blank line. Data Management Commands
These commands read or modify the data in a database. transact
[
server
]
transaction
Connects to
server
, sends it the specified
transaction
,
              which must be a JSON array appropriate for use as the
params
to a JSON-RPC
transact
request, and prints the
              received reply on stdout."
929,26,ovsdb-client,"transact
[
server
]
transaction
Connects to
server
, sends it the specified
transaction
,
              which must be a JSON array appropriate for use as the
params
to a JSON-RPC
transact
request, and prints the
              received reply on stdout. query
[
server
]
transaction
This commands acts like a read-only version of
transact
. It connects to
server
, sends it the specified
transaction
,
              which must be a JSON array appropriate for use as the
params
to a JSON-RPC
transact
request, and prints the
              received reply on stdout."
929,27,ovsdb-client,"It connects to
server
, sends it the specified
transaction
,
              which must be a JSON array appropriate for use as the
params
to a JSON-RPC
transact
request, and prints the
              received reply on stdout. To ensure that the transaction
              does not modify the database, this command appends an
abort
operation to the set of operations included in
transaction
before sending it to the database, and then removes the
abort
result from the reply (if it is present). dump
[
server
] [
database
] [
table
[
column
...]]
              Connects to
server
, retrieves all of the data in
database
,
              and prints it on stdout as a series of tables."
929,28,ovsdb-client,"dump
[
server
] [
database
] [
table
[
column
...]]
              Connects to
server
, retrieves all of the data in
database
,
              and prints it on stdout as a series of tables. If
table
is
              specified, only that table is retrieved. If at least one
column
is specified, only those columns are retrieved."
929,29,ovsdb-client,"If at least one
column
is specified, only those columns are retrieved. backup
[
server
] [
database
]
>
snapshot
Connects to
server
, retrieves a snapshot of the schema and
              data in
database
, and prints it on stdout in the format
              used for OVSDB standalone and active-backup databases. This is an appropriate way to back up any remote database."
929,30,ovsdb-client,"This is an appropriate way to back up any remote database. The database snapshot that it outputs is suitable to be
              served up directly by
ovsdb-server
or used as the input to
ovsdb-client restore
. Another way to back up a standalone or active-backup
              database is to copy its database file, e.g."
929,31,ovsdb-client,"Another way to back up a standalone or active-backup
              database is to copy its database file, e.g. with
cp
. This
              is safe even if the database is in use."
929,32,ovsdb-client,"This
              is safe even if the database is in use. The output does not include ephemeral columns, which by
              design do not survive across restarts of
ovsdb-server
. [
--force
]
restore
[
server
] [
database
]
<
snapshot
Reads
snapshot
, which must be a OVSDB standalone or active-
              backup database (possibly but not necessarily created by
ovsdb-client backup)."
929,33,ovsdb-client,"[
--force
]
restore
[
server
] [
database
]
<
snapshot
Reads
snapshot
, which must be a OVSDB standalone or active-
              backup database (possibly but not necessarily created by
ovsdb-client backup). Then, connects to
server
, verifies
              that
database
and
snapshot
have the same schema, then
              deletes all of the data in
database
and replaces it by
snapshot
. The replacement happens atomically, in a single
              transaction."
929,34,ovsdb-client,"The replacement happens atomically, in a single
              transaction. UUIDs for rows in the restored database will differ from
              those in
snapshot
, because the OVSDB protocol does not
              allow clients to specify row UUIDs. Another way to restore
              a standalone or active-backup database, which does also
              restore row UUIDs, is to stop the server or servers,
              replace the database file by the snapshot, then restart the
              database."
929,35,ovsdb-client,"Another way to restore
              a standalone or active-backup database, which does also
              restore row UUIDs, is to stop the server or servers,
              replace the database file by the snapshot, then restart the
              database. Either way, ephemeral columns are not restored,
              since by design they do not survive across restarts of
ovsdb-server
. Normally
restore
exits with a failure if
snapshot
and the
              server's database have different schemas."
929,36,ovsdb-client,"Normally
restore
exits with a failure if
snapshot
and the
              server's database have different schemas. In such a case,
              it is a good idea to convert the database to the new schema
              before restoring, e.g. with
ovsdb-client convert
."
929,37,ovsdb-client,"with
ovsdb-client convert
. Use
--force
to proceed regardless of schema differences even
              though the restore might fail with an error or succeed with
              surprising results. monitor
[
server
] [
database
]
table
[
column
[
,
column
]...]..."
929,38,ovsdb-client,"monitor
[
server
] [
database
]
table
[
column
[
,
column
]...]... monitor-cond
[
server
] [
database
]
conditions table
[
column
[
,
column
]...]... monitor-cond-since
[
server
] [
database
] [
last-id
]
conditions table
[
column
[
,
column
]...]..."
929,39,ovsdb-client,"monitor-cond-since
[
server
] [
database
] [
last-id
]
conditions table
[
column
[
,
column
]...]... Connects to
server
and monitors the contents of rows that
              match conditions in
table
in
database
. By default, the
              initial contents of
table
are printed, followed by each
              change as it occurs."
929,40,ovsdb-client,"By default, the
              initial contents of
table
are printed, followed by each
              change as it occurs. If conditions empty, all rows will be
              monitored. If at least one
column
is specified, only those
              columns are monitored."
929,41,ovsdb-client,"If at least one
column
is specified, only those
              columns are monitored. The following
column
names have
              special meanings:
!initial
Do not print the initial contents of the specified
                     columns. !insert
Do not print newly inserted rows."
929,42,ovsdb-client,"!insert
Do not print newly inserted rows. !delete
Do not print deleted rows. !modify
Do not print modifications to existing rows."
929,43,ovsdb-client,"!modify
Do not print modifications to existing rows. Multiple [
column
[
,
column
]...] groups may be specified as
              separate arguments, e.g. to apply different reporting
              parameters to each group."
929,44,ovsdb-client,"to apply different reporting
              parameters to each group. Whether multiple groups or only
              a single group is specified, any given column may only be
              mentioned once on the command line. conditions
is a JSON array of <condition> as defined in RFC
              7047 5.1 with the following change: A condition can be
              either a 3-element JSON array as described in the RFC or a
              boolean value."
929,45,ovsdb-client,"conditions
is a JSON array of <condition> as defined in RFC
              7047 5.1 with the following change: A condition can be
              either a 3-element JSON array as described in the RFC or a
              boolean value. If
--detach
is used with
monitor
,
monitor-cond
or
monitor-cond-since
, then
ovsdb-client
detaches after it has
              successfully received and printed the initial contents of
table
. The
monitor
command uses RFC 7047 ""monitor"" method to open
              a monitor session with the server."
929,46,ovsdb-client,"The
monitor
command uses RFC 7047 ""monitor"" method to open
              a monitor session with the server. The
monitor-cond
and
monitor-cond-since
commandls uses RFC 7047 extension
              ""monitor_cond"" and ""monitor_cond_since"" methods. See
ovsdb-server(1)
for details."
929,47,ovsdb-client,"See
ovsdb-server(1)
for details. monitor
[
server
] [
database
]
ALL
Connects to
server
and monitors the contents of all tables
              in
database
. Prints initial values and all kinds of
              changes to all columns in the database."
929,48,ovsdb-client,"Prints initial values and all kinds of
              changes to all columns in the database. The
--detach
option causes
ovsdb-client
to detach after it successfully
              receives and prints the initial database contents. The
monitor
command uses RFC 7047 ""monitor"" method to open
              a monitor session with the server."
929,49,ovsdb-client,"The
monitor
command uses RFC 7047 ""monitor"" method to open
              a monitor session with the server. wait
[
server
]
database state
Waits for
database
on
server
to enter a desired
state
,
              which may be one of:
added
Waits until a database with the given name has been
                     added to
server
. connected
Waits until a database with the given name has been
                     added to
server
."
929,50,ovsdb-client,"connected
Waits until a database with the given name has been
                     added to
server
. Then, if
database
is clustered,
                     additionally waits until it has joined and connected
                     to its cluster. removed
Waits until
database
has been removed from the
                     database server."
929,51,ovsdb-client,"removed
Waits until
database
has been removed from the
                     database server. This can also be used to wait for
                     a database to complete leaving its cluster, because
ovsdb-server
removes a database at that point. database
is mandatory for this command because it is often
              used to check for databases that have not yet been added to
              the server, so that the
ovsdb-client
semantics of acting on
              a default database do not work."
929,52,ovsdb-client,"database
is mandatory for this command because it is often
              used to check for databases that have not yet been added to
              the server, so that the
ovsdb-client
semantics of acting on
              a default database do not work. This command acts on a particular database server, not on a
              cluster, so
server
must name a single server, not a comma-
              delimited list of servers. Testing commands
These commands are mostly of interest for testing the correctness
       of the OVSDB server."
929,53,ovsdb-client,"Testing commands
These commands are mostly of interest for testing the correctness
       of the OVSDB server. lock
[
server
]
lock
steal
[
server
]
lock
unlock
[
server
]
lock
Connects to
server
and issues corresponding RFC 7047 lock
              operations on
lock
. Prints json reply or subsequent update
              messages."
929,54,ovsdb-client,"Prints json reply or subsequent update
              messages. The
--detach
option causes
ovsdb-client
to
              detach after it successfully receives and prints the
              initial reply. When running with the
--detach
option,
lock
,
steal
,
unlock
and
exit
commands can be issued by using
ovs-appctl
."
929,55,ovsdb-client,"When running with the
--detach
option,
lock
,
steal
,
unlock
and
exit
commands can be issued by using
ovs-appctl
. exit
command causes the
ovsdb-client
to close its
ovsdb-server
connection before exit. The
lock
,
steal
and
unlock
commands can be used to issue additional lock operations
              over the same
ovsdb-server
connection."
929,56,ovsdb-client,"exit
command causes the
ovsdb-client
to close its
ovsdb-server
connection before exit. The
lock
,
steal
and
unlock
commands can be used to issue additional lock operations
              over the same
ovsdb-server
connection. All above commands
              take a single
lock
argument, which does not have to be the
              same as the
lock
that
ovsdb-client
started with."
930,0,ovsdb-tool,"The
ovsdb-tool
program is a command-line tool for managing Open
       vSwitch database (OVSDB) files. It does not interact directly
       with running Open vSwitch database servers (instead, use
ovsdb-client
). For an introduction to OVSDB and its
       implementation in Open vSwitch, see
ovsdb(7)
."
930,1,ovsdb-tool,"For an introduction to OVSDB and its
       implementation in Open vSwitch, see
ovsdb(7)
. Each command that takes an optional
db
or
schema
argument has a
       default file location if it is not specified.. The default
db
is
/usr/local/etc/openvswitch/conf.db
."
930,2,ovsdb-tool,"The default
db
is
/usr/local/etc/openvswitch/conf.db
. The default
schema
is
/usr/local/share/openvswitch/vswitch.ovsschema
. This OVSDB implementation supports standalone and active-backup
       database service models with one on-disk format and a clustered
       database service model with a different format."
930,3,ovsdb-tool,"This OVSDB implementation supports standalone and active-backup
       database service models with one on-disk format and a clustered
       database service model with a different format. ovsdb-tool
supports both formats, but some commands are appropriate for only
       one format, as documented for individual commands below. For a
       specification of these formats, see
ovsdb(5)
."
930,4,ovsdb-tool,"For a
       specification of these formats, see
ovsdb(5)
. For more
       information on OVSDB service models, see the
Service Models
section in
ovsdb(7)
. Database Creation Commands
These commands create a new OVSDB database file."
930,5,ovsdb-tool,"Database Creation Commands
These commands create a new OVSDB database file. They will not
       overwrite an existing database file. To replace an existing
       database with a new one, first delete the old one."
930,6,ovsdb-tool,"To replace an existing
       database with a new one, first delete the old one. create
[
db
[
schema
]]
              Use this command to create the database for controlling
ovs-vswitchd
or another standalone or active-backup
              database. It creates database file
db
with the given
schema
, which must be the name of a file that contains an
              OVSDB schema in JSON format, as specified in the OVSDB
              specification."
930,7,ovsdb-tool,"It creates database file
db
with the given
schema
, which must be the name of a file that contains an
              OVSDB schema in JSON format, as specified in the OVSDB
              specification. The new database is initially empty. (You
              can use
cp
to copy a database including both its schema and
              data.)

       [
--election-timer=
ms
]
create-cluster
db contents local
Use this command to initialize the first server in a high-
              availability cluster of 3 (or more) database servers, e.g."
930,8,ovsdb-tool,"(You
              can use
cp
to copy a database including both its schema and
              data.)

       [
--election-timer=
ms
]
create-cluster
db contents local
Use this command to initialize the first server in a high-
              availability cluster of 3 (or more) database servers, e.g. for a database in an environment that cannot tolerate a
              single point of failure. It creates clustered database
              file
db
and configures the server to listen on
local
, which
              must take the form
protocol
:
ip
:
port
, where
protocol
is
tcp
or
ssl
,
ip
is the server's IP (either an IPv4 address or an
              IPv6 address enclosed in square brackets), and
port
is a
              TCP port number."
930,9,ovsdb-tool,"It creates clustered database
              file
db
and configures the server to listen on
local
, which
              must take the form
protocol
:
ip
:
port
, where
protocol
is
tcp
or
ssl
,
ip
is the server's IP (either an IPv4 address or an
              IPv6 address enclosed in square brackets), and
port
is a
              TCP port number. Only one address is specified, for the
              first server in the cluster, ordinarily the one for the
              server running
create-cluster
. The address is used for
              communication within the cluster, not for communicating
              with OVSDB clients, and must not use the same port used for
              the OVSDB protocol."
930,10,ovsdb-tool,"The address is used for
              communication within the cluster, not for communicating
              with OVSDB clients, and must not use the same port used for
              the OVSDB protocol. The new database is initialized with
contents
, which must
              name a file that contains either an OVSDB schema in JSON
              format or a standalone OVSDB database. If it is a schema
              file, the new database will initially be empty, with the
              given schema."
930,11,ovsdb-tool,"If it is a schema
              file, the new database will initially be empty, with the
              given schema. If it is a database file, the new database
              will have the same schema and contents. Leader election will be initiated by a follower if there is
              no heartbeat received from the cluster leader within the
              specified election timer."
930,12,ovsdb-tool,"Leader election will be initiated by a follower if there is
              no heartbeat received from the cluster leader within the
              specified election timer. The default leader election
              timer is 1000 milliseconds. To use a different value when
              creating the database, specify
--election-timer=
ms
, where
ms
is a value in milliseconds between 100 and 600000
              inclusive."
930,13,ovsdb-tool,"To use a different value when
              creating the database, specify
--election-timer=
ms
, where
ms
is a value in milliseconds between 100 and 600000
              inclusive. [
--cid=
uuid
]
join-cluster
db name local remote
... Use this command to initialize each server after the first
              one in an OVSDB high-availability cluster."
930,14,ovsdb-tool,"Use this command to initialize each server after the first
              one in an OVSDB high-availability cluster. It creates
              clustered database file
db
for a database named
name
, and
              configures the server to listen on
local
and to initially
              connect to
remote
, which must be a server that already
              belongs to the cluster. local
and
remote
use the same
protocol
:
ip
:
port
syntax as
create-cluster
."
930,15,ovsdb-tool,"local
and
remote
use the same
protocol
:
ip
:
port
syntax as
create-cluster
. The
name
must be the name of the schema or database passed
              to
create-cluster
. For example, the name of the OVN
              Southbound database schema is
OVN_Southbound
."
930,16,ovsdb-tool,"For example, the name of the OVN
              Southbound database schema is
OVN_Southbound
. Use
ovsdb-tool
's
schema-name
or
db-name
command to find out the
              name of a schema or database, respectively. This command does not do any network access, which means
              that it cannot actually join the new server to the cluster."
930,17,ovsdb-tool,"This command does not do any network access, which means
              that it cannot actually join the new server to the cluster. Instead, the
db
file that it creates prepares the server to
              join the cluster the first time that
ovsdb-server
serves
              it. As part of joining the cluster, the new server
              retrieves the database schema and obtains the list of all
              cluster members."
930,18,ovsdb-tool,"As part of joining the cluster, the new server
              retrieves the database schema and obtains the list of all
              cluster members. Only after that does it become a full
              member of the cluster. Optionally, more than one
remote
may be specified; for
              example, in a cluster that already contains multiple
              servers, one could specify all the existing servers."
930,19,ovsdb-tool,"Optionally, more than one
remote
may be specified; for
              example, in a cluster that already contains multiple
              servers, one could specify all the existing servers. This
              is beneficial if some of the existing servers are down
              while the new server joins, but it is not otherwise needed. By default, the
db
created by
join-cluster
will join any
              clustered database named
name
that is available at a
remote
."
930,20,ovsdb-tool,"By default, the
db
created by
join-cluster
will join any
              clustered database named
name
that is available at a
remote
. In theory, if machines go up and down and IP
              addresses change in the right way, it could join the wrong
              database cluster. To avoid this possibility, specify
--cid=
uuid
, where
uuid
is the cluster ID of the cluster to
              join, as printed by
ovsdb-tool get-cid
."
930,21,ovsdb-tool,"To avoid this possibility, specify
--cid=
uuid
, where
uuid
is the cluster ID of the cluster to
              join, as printed by
ovsdb-tool get-cid
. Database Migration Commands
This commands will convert cluster database to standalone
       database. cluster-to-standalone
db clusterdb
Use this command to convert to standalone database from
              clustered database when the cluster is down and cannot be
              revived."
930,22,ovsdb-tool,"cluster-to-standalone
db clusterdb
Use this command to convert to standalone database from
              clustered database when the cluster is down and cannot be
              revived. It creates new standalone
db
file from the given
              cluster
db
file. Version Management Commands
An OVSDB schema has a schema version number, and an OVSDB database
       embeds a particular version of an OVSDB schema."
930,23,ovsdb-tool,"Version Management Commands
An OVSDB schema has a schema version number, and an OVSDB database
       embeds a particular version of an OVSDB schema. These version
       numbers take the form
x
. y
."
930,24,ovsdb-tool,"y
. z
, e.g. 1.2.3
."
930,25,ovsdb-tool,"1.2.3
. The OVSDB implementation
       does not enforce a particular version numbering scheme, but
       schemas managed within the Open vSwitch project use the following
       approach. Whenever the database schema is changed in a non-
       backward compatible way (e.g."
930,26,ovsdb-tool,"Whenever the database schema is changed in a non-
       backward compatible way (e.g. deleting a column or a table),
x
is
       incremented (and
y
and
z
are reset to 0). When the database
       schema is changed in a backward compatible way (e.g."
930,27,ovsdb-tool,"When the database
       schema is changed in a backward compatible way (e.g. adding a new
       column),
y
is incremented (and
z
is reset to 0). When the
       database schema is changed cosmetically (e.g."
930,28,ovsdb-tool,"When the
       database schema is changed cosmetically (e.g. reindenting its
       syntax),
z
is incremented. Some OVSDB databases and schemas, especially very old ones, do not
       have a version number."
930,29,ovsdb-tool,"Some OVSDB databases and schemas, especially very old ones, do not
       have a version number. Schema version numbers and Open vSwitch version numbers are
       independent. These commands work with different versions of OVSDB schemas and
       databases."
930,30,ovsdb-tool,"These commands work with different versions of OVSDB schemas and
       databases. convert
[
db
[
schema
[
target
]]]
              Reads
db
, translating it into to the schema specified in
schema
, and writes out the new interpretation. If
target
is specified, the translated version is written as a new
              file named
target
, which must not already exist."
930,31,ovsdb-tool,"If
target
is specified, the translated version is written as a new
              file named
target
, which must not already exist. If
target
is omitted, then the translated version of the database
              replaces
db
in-place. In-place conversion cannot take
              place if the database is currently being served by
ovsdb-server
(instead, either stop
ovsdb-server
first or
              use
ovsdb-client
's
convert
command)."
930,32,ovsdb-tool,"In-place conversion cannot take
              place if the database is currently being served by
ovsdb-server
(instead, either stop
ovsdb-server
first or
              use
ovsdb-client
's
convert
command). This command can do simple ``upgrades'' and ``downgrades''
              on a database's schema. The data in
db
must be valid when
              interpreted under
schema
, with only one exception: data in
db
for tables and columns that do not exist in
schema
are
              ignored."
930,33,ovsdb-tool,"The data in
db
must be valid when
              interpreted under
schema
, with only one exception: data in
db
for tables and columns that do not exist in
schema
are
              ignored. Columns that exist in
schema
but not in
db
are
              set to their default values. All of
schema
's constraints
              apply in full."
930,34,ovsdb-tool,"All of
schema
's constraints
              apply in full. Some uses of this command can cause unrecoverable data
              loss. For example, converting a database from a schema
              that has a given column or table to one that does not will
              delete all data in that column or table."
930,35,ovsdb-tool,"For example, converting a database from a schema
              that has a given column or table to one that does not will
              delete all data in that column or table. Back up critical
              databases before converting them. This command is for standalone and active-backup databases
              only."
930,36,ovsdb-tool,"This command is for standalone and active-backup databases
              only. For clustered databases, use
ovsdb-client
's
convert
command to convert them online. needs-conversion
[
db
[
schema
]]
              Reads the schema embedded in
db
and the JSON schema from
schema
and compares them."
930,37,ovsdb-tool,"needs-conversion
[
db
[
schema
]]
              Reads the schema embedded in
db
and the JSON schema from
schema
and compares them. If the schemas are the same,
              prints
no
on stdout; if they differ, prints
yes
. This command is for standalone and active-backup databases
              only."
930,38,ovsdb-tool,"This command is for standalone and active-backup databases
              only. For clustered databases, use
ovsdb-client
's
needs-
conversion
command instead. db-version
[
db
]
schema-version
[
schema
]
              Prints the version number in the schema embedded within the
              database
db
or in the JSON schema
schema
on stdout."
930,39,ovsdb-tool,"db-version
[
db
]
schema-version
[
schema
]
              Prints the version number in the schema embedded within the
              database
db
or in the JSON schema
schema
on stdout. If
schema
or
db
was created before schema versioning was
              introduced, then it will not have a version number and this
              command will print a blank line. The
db-version
command is for standalone and active-backup
              databases only."
930,40,ovsdb-tool,"The
db-version
command is for standalone and active-backup
              databases only. For clustered databases, use
ovsdb-client
's
schema-version
command instead. db-cksum
[
db
]
schema-cksum
[
schema
]
              Prints the checksum in the schema embedded within the
              database
db
or of the JSON schema
schema
on stdout."
930,41,ovsdb-tool,"db-cksum
[
db
]
schema-cksum
[
schema
]
              Prints the checksum in the schema embedded within the
              database
db
or of the JSON schema
schema
on stdout. If
schema
or
db
was created before schema checksums were
              introduced, then it will not have a checksum and this
              command will print a blank line. The
db-cksum
command is for standalone and active-backup
              databases only."
930,42,ovsdb-tool,"The
db-cksum
command is for standalone and active-backup
              databases only. For clustered databases, use
ovsdb-client
's
schema-cksum
command instead. compare-versions
a op b
Compares
a
and
b
according to
op
."
930,43,ovsdb-tool,"compare-versions
a op b
Compares
a
and
b
according to
op
. Both
a
and
b
must be
              OVSDB schema version numbers in the form
x
. y
."
930,44,ovsdb-tool,"y
. z
, as
              described in
ovsdb(7)
, and
op
must be one of
< <= == >= >
!=
. If the comparison is true, exits with status 0; if it
              is false, exits with status 2."
930,45,ovsdb-tool,"If the comparison is true, exits with status 0; if it
              is false, exits with status 2. (Exit status 1 indicates an
              error, e.g. a
or
b
is the wrong syntax for an OVSDB version
              or
op
is not a valid comparison operator.)
Other Commands
compact
[
db
[
target
]]
              Reads
db
and writes a compacted version."
930,46,ovsdb-tool,"a
or
b
is the wrong syntax for an OVSDB version
              or
op
is not a valid comparison operator.)
Other Commands
compact
[
db
[
target
]]
              Reads
db
and writes a compacted version. If
target
is
              specified, the compacted version is written as a new file
              named
target
, which must not already exist. If
target
is
              omitted, then the compacted version of the database
              replaces
db
in-place."
930,47,ovsdb-tool,"If
target
is
              omitted, then the compacted version of the database
              replaces
db
in-place. This command is not needed in normal
              operation because
ovsdb-server
from time to time
              automatically compacts a database that grows much larger
              than its minimum size. This command does not work if
db
is currently being served
              by
ovsdb-server
, or if it is otherwise locked for writing
              by another process."
930,48,ovsdb-tool,"This command does not work if
db
is currently being served
              by
ovsdb-server
, or if it is otherwise locked for writing
              by another process. This command also does not work with
              clustered databases. Instead, in either case, send the
ovsdb-server/compact
command to
ovsdb-server
, via
ovs-appctl
)."
930,49,ovsdb-tool,"Instead, in either case, send the
ovsdb-server/compact
command to
ovsdb-server
, via
ovs-appctl
). [
--rbac-role=
role
]
query
[
db
]
transaction
Opens
db
, executes
transaction
on it, and prints the
              results. The
transaction
must be a JSON array in the
              format of the
params
array for the JSON-RPC
transact
method, as described in the OVSDB specification."
930,50,ovsdb-tool,"The
transaction
must be a JSON array in the
              format of the
params
array for the JSON-RPC
transact
method, as described in the OVSDB specification. This command opens
db
for read-only access, so it may
              safely run concurrently with other database activity,
              including
ovsdb-server
and other database writers. The
transaction
may specify database modifications, but these
              will have no effect on
db
."
930,51,ovsdb-tool,"The
transaction
may specify database modifications, but these
              will have no effect on
db
. By default, the transaction is executed using the
              ``superuser'' RBAC role. Use
--rbac-role
to specify a
              different role."
930,52,ovsdb-tool,"Use
--rbac-role
to specify a
              different role. This command does not work with clustered databases. Instead, use
ovsdb-client
's
query
command to send the query
              to
ovsdb-server
."
930,53,ovsdb-tool,"Instead, use
ovsdb-client
's
query
command to send the query
              to
ovsdb-server
. [
--rbac-role=
role
]
transact
[
db
]
transaction
Opens
db
, executes
transaction
on it, prints the results,
              and commits any changes to
db
. The
transaction
must be a
              JSON array in the format of the
params
array for the JSON-
              RPC
transact
method, as described in the OVSDB
              specification."
930,54,ovsdb-tool,"The
transaction
must be a
              JSON array in the format of the
params
array for the JSON-
              RPC
transact
method, as described in the OVSDB
              specification. This command does not work if
db
is currently being served
              by
ovsdb-server
, or if it is otherwise locked for writing
              by another process. This command also does not work with
              clustered databases."
930,55,ovsdb-tool,"This command also does not work with
              clustered databases. Instead, in either case, use
ovsdb-client
's
transact
command to send the query to
ovsdb-server
. By default, the transaction is executed using the
              ``superuser'' RBAC role."
930,56,ovsdb-tool,"By default, the transaction is executed using the
              ``superuser'' RBAC role. Use
--rbac-role
to specify a
              different role. [
-m
|
--more
]..."
930,57,ovsdb-tool,"[
-m
|
--more
]... show-log
[
db
]
              Prints a summary of the records in
db
's log, including the
              time and date at which each database change occurred and
              any associated comment. This may be useful for debugging."
930,58,ovsdb-tool,"This may be useful for debugging. To increase the verbosity of output, add
-m
(or
--more
) one
              or more times to the command line. With one
-m
,
show-log
prints a summary of the records added, deleted, or modified
              by each transaction."
930,59,ovsdb-tool,"With one
-m
,
show-log
prints a summary of the records added, deleted, or modified
              by each transaction. With two
-m
s,
show-log
also prints
              the values of the columns modified by each change to a
              record. This command works with standalone and active-backup
              databases and with clustered databases, but the output
              formats are different."
930,60,ovsdb-tool,"This command works with standalone and active-backup
              databases and with clustered databases, but the output
              formats are different. check-cluster
db
... Reads all of the records in the supplied databases, which
              must be collected from different servers (and ideally all
              the servers) in a single cluster."
930,61,ovsdb-tool,"Reads all of the records in the supplied databases, which
              must be collected from different servers (and ideally all
              the servers) in a single cluster. Checks each database for
              self-consistency and the set together for cross-
              consistency. If
ovsdb-tool
detects unusual but not
              necessarily incorrect content, it prints a warning or
              warnings on stdout."
930,62,ovsdb-tool,"If
ovsdb-tool
detects unusual but not
              necessarily incorrect content, it prints a warning or
              warnings on stdout. If
ovsdb-tool
find consistency errors,
              it prints an error on stderr and exits with status 1. Errors typically indicate bugs in
ovsdb-server
; please
              consider reporting them to the Open vSwitch developers."
930,63,ovsdb-tool,"Errors typically indicate bugs in
ovsdb-server
; please
              consider reporting them to the Open vSwitch developers. db-name
[
db
]
schema-name
[
schema
]
              Prints the name of the schema embedded within the database
db
or in the JSON schema
schema
on stdout. db-cid
db
Prints the cluster ID, which is a UUID that identifies the
              cluster, for
db
."
930,64,ovsdb-tool,"db-cid
db
Prints the cluster ID, which is a UUID that identifies the
              cluster, for
db
. If
db
is a database newly created by
ovsdb-tool cluster-join
that has not yet successfully
              joined its cluster, and
--cid
was not specified on the
cluster-join
command line, then this command will output an
              error, and exit with status 2, because the cluster ID is
              not yet known. This command works only with clustered
              databases."
930,65,ovsdb-tool,"This command works only with clustered
              databases. The all-zeros UUID is not a valid cluster ID. db-sid
db
Prints the server ID, which is a UUID that identifies the
              server, for
db
."
930,66,ovsdb-tool,"db-sid
db
Prints the server ID, which is a UUID that identifies the
              server, for
db
. This command works only with clustered
              databases. It works even if
db
is a database newly created
              by
ovsdb-tool cluster-join
that has not yet successfully
              joined its cluster."
930,67,ovsdb-tool,"It works even if
db
is a database newly created
              by
ovsdb-tool cluster-join
that has not yet successfully
              joined its cluster. db-local-address db
Prints the local address used for database clustering for
db
, in the same
protocol
:
ip
:
port
form used on
create-cluster
and
join-cluster
. db-is-clustered
db
db-is-standalone
db
Tests whether
db
is a database file in clustered or
              standalone format, respectively."
930,68,ovsdb-tool,"db-is-clustered
db
db-is-standalone
db
Tests whether
db
is a database file in clustered or
              standalone format, respectively. If so, exits with status
              0; if not, exits with status 2. (Exit status 1 indicates
              an error, e.g."
930,69,ovsdb-tool,"If so, exits with status
              0; if not, exits with status 2. (Exit status 1 indicates
              an error, e.g. db
is not an OVSDB database or does not
              exist.)"
931,0,package-cleanup,"package-cleanup
is a program for cleaning up the locally-installed
       RPMs."
932,0,p11tool,"Program that allows operations on PKCS #11 smart cards and
       security modules. To use PKCS #11 tokens with GnuTLS the p11-kit configuration files
       need to be setup. That is create a .module file in
       /etc/pkcs11/modules with the contents 'module:
       /path/to/pkcs11.so'."
932,1,p11tool,"That is create a .module file in
       /etc/pkcs11/modules with the contents 'module:
       /path/to/pkcs11.so'. Alternatively the configuration file
       /etc/gnutls/pkcs11.conf has to exist and contain a number of lines
       of the form 'load=/usr/lib/opensc-pkcs11.so'. You can provide the PIN to be used for the PKCS #11 operations
       with the environment variables GNUTLS_PIN and GNUTLS_SO_PIN."
933,0,ovsdb-server,"The
ovsdb-server
program provides RPC interfaces to one or more
       Open vSwitch databases (OVSDBs). It supports JSON-RPC client
       connections over active or passive TCP/IP or Unix domain sockets. For an introduction to OVSDB and its implementation in Open
       vSwitch, see
ovsdb(7)
."
933,1,ovsdb-server,"For an introduction to OVSDB and its implementation in Open
       vSwitch, see
ovsdb(7)
. Each OVSDB file may be specified on the command line as
database
. Relay databases may be specified on the command line as
relay:schema_name:remote
."
933,2,ovsdb-server,"Relay databases may be specified on the command line as
relay:schema_name:remote
. For a detailed description of relay
       database argument, see
ovsdb(7)
. If none of database files or
       relay databases is specified, the default is
/usr/local/etc/openvswitch/conf.db
."
933,3,ovsdb-server,"If none of database files or
       relay databases is specified, the default is
/usr/local/etc/openvswitch/conf.db
. The database files must
       already have been created and initialized using, for example,
ovsdb-tool
's
create
,
create-cluster
, or
join-cluster
command. All types of databases can alternatively be added using a
       configuration file provided via
--config-file
option."
933,4,ovsdb-server,"All types of databases can alternatively be added using a
       configuration file provided via
--config-file
option. This option
       is mutually exclusive with specifying
database
on the command
       line. For a detailed description of the configuration file format
       see
ovsdb(7)
."
933,5,ovsdb-server,"For a detailed description of the configuration file format
       see
ovsdb(7)
. This OVSDB implementation supports standalone, active-backup,
       relay and clustered database service models, as well as database
       replication. See the Service Models section of
ovsdb(7)
for more
       information."
933,6,ovsdb-server,"See the Service Models section of
ovsdb(7)
for more
       information. For clustered databases, when the
--detach
option is used,
ovsdb-server
detaches without waiting for the server to
       successfully join a cluster (if the database file is freshly
       created with
ovsdb-tool join-cluster
) or connect to a cluster that
       it has already joined. Use
ovsdb-client wait
(see
ovsdb-client(1)
) to wait until the server has successfully joined
       and connected to a cluster."
933,7,ovsdb-server,"Use
ovsdb-client wait
(see
ovsdb-client(1)
) to wait until the server has successfully joined
       and connected to a cluster. The same is true for relay databases. Same commands could be used to wait for a relay database to
       connect to the relay source (remote)."
933,8,ovsdb-server,"Same commands could be used to wait for a relay database to
       connect to the relay source (remote). In addition to user-specified databases,
ovsdb-server
version 2.9
       and later also always hosts a built-in database named
_Server
. Please see
ovsdb-server(5)
for documentation on this database's
       schema."
934,0,passwd,"The
passwd
command changes passwords for user accounts. A normal
       user may only change the password for their own account, while the
       superuser may change the password for any account. passwd
also
       changes the account or associated password validity period."
934,1,passwd,"passwd
also
       changes the account or associated password validity period. Password Changes
The user is first prompted for their old password, if one is
       present. This password is then encrypted and compared against the
       stored password."
934,2,passwd,"This password is then encrypted and compared against the
       stored password. The user has only one chance to enter the correct
       password. The superuser is permitted to bypass this step so that
       forgotten passwords may be changed."
934,3,passwd,"The superuser is permitted to bypass this step so that
       forgotten passwords may be changed. After the password has been entered, password aging information is
       checked to see if the user is permitted to change the password at
       this time. If not,
passwd
refuses to change the password and
       exits."
934,4,passwd,"If not,
passwd
refuses to change the password and
       exits. The user is then prompted twice for a replacement password. The
       second entry is compared against the first and both are required
       to match in order for the password to be changed."
934,5,passwd,"The
       second entry is compared against the first and both are required
       to match in order for the password to be changed. Then, the password is tested for complexity. passwd
will reject
       any password which is not suitably complex."
934,6,passwd,"passwd
will reject
       any password which is not suitably complex. Care must be taken not
       to include the system default erase or kill characters. Hints for user passwords
The security of a password depends upon the strength of the
       encryption algorithm and the size of the key space."
934,7,passwd,"Hints for user passwords
The security of a password depends upon the strength of the
       encryption algorithm and the size of the key space. The legacy
UNIX
System encryption method is based on the NBS DES algorithm. More recent methods are now recommended (see
ENCRYPT_METHOD
)."
934,8,passwd,"More recent methods are now recommended (see
ENCRYPT_METHOD
). The
       size of the key space depends upon the randomness of the password
       which is selected. Compromises in password security normally result from careless
       password selection or handling."
934,9,passwd,"Compromises in password security normally result from careless
       password selection or handling. For this reason, you should not
       select a password which appears in a dictionary or which must be
       written down. The password should also not be a proper name, your
       license number, birth date, or street address."
934,10,passwd,"The password should also not be a proper name, your
       license number, birth date, or street address. Any of these may be
       used as guesses to violate system security. As a general guideline, passwords should be long and random."
934,11,passwd,"As a general guideline, passwords should be long and random. It's
       fine to use simple character sets, such as passwords consisting
       only of lowercase letters, if that helps memorizing longer
       passwords. For a password consisting only of lowercase English
       letters randomly chosen, and a length of 32, there are 26^32
       (approximately 2^150) different possible combinations."
934,12,passwd,"For a password consisting only of lowercase English
       letters randomly chosen, and a length of 32, there are 26^32
       (approximately 2^150) different possible combinations. Being an
       exponential equation, it's apparent that the exponent (the length)
       is more important than the base (the size of the character set). You can find advice on how to choose a strong password on
http://en.wikipedia.org/wiki/Password_strength"
935,0,paste,"Write lines consisting of the sequentially corresponding lines
       from each FILE, separated by TABs, to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
935,1,paste,"With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too. -d
,
--delimiters
=
LIST
reuse characters from LIST instead of TABs
-s
,
--serial
paste one file at a time instead of in parallel
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit"
936,0,paste,"The
paste
utility shall concatenate the corresponding lines of the
       given input files, and write the resulting lines to standard
       output. The default operation of
paste
shall concatenate the corresponding
       lines of the input files. The <newline> of every line except the
       line from the last input file shall be replaced with a <tab>."
936,1,paste,"The default operation of
paste
shall concatenate the corresponding
       lines of the input files. The <newline> of every line except the
       line from the last input file shall be replaced with a <tab>. If an end-of-file condition is detected on one or more input
       files, but not all input files,
paste
shall behave as though empty
       lines were read from the files on which end-of-file was detected,
       unless the
-s
option is specified."
937,0,patch,"The
patch
utility shall read a source (patch) file containing any
       of four forms of difference (diff) listings produced by the
diff
utility (normal, copied context, unified context, or in the style
       of
ed
) and apply those differences to a file. By default,
patch
shall read from the standard input. The
patch
utility shall attempt to determine the type of the
diff
listing, unless overruled by a
-c
,
-e
,
-n
, or
-u
option."
937,1,patch,"The
patch
utility shall attempt to determine the type of the
diff
listing, unless overruled by a
-c
,
-e
,
-n
, or
-u
option. If the patch file contains more than one patch,
patch
shall
       attempt to apply each of them as if they came from separate patch
       files. (In this case, the application shall ensure that the name
       of the patch file is determinable for each
diff
listing.)"
938,0,patch,"patch
takes a patch file
patchfile
containing a difference listing
       produced by the
diff
program and applies those differences to one
       or more original files, producing patched versions. Normally the
       patched versions are put in place of the originals. Backups can
       be made; see the
-b
or
--backup
option."
938,1,patch,"Backups can
       be made; see the
-b
or
--backup
option. The names of the files to
       be patched are usually taken from the patch file, but if there's
       just one file to be patched it can be specified on the command
       line as
originalfile
. Upon startup, patch attempts to determine the type of the diff
       listing, unless overruled by a
-c
(
--context
),
-e
(
--ed
),
-n
(
--normal
), or
-u
(
--unified
) option."
938,2,patch,"Upon startup, patch attempts to determine the type of the diff
       listing, unless overruled by a
-c
(
--context
),
-e
(
--ed
),
-n
(
--normal
), or
-u
(
--unified
) option. Context diffs (old-style,
       new-style, and unified) and normal diffs are applied by the
patch
program itself, while
ed
diffs are simply fed to the
ed
(1) editor
       via a pipe. patch
tries to skip any leading garbage, apply the diff, and then
       skip any trailing garbage."
938,3,patch,"patch
tries to skip any leading garbage, apply the diff, and then
       skip any trailing garbage. Thus you could feed an email message
       containing a diff listing to
patch
, and it should work. If the
       entire diff is indented by a consistent amount, if lines end in
       CRLF, or if a diff is encapsulated one or more times by prepending
       ""
-
"" to lines starting with ""
-
"" as specified by Internet RFC 934,
       this is taken into account."
938,4,patch,"If the
       entire diff is indented by a consistent amount, if lines end in
       CRLF, or if a diff is encapsulated one or more times by prepending
       ""
-
"" to lines starting with ""
-
"" as specified by Internet RFC 934,
       this is taken into account. After removing indenting or
       encapsulation, lines beginning with
#
are ignored, as they are
       considered to be comments. With context diffs, and to a lesser extent with normal diffs,
patch
can detect when the line numbers mentioned in the patch are
       incorrect, and attempts to find the correct place to apply each
       hunk of the patch."
938,5,patch,"With context diffs, and to a lesser extent with normal diffs,
patch
can detect when the line numbers mentioned in the patch are
       incorrect, and attempts to find the correct place to apply each
       hunk of the patch. As a first guess, it takes the line number
       mentioned for the hunk, plus or minus any offset used in applying
       the previous hunk. If that is not the correct place,
patch
scans
       both forwards and backwards for a set of lines matching the
       context given in the hunk."
938,6,patch,"If that is not the correct place,
patch
scans
       both forwards and backwards for a set of lines matching the
       context given in the hunk. First
patch
looks for a place where
       all lines of the context match. If no such place is found, and
       it's a context diff, and the maximum fuzz factor is set to 1 or
       more, then another scan takes place ignoring the first and last
       line of context."
938,7,patch,"If no such place is found, and
       it's a context diff, and the maximum fuzz factor is set to 1 or
       more, then another scan takes place ignoring the first and last
       line of context. If that fails, and the maximum fuzz factor is
       set to 2 or more, the first two and last two lines of context are
       ignored, and another scan is made. (The default maximum fuzz
       factor is 2.)

       Hunks with less prefix context than suffix context (after applying
       fuzz) must apply at the start of the file if their first line
       number is 1."
938,8,patch,"(The default maximum fuzz
       factor is 2.)

       Hunks with less prefix context than suffix context (after applying
       fuzz) must apply at the start of the file if their first line
       number is 1. Hunks with more prefix context than suffix context
       (after applying fuzz) must apply at the end of the file. If
patch
cannot find a place to install that hunk of the patch, it
       puts the hunk out to a reject file, which normally is the name of
       the output file plus a
.rej
suffix, or
#
if
.rej
would generate a
       file name that is too long (if even appending the single character
#
makes the file name too long, then
#
replaces the file name's
       last character)."
938,9,patch,"If
patch
cannot find a place to install that hunk of the patch, it
       puts the hunk out to a reject file, which normally is the name of
       the output file plus a
.rej
suffix, or
#
if
.rej
would generate a
       file name that is too long (if even appending the single character
#
makes the file name too long, then
#
replaces the file name's
       last character). The rejected hunk comes out in unified or context diff format. If
       the input was a normal diff, many of the contexts are simply null."
938,10,patch,"If
       the input was a normal diff, many of the contexts are simply null. The line numbers on the hunks in the reject file may be different
       than in the patch file: they reflect the approximate location
       patch thinks the failed hunks belong in the new file rather than
       the old one. As each hunk is completed, you are told if the hunk failed, and if
       so which line (in the new file)
patch
thought the hunk should go
       on."
938,11,patch,"As each hunk is completed, you are told if the hunk failed, and if
       so which line (in the new file)
patch
thought the hunk should go
       on. If the hunk is installed at a different line from the line
       number specified in the diff, you are told the offset. A single
       large offset
may
indicate that a hunk was installed in the wrong
       place."
938,12,patch,"A single
       large offset
may
indicate that a hunk was installed in the wrong
       place. You are also told if a fuzz factor was used to make the
       match, in which case you should also be slightly suspicious. If
       the
--verbose
option is given, you are also told about hunks that
       match exactly."
938,13,patch,"If
       the
--verbose
option is given, you are also told about hunks that
       match exactly. If no original file
origfile
is specified on the command line,
patch
tries to figure out from the leading garbage what the name
       of the file to edit is, using the following rules. First,
patch
takes an ordered list of candidate file names as
       follows:

         â¢  If the header is that of a context diff,
patch
takes the old
            and new file names in the header."
938,14,patch,"First,
patch
takes an ordered list of candidate file names as
       follows:

         â¢  If the header is that of a context diff,
patch
takes the old
            and new file names in the header. A name is ignored if it
            does not have enough slashes to satisfy the
-p
num
or
--strip=
num
option. The name
/dev/null
is also ignored."
938,15,patch,"The name
/dev/null
is also ignored. â¢  If there is an
Index:
line in the leading garbage and if
            either the old and new names are both absent or if
patch
is
            conforming to POSIX,
patch
takes the name in the
Index:
line. â¢  For the purpose of the following rules, the candidate file
            names are considered to be in the order (old, new, index),
            regardless of the order that they appear in the header."
938,16,patch,"â¢  For the purpose of the following rules, the candidate file
            names are considered to be in the order (old, new, index),
            regardless of the order that they appear in the header. Then
patch
selects a file name from the candidate list as follows:

         â¢  If some of the named files exist,
patch
selects the first
            name if conforming to POSIX, and the best name otherwise. â¢  If
patch
is not ignoring RCS, ClearCase, Perforce, and SCCS
            (see the
-g
num
or
--get=
num
option), and no named files
            exist but an RCS, ClearCase, Perforce, or SCCS master is
            found,
patch
selects the first named file with an RCS,
            ClearCase, Perforce, or SCCS master."
938,17,patch,"â¢  If
patch
is not ignoring RCS, ClearCase, Perforce, and SCCS
            (see the
-g
num
or
--get=
num
option), and no named files
            exist but an RCS, ClearCase, Perforce, or SCCS master is
            found,
patch
selects the first named file with an RCS,
            ClearCase, Perforce, or SCCS master. â¢  If no named files exist, no RCS, ClearCase, Perforce, or SCCS
            master was found, some names are given,
patch
is not
            conforming to POSIX, and the patch appears to create a file,
patch
selects the best name requiring the creation of the
            fewest directories. â¢  If no file name results from the above heuristics, you are
            asked for the name of the file to patch, and
patch
selects
            that name."
938,18,patch,"â¢  If no file name results from the above heuristics, you are
            asked for the name of the file to patch, and
patch
selects
            that name. To determine the
best
of a nonempty list of file names,
patch
first takes all the names with the fewest path name components; of
       those, it then takes all the names with the shortest basename; of
       those, it then takes all the shortest names; finally, it takes the
       first remaining name. Additionally, if the leading garbage contains a
Prereq:
line,
patch
takes the first word from the prerequisites line (normally a
       version number) and checks the original file to see if that word
       can be found."
938,19,patch,"Additionally, if the leading garbage contains a
Prereq:
line,
patch
takes the first word from the prerequisites line (normally a
       version number) and checks the original file to see if that word
       can be found. If not,
patch
asks for confirmation before
       proceeding. The upshot of all this is that you should be able to run something
       like the following shell command:
patch -d /usr/src/local/blurfl
and patch a file in the
blurfl
directory directly from a patch
       that is read from standard input."
938,20,patch,"The upshot of all this is that you should be able to run something
       like the following shell command:
patch -d /usr/src/local/blurfl
and patch a file in the
blurfl
directory directly from a patch
       that is read from standard input. If the patch file contains more than one patch,
patch
tries to
       apply each of them as if they came from separate patch files. This means, among other things, that it is assumed that the name
       of the file to patch must be determined for each diff listing, and
       that the garbage before each diff listing contains interesting
       things such as file names and revision level, as mentioned
       previously."
939,0,pathchk,"Diagnose invalid or non-portable file names.
-p
check for most POSIX systems
-P
check for empty names and leading ""-""
--portability
check for all POSIX systems (equivalent to
-p -P
)
--help
display this help and exit
--version
output version information and exit"
940,0,pathchk,"The
pathchk
utility shall check that one or more pathnames are
       valid (that is, they could be used to access or create a file
       without causing syntax errors) and portable (that is, no filename
       truncation results). More extensive portability checks are
       provided by the
-p
and
-P
options. By default, the
pathchk
utility shall check each component of each
pathname
operand based on the underlying file system."
940,1,pathchk,"By default, the
pathchk
utility shall check each component of each
pathname
operand based on the underlying file system. A diagnostic
       shall be written for each
pathname
operand that:

        *  Is longer than {PATH_MAX} bytes (see
Pathname Variable Values
in the Base Definitions volume of POSIX.1â2017,
limits.h(0p)
)

        *  Contains any component longer than {NAME_MAX} bytes in its
           containing directory

        *  Contains any component in a directory that is not searchable

        *  Contains any byte sequence that is not valid in its containing
           directory

       The format of the diagnostic message is not specified, but shall
       indicate the error detected and the corresponding
pathname
operand. It shall not be considered an error if one or more components of a
pathname
operand do not exist as long as a file matching the
       pathname specified by the missing components could be created that
       does not violate any of the checks specified above."
941,0,pcap-config,"When  run  with  the
--cflags
option,
pcap-config
writes to the
       standard  output  the
-I
compiler  flags  required  to   include
       libpcap's  header  files. When run with the
--libs
option,
pcap-
config
writes to the standard output the
-L
and
-l
linker  flags
       required  to  link  with libpcap, including
-l
flags for libraries
       required by libpcap. When run with the
--additional-libs
option,
pcap-config
writes to the standard output the
-L
and
-l
flags for
       libraries required by libpcap, but not the
-lpcap
flag  to  link
       with libpcap itself."
941,1,pcap-config,"When run with the
--libs
option,
pcap-
config
writes to the standard output the
-L
and
-l
linker  flags
       required  to  link  with libpcap, including
-l
flags for libraries
       required by libpcap. When run with the
--additional-libs
option,
pcap-config
writes to the standard output the
-L
and
-l
flags for
       libraries required by libpcap, but not the
-lpcap
flag  to  link
       with libpcap itself. By  default,  it  writes  flags  appropriate  for compiling with a
       dynamically-linked version of libpcap; the
--static
flag causes it
       to write flags appropriate for compiling with a  statically-linked
       version of libpcap."
942,0,pcp-buddyinfo,"The
pcp-buddyinfo
command is used for viewing different stats
       related to buddyinfo. It helps users analyze the dynamic
       behaviour of the buddy algorithm used in the Linux kernel virtual
       memory subsystem. The information includes the total number of
       zones that are currently active, counts of different order pages,
       and so on."
942,1,pcp-buddyinfo,"The information includes the total number of
       zones that are currently active, counts of different order pages,
       and so on. By default,
pcp-buddyinfo
reports live data for the
       local host. The statistics shown are as follows:
HEADER          DESCRIPTION
_               _
       Normal          zones available
       Nodes           available nodes
       Order0          available pages of order 0
       Order1          available pages of order 1
       Order2          available pages of order 2
       Order3          available pages of order 3
       Order4          available pages of order 4
       Order5          available pages of order 5
       Order6          available pages of order 6
       Order7          available pages of order 7
       Order8          available pages of order 8
       Order9          available pages of order 9
       Order10         available pages of order 10

       Each column represents the number of pages of a certain order (a
       certain size) that are available at any given time."
942,2,pcp-buddyinfo,"The statistics shown are as follows:
HEADER          DESCRIPTION
_               _
       Normal          zones available
       Nodes           available nodes
       Order0          available pages of order 0
       Order1          available pages of order 1
       Order2          available pages of order 2
       Order3          available pages of order 3
       Order4          available pages of order 4
       Order5          available pages of order 5
       Order6          available pages of order 6
       Order7          available pages of order 7
       Order8          available pages of order 8
       Order9          available pages of order 9
       Order10         available pages of order 10

       Each column represents the number of pages of a certain order (a
       certain size) that are available at any given time. For example,
       for zone DMA (direct memory access), there are 90 of
       2^(0*PAGE_SIZE) chunks of memory. Similarly, there are 6 of
       2^(1*PAGE_SIZE) chunks, and 2 of 2^(2*PAGE_SIZE) chunks of memory
       available."
942,3,pcp-buddyinfo,"For example,
       for zone DMA (direct memory access), there are 90 of
       2^(0*PAGE_SIZE) chunks of memory. Similarly, there are 6 of
       2^(1*PAGE_SIZE) chunks, and 2 of 2^(2*PAGE_SIZE) chunks of memory
       available. The DMA row references the first 16 MB on a system, the HighMem
       row references all memory greater than 4 GB on a system, and the
       Normal row references all memory in between."
943,0,pcp-atopsar,"The
pcp-atopsar
program can be used to report statistics at the
       system level. In the first synopsis line (no sampling interval specified),
pcp-
atopsar
extracts data from a raw logfile that has been recorded
       previously by
pmlogger(1)
(or via the
-w
option of the
pcp-atop
program). You can specify the name of the logfile with the
-r
option of the
pcp-atopsar
program."
943,1,pcp-atopsar,"You can specify the name of the logfile with the
-r
option of the
pcp-atopsar
program. When a
pmlogger
daily logfile is used, named
$PCP_LOG_DIR/pmlogger/[host]/YYYYMMDD
(where YYYYMMDD reflects the
       date), the required date of the form YYYYMMDD can be specified
       with the
-r
option instead of the filename, or the symbolic name
       'y' can be used for yesterday's daily logfile (this can be
       repeated so 'yyyy' indicates the logfile of four days ago). If
       the
-r
option is not specified at all, today's daily logfile is
       used by default."
943,2,pcp-atopsar,"If
       the
-r
option is not specified at all, today's daily logfile is
       used by default. By default, the hostname of the localhost will be used when
       resolving
pmlogger
archives, however an alternative
host
can be
       specified using the
-h
option. The starting and ending times of the report can be defined using
       the options
-b
and
-e
followed by a time argument of the form
       [YYYYMMDD]hh:mm[ss]."
943,3,pcp-atopsar,"The starting and ending times of the report can be defined using
       the options
-b
and
-e
followed by a time argument of the form
       [YYYYMMDD]hh:mm[ss]. In the second synopsis line,
pcp-atopsar
reads actual activity
       counters from the kernel with the specified
interval
(in seconds)
       and the specified number of
samples
(optionally). When
pcp-
atopsar
is activated in this way it immediately sends the output
       for every requested report to standard output."
943,4,pcp-atopsar,"When
pcp-
atopsar
is activated in this way it immediately sends the output
       for every requested report to standard output. If only one type
       of report is requested, the header is printed once and after every
interval
seconds the statistical counters are shown for that
       period. If several reports are requested, a header is printed per
       sample followed by the statistical counters for that period."
943,5,pcp-atopsar,"If several reports are requested, a header is printed per
       sample followed by the statistical counters for that period. When invoked via the
pcp(1)
command, the
PCPIntro(1)
options
-h
/
--host
,
-a
/
--archive
,
-O
/
--origin
,
-s
/
--samples
,
-t
/
--interval
,
-Z
/
--timezone
and several other
pcp options
become indirectly
       available, see
PCPIntro(1)
for their descriptions. Some generic flags can be specified to influence the behaviour of
       the
pcp-atopsar
program:
-S
By default the timestamp at the beginning of a line is
            suppressed if more lines are shown for one interval."
943,6,pcp-atopsar,"Some generic flags can be specified to influence the behaviour of
       the
pcp-atopsar
program:
-S
By default the timestamp at the beginning of a line is
            suppressed if more lines are shown for one interval. With
            this flag a timestamp is given for every output-line (easier
            for post-processing). -a
By default certain resources as disks and network interfaces
            are only shown when they were active during the interval."
943,7,pcp-atopsar,"-a
By default certain resources as disks and network interfaces
            are only shown when they were active during the interval. With this flag all resources of a given type are shown, even
            if they were inactive during the interval. -x
By default
pcp-atopsar
only uses colors if output is directed
            to a terminal (window)."
943,8,pcp-atopsar,"-x
By default
pcp-atopsar
only uses colors if output is directed
            to a terminal (window). These colors might indicate that a
            critical occupation percentage has been reached (red) or has
            been almost reached (cyan) for a particular resource. See
            the man-page of
atop
for a detailed description of this
            feature (section COLORS)."
943,9,pcp-atopsar,"See
            the man-page of
atop
for a detailed description of this
            feature (section COLORS). With the flag
-x
the use of colors is suppressed
            unconditionally. -C
By default
pcp-atopsar
only uses colors if output is directed
            to a terminal (window)."
943,10,pcp-atopsar,"-C
By default
pcp-atopsar
only uses colors if output is directed
            to a terminal (window). These colors might indicate that a
            critical occupation percentage has been reached (red) or has
            been almost reached (cyan) for a particular resource. See
            the man-page of
atop
for a detailed description of this
            feature (section COLORS)."
943,11,pcp-atopsar,"See
            the man-page of
atop
for a detailed description of this
            feature (section COLORS). With the flag
-C
colors will always be used, even if output
            is not directed to a terminal. -M
Use markers at the end of a line to indicate that a critical
            occupation percentage has been reached ('*') or has been
            almost reached ('+') for particular resources."
943,12,pcp-atopsar,"-M
Use markers at the end of a line to indicate that a critical
            occupation percentage has been reached ('*') or has been
            almost reached ('+') for particular resources. The marker '*'
            is similar to the color red and the marker '+' to the color
            cyan. See the man-page of
atop
for a detailed description of
            these colors (section COLORS)."
943,13,pcp-atopsar,"See the man-page of
atop
for a detailed description of
            these colors (section COLORS). -H
Repeat the header line within a report for every
N
detail
            lines. The value of
N
is determined dynamically in case of
            output to a tty/window (depending on the number of lines);
            for output to a file or pipe this value is 23."
943,14,pcp-atopsar,"The value of
N
is determined dynamically in case of
            output to a tty/window (depending on the number of lines);
            for output to a file or pipe this value is 23. -R
Summarize
cnt
samples into one sample. When the logfile
            contains e.g."
943,15,pcp-atopsar,"When the logfile
            contains e.g. samples of 10 minutes, the use of the flag '-R
            6' shows a report with one sample for every hour. Other flags are used to define which reports are required:
-A
Show all possible reports."
943,16,pcp-atopsar,"Other flags are used to define which reports are required:
-A
Show all possible reports. -c
Report about CPU utilization (in total and per cpu). -g
Report about GPU utilization (per GPU)."
943,17,pcp-atopsar,"-g
Report about GPU utilization (per GPU). -p
Report about processor-related matters, like load-averages
            and hardware interrupts. -P
Report about processes."
943,18,pcp-atopsar,"-P
Report about processes. -m
Current memory- and swap-occupation. -s
Report about paging- and swapping-activity, and
            overcommitment."
943,19,pcp-atopsar,"-s
Report about paging- and swapping-activity, and
            overcommitment. -B
Report about Pressure Stall Information (PSI). -l
Report about utilization of logical volumes."
943,20,pcp-atopsar,"-l
Report about utilization of logical volumes. -f
Report about utilization of multiple devices. -d
Report about utilization of disks."
943,21,pcp-atopsar,"-d
Report about utilization of disks. -n
Report about NFS mounted filesystems on NFS client. -j
Report about NFS client activity."
943,22,pcp-atopsar,"-j
Report about NFS client activity. -J
Report about NFS server activity. -i
Report about the network interfaces."
943,23,pcp-atopsar,"-i
Report about the network interfaces. -I
Report about errors for network-interfaces. -w
Report about IP version 4 network traffic."
943,24,pcp-atopsar,"-w
Report about IP version 4 network traffic. -W
Report about errors for IP version 4 traffic. -y
General report about ICMP version 4 layer activity."
943,25,pcp-atopsar,"-y
General report about ICMP version 4 layer activity. -Y
Per-type report about ICMP version 4 layer activity. -u
Report about UDP version 4 network traffic."
943,26,pcp-atopsar,"-u
Report about UDP version 4 network traffic. -z
Report about IP version 6 network traffic. -Z
Report about errors for IP version 6 traffic."
943,27,pcp-atopsar,"-Z
Report about errors for IP version 6 traffic. -k
General report about ICMP version 6 layer activity. -K
Per-type report about ICMP version 6 layer activity."
943,28,pcp-atopsar,"-K
Per-type report about ICMP version 6 layer activity. -U
Report about UDP version 6 network traffic. -t
Report about TCP network traffic."
943,29,pcp-atopsar,"-t
Report about TCP network traffic. -T
Report about errors for TCP-traffic. -h
Report about Infiniband utilization."
943,30,pcp-atopsar,"-h
Report about Infiniband utilization. -O
Report about top-3 processes consuming most processor
            capacity. This report is only available when using a log
            file (not when specifying an interval)."
943,31,pcp-atopsar,"This report is only available when using a log
            file (not when specifying an interval). -G
Report about top-3 processes consuming most resident memory. This report is only available when using a log file (not when
            specifying an interval)."
943,32,pcp-atopsar,"This report is only available when using a log file (not when
            specifying an interval). -D
Report about top-3 processes issuing most disk transfers. This report is only available when using a log file (not when
            specifying an interval)."
943,33,pcp-atopsar,"This report is only available when using a log file (not when
            specifying an interval). -N
Report about top-3 processes issuing most IPv4/IPv6 socket
            transfers. This report is only available when using a log
            file (not when specifying an interval)."
944,0,pcp-check,"The Performance Co-Pilot (PCP) includes a number of core
       components that are likely to be pre-configured and operational,
       but it also includes a larger number of components that are not
       active by default. In the context of
pmcheck
these components
       cover services that are typically started as part of the system
       boot procedure, e.g. pmcd(1)
,
pmlogger(1)
,
pmproxy(1)
, etc."
944,1,pcp-check,"pmcd(1)
,
pmlogger(1)
,
pmproxy(1)
, etc. or
       optional Performance Metric Domain Agents (PMDAs) that augment the
       available performance metrics exported by
pmcd(1)
. pmcheck
allows the interrogation of the state of components with
       the
-s
,
--state
option."
944,2,pcp-check,"pmcheck
allows the interrogation of the state of components with
       the
-s
,
--state
option. Components can be activated with the
-a
,
--activate
option, or deactivated with the
-d
,
--deactivate
option. These three options are clearly mutually exclusive for
       any single execution of
pmcheck
, and in the absence of any of them
-s
is assumed to be the default."
944,3,pcp-check,"These three options are clearly mutually exclusive for
       any single execution of
pmcheck
, and in the absence of any of them
-s
is assumed to be the default. The set of components to be interrogated or configured are
       specified by the
component
name(s) from the command line, else all
       known components in the absence of any
component
arguments. When
       one or more
component
arguments are specified, these may
       optionally be
sh
(1) (glob) patterns that are matched against the
       names of the known components."
944,4,pcp-check,"When
       one or more
component
arguments are specified, these may
       optionally be
sh
(1) (glob) patterns that are matched against the
       names of the known components. The
-l
,
--list
option reports on known components. With one or
       more
components
each is reported."
944,5,pcp-check,"With one or
       more
components
each is reported. Without any
component
arguments
       the
-l
option lists all known components, which is simply all the
       component scripts (see the
COMPONENT SCRIPTS
section below) stored
       in the
$PCP_SHARE_DIR/lib/pmcheck
directory. If the
-v
option is
       also used, a short description of each requested component is also
       displayed."
944,6,pcp-check,"If the
-v
option is
       also used, a short description of each requested component is also
       displayed. Additional components can be integrated into the
pmcheck
framework, and the
-c
,
--file
option allows an alternate
sh
(1)
script
to be used instead of a script associated with a known
component
. In concert with the
-a
or
-d
options, the
-n
,
--show-me
option
       performs a dry run, showing the
sh
(1) commands that would be
       needed to perform the reconfiguration, but no reconfiguration is
       done."
944,7,pcp-check,"In concert with the
-a
or
-d
options, the
-n
,
--show-me
option
       performs a dry run, showing the
sh
(1) commands that would be
       needed to perform the reconfiguration, but no reconfiguration is
       done. Commands that need to be run as ``root'' are prefixed with
#
and other commands are prefixed with
$
. The
-v
,
--verbose
option increases reporting verbosity."
944,8,pcp-check,"The
-v
,
--verbose
option increases reporting verbosity. The
-x
,
--trace
option may be used specify that the component
       scripts are run with
-x
option to
sh
(1). This can assist with
       debugging the failure of a component script or during the
       development of a new component script, probably also involving the
-c
option to
pmcheck
."
944,9,pcp-check,"This can assist with
       debugging the failure of a component script or during the
       development of a new component script, probably also involving the
-c
option to
pmcheck
. The
-? ,
--help
option displays a usage message."
944,10,pcp-check,",
--help
option displays a usage message. As a convience,
pmcheck . is an alias for
pcp-check
."
945,0,pcp-dmcache,"pcp-dmcache
reports on the activity of any configured Device
       Mapper Cache targets. The reported information includes device
       IOPs, cache and metadata device utilization, as well as hit and
       miss rates and ratios for both reads and writes for each cache
       device. pcp-lvmcache
(Logical Volume Manager cache) is an exact synonym
       for
pcp-dmcache
(Device Mapper cache)."
945,1,pcp-dmcache,"The reported information includes device
       IOPs, cache and metadata device utilization, as well as hit and
       miss rates and ratios for both reads and writes for each cache
       device. pcp-lvmcache
(Logical Volume Manager cache) is an exact synonym
       for
pcp-dmcache
(Device Mapper cache). By default,
pcp-dmcache
reports on all available cache target
       devices (one line each, per sample), but this can be restricted to
       specific devices on the command line."
946,0,pcpcompat,nan
947,0,pcp-atop,"The program
pcp-atop
is an interactive monitor to view various
       aspects of load on a system. Every
interval
seconds (default: 10
       seconds) information is gathered about the resource occupation on
       system level of the most critical hardware resources (from a
       performance point of view), i.e. CPUs, memory, disks and network
       interfaces."
947,1,pcp-atop,"CPUs, memory, disks and network
       interfaces. Besides, information is gathered about the processes
       (or threads) that are responsible for the utilization of the CPUs,
       memory and disks. Network load per process is shown only when the
       optional
pmdabpf(1)
or
pmdabcc(1)
metrics have been installed and
       configured."
948,0,pax,"The
pax
utility shall read, write, and write lists of the members
       of archive files and copy directory hierarchies. A variety of
       archive formats shall be supported; see the
-x
format
option. The action to be taken depends on the presence of the
-r
and
-w
options."
948,1,pax,"The action to be taken depends on the presence of the
-r
and
-w
options. The four combinations of
-r
and
-w
are referred to as the
       four modes of operation:
list
,
read
,
write
, and
copy
modes,
       corresponding respectively to the four forms shown in the SYNOPSIS
       section. list
In
list
mode (when neither
-r
nor
-w
are specified),
pax
shall write the names of the members of the archive file
                 read from the standard input, with pathnames matching
                 the specified patterns, to standard output."
948,2,pax,"list
In
list
mode (when neither
-r
nor
-w
are specified),
pax
shall write the names of the members of the archive file
                 read from the standard input, with pathnames matching
                 the specified patterns, to standard output. If a named
                 file is of type directory, the file hierarchy rooted at
                 that file shall be listed as well. read
In
read
mode (when
-r
is specified, but
-w
is not),
pax
shall extract the members of the archive file read from
                 the standard input, with pathnames matching the
                 specified patterns."
948,3,pax,"read
In
read
mode (when
-r
is specified, but
-w
is not),
pax
shall extract the members of the archive file read from
                 the standard input, with pathnames matching the
                 specified patterns. If an extracted file is of type
                 directory, the file hierarchy rooted at that file shall
                 be extracted as well. The extracted files shall be
                 created performing pathname resolution with the
                 directory in which
pax
was invoked as the current
                 working directory."
948,4,pax,"The extracted files shall be
                 created performing pathname resolution with the
                 directory in which
pax
was invoked as the current
                 working directory. If an attempt is made to extract a directory when the
                 directory already exists, this shall not be considered
                 an error. If an attempt is made to extract a FIFO when
                 the FIFO already exists, this shall not be considered an
                 error."
948,5,pax,"If an attempt is made to extract a FIFO when
                 the FIFO already exists, this shall not be considered an
                 error. The ownership, access, and modification times, and file
                 mode of the restored files are discussed under the
-p
option. write
In
write
mode (when
-w
is specified, but
-r
is not),
pax
shall write the contents of the
file
operands to the
                 standard output in an archive format."
948,6,pax,"write
In
write
mode (when
-w
is specified, but
-r
is not),
pax
shall write the contents of the
file
operands to the
                 standard output in an archive format. If no
file
operands are specified, a list of files to copy, one per
                 line, shall be read from the standard input and each
                 entry in this list shall be processed as if it had been
                 a
file
operand on the command line. A file of type
                 directory shall include all of the files in the file
                 hierarchy rooted at the file."
948,7,pax,"A file of type
                 directory shall include all of the files in the file
                 hierarchy rooted at the file. copy
In
copy
mode (when both
-r
and
-w
are specified),
pax
shall copy the
file
operands to the destination
                 directory. If no
file
operands are specified, a list of files to
                 copy, one per line, shall be read from the standard
                 input."
948,8,pax,"If no
file
operands are specified, a list of files to
                 copy, one per line, shall be read from the standard
                 input. A file of type directory shall include all of the
                 files in the file hierarchy rooted at the file. The effect of the
copy
shall be as if the copied files
                 were written to a
pax
format archive file and then
                 subsequently extracted, except that copying of sockets
                 may be supported even if archiving them in write mode is
                 not supported, and that there may be hard links between
                 the original and the copied files."
948,9,pax,"The effect of the
copy
shall be as if the copied files
                 were written to a
pax
format archive file and then
                 subsequently extracted, except that copying of sockets
                 may be supported even if archiving them in write mode is
                 not supported, and that there may be hard links between
                 the original and the copied files. If the destination
                 directory is a subdirectory of one of the files to be
                 copied, the results are unspecified. If the destination
                 directory is a file of a type not defined by the System
                 Interfaces volume of POSIX.1â2017, the results are
                 implementation-defined; otherwise, it shall be an error
                 for the file named by the
directory
operand not to
                 exist, not be writable by the user, or not be a file of
                 type directory."
948,10,pax,"If the destination
                 directory is a file of a type not defined by the System
                 Interfaces volume of POSIX.1â2017, the results are
                 implementation-defined; otherwise, it shall be an error
                 for the file named by the
directory
operand not to
                 exist, not be writable by the user, or not be a file of
                 type directory. In
read
or
copy
modes, if intermediate directories are necessary
       to extract an archive member,
pax
shall perform actions equivalent
       to the
mkdir
() function defined in the System Interfaces volume of
       POSIX.1â2017, called with the following arguments:

        *  The intermediate directory used as the
path
argument

        *  The value of the bitwise-inclusive OR of S_IRWXU, S_IRWXG, and
           S_IRWXO as the
mode
argument

       If any specified
pattern
or
file
operands are not matched by at
       least one file or archive member,
pax
shall write a diagnostic
       message to standard error for each one that did not match and exit
       with a non-zero exit status. The archive formats described in the EXTENDED DESCRIPTION section
       shall be automatically detected on input."
948,11,pax,"The archive formats described in the EXTENDED DESCRIPTION section
       shall be automatically detected on input. The default output
       archive format shall be implementation-defined. A single archive can span multiple files."
948,12,pax,"A single archive can span multiple files. The
pax
utility shall
       determine, in an implementation-defined manner, what file to read
       or write as the next file. If the selected archive format supports the specification of
       linked files, it shall be an error if these files cannot be linked
       when the archive is extracted."
948,13,pax,"If the selected archive format supports the specification of
       linked files, it shall be an error if these files cannot be linked
       when the archive is extracted. For archive formats that do not
       store file contents with each name that causes a hard link, if the
       file that contains the data is not extracted during this
pax
session, either the data shall be restored from the original file,
       or a diagnostic message shall be displayed with the name of a file
       that can be used to extract the data. In traversing directories,
pax
shall detect infinite loops; that is, entering a previously
       visited directory that is an ancestor of the last file visited."
948,14,pax,"For archive formats that do not
       store file contents with each name that causes a hard link, if the
       file that contains the data is not extracted during this
pax
session, either the data shall be restored from the original file,
       or a diagnostic message shall be displayed with the name of a file
       that can be used to extract the data. In traversing directories,
pax
shall detect infinite loops; that is, entering a previously
       visited directory that is an ancestor of the last file visited. When it detects an infinite loop,
pax
shall write a diagnostic
       message to standard error and shall terminate."
949,0,pcp-geolocate,"pcp-geolocate
reports the latitude and longitude for the local
       Performance Co-Pilot collector host in JSON format. This
       geolocation information is sourced from the cache file
$PCP_SYSCONF_DIR/labels/optional/geolocate
if it exists, else an
       attempt is made to perform geolocation based on the host IP
       address, via several online sources (REST APIs). The output from this command is suited for storing as metric
       labels by saving it to the cache file mentioned above."
949,1,pcp-geolocate,"This
       geolocation information is sourced from the cache file
$PCP_SYSCONF_DIR/labels/optional/geolocate
if it exists, else an
       attempt is made to perform geolocation based on the host IP
       address, via several online sources (REST APIs). The output from this command is suited for storing as metric
       labels by saving it to the cache file mentioned above. The opt-in
systemd(1)
service unit file for this command provides
       an automated location discovery for PCP metric labels."
950,0,pcp-dstat,"pcp-dstat
is a general performance analysis tool allowing you to
       view multiple system resources instantly, for example you can
       compare disk usage in combination with interrupts from a disk
       controller, or compare the network bandwidth numbers directly with
       the disk throughput (in the same interval). It also cleverly gives you the most detailed information in
       columns and clearly indicates in what magnitude and unit the
       output is being displayed. Less confusion, fewer mistakes, more
       efficient."
950,1,pcp-dstat,"Less confusion, fewer mistakes, more
       efficient. The
delay
is the delay in seconds between each update, and the
count
is the number of updates to display before exiting. The
       default
delay
is 1 second and
count
is unspecified (run until
       interrupted or end of archive is reached)."
950,2,pcp-dstat,"The
       default
delay
is 1 second and
count
is unspecified (run until
       interrupted or end of archive is reached). This latest generation of Dstat,
pcp-dstat
, allows for analysis of
       historical performance data (in the PCP archive format created by
pmlogger(1)
), as well as distributed systems analysis of live
       performance data from remote hosts running the
pmcd(1)
process. The original Dstat notion of ``plugins'' is replaced by use of
       named metrics in a Performance Metric Name Space (
PMNS(5)
)
       supplied by Performance Metric Domain Agents (PMDAs)."
950,3,pcp-dstat,"The original Dstat notion of ``plugins'' is replaced by use of
       named metrics in a Performance Metric Name Space (
PMNS(5)
)
       supplied by Performance Metric Domain Agents (PMDAs). Metrics and
       other formatting information is now specified as plugin
       configuration files in
pcp-dstat(5)
format. This new style of
       plugin is either built-in (time-related reporting only), or
       sourced from the system-wide location (
$PCP_SYSCONF_DIR/dstat
)
       and/or sourced from an individual users set of personal plugins
       (
$HOME/.pcp/dstat
)."
950,4,pcp-dstat,"Metrics and
       other formatting information is now specified as plugin
       configuration files in
pcp-dstat(5)
format. This new style of
       plugin is either built-in (time-related reporting only), or
       sourced from the system-wide location (
$PCP_SYSCONF_DIR/dstat
)
       and/or sourced from an individual users set of personal plugins
       (
$HOME/.pcp/dstat
). The list of all available plugins can be seen using the
--list
dstat command line option."
951,0,pcp-free,"pcp-free
gives a summary display of the total amount of free and
       used physical memory and swap in the system, as well as the caches
       used by the kernel. When invoked via the
pcp(1)
command, the
-h
/
--host
,
-a
/
--archive
,
-O
/
--origin
,
-s
/
--samples
,
-t
/
--interval
,
-Z
/
--timezone
and
       several other
pcp
options
become indirectly available, see
PCPIntro(1)
for their descriptions. The displayed columns are:
total
Total installed memory (MemTotal and SwapTotal in
              /proc/meminfo)
used
Used memory (calculated as
total
-
free
-
buffers
-
cache
)
free
Unused memory (MemFree and SwapFree in /proc/meminfo)
shared
Memory used (mostly) by tmpfs (Shmem in /proc/meminfo)
buffers
Memory used by kernel buffers (Buffers in /proc/meminfo)
cache
Memory used by the page cache and slabs (Cached and
              SReclaimable in /proc/meminfo)
buff/cache
Sum of
buffers
and
cache
available
Estimation of how much memory is available for starting new
              applications, without swapping."
951,1,pcp-free,"When invoked via the
pcp(1)
command, the
-h
/
--host
,
-a
/
--archive
,
-O
/
--origin
,
-s
/
--samples
,
-t
/
--interval
,
-Z
/
--timezone
and
       several other
pcp
options
become indirectly available, see
PCPIntro(1)
for their descriptions. The displayed columns are:
total
Total installed memory (MemTotal and SwapTotal in
              /proc/meminfo)
used
Used memory (calculated as
total
-
free
-
buffers
-
cache
)
free
Unused memory (MemFree and SwapFree in /proc/meminfo)
shared
Memory used (mostly) by tmpfs (Shmem in /proc/meminfo)
buffers
Memory used by kernel buffers (Buffers in /proc/meminfo)
cache
Memory used by the page cache and slabs (Cached and
              SReclaimable in /proc/meminfo)
buff/cache
Sum of
buffers
and
cache
available
Estimation of how much memory is available for starting new
              applications, without swapping. Unlike the data provided
              by the
cache
or
free
fields, this field takes into account
              page cache and also that not all reclaimable memory slabs
              will be reclaimed due to items being in use (MemAvailable
              in /proc/meminfo)."
952,0,pcp-ipcs,"pcp-ipcs
provides information on the inter-process communication
       facilities for which the calling process has read access."
953,0,pcp-iostat,"pcp-iostat
reports I/O statistics for SCSI (by default) or other
       devices (if the
-x
option is specified)."
954,0,htop,"htop
is a cross-platform ncurses-based process viewer. It is similar to
top
, but allows you to scroll vertically and
       horizontally, and interact using a pointing device (mouse). You
       can observe all processes running on the system, along with their
       command line arguments, as well as view them in a tree format,
       select multiple processes and act on them all at once."
954,1,htop,"You
       can observe all processes running on the system, along with their
       command line arguments, as well as view them in a tree format,
       select multiple processes and act on them all at once. Tasks related to processes (killing, renicing) can be done without
       entering their PIDs. pcp-htop
is a version of
htop
built using the Performance Co-Pilot
       (PCP) Metrics API (see
PCPIntro(1)
,
PMAPI(3)
), allowing to extend
htop
to display values from arbitrary metrics."
954,2,htop,"Tasks related to processes (killing, renicing) can be done without
       entering their PIDs. pcp-htop
is a version of
htop
built using the Performance Co-Pilot
       (PCP) Metrics API (see
PCPIntro(1)
,
PMAPI(3)
), allowing to extend
htop
to display values from arbitrary metrics. See the section
       below titled
CONFIG FILES
for further details."
955,0,pcp-kube-pods,"pcp-kube-pods
uses
kubectl
(1) to provide a list of IP addresses
       for PODs running in a local Kubenetes cluster, that may be running
       PCP services like
pmcd(1)
and
pmproxy(1)
. It is used by the
pmfind(1)
command and the
pmDiscoverServices(3)
API as a ``shell'' command. The script invokes the
kubectl get pod
command line (see
kubectl-get
(1)) to discover IP addresses for pods."
955,1,pcp-kube-pods,"The script invokes the
kubectl get pod
command line (see
kubectl-get
(1)) to discover IP addresses for pods. The
.status.podIP
output field is extracted from the Kubernetes pod
       object(s). Additional options can be specified via configuration
       file, such as
-l service=database
to restrict the results using
       Kubernetes pod labels."
955,2,pcp-kube-pods,"Additional options can be specified via configuration
       file, such as
-l service=database
to restrict the results using
       Kubernetes pod labels. The default configuration file is
$PCP_SYSCONF_DIR/discover/pcp-kube-pods.conf
. If no local
kubectl
command is found, nothing is reported and an
       exit code indicating success is returned."
956,0,pcp-dmcache,"pcp-dmcache
reports on the activity of any configured Device
       Mapper Cache targets. The reported information includes device
       IOPs, cache and metadata device utilization, as well as hit and
       miss rates and ratios for both reads and writes for each cache
       device. pcp-lvmcache
(Logical Volume Manager cache) is an exact synonym
       for
pcp-dmcache
(Device Mapper cache)."
956,1,pcp-dmcache,"The reported information includes device
       IOPs, cache and metadata device utilization, as well as hit and
       miss rates and ratios for both reads and writes for each cache
       device. pcp-lvmcache
(Logical Volume Manager cache) is an exact synonym
       for
pcp-dmcache
(Device Mapper cache). By default,
pcp-dmcache
reports on all available cache target
       devices (one line each, per sample), but this can be restricted to
       specific devices on the command line."
957,0,pcp-meminfo,"The
pcp-meminfo
command is used for viewing the different kinds of
       stats related to memory. Using various options it helps a user to
       analyze useful information related to the memory availability. This information includes total memory, memory available, shared
       memory, etc."
957,1,pcp-meminfo,"Using various options it helps a user to
       analyze useful information related to the memory availability. This information includes total memory, memory available, shared
       memory, etc. By default
pcp-meminfo
reports live data for the
       local host."
958,0,pcp-mpstat,"pcp-mpstat
command writes to standard output activities for each
       available processor, processor 0 being the first one. If no
       activity/option has been selected, then the default report is the
       CPU utilization (
-u
) report. The
interval
parameter specifies the amount of time in seconds
       between each report."
958,1,pcp-mpstat,"The
interval
parameter specifies the amount of time in seconds
       between each report. The default is one second. The value of
count
parameter determines the number of samples to be displayed."
958,2,pcp-mpstat,"The default is one second. The value of
count
parameter determines the number of samples to be displayed. The default is continuous."
959,0,pcp-numastat,"pcp-numastat
displays NUMA allocation statistics from the kernel
       memory allocator. Each process has NUMA policies that specify on
       which node pages are allocated. The performance counters in the
       kernel track on which nodes memory is allocated and these values
       are sampled and reported by
pcp-numastat
."
959,1,pcp-numastat,"The performance counters in the
       kernel track on which nodes memory is allocated and these values
       are sampled and reported by
pcp-numastat
. Counters are maintained individually for each NUMA node. Details
       of the semantics of each reported metric can be retrieved using
       the following command:

            # pminfo âdt mem.numa.alloc"
960,0,pcp-netstat,"The
pcp-netstat
command is used for viewing the different kinds of
       statistics related to the network protocols and the network
       interfaces. This tool is useful for checking the status of your
       network interfaces, network connections and for troubleshooting
       network issues. This tool can also be used to analyze network
       statistics for all available protocols, including TCP, UDP, ICMP,
       and IP protocols."
960,1,pcp-netstat,"This tool can also be used to analyze network
       statistics for all available protocols, including TCP, UDP, ICMP,
       and IP protocols. By default
pcp-netstat
reports live data for the local host. It
       has the capabilities to analyze the data on the archives as well."
961,0,pcp-pidstat,"The
pcp-pidstat
command is used for monitoring individual tasks
       running on the system. Using various options it helps a user to
       see useful information related to the processes. This information
       includes CPU percentage, memory and stack usage, scheduling and
       priority."
961,1,pcp-pidstat,"Using various options it helps a user to
       see useful information related to the processes. This information
       includes CPU percentage, memory and stack usage, scheduling and
       priority. By default
pcp-pidstat
reports live data for the local
       host."
962,0,pcp-ps,"The
pcp-ps
command is used for monitoring individual process
       running on the system. Using various options it helps a user to
       see useful information related to the processes. This information
       includes CPU percentage, memory and stack usage, scheduling and
       priority."
962,1,pcp-ps,"Using various options it helps a user to
       see useful information related to the processes. This information
       includes CPU percentage, memory and stack usage, scheduling and
       priority. By default
pcp-ps
reports live data for the local host."
963,0,pcp-python,"pcp-python
has been replaced by
pmpython(1)
which is preferred,
       however
pcp-python
is still installed to provided backwards
       compatibility. pcp-python
provides a way to run python scripts using a
       customisable python binary, rather than embedding any particular
       version of python into each script. This can be useful as it allows version-independent python code to
       be run anywhere."
963,1,pcp-python,"This can be useful as it allows version-independent python code to
       be run anywhere. All python modules shipped with PCP support
       versions 2.6 and later (in the python2 series), and 3.3 and later
       (in the python3 release series). Due to python monitoring and collecting scripts being relatively
       simple in PCP (not requiring new modules, language features, etc),
       it has been possible to ensure they work for all of the above
       python versions."
963,2,pcp-python,"Due to python monitoring and collecting scripts being relatively
       simple in PCP (not requiring new modules, language features, etc),
       it has been possible to ensure they work for all of the above
       python versions. Thus, it is common for PCP python scripts to use
       a ""shebang"" line that invokes
pcp-python
as follows:
#!/usr/bin/pcp python
This allows the custom setting to be injected instead of a hard-
       coded python version, while still allowing the user to override
       the python version as follows:
$ PCP_PYTHON_PROG=python3 /usr/bin/pcp python --version
Python 3.3.2
$ PCP_PYTHON_PROG=python2 /usr/bin/pcp python --version
Python 2.7.5

       This is convenient for shipping identical scripts on multiple
       platforms, and for testing different python versions with the one
       script (e.g. in the case where multiple versions of python are
       installed, PCP_PYTHON_PROG can be set in the local environment to
       override the global setting)."
963,3,pcp-python,"in the case where multiple versions of python are
       installed, PCP_PYTHON_PROG can be set in the local environment to
       override the global setting). By default, the value of PCP_PYTHON_PROG from
/etc/pcp.conf
will
       be used. The default value of this configuration parameter is set
       depending on some heuristics about the target build platform."
963,4,pcp-python,"By default, the value of PCP_PYTHON_PROG from
/etc/pcp.conf
will
       be used. The default value of this configuration parameter is set
       depending on some heuristics about the target build platform. These heuristics favour the use of
python3
in all recent releases
       of PCP, for those platforms that support it."
964,0,pcp-reboot-init,"pcp-reboot-init
performs ``one-trip'' initialization after system
       reboot for the various components of the Performance Co-Pilot
       (PCP). The script is normally called from
init(1)
or
systemd(1)
scripts
       prior to starting other PCP components. It should not need to be
       run at other times, but is idempotent so repeated execution is
       harmless, but useless."
964,1,pcp-reboot-init,"The script is normally called from
init(1)
or
systemd(1)
scripts
       prior to starting other PCP components. It should not need to be
       run at other times, but is idempotent so repeated execution is
       harmless, but useless. pcp-reboot-init
is intended to be run as the ``root'' user, and
       will fail otherwise."
965,0,pcp-shping,"pcp-shping
samples and reports on the shell-ping service metrics
       exported by the
pmdashping(1)
agent.

       The default report from
pcp-shping
shows two columns for each
       service
tag
, the first showing service status (zero indicating
       success) and the second service response time, for the last
pmdashping
command refresh cycle.

       When invoked via the
pcp(1)
command, the
-h
/
--host
,
-a
/
--archive
,
-O
/
--origin
,
-s
/
--samples
,
-t
/
--interval
,
-Z
/
--timezone
and
       several other
pcp
options
become indirectly available, see
PCPIntro(1)
for their descriptions."
966,0,pcp-slabinfo,"The
pcp-slabinfo
command is used for viewing different stats
       related to slab. It helps users analyze useful information
       related to the slab allocator. The information includes the total
       number of objects that are currently active, allocated objects,
       pages per slab, etc."
966,1,pcp-slabinfo,"The information includes the total
       number of objects that are currently active, allocated objects,
       pages per slab, etc. By default,
pcp-slabinfo
reports live data
       for the local host. The statistics shown are as follows:
HEADER         DESCRIPTION
âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
       active_objs    The number of objects that are currently active
                      (i.e., in use)
       num_objs       The total number of allocated objects (i.e."
966,2,pcp-slabinfo,"The statistics shown are as follows:
HEADER         DESCRIPTION
âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
       active_objs    The number of objects that are currently active
                      (i.e., in use)
       num_objs       The total number of allocated objects (i.e. objects
                      that are both in use and not in use). objsize        The size of objects in this slab, in bytes."
966,3,pcp-slabinfo,"objsize        The size of objects in this slab, in bytes. objperslab     The number of objects stored in each slab. pagesperslab   The number of pages allocated for each slab
       active_slabs   The number of active slabs."
966,4,pcp-slabinfo,"objperslab     The number of objects stored in each slab. pagesperslab   The number of pages allocated for each slab
       active_slabs   The number of active slabs. num_slabs      The total number of slabs."
967,0,pcp-ss,"pcp-ss
reports socket statistics collected by the
pmdasockets(1)
PMDA agent. The command is intended to be reasonably compatible
       with many of the
ss(8)
command line options and reporting formats,
       but also offer the advantages of local or remote monitoring (in
       live mode) and also historical replay from a previously recorded
       PCP archive. Note that since
ss
(1) has many command line options,
       many of which are the same as standard PCP command line options as
       described in
PCPIntro(1)
, the
pcp-ss
tool should always be invoked
       by users using the
pcp
front-end."
967,1,pcp-ss,"Note that since
ss
(1) has many command line options,
       many of which are the same as standard PCP command line options as
       described in
PCPIntro(1)
, the
pcp-ss
tool should always be invoked
       by users using the
pcp
front-end. This allows standard PCP
       commandline options such as
-h
,
-a
,
-S
,
-T
,
-O
,
-z
, etc to be
       passed without conflict with
ss
(1) options. See the
EXAMPLES
sections below for typical usage and command lines."
967,2,pcp-ss,"See the
EXAMPLES
sections below for typical usage and command lines. Live mode uses the
pcp -h
host
option and requires the
pmdasockets(1)
PMDA to be installed and enabled on the target
host
(local or remote), see
pmdasockets(1)
for details on how to enable
       the
sockets
PMDA on a particular host. The default source is live
       metrics collected on
localhost
, if neither of the
-h
or
-a
options
       are given."
967,3,pcp-ss,"The default source is live
       metrics collected on
localhost
, if neither of the
-h
or
-a
options
       are given. Historical/archive replay uses the
pcp -a
archive
option, where
archive
is the basename of a previously recorded PCP archive. The
       archive replay feature is particularly useful because socket
       statistics can be reported for a designated time using the
pcp
--origin
option (which defaults to the start time of the archive)."
968,0,pcp,"The
pcp
command is used in one of two modes. By default, it
       summarizes the Performance Co-Pilot (PCP) installation on the
       local host. This mode can also be used to summarize the
       installation from a remote
host
, or a historical installation from
       a set of PCP
archives
."
968,1,pcp,"This mode can also be used to summarize the
       installation from a remote
host
, or a historical installation from
       a set of PCP
archives
. This mode indirectly invokes the
pcp-
summary
command
(in the absence of any other requested command). Alternatively, a
command
can be passed to
pcp
to run, again
       possibly in the context of a remote
host
or set of historical
archives
."
969,0,pcp-uptime,"pcp-uptime
gives a one line display of the following information.
       The current time, how long the system has been running, how many
       users are currently logged on, and the system load averages for
       the past 1, 5, and 15 minutes.

       When invoked via the
pcp(1)
command, the
-h
/
--host
,
-a
/
--archive
,
-O
/
--origin
,
-Z
/
--timezone
and several other
pcp options
become
       indirectly available."
970,0,pcp-tapestat,"pcp-tapestat
reports I/O statistics for tape devices."
971,0,pcp-verify,"pcp-verify
inspects various aspects of a PCP collector
       installation and reports on whether it is configured correctly for
       certain modes of operation.

       By default,
pcp-verify
checks that PMCD is running and no agents
       are in a failed state.  These checks can be extended and refined
       using the command line options."
972,0,pcp-xsos,"pcp-xsos
gives a summary report of a system using either a PCP
       archive or live metric values from that system. It is designed to be fast and performs a single-sample only,
       similar to tools like
ps(1)
. Thus, level of detail in reporting
       is traded off in favour of execution speed."
972,1,pcp-xsos,"Thus, level of detail in reporting
       is traded off in favour of execution speed. pcp-xsos
is designed
       as an initial performance triage tool that quickly informs an
       operator as to avenues of investigation that may prove more
       fruitful. At this time the focus is entirely on operating system
       metrics, however this is not a requirement and in time it may be
       extended to report on any performance domain with associated PCP
       metrics."
972,2,pcp-xsos,"At this time the focus is entirely on operating system
       metrics, however this is not a requirement and in time it may be
       extended to report on any performance domain with associated PCP
       metrics. When invoked via the
pcp(1)
command, the
-h
/
--host
,
-a
/
--archive
,
-O
/
--origin pcp
options
become indirectly available, see
PCPIntro(1)
for their descriptions. The default report with no command line options presented is the
       operating system overview."
973,0,pmstat,"pmstat
provides a one line summary of system performance every
interval
unit of time (the default is 5 seconds). pmstat
is
       intended to monitor system performance at the highest level, after
       which other tools may be used to examine subsystems in which
       potential performance problems may be observed in greater detail. pcp-vmstat
is a simple wrapper for use with the
pcp(1)
command,
       providing a more familiar command line format for some users."
973,1,pmstat,"pcp-vmstat
is a simple wrapper for use with the
pcp(1)
command,
       providing a more familiar command line format for some users. It
       also enables the extended reporting option by default, see the
-x
option below. Multiple hosts may be monitored by supplying more than one host
       with multiple
-h
flags (for live monitoring) or by providing a
       name of the hostlist file, where each line contain one host name,
       with
-H,
or multiple
-a
flags (for retrospective monitoring from
       sets of archives)."
973,2,pmstat,"Multiple hosts may be monitored by supplying more than one host
       with multiple
-h
flags (for live monitoring) or by providing a
       name of the hostlist file, where each line contain one host name,
       with
-H,
or multiple
-a
flags (for retrospective monitoring from
       sets of archives). By default,
pmstat
fetches metrics by connecting to the
       Performance Metrics Collector Daemon (PMCD) on the local host. If
       the
-L
option is specified, then
pmcd(1)
is bypassed, and metrics
       are fetched from PMDAs on the local host using the stand-alone
PM_CONTEXT_LOCAL
variant of
pmNewContext(3)
."
973,3,pmstat,"If
       the
-L
option is specified, then
pmcd(1)
is bypassed, and metrics
       are fetched from PMDAs on the local host using the stand-alone
PM_CONTEXT_LOCAL
variant of
pmNewContext(3)
. When the
-h
option
       is specified,
pmstat
connects to the
pmcd(1)
on
host
and fetches
       metrics from there. As mentioned above, multiple hosts may be
       monitored by supplying multiple
-h
flags."
973,4,pmstat,"As mentioned above, multiple hosts may be
       monitored by supplying multiple
-h
flags. Alternatively, if the
-a
option is used, the metrics are retrieved
       from the Performance Co-Pilot archive files identified by
archive
,
       which is a comma-separated list of names, each of which may be the
       base name of an archive or the name of a directory containing one
       or more archives. Multiple sets of archives may be replayed by
       supplying multiple
-a
flags."
973,5,pmstat,"Multiple sets of archives may be replayed by
       supplying multiple
-a
flags. When the
-a
flag is used, the
-P
flag may also be used to pause the output after each interval. Stand-alone mode can only connect to the local host, using a set
       of archives implies a host name, and nominating a host precludes
       using an archive, so the options
-L
,
-a
and
-h
are mutually
       exclusive."
973,6,pmstat,"Stand-alone mode can only connect to the local host, using a set
       of archives implies a host name, and nominating a host precludes
       using an archive, so the options
-L
,
-a
and
-h
are mutually
       exclusive. pmstat
may relinquish its own timing control, and operate under
       the control of a
pmtime(1)
process that uses a GUI dialog to
       provide timing control. In this case, either the
-g
option should
       be used to start
pmstat
as the sole client of a new
pmtime(1)
instance, or
-p
should be used to attach
pmstat
to an existing
pmtime(1)
instance via the IPC channel identified by the
port
argument."
973,7,pmstat,"pmstat
may relinquish its own timing control, and operate under
       the control of a
pmtime(1)
process that uses a GUI dialog to
       provide timing control. In this case, either the
-g
option should
       be used to start
pmstat
as the sole client of a new
pmtime(1)
instance, or
-p
should be used to attach
pmstat
to an existing
pmtime(1)
instance via the IPC channel identified by the
port
argument. The
-S
,
-T
,
-O
and
-A
options may be used to define a time window
       to restrict the samples retrieved, set an initial origin within
       the time window, or specify a ``natural'' alignment of the sample
       times; refer to
PCPIntro(1)
for a complete description of these
       options."
974,0,pcp-zoneinfo,"The
pcp-zoneinfo
command is used for viewing the different kinds
       of stats related to NUMA nodes. Using various options it helps a
       user to analyze useful information related to the zone
       availability for different NUMA nodes. This is useful for
       analyzing virtual memory behavior."
974,1,pcp-zoneinfo,"This is useful for
       analyzing virtual memory behavior. By default
pcp-zoneinfo
reports live data for the local host. The statistics shown are as follows:
Per node stats (for each NUMA node)
HEADER                          DESCRIPTION
nr_inactive_anon                zone inactive anonymous pages
       nr_active_anon                  active anonymous memory pages
       nr_inactive_file                inactive file memory pages
       nr_active_file                  active file memory memory pages
       nr_unevictable                  unevictable pages
       nr_slab_reclaimable             reclaimable slab pages
       nr_slab_unreclaimable           unreclaimable slab pages
       nr_isolated_anon                isolated anonymous memory pages
       nr_isolated_file                isolated file memory pages
       nr_anon_pages                   anonymous mapped pagecache pages
       nr_mapped                       mapped pagecache pages
       nr_file_pages                   file pagecache pages
       nr_dirty                        pages dirty state
       nr_writeback                    pages writeback state
       nr_writeback_temp               temporary writeback pages
       nr_shmem                        shared memory pages
       nr_shmem_hugepages              shared memory huge pages
       nr_shmem_pmdmapped              shared memory PMD mappings
       nr_file_hugepages               file-backed huge pages
       nr_file_pmdmapped               file-backed PMD mappings
       nr_anon_transparent_hugepages   anonymous transparent huge pages
       nr_unstable                     pages in unstable state in each zone
       nr_vmscan_write                 pages written from the LRU by the VM
                                       scanner The VM is supposed to minimise
                                       the number of pages which get written
                                       from the LRU (for IO scheduling
                                       efficiency and reclaim success)."
974,2,pcp-zoneinfo,"By default
pcp-zoneinfo
reports live data for the local host. The statistics shown are as follows:
Per node stats (for each NUMA node)
HEADER                          DESCRIPTION
nr_inactive_anon                zone inactive anonymous pages
       nr_active_anon                  active anonymous memory pages
       nr_inactive_file                inactive file memory pages
       nr_active_file                  active file memory memory pages
       nr_unevictable                  unevictable pages
       nr_slab_reclaimable             reclaimable slab pages
       nr_slab_unreclaimable           unreclaimable slab pages
       nr_isolated_anon                isolated anonymous memory pages
       nr_isolated_file                isolated file memory pages
       nr_anon_pages                   anonymous mapped pagecache pages
       nr_mapped                       mapped pagecache pages
       nr_file_pages                   file pagecache pages
       nr_dirty                        pages dirty state
       nr_writeback                    pages writeback state
       nr_writeback_temp               temporary writeback pages
       nr_shmem                        shared memory pages
       nr_shmem_hugepages              shared memory huge pages
       nr_shmem_pmdmapped              shared memory PMD mappings
       nr_file_hugepages               file-backed huge pages
       nr_file_pmdmapped               file-backed PMD mappings
       nr_anon_transparent_hugepages   anonymous transparent huge pages
       nr_unstable                     pages in unstable state in each zone
       nr_vmscan_write                 pages written from the LRU by the VM
                                       scanner The VM is supposed to minimise
                                       the number of pages which get written
                                       from the LRU (for IO scheduling
                                       efficiency and reclaim success). nr_vmscan_immediate_reclaim     prioritise for reclaim when writeback
                                       ends
       nr_dirtied                      pages entering dirty state
       nr_written                      pages written out in each zone
       nr_kernel_misc_reclaimable      miscellaneous reclaimable kernel pages
Per zone stats (in each zone for each NUMA node)
HEADER                  DESCRIPTION
pages free              free space
       pages min               min space
       pages low               low space
       pages high              high space
       pages spanned           spanned space
       pages present           present space
       pages managed           managed space
       pages protection        protection space
       nr_free_pages           number of free pages
       nr_zone_inactive_anon   zone inactive anonymous pages
       nr_zone_active_anon     zone active anonymous pages
       nr_zone_inactive_file   zone inactive file-backed pages
       nr_zone_active_file     zone active file-backed pages
       nr_zone_unevictable     zone unevictable pages
       nr_zone_write_pending   zone write-pending pages
       nr_mlock                pages under mlock
       nr_page_table_pages     page table pages
       nr_kernel_stack         pages of kernel stack
       nr_bounce               bounce buffer pages
       nr_zspages              zsmalloc memory allocator pages
       nr_free_cma             free Contiguous Memory Allocator pages
       numa_hit                successful allocations from preferred NUMA
                               zone
       numa_miss               unsuccessful allocations from preferred
                               NUMA zone
       numa_foreign            foreign NUMA zone allocations
       numa_interleave         interleaved NUMA allocations
       numa_local              successful allocations from local NUMA
                               zone
       numa_other              unsuccessful allocations from local NUMA
                               zone"
975,0,pcp,"The
pcp
command is used in one of two modes. By default, it
       summarizes the Performance Co-Pilot (PCP) installation on the
       local host. This mode can also be used to summarize the
       installation from a remote
host
, or a historical installation from
       a set of PCP
archives
."
975,1,pcp,"This mode can also be used to summarize the
       installation from a remote
host
, or a historical installation from
       a set of PCP
archives
. This mode indirectly invokes the
pcp-
summary
command
(in the absence of any other requested command). Alternatively, a
command
can be passed to
pcp
to run, again
       possibly in the context of a remote
host
or set of historical
archives
."
976,0,pcp2arrow,"pcp2arrow
is a customizable performance metrics exporter tool from
       PCP to Apache Arrow. It is particularly useful as a mechanism for
       producing the Parquet columnar data format, for use with Pandas or
       similar data analysis modules. Each PCP metric, and each instance
       of each metric, will form a unique column named according to the
       PCP metric specification - that is, metric name followed by square
       bracket enclosed instance name (for metrics with an instance
       domain)."
976,1,pcp2arrow,"Each PCP metric, and each instance
       of each metric, will form a unique column named according to the
       PCP metric specification - that is, metric name followed by square
       bracket enclosed instance name (for metrics with an instance
       domain). Any available performance metric, live or archived, system and/or
       application, can be selected for exporting using either command
       line arguments or a configuration file. With no
metricspec
options, all available metrics are considered
       for exporting."
976,2,pcp2arrow,"With no
metricspec
options, all available metrics are considered
       for exporting. pcp2arrow
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2arrow
command line."
976,3,pcp2arrow,"Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2arrow
command line. See
pmrep.conf(5)
for description of the
pcp2arrow.conf
configuration file syntax. This page describes
pcp2arrow
specific
       options and configuration file differences with
pmrep.conf(5)
."
976,4,pcp2arrow,"This page describes
pcp2arrow
specific
       options and configuration file differences with
pmrep.conf(5)
. pmrep(1)
also lists some usage examples of which most are
       applicable with
pcp2arrow
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported."
976,5,pcp2arrow,"Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any)."
976,6,pcp2arrow,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
977,0,pcp2elasticsearch,"pcp2elasticsearch
is a customizable performance metrics exporter
       tool from PCP to Elasticsearch. Any available performance metric,
       live or archived, system and/or application, can be selected for
       exporting using either command line arguments or a configuration
       file. pcp2elasticsearch
is a close relative of
pmrep(1)
."
977,1,pcp2elasticsearch,"pcp2elasticsearch
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for the
metricspec
description accepted on
pcp2elasticsearch
command line. See
pmrep.conf(5)
for description
       of the
pcp2elasticsearch.conf
configuration file syntax."
977,2,pcp2elasticsearch,"See
pmrep.conf(5)
for description
       of the
pcp2elasticsearch.conf
configuration file syntax. This
       page describes
pcp2elasticsearch
specific options and
       configuration file differences with
pmrep.conf(5)
. pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2elasticsearch
as well."
977,3,pcp2elasticsearch,"pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2elasticsearch
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
977,4,pcp2elasticsearch,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
978,0,pcp2influxdb,"pcp2influxdb
is a customizable performance metrics exporter tool
       from PCP to InfluxDB. Any available performance metric, live or
       archived, system and/or application, can be selected for exporting
       using either command line arguments or a configuration file. pcp2influxdb
is a close relative of
pmrep(1)
."
978,1,pcp2influxdb,"pcp2influxdb
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for the
metricspec
description accepted on
pcp2influxdb
command
       line. See
pmrep.conf(5)
for description of the
pcp2influxdb.conf
configuration file syntax."
978,2,pcp2influxdb,"See
pmrep.conf(5)
for description of the
pcp2influxdb.conf
configuration file syntax. This page describes
pcp2influxdb
specific options and configuration file differences with
pmrep.conf(5)
. pmrep(1)
also lists some usage examples of which
       most are applicable with
pcp2influxdb
as well."
978,3,pcp2influxdb,"pmrep(1)
also lists some usage examples of which
       most are applicable with
pcp2influxdb
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
978,4,pcp2influxdb,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
979,0,pcp2graphite,"pcp2graphite
is a customizable performance metrics exporter tool
       from PCP to Graphite. Any available performance metric, live or
       archived, system and/or application, can be selected for exporting
       using either command line arguments or a configuration file. pcp2graphite
is a close relative of
pmrep(1)
."
979,1,pcp2graphite,"pcp2graphite
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for the
metricspec
description accepted on
pcp2graphite
command
       line. See
pmrep.conf(5)
for description of the
pcp2graphite.conf
configuration file syntax."
979,2,pcp2graphite,"See
pmrep.conf(5)
for description of the
pcp2graphite.conf
configuration file syntax. This page describes
pcp2graphite
specific options and configuration file differences with
pmrep.conf(5)
. pmrep(1)
also lists some usage examples of which
       most are applicable with
pcp2graphite
as well."
979,3,pcp2graphite,"pmrep(1)
also lists some usage examples of which
       most are applicable with
pcp2graphite
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
979,4,pcp2graphite,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
980,0,pcp2json,"pcp2json
is a customizable performance metrics exporter tool from
       PCP to JSON. Any available performance metric, live or archived,
       system and/or application, can be selected for exporting using
       either command line arguments or a configuration file. pcp2json
is a close relative of
pmrep(1)
."
980,1,pcp2json,"pcp2json
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2json
command line. See
pmrep.conf(5)
for description of the
pcp2json.conf
configuration
       file syntax."
980,2,pcp2json,"See
pmrep.conf(5)
for description of the
pcp2json.conf
configuration
       file syntax. This page describes
pcp2json
specific options and
       configuration file differences with
pmrep.conf(5)
. pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2json
as well."
980,3,pcp2json,"pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2json
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
980,4,pcp2json,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
981,0,pmrep,"pmrep
is a customizable performance metrics reporting tool. Any
       available performance metric, live or archived, system and/or
       application, can be selected for reporting using one of the output
       alternatives listed below together with applicable formatting
       options. pmrep
collects selected metric values through the facilities of
       the Performance Co-Pilot (PCP), see
PCPIntro(1)
."
981,1,pmrep,"pmrep
collects selected metric values through the facilities of
       the Performance Co-Pilot (PCP), see
PCPIntro(1)
. The metrics to
       be reported are specified on the command line, in configuration
       files, or both. Metrics can be automatically converted and scaled
       using the PCP facilities, either by default or by per-metric
       scaling specifications."
981,2,pmrep,"Metrics can be automatically converted and scaled
       using the PCP facilities, either by default or by per-metric
       scaling specifications. In addition to the existing metrics,
       derived metrics can be defined using the arithmetic expressions
       described in
pmRegisterDerived(3)
. A wide range of metricsets (see below) is included by default,
       providing reports on per-process details, NUMA performance,
       mimicking other tools like
sar(1)
and more, see the
pmrep
configuration files in
$PCP_SYSCONF_DIR/pmrep
(typically
/etc/pcp/pmrep
) for details."
981,3,pmrep,"A wide range of metricsets (see below) is included by default,
       providing reports on per-process details, NUMA performance,
       mimicking other tools like
sar(1)
and more, see the
pmrep
configuration files in
$PCP_SYSCONF_DIR/pmrep
(typically
/etc/pcp/pmrep
) for details. Tab completion for options, metrics,
       and metricsets is available for bash and zsh. Unless directed to another host by the
-h
option,
pmrep
will
       contact the Performance Metrics Collector Daemon (PMCD, see
pmcd(1)
) on the local host."
981,4,pmrep,"Unless directed to another host by the
-h
option,
pmrep
will
       contact the Performance Metrics Collector Daemon (PMCD, see
pmcd(1)
) on the local host. The
-a
option causes
pmrep
to use the specified set of archives
       rather than connecting to a PMCD. The
-a
and
-h
options are
       mutually exclusive."
981,5,pmrep,"The
-a
and
-h
options are
       mutually exclusive. The
-L
option causes
pmrep
to use a local context to collect
       metrics from DSO PMDAs (Performance Metrics Domain Agents,
       ``plugins'') on the local host without PMCD. Only some metrics
       are available in this mode."
981,6,pmrep,"Only some metrics
       are available in this mode. The
-a
,
-h
, and
-L
options are
       mutually exclusive. The metrics of interest are named in the
metricspec
argument(s)."
981,7,pmrep,"The metrics of interest are named in the
metricspec
argument(s). If a metricspec specifies a non-leaf node in the Performance
       Metrics Name Space (PMNS), then
pmrep
will recursively descend the
       PMNS and report on all leaf nodes (i.e. metrics) for that
       metricspec."
981,8,pmrep,"metrics) for that
       metricspec. Use
pminfo(1)
to list all the metrics (PMNS lead
       nodes) and their descriptions. A
metricspec
has three different forms."
981,9,pmrep,"A
metricspec
has three different forms. First, on the command
       line it can start with a colon (``:'') to indicate a
metricset
to
       be read from
pmrep
configuration files (see
-c
and
pmrep.conf(5)
),
       which may then consist of any number of metrics. Second, a
metricspec
starting with non-colon specifies a PMNS node as
       described above, optionally followed by metric output formatting
       definitions."
981,10,pmrep,"Second, a
metricspec
starting with non-colon specifies a PMNS node as
       described above, optionally followed by metric output formatting
       definitions. This so-called
compact form
of a metricspec is
       defined as follows:

     metric[,label[,instances[,unit/scale[,type[,width[,precision[,limit]]]]]]]

       A valid PMNS node (
metric
) is mandatory. It may be followed by a
       text
label
used with
stdout
output."
981,11,pmrep,"It may be followed by a
       text
label
used with
stdout
output. The optional
instances
definition restricts
csv
and
stdout
reporting to the specified
       instances of the metric so non-matching instances will be filtered
       out (see
-i
). An optional
unit/scale
is applicable for dimension-
       compatible, non-string metrics."
981,12,pmrep,"An optional
unit/scale
is applicable for dimension-
       compatible, non-string metrics. See below for supported
unit/scale
specifications. By default, cumulative counter metrics
       are converted to rates, an optional
type
can be set to
raw
to
       disable this rate conversion."
981,13,pmrep,"By default, cumulative counter metrics
       are converted to rates, an optional
type
can be set to
raw
to
       disable this rate conversion. For
stdout
output a numeric
width
can be used to set the width of the output column for this metric. Too wide strings in the output will be truncated to fit the
       column."
981,14,pmrep,"Too wide strings in the output will be truncated to fit the
       column. A metric-specific
precision
can be provided for numeric
       non-integer output values. Lastly, a metric-specific
limit
can be
       set for filtering out numeric values per the limit."
981,15,pmrep,"Lastly, a metric-specific
limit
can be
       set for filtering out numeric values per the limit. As a special case for metrics that are counters with time units
       (nanoseconds to hours), the
unit/scale
can be used to change the
       default reporting (for example, milliseconds / second) to
       normalize to the range zero to one by setting this to
sec
(see
       also
-y
and
-Y
). The following
metricspec
requests the metric
kernel.all.sysfork
to
       be reported under the text label
forks
, converting to the metric
       default rate count/s in an
8
wide column."
981,16,pmrep,"The following
metricspec
requests the metric
kernel.all.sysfork
to
       be reported under the text label
forks
, converting to the metric
       default rate count/s in an
8
wide column. Although the
       definitions in this
compact form
are optional, they must always be
       provided in the order specified above, thus the commas. kernel.all.sysfork,forks,,,,8

       The third form of a metricspec,
verbose form
, is described and
       valid only in
pmrep.conf(5)
."
981,17,pmrep,"kernel.all.sysfork,forks,,,,8

       The third form of a metricspec,
verbose form
, is described and
       valid only in
pmrep.conf(5)
. Derived metrics are specified like regular PMNS leaf node metrics. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
981,18,pmrep,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
982,0,pcp2template,"pcp2XXX
is a customizable performance metrics exporter tool from
       PCP to XXX. Any available performance metric, live or archived,
       system and/or application, can be selected for exporting using
       either command line arguments or a configuration file. pcp2XXX
is a close relative of
pmrep(1)
."
982,1,pcp2template,"pcp2XXX
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2XXX
command line. See
pmrep.conf(5)
for description of the
pcp2XXX.conf
configuration
       file syntax."
982,2,pcp2template,"See
pmrep.conf(5)
for description of the
pcp2XXX.conf
configuration
       file syntax. This page describes
pcp2XXX
specific options and
       configuration file differences with
pmrep.conf(5)
. pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2XXX
as well."
982,3,pcp2template,"pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2XXX
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
982,4,pcp2template,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
983,0,pcp2xml,"pcp2xml
is a customizable performance metrics exporter tool from
       PCP to XML. Any available performance metric, live or archived,
       system and/or application, can be selected for exporting using
       either command line arguments or a configuration file. pcp2xml
is a close relative of
pmrep(1)
."
983,1,pcp2xml,"pcp2xml
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2xml
command line. See
pmrep.conf(5)
for description of the
pcp2xml.conf
configuration
       file syntax."
983,2,pcp2xml,"See
pmrep.conf(5)
for description of the
pcp2xml.conf
configuration
       file syntax. This page describes
pcp2xml
specific options and
       configuration file differences with
pmrep.conf(5)
. pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2xml
as well."
983,3,pcp2xml,"pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2xml
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
983,4,pcp2xml,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
984,0,pcp2spark,"pcp2spark
is a customizable performance metrics exporter tool from
       PCP to Apache Spark. Any available performance metric, live or
       archived, system and/or application, can be selected for exporting
       using either command line arguments or a configuration file. pcp2spark
acts as a bridge which provides a network socket stream
       on a given address/port which an Apache Spark worker task can
       connect to and pull the configured PCP metrics from
pcp2spark
exporting them using the streaming extensions of the Apache Spark
       API."
984,1,pcp2spark,"pcp2spark
acts as a bridge which provides a network socket stream
       on a given address/port which an Apache Spark worker task can
       connect to and pull the configured PCP metrics from
pcp2spark
exporting them using the streaming extensions of the Apache Spark
       API. pcp2spark
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2spark
command line."
984,2,pcp2spark,"Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2spark
command line. See
pmrep.conf(5)
for description of the
pcp2spark.conf
configuration file syntax. This page describes
pcp2spark
specific
       options and configuration file differences with
pmrep.conf(5)
."
984,3,pcp2spark,"This page describes
pcp2spark
specific
       options and configuration file differences with
pmrep.conf(5)
. pmrep(1)
also lists some usage examples of which most are
       applicable with
pcp2spark
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported."
984,4,pcp2spark,"Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any)."
984,5,pcp2spark,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
985,0,pcp2openmetrics,"pcp2openmetrics
is a customizable performance metrics exporter
       tool from PCP to Open Metrics -
https://openmetrics.io
-  format. Any available performance metric, live or archived, system and/or
       application, can be selected for exporting using either command
       line arguments or a configuration file. pcp2openmetrics
is a close relative of
pmrep(1)
."
985,1,pcp2openmetrics,"pcp2openmetrics
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for the
metricspec
description accepted on
pcp2openmetrics
command line. See
pmrep.conf(5)
for description
       of the
pcp2openmetrics.conf
configuration file syntax."
985,2,pcp2openmetrics,"See
pmrep.conf(5)
for description
       of the
pcp2openmetrics.conf
configuration file syntax. This page
       describes
pcp2openmetrics
specific options and configuration file
       differences with
pmrep.conf(5)
. pmrep(1)
also lists some usage
       examples of which most are applicable with
pcp2openmetrics
as
       well."
985,3,pcp2openmetrics,"pmrep(1)
also lists some usage
       examples of which most are applicable with
pcp2openmetrics
as
       well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
985,4,pcp2openmetrics,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
986,0,pcp2xlsx,"pcp2xlsx
is a customizable performance metrics exporter tool from
       PCP to XLSX. Any available performance metric, live or archived,
       system and/or application, can be selected for exporting using
       either command line arguments or a configuration file. pcp2xlsx
is a close relative of
pmrep(1)
."
986,1,pcp2xlsx,"pcp2xlsx
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2xlsx
command line. See
pmrep.conf(5)
for description of the
pcp2xlsx.conf
configuration
       file syntax."
986,2,pcp2xlsx,"See
pmrep.conf(5)
for description of the
pcp2xlsx.conf
configuration
       file syntax. This page describes
pcp2xlsx
specific options and
       configuration file differences with
pmrep.conf(5)
. pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2xlsx
as well."
986,3,pcp2xlsx,"pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2xlsx
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
986,4,pcp2xlsx,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
987,0,pcp2zabbix,"pcp2zabbix
is a customizable performance metrics exporter tool
       from PCP to Zabbix. Any available performance metric, live or
       archived, system and/or application, can be selected for exporting
       using either command line arguments or a configuration file. pcp2zabbix
is a close relative of
pmrep(1)
."
987,1,pcp2zabbix,"pcp2zabbix
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2zabbix
command line. See
pmrep.conf(5)
for description of the
pcp2zabbix.conf
configuration file syntax."
987,2,pcp2zabbix,"See
pmrep.conf(5)
for description of the
pcp2zabbix.conf
configuration file syntax. This page describes
pcp2zabbix
specific options and configuration file differences with
pmrep.conf(5)
. pmrep(1)
also lists some usage examples of which
       most are applicable with
pcp2zabbix
as well."
987,3,pcp2zabbix,"pmrep(1)
also lists some usage examples of which
       most are applicable with
pcp2zabbix
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
987,4,pcp2zabbix,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
988,0,pcp2template,"pcp2XXX
is a customizable performance metrics exporter tool from
       PCP to XXX. Any available performance metric, live or archived,
       system and/or application, can be selected for exporting using
       either command line arguments or a configuration file. pcp2XXX
is a close relative of
pmrep(1)
."
988,1,pcp2template,"pcp2XXX
is a close relative of
pmrep(1)
. Refer to
pmrep(1)
for
       the
metricspec
description accepted on
pcp2XXX
command line. See
pmrep.conf(5)
for description of the
pcp2XXX.conf
configuration
       file syntax."
988,2,pcp2template,"See
pmrep.conf(5)
for description of the
pcp2XXX.conf
configuration
       file syntax. This page describes
pcp2XXX
specific options and
       configuration file differences with
pmrep.conf(5)
. pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2XXX
as well."
988,3,pcp2template,"pmrep(1)
also
       lists some usage examples of which most are applicable with
pcp2XXX
as well. Only the command line options listed on this page are supported,
       other options available for
pmrep(1)
are not supported. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
988,4,pcp2template,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
989,0,pcpcompat,nan
990,0,pcpcompat,nan
991,0,pcre2-config,"pcre2-config
returns the configuration of the installed PCRE2
       libraries and the options required to compile a program to use
       them. Some of the options apply only to the 8-bit, or 16-bit, or
       32-bit libraries, respectively, and are not available for
       libraries that have not been built. If an unavailable option is
       encountered, the ""usage"" information is output."
992,0,pdfman,"The
pdfman
command renders a manual page in PDF.  All the
       arguments are interpreted by
man(1)
."
993,0,pcpintro,nan
994,0,pcpintro,nan
995,0,pcre2grep,"pcre2grep
searches files for character patterns, in the same way
       as other grep commands do, but it uses the PCRE2 regular
       expression library to support patterns that are compatible with
       the regular expressions of Perl 5. See
pcre2syntax(3)
for a quick-
       reference summary of pattern syntax, or
pcre2pattern(3)
for a full
       description of the syntax and semantics of the regular expressions
       that PCRE2 supports. Patterns, whether supplied on the command line or in a separate
       file, are given without delimiters."
995,1,pcre2grep,"Patterns, whether supplied on the command line or in a separate
       file, are given without delimiters. For example:

         pcre2grep Thursday /etc/motd

       If you attempt to use delimiters (for example, by surrounding a
       pattern with slashes, as is common in Perl scripts), they are
       interpreted as part of the pattern. Quotes can of course be used
       to delimit patterns on the command line because they are
       interpreted by the shell, and indeed quotes are required if a
       pattern contains white space or shell metacharacters."
995,2,pcre2grep,"Quotes can of course be used
       to delimit patterns on the command line because they are
       interpreted by the shell, and indeed quotes are required if a
       pattern contains white space or shell metacharacters. The first argument that follows any option settings is treated as
       the single pattern to be matched when neither
-e
nor
-f
is
       present. Conversely, when one or both of these options are used
       to specify patterns, all arguments are treated as path names."
995,3,pcre2grep,"Conversely, when one or both of these options are used
       to specify patterns, all arguments are treated as path names. At
       least one of
-e
,
-f
, or an argument pattern must be provided. If no files are specified,
pcre2grep
reads the standard input."
995,4,pcre2grep,"If no files are specified,
pcre2grep
reads the standard input. The
       standard input can also be referenced by a name consisting of a
       single hyphen. For example:

         pcre2grep some-pattern file1 - file3

       By default, input files are searched line by line, so pattern
       assertions about the beginning and end of a subject string (^, $,
       \A, \Z, and \z) match at the beginning and end of each line."
995,5,pcre2grep,"For example:

         pcre2grep some-pattern file1 - file3

       By default, input files are searched line by line, so pattern
       assertions about the beginning and end of a subject string (^, $,
       \A, \Z, and \z) match at the beginning and end of each line. When
       a line matches a pattern, it is copied to the standard output, and
       if there is more than one file, the file name is output at the
       start of each line, followed by a colon. However, there are
       options that can change how
pcre2grep
behaves."
995,6,pcre2grep,"However, there are
       options that can change how
pcre2grep
behaves. For example, the
-M
option makes it possible to search for strings that span line
       boundaries. What defines a line boundary is controlled by the
-N
(
--newline
) option."
995,7,pcre2grep,"What defines a line boundary is controlled by the
-N
(
--newline
) option. The
-h
and
-H
options control whether or not
       file names are shown, and the
-Z
option changes the file name
       terminator to a zero byte. The amount of memory used for buffering files that are being
       scanned is controlled by parameters that can be set by the
--buffer-size
and
--max-buffer-size
options."
995,8,pcre2grep,"The amount of memory used for buffering files that are being
       scanned is controlled by parameters that can be set by the
--buffer-size
and
--max-buffer-size
options. The first of these
       sets the size of buffer that is obtained at the start of
       processing. If an input file contains very long lines, a larger
       buffer may be needed; this is handled by automatically extending
       the buffer, up to the limit specified by
--max-buffer-size
."
995,9,pcre2grep,"If an input file contains very long lines, a larger
       buffer may be needed; this is handled by automatically extending
       the buffer, up to the limit specified by
--max-buffer-size
. The
       default values for these parameters can be set when
pcre2grep
is
       built; if nothing is specified, the defaults are set to 20KiB and
       1MiB respectively. An error occurs if a line is too long and the
       buffer can no longer be expanded."
995,10,pcre2grep,"An error occurs if a line is too long and the
       buffer can no longer be expanded. The block of memory that is actually used is three times the
       ""buffer size"", to allow for buffering ""before"" and ""after"" lines. If the buffer size is too small, fewer than requested ""before"" and
       ""after"" lines may be output."
995,11,pcre2grep,"If the buffer size is too small, fewer than requested ""before"" and
       ""after"" lines may be output. When matching with a multiline pattern, the size of the buffer
       must be at least half of the maximum match expected or the pattern
       might fail to match. Patterns can be no longer than 8KiB or BUFSIZ bytes, whichever is
       the greater."
995,12,pcre2grep,"Patterns can be no longer than 8KiB or BUFSIZ bytes, whichever is
       the greater. BUFSIZ is defined in
<stdio.h>
. When there is more
       than one pattern (specified by the use of
-e
and/or
-f
), each
       pattern is applied to each line in the order in which they are
       defined, except that all the
-e
patterns are tried before the
-f
patterns."
995,13,pcre2grep,"When there is more
       than one pattern (specified by the use of
-e
and/or
-f
), each
       pattern is applied to each line in the order in which they are
       defined, except that all the
-e
patterns are tried before the
-f
patterns. By default, as soon as one pattern matches a line, no further
       patterns are considered. However, if
--colour
(or
--color
) is used
       to colour the matching substrings, or if
--only-matching
,
--file-
offsets
,
--line-offsets
, or
--output
is used to output only the
       part of the line that matched (either shown literally, or as an
       offset), the behaviour is different."
995,14,pcre2grep,"However, if
--colour
(or
--color
) is used
       to colour the matching substrings, or if
--only-matching
,
--file-
offsets
,
--line-offsets
, or
--output
is used to output only the
       part of the line that matched (either shown literally, or as an
       offset), the behaviour is different. In this situation, all the
       patterns are applied to the line. If there is more than one match,
       the one that begins nearest to the start of the subject is
       processed; if there is more than one match at that position, the
       one with the longest matching substring is processed; if the
       matching substrings are equal, the first match found is processed."
995,15,pcre2grep,"If there is more than one match,
       the one that begins nearest to the start of the subject is
       processed; if there is more than one match at that position, the
       one with the longest matching substring is processed; if the
       matching substrings are equal, the first match found is processed. Scanning with all the patterns resumes immediately following the
       match, so that later matches on the same line can be found. Note,
       however, that an overlapping match that starts in the middle of
       another match will not be processed."
995,16,pcre2grep,"Note,
       however, that an overlapping match that starts in the middle of
       another match will not be processed. The above behaviour was changed at release 10.41 to be more
       compatible with GNU grep. In earlier releases,
pcre2grep
did not
       recognize matches from later patterns that were earlier in the
       subject."
995,17,pcre2grep,"In earlier releases,
pcre2grep
did not
       recognize matches from later patterns that were earlier in the
       subject. Patterns that can match an empty string are accepted, but empty
       string matches are never recognized. An example is the pattern
       ""(super)?(man)?"", in which all components are optional."
995,18,pcre2grep,"An example is the pattern
       ""(super)?(man)?"", in which all components are optional. This
       pattern finds all occurrences of both ""super"" and ""man""; the
       output differs from matching with ""super|man"" when only the
       matching substrings are being shown. If the
LC_ALL
or
LC_CTYPE
environment variable is set,
pcre2grep
uses the value to set a locale when calling the PCRE2 library."
995,19,pcre2grep,"This
       pattern finds all occurrences of both ""super"" and ""man""; the
       output differs from matching with ""super|man"" when only the
       matching substrings are being shown. If the
LC_ALL
or
LC_CTYPE
environment variable is set,
pcre2grep
uses the value to set a locale when calling the PCRE2 library. The
--locale
option can be used to override this."
996,0,peekfd,"peekfd
attaches to a running process and intercepts all reads and
       writes to file descriptors.  You can specify the desired file
       descriptor numbers or dump all of them."
997,0,pdfroff,nan
998,0,pdfmom,nan
999,0,pcre2test,"If
pcre2test
is given two filename arguments, it reads from the
       first and writes to the second. If the first name is ""-"", input is
       taken from the standard input. If
pcre2test
is given only one
       argument, it reads from that file and writes to stdout."
999,1,pcre2test,"If
pcre2test
is given only one
       argument, it reads from that file and writes to stdout. Otherwise,
       it reads from stdin and writes to stdout. When
pcre2test
is built, a configuration option can specify that
       it should be linked with the
libreadline
or
libedit
library."
999,2,pcre2test,"When
pcre2test
is built, a configuration option can specify that
       it should be linked with the
libreadline
or
libedit
library. When
       this is done, if the input is from a terminal, it is read using
       the
readline()
function. This provides line-editing and history
       facilities."
999,3,pcre2test,"This provides line-editing and history
       facilities. The output from the
-help
option states whether or not
readline()
will be used. The program handles any number of tests, each of which consists of
       a set of input lines."
999,4,pcre2test,"The program handles any number of tests, each of which consists of
       a set of input lines. Each set starts with a regular expression
       pattern, followed by any number of subject lines to be matched
       against that pattern. In between sets of test data, command lines
       that begin with # may appear."
999,5,pcre2test,"In between sets of test data, command lines
       that begin with # may appear. This file format, with some
       restrictions, can also be processed by the
perltest.sh
script that
       is distributed with PCRE2 as a means of checking that the
       behaviour of PCRE2 and Perl is the same. For a specification of
perltest.sh
, see the comments near its beginning."
999,6,pcre2test,"For a specification of
perltest.sh
, see the comments near its beginning. See also the
       #perltest command below. When the input is a terminal,
pcre2test
prompts for each line of
       input, using ""re>"" to prompt for regular expression patterns, and
       ""data>"" to prompt for subject lines."
999,7,pcre2test,"When the input is a terminal,
pcre2test
prompts for each line of
       input, using ""re>"" to prompt for regular expression patterns, and
       ""data>"" to prompt for subject lines. Command lines starting with #
       can be entered only in response to the ""re>"" prompt. Each subject line is matched separately and independently."
999,8,pcre2test,"Each subject line is matched separately and independently. If you
       want to do multi-line matches, you have to use the \n escape
       sequence (or \r or \r\n, etc., depending on the newline setting)
       in a single line of input to encode the newline sequences. There
       is no limit on the length of subject lines; the input buffer is
       automatically extended if it is too small."
999,9,pcre2test,"There
       is no limit on the length of subject lines; the input buffer is
       automatically extended if it is too small. There are replication
       features that makes it possible to generate long repetitive
       pattern or subject lines without having to supply them explicitly. An empty line or the end of the file signals the end of the
       subject lines for a test, at which point a new pattern or command
       line is expected if there is still input to be read."
1000,0,perf-amd-ibs,"Instruction-Based Sampling (IBS) provides precise Instruction
       Pointer (IP) profiling support on AMD platforms. IBS has two
       independent components: IBS Op and IBS Fetch. IBS Op sampling
       provides information about instruction execution (micro-op
       execution to be precise) with details like d-cache hit/miss, d-TLB
       hit/miss, cache miss latency, load/store data source, branch
       behavior etc."
1000,1,perf-amd-ibs,"IBS Op sampling
       provides information about instruction execution (micro-op
       execution to be precise) with details like d-cache hit/miss, d-TLB
       hit/miss, cache miss latency, load/store data source, branch
       behavior etc. IBS Fetch sampling provides information about
       instruction fetch with details like i-cache hit/miss, i-TLB
       hit/miss, fetch latency etc. IBS is per-smt-thread i.e."
1000,2,perf-amd-ibs,"IBS is per-smt-thread i.e. each SMT
       hardware thread contains standalone IBS units. Both, IBS Op and IBS Fetch, are exposed as PMUs by Linux and can
       be exploited using the Linux perf utility."
1000,3,perf-amd-ibs,"Both, IBS Op and IBS Fetch, are exposed as PMUs by Linux and can
       be exploited using the Linux perf utility. The following files
       will be created at boot time if IBS is supported by the hardware
       and kernel. /sys/bus/event_source/devices/ibs_op/
           /sys/bus/event_source/devices/ibs_fetch/

       IBS Op PMU supports two events: cycles and micro ops."
1000,4,perf-amd-ibs,"/sys/bus/event_source/devices/ibs_op/
           /sys/bus/event_source/devices/ibs_fetch/

       IBS Op PMU supports two events: cycles and micro ops. IBS Fetch
       PMU supports one event: fetch ops. IBS PMUs do not have user/kernel filtering capability and thus it
       requires CAP_SYS_ADMIN or CAP_PERFMON privilege."
1001,0,perf-annotate,"This command reads the input file and displays an annotated
       version of the code. If the object file has debug symbols then the
       source code will be displayed alongside assembly code.

       If there is no debug info in the object, then annotated assembly
       is displayed."
1002,0,perf-archive,"This command runs perf-buildid-list --with-hits, and collects the
       files with the buildids found so that analysis of perf.data
       contents can be possible on another machine."
1003,0,perf-arm-spe,"The SPE (Statistical Profiling Extension) feature provides
       accurate attribution of latencies and events down to individual
       instructions. Rather than being interrupt-driven, it picks an
       instruction to sample and then captures data for it during
       execution. Data includes execution time in cycles."
1003,1,perf-arm-spe,"Data includes execution time in cycles. For loads and
       stores it also includes data address, cache miss events, and data
       origin. The sampling has 5 stages:

        1."
1003,2,perf-arm-spe,"The sampling has 5 stages:

        1. Choose an operation

        2. Collect data about the operation

        3."
1003,3,perf-arm-spe,"Collect data about the operation

        3. Optionally discard the record based on a filter

        4. Write the record to memory

        5."
1003,4,perf-arm-spe,"Write the record to memory

        5. Interrupt when the buffer is full
Choose an operation
This is chosen from a sample population, for SPE this is an
       IMPLEMENTATION DEFINED choice of all architectural instructions or
       all micro-ops. Sampling happens at a programmable interval."
1003,5,perf-arm-spe,"Sampling happens at a programmable interval. The
       architecture provides a mechanism for the SPE driver to infer the
       minimum interval at which it should sample. This minimum interval
       is used by the driver if no interval is specified."
1003,6,perf-arm-spe,"This minimum interval
       is used by the driver if no interval is specified. A pseudo-random
       perturbation is also added to the sampling interval by default. Collect data about the operation
Program counter, PMU events, timings and data addresses related to
       the operation are recorded."
1003,7,perf-arm-spe,"Collect data about the operation
Program counter, PMU events, timings and data addresses related to
       the operation are recorded. Sampling ensures there is only one
       sampled operation is in flight. Optionally discard the record based on a filter
Based on programmable criteria, choose whether to keep the record
       or discard it."
1003,8,perf-arm-spe,"Optionally discard the record based on a filter
Based on programmable criteria, choose whether to keep the record
       or discard it. If the record is discarded then the flow stops here
       for this sample. Write the record to memory
The record is appended to a memory buffer
Interrupt when the buffer is full
When the buffer fills, an interrupt is sent and the driver signals
       Perf to collect the records."
1003,9,perf-arm-spe,"If the record is discarded then the flow stops here
       for this sample. Write the record to memory
The record is appended to a memory buffer
Interrupt when the buffer is full
When the buffer fills, an interrupt is sent and the driver signals
       Perf to collect the records. Perf saves the raw data in the
       perf.data file."
1004,0,perf-bench,"This
perf bench
command is a general framework for benchmark
       suites."
1005,0,perf-buildid-cache,"This command manages the build-id cache. It can add, remove,
       update and purge files to/from the cache. In the future it should
       as well set upper limits for the space used by the cache, etc."
1005,1,perf-buildid-cache,"In the future it should
       as well set upper limits for the space used by the cache, etc. This also scans the target binary for SDT (Statically Defined
       Tracing) and record it along with the buildid-cache, which will be
       used by perf-probe. For more details, see
perf-probe(1)
."
1006,0,perf-check,"With no subcommands given,
perf check
command just prints the
       command usage on the standard output. If the subcommand
feature
is used, then status of feature is
       printed on the standard output (unless
-q
is also passed), ie. whether it is compiled-in/built-in or not."
1006,1,perf-check,"If the subcommand
feature
is used, then status of feature is
       printed on the standard output (unless
-q
is also passed), ie. whether it is compiled-in/built-in or not. Also,
perf check
feature
returns with exit status 0 if the feature is built-in,
       otherwise returns with exit status 1."
1007,0,perf-buildid-list,"This command displays the buildids found in a perf.data file, so
       that other tools can be used to fetch packages with matching
       symbol tables for use by perf report.

       It can also be used to show the build id of the running kernel or
       in an ELF file using -i/--input."
1008,0,perf-c2c,"C2C stands for Cache To Cache. The perf c2c tool provides means for Shared Data C2C/HITM
       analysis. It allows you to track down the cacheline contentions."
1008,1,perf-c2c,"It allows you to track down the cacheline contentions. On Intel, the tool is based on load latency and precise store
       facility events provided by Intel CPUs. On PowerPC, the tool uses
       random instruction sampling with thresholding feature."
1008,2,perf-c2c,"On PowerPC, the tool uses
       random instruction sampling with thresholding feature. On AMD, the
       tool uses IBS op pmu (due to hardware limitations, perf c2c is not
       supported on Zen3 cpus). On Arm64 it uses SPE to sample load and
       store operations, therefore hardware and kernel support is
       required."
1008,3,perf-c2c,"On Arm64 it uses SPE to sample load and
       store operations, therefore hardware and kernel support is
       required. See
perf-arm-spe(1)
for a setup guide. Due to the
       statistical nature of Arm SPE sampling, not every memory operation
       will be sampled."
1008,4,perf-c2c,"Due to the
       statistical nature of Arm SPE sampling, not every memory operation
       will be sampled. These events provide: - memory address of the access - type of the
       access (load and store details) - latency (in cycles) of the load
       access

       The c2c tool provide means to record this data and report back
       access details for cachelines with highest contention - highest
       number of HITM accesses. The basic workflow with this tool follows the standard
       record/report phase."
1008,5,perf-c2c,"These events provide: - memory address of the access - type of the
       access (load and store details) - latency (in cycles) of the load
       access

       The c2c tool provide means to record this data and report back
       access details for cachelines with highest contention - highest
       number of HITM accesses. The basic workflow with this tool follows the standard
       record/report phase. User uses the record command to record events
       data and report command to display it."
1009,0,perf-daemon,"This command allows to run simple daemon process that starts and
       monitors configured record sessions. You can imagine
perf daemon
of background process with several
perf record
child tasks, like:

           # ps axjf
           ... 1  916507 ..."
1009,1,perf-daemon,"1  916507 ... perf daemon start
           916507  916508 ... \_ perf record --control=fifo:control,ack -m 10M -e cycles --overwrite --switch-output -a
           916507  916509 ..."
1009,2,perf-daemon,"\_ perf record --control=fifo:control,ack -m 10M -e cycles --overwrite --switch-output -a
           916507  916509 ... \_ perf record --control=fifo:control,ack -m 20M -e sched:* --overwrite --switch-output -a

       Not every
perf record
session is suitable for running under
       daemon. User need perf session that either produces data on query,
       like the flight recorder sessions in above example or session that
       is configured to produce data periodically, like with
       --switch-output configuration for time and size."
1009,3,perf-daemon,"User need perf session that either produces data on query,
       like the flight recorder sessions in above example or session that
       is configured to produce data periodically, like with
       --switch-output configuration for time and size. Each session is started with control setup (with perf record
       --control options). Sessions are configured through config file, see CONFIG FILE
       section with EXAMPLES."
1010,0,perf-data,Data file related processing.
1011,0,perf-config,"You can manage variables in a configuration file with this
       command."
1012,0,perf-dlfilter,"This option is used to process data through a custom filter
       provided by a dynamically loaded shared object file. Arguments can
       be passed using --dlarg and retrieved using
       perf_dlfilter_fns.args().

       If
file.so
does not contain ""/"", then it will be found either in
       the current directory, or perf tools exec path which is
       ~/libexec/perf-core/dlfilters for a local build and install (refer
       perf --exec-path), or the dynamic linker paths."
1013,0,perf-diff,"This command displays the performance difference amongst two or
       more perf.data files captured via perf record. If no parameters are passed it will assume perf.data.old and
       perf.data. The differential profile is displayed only for events matching
       both specified perf.data files."
1013,1,perf-diff,"The differential profile is displayed only for events matching
       both specified perf.data files. If no parameters are passed the samples will be sorted by dso and
       symbol. As the perf.data files could come from different binaries,
       the symbols addresses could vary."
1013,2,perf-diff,"If no parameters are passed the samples will be sorted by dso and
       symbol. As the perf.data files could come from different binaries,
       the symbols addresses could vary. So perf diff is based on the
       comparison of the files and symbols name."
1014,0,perf-evlist,"This command displays the names of events sampled in a perf.data
       file."
1015,0,perf-ftrace,"The
perf ftrace
command provides a collection of subcommands which
       use kernelâs ftrace infrastructure. 'perf ftrace trace' is a simple wrapper of the ftrace. It only supports
           single thread tracing currently and just reads trace_pipe in text and then
           write it to stdout."
1015,1,perf-ftrace,"It only supports
           single thread tracing currently and just reads trace_pipe in text and then
           write it to stdout. 'perf ftrace latency' calculates execution latency of a given function
           (optionally with BPF) and display it as a histogram. 'perf ftrace profile' show a execution profile for each function including
           total, average, max time and the number of calls."
1015,2,perf-ftrace,"'perf ftrace latency' calculates execution latency of a given function
           (optionally with BPF) and display it as a histogram. 'perf ftrace profile' show a execution profile for each function including
           total, average, max time and the number of calls. The following options apply to perf ftrace."
1016,0,perf-help,"With no options and no COMMAND given, the synopsis of the
perf
command and a list of the most commonly used perf commands are
       printed on the standard output. If the option
--all
or
-a
is given, then all available commands
       are printed on the standard output. If a perf command is named, a manual page for that command is
       brought up."
1016,1,perf-help,"If a perf command is named, a manual page for that command is
       brought up. The
man
program is used by default for this purpose,
       but this can be overridden by other options or configuration
       variables. Note that perf --help ..."
1016,2,perf-help,"Note that perf --help ... is identical to perf help ... because
       the former is internally converted into the latter."
1017,0,perf-inject,"perf-inject reads a perf-record event stream and repipes it to
       stdout. At any point the processing code can inject other events
       into the event stream - in this case build-ids (-b option) are
       read and injected as needed into the event stream.

       Build-ids are just the first user of perf-inject - potentially
       anything that needs userspace processing to augment the events
       stream with additional information could make use of this
       facility."
1018,0,perf-iostat,"Mode is intended to provide four I/O performance metrics per each
       PCIe root port:

       â¢   Inbound Read - I/O devices below root port read from the host
           memory, in MB

       â¢   Inbound Write - I/O devices below root port write to the host
           memory, in MB

       â¢   Outbound Read - CPU reads from I/O devices below root port, in
           MB

       â¢   Outbound Write - CPU writes to I/O devices below root port, in
           MB"
1019,0,perf-kmem,"There are two variants of perf kmem:

           'perf kmem [<options>] record [<perf-record-options>] <command>' to
           record the kmem events of an arbitrary workload. Additional 'perf
           record' options may be specified after record, such as '-o' to
           change the output file name.

           'perf kmem [<options>] stat' to report kernel memory statistics."
1020,0,perf-kallsyms,"This command searches the running kernel kallsyms file for the
       given symbol(s) and prints information about it, including the
       DSO, the kallsyms begin/end addresses and the addresses in the ELF
       kallsyms symbol table (for symbols in modules)."
1021,0,perf-intel-pt,"Intel Processor Trace (Intel PT) is an extension of Intel
       Architecture that collects information about software execution
       such as control flow, execution modes and timings and formats it
       into highly compressed binary packets. Technical details are
       documented in the Intel 64 and IA-32 Architectures Software
       Developer Manuals, Chapter 36 Intel Processor Trace. Intel PT is first supported in Intel Core M and 5th generation
       Intel Core processors that are based on the Intel
       micro-architecture code name Broadwell."
1021,1,perf-intel-pt,"Intel PT is first supported in Intel Core M and 5th generation
       Intel Core processors that are based on the Intel
       micro-architecture code name Broadwell. Trace data is collected by
perf record
and stored within the
       perf.data file. See below for options to
perf record
."
1021,2,perf-intel-pt,"See below for options to
perf record
. Trace data must be
decoded
which involves walking the object code
       and matching the trace data packets. For example a TNT packet only
       tells whether a conditional branch was taken or not taken, so to
       make use of that packet the decoder must know precisely which
       instruction was being executed."
1021,3,perf-intel-pt,"For example a TNT packet only
       tells whether a conditional branch was taken or not taken, so to
       make use of that packet the decoder must know precisely which
       instruction was being executed. Decoding is done on-the-fly. The decoder outputs samples in the
       same format as samples output by perf hardware events, for example
       as though the ""instructions"" or ""branches"" events had been
       recorded."
1021,4,perf-intel-pt,"The decoder outputs samples in the
       same format as samples output by perf hardware events, for example
       as though the ""instructions"" or ""branches"" events had been
       recorded. Presently 3 tools support this:
perf script
,
perf report
and
perf inject
. See below for more information on using those
       tools."
1021,5,perf-intel-pt,"See below for more information on using those
       tools. The main distinguishing feature of Intel PT is that the decoder
       can determine the exact flow of software execution. Intel PT can
       be used to understand why and how did software get to a certain
       point, or behave a certain way."
1021,6,perf-intel-pt,"Intel PT can
       be used to understand why and how did software get to a certain
       point, or behave a certain way. The software does not have to be
       recompiled, so Intel PT works with debug or release builds,
       however the executed images are needed - which makes use in
       JIT-compiled environments, or with self-modified code, a
       challenge. Also symbols need to be provided to make sense of
       addresses."
1021,7,perf-intel-pt,"Also symbols need to be provided to make sense of
       addresses. A limitation of Intel PT is that it produces huge amounts of trace
       data (hundreds of megabytes per second per core) which takes a
       long time to decode, for example two or three orders of magnitude
       longer than it took to collect. Another limitation is the
       performance impact of tracing, something that will vary depending
       on the use-case and architecture."
1022,0,perf-kvm,"There are a couple of variants of perf kvm:

           'perf kvm [options] top <command>' to generates and displays
           a performance counter profile of guest os in realtime
           of an arbitrary workload. 'perf kvm record <command>' to record the performance counter profile
           of an arbitrary workload and save it into a perf data file. We set the
           default behavior of perf kvm as --guest, so if neither --host nor --guest
           is input, the perf data file name is perf.data.guest."
1022,1,perf-kvm,"We set the
           default behavior of perf kvm as --guest, so if neither --host nor --guest
           is input, the perf data file name is perf.data.guest. If --host is input,
           the perf data file name is perf.data.kvm. If you want to record data into
           perf.data.host, please input --host --no-guest."
1022,2,perf-kvm,"If you want to record data into
           perf.data.host, please input --host --no-guest. The behaviors are shown as
           following:
             Default('')         ->  perf.data.guest
             --host              ->  perf.data.kvm
             --guest             ->  perf.data.guest
             --host --guest      ->  perf.data.kvm
             --host --no-guest   ->  perf.data.host

           'perf kvm report' to display the performance counter profile information
           recorded via perf kvm record. 'perf kvm diff' to displays the performance difference amongst two perf.data
           files captured via perf record."
1022,3,perf-kvm,"'perf kvm diff' to displays the performance difference amongst two perf.data
           files captured via perf record. 'perf kvm buildid-list' to  display the buildids found in a perf data file,
           so that other tools can be used to fetch packages with matching symbol tables
           for use by perf report. As buildid is read from /sys/kernel/notes in os, then
           if you want to list the buildid for guest, please make sure your perf data file
           was captured with --guestmount in perf kvm record."
1022,4,perf-kvm,"As buildid is read from /sys/kernel/notes in os, then
           if you want to list the buildid for guest, please make sure your perf data file
           was captured with --guestmount in perf kvm record. 'perf kvm stat <command>' to run a command and gather performance counter
           statistics. Especially, perf 'kvm stat record/report' generates a statistical analysis
           of KVM events."
1022,5,perf-kvm,"Especially, perf 'kvm stat record/report' generates a statistical analysis
           of KVM events. Currently, vmexit, mmio (x86 only) and ioport (x86 only)
           events are supported. 'perf kvm stat record <command>' records kvm events
           and the events between start and end <command>."
1022,6,perf-kvm,"'perf kvm stat record <command>' records kvm events
           and the events between start and end <command>. And this command produces a file which contains tracing results of kvm
           events. 'perf kvm stat report' reports statistical data which includes events
           handled sample, percent_sample, time, percent_time, max_t, min_t, mean_t."
1022,7,perf-kvm,"And this command produces a file which contains tracing results of kvm
           events. 'perf kvm stat report' reports statistical data which includes events
           handled sample, percent_sample, time, percent_time, max_t, min_t, mean_t. 'perf kvm stat live' reports statistical data in a live mode (similar to
           record + report but with statistical data updated live at a given display
           rate)."
1023,0,perf-kwork,"There are several variants of
perf kwork
:

           'perf kwork record <command>' to record the kernel work
           of an arbitrary workload. 'perf kwork report' to report the per kwork runtime. 'perf kwork latency' to report the per kwork latencies."
1023,1,perf-kwork,'perf kwork latency' to report the per kwork latencies. 'perf kwork timehist' provides an analysis of kernel work events. 'perf kwork top' to report the task cpu usage.
1023,2,perf-kwork,"'perf kwork top' to report the task cpu usage. Example usage:
               perf kwork record -- sleep 1
               perf kwork report
               perf kwork report -b
               perf kwork latency
               perf kwork latency -b
               perf kwork timehist
               perf kwork top
               perf kwork top -b

           By default it shows the individual work events such as irq, workqueue,
           including the run time and delay (time between raise and actually entry):

              Runtime start      Runtime end        Cpu     Kwork name                 Runtime     Delaytime
                                                            (TYPE)NAME:NUM             (msec)      (msec)
           -----------------  -----------------  ------  -------------------------  ----------  ----------
              1811186.976062     1811186.976327  [0000]  (s)RCU:9                        0.266       0.114
              1811186.978452     1811186.978547  [0000]  (s)SCHED:7                      0.095       0.171
              1811186.980327     1811186.980490  [0000]  (s)SCHED:7                      0.162       0.083
              1811186.981221     1811186.981271  [0000]  (s)SCHED:7                      0.050       0.077
              1811186.984267     1811186.984318  [0000]  (s)SCHED:7                      0.051       0.075
              1811186.987252     1811186.987315  [0000]  (s)SCHED:7                      0.063       0.081
              1811186.987785     1811186.987843  [0006]  (s)RCU:9                        0.058       0.645
              1811186.988319     1811186.988383  [0000]  (s)SCHED:7                      0.064       0.143
              1811186.989404     1811186.989607  [0002]  (s)TIMER:1                      0.203       0.111
              1811186.989660     1811186.989732  [0002]  (s)SCHED:7                      0.072       0.310
              1811186.991295     1811186.991407  [0002]  eth0:10                         0.112
              1811186.991639     1811186.991734  [0002]  (s)NET_RX:3                     0.095       0.277
              1811186.989860     1811186.991826  [0002]  (w)vmstat_shepherd              1.966       0.345
            ... Times are in msec.usec."
1024,0,perf-list,"This command displays the symbolic event types which can be
       selected in the various perf commands with the -e option."
1025,0,perf-lock,"You can analyze various lock behaviours and statistics with this
perf lock
command. 'perf lock record <command>' records lock events
           between start and end <command>. And this command
           produces the file ""perf.data"" which contains tracing
           results of lock events."
1025,1,perf-lock,"And this command
           produces the file ""perf.data"" which contains tracing
           results of lock events. 'perf lock report' reports statistical data. 'perf lock script' shows raw lock events."
1025,2,perf-lock,"'perf lock script' shows raw lock events. 'perf lock info' shows metadata like threads or addresses
           of lock instances. 'perf lock contention' shows contention statistics."
1026,0,perf-mem,"""perf mem record"" runs a command and gathers memory operation data
       from it, into perf.data. Perf record options are accepted and are
       passed through. ""perf mem report"" displays the result."
1026,1,perf-mem,"""perf mem report"" displays the result. It invokes perf report with
       the right set of options to display a memory access profile. By
       default, loads and stores are sampled."
1026,2,perf-mem,"By
       default, loads and stores are sampled. Use the -t option to limit
       to loads or stores. Note that on Intel systems the memory latency reported is the
       use-latency, not the pure load (or store latency)."
1026,3,perf-mem,"Note that on Intel systems the memory latency reported is the
       use-latency, not the pure load (or store latency). Use latency
       includes any pipeline queuing delays in addition to the memory
       subsystem latency. On Arm64 this uses SPE to sample load and store operations,
       therefore hardware and kernel support is required."
1026,4,perf-mem,"On Arm64 this uses SPE to sample load and store operations,
       therefore hardware and kernel support is required. See
perf-arm-spe(1)
for a setup guide. Due to the statistical nature
       of SPE sampling, not every memory operation will be sampled."
1027,0,perf-script-perl,"This perf script option is used to process perf script data using
       perfâs built-in Perl interpreter. It reads and processes the input
       file and displays the results of the trace analysis implemented in
       the given Perl script, if any."
1028,0,perf-report,"This command displays the performance counter profile information
       recorded via perf record."
1029,0,perf-record,"This command runs a command and gathers a performance counter
       profile from it, into perf.data - without displaying anything.

       This file can then be inspected later on, using
perf report
."
1030,0,perf-probe,"This command defines dynamic tracepoint events, by symbol and
       registers without debuginfo, or by C expressions (C line numbers,
       C function names, and C local variables) with debuginfo."
1031,0,perf-sched,"There are several variants of
perf sched
:

           'perf sched record <command>' to record the scheduling events
           of an arbitrary workload. 'perf sched latency' to report the per task scheduling latencies
           and other scheduling properties of the workload. Example usage:
               perf sched record -- sleep 1
               perf sched latency

           -------------------------------------------------------------------------------------------------------------------------------------------
           Task                  |   Runtime ms  |  Count   | Avg delay ms    | Max delay ms    | Max delay start           | Max delay end          |
           -------------------------------------------------------------------------------------------------------------------------------------------
           perf:(2)              |      2.804 ms |       66 | avg:   0.524 ms | max:   1.069 ms | max start: 254752.314960 s | max end: 254752.316029 s
           NetworkManager:1343   |      0.372 ms |       13 | avg:   0.008 ms | max:   0.013 ms | max start: 254751.551153 s | max end: 254751.551166 s
           kworker/1:2-xfs:4649  |      0.012 ms |        1 | avg:   0.008 ms | max:   0.008 ms | max start: 254751.519807 s | max end: 254751.519815 s
           kworker/3:1-xfs:388   |      0.011 ms |        1 | avg:   0.006 ms | max:   0.006 ms | max start: 254751.519809 s | max end: 254751.519815 s
           sleep:147736          |      0.938 ms |        3 | avg:   0.006 ms | max:   0.007 ms | max start: 254751.313817 s | max end: 254751.313824 s

           It shows Runtime(time that a task spent actually running on the CPU),
           Count(number of times a delay was calculated) and delay(time that a
           task was ready to run but was kept waiting)."
1031,1,perf-sched,"Example usage:
               perf sched record -- sleep 1
               perf sched latency

           -------------------------------------------------------------------------------------------------------------------------------------------
           Task                  |   Runtime ms  |  Count   | Avg delay ms    | Max delay ms    | Max delay start           | Max delay end          |
           -------------------------------------------------------------------------------------------------------------------------------------------
           perf:(2)              |      2.804 ms |       66 | avg:   0.524 ms | max:   1.069 ms | max start: 254752.314960 s | max end: 254752.316029 s
           NetworkManager:1343   |      0.372 ms |       13 | avg:   0.008 ms | max:   0.013 ms | max start: 254751.551153 s | max end: 254751.551166 s
           kworker/1:2-xfs:4649  |      0.012 ms |        1 | avg:   0.008 ms | max:   0.008 ms | max start: 254751.519807 s | max end: 254751.519815 s
           kworker/3:1-xfs:388   |      0.011 ms |        1 | avg:   0.006 ms | max:   0.006 ms | max start: 254751.519809 s | max end: 254751.519815 s
           sleep:147736          |      0.938 ms |        3 | avg:   0.006 ms | max:   0.007 ms | max start: 254751.313817 s | max end: 254751.313824 s

           It shows Runtime(time that a task spent actually running on the CPU),
           Count(number of times a delay was calculated) and delay(time that a
           task was ready to run but was kept waiting). Tasks with the same command name are merged and the merge count is
           given within (), However if -p option is used, pid is mentioned. 'perf sched script' to see a detailed trace of the workload that
            was recorded (aliased to 'perf script' for now)."
1031,2,perf-sched,"'perf sched script' to see a detailed trace of the workload that
            was recorded (aliased to 'perf script' for now). 'perf sched replay' to simulate the workload that was recorded
           via perf sched record. (this is done by starting up mockup threads
           that mimic the workload based on the events in the trace."
1031,3,perf-sched,"(this is done by starting up mockup threads
           that mimic the workload based on the events in the trace. These
           threads can then replay the timings (CPU runtime and sleep patterns)
           of the workload as it occurred when it was recorded - and can repeat
           it a number of times, measuring its performance.)

           'perf sched map' to print a textual context-switching outline of
           workload captured via perf sched record. Columns stand for
           individual CPUs, and the two-letter shortcuts stand for tasks that
           are running on a CPU."
1031,4,perf-sched,"Columns stand for
           individual CPUs, and the two-letter shortcuts stand for tasks that
           are running on a CPU. A '*' denotes the CPU that had the event, and
           a dot signals an idle CPU. 'perf sched timehist' provides an analysis of scheduling events."
1031,5,perf-sched,"'perf sched timehist' provides an analysis of scheduling events. Example usage:
               perf sched record -- sleep 1
               perf sched timehist

           By default it shows the individual schedule events, including the wait
           time (time between sched-out and next sched-in events for the task), the
           task scheduling delay (time between runnable and actually running) and
           run time for the task:

                       time    cpu  task name             wait time  sch delay   run time
                                    [tid/pid]                (msec)     (msec)     (msec)
             -------------- ------  --------------------  ---------  ---------  ---------
               79371.874569 [0011]  gcc[31949]                0.014      0.000      1.148
               79371.874591 [0010]  gcc[31951]                0.000      0.000      0.024
               79371.874603 [0010]  migration/10[59]          3.350      0.004      0.011
               79371.874604 [0011]  <idle>                    1.148      0.000      0.035
               79371.874723 [0005]  <idle>                    0.016      0.000      1.383
               79371.874746 [0005]  gcc[31949]                0.153      0.078      0.022
           ... Times are in msec.usec."
1032,0,perf-script-python,"This perf script option is used to process perf script data using
       perfâs built-in Python interpreter. It reads and processes the
       input file and displays the results of the trace analysis
       implemented in the given Python script, if any."
1033,0,perf-script,"This command reads the input file and displays the trace recorded. There are several variants of perf script:

           'perf script' to see a detailed trace of the workload that was
           recorded. You can also run a set of pre-canned scripts that aggregate and
           summarize the raw trace data in various ways (the list of scripts is
           available via 'perf script -l')."
1033,1,perf-script,"You can also run a set of pre-canned scripts that aggregate and
           summarize the raw trace data in various ways (the list of scripts is
           available via 'perf script -l'). The following variants allow you to
           record and run those scripts:

           'perf script record <script> <command>' to record the events required
           for 'perf script report'. <script> is the name displayed in the
           output of 'perf script --list' i.e."
1033,2,perf-script,"<script> is the name displayed in the
           output of 'perf script --list' i.e. the actual script name minus any
           language extension. If <command> is not specified, the events are
           recorded using the -a (system-wide) 'perf record' option."
1033,3,perf-script,"If <command> is not specified, the events are
           recorded using the -a (system-wide) 'perf record' option. 'perf script report <script> [args]' to run and display the results
           of <script>. <script> is the name displayed in the output of 'perf
           script --list' i.e."
1033,4,perf-script,"<script> is the name displayed in the output of 'perf
           script --list' i.e. the actual script name minus any language
           extension. The perf.data output from a previous run of 'perf script
           record <script>' is used and should be present for this command to
           succeed."
1033,5,perf-script,"The perf.data output from a previous run of 'perf script
           record <script>' is used and should be present for this command to
           succeed. [args] refers to the (mainly optional) args expected by
           the script. 'perf script <script> <required-script-args> <command>' to both
           record the events required for <script> and to run the <script>
           using 'live-mode' i.e."
1033,6,perf-script,"'perf script <script> <required-script-args> <command>' to both
           record the events required for <script> and to run the <script>
           using 'live-mode' i.e. without writing anything to disk. <script>
           is the name displayed in the output of 'perf script --list' i.e."
1033,7,perf-script,"<script>
           is the name displayed in the output of 'perf script --list' i.e. the
           actual script name minus any language extension. If <command> is
           not specified, the events are recorded using the -a (system-wide)
           'perf record' option."
1033,8,perf-script,"If <command> is
           not specified, the events are recorded using the -a (system-wide)
           'perf record' option. If <script> has any required args, they
           should be specified before <command>. This mode doesn't allow for
           optional script args to be specified; if optional script args are
           desired, they can be specified using separate 'perf script record'
           and 'perf script report' commands, with the stdout of the record step
           piped to the stdin of the report script, using the '-o -' and '-i -'
           options of the corresponding commands."
1033,9,perf-script,"This mode doesn't allow for
           optional script args to be specified; if optional script args are
           desired, they can be specified using separate 'perf script record'
           and 'perf script report' commands, with the stdout of the record step
           piped to the stdin of the report script, using the '-o -' and '-i -'
           options of the corresponding commands. 'perf script <top-script>' to both record the events required for
           <top-script> and to run the <top-script> using 'live-mode'
           i.e. without writing anything to disk."
1033,10,perf-script,"without writing anything to disk. <top-script> is the name
           displayed in the output of 'perf script --list' i.e. the actual
           script name minus any language extension; a <top-script> is defined
           as any script name ending with the string 'top'."
1033,11,perf-script,"the actual
           script name minus any language extension; a <top-script> is defined
           as any script name ending with the string 'top'. [<record-options>] can be passed to the record steps of 'perf script
           record' and 'live-mode' variants; this isn't possible however for
           <top-script> 'live-mode' or 'perf script report' variants. See the 'SEE ALSO' section for links to language-specific
           information on how to write and run your own trace scripts."
1034,0,perf-timechart,"There are two variants of perf timechart:

           'perf timechart record <command>' to record the system level events
           of an arbitrary workload. By default timechart records only scheduler
           and CPU events (task switches, running times, CPU power states, etc),
           but it's possible to record IO (disk, network) activity using -I argument. 'perf timechart' to turn a trace into a Scalable Vector Graphics file,
           that can be viewed with popular SVG viewers such as 'Inkscape'."
1034,1,perf-timechart,"'perf timechart' to turn a trace into a Scalable Vector Graphics file,
           that can be viewed with popular SVG viewers such as 'Inkscape'. Depending
           on the events in the perf.data file, timechart will contain scheduler/cpu
           events or IO events. In IO mode, every bar has two charts: upper and lower."
1034,2,perf-timechart,"In IO mode, every bar has two charts: upper and lower. Upper bar shows incoming events (disk reads, ingress network packets). Lower bar shows outgoing events (disk writes, egress network packets)."
1034,3,perf-timechart,"Upper bar shows incoming events (disk reads, ingress network packets). Lower bar shows outgoing events (disk writes, egress network packets). There are also poll bars which show how much time application spent
           in poll/epoll/select syscalls."
1035,0,perf-test,"This command does assorted sanity tests, initially through linked
       routines but also will look for a directory with more tests in the
       form of scripts.

       To get a list of available tests use
perf test list
, specifying a
       test name fragment will show all tests that have it.

       To run just specific tests, inform test name fragments or the
       numbers obtained from
perf test list
."
1036,0,perf-stat,"This command runs a command and gathers performance counter
       statistics from it."
1037,0,perf-trace,"This command will show the events associated with the target,
       initially syscalls, but other system events like pagefaults, task
       lifetime events, scheduling events, etc. This is a live mode tool in addition to working with perf.data
       files like the other perf tools. Files can be generated using the
perf record
command but the session needs to include the
       raw_syscalls events (-e
raw_syscalls:*
)."
1037,1,perf-trace,"Files can be generated using the
perf record
command but the session needs to include the
       raw_syscalls events (-e
raw_syscalls:*
). Alternatively,
perf trace
record
can be used as a shortcut to automatically include the
       raw_syscalls events when writing events to a file. The following options apply to perf trace; options to perf trace
       record are found in the perf record man page."
1038,0,perf,"Performance counters for Linux are a new kernel-based subsystem
       that provide a framework for all things performance analysis. It
       covers hardware level (CPU/PMU, Performance Monitoring Unit)
       features and software features (software counters, tracepoints) as
       well."
1039,0,perf-top,"This command generates and displays a performance counter profile
       in real time."
1040,0,perf-version,"With no options given, the
perf version
prints the perf version on
       the standard output.

       If the option
--build-options
is given, then the status of
       compiled-in libraries are printed on the standard output."
1041,0,perfalloc,"perfalloc
is a command that notifies the
pmdaperfevent(1)
to
       disable hardware counter event collection. This allow
       unprivileged processes to use the hardware counters. If the reservation request fails, then perfalloc exits immediately
       with exit code EXIT_FAILURE."
1041,1,perfalloc,"If the reservation request fails, then perfalloc exits immediately
       with exit code EXIT_FAILURE. If successful, the perfalloc will
       run until a kill signal is received. The reservation request
       persists while perfalloc is running."
1041,2,perfalloc,"The reservation request
       persists while perfalloc is running. Note that
pmdaperfevent
is affected by the value of the
kernel.perf_event_paranoid
setting, which can be adjusted by
sysctl(8)
. If a commandline is given, this is executed as a subprocess of the
       agent."
1041,3,perfalloc,"If a commandline is given, this is executed as a subprocess of the
       agent. When the command dies, so does the agent. A brief description of the command line options follows:
-D
run in the foreground (the default)
-d
run in the background
-f FILE
use FILE as the lock file (default
            $PCP_PMDAS_DIR/perfevent/perflock)
-h
display a help message and exit
-v
output version number and exit"
1042,0,perror,"For most system errors, MariaDB displays, in addition to an
       internal text message, the system error code in one of the
       following styles:

           message ... (errno: #)
           message ... (Errcode: #)

       You can find out what the error code means by examining the
       documentation for your system or by using the
perror
utility."
1042,1,perror,"(Errcode: #)

       You can find out what the error code means by examining the
       documentation for your system or by using the
perror
utility. perror
prints a description for a system error code or for a
       storage engine (table handler) error code. Invoke
perror
like this:

           shell>
perror [
options
]
errorcode
..."
1042,2,perror,"Invoke
perror
like this:

           shell>
perror [
options
]
errorcode
... Example:

           shell>
perror 13 64
OS error code  13:  Permission denied
           OS error code  64:  Machine is not on the network

       Note that the meaning of system error messages may be dependent on
       your operating system. A given error code may mean different
       things on different operating systems."
1042,3,perror,"A given error code may mean different
       things on different operating systems. perror
supports the following options. â¢
--help
,
--info
,
-I
,
-?"
1042,4,perror,"â¢
--help
,
--info
,
-I
,
-? Display a help message and exit. â¢
--silent
,
-s
Silent mode."
1042,5,perror,"â¢
--silent
,
-s
Silent mode. Print only the error message. â¢
--verbose
,
-v
Verbose mode."
1042,6,perror,"â¢
--verbose
,
-v
Verbose mode. Print error code and message. This is the
           default behavior."
1042,7,perror,"Print error code and message. This is the
           default behavior. â¢
--version
,
-V
Display version information and exit."
1043,0,pfbtops,nan
1044,0,pgrep,"pgrep
looks through the currently running processes and lists the
       process IDs which match the selection criteria to stdout. All the
       criteria have to match. For example,

              $ pgrep -u root sshd

       will only list the processes whose name include
sshd
AND owned by
root
."
1044,1,pgrep,"For example,

              $ pgrep -u root sshd

       will only list the processes whose name include
sshd
AND owned by
root
. On the other hand,

              $ pgrep -u root,daemon

       will list the processes owned by
root
OR
daemon
. pkill
will send the specified signal (by default
SIGTERM
) to each
       process instead of listing them on stdout."
1044,2,pgrep,"On the other hand,

              $ pgrep -u root,daemon

       will list the processes owned by
root
OR
daemon
. pkill
will send the specified signal (by default
SIGTERM
) to each
       process instead of listing them on stdout. pidwait
will wait for each process instead of listing them on
       stdout."
1045,0,pic,nan
1046,0,pic2graph,nan
1047,0,pidof,"Pidof
finds the process id's (pids) of the named programs. It
       prints those id's on the standard output."
1048,0,pidstat,"The
pidstat
command is used for monitoring individual tasks
       currently being managed by the Linux kernel. It writes to
       standard output activities for every task selected with option
-p
or for every task managed by the Linux kernel if option
-p ALL
has
       been used. Not selecting any tasks is equivalent to specifying
-p
ALL
but only active tasks (tasks with non-zero statistics values)
       will appear in the report."
1048,1,pidstat,"Not selecting any tasks is equivalent to specifying
-p
ALL
but only active tasks (tasks with non-zero statistics values)
       will appear in the report. The
pidstat
command can also be used for monitoring the child
       processes of selected tasks. Read about option
-T
below."
1048,2,pidstat,"Read about option
-T
below. The
interval
parameter specifies the amount of time in seconds
       between each report. A value of 0 (or no parameters at all)
       indicates that tasks statistics are to be reported for the time
       since system startup (boot)."
1048,3,pidstat,"A value of 0 (or no parameters at all)
       indicates that tasks statistics are to be reported for the time
       since system startup (boot). The
count
parameter can be specified
       in conjunction with the
interval
parameter if this one is not set
       to zero. The value of
count
determines the number of reports
       generated at
interval
seconds apart."
1048,4,pidstat,"The value of
count
determines the number of reports
       generated at
interval
seconds apart. If the
interval
parameter is
       specified without the
count
parameter, the
pidstat
command
       generates reports continuously. You can select information about specific task activities using
       flags."
1048,5,pidstat,"If the
interval
parameter is
       specified without the
count
parameter, the
pidstat
command
       generates reports continuously. You can select information about specific task activities using
       flags. Not specifying any flags selects only CPU activity."
1049,0,pipesz,"Pipes and FIFOs maintain an internal buffer used to transfer data
       between the read end and the write end. In some cases, the default
       size of this internal buffer may not be appropriate. This program
       provides facilities to set and examine the size of these buffers."
1049,1,pipesz,"This program
       provides facilities to set and examine the size of these buffers. The
--set
operation sets pipe buffer sizes. If it is specified, it
       must be specified with an explicit
size
."
1049,2,pipesz,"If it is specified, it
       must be specified with an explicit
size
. Otherwise, it is implied
       and the size is read from
/proc/sys/fs/pipe-max-size
. The kernel
       may adjust
size
as described in
fcntl(2)
."
1049,3,pipesz,"The kernel
       may adjust
size
as described in
fcntl(2)
. To determine the actual
       buffer sizes set, use the
--verbose
option. If neither
--file
nor
--fd
are specified,
--set
acts on standard output."
1049,4,pipesz,"If neither
--file
nor
--fd
are specified,
--set
acts on standard output. The
--set
operation permits an optional
command
to execute after
       setting the pipe buffer sizes. This command is executed with the
       adjusted pipes."
1049,5,pipesz,"This command is executed with the
       adjusted pipes. The
--get
operation outputs data in a tabular format. The first
       column is the name of the pipe as passed to
pipesz
."
1049,6,pipesz,"The first
       column is the name of the pipe as passed to
pipesz
. File
       descriptors are named as ""fd
N
"". The second column is the size, in
       bytes, of the pipeâs internal buffer."
1049,7,pipesz,"The second column is the size, in
       bytes, of the pipeâs internal buffer. The third column is the
       number of unread bytes currently in the pipe. The columns are
       separated by tabs ('\t', ASCII 09h)."
1049,8,pipesz,"The columns are
       separated by tabs ('\t', ASCII 09h). If
--verbose
is specified, a
       descriptive header is also emitted. If neither
--file
nor
--fd
are
       specified,
--get
acts on standard input."
1049,9,pipesz,"If neither
--file
nor
--fd
are
       specified,
--get
acts on standard input. Unless the
--check
option is specified,
pipesz
does
not
exit if it
       encounters an error while manipulating a file or file descriptor. This allows
pipesz
to be used generically without fear of
       disrupting the execution of pipelines should the type of certain
       files be later changed."
1049,10,pipesz,"This allows
pipesz
to be used generically without fear of
       disrupting the execution of pipelines should the type of certain
       files be later changed. For minimal disruption, the
--quiet
option
       prevents warnings from being emitted in these cases. The kernel imposes limits on the amount of pipe buffer space
       unprivileged processes can use, though see
BUGS
below."
1049,11,pipesz,"The kernel imposes limits on the amount of pipe buffer space
       unprivileged processes can use, though see
BUGS
below. The kernel
       will also refuse to shrink a pipe buffer if this would cause a
       loss of buffered data. See
pipe(7)
for additional details."
1049,12,pipesz,"See
pipe(7)
for additional details. pipesz
supports specifying multiple short options consecutively,
       in the usual
getopt(3)
fashion. The first non-option argument is
       interpreted as
command
."
1049,13,pipesz,"The first non-option argument is
       interpreted as
command
. If
command
might begin with '-', use '--'
       to separate it from arguments to
pipesz
. In shell scripts, it is
       good practice to use '--' when parameter expansion is involved."
1049,14,pipesz,"If
command
might begin with '-', use '--'
       to separate it from arguments to
pipesz
. In shell scripts, it is
       good practice to use '--' when parameter expansion is involved. pipesz
itself does not read from standard input and does not write
       to standard output unless
--get
,
--help
, or
--version
are
       specified."
1050,0,pgrep,"pgrep
looks through the currently running processes and lists the
       process IDs which match the selection criteria to stdout. All the
       criteria have to match. For example,

              $ pgrep -u root sshd

       will only list the processes whose name include
sshd
AND owned by
root
."
1050,1,pgrep,"For example,

              $ pgrep -u root sshd

       will only list the processes whose name include
sshd
AND owned by
root
. On the other hand,

              $ pgrep -u root,daemon

       will list the processes owned by
root
OR
daemon
. pkill
will send the specified signal (by default
SIGTERM
) to each
       process instead of listing them on stdout."
1050,2,pgrep,"On the other hand,

              $ pgrep -u root,daemon

       will list the processes owned by
root
OR
daemon
. pkill
will send the specified signal (by default
SIGTERM
) to each
       process instead of listing them on stdout. pidwait
will wait for each process instead of listing them on
       stdout."
1051,0,pinky,"-l
produce long format output for the specified USERs
-b
omit the user's home directory and shell in long format
-h
omit the user's project file in long format
-p
omit the user's plan file in long format
-s
do short format output, this is the default
-f
omit the line of column headings in short format
-w
omit the user's full name in short format
-i
omit the user's full name and remote host in short format
-q
omit the user's full name, remote host and idle time in
              short format
--lookup
attempt to canonicalize hostnames via DNS
--help
display this help and exit
--version
output version information and exit

       A lightweight 'finger' program;  print user information.  The utmp
       file will be
/var/run/utmp
."
1052,0,pkgdata,"pkgdata
takes a set of data files and packages them for use by ICU
       or applications that use ICU. The typical reason to package files
       using
pkgdata
is to make their distribution easier and their
       loading by ICU faster and less consuming of limited system
       resources such as file descriptors. Packaged data also allow
       applications to be distributed with fewer resource files, or even
       with none at all if they link against the packaged data directly."
1052,1,pkgdata,"Packaged data also allow
       applications to be distributed with fewer resource files, or even
       with none at all if they link against the packaged data directly. pkgdata
supports a few different methods of packaging data that
       serve different purposes. The default packaging
mode
is
common
, or
archive
."
1052,2,pkgdata,"The default packaging
mode
is
common
, or
archive
. In this mode,
       the different data files are bundled together as an architecture-
       dependent file that can later be memory mapped for use by ICU. Data packaged using this mode will be looked up under the ICU data
       directory."
1052,3,pkgdata,"Data packaged using this mode will be looked up under the ICU data
       directory. Such packaging is easy to use for applications resource
       bundles, for example, as long as the application can install the
       packaged file in the ICU data directory. Another packaging mode is the
dll
, or
library
, mode, where the
       data files are compiled into a shared library."
1052,4,pkgdata,"Another packaging mode is the
dll
, or
library
, mode, where the
       data files are compiled into a shared library. ICU used to be able
       to dynamically load these shared libraries, but as of ICU 2.0,
       such support has been removed. This mode is still useful for two
       main purposes: to build ICU itself, as the ICU data is packaged as
       a shared library by default; and to build resource bundles that
       are linked to the application that uses them."
1052,5,pkgdata,"This mode is still useful for two
       main purposes: to build ICU itself, as the ICU data is packaged as
       a shared library by default; and to build resource bundles that
       are linked to the application that uses them. Such resource
       bundles can then be placed anywhere where the system's dynamic
       linker will be looking for shared libraries, instead of being
       forced to live inside the ICU data directory. The
static
packaging mode is similar to the shared library one
       except that it produces a static library."
1052,6,pkgdata,"The
static
packaging mode is similar to the shared library one
       except that it produces a static library. Finally,
pkgdata
supports a
files
mode which simply copies the
       data files instead of packaging them as a single file or library. This mode is mainly intended to provide support for building ICU
       before it is packaged as separate small packages for distribution
       with operating systems such as Debian GNU/Linux for example."
1052,7,pkgdata,"This mode is mainly intended to provide support for building ICU
       before it is packaged as separate small packages for distribution
       with operating systems such as Debian GNU/Linux for example. Please refer to the packaging documentation in the ICU source
       distribution for further information on the use of this mode. pkgdata
builds, packages, installs, or cleans the appropriate data
       based on the options given without the need to call GNU
make
anymore."
1053,0,pgrep,"pgrep
looks through the currently running processes and lists the
       process IDs which match the selection criteria to stdout. All the
       criteria have to match. For example,

              $ pgrep -u root sshd

       will only list the processes whose name include
sshd
AND owned by
root
."
1053,1,pgrep,"For example,

              $ pgrep -u root sshd

       will only list the processes whose name include
sshd
AND owned by
root
. On the other hand,

              $ pgrep -u root,daemon

       will list the processes owned by
root
OR
daemon
. pkill
will send the specified signal (by default
SIGTERM
) to each
       process instead of listing them on stdout."
1053,2,pgrep,"On the other hand,

              $ pgrep -u root,daemon

       will list the processes owned by
root
OR
daemon
. pkill
will send the specified signal (by default
SIGTERM
) to each
       process instead of listing them on stdout. pidwait
will wait for each process instead of listing them on
       stdout."
1054,0,pldd,"The
pldd
command displays a list of the dynamic shared objects
       (DSOs) that are linked into the process with the specified process
       ID (PID).  The list includes the libraries that have been
       dynamically loaded using
dlopen(3)
."
1055,0,pon,"This manual page describes the
pon
,
plog
and
poff
scripts, which
       allow users to control PPP connections. pon
pon
, invoked without arguments, runs the
/etc/ppp/ppp_on_boot
file, if it exists and is executable. Otherwise, a PPP connection
       will be started using configuration from
/etc/ppp/peers/provider
."
1055,1,pon,"Otherwise, a PPP connection
       will be started using configuration from
/etc/ppp/peers/provider
. This is the default behaviour unless an
isp-name
argument is
       given. For instance, to use ISP configuration ""myisp"" run:

              pon myisp
pon
will then use the options file
/etc/ppp/peers/myisp
."
1055,2,pon,"For instance, to use ISP configuration ""myisp"" run:

              pon myisp
pon
will then use the options file
/etc/ppp/peers/myisp
. You can
       pass additional
options
after the ISP name, too. pon
can be used
       to run multiple, simultaneous PPP connections."
1055,3,pon,"pon
can be used
       to run multiple, simultaneous PPP connections. poff
poff
closes a PPP connection. If more than one PPP connection
       exists, the one named in the argument to
poff
will be killed, e.g."
1055,4,pon,"If more than one PPP connection
       exists, the one named in the argument to
poff
will be killed, e.g. poff myprovider2

       will terminate the connection to myprovider2, and leave the PPP
       connections to e.g. ""myprovider1"" or ""myprovider3"" up and running."
1055,5,pon,"""myprovider1"" or ""myprovider3"" up and running. poff
takes the following command line options:
-r
causes the connection to be redialed after it is
                     dropped. -d
toggles the state of pppd's debug option."
1055,6,pon,"-d
toggles the state of pppd's debug option. -c
causes
pppd(8)
to renegotiate compression. -a
stops all running ppp connections."
1055,7,pon,"-a
stops all running ppp connections. If the argument
isp-name
is given it will be ignored. -h
displays help information."
1055,8,pon,"-h
displays help information. -v
prints the version and exits. If no argument is given,
poff
will stop or signal pppd if
              and only if there is exactly one running."
1055,9,pon,"If no argument is given,
poff
will stop or signal pppd if
              and only if there is exactly one running. If more than one
              connection is active, it will exit with an error code of 1. plog
plog
shows you the last few lines of
/var/log/ppp.log
."
1055,10,pon,"plog
plog
shows you the last few lines of
/var/log/ppp.log
. If that
       file doesn't exist, it shows you the last few lines of your
/var/log/syslog
file, but excluding the lines not generated by
       pppd. This script makes use of the
tail(1)
command, so arguments
       that can be passed to
tail(1)
can also be passed to
plog
."
1055,11,pon,"This script makes use of the
tail(1)
command, so arguments
       that can be passed to
tail(1)
can also be passed to
plog
. Note: the
plog
script can only be used by root or another system
       administrator in group ""adm"", due to security reasons. Also, to
       have all pppd-generated information in one logfile, that plog can
       show, you need the following line in your
/etc/syslog.conf
file:

       local2.*       -/var/log/ppp.log"
1056,0,pmafm,"A collection of one or more Performance Co-Pilot (PCP) archives
       may be combined with a control file to produce a PCP archive
       folio. Archive folios are created using either
mkaf(1)
or the
       interactive ``record mode'' services of PCP clients like
pmchart(1)
. pmafm
provides a number of services that may be used to process
       folios."
1056,1,pmafm,"pmafm
provides a number of services that may be used to process
       folios. In particular, it provides support for execution of PCP
       tools using one or more of the component archives within an
       archive folio. The target folio is identified by the folio control file
folioname
."
1056,2,pmafm,"The target folio is identified by the folio control file
folioname
. The syntax for a folio control file is described in
mkaf(1)
. If present, the command and arguments following
folioname
are
       interpreted and executed as a single command, otherwise commands
       are read from standard input."
1056,3,pmafm,"If present, the command and arguments following
folioname
are
       interpreted and executed as a single command, otherwise commands
       are read from standard input. The following commands are supported. archives
Subsequent commands apply to all archives in the folio."
1056,4,pmafm,"archives
Subsequent commands apply to all archives in the folio. archives
N
[,...]
              Archives within a folio are numbered 1, 2, etc. Subsequent
              commands are restricted to apply only to the designated
              archives."
1056,5,pmafm,"Subsequent
              commands are restricted to apply only to the designated
              archives. archives
name
[,...]
              Archives within a folio have unique names. Subsequent
              commands are restricted to apply only to the designated
              archives."
1056,6,pmafm,"Subsequent
              commands are restricted to apply only to the designated
              archives. check
Validate the presence and format of each file in the folio
              and the component archives. help
A brief reminder of the command syntax."
1056,7,pmafm,"help
A brief reminder of the command syntax. ? is a synonym
              for
help
."
1056,8,pmafm,"is a synonym
              for
help
. hosts
Subsequent commands apply to all archives in the folio. hosts
hostname
[,...]
              Subsequent commands are restricted to apply only to those
              archives that match the designated hostnames."
1056,9,pmafm,"hosts
hostname
[,...]
              Subsequent commands are restricted to apply only to those
              archives that match the designated hostnames. list
[
verbose
]
              Display the contents of the folio. By default the control
              header and the ordinal number, hostname and archive base
              name for each archive in the folio."
1056,10,pmafm,"By default the control
              header and the ordinal number, hostname and archive base
              name for each archive in the folio. The
verbose
option
              causes
pmafm
to dump the label record from each archive
              using
pmlogdump -l
. The first named archive in the folio is assumed to be
              associated with the default host for any tool that tries to
              replay multiple archives from the folio."
1056,11,pmafm,"The first named archive in the folio is assumed to be
              associated with the default host for any tool that tries to
              replay multiple archives from the folio. quit
Exit
pmafm
. remove
Echo on standard output the
sh
(1) commands required to
              remove all of the physical files associated with this
              archive folio."
1056,12,pmafm,"remove
Echo on standard output the
sh
(1) commands required to
              remove all of the physical files associated with this
              archive folio. repeat
tool
[
arg
...]
              Execute the known PCP
tool
once per selected archive. For
              example, the command
                   repeat pmval -t60 kernel.all.load
              would run
pmval(1)
once per archive, with an appropriate
-a
argument."
1056,13,pmafm,"For
              example, the command
                   repeat pmval -t60 kernel.all.load
              would run
pmval(1)
once per archive, with an appropriate
-a
argument. replay
Some archive folios are created by tools (e.g. pmchart(1)
)
              that provide sufficient information to allow all of the
              information in all of the archives of a folio to be
              replayed."
1056,14,pmafm,"pmchart(1)
)
              that provide sufficient information to allow all of the
              information in all of the archives of a folio to be
              replayed. [
run
]
tool
[
arg
...]
              Execute the known PCP
tool
on the selected archives. Some
              PCP tools are able to process multiple concurrent archives,
              and in this case the tool is run once with the list of all
              selected archives passed via a
-a
argument."
1056,15,pmafm,"Some
              PCP tools are able to process multiple concurrent archives,
              and in this case the tool is run once with the list of all
              selected archives passed via a
-a
argument. Otherwise,
              this command is synonymous with
repeat
. selections
Display those archives that would be selected for
              processing with a
repeat
,
replay
or
run
command."
1056,16,pmafm,"selections
Display those archives that would be selected for
              processing with a
repeat
,
replay
or
run
command. The restrictions via any
hosts
and
archives
commands are
       conjuncted. These restrictions serve to limit the specific
       archives processed in the subsequent
repeat
,
replay
,
run
and
selections
commands."
1056,17,pmafm,"These restrictions serve to limit the specific
       archives processed in the subsequent
repeat
,
replay
,
run
and
selections
commands. By default, all archives are selected. Keywords in commands may be abbreviated provided no ambiguity is
       introduced, e.g."
1056,18,pmafm,"By default, all archives are selected. Keywords in commands may be abbreviated provided no ambiguity is
       introduced, e.g. help
,
hel
and
he
are synonymous, but
h
is
       ambiguous."
1057,0,pmap,"The
pmap
command reports the memory map of a process or processes."
1058,0,pmclient,"pmclient
and
pmclient_fg
are simple clients that use the
       Performance Metrics Application Programming Interface (PMAPI) to
       report some high-level system performance metrics. The real value of these tools is as sample clients using the
PMAPI(3)
, interfaces and to this end the source code is included
       with the Performance Co-Pilot (PCP) package (see
PCPIntro(1)
), and
       is typically installed in
/usr/share/pcp/demos/pmclient
. The
pmclient_fg
program differs to
pmclient
in that it uses the
       fetchgroup API extension to the PMAPI, see
pmFetchGroup(3)
."
1058,1,pmclient,"The
pmclient_fg
program differs to
pmclient
in that it uses the
       fetchgroup API extension to the PMAPI, see
pmFetchGroup(3)
. Normally
pmclient
operates on the distributed Performance Metrics
       Name Space (PMNS), however if the
-n
option is specified an
       alternative local PMNS is loaded from the file
pmnsfile
. Unless directed to another host by the
-h
option, or to an archive
       by the
-a
option,
pmclient
will contact the Performance Metrics
       Collector Daemon (PMCD) on the local host to obtain the required
       information."
1058,2,pmclient,"Unless directed to another host by the
-h
option, or to an archive
       by the
-a
option,
pmclient
will contact the Performance Metrics
       Collector Daemon (PMCD) on the local host to obtain the required
       information. The argument to
-a
is a comma-separated list of
       names, each of which may be the base name of an archive or the
       name of a directory containing one or more archives. The
-a
and
-h
options are mutually exclusive."
1058,3,pmclient,"The
-a
and
-h
options are mutually exclusive. By default,
pmclient
reports the time of day according to the
       local timezone on the system where
pmclient
is run. The
-Z
option
       changes the timezone to
timezone
in the format of the environment
       variable
TZ
as described in
environ(7)
."
1058,4,pmclient,"The
-Z
option
       changes the timezone to
timezone
in the format of the environment
       variable
TZ
as described in
environ(7)
. The
-z
option changes the
       timezone to the local timezone at the host that is the source of
       the performance metrics, as identified via either the
-h
or
-a
options. The output from
pmclient
is directed to standard output, and lists

       +  Aggregate CPU utilization, in the range 0 to 1."
1058,5,pmclient,"The output from
pmclient
is directed to standard output, and lists

       +  Aggregate CPU utilization, in the range 0 to 1. +  If the system has more than 1 CPU, the ordinal number of the
          busiest CPU, in the range 0 to ... +  If the system has more than 1 CPU, the CPU utilization for the
          busiest CPU."
1058,6,pmclient,"+  If the system has more than 1 CPU, the CPU utilization for the
          busiest CPU. +  Real free memory in Mbytes. +  Aggregate physical disk I/O operations per second (IOPS)."
1058,7,pmclient,"+  Real free memory in Mbytes. +  Aggregate physical disk I/O operations per second (IOPS). +  Load average over the last 1 minute and over the last 15
          minutes."
1059,0,pmcd_wait,"pmcd_wait
waits for the Performance Metrics Collector Daemon
       (PMCD) to be running and accepting client connections. Unless directed to another host by the
-h
option,
pmcd_wait
will
       try to contact
pmcd(1)
on the local host. pmcd_wait
will timeout and abandon the attempt to connect to
pmcd
after 60 seconds."
1059,1,pmcd_wait,"pmcd_wait
will timeout and abandon the attempt to connect to
pmcd
after 60 seconds. This default timeout interval may be changed
       using the
-t
option, where the
interval
argument follows the
       syntax described in
PCPIntro(1)
and in the simplest form may be an
       unsigned integer (the implied units in this case are seconds). On successful connection to
pmcd
an exit status of zero is
       returned."
1059,2,pmcd_wait,"This default timeout interval may be changed
       using the
-t
option, where the
interval
argument follows the
       syntax described in
PCPIntro(1)
and in the simplest form may be an
       unsigned integer (the implied units in this case are seconds). On successful connection to
pmcd
an exit status of zero is
       returned. If an error or timeout occurs, then a non-zero exit status is
       returned as described below."
1060,0,pmclient,"pmclient
and
pmclient_fg
are simple clients that use the
       Performance Metrics Application Programming Interface (PMAPI) to
       report some high-level system performance metrics. The real value of these tools is as sample clients using the
PMAPI(3)
, interfaces and to this end the source code is included
       with the Performance Co-Pilot (PCP) package (see
PCPIntro(1)
), and
       is typically installed in
/usr/share/pcp/demos/pmclient
. The
pmclient_fg
program differs to
pmclient
in that it uses the
       fetchgroup API extension to the PMAPI, see
pmFetchGroup(3)
."
1060,1,pmclient,"The
pmclient_fg
program differs to
pmclient
in that it uses the
       fetchgroup API extension to the PMAPI, see
pmFetchGroup(3)
. Normally
pmclient
operates on the distributed Performance Metrics
       Name Space (PMNS), however if the
-n
option is specified an
       alternative local PMNS is loaded from the file
pmnsfile
. Unless directed to another host by the
-h
option, or to an archive
       by the
-a
option,
pmclient
will contact the Performance Metrics
       Collector Daemon (PMCD) on the local host to obtain the required
       information."
1060,2,pmclient,"Unless directed to another host by the
-h
option, or to an archive
       by the
-a
option,
pmclient
will contact the Performance Metrics
       Collector Daemon (PMCD) on the local host to obtain the required
       information. The argument to
-a
is a comma-separated list of
       names, each of which may be the base name of an archive or the
       name of a directory containing one or more archives. The
-a
and
-h
options are mutually exclusive."
1060,3,pmclient,"The
-a
and
-h
options are mutually exclusive. By default,
pmclient
reports the time of day according to the
       local timezone on the system where
pmclient
is run. The
-Z
option
       changes the timezone to
timezone
in the format of the environment
       variable
TZ
as described in
environ(7)
."
1060,4,pmclient,"The
-Z
option
       changes the timezone to
timezone
in the format of the environment
       variable
TZ
as described in
environ(7)
. The
-z
option changes the
       timezone to the local timezone at the host that is the source of
       the performance metrics, as identified via either the
-h
or
-a
options. The output from
pmclient
is directed to standard output, and lists

       +  Aggregate CPU utilization, in the range 0 to 1."
1060,5,pmclient,"The output from
pmclient
is directed to standard output, and lists

       +  Aggregate CPU utilization, in the range 0 to 1. +  If the system has more than 1 CPU, the ordinal number of the
          busiest CPU, in the range 0 to ... +  If the system has more than 1 CPU, the CPU utilization for the
          busiest CPU."
1060,6,pmclient,"+  If the system has more than 1 CPU, the CPU utilization for the
          busiest CPU. +  Real free memory in Mbytes. +  Aggregate physical disk I/O operations per second (IOPS)."
1060,7,pmclient,"+  Real free memory in Mbytes. +  Aggregate physical disk I/O operations per second (IOPS). +  Load average over the last 1 minute and over the last 15
          minutes."
1061,0,pmconfig,"pmconfig
displays the values for some or all configuration
       parameters of the local Performance Co-Pilot toolkit installation."
1062,0,pmcd,"pmcd
is the collector used by the Performance Co-Pilot (see
PCPIntro(1)
) to gather performance metrics on a system. As a
       rule, there must be an instance of
pmcd
running on a system for
       any performance metrics to be available to the PCP. pmcd
accepts connections from client applications running either
       on the same machine or remotely and provides them with metrics and
       other related information from the machine that
pmcd
is executing
       on."
1062,1,pmcd,"pmcd
accepts connections from client applications running either
       on the same machine or remotely and provides them with metrics and
       other related information from the machine that
pmcd
is executing
       on. pmcd
delegates most of this request servicing to a collection
       of Performance Metrics Domain Agents (or just agents), where each
       agent is responsible for a particular group of metrics, known as
       the domain of the agent. For instance, the
postgresql
agent is
       responsible for reporting information relating to the PostgreSQL
       database, such as the transaction and query counts, indexing and
       replication statistics, and so on."
1062,2,pmcd,"For instance, the
postgresql
agent is
       responsible for reporting information relating to the PostgreSQL
       database, such as the transaction and query counts, indexing and
       replication statistics, and so on. The agents may be processes started by
pmcd
, independent processes
       or Dynamic Shared Objects (DSOs, see
dlopen(3)
) attached to
pmcd
's
       address space. The configuration section below describes how
       connections to agents are specified."
1062,3,pmcd,"The configuration section below describes how
       connections to agents are specified. Note that if a PDU exchange with an agent times out, the agent has
       violated the requirement that it delivers metrics with little or
       no delay. This is deemed a protocol failure and the agent is
       disconnected from
pmcd
."
1062,4,pmcd,"This is deemed a protocol failure and the agent is
       disconnected from
pmcd
. Any subsequent requests for information
       from the agent will fail with a status indicating that there is no
       agent to provide it. It is possible to specify access control to
pmcd
based on users,
       groups and hosts."
1062,5,pmcd,"Any subsequent requests for information
       from the agent will fail with a status indicating that there is no
       agent to provide it. It is possible to specify access control to
pmcd
based on users,
       groups and hosts. This allows one to prevent users, groups of
       users, and certain hosts from accessing the metrics provided by
pmcd
and is described in more detail in the access control section
       below."
1063,0,pmchart,"pmchart
is a graphical utility that plots performance metrics
       values available through the facilities of the Performance Co-
       Pilot (PCP). Multiple charts can be displayed simultaneously,
       either aligned on the unified time axis (X-axis), and through the
       use of multiple interface Tabs. Metric values can be sourced from one or more live hosts
       (simultaneously)."
1063,1,pmchart,"Metric values can be sourced from one or more live hosts
       (simultaneously). Alternatively, one or more sets of PCP archives
       can be used as a source of historical data. See
PCPIntro(1)
for
       an in-depth discussion of the capabilities of the PCP framework,
       many of which are used by
pmchart."
1063,2,pmchart,"See
PCPIntro(1)
for
       an in-depth discussion of the capabilities of the PCP framework,
       many of which are used by
pmchart. Many aspects of the behaviour of
pmchart
can be customised through
       the interface. In particular, the use of ""views"" (refer to the
       section describing VIEWS later in this document) allows predefined
       sets of metrics and charting parameters like colors, scaling,
       titles, legends, and so on to be stored for later use, or use with
       different hosts and sets of archives."
1063,3,pmchart,"In particular, the use of ""views"" (refer to the
       section describing VIEWS later in this document) allows predefined
       sets of metrics and charting parameters like colors, scaling,
       titles, legends, and so on to be stored for later use, or use with
       different hosts and sets of archives. In addition, the
       Preferences dialog allows customisations to the rest of the
pmchart
user interface to be saved and restored between different
       invocations of the tool. This allows the default background
       color, highlight color, contents and location of the toolbar, and
       many other aspects to be configured."
1063,4,pmchart,"In addition, the
       Preferences dialog allows customisations to the rest of the
pmchart
user interface to be saved and restored between different
       invocations of the tool. This allows the default background
       color, highlight color, contents and location of the toolbar, and
       many other aspects to be configured. pmchart
makes extensive use of the
pmtime(1)
utility for time
       control, refer to the
pmtime
manual page for further details of
       its operation."
1064,0,pmquery,"pmquery
provides a command-line-option compatible implementation
       of the
xconfirm
and
xmessage
tools, using a look-and-feel that is
       consistent with
pmchart
. Several extensions to the functionality
       of the original tools have been made, in order to improve their
       specific utility for
pmchart
, but wherever possible the original
       semantics remain. pmconfirm
displays a line of text for each
-t
option specified (or
       a file when the
-file
option is used), and a button for each
-b
option specified."
1064,1,pmquery,"pmconfirm
displays a line of text for each
-t
option specified (or
       a file when the
-file
option is used), and a button for each
-b
option specified. When one of the buttons is pressed, the label
       of that button is written to
pmquery's
standard output. This
       provides a means of communication/feedback from within shell
       scripts and a means to display useful information to a user from
       an application."
1064,2,pmquery,"This
       provides a means of communication/feedback from within shell
       scripts and a means to display useful information to a user from
       an application. pmmessage
displays a window containing a message from the command
       line, a file, or standard input. It additionally allows buttons
       to be associated with an exit status, and only optionally will
       write the label of the button to standard output."
1064,3,pmquery,"It additionally allows buttons
       to be associated with an exit status, and only optionally will
       write the label of the button to standard output. pmquery
extends the above tools to additionally support limited
       user input, as free form text. In this
-input
mode, any text
       entered will be output when the default button is pressed."
1064,4,pmquery,"In this
-input
mode, any text
       entered will be output when the default button is pressed. A
       default text can be entered using the same mechanisms as the other
       tools. Command line options are available to specify font style, frame
       style, modality and one of several different icons to be presented
       for tailored visual feedback to the user."
1065,0,pmcpp,"pmcpp
provides a very simple pre-processor originally designed for
       manipulating Performance Metric Name Space (PMNS) files for the
       Performance Co-Pilot (PCP), but later generalized to provide
       conditional blocks, include file processing, in-line shell command
       execution and macro substitution for arbitrary files. It is most
       commonly used internally to process the PMNS file(s) after
pmLoadNameSpace(3)
or
pmLoadASCIINameSpace(3)
is called and to
       pre-process the configuration files for
pmlogger(1)
. Input lines are read from
infile
(or standard input if
infile
is
       not specified), processed and written to
outfile
(standard output
       if
outfile
is not specified)."
1065,1,pmcpp,"Input lines are read from
infile
(or standard input if
infile
is
       not specified), processed and written to
outfile
(standard output
       if
outfile
is not specified). All C-style comments of the form /* ... */ are stripped from the
       input stream."
1065,2,pmcpp,"*/ are stripped from the
       input stream. There are no predefined macros for
pmcpp
although macros may be
       defined on the command line using the
-D
option, where
name
and
value
must follow the same rules as described below for the
#define
directive. pmcpp
accepts the following directives in the input stream (like
cpp(1)
):

       â¢
#include ""
filename
""
or
#include <
filename
>
In either case the directory search path for
filename
tries
filename
first, then the directory for the command line
infile
(if any), followed by any directories named in
-I
command line
          arguments, and finally the
$PCP_VAR_DIR/pmns
directory (the
          latter is for backwards compatibility with earlier versions of
pmcpp
and the implied used from
pmLoadASCIINameSpace(3)
)."
1065,3,pmcpp,"pmcpp
accepts the following directives in the input stream (like
cpp(1)
):

       â¢
#include ""
filename
""
or
#include <
filename
>
In either case the directory search path for
filename
tries
filename
first, then the directory for the command line
infile
(if any), followed by any directories named in
-I
command line
          arguments, and finally the
$PCP_VAR_DIR/pmns
directory (the
          latter is for backwards compatibility with earlier versions of
pmcpp
and the implied used from
pmLoadASCIINameSpace(3)
). #include
directives may be nested, up to a maximum depth of 5. â¢
#shell ""
command
""
or
#shell '
command
'
The shell
command
will be executed and the standard output is
          inserted into the stream of data to be processed by
pmcpp
."
1065,4,pmcpp,"â¢
#shell ""
command
""
or
#shell '
command
'
The shell
command
will be executed and the standard output is
          inserted into the stream of data to be processed by
pmcpp
. Functionally this is similar to a
#include
directive, except
          input lines are read from a
command
rather than a file. The
#shell
directive is most useful for including or excluding
#define
or
#undef
directives based on run-time logic in the
command
."
1065,5,pmcpp,"The
#shell
directive is most useful for including or excluding
#define
or
#undef
directives based on run-time logic in the
command
. â¢
#define
name value
or
#define
name
""
value
""
or
#define
name
'
value
'
Defines a value for the macro
name
which must be a valid C-
          style name, so leading alphabetic or underscore followed by
          zero or more alphanumerics or underscores. value
is optional
          (and defaults to an empty string)."
1065,6,pmcpp,"value
is optional
          (and defaults to an empty string). There is no character
          escape mechanism, but either single quotes or double quotes may
          be used to define a
value
with special characters or embedded
          horizontal white space (no newlines). â¢
#undef
name
Removes the macro definition, if any, for
name
."
1065,7,pmcpp,"â¢
#undef
name
Removes the macro definition, if any, for
name
. â¢
#ifdef
name
... #endif
or
#ifndef
name
..."
1065,8,pmcpp,"#endif
or
#ifndef
name
... #endif
The enclosing lines will be stripped or included, depending if
          the macro
name
is defined or not. â¢
#else
Within a
#ifdef
or
#ifndef
block,
#else
may be used to delimit
          lines to be included if the preceding ``if'' condition is
          false."
1065,9,pmcpp,"â¢
#else
Within a
#ifdef
or
#ifndef
block,
#else
may be used to delimit
          lines to be included if the preceding ``if'' condition is
          false. Macro substitution is achieved by breaking the input stream into
       words separated by white space or characters that are not valid in
       a macro name, i.e. not alphanumeric and not underscore."
1065,10,pmcpp,"not alphanumeric and not underscore. Each word
       is checked and if it matches a macro name, the word is replaced by
       the macro value, otherwise the word is unchanged. There is generally one output line for each input line, although
       the line may be empty if the text has been stripped due to the
       handling of comments or conditional directives."
1065,11,pmcpp,"Each word
       is checked and if it matches a macro name, the word is replaced by
       the macro value, otherwise the word is unchanged. There is generally one output line for each input line, although
       the line may be empty if the text has been stripped due to the
       handling of comments or conditional directives. When there is a
       change in the input stream, an additional output line is generated
       of the form:

                 # lineno ""filename""

       to indicate the
following
line of output corresponds to line
       number
lineno
of the input file
filename
."
1066,0,pmdaactivemq,"pmdaactivemq
is a Performance Metrics Domain Agent (PMDA) which
       exports performance metrics from ActiveMQ."
1067,0,pmdakernel,"Each supported platform has a kernel Performance Metrics Domain
       Agent (PMDA) which extracts performance metrics from the kernel of
       that platfrom. A variety of platform-specific metrics are
       available, with an equally varied set of access mechanisms -
       typically this involves special system calls, or reading from
       files in kernel virtual filesystems such as the Linux
sysfs
and
procfs
filesystems. The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible."
1067,1,pmdakernel,"The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible. In all installations the default kernel PMDA will be
       installed as a shared library and thus executes directly within
       the
pmcd(1)
process. This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required)."
1067,2,pmdakernel,"This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required). Unlike many other PMDAs, the kernel PMDA exports a number of
       metric namespace subtrees, such as kernel, network, swap, mem,
       ipc, filesys, nfs, disk and hinv (hardware inventory). Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA."
1067,3,pmdakernel,"Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA. This
       is to aid profiling and debugging activities, with
dbpmda(1)
for
       example. In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account."
1067,4,pmdakernel,"In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account. Only enable this option if you understand the risks involved,
            and are sure that all remote accesses will be from benevolent
            users. If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to."
1067,5,pmdakernel,"If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to. Refer to CVE-2012-3419 for additional
            details. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1067,6,pmdakernel,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1067,7,pmdakernel,"-l
Location of the log file. By default, a log file named
[platform].log
is written in the current directory of
pmcd(1)
when
pmda[platform]
is started, i.e. $PCP_LOG_DIR/pmcd
."
1067,8,pmdakernel,"$PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1067,9,pmdakernel,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            either the privileged ""root"" account on some platforms
            (Linux, for example) or the unprivileged ""pcp"" account
            (wherever possible)."
1068,0,pmdaamdgpu,"pmdaamdgpu
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics describing the metrics available on
       AMD GPU cards via the DRM library. The
amdgpu
PMDA exports metrics that measure GPU activity, memory
       utilization, temperature, etc on GCN 1.2+ AMD GPUs. A brief description of the
pmdaamdgpu
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1068,1,pmdaamdgpu,"A brief description of the
pmdaamdgpu
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1068,2,pmdaamdgpu,"-l
Location of the log file. By default, a log file named
amdgpu.log
is written in the current directory of
pmcd(1)
when
pmdaamdgpu
is started, i.e. $PCP_LOG_DIR/pmcd
."
1068,3,pmdaamdgpu,"$PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -t
Enables and sets a sampling
interval
for automatic refreshing
            of metric values."
1068,4,pmdaamdgpu,"-t
Enables and sets a sampling
interval
for automatic refreshing
            of metric values. The functionality is disabled by default,
            however this option allows a time interval to be specified on
            which all values are sampled - this has the effect of
            constantly updating the accumulating metrics, with the goal
            of assisting client tools such as
pcp-atop(1)
and
pmlogger(1)
to observe sub-sample time changes in GPU and process state. Typically these tools have longer sampling intervals, and can
            thus 'miss' activity happening during their sampling
            interval."
1069,0,pmdabash,"pmdabash
is an experimental Performance Metrics Domain Agent
       (PMDA) which exports ""xtrace"" events from a traced
bash(1)
process. This includes the command execution information that
       would usually be sent to standard error with the
set -x
option to
       the shell. Event metrics are exported showing each command executed, the
       function name and line number in the script, and a timestamp."
1069,1,pmdabash,"Event metrics are exported showing each command executed, the
       function name and line number in the script, and a timestamp. Additionally, the process identifier for the shell and its parent
       process are exported. This requires
bash
version 4 or later."
1069,2,pmdabash,"This requires
bash
version 4 or later. A brief description of the
pmdabash
command line options follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1069,3,pmdabash,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
bash.log
is written in the current directory of
pmcd(1)
when
pmdabash
is started, i.e."
1069,4,pmdabash,"By default, a log file named
bash.log
is written in the current directory of
pmcd(1)
when
pmdabash
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log
            file cannot be created or is not writable, output is written
            to the standard error instead."
1069,5,pmdabash,"If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -s
Amount of time (in seconds) between subsequent evaluations of
            the shell trace file descriptor(s). The default is 2
            seconds."
1069,6,pmdabash,"The default is 2
            seconds. -m
Maximum amount of memory to be allowed for each event queue
            (one per traced process). The default is 2 megabytes."
1069,7,pmdabash,"The default is 2 megabytes. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1070,0,pmdaapache,"pmdaapache
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics describing the state of an Apache web
       server. The
apache
PMDA exports metrics that measure the request rate,
       cumulative request sizes, uptime and various connection states for
       active clients. This information is obtained by performing a HTTP request to the
       server status URL, which must be enabled in the
httpd.conf
configuration file."
1070,1,pmdaapache,"This information is obtained by performing a HTTP request to the
       server status URL, which must be enabled in the
httpd.conf
configuration file. ExtendedStatus on
            <Location /server-status>
            SetHandler server-status
            Order deny,allow
            Deny from all
            Allow from localhost
            </Location>

       A brief description of the
pmdaapache
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1070,2,pmdaapache,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
apache.log
is written in the current directory of
pmcd(1)
when
pmdaapache
is started, i.e."
1070,3,pmdaapache,"By default, a log file named
apache.log
is written in the current directory of
pmcd(1)
when
pmdaapache
is started, i.e. $PCP_LOG_DIR/pmcd . If the
            log file cannot be created or is not writable, output is
            written to the standard error instead."
1070,4,pmdaapache,"If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -S
Query the Apache status information from the named
server
rather than the local host. -P
Query the Apache status information from the given
port
rather than the default (80)."
1070,5,pmdaapache,"-P
Query the Apache status information from the given
port
rather than the default (80). -L
Specify an alternative
location
for finding the server-status
            page. -U
User account under which to run the agent."
1070,6,pmdaapache,"-L
Specify an alternative
location
for finding the server-status
            page. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1071,0,pmdabcc,"pmdabcc
is a Performance Co-Pilot (PCP) Performance Metrics Domain
       Agent (PMDA) which extracts live performance data from extended
       BPF (Berkeley Packet Filter) in-kernel programs by using BCC (BPF
       Compiler Collection) Python frontend. pmdabcc
loads and acts as a bridge for any number of configured,
       separate PCP BCC PMDA Python modules running BPF programs. Existing BCC Python tools and programs should be possible to be
       utilized with PCP BCC PMDA modules with reasonable effort."
1071,1,pmdabcc,"pmdabcc
loads and acts as a bridge for any number of configured,
       separate PCP BCC PMDA Python modules running BPF programs. Existing BCC Python tools and programs should be possible to be
       utilized with PCP BCC PMDA modules with reasonable effort. See the BPF and BCC documentation for detailed description of
       both."
1072,0,pmdabind2,"This PMDA extracts performance data from BIND (Berkeley Internet
       Name Domain).  It enables collection of most of the statistics
       metrics from the Bind server version 9 or later, which includes:

       â¢ overall memory statistics

       â¢ overall per-query statistics (general queries, EDNS/truncated
         responses, Update/Notify/AXFR/IXFR messages)

       â¢ overall error statistics (Rejected, SERVFAIL, Update/XFR
         failures ...)

       â¢ overall statistics per transport protocol, EDNS and per version
         of IP protocol

       â¢ resolver statistics (successes, errors, round-trip times in
         several ranges)

       â¢ detailed per-socket statistics with respect to the transport
         protocol and IP version including errors

       â¢ detailed per-file-descriptor statistics including errors

       The PMDA performs per-second collection of the whole data set (148
       metrics on the test environment) with modest requirements (2% CPU
       usage on Intel i7-4700MQ @2.4 GHz, cca 30 MB RAM).

       If more than 1 requests/sec is performed, the memoized values are
       used so that the statistics interface of the Bind server does not
       get overloaded."
1073,0,pmdabonding,"pmdabonding
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values from bonded network interfaces in the Linux
       kernel."
1074,0,pmdabpftrace,"pmdabpftrace
is a Performance Co-Pilot (PCP) Performance Metrics
       Domain Agent (PMDA) which exports metrics from
bpftrace
(8)
       scripts."
1075,0,pmdabpf,"pmdabpf
is a Performance Co-Pilot (PCP) Performance Metrics Domain
       Agent (PMDA) which extracts live performance data from eBPF
       programs utilizing BPF CO-RE (libbpf and BTF). pmdabpf
loads and acts as a bridge for any number of configured,
       separate bpf PMDA modules. Existing libbpf tools should be
       possible to be utilized with the bpf PMDA modules with reasonable
       effort."
1075,1,pmdabpf,"pmdabpf
loads and acts as a bridge for any number of configured,
       separate bpf PMDA modules. Existing libbpf tools should be
       possible to be utilized with the bpf PMDA modules with reasonable
       effort. See the eBPF, libbpf and BPF CO-RE documentation for detailed
       descriptions."
1076,0,pmdacifs,"pmdacifs
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values about mounted CIFS shares from the
       /proc/fs/cifs directory. This PMDA requires at least the CIFS
       kernel module to be loaded to return some metric values and at
       least one mounted CIFS share in order to provide data for all
       metrics."
1077,0,pmdacisco,"pmdacisco
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics from one or more Cisco routers. A brief description of the
pmdacisco
command line options follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1077,1,pmdacisco,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
cisco.log
is written in the current directory of
pmcd(1)
when
pmdacisco
is started, i.e."
1077,2,pmdacisco,"By default, a log file named
cisco.log
is written in the current directory of
pmcd(1)
when
pmdacisco
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log
            file cannot be created or is not writable, output is written
            to the standard error instead."
1077,3,pmdacisco,"If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -P
By default, it is assumed that no user-level password is
            required to access the Cisco's telnet port. If user-level
            passwords have been enabled on the Ciscos, then those
            passwords must be specified to
pmdacisco
."
1077,4,pmdacisco,"If user-level
            passwords have been enabled on the Ciscos, then those
            passwords must be specified to
pmdacisco
. If specified with
            the
-P
option,
password
will be used as the default user-
            level password for all Ciscos. See also the INTERFACE
            IDENTIFICATION section below."
1077,5,pmdacisco,"See also the INTERFACE
            IDENTIFICATION section below. -r   pmdacisco
will refresh the current values for all performance
            metrics by contacting each Cisco router once every
refresh
seconds. The default
refresh
is 120 seconds."
1077,6,pmdacisco,"The default
refresh
is 120 seconds. -s
The Cisco command prompt ends with the string
prompt
. The
            default value is ``>''."
1077,7,pmdacisco,"The
            default value is ``>''. The only way
pmdacisco
can
            synchronize the sending of commands and the parsing of output
            is by recognizing
prompt
as a unique string that comes at the
            end of all output, i.e. as the command prompt when waiting
            for the next command."
1077,8,pmdacisco,"as the command prompt when waiting
            for the next command. -U
By default, it is assumed that no username login is required
            to access the Cisco's telnet port. If username login has
            been enabled on the Ciscos, then the corresponding usernames
            must be specified to
pmdacisco
."
1077,9,pmdacisco,"If username login has
            been enabled on the Ciscos, then the corresponding usernames
            must be specified to
pmdacisco
. If specified with the
-U
option,
username
will be used as the default username login
            for all Ciscos. See also the INTERFACE IDENTIFICATION
            section below."
1077,10,pmdacisco,"See also the INTERFACE IDENTIFICATION
            section below. -M
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1077,11,pmdacisco,"The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default. -x
Connect to the Cisco via TCP port number
port
rather than the
            default 23 for a telnet connection. For each interface, once the telnet connection is established,
pmdacisco
is willing to wait up to 5 seconds for the Cisco to
       provide a new snapshot of the requested information."
1077,12,pmdacisco,"For each interface, once the telnet connection is established,
pmdacisco
is willing to wait up to 5 seconds for the Cisco to
       provide a new snapshot of the requested information. If this does
       not happen, the telnet connection is broken and no values are
       returned. This prevents
pmdacisco
tying up the Cisco's telnet
       ports waiting indefinitely when the response from the router is
       not what is expected, e.g."
1077,13,pmdacisco,"If this does
       not happen, the telnet connection is broken and no values are
       returned. This prevents
pmdacisco
tying up the Cisco's telnet
       ports waiting indefinitely when the response from the router is
       not what is expected, e.g. if the format of the ``show int''
       output changes, or the command is in error because an interface is
       no longer configured on the router."
1078,0,pmdakernel,"Each supported platform has a kernel Performance Metrics Domain
       Agent (PMDA) which extracts performance metrics from the kernel of
       that platfrom. A variety of platform-specific metrics are
       available, with an equally varied set of access mechanisms -
       typically this involves special system calls, or reading from
       files in kernel virtual filesystems such as the Linux
sysfs
and
procfs
filesystems. The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible."
1078,1,pmdakernel,"The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible. In all installations the default kernel PMDA will be
       installed as a shared library and thus executes directly within
       the
pmcd(1)
process. This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required)."
1078,2,pmdakernel,"This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required). Unlike many other PMDAs, the kernel PMDA exports a number of
       metric namespace subtrees, such as kernel, network, swap, mem,
       ipc, filesys, nfs, disk and hinv (hardware inventory). Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA."
1078,3,pmdakernel,"Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA. This
       is to aid profiling and debugging activities, with
dbpmda(1)
for
       example. In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account."
1078,4,pmdakernel,"In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account. Only enable this option if you understand the risks involved,
            and are sure that all remote accesses will be from benevolent
            users. If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to."
1078,5,pmdakernel,"If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to. Refer to CVE-2012-3419 for additional
            details. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1078,6,pmdakernel,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1078,7,pmdakernel,"-l
Location of the log file. By default, a log file named
[platform].log
is written in the current directory of
pmcd(1)
when
pmda[platform]
is started, i.e. $PCP_LOG_DIR/pmcd
."
1078,8,pmdakernel,"$PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1078,9,pmdakernel,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            either the privileged ""root"" account on some platforms
            (Linux, for example) or the unprivileged ""pcp"" account
            (wherever possible)."
1079,0,pmdadm,"pmdadm
is a Performance Metrics Domain Agent (PMDA) which exports
       metric values for Device Mapper on the local system. This PMDA collects its data through the
dmsetup(8)
utility and the
       dmstats API and requires that the program is installed in order to
       function. In addition, at least one statistics region must be
       created using the
dmstats(8)
utility in order to get basic counter
       values."
1079,1,pmdadm,"In addition, at least one statistics region must be
       created using the
dmstats(8)
utility in order to get basic counter
       values. See below for examples. Note that device-mapper statistics collection is not enabled by
       default and is not persistent across reboots (unless a system
       administrator has configured something to run in
rc.local
or
       equivalent)."
1079,2,pmdadm,"Note that device-mapper statistics collection is not enabled by
       default and is not persistent across reboots (unless a system
       administrator has configured something to run in
rc.local
or
       equivalent). This is because there are overheads associated with
       statistics collection. In addition, the
pmdadm
PMDA does not
       automatically enable any statistics collection because it may not
       be the only consumer of the data."
1080,0,pmdadbping,"pmdadbping
is a database response time measurement PMDA.
pmdadbping
runs
dbprobe(1)
, and exports the performance
       measurements it makes available as PCP metrics.
dbprobe(1)
should be configured to use the type of DBI appropriate
       for the local database, which includes: RDBMS flavour,
       user/password, delay between ""ping"" requests, and the SQL
       statement to use."
1081,0,pmdadenki,"pmdadenki
is a Performance Metrics Domain Agent (PMDA) which
       extracts electricity related performance metrics. Currently, metrics from RAPL (on Intel cpus) and battery charge
       values are available, if supported by the hardware. -l
Location of the log file."
1081,1,pmdadenki,"-l
Location of the log file. By default, a log file named
denki.log
is written in the current directory of
pmcd(1)
when
pmdadenki
is started, i.e. $PCP_LOG_DIR/pmcd
."
1081,2,pmdadenki,"By default, a log file named
denki.log
is written in the current directory of
pmcd(1)
when
pmdadenki
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log file
       cannot be created or is not writable, output is written to the
       standard error instead."
1082,0,pmdadocker,"pmdadocker
is a docker Performance Metrics Domain Agent (PMDA)
       which exposes performance metrics as reported from the Docker
       Remote API. A brief description of the
pmdadocker
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1082,1,pmdadocker,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
docker.log
is written in the current directory of
pmcd(1)
when
pmdadocker
is started, i.e."
1082,2,pmdadocker,"By default, a log file named
docker.log
is written in the current directory of
pmcd(1)
when
pmdadocker
is started, i.e. $PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead."
1082,3,pmdadocker,"If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. Remote API metric requests are activated automatically and are
       fetched on a timer. This timer is represented as a by
pmdadocker
via the
docker.control.timing."
1082,4,pmdadocker,"This timer is represented as a by
pmdadocker
via the
docker.control.timing. By default,
pmdadocker
will be set
       to fetch on a 1 second interval. pmdadocker
will iterate over three different
docker
remote API
       calls:
/containers/$ID/json
Container metrics regarding the current state of the
              container."
1082,5,pmdadocker,"pmdadocker
will iterate over three different
docker
remote API
       calls:
/containers/$ID/json
Container metrics regarding the current state of the
              container. Such as PID, name or if the container is
              running. /version
Basic version metrics about the current docker daemon in
              use."
1082,6,pmdadocker,"Such as PID, name or if the container is
              running. /version
Basic version metrics about the current docker daemon in
              use. /containers/$ID/stats?stream=0
More in depth memory and cpu metrics of the container."
1083,0,pmdads389,"pmdads389
is a Performance Metrics Domain Agent (PMDA) which
       extracts live performance data from a running 389 Directory Server
       instance.

       See the Red Hat Directory Server Administration Guide for
       description for each metric."
1084,0,pmdafarm,"pmdafarm
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values for Device Mapper on the local system.

       This PMDA collects its data through the
smartctl
(8) utility and
       requires that the program is installed in order to function.

       Further details on smartctl and smartmontools can be found at
https://smartmontools.org
."
1085,0,pmdaelasticsearch,"pmdaelasticsearch
is a Performance Metrics Domain Agent (PMDA)
       which exports performance metrics from elasticsearch."
1086,0,pmdads389log,"pmdads389log
is a Performance Metrics Domain Agent (PMDA) which
       extracts statistics from 389 Directory Server access log using the
logconv.pl
(1) utility."
1087,0,pmdakernel,"Each supported platform has a kernel Performance Metrics Domain
       Agent (PMDA) which extracts performance metrics from the kernel of
       that platfrom. A variety of platform-specific metrics are
       available, with an equally varied set of access mechanisms -
       typically this involves special system calls, or reading from
       files in kernel virtual filesystems such as the Linux
sysfs
and
procfs
filesystems. The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible."
1087,1,pmdakernel,"The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible. In all installations the default kernel PMDA will be
       installed as a shared library and thus executes directly within
       the
pmcd(1)
process. This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required)."
1087,2,pmdakernel,"This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required). Unlike many other PMDAs, the kernel PMDA exports a number of
       metric namespace subtrees, such as kernel, network, swap, mem,
       ipc, filesys, nfs, disk and hinv (hardware inventory). Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA."
1087,3,pmdakernel,"Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA. This
       is to aid profiling and debugging activities, with
dbpmda(1)
for
       example. In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account."
1087,4,pmdakernel,"In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account. Only enable this option if you understand the risks involved,
            and are sure that all remote accesses will be from benevolent
            users. If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to."
1087,5,pmdakernel,"If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to. Refer to CVE-2012-3419 for additional
            details. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1087,6,pmdakernel,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1087,7,pmdakernel,"-l
Location of the log file. By default, a log file named
[platform].log
is written in the current directory of
pmcd(1)
when
pmda[platform]
is started, i.e. $PCP_LOG_DIR/pmcd
."
1087,8,pmdakernel,"$PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1087,9,pmdakernel,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            either the privileged ""root"" account on some platforms
            (Linux, for example) or the unprivileged ""pcp"" account
            (wherever possible)."
1088,0,pmdagfs2,"pmdagfs2
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values about mounted GFS2 filesystems from the
       debugfs filesystem. This PMDA requires debugfs along with at
       least one mounted GFS2 filesystem to be mounted in order to be
       able to provide metric data. This PMDA can be used with GFS2 filesystems which are both mounted
       as local filesystems and filesystems which are  mounted as shared
       storage within a clustered environment."
1088,1,pmdagfs2,"This PMDA can be used with GFS2 filesystems which are both mounted
       as local filesystems and filesystems which are  mounted as shared
       storage within a clustered environment. However there are some
       metrics which specifically require GFS2 to be setup in a clustered
       environment to be able to provide metric data. This is due to them
       expecting locking messages to be passed via the distributed lock
       manager (DLM) between nodes of a cluster in order to generate
       their output."
1088,2,pmdagfs2,"This is due to them
       expecting locking messages to be passed via the distributed lock
       manager (DLM) between nodes of a cluster in order to generate
       their output. These cluster-environment-only metrics can be distinguished by the
       inclusion of their corresponding control metrics so that they can
       be optionally enabled or disabled on systems where they are not
       desired to be monitored or not supported. pmstore(3)
can be used to assign values to these control metrics
       in order to enable (1) or disable (0) them."
1088,3,pmdagfs2,"These cluster-environment-only metrics can be distinguished by the
       inclusion of their corresponding control metrics so that they can
       be optionally enabled or disabled on systems where they are not
       desired to be monitored or not supported. pmstore(3)
can be used to assign values to these control metrics
       in order to enable (1) or disable (0) them. This mechanism is
       also useful on distributions that do not currently have full
       support for the GFS2 trace-points or provide older versions of the
       GFS2 driver."
1089,0,pmdahacluster,"pmdahacluster
is capable of collecting metric information to
       enable the monitoring of Pacemaker based HA Clusters through
       Performance Co-Pilot.

       The PMDA collects it's metric data from the following components
       that make up a Pacemaker based HA Cluster: Pacemaker, Corosync,
       SBD, DRBD.

       For more detailed information regarding the metrics available
       please see the included pmns and helpfile with the PMDA."
1090,0,pmdahaproxy,"pmdahaproxy
is a Performance Metrics Domain Agent (PMDA) which
       extracts live performance data from HAProxy statistics socket or
       URL.

       By default the HAProxy stats socket is used to retrieve the metric
       but if the optional URL option is set (see below), then the
       HAProxy URL is used instead.

       See the HAProxy documentation for detailed description of each
       metric."
1091,0,pmdagpfs,"pmdagpfs
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values from the
/usr/lpp/mmfs/bin/mmpmon
program to
       provide information on mounted gpfs filesystems."
1092,0,pmdaib,"pmdaib
is a Performance Metrics Domain Agent (PMDA) which exports
       information and performance metrics about local Infiniband HCAs
       and local or remote Infiniband GUIDs. A brief description of the
pmdaib
command line options follows:
-c
Location of the config file. By default, the config file is
            named
$PCP_PMDAS_DIR/infiniband/config."
1092,1,pmdaib,"By default, the config file is
            named
$PCP_PMDAS_DIR/infiniband/config. See
CONFIG FILE
for
            more information. -D
A debug values, as specified by
pmdbg(1)
-d
Specify an alternate performance metrics
domain
number."
1092,2,pmdaib,"-D
A debug values, as specified by
pmdbg(1)
-d
Specify an alternate performance metrics
domain
number. Almost never necessary. -l
Location of the log file."
1092,3,pmdaib,"-l
Location of the log file. By default, a log file named
ib.log
is written to
$PCP_LOG_DIR/pmcd
. If the log file
            cannot be created or is not writable, output is written to
            the standard error instead."
1092,4,pmdaib,"If the log file
            cannot be created or is not writable, output is written to
            the standard error instead. -w
Write out the default config file to
$PCP_PMDAS_DIR/infiniband
and exit immediately. The written
            config file will contain the local HCA ports."
1092,5,pmdaib,"The written
            config file will contain the local HCA ports. It will not
            overwrite an existing file. This argument should only be
            used to create the template config file and should never
            appear in
pmcd.conf."
1092,6,pmdaib,"It will not
            overwrite an existing file. This argument should only be
            used to create the template config file and should never
            appear in
pmcd.conf. See
CONFIG FILE
for more information on
            the file format and on monitoring remote GUIDs."
1093,0,pmdagluster,"pmdagluster
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values about mounted gluster filesystems using the
gluster
(8) command. This PMDA exports metrics about volumes and
       bricks both local and remote to the node where pmdagluster is
       running. The gluster filesystem supports fine-grained control over enabling
       statistics on individual volumes, so that the values are
       optionally enabled or disabled on systems where they are not
       desired to be monitored."
1093,1,pmdagluster,"The gluster filesystem supports fine-grained control over enabling
       statistics on individual volumes, so that the values are
       optionally enabled or disabled on systems where they are not
       desired to be monitored. The
pmstore(1)
command can be used to enable and disable profiling
       of volumes. Using the individual instances of the
       gluster.volume.profile metric, one can set their values (and
       associated profiling) either on (1) or off (0)."
1093,2,pmdagluster,"Using the individual instances of the
       gluster.volume.profile metric, one can set their values (and
       associated profiling) either on (1) or off (0). Additionally,
pminfo(1)
can report on the current status of profiling of each
       volume. # pminfo âf gluster.volume.profile

            gluster.volume.profile
                inst [0 or ""gv0""] value 0
                inst [1 or ""gv1""] value 1

            # pmstore âi ""gv0"" gluster.volume.profile 1
            gluster.volume.profile inst [0 or ""gv0""] old value=0 new value=1

       Further details on the gluster filesystem can be found at
http://www.gluster.org
."
1094,0,pmdakernel,"Each supported platform has a kernel Performance Metrics Domain
       Agent (PMDA) which extracts performance metrics from the kernel of
       that platfrom. A variety of platform-specific metrics are
       available, with an equally varied set of access mechanisms -
       typically this involves special system calls, or reading from
       files in kernel virtual filesystems such as the Linux
sysfs
and
procfs
filesystems. The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible."
1094,1,pmdakernel,"The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible. In all installations the default kernel PMDA will be
       installed as a shared library and thus executes directly within
       the
pmcd(1)
process. This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required)."
1094,2,pmdakernel,"This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required). Unlike many other PMDAs, the kernel PMDA exports a number of
       metric namespace subtrees, such as kernel, network, swap, mem,
       ipc, filesys, nfs, disk and hinv (hardware inventory). Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA."
1094,3,pmdakernel,"Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA. This
       is to aid profiling and debugging activities, with
dbpmda(1)
for
       example. In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account."
1094,4,pmdakernel,"In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account. Only enable this option if you understand the risks involved,
            and are sure that all remote accesses will be from benevolent
            users. If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to."
1094,5,pmdakernel,"If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to. Refer to CVE-2012-3419 for additional
            details. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1094,6,pmdakernel,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1094,7,pmdakernel,"-l
Location of the log file. By default, a log file named
[platform].log
is written in the current directory of
pmcd(1)
when
pmda[platform]
is started, i.e. $PCP_LOG_DIR/pmcd
."
1094,8,pmdakernel,"$PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1094,9,pmdakernel,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            either the privileged ""root"" account on some platforms
            (Linux, for example) or the unprivileged ""pcp"" account
            (wherever possible)."
1095,0,pmdajbd2,"pmdajbd2
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics from the Journal Block Device
       subsystem (version 2) in the Linux kernel. These metrics are
       exported by the kernel in procfs files, one file per block device. The JBD2 subsystem is used by several filesystems including ext3,
       ext4 and ocfs2."
1095,1,pmdajbd2,"The JBD2 subsystem is used by several filesystems including ext3,
       ext4 and ocfs2. The
jbd2
PMDA exports metrics that measure detailed journal
       transaction information, such as time spent waiting and locked,
       request rates, blocks used and so on. A brief description of the
pmdajbd2
command line options follows
       (these are only relevant when running the PMDA as a daemon, and
       not as a shared library):
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1095,2,pmdajbd2,"A brief description of the
pmdajbd2
command line options follows
       (these are only relevant when running the PMDA as a daemon, and
       not as a shared library):
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1095,3,pmdajbd2,"-l
Location of the log file. By default, when running as a
            daemon a log file named
jbd2.log
is written in the current
            directory of when
pmdajbd2
is started, i.e. $PCP_LOG_DIR/pmcd
."
1095,4,pmdajbd2,"$PCP_LOG_DIR/pmcd
. If the log file cannot be created or is
            not writable, output is written to the standard error
            instead. When running in shared library mode, and diagnostic
            information will be written into the
pmcd
log file, namely
$PCP_LOG_DIR/pmcd/pmcd.log
."
1095,5,pmdajbd2,"When running in shared library mode, and diagnostic
            information will be written into the
pmcd
log file, namely
$PCP_LOG_DIR/pmcd/pmcd.log
. -j
Allows an alternate path to the jbd2 statistics files to be
            specified. The default path is
/proc/fs/jbd2
."
1095,6,pmdajbd2,"The default path is
/proc/fs/jbd2
. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1096,0,pmdajson,"pmdajson
is a Performance Metrics Domain Agent (PMDA) which
       exports metrics from arbitrary sources generating JavaScript
       Object Notation (JSON) syntax. At least one pair of JSON inputs are required for
pmdajson
to
       provide metrics for PCP clients; one describing metric metadata
       and one containing metric values data. Metadata is read once from
       a file at PMDA startup while the data is read every time a request
       for metric values is made by a PCP client."
1096,1,pmdajson,"Metadata is read once from
       a file at PMDA startup while the data is read every time a request
       for metric values is made by a PCP client. The data is read
       either from a JSON file or an external command generating JSON
       output. More than one pair of JSON inputs can be used to support
       arbitrary number of metric sources in different configured
       directories."
1096,2,pmdajson,"The data is read
       either from a JSON file or an external command generating JSON
       output. More than one pair of JSON inputs can be used to support
       arbitrary number of metric sources in different configured
       directories. The overall JSON format description is at
http://www.json.org/
."
1097,0,pmdakvm,"pmdakvm
is a Performance Metrics Domain Agent (PMDA) which exports
       metric values from the Linux KVM (Kernel Virtual Machine)
       virtualization subsystem.

       Per-processor KVM trace metrics from the kernel events enumerated
       below
/sys/kernel/debug/tracing/events/kvm
can be configured
       statically using the
pmdakvm
configuration file,
/etc/pcp/kvm/kvm.conf
."
1098,0,pmdalibvirt,"pmdalibvirt
is a Performance Metrics Domain Agent (PMDA) which
       extracts live performance data from libvirt hypervisor and domains
       (VMs).

       See the libvirt documentation for detailed description of each
       metric."
1099,0,pmdakernel,"Each supported platform has a kernel Performance Metrics Domain
       Agent (PMDA) which extracts performance metrics from the kernel of
       that platfrom. A variety of platform-specific metrics are
       available, with an equally varied set of access mechanisms -
       typically this involves special system calls, or reading from
       files in kernel virtual filesystems such as the Linux
sysfs
and
procfs
filesystems. The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible."
1099,1,pmdakernel,"The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible. In all installations the default kernel PMDA will be
       installed as a shared library and thus executes directly within
       the
pmcd(1)
process. This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required)."
1099,2,pmdakernel,"This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required). Unlike many other PMDAs, the kernel PMDA exports a number of
       metric namespace subtrees, such as kernel, network, swap, mem,
       ipc, filesys, nfs, disk and hinv (hardware inventory). Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA."
1099,3,pmdakernel,"Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA. This
       is to aid profiling and debugging activities, with
dbpmda(1)
for
       example. In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account."
1099,4,pmdakernel,"In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account. Only enable this option if you understand the risks involved,
            and are sure that all remote accesses will be from benevolent
            users. If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to."
1099,5,pmdakernel,"If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to. Refer to CVE-2012-3419 for additional
            details. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1099,6,pmdakernel,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1099,7,pmdakernel,"-l
Location of the log file. By default, a log file named
[platform].log
is written in the current directory of
pmcd(1)
when
pmda[platform]
is started, i.e. $PCP_LOG_DIR/pmcd
."
1099,8,pmdakernel,"$PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1099,9,pmdakernel,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            either the privileged ""root"" account on some platforms
            (Linux, for example) or the unprivileged ""pcp"" account
            (wherever possible)."
1100,0,pmdalustre,"pmdalustre
is a Performance Metrics Domain Agent (PMDA) which
       reads and exports metric values from the statistics interfaces of
       a Lustre filesystem. pmdalustre
searches for statistics interfaces from several
       locations, which vary depending on the version of
Lustre
installed
       locally. Recent
Lustre
versions (v2.12 and later) export statistics from
       the kernel
debugfs
pseudo filesystem, in the directories
/sys/kernel/debug/lustre/llite
and
/sys/kernel/debug/lnet
."
1100,1,pmdalustre,"Recent
Lustre
versions (v2.12 and later) export statistics from
       the kernel
debugfs
pseudo filesystem, in the directories
/sys/kernel/debug/lustre/llite
and
/sys/kernel/debug/lnet
. If
       these interfaces are not found during startup,
pmdalustre
will
       automatically check if the statistics interfaces are available
       from the
procfs
pseudo filesystem below the
/proc/fs/lustre/llite
and
/proc/sys/lnet
directories. These are the default locations
       of the statistics for
Lustre
versions less than
v2.12
."
1100,2,pmdalustre,"These are the default locations
       of the statistics for
Lustre
versions less than
v2.12
. If neither of the above filesystem interfaces are detected, or if
       the user wants to override the default locations,
pmdalustre
also
       supports an optional configuration file named
$PCP_PMDAS_DIR/lustre/lustre.conf
. Note that
$PCP_PMDAS_DIR
is
       set to
/var/lib/pcp/pmdas
on most Linux based  systems."
1100,3,pmdalustre,"Note that
$PCP_PMDAS_DIR
is
       set to
/var/lib/pcp/pmdas
on most Linux based  systems. The
       configuration file supports
perl
(1) variable assignment syntax. An example configuration file suitable for
Lustre
v2.12 and later
       is:
$LLITE_PATH=""/sys/kernel/debug/lustre/llite/"";
$LNET_PATH=""/sys/kernel/debug/lustre/lnet/"";
See comments in the shipped
lustre.conf
file for further details."
1100,4,pmdalustre,"An example configuration file suitable for
Lustre
v2.12 and later
       is:
$LLITE_PATH=""/sys/kernel/debug/lustre/llite/"";
$LNET_PATH=""/sys/kernel/debug/lustre/lnet/"";
See comments in the shipped
lustre.conf
file for further details. By default, this file is installed with everything commented (and
       so it has no effect unless edited) because the built-in heuristics
       used by
pmdalustre
should suffice. Finally, overriding all of the above, the
LUSTRE_LLITE_PATH
and
LUSTRE_LNET_PATH
environment variables may be set (and exported)
       to specify the directory locations of the statistics interfaces to
       be used."
1100,5,pmdalustre,"Finally, overriding all of the above, the
LUSTRE_LLITE_PATH
and
LUSTRE_LNET_PATH
environment variables may be set (and exported)
       to specify the directory locations of the statistics interfaces to
       be used. This mechanism using environment variables is intended
       to be used for development and testing purposes only. The
pmdalustre
process runs as the root user because
debugfs
directories are not normally readable by unprivileged users."
1101,0,pmdalio,"pmdalio
is a Performance Metrics Domain Agent (PMDA) which exports
       metric values about the Linux I/O target subsystem, which provides
       for protocols like iSCSI, FCP, FCoE. These allow storage
       available on one host to be exported and consumed by other hosts
       using industry standard protocols. This PMDA exports summary metrics which are performance value
       aggregations and configuration per LIO target instance."
1101,1,pmdalio,"This PMDA exports summary metrics which are performance value
       aggregations and configuration per LIO target instance. Additionally, it provides per LUN performance metrics including
       IOPS, and READ and WRITE throughput. The LIO configuration is maintained within the kernel's
configfs
virtual filesystem."
1101,2,pmdalio,"Additionally, it provides per LUN performance metrics including
       IOPS, and READ and WRITE throughput. The LIO configuration is maintained within the kernel's
configfs
virtual filesystem. The
python-rtslib
module provides an
       interface to
configfs
, allowing tools like
pmdalio
to interact
       with the settings and metadata held in
configfs
."
1102,0,pmdalogger,"pmdalogger
is a configurable log file monitoring Performance
       Metrics Domain Agent (PMDA). It can be seen as analogous to the
-f
option to
tail(1)
and converts each new log line into a
       performance event. It was the first PMDA to make extensive use of
       event metrics, which can be consumed by client tools like
pmevent(1)
."
1102,1,pmdalogger,"It was the first PMDA to make extensive use of
       event metrics, which can be consumed by client tools like
pmevent(1)
. The
logger
PMDA exports both event-style metrics reflecting
       timestamped event records for text logged to a file (or set of
       files or output from a process), as well as the more orthodox
       sample-style metrics such as event counts and throughput size
       values. The PMDA is configured via a
configfile
which contains one line
       for each source of events (file or process)."
1102,2,pmdalogger,"The PMDA is configured via a
configfile
which contains one line
       for each source of events (file or process). This file is setup
       by the Install script described in the later section on
       ``INSTALLATION'' of the PMDA. A brief description of the
pmdalogger
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1102,3,pmdalogger,"A brief description of the
pmdalogger
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1102,4,pmdalogger,"-l
Location of the log file. By default, a log file named
logger.log
is written in the current directory of
pmcd(1)
when
pmdalogger
is started, i.e. $PCP_LOG_DIR/pmcd
."
1102,5,pmdalogger,"$PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -m
Limit the physical memory used by the PMDA to buffer event
            records to
maxsize
bytes."
1102,6,pmdalogger,"-m
Limit the physical memory used by the PMDA to buffer event
            records to
maxsize
bytes. As log events arrive at the PMDA,
            they must be buffered until individual client tools request
            the next batch since their previous batch of events. The
            default maximum is 2 megabytes."
1102,7,pmdalogger,"The
            default maximum is 2 megabytes. -s
Sets the polling interval for detecting newly arrived log
            lines. Mirrors the same option from the
tail(1)
command."
1102,8,pmdalogger,"Mirrors the same option from the
tail(1)
command. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1103,0,pmdalmsensors,"pmdalmsensors
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics describing the state of hardware
       using the lm-sensors software on compatible motherboards.

       The
lmsensors
PMDA exports metrics that measure fan speeds and
       core temperatures."
1104,0,pmdalustrecomm,"pmdalustrecomm
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics from the Linux procfs filesystem
       about the state of various aspects of the Lustre filesystem. The
lustrecomm
PMDA exports metrics that focus on distributed
       communication in the filesystem, including metrics related to
       timeouts, network drops, send/receive information and route
       lengths. However, it also covers the memory use of some of the
       Lustre filesystem components."
1104,1,pmdalustrecomm,"However, it also covers the memory use of some of the
       Lustre filesystem components. A brief description of the
pmdalustrecomm
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1104,2,pmdalustrecomm,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
lustrecomm.log
is written in the current directory of
pmcd(1)
when
pmdalustrecomm
is started, i.e."
1104,3,pmdalustrecomm,"By default, a log file named
lustrecomm.log
is written in the current directory of
pmcd(1)
when
pmdalustrecomm
is started, i.e. $PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead."
1104,4,pmdalustrecomm,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1105,0,pmdamemcache,"This PMDA extracts performance data from memcached, a distributed
       memory caching daemon commonly used to improve web serving
       performance.  A farm of memcached processes over multiple servers
       can be utilised by a single web application, increasing the total
       available object cache size, and decreasing the database load
       associated with smaller cache sizes.  This system is described in
       detail at
http://www.danga.com/memcached
."
1106,0,pmdamailq,"pmdamailq
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics describing the state of the e-mail
       queues managed by
sendmail
(1) and other mail transfer agents. The
mailq
PMDA exports metrics that measure the total number of
       entries in the mail queue, and the subtotals for entries that have
       been queued for various time periods. A brief description of the
pmdamailq
command line options follows:
-b
The
binlist
argument specifies a list of delay thresholds
            used to ``bin'' the entries in the queue into a a histogram
            based on how long the entry has been in the mail queue."
1106,1,pmdamailq,"A brief description of the
pmdamailq
command line options follows:
-b
The
binlist
argument specifies a list of delay thresholds
            used to ``bin'' the entries in the queue into a a histogram
            based on how long the entry has been in the mail queue. The
            default thresholds are: 1 hour, 4 hours, 8 hours, 1 day, 3
            days and 7 days. The entries in
binlist
are comma separated
            time intervals, using the syntax described in
PCPIntro(1)
for
            an update or reporting interval, e.g."
1106,2,pmdamailq,"The entries in
binlist
are comma separated
            time intervals, using the syntax described in
PCPIntro(1)
for
            an update or reporting interval, e.g. the default list could
            be specified using the value
1hr,4hrs,8hrs,1day,3days,7days
. Values in
binlist
are assumed to be in ascending order, and
            mail items in the queue less than the first threshold are
            binned into a special bin labeled ``recent''."
1106,3,pmdamailq,"Values in
binlist
are assumed to be in ascending order, and
            mail items in the queue less than the first threshold are
            binned into a special bin labeled ``recent''. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1106,4,pmdamailq,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
mailq.log
is written in the current directory of
pmcd(1)
when
pmdamailq
is started, i.e."
1106,5,pmdamailq,"By default, a log file named
mailq.log
is written in the current directory of
pmcd(1)
when
pmdamailq
is started, i.e. $PCP_LOG_DIR/pmcd . If the log
            file cannot be created or is not writable, output is written
            to the standard error instead."
1106,6,pmdamailq,"If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -r
Use an extended regular expression to match file names in the
            mail queue directory, rather than assuming all ""df"" prefixed
            files in the directory are mail files (the ""df"" prefix is the
sendmail
convention, but this convention is not followed by
            other mail daemons). The
regex
pattern specified should
            conform to the POSIX format described in
regex(3)
, and it
            describes file names that should be considered mail."
1106,7,pmdamailq,"The
regex
pattern specified should
            conform to the POSIX format described in
regex(3)
, and it
            describes file names that should be considered mail. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1106,8,pmdamailq,"The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default. The optional
queuedir
argument defines the directory in which
pmdamailq
expects to find the mail queue. The default is
/var/spool/mqueue
."
1107,0,pmdamic,"pmdamic
is a Performance Metrics Domain Agent (PMDA) which exports
       metric values about Intel MIC cards using the
libmicmgmt
(7) python
       bindings.

       This provides information on core, memory and power utilization"
1108,0,pmdammv,"pmdammv
is a Performance Metrics Domain Agent (PMDA) which exports
       application level performance metrics using memory mapped files. It offers an extremely low overhead instrumentation facility that
       is well-suited to long running, mission critical applications
       where it is desirable to have performance metrics and availability
       information permanently enabled. The
mmv
PMDA exports instrumentation that has been added to an
       application using the MMV APIs (refer to
mmv_stats_init(3)
and
mmv(5)
for further details)."
1108,1,pmdammv,"The
mmv
PMDA exports instrumentation that has been added to an
       application using the MMV APIs (refer to
mmv_stats_init(3)
and
mmv(5)
for further details). These APIs can be called from
       several languages, including C, C++, Perl, Python, Java (via the
       separate ``Parfait'' class library) and GoLang (via the separate
       ``Speed'' library). A brief description of the
pmdammv
command line options follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1108,2,pmdammv,"A brief description of the
pmdammv
command line options follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1108,3,pmdammv,"-l
Location of the log file. By default, a log file named
mmv.log
is written in the current directory of
pmcd(1)
when
pmdammv
is started, i.e. $PCP_LOG_DIR/pmcd
."
1108,4,pmdammv,"$PCP_LOG_DIR/pmcd
. If the log file
            cannot be created or is not writable, output is written to
            the standard error instead. -U
User account under which to run the agent."
1108,5,pmdammv,"If the log file
            cannot be created or is not writable, output is written to
            the standard error instead. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1109,0,pmdamongodb,"pmdamongodb
is a Performance Co-Pilot (PCP) Performance Metrics
       Domain Agent (PMDA) which extracts live performance data from a
       running MongoDB database server."
1110,0,pmdamssql,"pmdamssql
is a Performance Co-Pilot (PCP) Performance Metrics
       Domain Agent (PMDA) which extracts live performance data from a
       running Microsoft SQL Server database server."
1111,0,pmdakernel,"Each supported platform has a kernel Performance Metrics Domain
       Agent (PMDA) which extracts performance metrics from the kernel of
       that platfrom. A variety of platform-specific metrics are
       available, with an equally varied set of access mechanisms -
       typically this involves special system calls, or reading from
       files in kernel virtual filesystems such as the Linux
sysfs
and
procfs
filesystems. The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible."
1111,1,pmdakernel,"The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible. In all installations the default kernel PMDA will be
       installed as a shared library and thus executes directly within
       the
pmcd(1)
process. This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required)."
1111,2,pmdakernel,"This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required). Unlike many other PMDAs, the kernel PMDA exports a number of
       metric namespace subtrees, such as kernel, network, swap, mem,
       ipc, filesys, nfs, disk and hinv (hardware inventory). Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA."
1111,3,pmdakernel,"Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA. This
       is to aid profiling and debugging activities, with
dbpmda(1)
for
       example. In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account."
1111,4,pmdakernel,"In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account. Only enable this option if you understand the risks involved,
            and are sure that all remote accesses will be from benevolent
            users. If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to."
1111,5,pmdakernel,"If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to. Refer to CVE-2012-3419 for additional
            details. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1111,6,pmdakernel,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1111,7,pmdakernel,"-l
Location of the log file. By default, a log file named
[platform].log
is written in the current directory of
pmcd(1)
when
pmda[platform]
is started, i.e. $PCP_LOG_DIR/pmcd
."
1111,8,pmdakernel,"$PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1111,9,pmdakernel,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            either the privileged ""root"" account on some platforms
            (Linux, for example) or the unprivileged ""pcp"" account
            (wherever possible)."
1112,0,pmdamounts,"pmdamounts
is a simple Performance Metrics Domain Agent (PMDA)
       which monitors availability of a given set of filesystem mounts. The
mounts
PMDA exports metrics that reflect whether the
       configured filesystems are mounted (""up"") or not. The list of
       mount points to monitor is specified via the
$PCP_PMDAS_DIR/mounts/mounts.conf
file which simply contains one
       line for each mount point."
1112,1,pmdamounts,"The list of
       mount points to monitor is specified via the
$PCP_PMDAS_DIR/mounts/mounts.conf
file which simply contains one
       line for each mount point. A brief description of the
pmdamounts
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1112,2,pmdamounts,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
mounts.log
is written in the current directory of
pmcd(1)
when
pmdamounts
is started, i.e."
1112,3,pmdamounts,"By default, a log file named
mounts.log
is written in the current directory of
pmcd(1)
when
pmdamounts
is started, i.e. $PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead."
1112,4,pmdamounts,"If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1113,0,pmdamysql,"pmdamysql
is a Performance Co-Pilot PMDA which extracts live
       performance data from a running MySQL or MariaDB database."
1114,0,pmdanetfilter,"pmdanetfilter
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values from the IP connection tracking module in
       the Linux kernel."
1115,0,pmdanfsclient,"pmdanfsclient
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values from the
/proc/self/mountstats
interface to
       provide information on NFS mounts."
1116,0,pmdanetcheck,"pmdanetcheck
is a Performance Co-Pilot (PCP) Performance Metrics
       Domain Agent (PMDA) which does basic network checks on the local
       host by using simple Python modules and, in some cases, external
       utilities such as
ping
(1). pmdanetcheck
loads and acts as a bridge for any number of
       configured, separate PCP netcheck PMDA Python modules running
       Python code or external programs. Existing Python modules and
       programs should be possible to be utilized with PCP netcheck PMDA
       modules with minimal effort."
1116,1,pmdanetcheck,"pmdanetcheck
loads and acts as a bridge for any number of
       configured, separate PCP netcheck PMDA Python modules running
       Python code or external programs. Existing Python modules and
       programs should be possible to be utilized with PCP netcheck PMDA
       modules with minimal effort. Note that on SELinux enabled systems for
pmdanetcheck
to be able
       to use the
ping
(1) command the
pcp
group must be able to create
       ICMP Echo sockets; please make sure the group id for
pcp
is
       included in the range at
/proc/sys/net/ipv4/ping_group_range
and
       refer to
icmp(7)
for more details on this."
1117,0,pmdanginx,"pmdanginx
is a Performance Metrics Domain Agent (PMDA) which
       exports performance metrics from
nginx
(8) - an HTTP and reverse
       proxy server, a mail proxy server, and a generic TCP proxy server."
1118,0,pmdanutcracker,"This PMDA extracts performance data from NutCracker (or
       TwemProxy), a fast and lightweight proxy for memcached and Redis
       protocol."
1119,0,pmdanvidia,"pmdanvidia
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics describing the metrics available on
       NVIDIA GPU cards via the NVML library. The
nvidia
PMDA exports metrics that measure gpu activity, memory
       utilization, fan speed, etc on NVIDIA Tesla and Quadro cards. Metrics are unlikely to be available for consumer class cards."
1119,1,pmdanvidia,"Metrics are unlikely to be available for consumer class cards. A brief description of the
pmdanvidia
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1119,2,pmdanvidia,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
nvidia.log
is written in the current directory of
pmcd(1)
when
pmdanvidia
is started, i.e."
1119,3,pmdanvidia,"By default, a log file named
nvidia.log
is written in the current directory of
pmcd(1)
when
pmdanvidia
is started, i.e. $PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead."
1119,4,pmdanvidia,"If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -t
Enables and sets a sampling
interval
for automatic refreshing
            of metric values. The functionality is disabled by default,
            however this option allows a time interval to be specified on
            which all values are sampled - this has the effect of
            constantly updating the accumulating metrics, with the goal
            of assisting client tools such as
pcp-atop(1)
and
pmlogger(1)
to observe sub-sample time changes in GPU and process state."
1119,5,pmdanvidia,"-t
Enables and sets a sampling
interval
for automatic refreshing
            of metric values. The functionality is disabled by default,
            however this option allows a time interval to be specified on
            which all values are sampled - this has the effect of
            constantly updating the accumulating metrics, with the goal
            of assisting client tools such as
pcp-atop(1)
and
pmlogger(1)
to observe sub-sample time changes in GPU and process state. Typically these tools have longer sampling intervals, and can
            thus 'miss' activity happening during their sampling
            interval."
1120,0,pmdaopenvswitch,"pmdaopenvswitch
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values for each openvswitch virtual switch
       configured on the local system."
1121,0,pmdaoracle,"pmdaoracle
is a Performance Co-Pilot PMDA which extracts live
       performance data from a running Oracle database."
1122,0,pmdapipe,"pmdapipe
is a configurable command output monitoring Performance
       Metrics Domain Agent (PMDA). It can be seen as analogous to a
       restricted shell, where options can be passed to preset commands,
       and each line of their output is converted into a performance
       event. These events can be consumed by client tools like
pmval(1)
."
1122,1,pmdapipe,"These events can be consumed by client tools like
pmval(1)
. The
pipe
PMDA exports both event-style metrics reflecting
       timestamped event records for text-oriented command output, as
       well as the more orthodox sample-style metrics such as event
       counts and throughput size values. The PMDA is configured via a
configfile
which contains one line
       for each process from which output can be captured, as described
       in the ``CONFIGURATION'' section below."
1122,2,pmdapipe,"The PMDA is configured via a
configfile
which contains one line
       for each process from which output can be captured, as described
       in the ``CONFIGURATION'' section below. A brief description of the
pmdapipe
command line options follows:
-c
specifies an alternate configuration file for the PMDA. By
            default, a file named
$PCP_PMDAS_DIR/pipe/pipe.conf
and any
            files below the
$PCP_SYSCONF_DIR/pipe.conf.d/
directory are
            used."
1122,3,pmdapipe,"By
            default, a file named
$PCP_PMDAS_DIR/pipe/pipe.conf
and any
            files below the
$PCP_SYSCONF_DIR/pipe.conf.d/
directory are
            used. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1122,4,pmdapipe,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
pipe.log
is written in the current directory of
pmcd(1)
when
pmdapipe
is started, i.e."
1122,5,pmdapipe,"By default, a log file named
pipe.log
is written in the current directory of
pmcd(1)
when
pmdapipe
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log
            file cannot be created or is not writable, output is written
            to the standard error instead."
1122,6,pmdapipe,"If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -m
Limit the physical memory used by the PMDA to buffer event
            records to
maxsize
bytes. As log events arrive at the PMDA,
            they must be buffered until individual client tools request
            the next batch since their previous batch of events."
1122,7,pmdapipe,"-m
Limit the physical memory used by the PMDA to buffer event
            records to
maxsize
bytes. As log events arrive at the PMDA,
            they must be buffered until individual client tools request
            the next batch since their previous batch of events. The
            default maximum is 2 megabytes."
1123,0,pmdaoverhead,"pmdaoverhead
is a configurable Performance Metrics Domain Agent
       (PMDA) for exporting resource consumption for groups of related
       processes. The
pmdaoverhead
command line options are:
-C
parse the configuration file(s) and exit after reporting any
           errors. -c
configuration file(s),
config
may be either a file or a
           directory; in the latter case all the files within
config
are
           assumed to be configuration files for
pmdaoverhead
and they
           will all be processed."
1123,1,pmdaoverhead,"-c
configuration file(s),
config
may be either a file or a
           directory; in the latter case all the files within
config
are
           assumed to be configuration files for
pmdaoverhead
and they
           will all be processed. Each configuration file defines one or more ``groups'' of
           processes of interest, using the syntax described in the
           ``CONFIGURATION'' section below. By default all configuration files below the
$PCP_SYSCONF_DIR/overhead/conf.d/
directory are used."
1123,2,pmdaoverhead,"By default all configuration files below the
$PCP_SYSCONF_DIR/overhead/conf.d/
directory are used. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host, and
           the same
domain
number should be used for the same PMDA on all
           hosts."
1123,3,pmdaoverhead,"That is,
domain
should be different for every PMDA on the one host, and
           the same
domain
number should be used for the same PMDA on all
           hosts. -l
Location of the log file. By default, a log file named
overhead.log
is written in the current directory of
pmcd(1)
when
pmdaoverhead
is started, i.e."
1123,4,pmdaoverhead,"By default, a log file named
overhead.log
is written in the current directory of
pmcd(1)
when
pmdaoverhead
is started, i.e. $PCP_LOG_DIR/pmcd
. If the
           log file cannot be created or is not writable, output is
           written to the standard error instead."
1123,5,pmdaoverhead,"If the
           log file cannot be created or is not writable, output is
           written to the standard error instead. -R
The PMDA uses a separate thread to periodically scan all
           processes to determine which processes are deemed
           ``interesting'' in each group, and extracting resource
           consumption for those processes. The
interval
(in seconds)
           determines how often this scanning and resource calculation is
           done, the default is 60 (seconds)."
1124,0,pmdapostfix,"pmdapostfix
is a Performance Metrics Domain Agent (PMDA) which
       exports mail queue sizes as reported by
qshape
(1), as well as
       aggregate statistics collected from mail.log."
1125,0,pmdaperfevent,"pmdaperfevent
is a Performance Metrics Domain Agent (PMDA) that
       configures and reads the hardware performance counters using the
       Linux kernel perf_event API. The
perfevent
PMDA exports metrics for hardware performance
       counters that are configurable from the Linux kernel perf_event
       API. The PMDA uses the libpfm4 library to access the hardware
       performance counters so any counters that are supported in libpfm4
       should be available."
1125,1,pmdaperfevent,"The PMDA uses the libpfm4 library to access the hardware
       performance counters so any counters that are supported in libpfm4
       should be available. Also included is the ability to read the
       Intel RAPL counters via direct MSR access. The PMDA supports
       automatically loading different counters for each hardware
       architecture."
1125,2,pmdaperfevent,"The PMDA supports
       automatically loading different counters for each hardware
       architecture. A single configuration file is used to specify the
       desired counters for each hardware performance monitoring unit
       (PMU). The configuration file allows different counters to be
       programmed on different CPUs and supports round-robin assignment
       of uncore counters needed for some AMD chips."
1125,3,pmdaperfevent,"The configuration file allows different counters to be
       programmed on different CPUs and supports round-robin assignment
       of uncore counters needed for some AMD chips. The PMDA also counts for events exposed in the kernel via
       /sys/bus/event_source/devices directory. The PMU device name and
       the event name must be mentioned in the configuration file."
1125,4,pmdaperfevent,"The PMU device name and
       the event name must be mentioned in the configuration file. Otherwise, the metric won't be available to monitor through this
       PMDA. The PMDA configures the counters to count events in both user and
       kernel mode."
1125,5,pmdaperfevent,"The PMDA configures the counters to count events in both user and
       kernel mode. This means that the hardware counters are
       unavailable to use by normal unprivileged user applications when
       they are in use by the PMDA. The PMDA provides a mechanism to
       temporarily disable the system-wide counters in order to allow
       normal users to be able to use the counters if they wish."
1125,6,pmdaperfevent,"The PMDA provides a mechanism to
       temporarily disable the system-wide counters in order to allow
       normal users to be able to use the counters if they wish. See
perfalloc(1)
for details. Note that
pmdaperfevent
is affected by the value of the
kernel.perf_event_paranoid
setting, which can be adjusted by
sysctl(8)
."
1125,7,pmdaperfevent,"Note that
pmdaperfevent
is affected by the value of the
kernel.perf_event_paranoid
setting, which can be adjusted by
sysctl(8)
. A brief description of the
pmdaperfevent
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1125,8,pmdaperfevent,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
perfevent.log
is written in the current directory of
pmcd(1)
when
pmdaperfevent
is started, i.e."
1125,9,pmdaperfevent,"By default, a log file named
perfevent.log
is written in the current directory of
pmcd(1)
when
pmdaperfevent
is started, i.e. $PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead."
1125,10,pmdaperfevent,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            the privileged ""root"" account."
1125,11,pmdaperfevent,"-U
User account under which to run the agent. The default is
            the privileged ""root"" account. -i
listen on given port number for connection from
pmcd(1)
-p
communicate with
pmcd(1)
via stdin/stdout
-u
expect
pmcd(1)
to connect on given unix domain socket
-6
expect
pmcd(1)
to connect on given ipv6 port (number or name)"
1126,0,pmdapodman,"podman
(1) is a utility for managing pods, containers and container
       images, following the container pod concept popularized by
       Kubernetes. pmdapodman
is a Performance Metrics Domain Agent
       (PMDA) which extracts performance metrics describing the state of
       containers and pods managed by podman. The
podman
PMDA exports metrics that measure information about
       individual containers and groups of containers, called pods."
1126,1,pmdapodman,"The
podman
PMDA exports metrics that measure information about
       individual containers and groups of containers, called pods. A brief description of the
pmdapodman
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1126,2,pmdapodman,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
podman.log
is written in the current directory of
pmcd(1)
when
pmdapodman
is started, i.e."
1126,3,pmdapodman,"By default, a log file named
podman.log
is written in the current directory of
pmcd(1)
when
pmdapodman
is started, i.e. $PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead."
1127,0,pmdapostgresql,"pmdapostgresql
is a Performance Co-Pilot (PCP) Performance Metrics
       Domain Agent (PMDA) which extracts live performance data from a
       running PostgreSQL database server.

       Many of the statistics available from a PostgreSQL server may not
       be enabled by default.  Refer to the online documentation
https://www.postgresql.org/docs/current/static/monitoring-stats.html
which describes each of the available parameters related to
       statistics collection and how to enable them."
1128,0,pmdaopenmetrics,"pmdaopenmetrics
is a Performance Metrics Domain Agent (PMDA) which
       dynamically creates PCP metrics from configured OpenMetrics
       endpoints, which provide HTTP based access to application metrics. The PMDA essentially implements a bridge between
Prometheus
and
PCP
, allowing PCP to easily ingest performance data from more than
       650 registered end-points and many other application specific end-
       points. The default
config
directory is
$PCP_PMDAS_DIR/openmetrics/config.d/
, see ``CONFIGURATION
       SOURCES'' below."
1128,1,pmdaopenmetrics,"The default
config
directory is
$PCP_PMDAS_DIR/openmetrics/config.d/
, see ``CONFIGURATION
       SOURCES'' below. The default URL fetch
timeout
is
2
seconds. The
       default
user
, if not specified with the
-u
option, is the current
       user."
1128,2,pmdaopenmetrics,"The
       default
user
, if not specified with the
-u
option, is the current
       user. If the
-n
option is given, the list of configuration files
       will not be sorted prior to processing. This list is sorted by
       default but that can be expensive if there are a large number of
       configuration files (URLs and/or scripts)."
1128,3,pmdaopenmetrics,"This list is sorted by
       default but that can be expensive if there are a large number of
       configuration files (URLs and/or scripts). If the
-D
option is given, additional diagnostic messages will be
       written to the PMDA log file, which is
$PCP_LOG_DIR/pmcd/openmetrics.log
by default (see also
-l
below). In addition, the metric
openmetrics.control.debug
controls the
       same debug flag and can be set with the following command:
pmstore openmetrics.control.debug
value
where
value
is either
1
(to enable verbose log messages) or
0
(to
       disable verbose log messages)."
1128,4,pmdaopenmetrics,"In addition, the metric
openmetrics.control.debug
controls the
       same debug flag and can be set with the following command:
pmstore openmetrics.control.debug
value
where
value
is either
1
(to enable verbose log messages) or
0
(to
       disable verbose log messages). This is particularly useful for
       examining the http headers passed to each fetch request, filter
       settings and other processing details that are logged when the
       debugging flag is enabled. The
-d
option may be used to override the default performance
       metrics
domain
number, which defaults to
144."
1128,5,pmdaopenmetrics,"The
-d
option may be used to override the default performance
       metrics
domain
number, which defaults to
144. It is strongly
       recommended not to change this. The
domain
number should be
       different for every PMDA on the one host, and the same
domain
number should be used for
pmdaopenmetrics
PMDA on all hosts."
1128,6,pmdaopenmetrics,"The
domain
number should be
       different for every PMDA on the one host, and the same
domain
number should be used for
pmdaopenmetrics
PMDA on all hosts. See
       also the
-r
option, which allows the root of the dynamic namespace
       to be changed from the default
openmetrics
. The
-l
option may be used to specify
logfile
as the destination
       for PMDA messages instead of the default,
$PCP_LOG_DIR/pmcd/openmetrics.log
."
1128,7,pmdaopenmetrics,"The
-l
option may be used to specify
logfile
as the destination
       for PMDA messages instead of the default,
$PCP_LOG_DIR/pmcd/openmetrics.log
. As a special case,
logfile
may
       be
""-""
to send messages to the
stderr
stream instead, e.g. -l-
."
1128,8,pmdaopenmetrics,"-l-
. This would normally be the
stderr
stream for the parent process,
pmcd(1)
, which may itself have redirected
stderr
. This
       redirection is normally most useful in a containerized
       environment, or when using
dbpmda(1)
."
1128,9,pmdaopenmetrics,"This
       redirection is normally most useful in a containerized
       environment, or when using
dbpmda(1)
. The
-r
option allows the root of the dynamic namespace to be
       changed to
root
from the default,
openmetrics
. In conjunction
       with other command line options, this allows
pmdaopenmetrics
to be
       deployed as a different PMDA with distinct metrics namespace and
       metrics domain on the same host system."
1128,10,pmdaopenmetrics,"In conjunction
       with other command line options, this allows
pmdaopenmetrics
to be
       deployed as a different PMDA with distinct metrics namespace and
       metrics domain on the same host system. Note that all PMDAs
       require a unique domain number so the
-d
option must also be
       specified. Use of the
-r
option may also change the defaults for
       some other command line options, e.g."
1128,11,pmdaopenmetrics,"Note that all PMDAs
       require a unique domain number so the
-d
option must also be
       specified. Use of the
-r
option may also change the defaults for
       some other command line options, e.g. the default log file name
       and the default configuration directory."
1129,0,pmdaproc,"pmdaproc
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics describing the state of the
       individual processes running on a Linux system. The
proc
PMDA exports metrics that measure the memory, processor
       and other resource use of each process, as well as summary
       information collated across all of the running processes. The
       PMDA uses credentials passed from the
PMAPI(3)
monitoring tool
       identifying the user requesting the information, to ensure that
       only values the user is allowed to access are returned by the
       PMDA."
1129,1,pmdaproc,"The
       PMDA uses credentials passed from the
PMAPI(3)
monitoring tool
       identifying the user requesting the information, to ensure that
       only values the user is allowed to access are returned by the
       PMDA. This involves the PMDA temporarily changing its effective
       user and group identifiers for the duration of requests for
       instances and values. In other words, system calls to extract
       information are performed as the user originating the request and
       not as a privileged user."
1129,2,pmdaproc,"In other words, system calls to extract
       information are performed as the user originating the request and
       not as a privileged user. The mechanisms available for transfer
       of user credentials are described further in the
PCPIntro(1)
page. A brief description of the
pmdaproc
command line options follows:
-A
Disables use of the credentials provided by
PMAPI
client
            tools and simply runs everything under the ""root"" account."
1129,3,pmdaproc,"A brief description of the
pmdaproc
command line options follows:
-A
Disables use of the credentials provided by
PMAPI
client
            tools and simply runs everything under the ""root"" account. Refer to the ACCESS CONFIGURATION section below for finer
            grained control when using
pmcd(1)
with remote client
            authentication. Only enable this option if you understand
            the risks involved, and are sure that all remote accesses
            will be from benevolent users."
1129,4,pmdaproc,"Only enable this option if you understand
            the risks involved, and are sure that all remote accesses
            will be from benevolent users. If enabled, unauthenticated
            remote
PMAPI
clients will be able to access potentially
            sensitive performance metric values which an unauthenticated
PMAPI
client usually would not be able to. Refer to
            CVE-2011-2495 and CVE-2012-3419 for additional details."
1129,5,pmdaproc,"Refer to
            CVE-2011-2495 and CVE-2012-3419 for additional details. -L
Changes the per-process instance domain used by most
pmdaproc
metrics to include threads as well. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1129,6,pmdaproc,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1129,7,pmdaproc,"-l
Location of the log file. By default, a log file named
proc.log
is written in the current directory of
pmcd(1)
when
pmdaproc
is started, i.e. $PCP_LOG_DIR/pmcd
."
1129,8,pmdaproc,"$PCP_LOG_DIR/pmcd
. If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -r
Restrict the set of processes exported in the per-process
            instance domain to only those processes that are contained by
            the specified
cgroup
resource container."
1129,9,pmdaproc,"-r
Restrict the set of processes exported in the per-process
            instance domain to only those processes that are contained by
            the specified
cgroup
resource container. This option
            provides an optional finer granularity to the monitoring, and
            can also be used to reduce the resources consumed by
pmdaproc
during requests for instances and values. -U
User account under which to run the agent."
1129,10,pmdaproc,"This option
            provides an optional finer granularity to the monitoring, and
            can also be used to reduce the resources consumed by
pmdaproc
during requests for instances and values. -U
User account under which to run the agent. The default is
            the privileged ""root"" account, with seteuid (2) and setegid
            (2) switching for accessing most information."
1130,0,pmdaredis,"This PMDA extracts performance data from sending the INFO command
       to a Redis (redis.io) server, which includes:

       â¢ General information about the Redis server

       â¢ Client connections

       â¢ Memory consumption

       â¢ Persistence statistics

       â¢ Replication statistics

       â¢ CPU consumption statistics

       â¢ Redis command statistics

       â¢ Redis Cluster statistics

       â¢ Database related statistics

       The hostname (localhost), port (6379 by default) and other
       configuration information must be specified in the
       $PCP_PMDAS_DIR/redis/redis.conf file.
# cd $PCP_PMDAS_DIR/redis
# [ edit redis.conf ]
host=localhost.localdomain:6379
To uninstall, the following must be done as root:
# cd $PCP_PMDAS_DIR/redis
# ./Remove
Once this is setup, you can access the names and values for the
       redis performance metrics by doing the following as root:
# cd $PCP_PMDAS_DIR/redis
# ./Install
To uninstall, the following must be done as root:
# cd $PCP_PMDAS_DIR/redis
# ./Remove
pmdaredis
is launched by
pmcd(1)
and should never be executed
       directly. The Install and Remove scripts notify
pmcd(1)
when the
       agent is installed or removed."
1131,0,pmdarabbitmq,"pmdarabbitmq
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values for each RabbitMQ queue configured on the
       local system."
1132,0,pmdaroomtemp,"pmdaroomtemp
is a Performance Metrics Domain Agent (PMDA) which
       exports the temperature from one or more sensors built using the
       DS2480 and DS1280 chipsets and MicroLAN technology from Dallas
       Semiconductor Corporation. The
roomtemp
PMDA exports metrics that reflect the temperatures
       from one or more of these devices, in both degrees Celsius and
       Fahrenheit. Each metric has one instance for each temperature
       sensor device."
1132,1,pmdaroomtemp,"Each metric has one instance for each temperature
       sensor device. The external instance identifiers are the serial
       numbers (in hex) of the DS1280 chips discovered when the MicroLAN
       was probed. A brief description of the
pmdaroomtemp
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1132,2,pmdaroomtemp,"A brief description of the
pmdaroomtemp
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1132,3,pmdaroomtemp,"-l
Location of the log file. By default, a log file named
roomtemp.log
is written in the current directory of
pmcd(1)
when
pmdaroomtemp
is started, i.e. $PCP_LOG_DIR/pmcd
."
1132,4,pmdaroomtemp,"By default, a log file named
roomtemp.log
is written in the current directory of
pmcd(1)
when
pmdaroomtemp
is started, i.e. $PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead."
1133,0,pmdarsyslog,"pmdarsyslog
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values from the
rsyslogd(8)
server.

       Further details about rsyslog can be found at
http://www.rsyslog.com/
."
1134,0,pmdaroot,"pmdaroot
is a special Performance Metrics Domain Agent (PMDA)
       which cooperates closely with
pmcd(1)
and other PMDAs to provide
       limited privileged services to these unprivileged processes. In this role it is used to discover operating system containers
       running on the local host. It also enables access to performance
       data from within those containers by other PMDAs running on the
       bare-metal host, using the
pmdaRootConnect(3)
and the associated
       namespace interfaces."
1134,1,pmdaroot,"It also enables access to performance
       data from within those containers by other PMDAs running on the
       bare-metal host, using the
pmdaRootConnect(3)
and the associated
       namespace interfaces. Like all other PMDAs, it also exports performance metrics from the
       domain it controls. Currently, this is limited to information
       about the containers on the local system; currently Docker and LXC
       containers can be detected."
1134,2,pmdaroot,"Currently, this is limited to information
       about the containers on the local system; currently Docker and LXC
       containers can be detected. If a non-default Docker parent-cgroup name is being used, this
       value can be indicated to
pmdaroot
through addition of a
$PCP_SYSTEMD_CGROUP
variable in
/etc/pcp.conf
. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1134,3,pmdaroot,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1134,4,pmdaroot,"-l
Location of the log file. By default, a log file named
root.log
is written in the current directory of
pmcd(1)
when
pmdaroot
is started, i.e. $PCP_LOG_DIR/pmcd
."
1134,5,pmdaroot,"$PCP_LOG_DIR/pmcd
. If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -s
Location of the
unix(7)
domain socket for communication with
            clients seeking privileged operations."
1134,6,pmdaroot,"If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -s
Location of the
unix(7)
domain socket for communication with
            clients seeking privileged operations. By default, a socket
            file named
$PCP_TMP_DIR/pmcd/root.socket
is used."
1135,0,pmdasample,"pmdasample
is a sample Performance Metrics Domain Agent (PMDA)
       which exports a variety of synthetic performance metrics. This PMDA was developed as part of the quality assurance testing
       for the PCP product, but has other uses, most notably in the
       development of new PCP clients. The metrics exported by the sample PMDA cover the full range of
       data types, data semantics, value cardinality, instance domain
       stability and error conditions found in real PMDAs."
1135,1,pmdasample,"The metrics exported by the sample PMDA cover the full range of
       data types, data semantics, value cardinality, instance domain
       stability and error conditions found in real PMDAs. A brief description of the
pmdasample
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1135,2,pmdasample,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -i
Expect PMCD to connect to
pmdasample
on the specified TCP/IP
            port. port
may be a port number or port name."
1135,3,pmdasample,"port
may be a port number or port name. -l
Location of the log file. By default, a log file named
sample.log
is written in the current directory of
pmcd(1)
when
pmdasample
is started, i.e."
1135,4,pmdasample,"By default, a log file named
sample.log
is written in the current directory of
pmcd(1)
when
pmdasample
is started, i.e. $PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead."
1135,5,pmdasample,"If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -p
Expect PMCD to create a pipe and the connection to
pmdasample
is via standard input and standard output. This is the
            default connection mode."
1135,6,pmdasample,"This is the
            default connection mode. -u
Expect PMCD to connect to
pmdasample
on the Unix domain
            socket named
socket
. -U
User account under which to run the agent."
1135,7,pmdasample,"-U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default. At most one of the options
-i
,
-p
and
-u
may be specified."
1136,0,pmdasendmail,"pmdasendmail
is a sendmail Performance Metrics Domain Agent (PMDA)
       which exports mail traffic statistics as collected by
sendmail
(1). Before the sendmail PMDA can export any metrics,
sendmail
(1) must
       have statistics collection enabled. This involves checking the
       name of the statistics file, as given by the
OS
or
O StatusFile
control lines in
/etc/sendmail.cf
, and then creating this file if
       it does not already exist."
1136,1,pmdasendmail,"This involves checking the
       name of the statistics file, as given by the
OS
or
O StatusFile
control lines in
/etc/sendmail.cf
, and then creating this file if
       it does not already exist. Removing the file will terminate
       statistics collection by
sendmail
(1) and hence the sendmail PMDA. A brief description of the
pmdasendmail
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1136,2,pmdasendmail,"A brief description of the
pmdasendmail
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1136,3,pmdasendmail,"-l
Location of the log file. By default, a log file named
sendmail.log
is written in the current directory of
pmcd(1)
when
pmdasendmail
is started, i.e. $PCP_LOG_DIR/pmcd
."
1136,4,pmdasendmail,"$PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1136,5,pmdasendmail,"-U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default. There are no communication options, as the
Install
script ensures
       the sendmail PMDA will be connected to PMCD by a pipe."
1137,0,pmdashping,"pmdashping
is a Performance Metrics Domain Agent (PMDA) which
       exports quality of service and response time measurements for
       arbitrary commands as might be run from a shell such as
sh
(1). These measurements are intended to be used to quantify service
       quality and service availability for those services that are
       either mission critical or act as early indicators of adverse
       system performance. The sample configuration monitors simple shell commands (
exit
and
date(1)
), a short computationally intensive task using
sum(1)
, a
       short C compilation, DNS lookup via
nslookup
(1), YP lookup via
ypcat
(1), bind/portmapper service using
rpcbind
(1), SMTP by
       connecting to telnet port 25 and sending an ``expn root'' request,
       and NNTP by connecting to telnet port 119 and running a
       ``listgroup'' command."
1137,1,pmdashping,"The sample configuration monitors simple shell commands (
exit
and
date(1)
), a short computationally intensive task using
sum(1)
, a
       short C compilation, DNS lookup via
nslookup
(1), YP lookup via
ypcat
(1), bind/portmapper service using
rpcbind
(1), SMTP by
       connecting to telnet port 25 and sending an ``expn root'' request,
       and NNTP by connecting to telnet port 119 and running a
       ``listgroup'' command. It is expected that other commands would follow the examples in
       the sample configuration file, and most deployments of the
pmdashping
PMDA are expected to use a customized configuration
       file. A brief description of the
pmdashping
command line options
       follows:
-C
Parse
configfile
, reporting any errors and exiting with non-
            zero status if the file contains syntactical errors."
1137,2,pmdashping,"A brief description of the
pmdashping
command line options
       follows:
-C
Parse
configfile
, reporting any errors and exiting with non-
            zero status if the file contains syntactical errors. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1137,3,pmdashping,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
shping.log
is written in the current directory of
pmcd(1)
when
pmdashping
is started, i.e."
1137,4,pmdashping,"By default, a log file named
shping.log
is written in the current directory of
pmcd(1)
when
pmdashping
is started, i.e. $PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead."
1137,5,pmdashping,"If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -I
Amount of time (in seconds) between subsequent executions of
            the list of commands provided via the configuration file
configfile
. The default is 2 minutes."
1137,6,pmdashping,"The default is 2 minutes. -t
Amount of time (in seconds) to wait before timing out
            awaiting a response for a command from
configfile
. The
            default is 20 seconds."
1137,7,pmdashping,"The
            default is 20 seconds. -U
User account under which to run the agent and all commands. The default is the unprivileged ""pcp"" account in current
            versions of PCP, but in older versions the superuser account
            (""root"") was used by default."
1137,8,pmdashping,"The default is the unprivileged ""pcp"" account in current
            versions of PCP, but in older versions the superuser account
            (""root"") was used by default. The required
configfile
specifies ``tag'' and ``command'' pairs,
       each on a separate line. All of the commands are run one after
       another, with the whole group rescheduled to be run once per
interval
."
1137,9,pmdashping,"All of the commands are run one after
       another, with the whole group rescheduled to be run once per
interval
. For each command that is run,
pmdashping
records
       information related to the success (or timeout), exit status,
       elapsed time and CPU time (system and user), and this information
       is exported by the PMDA. The tags are used to identify the
       individual commands amongst the values exported by the PMDA, and
       form the external instance domain identifiers for the
pmdashping
metrics which relate to each command."
1138,0,pmdaresctrl,"pmdaresctrl
is a resctrl Performance Metrics Domain Agent (PMDA)
       which exposes performance metrics values from the /sys/fs/resctrl
       interface to provide information on the last level cache.

       Further details on linux support for last level cache metrics can
       be found at
https://github.com/torvalds/linux/tree/master/Documentation/arch/x86/resctrl.rst
."
1139,0,pmdasimple,"pmdasimple
is a simple Performance Metrics Domain Agent (PMDA)
       which exports a small number of synthetic performance metrics. The simple PMDA is shipped as source code and is designed to be an
       aid for PMDA developers. In terms of code size and features, it
       is more complex than the trivial PMDA, about the same as the txmon
       PMDA and less complex than the sample PMDA."
1139,1,pmdasimple,"In terms of code size and features, it
       is more complex than the trivial PMDA, about the same as the txmon
       PMDA and less complex than the sample PMDA. The source for the
       simple PMDA is a good template from which production, customized
       PMDAs can be developed. A brief description of the
pmdasimple
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1139,2,pmdasimple,"A brief description of the
pmdasimple
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -i
Expect PMCD to connect to
pmdasimple
on the specified TCP/IP
            port."
1139,3,pmdasimple,"-i
Expect PMCD to connect to
pmdasimple
on the specified TCP/IP
            port. port
may be a port number or port name. -l
Location of the log file."
1139,4,pmdasimple,"-l
Location of the log file. By default, a log file named
simple.log
is written in the current directory of
pmcd(1)
when
pmdasimple
is started, i.e. $PCP_LOG_DIR/pmcd
."
1139,5,pmdasimple,"$PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -p
Expect PMCD to create a pipe and the connection to
pmdasimple
is via standard input and standard output."
1139,6,pmdasimple,"-p
Expect PMCD to create a pipe and the connection to
pmdasimple
is via standard input and standard output. This is the
            default connection mode. -u
Expect PMCD to connect to
pmdasimple
on the Unix domain
            socket named
socket
."
1139,7,pmdasimple,"-u
Expect PMCD to connect to
pmdasimple
on the Unix domain
            socket named
socket
. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1139,8,pmdasimple,"-U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default. At most one of the options
-i
,
-p
and
-u
may be specified."
1140,0,pmdaslurm,"pmdaslurm
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values from the slurm perlapi interface to provide
       information on slurm jobs, nodes and users."
1141,0,pmdasmart,"pmdasmart
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values for Device Mapper on the local system.

       This PMDA collects its data through the
smartctl
(8) utility and
       requires that the program is installed in order to function.

       Further details on smartctl and smartmontools can be found at
https://smartmontools.org
."
1142,0,pmdasockets,"pmdasockets
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values for current sockets on the local system.

       This PMDA currently collects its data through the
ss(8)
utility
       and requires that the program is installed in order to function.
       This dependency may change in the future."
1143,0,pmdakernel,"Each supported platform has a kernel Performance Metrics Domain
       Agent (PMDA) which extracts performance metrics from the kernel of
       that platfrom. A variety of platform-specific metrics are
       available, with an equally varied set of access mechanisms -
       typically this involves special system calls, or reading from
       files in kernel virtual filesystems such as the Linux
sysfs
and
procfs
filesystems. The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible."
1143,1,pmdakernel,"The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible. In all installations the default kernel PMDA will be
       installed as a shared library and thus executes directly within
       the
pmcd(1)
process. This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required)."
1143,2,pmdakernel,"This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required). Unlike many other PMDAs, the kernel PMDA exports a number of
       metric namespace subtrees, such as kernel, network, swap, mem,
       ipc, filesys, nfs, disk and hinv (hardware inventory). Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA."
1143,3,pmdakernel,"Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA. This
       is to aid profiling and debugging activities, with
dbpmda(1)
for
       example. In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account."
1143,4,pmdakernel,"In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account. Only enable this option if you understand the risks involved,
            and are sure that all remote accesses will be from benevolent
            users. If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to."
1143,5,pmdakernel,"If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to. Refer to CVE-2012-3419 for additional
            details. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1143,6,pmdakernel,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1143,7,pmdakernel,"-l
Location of the log file. By default, a log file named
[platform].log
is written in the current directory of
pmcd(1)
when
pmda[platform]
is started, i.e. $PCP_LOG_DIR/pmcd
."
1143,8,pmdakernel,"$PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1143,9,pmdakernel,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            either the privileged ""root"" account on some platforms
            (Linux, for example) or the unprivileged ""pcp"" account
            (wherever possible)."
1144,0,pmdatrace,"pmdatrace
is a Performance Metrics Domain Agent (PMDA) which
       exports transaction performance metrics from application processes
       which use the
pcp_trace
library described in
pmdatrace(3)
. A brief description of the
pmdatrace
command line options follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1144,1,pmdatrace,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
trace.log
is written in the current directory of
pmcd(1)
when
pmdatrace
is started, i.e."
1144,2,pmdatrace,"By default, a log file named
trace.log
is written in the current directory of
pmcd(1)
when
pmdatrace
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log
            file cannot be created or is not writable, output is written
            to the standard error instead."
1144,3,pmdatrace,"If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -A
Host-based access control for
pmdatrace
. access
must be
            either an allow or deny specification, using either
            allow:hostspec:maxconns or disallow:hostspec, where `allow'
            and `disallow' are keywords, `hostspec' is a host
            specification conforming to the format used by both
pmcd(1)
and
pmlogger(1)
, and `maxconns' is the maximum number of
            connections allowed from a given `hostspec'."
1144,4,pmdatrace,"access
must be
            either an allow or deny specification, using either
            allow:hostspec:maxconns or disallow:hostspec, where `allow'
            and `disallow' are keywords, `hostspec' is a host
            specification conforming to the format used by both
pmcd(1)
and
pmlogger(1)
, and `maxconns' is the maximum number of
            connections allowed from a given `hostspec'. Using a maximum
            connections of zero specifies an unlimited number of
            connections for the accompanying `hostspec'. -I
Communicate with
pcp_trace
clients via the given Internet
port
."
1144,5,pmdatrace,"-I
Communicate with
pcp_trace
clients via the given Internet
port
. This can alternatively be specified by setting
$PCP_TRACE_PORT
in the environment to some valid port number
            (use of the
-I
option overrides this). The default port
            number is 4323."
1144,6,pmdatrace,"The default port
            number is 4323. -T
period
defines the aggregation period used to compute the
            recent averages and extrema. Specified as a time interval
            using the syntax described in
PCPIntro(1)
for the common
-t
PCP argument, e.g."
1144,7,pmdatrace,"Specified as a time interval
            using the syntax described in
PCPIntro(1)
for the common
-t
PCP argument, e.g. 30 seconds
or
1 min
. The default is 60
            seconds."
1144,8,pmdatrace,"The default is 60
            seconds. -M
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1144,9,pmdatrace,"The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default. -N
Internally, the aggregation
period
is divided into
bucket
divisions, and the rolling average is recomputed every
period
/
bucket
seconds. For example, the defaults correspond
            to -T 60 and -N 12, which means the average is recomputed
            every five seconds for a period covering the prior 60
            seconds."
1144,10,pmdatrace,"For example, the defaults correspond
            to -T 60 and -N 12, which means the average is recomputed
            every five seconds for a period covering the prior 60
            seconds. -U
This option allows the dimension and scale associated with
            the observation value metric to be configured. units
is a
            comma-separated string of six integer values, which are the
            space dimension, time dimension, count dimension, space
            scale, time scale, and count scale, respectively."
1144,11,pmdatrace,"units
is a
            comma-separated string of six integer values, which are the
            space dimension, time dimension, count dimension, space
            scale, time scale, and count scale, respectively. The
            default dimension and scale is ``none'', which is equivalent
            to presenting ``0,0,0,0,0,0'' as the argument to -U. The
            units associated with a metric are most easily viewed using
            the -d (metric description) option to
pminfo(1)
."
1144,12,pmdatrace,"The
            units associated with a metric are most easily viewed using
            the -d (metric description) option to
pminfo(1)
. The Install
            script described below steps through this option quite
            explicitly, so it is recommended that the Install script be
            used for building up the
units
specification. Essentially, the exported metrics provide statistics on the time
       for completion of each transaction, and an average count of
       transactions completed and watch points passed over a given time
period
."
1145,0,pmdate,"pmdate
displays the current date and/or time, with an optional
       offset.

       An
offset
is specified with a leading sign (``+'' or ``-''),
       followed by an integer value, followed by one of the following
       ``scale'' specifiers;

       S      seconds
       M      minutes
       H      hours
       d      days
       m      months
       y      years

       The output
format
follows the same rules as for
date(1)
and
strftime(3)
.

       For example, the following will display the date a week ago as
       DDMMYYYY;
               pmdate -7d %d%m%Y"
1146,0,pmdasummary,"pmdasummary
is a Performance Metrics Domain Agent (PMDA) which
       derives performance metrics values from values made available by
       other PMDAs. pmdasummary
consists of two processes:
pmie process
The inference engine for performance values
pmie(1)
is used
              to periodically sample values for the base metrics and
              compute the derived values. This process is launched with
              the given
pmie-command-line
arguments by the main process,
              described below."
1146,1,pmdasummary,"This process is launched with
              the given
pmie-command-line
arguments by the main process,
              described below. main process
The main process reads and buffers the values computed by
pmie(1)
and makes them available to the performance metrics
              collector daemon
pmcd(1)
. A brief description of the
pmdasummary
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1146,2,pmdasummary,"A brief description of the
pmdasummary
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -h
This option specifies an alternative help text file
helpfile
for describing the metrics that
pmdasummary
represents."
1146,3,pmdasummary,"-h
This option specifies an alternative help text file
helpfile
for describing the metrics that
pmdasummary
represents. -l
Location of the log file. By default, a log file named
summary.log
is written in the current directory of
pmcd(1)
when
pmdasummary
is started, i.e."
1146,4,pmdasummary,"By default, a log file named
summary.log
is written in the current directory of
pmcd(1)
when
pmdasummary
is started, i.e. $PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead."
1146,5,pmdasummary,"If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1147,0,pmdasystemd,"pmdasystemd
is a systemd log file monitoring Performance Metrics
       Domain Agent (PMDA). It can be seen as analogous to the
-f
option
       to
journalctl(1)
and converts each new log line into a performance
       event, suitable for consumption by
PMAPI(3)
client tools like
pmevent(1)
. The
systemd
PMDA exports both event-style metrics reflecting
       timestamped event records for messages logged to the system logs,
       as well as the more orthodox sample-style metrics such as message
       counts and throughput size values."
1147,1,pmdasystemd,"The
systemd
PMDA exports both event-style metrics reflecting
       timestamped event records for messages logged to the system logs,
       as well as the more orthodox sample-style metrics such as message
       counts and throughput size values. A brief description of the
pmdasystemd
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1147,2,pmdasystemd,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -f
Disables per-uid/gid record filtering. By default the user
            and group credentials will be used to filter log records
            returned to the client tool, preventing information exposure
            to arbitrary users."
1147,3,pmdasystemd,"By default the user
            and group credentials will be used to filter log records
            returned to the client tool, preventing information exposure
            to arbitrary users. This option disables that, so use only
            with extreme caution. -l
Location of the log file."
1147,4,pmdasystemd,"-l
Location of the log file. By default, a log file named
systemd.log
is written in the current directory of
pmcd(1)
when
pmdasystemd
is started, i.e. $PCP_LOG_DIR/pmcd
."
1147,5,pmdasystemd,"$PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -m
Limit the physical memory used by the PMDA to buffer event
            records to
maxsize
bytes."
1147,6,pmdasystemd,"-m
Limit the physical memory used by the PMDA to buffer event
            records to
maxsize
bytes. As log events arrive at the PMDA,
            they must be buffered until individual client tools request
            the next batch since their previous batch of events. The
            default maximum is 2 megabytes."
1147,7,pmdasystemd,"The
            default maximum is 2 megabytes. -s
Sets the polling interval for detecting newly arrived log
            lines. Mirrors the same option from the
tail(1)
command."
1147,8,pmdasystemd,"Mirrors the same option from the
tail(1)
command. -U
User account under which to run the agent. The default is
            the ""adm"" user account."
1148,0,pmdatrivial,"pmdatrivial
is the simplest possible Performance Metrics Domain
       Agent (PMDA) which exports a single performance metric, the time
       in seconds since the 1st of January, 1970. The trivial PMDA is shipped as source code and is designed to be
       an aid for PMDA developers. A brief description of the
pmdatrivial
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1148,1,pmdatrivial,"A brief description of the
pmdatrivial
command line options
       follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1148,2,pmdatrivial,"-l
Location of the log file. By default, a log file named
trivial.log
is written in the current directory of
pmcd(1)
when
pmdatrivial
is started, i.e. $PCP_LOG_DIR/pmcd
."
1148,3,pmdatrivial,"$PCP_LOG_DIR/pmcd
. If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1148,4,pmdatrivial,"If the
            log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1149,0,pmdastatsd,"StatsD
is simple, text-based UDP protocol for receiving monitoring
       data of applications in architecture client-server.
pmdastatsd
is
       an Performance Metrics Domain Agent that collects
StatsD
data,
       aggregates them and makes them available to any Performance Co-
       Pilot client, which is ideal for easily tracking stats in your
       application.

       The
statsd
PMDA supports Counter, Gauge and Duration (with
       instances for minimum, maximum, median, average, 90th percentile,
       95th percentile, 99th percentile, count and standard deviation)
       metric types, offers multiple parsing options:
Ragel
or
handwritten/custom parser
, offers multiple aggregating options for
       duration metric type:
basic histogram
or
HDR histogram
, supports
       custom form of
labels
,
logging
, exports multiple metrics about
       itself and may be configured either with an ini file or command
       line options."
1150,0,pmdatxmon,"pmdatxmon
is an example Performance Metrics Domain Agent (PMDA)
       which exports a small number of performance metrics from a
       simulated transaction monitor. The txmon PMDA is shipped as both binary and source code and is
       designed to be an aid for PMDA developers; the txmon PMDA
       demonstrates how performance data can be exported from an
       application (in this case
txrecord
) to the PCP infrastructure via
       a shared memory segment. As a matter of convenience,
pmdatxmon
creates (and destroys on exit) the shared memory segment."
1150,1,pmdatxmon,"As a matter of convenience,
pmdatxmon
creates (and destroys on exit) the shared memory segment. The
tx_type
arguments are arbitrary unique tags used to identify
       different transaction types. The
txrecord
application simulates the processing of one or more
       transactions identified by
tx_type
and with an observed service
       time of
servtime ."
1150,2,pmdatxmon,"The
txrecord
application simulates the processing of one or more
       transactions identified by
tx_type
and with an observed service
       time of
servtime . With the
-l
option,
txrecord
displays the current summary of the
       transaction activity from the shared memory segment. genload
is a shell and
awk
(1) script that acts as a front-end to
txrecord
to generate a constant load of simulated transaction
       activity."
1150,3,pmdatxmon,"genload
is a shell and
awk
(1) script that acts as a front-end to
txrecord
to generate a constant load of simulated transaction
       activity. A brief description of the
pmdatxmon
command line options follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1150,4,pmdatxmon,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
txmon.log
is written in the current directory of
pmcd(1)
when
pmdatxmon
is started, i.e."
1150,5,pmdatxmon,"By default, a log file named
txmon.log
is written in the current directory of
pmcd(1)
when
pmdatxmon
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log
            file cannot be created or is not writable, output is written
            to the standard error instead."
1150,6,pmdatxmon,"If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1151,0,pmdaunbound,"pmdaunbound
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values about the Unbound DNS resolver using the
unbound-control
(8)
stats_noreset
command. This gives lots of insight into query types, response time, cache
       hits/misses, etc. Please see the
unbound-control
(8) man page for
       explanation about each statistics counter."
1151,1,pmdaunbound,"This gives lots of insight into query types, response time, cache
       hits/misses, etc. Please see the
unbound-control
(8) man page for
       explanation about each statistics counter. Further details on the Unbound DNS resolver can be found at
https://unbound.net/
."
1152,0,pmdauwsgi,"pmdauwsgi
is a Performance Metrics Domain Agent (PMDA) which
       exports performance metrics from uwsgi. uWSGI is often used in
       conjunction with web servers such Nginx, which offer direct
       support for uWSGI's native uwsgi protocol, to serve Python web
       applications such as Django. pmdauwsgi
reads an optional ini-style configuration file:

              $PCP_SYSCONF_DIR
/uwsgi/uwsgi.conf
This file has a [pmda] section
[pmda]
host =
(
127.0.0.1
)
              Connect uwsgi stats server on the given hostname."
1152,1,pmdauwsgi,"uWSGI is often used in
       conjunction with web servers such Nginx, which offer direct
       support for uWSGI's native uwsgi protocol, to serve Python web
       applications such as Django. pmdauwsgi
reads an optional ini-style configuration file:

              $PCP_SYSCONF_DIR
/uwsgi/uwsgi.conf
This file has a [pmda] section
[pmda]
host =
(
127.0.0.1
)
              Connect uwsgi stats server on the given hostname. port =
(
9051
)
              Connect to the uwsgi stats server on the given port."
1153,0,pmdaxfs,"pmdaxfs
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics describing the state of the XFS
       filesystem from the Linux kernel. The
xfs
PMDA exports metrics that measure information about
       metadata buffer usage, the journal, btree operations, inode
       operations, extended attributes, directories, quotas, read and
       write operation counts and of course throughput. The PMDA provides a facility to reset the values of all counters
       to zero using
pmstore(1)
with the xfs.control.reset metric."
1153,1,pmdaxfs,"The PMDA provides a facility to reset the values of all counters
       to zero using
pmstore(1)
with the xfs.control.reset metric. A brief description of the
pmdaxfs
command line options follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1153,2,pmdaxfs,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
xfs.log
is written in the current directory of
pmcd(1)
when
pmdaxfs
is started, i.e."
1153,3,pmdaxfs,"By default, a log file named
xfs.log
is written in the current directory of
pmcd(1)
when
pmdaxfs
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log file
            cannot be created or is not writable, output is written to
            the standard error instead."
1154,0,pmdaweblog,"pmdaweblog
is a Performance Metrics Domain Agent (
PMDA(3)
) that
       scans Web server logs to extract metrics characterizing Web server
       activity. These performance metrics are then made available
       through the infrastructure of the Performance Co-Pilot (PCP). The
configfile
specifies which Web servers are to be monitored,
       their associated access logs and error logs, and a regular-
       expression based scheme for extracting detailed information about
       each Web access."
1154,1,pmdaweblog,"The
configfile
specifies which Web servers are to be monitored,
       their associated access logs and error logs, and a regular-
       expression based scheme for extracting detailed information about
       each Web access. This file is maintained as part of the PMDA
       installation and/or de-installation by the scripts
Install
and
Remove
in the directory
$PCP_PMDAS_DIR/weblog
. For more details,
       refer to the section below covering installation."
1154,2,pmdaweblog,"For more details,
       refer to the section below covering installation. Once started,
pmdaweblog
monitors a set of log files and in
       response to a request for information, will process any new
       information that has been appended to the log files, similar to a
tail(1)
. There is also periodic ""catch up"" to process new
       information from all log files, and a scheme to detect the
       rotation of log files."
1154,3,pmdaweblog,"There is also periodic ""catch up"" to process new
       information from all log files, and a scheme to detect the
       rotation of log files. Like all other PMDAs,
pmdaweblog
is launched by
pmcd(1)
using
       command line options specified in
$PCP_PMCDCONF_PATH
- the
Install
script will prompt for appropriate values for the command line
       options, and update
$PCP_PMCDCONF_PATH
. A brief description of the
pmdaweblog
command line options
       follows:
-C
Check the configuration and exit."
1154,4,pmdaweblog,"A brief description of the
pmdaweblog
command line options
       follows:
-C
Check the configuration and exit. -d
domain
Specify the
domain
number. It is absolutely crucial that
              the performance metrics
domain
number specified here is
              unique and consistent."
1154,5,pmdaweblog,"It is absolutely crucial that
              the performance metrics
domain
number specified here is
              unique and consistent. That is,
domain
should be different
              for every PMDA on the one host, and the same
domain
number
              should be used for the
pmdaweblog
PMDA on all hosts. For most installations, the default
domain
as encapsulated
              in the file
$PCP_PMDAS_DIR/weblog/domain.h
will suffice."
1154,6,pmdaweblog,"For most installations, the default
domain
as encapsulated
              in the file
$PCP_PMDAS_DIR/weblog/domain.h
will suffice. For alternate values, check
$PCP_PMCDCONF_PATH
for the
domain
values already in use on this host, and the file
$PCP_VAR_DIR/pmns/stdpmid
contains a repository of ``well
              known''
domain
assignments that probably should be avoided. -h
helpfile
Get the help text from the supplied
helpfile
rather than
              from the default location."
1154,7,pmdaweblog,"-h
helpfile
Get the help text from the supplied
helpfile
rather than
              from the default location. -i
port
Communicate with
pmcd(1)
on the specified Internet
port
(which may be a number or a name). -l
logfile
Location of the log file."
1154,8,pmdaweblog,"-l
logfile
Location of the log file. By default, a log file named
weblog.log
is written in the current directory of
pmcd(1)
when
pmdaweblog
is started, i.e. $PCP_LOG_DIR/pmcd
."
1154,9,pmdaweblog,"$PCP_LOG_DIR/pmcd
. If
              the log file cannot be created or is not writable, output
              is written to the standard error instead. -n
idlesec
If a Web server log file has not been modified for
idlesec
seconds, then the file will be closed and re-opened."
1154,10,pmdaweblog,"-n
idlesec
If a Web server log file has not been modified for
idlesec
seconds, then the file will be closed and re-opened. This
              is the only way
pmdaweblog
can detect any asynchronous
              rotation of the logs by Web server administrative scripts. The default period is 20 seconds."
1154,11,pmdaweblog,"The default period is 20 seconds. This value may be
              changed dynamically using
pmstore(1)
to modify the value of
              the performance metric
web.config.check
. -p
Communicate with
pmcd(1)
via a pipe."
1154,12,pmdaweblog,"-p
Communicate with
pmcd(1)
via a pipe. -S
num
Specify the maximum number of Web servers per
sproc
. It
              may be desirable (from a latency and load balancing
              perspective) or necessary (due to file descriptor limits)
              to delegate responsibility for scanning the Web server log
              files to several
sprocs
."
1154,13,pmdaweblog,"It
              may be desirable (from a latency and load balancing
              perspective) or necessary (due to file descriptor limits)
              to delegate responsibility for scanning the Web server log
              files to several
sprocs
. pmdaweblog
will ensure that each
sproc
handles the log files for at most
num
Web servers. The default value is 80 Web servers per
sproc
."
1154,14,pmdaweblog,"The default value is 80 Web servers per
sproc
. -t
delay
To avoid the need to scan a lot of information from the Web
              server logs in response to a single request for performance
              metrics, all log files will be checked at least once every
delay
seconds. The default is 15 seconds."
1154,15,pmdaweblog,"The default is 15 seconds. This value may
              by changed dynamically using
pmstore(1)
to modify the value
              of the performance metric
web.config.catchup
. -u
socket
Communicate with
pmcd(1)
via the given Unix domain
socket
."
1154,16,pmdaweblog,"-u
socket
Communicate with
pmcd(1)
via the given Unix domain
socket
. -U
User account under which to run the agent. The default is
              the unprivileged ""pcp"" account in current versions of PCP,
              but in older versions the superuser account (""root"") was
              used by default."
1155,0,pmdakernel,"Each supported platform has a kernel Performance Metrics Domain
       Agent (PMDA) which extracts performance metrics from the kernel of
       that platfrom. A variety of platform-specific metrics are
       available, with an equally varied set of access mechanisms -
       typically this involves special system calls, or reading from
       files in kernel virtual filesystems such as the Linux
sysfs
and
procfs
filesystems. The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible."
1155,1,pmdakernel,"The platform kernel PMDA is one of the most critical components of
       the PCP installation, and must be as efficient and reliable as
       possible. In all installations the default kernel PMDA will be
       installed as a shared library and thus executes directly within
       the
pmcd(1)
process. This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required)."
1155,2,pmdakernel,"This slightly reduces overheads associated
       with querying the metadata and values associated with these
       metrics (no message passing is required). Unlike many other PMDAs, the kernel PMDA exports a number of
       metric namespace subtrees, such as kernel, network, swap, mem,
       ipc, filesys, nfs, disk and hinv (hardware inventory). Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA."
1155,3,pmdakernel,"Despite usually running as shared libraries, most installations
       also include a stand-alone executable for the kernel PMDA. This
       is to aid profiling and debugging activities, with
dbpmda(1)
for
       example. In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account."
1155,4,pmdakernel,"In this case (but not for shared libraries), the
       following command line options are available:
-A
Disables use of the credentials provided by
PMAPI
client
            tools, and simply runs everything under the ""root"" account. Only enable this option if you understand the risks involved,
            and are sure that all remote accesses will be from benevolent
            users. If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to."
1155,5,pmdakernel,"If enabled, unauthenticated remote
PMAPI
clients will
            be able to access potentially sensitive performance metric
            values which an unauthenticated
PMAPI
client usually would
            not be able to. Refer to CVE-2012-3419 for additional
            details. -d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent."
1155,6,pmdakernel,"-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file."
1155,7,pmdakernel,"-l
Location of the log file. By default, a log file named
[platform].log
is written in the current directory of
pmcd(1)
when
pmda[platform]
is started, i.e. $PCP_LOG_DIR/pmcd
."
1155,8,pmdakernel,"$PCP_LOG_DIR/pmcd
. If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent."
1155,9,pmdakernel,"If
            the log file cannot be created or is not writable, output is
            written to the standard error instead. -U
User account under which to run the agent. The default is
            either the privileged ""root"" account on some platforms
            (Linux, for example) or the unprivileged ""pcp"" account
            (wherever possible)."
1156,0,pmdazswap,"pmdazswap
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values about compressed swap operation, as tracked
       by the
zswap
Linux kernel module. Zswap is a lightweight compressed cache for swap pages. It takes
       pages that are in the process of being swapped out and attempts to
       compress them into a dynamically allocated RAM-based memory pool."
1156,1,pmdazswap,"It takes
       pages that are in the process of being swapped out and attempts to
       compress them into a dynamically allocated RAM-based memory pool. Zswap trades CPU cycles for potentially reduced swap I/O. This
       tradeoff can also result in a performance improvement if reads
       from the compressed cache are faster than reads from a swap
       device."
1156,2,pmdazswap,"Zswap trades CPU cycles for potentially reduced swap I/O. This
       tradeoff can also result in a performance improvement if reads
       from the compressed cache are faster than reads from a swap
       device. This PMDA exports metrics about pool size, number of pages stored,
       and various counters for the reasons pages are rejected."
1157,0,pmdbg,"The components of the Performance Co-Pilot (PCP) use a global
       mechanism to control diagnostic and debug output. Historically
       this was a vector of bit-fields but this was later replaced by an
       array of debug options. All of the bit-field debug controls have
       an equivalent in the new scheme, but some new debug options cannot
       be represented in the old bit-field scheme."
1157,1,pmdbg,"All of the bit-field debug controls have
       an equivalent in the new scheme, but some new debug options cannot
       be represented in the old bit-field scheme. pmdbg
with a
-l
option prints out all the debug options. If there
       is no
-g
and no
-o
option then the output lists the name of each
       option and some descriptive text."
1157,2,pmdbg,"If there
       is no
-g
and no
-o
option then the output lists the name of each
       option and some descriptive text. With the
-l
and
-g
options the descriptive text is replaced with
       an expression that can be used to set or print the corresponding
       debug flag in
gdb(1)
. With the
-l
and
-o
options the output is for only the old bit-
       fields with the mnemonic and decimal values of each the bit-field
       along with some descriptive text."
1157,3,pmdbg,"With the
-l
and
-o
options the output is for only the old bit-
       fields with the mnemonic and decimal values of each the bit-field
       along with some descriptive text. Obviously the
-o
and
-g
options are mutually exclusive. pmdbg
with a
-D
option parses the list of
names
(s) using
__pmParseDebug(3)
and reports the corresponding decimal value."
1157,4,pmdbg,"pmdbg
with a
-D
option parses the list of
names
(s) using
__pmParseDebug(3)
and reports the corresponding decimal value. This use is not required in the new scheme, but for the old bit-
       fields scheme it was useful when debugging and wanting to set the
       internal value of the control vector (
pmDebug
) via a debugger,
       e.g. gdb(1)
."
1157,5,pmdbg,"gdb(1)
. For the new scheme, the same effect can be achieved
       using the name of the option(s) and calling
pmSetDebug(3)
from
       within the debugger. The alternative usage also relates to the old bit-field scheme and
       the
code
arguments are values for the debug vector, and the bit-
       fields that are enabled by each of these values is listed."
1157,6,pmdbg,"The alternative usage also relates to the old bit-field scheme and
       the
code
arguments are values for the debug vector, and the bit-
       fields that are enabled by each of these values is listed. Each
code
may be an integer, a hexadecimal value or a hexadecimal
       value prefixed by either ``0x'' or ``0X''. Most applications using the facilities of the PCP support a
-D
name
[,
name
...]  command-line syntax to enable debug control using
       the name(s) of the desired debug options."
1157,7,pmdbg,"Most applications using the facilities of the PCP support a
-D
name
[,
name
...]  command-line syntax to enable debug control using
       the name(s) of the desired debug options. Alternatively the initial value of the debug control flags may be
       set to either a value
N
(old scheme) or a comma-separated list if
       option name(s) (new scheme) using the environment variable
$PCP_DEBUG
, provided the applications use
pmGetOptions(3)
to
       process command line options and arguments. If both mechanisms
       are used the effect is additive, so the resultant flags are those
       set via
$PCP_DEBUG
combined with those set via any
-D
command line
       options."
1158,0,pmdazfs,"pmdazfs
is a Performance Metrics Domain Agent (PMDA) which
       extracts performance metrics describing the state of the ZFS
       filesystem from the stats files located in /proc. The
zfs
PMDA exports metrics that measure information about
       caching (ARC, L2ARC, ZIL, VDEV), buffering, RAIDZ, dnode
       operations and pools IO. A brief description of the
pmdazfs
command line options follows:
-d
The performance metrics
domain
number must be set to a unique
            value."
1158,1,pmdazfs,"A brief description of the
pmdazfs
command line options follows:
-d
The performance metrics
domain
number must be set to a unique
            value. -l
Location of the log file. By default, a log file named
zfs.log
is written in the current directory of
pmcd(1)
when
pmdazfs
is started, i.e."
1158,2,pmdazfs,"By default, a log file named
zfs.log
is written in the current directory of
pmcd(1)
when
pmdazfs
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log file
            cannot be created or is not writable, output is written to
            the standard error instead."
1159,0,pmdiff,"pmdiff
compares the average values for every metric in either one
       or two sets of archives, in a given time window, for changes that
       are likely to be of interest when searching for performance
       regressions. The archive specifiers
archive1
and
archive2
may be comma-
       separated lists of names, each of which may be the base name of an
       archive or the name of a directory containing one or more
       archives. Each archive in the resulting set of archives must have
       been previously created using
pmlogger(1)
."
1159,1,pmdiff,"Each archive in the resulting set of archives must have
       been previously created using
pmlogger(1)
. The
pmlogsummary(1)
utility is used to obtain the average values used for comparison. There are two sorts of invocation of the tool: with either one or
       two sets of archives."
1159,2,pmdiff,"There are two sorts of invocation of the tool: with either one or
       two sets of archives. In the first case, the only sensible command line requires use of
       all four time window arguments. These are specified using the
       same time window format described in
PCPIntro(1)
, and are
-S
/
--start
and
-T
/
--finish
for the start and end times of the
       first time window of interest in the archive set, and
-B
/
--before
and
-E
/
--end
for the start and end times of the second time window
       of interest."
1159,3,pmdiff,"These are specified using the
       same time window format described in
PCPIntro(1)
, and are
-S
/
--start
and
-T
/
--finish
for the start and end times of the
       first time window of interest in the archive set, and
-B
/
--before
and
-E
/
--end
for the start and end times of the second time window
       of interest. In the second case, with two sets of archives, the
-B
/
--before
and
-E
/
--end
options might be unnecessary. This might be the case,
       for example, when comparing the same time window of two
       consecutive days (usually two separate sets of archives), or a
       time window on the same day of different weeks."
1159,4,pmdiff,"This might be the case,
       for example, when comparing the same time window of two
       consecutive days (usually two separate sets of archives), or a
       time window on the same day of different weeks. In either case,
pmdiff
produces a sorted summary of those metrics
       in the specified window whose values have deviated the most from a
       minimal threshold. The level of deviation is calculated by
       dividing the average value of each metric in both logs, and then
       calculating whether the ratio falls outside of a range considered
       normal."
1159,5,pmdiff,"The level of deviation is calculated by
       dividing the average value of each metric in both logs, and then
       calculating whether the ratio falls outside of a range considered
       normal. This ratio can be adjusted using the
-q
/
--threshold
option, and by default it is 2 (i.e. report all metrics with
       average values that have more than doubled in the two time windows
       or more than halved in the two time windows)."
1159,6,pmdiff,"report all metrics with
       average values that have more than doubled in the two time windows
       or more than halved in the two time windows). If the baseline value is zero and the comparison value is non-
       zero, the ratio is reported as ``|+|'' (infinitely large). If the
       comparison value is zero and the baseline value is non-zero, the
       ratio is reported as ``|-|'' (infinitely small)."
1159,7,pmdiff,"If the
       comparison value is zero and the baseline value is non-zero, the
       ratio is reported as ``|-|'' (infinitely small). Reported metrics are sorted in ascending ratio order. Should any metrics be present in one window but missing from the
       other, a diagnostic will be displayed listing each missing metric
       and the archive set from which it was missing."
1159,8,pmdiff,"Reported metrics are sorted in ascending ratio order. Should any metrics be present in one window but missing from the
       other, a diagnostic will be displayed listing each missing metric
       and the archive set from which it was missing. Metrics with counter semantics are converted to rates before being
       evaluated."
1160,0,pmdazimbra,"pmdazimbra
is a Performance Metrics Domain Agent (PMDA) which
       exports metric values from several subsystems of the Zimbra Suite.

       Further details on Zimbra can be found at
http://www.zimbra.com/
."
1161,0,pmlogdump,"pmlogdump
dumps assorted control, metadata, index and state
       information from the files of a Performance Co-Pilot (PCP)
       archive. The archive has the base name
archive
and must have been
       previously created using
pmlogger(1)
. Alternatively
archive
is
       the name of a directory that contains a set of PCP archives than
       could be opened with
pmNewContext(3)
."
1161,1,pmlogdump,"Alternatively
archive
is
       the name of a directory that contains a set of PCP archives than
       could be opened with
pmNewContext(3)
. Historically,
pmlogdump
was known as
pmdumplog
but the latter name
       is not consistent with the other PCP commands that operate on PCP
       archives, so
pmlogdump
is preferred, however
pmdumplog
is
       maintained for backwards compatibility. Normally
pmlogdump
operates on the distributed Performance Metrics
       Name Space (PMNS), however if the
-n
option is specified an
       alternative local PMNS is loaded from the file
pmnsfile
."
1161,2,pmlogdump,"Normally
pmlogdump
operates on the distributed Performance Metrics
       Name Space (PMNS), however if the
-n
option is specified an
       alternative local PMNS is loaded from the file
pmnsfile
. If any
metricname
arguments appear, the report will be restricted
       to information relevant to the named performance metrics. If
metricname
is a non-leaf node in the namespace (see
PMNS(5)
), then
pmlogdump
will recursively descend the archive's namespace and
       report on all leaf nodes."
1161,3,pmlogdump,"If any
metricname
arguments appear, the report will be restricted
       to information relevant to the named performance metrics. If
metricname
is a non-leaf node in the namespace (see
PMNS(5)
), then
pmlogdump
will recursively descend the archive's namespace and
       report on all leaf nodes. Command line options control the specific information to be
       reported."
1162,0,pmdumptext,"pmdumptext
outputs the values of performance metrics collected
       live or from a set of Performance Co-Pilot (PCP) archives. By
       default, the metric values are displayed in tab separated columns,
       prefixed by a timestamp. Unless directed to another host by the
-h
option, or to one or
       more sets of archives by the
-a
option, or an explict host: or
       archive/ prefix in the
metric
(see below for more information),
pmdumptext
will contact the Performance Metrics Collector Daemon
       (PMCD) on the local host to obtain the required information."
1162,1,pmdumptext,"Unless directed to another host by the
-h
option, or to one or
       more sets of archives by the
-a
option, or an explict host: or
       archive/ prefix in the
metric
(see below for more information),
pmdumptext
will contact the Performance Metrics Collector Daemon
       (PMCD) on the local host to obtain the required information. pmdumptext
may be run in interactive mode with the
-i
option which
       displays the values in equal width columns. Without this option,
       no attempt is made to line up any values allowing the output to be
       easily parsed by other applications."
1162,2,pmdumptext,"Without this option,
       no attempt is made to line up any values allowing the output to be
       easily parsed by other applications. The format of the output can be further controlled by changing the
       precision of the values with
-P
, the width of the columns with
-w
,
       and the format of the values with the
-G
and
-F
options for the
       shortest of scientific or fixed digits, and a fixed width format,
       respectively. By default
pmdumptext
will scale metric values to ``canonical''
       units of bytes, seconds and counts."
1162,3,pmdumptext,"By default
pmdumptext
will scale metric values to ``canonical''
       units of bytes, seconds and counts. The one exception is with the
-r
option where the values are not scaled. The
-u
option reports
       the units of each metric."
1162,4,pmdumptext,"The
-u
option reports
       the units of each metric. The
metrics
to be dumped can be listed on the command line, in a
config
file, or piped to
pmdumptext
on
stdin
. A metric consists
       of an optional source (host or archive), the metric name, and an
       optional instance list immediately after the name."
1162,5,pmdumptext,"A metric consists
       of an optional source (host or archive), the metric name, and an
       optional instance list immediately after the name. A colon is
       used to separate a host name from the metric, and a forward slash
       (``/'') to separate an archive name from the metric. Instances
       are enclosed in square brackets and a comma is used between each
       instance if more than one is stated."
1162,6,pmdumptext,"Instances
       are enclosed in square brackets and a comma is used between each
       instance if more than one is stated. For example, some legal
       metrics are:

               kernel.all.cpu.idle
               myhost:kernel.all.cpu.idle[cpu0,cpu3]
               /path/to/myarchive/kernel.all.cpu.idle[cpu1]

       When a
metric
does not contain a host: or archive/ prefix, e.g. kernel.all.cpu.idle above, then the source of the metric is
       determined by the following rules:
       (a) PMCD on
host
from the
-h
option if any, else
       (b) the
archive
from the first
-a
option if any, else
       (c) the host from the first
metric
prior to this one with a host:
           prefix if any, else
       (d) the archive from the first
metric
prior to this one with an
           archive/ prefix if any, else
       (e) PMCD on the local host, which is equivalent to local::
metric
."
1162,7,pmdumptext,"kernel.all.cpu.idle above, then the source of the metric is
       determined by the following rules:
       (a) PMCD on
host
from the
-h
option if any, else
       (b) the
archive
from the first
-a
option if any, else
       (c) the host from the first
metric
prior to this one with a host:
           prefix if any, else
       (d) the archive from the first
metric
prior to this one with an
           archive/ prefix if any, else
       (e) PMCD on the local host, which is equivalent to local::
metric
. The format of a
metric
is further described in
PCPIntro(1)
in the
       PERFORMANCE METRIC SPECIFICATIONS section. A normalization value
       may optionally follow a metric name in a
config
file or on
stdin
."
1162,8,pmdumptext,"A normalization value
       may optionally follow a metric name in a
config
file or on
stdin
. The metric value will be scaled by this value. For example, if
       the file system ``/dev/root'' has a capacity of 1965437 bytes,
       then the percentage of the file system that is used could be
       dumped with this
config
:

               filesys.used[/dev/root] 19654.37

       A normalization value may not be used with
metrics
specified as
       command line arguments."
1162,9,pmdumptext,"For example, if
       the file system ``/dev/root'' has a capacity of 1965437 bytes,
       then the percentage of the file system that is used could be
       dumped with this
config
:

               filesys.used[/dev/root] 19654.37

       A normalization value may not be used with
metrics
specified as
       command line arguments. A metric name is not required to be a leaf node in the Performance
       Metrics Name Space (PMNS), except when one or more instances are
       specified. For example, to dump all file system metrics, only
filesys
is required to dump
filesys.capacity
,
filesys.used
,
filesys.free
etc."
1163,0,pmgetopt,"pmgetopt
is used to perform command line option parsing for shell
       scripts used in the Performance Co-Pilot (PCP toolkit). It is
       also used to generate usage messages for those scripts. The parameters given to
pmgetopt
take two forms: initially,
       options specific to
pmgetopt
itself are passed in, and terminated
       using the -- mechanism."
1163,1,pmgetopt,"It is
       also used to generate usage messages for those scripts. The parameters given to
pmgetopt
take two forms: initially,
       options specific to
pmgetopt
itself are passed in, and terminated
       using the -- mechanism. Thereafter, all of the parameters passed
       into the shell script should be passed (usually this is simply the
       ""$@"" variable)."
1164,0,pmfind_check,"This shell script is used to integrate the Performance Co-Pilot
       (see
PCPIntro(1)
) collector service discovery mechanisms with
pmie(1)
and
pmlogger(1)
service administration, such that multiple
       collector hosts can be monitored from a single centralized host. It is important to note that the
pmfind
service is tightly
       integrated with the
pmie
and
pmlogger
services, and these must
       also be enabled if the services are to be started for each
       collector system that
pmfind
discovers. pmfind_check
is designed to be enabled via a service management
       daemon such as
systemd(1)
on Linux."
1164,1,pmfind_check,"pmfind_check
is designed to be enabled via a service management
       daemon such as
systemd(1)
on Linux. It is run from a system timer
       (either by
systemd
or by
cron
on other systems). Once per timer
       interval
pmfind
attempts discovery of PCP collector systems."
1164,2,pmfind_check,"Once per timer
       interval
pmfind
attempts discovery of PCP collector systems. For
       each unique system found
pmfind_check
creates
pmie_check
and
pmlogger_check
control file entries, such that these latter
       process can manage one
pmie
and
pmlogger
service for each
       discovered collector system. When run through
systemd
these processes will be launched
       immediately because
systemd
monitors the service control files for
       changes."
1164,3,pmfind_check,"When run through
systemd
these processes will be launched
       immediately because
systemd
monitors the service control files for
       changes. With
systemd
one may also initiate an immediate service
       discovery with
pmfind
and
pmfind_check
by modifying the
$PCP_SYSCONF_DIR/pmfind
directory in any way. When run from
cron
the next (also timer-based) invocation of
pmie_check
or
pmlogger_check
will start and manage the associated
pmie
and
pmlogger
processes."
1164,4,pmfind_check,"When run from
cron
the next (also timer-based) invocation of
pmie_check
or
pmlogger_check
will start and manage the associated
pmie
and
pmlogger
processes. The control file entries created by
pmfind_check
follow the
       convention of individual files for each collector host. The files
       are named using the (unique) source identifier that
pmfind
calculates."
1164,5,pmfind_check,"The control file entries created by
pmfind_check
follow the
       convention of individual files for each collector host. The files
       are named using the (unique) source identifier that
pmfind
calculates. This identifier is a hash calculated based on (non-
       optional) context labels available from every collector host, and
       is the same source identifier reported and used by
pminfo(1)
and
pmseries(1)
."
1165,0,pmhostname,"pmhostname
reports the name of the host
hostname
as returned by
gethostbyname(3)
. If
hostname
is not specified, then the local host name is
       retrieved using
gethostname(2)
and this is than passed to
gethostbyname(3)
. pmhostname
provides a service for shell scripts that mimics the
       logic formerly used by Performance Co-Pilot applications when
       trying to determine the official name of a host."
1165,1,pmhostname,"pmhostname
provides a service for shell scripts that mimics the
       logic formerly used by Performance Co-Pilot applications when
       trying to determine the official name of a host. PCP applications
       no longer use DNS-based heuristics, and therefore this command is
deprecated
. If
gethostbyname(3)
fails, the input host name (either
hostname
or
       the result from calling
gethostname(2)
) is reported."
1166,0,pmerr,"pmerr
accepts standard Performance Co-Pilot (PCP) error codes via
       the
code
argument(s) and generates the corresponding error text.

       Each
code
may be an integer, a hexadecimal value or a hexadecimal
       value prefixed by either ``0x'' or ``0X''.

       Error codes must be less than zero, so if
code
is a positive
       number, a warning message is produced, and the negated value is
       used."
1167,0,pmgenmap,"Given one or more lists of metric names in
infile
or on standard
       input,
pmgenmap
generates C declarations and
cpp(1)
macros
       suitable for use across the Performance Metrics Programming
       Interface (PMAPI) on standard output. The declarations produced by
pmgenmap
simplify the coding for
       client applications using the PMAPI. The input should consist of one or more lists of metric names of
       the form

            listname {
                metricname1 symbolname1
                metricname2 symbolname2
                ..."
1167,1,pmgenmap,"The input should consist of one or more lists of metric names of
       the form

            listname {
                metricname1 symbolname1
                metricname2 symbolname2
                ... }

       which will generate C and
cpp(1)
declarations of the form

            char *listname[] = {
            #define symbolname1 0
                ""metricname1"",
            #define symbolname2 1
                ""metricname2"",
                ... };

       The array declarations produced are suitable as parameters to
pmLookupName(3)
and the
#define
d constants may be used to index
       the
vset
s in the
pmResult
structure returned by a
pmFetch(3)
call."
1167,2,pmgenmap,"};

       The array declarations produced are suitable as parameters to
pmLookupName(3)
and the
#define
d constants may be used to index
       the
vset
s in the
pmResult
structure returned by a
pmFetch(3)
call. Obviously,
listname
must conform to the C identifier naming rules,
       each
symbolname
must conform to the
cpp(1)
macro naming rules, and
       each
metricname
is expected to be a valid performance metrics name
       (see
PMNS(5)
for more details). The input may include
sh
-style comment lines, i.e."
1167,3,pmgenmap,"The input may include
sh
-style comment lines, i.e. with a `
#
' as
       the first non-blank character of a line, and these are translated
       on output to either single line or multi-line C comments in the
       K&R style. For example, the input:

            # leading block of multi-line comments
            # initialization group
            foo {
                    a.b.c   ONE
                    d.e.f.g TWO
                    # embedded block of multi-lines
                    # comments and boring pad text
                    xx.yy.zz        THREE
            }

            # trailing single line comment

       Produces the output:

            /*
             * leading block of multi-line comments
             * initialization group
             */
            char *foo[] = {
            #define ONE 0
                    ""a.b.c"",
            #define TWO 1
                    ""d.e.f.g"",
            /*
             * embedded block of multi-lines
             * comments and boring pad text
             */
            #define THREE 2
                    ""xx.yy.zz"",

            };

            /* trailing single line comment */"
1168,0,pmfind,"pmfind
searches for instances of the specified PCP service being
       advertised on the network and prints a list of URLs corresponding
       to the services discovered.  It can be used in conjunction with
pmfind_check(1)
to automate the monitoring of remote PCP collector
       systems."
1169,0,pmie2col,"pmie2col
is a simple tool that converts output from
pmie(1)
into
       regular column format. Each column is 7 characters wide (by
       default, may be changed with the
-w
option) with a single space
       between columns. That single space can be substituted with an
       alternate delimiter using the
-d
option (this is useful for
       importing the data into a spreadsheet, for example)."
1169,1,pmie2col,"That single space can be substituted with an
       alternate delimiter using the
-d
option (this is useful for
       importing the data into a spreadsheet, for example). The precision of the tabulated values from
pmie
can be specified
       with the
-p
option (default is 2 decimal places). This option can
       and will override any width setting in order to present the
       requested precision."
1169,2,pmie2col,"This option can
       and will override any width setting in order to present the
       requested precision. The
pmie(1)
configuration must follow these rules:

       (1)    Each
pmie(1)
expression is of the form ``NAME = expr;''. NAME will be used as the column heading, and must contain
              no white space, although special characters can be escaped
              by enclosing NAME in single quotes."
1169,3,pmie2col,"NAME will be used as the column heading, and must contain
              no white space, although special characters can be escaped
              by enclosing NAME in single quotes. (2)    The ``expr'' must be a valid
pmie(1)
expression that
              produces a singular value. In addition,
pmie(1)
must be run with the
-v
command line option."
1169,4,pmie2col,"(2)    The ``expr'' must be a valid
pmie(1)
expression that
              produces a singular value. In addition,
pmie(1)
must be run with the
-v
command line option. It is also possible to use the
-e
command line to
pmie(1)
and
       output lines will be prefixed by a timestamp."
1170,0,pmval,"pmval
prints current or archived values for the nominated
       performance metric. The metric of interest is named in the
metricname
argument, subject to instance qualification with the
-i
flag as described below. Unless directed to another host by the
-h
option, or to a set of
       archives by the
-a
or
-U
options,
pmval
will contact the
       Performance Metrics Collector Daemon (PMCD) on the local host to
       obtain the required information."
1170,1,pmval,"Unless directed to another host by the
-h
option, or to a set of
       archives by the
-a
or
-U
options,
pmval
will contact the
       Performance Metrics Collector Daemon (PMCD) on the local host to
       obtain the required information. The
metricname
argument may also be given in the metric
       specification syntax, as described in
PCPIntro(1)
, where the
       source, metric and instance may all be included in the
metricname
,
       e.g. thathost:kernel.all.load[""1 minute""]."
1170,2,pmval,"thathost:kernel.all.load[""1 minute""]. When this format is
       used, none of the
-h
or
-a
or
-U
options may be specified. When using the metric specification syntax, the ``hostname''
@
is
       treated specially and causes
pmval
to use a local context to
       collect metrics from PMDAs on the local host without PMCD."
1170,3,pmval,"When using the metric specification syntax, the ``hostname''
@
is
       treated specially and causes
pmval
to use a local context to
       collect metrics from PMDAs on the local host without PMCD. Only
       some metrics are available in this mode. When processing a set of archives,
pmval
may relinquish its own
       timing control, and operate under the control of a a
pmtime(1)
process that uses a GUI dialog to provide timing control."
1170,4,pmval,"When processing a set of archives,
pmval
may relinquish its own
       timing control, and operate under the control of a a
pmtime(1)
process that uses a GUI dialog to provide timing control. In this
       case, either the
-g
option should be used to start
pmval
as the
       sole client of a new
pmtime(1)
instance, or
-p
should be used to
       attach
pmval
to an existing
pmtime(1)
instance via the IPC channel
       identified by the
port
argument. The
-S
,
-T
,
-O
and
-A
options may be used to define a time window
       to restrict the samples retrieved, set an initial origin within
       the time window, or specify a ``natural'' alignment of the sample
       times; refer to
PCPIntro(1)
for a complete description of these
       options."
1170,5,pmval,"The
-S
,
-T
,
-O
and
-A
options may be used to define a time window
       to restrict the samples retrieved, set an initial origin within
       the time window, or specify a ``natural'' alignment of the sample
       times; refer to
PCPIntro(1)
for a complete description of these
       options. The output from
pmval
is directed to standard output. The
       following symbols may occasionally appear, in place of a metric
       value, in
pmval
output:  A question mark symbol (?) indicates that
       a value is no longer available for that metric instance."
1170,6,pmval,"The
       following symbols may occasionally appear, in place of a metric
       value, in
pmval
output:  A question mark symbol (?) indicates that
       a value is no longer available for that metric instance. An
       exclamation mark (!)  indicates that a 64-bit counter wrapped
       during the sample. pmevent
is an alias for
pmval
."
1171,0,pmie_check,"This series of shell scripts and associated control files may be
       used to create a customized regime of administration and
       management for the Performance Co-Pilot (see
PCPIntro(1)
)
       inference engine,
pmie(1)
. pmie_check
may be run at any time of the day and verifies that a
       desired set of
pmie
processes is running. If not, it (re-)starts
       any missing inference engine processes."
1171,1,pmie_check,"If not, it (re-)starts
       any missing inference engine processes. pmie_daily
is intended to be run once per day, preferably in the
       early morning, as soon after midnight as practicable. Its task is
       to rotate the log files for the running
pmie
processes - these
       files may grow without bound if the ``print'' action is used, or
       any other
pmie
action writes to its stdout/stderr streams."
1171,2,pmie_check,"pmie_daily
is intended to be run once per day, preferably in the
       early morning, as soon after midnight as practicable. Its task is
       to rotate the log files for the running
pmie
processes - these
       files may grow without bound if the ``print'' action is used, or
       any other
pmie
action writes to its stdout/stderr streams. After
       some period, old
pmie
log files are discarded."
1172,0,pmie,"pmie
accepts a collection of arithmetic, logical, and rule
       expressions to be evaluated at specified frequencies. The base
       data for the expressions consists of performance metrics values
       delivered in real-time from any host running the Performance
       Metrics Collection Daemon (PMCD), or using historical data from
       Performance Co-Pilot (PCP) archives. As well as computing arithmetic and logical values,
pmie
can
       execute actions (popup alarms, write system log messages, and
       launch programs) in response to specified conditions."
1172,1,pmie,"As well as computing arithmetic and logical values,
pmie
can
       execute actions (popup alarms, write system log messages, and
       launch programs) in response to specified conditions. Such
       actions are extremely useful in detecting, monitoring and
       correcting performance related problems. The expressions to be evaluated are read from configuration files
       specified by one or more
filename
arguments."
1172,2,pmie,"The expressions to be evaluated are read from configuration files
       specified by one or more
filename
arguments. In the absence of
       any
filename
, expressions are read from standard input. Output from
pmie
is directed to standard output and standard error
       as follows:
stdout
Expression values printed in the verbose
-v
mode and the
            output of
print
actions."
1172,3,pmie,"In the absence of
       any
filename
, expressions are read from standard input. Output from
pmie
is directed to standard output and standard error
       as follows:
stdout
Expression values printed in the verbose
-v
mode and the
            output of
print
actions. stderr
Error and warning messages for any syntactic or semantic
            problems during expression parsing, and any semantic or
            performance metrics availability problems during expression
            evaluation."
1173,0,pmie_dump_stats,"Each
pmie(1)
process maintains a file of state and statistics in
       binary files in the
$PCP_TMP_DIR/pmie
directory, named with the
       process' PID. These files are used by the
pmcd
PMDA to instantiate the
pmcd.pmie
performance metrics. pmie_dump_stats
is a stand alone utility that dumps the contents
       of these files in a terse, but script-friendly format."
1173,1,pmie_dump_stats,"These files are used by the
pmcd
PMDA to instantiate the
pmcd.pmie
performance metrics. pmie_dump_stats
is a stand alone utility that dumps the contents
       of these files in a terse, but script-friendly format. It is
       designed for use in the
pmiectl
(1) script."
1174,0,pmjson,"pmjson
is used to manipulate JSON (JavaScript Object Notation)
       formatted text used in the Performance Co-Pilot (PCP toolkit).  It
       can produce minimal and human readable output formats when it is
       supplied with valid JSON input."
1175,0,pmie_check,"This series of shell scripts and associated control files may be
       used to create a customized regime of administration and
       management for the Performance Co-Pilot (see
PCPIntro(1)
)
       inference engine,
pmie(1)
. pmie_check
may be run at any time of the day and verifies that a
       desired set of
pmie
processes is running. If not, it (re-)starts
       any missing inference engine processes."
1175,1,pmie_check,"If not, it (re-)starts
       any missing inference engine processes. pmie_daily
is intended to be run once per day, preferably in the
       early morning, as soon after midnight as practicable. Its task is
       to rotate the log files for the running
pmie
processes - these
       files may grow without bound if the ``print'' action is used, or
       any other
pmie
action writes to its stdout/stderr streams."
1175,2,pmie_check,"pmie_daily
is intended to be run once per day, preferably in the
       early morning, as soon after midnight as practicable. Its task is
       to rotate the log files for the running
pmie
processes - these
       files may grow without bound if the ``print'' action is used, or
       any other
pmie
action writes to its stdout/stderr streams. After
       some period, old
pmie
log files are discarded."
1176,0,pmiestatus,"pmiestatus
displays information used to identify a running
pmie(1)
process.  It is mostly used by
pmie_check(1)
and
pmie_daily(1)
when they hunt for instances of
pmie
to check against the control
       file."
1177,0,pmieconf,"pmieconf
is a utility for viewing and configuring variables from
       generalized
pmie(1)
rules.  The set of generalized rules is read
       in from
rulepath
, and the output
file
produced by
pmieconf
is a
       valid input file for
pmie
."
1178,0,pcp-iostat,"pcp-iostat
reports I/O statistics for SCSI (by default) or other
       devices (if the
-x
option is specified)."
1179,0,pminfo,"pminfo
displays various types of information about performance
       metrics available through the facilities of the Performance Co-
       Pilot (PCP). The metrics of interest are named in the
metricname
arguments. If
metricname
is a non-leaf node in the PMNS, then
pminfo
will
       recursively descend the PMNS and report on all leaf nodes."
1179,1,pminfo,"If
metricname
is a non-leaf node in the PMNS, then
pminfo
will
       recursively descend the PMNS and report on all leaf nodes. If no
metricname
argument is given, the root of the PMNS is used. If the
metricname
argument is in numeric dotted notation, it is
       interpreted as either a 3-dotted
pmid
(metric identifier - domain,
       cluster, item numbers) or a 2-dotted
indom
(instance domain
       identifier - domain, serial number)."
1179,2,pminfo,"If the
metricname
argument is in numeric dotted notation, it is
       interpreted as either a 3-dotted
pmid
(metric identifier - domain,
       cluster, item numbers) or a 2-dotted
indom
(instance domain
       identifier - domain, serial number). In the
pmid
case, a reverse
       PMID-to-name lookup is performed, and in the
indom
case, the
       instance domain is reported directly. This latter mode can be
       used to report the instance domain ``one line'' and long form help
       text summaries."
1179,3,pminfo,"This latter mode can be
       used to report the instance domain ``one line'' and long form help
       text summaries. Unless directed to another host by the
-h
option, by default
pminfo
will contact the Performance Metrics Collector Daemon
       (PMCD) on the local host. The connection to a PMCD is only
       required if
pminfo
requires distributed PMNS information, and/or
       meta-data describing metrics, and/or metric values, and/or help
       text."
1179,4,pminfo,"The connection to a PMCD is only
       required if
pminfo
requires distributed PMNS information, and/or
       meta-data describing metrics, and/or metric values, and/or help
       text. The
-a
option causes
pminfo
to use the specified set of archives
       rather than connecting to a PMCD. The
-L
option causes
pminfo
to use a local context to collect
       metrics from PMDAs on the local host without PMCD."
1179,5,pminfo,"The
-L
option causes
pminfo
to use a local context to collect
       metrics from PMDAs on the local host without PMCD. Only some
       metrics are available in this mode. The
-a, -h
and
-L
options are mutually exclusive."
1180,0,pmlc,"pmlc
may be used to change those metrics and instances which a
pmlogger(1)
writes to a Performance Co-Pilot archive (see
PCPIntro(1)
), the frequency with which the metrics are collected
       and whether the logging is mandatory, advisory, on or off. It
       also reports the current logging status of metrics and instances. pmlc
may be used to control pmlogger instances on remote hosts as
       well as those on the local host."
1180,1,pmlc,"pmlc
may be used to control pmlogger instances on remote hosts as
       well as those on the local host. Normally
pmlc
operates on the distributed Performance Metrics Name
       Space (PMNS), however if the
-n
option is specified an alternative
       local PMNS is loaded from the file
pmnsfile
. If the
-P
option is specified,
pmlc
will attempt to start with a
       connection to the primary pmlogger on the local host."
1180,2,pmlc,"If the
-P
option is specified,
pmlc
will attempt to start with a
       connection to the primary pmlogger on the local host. If the
-p
option is specified, then
pmlc
will attempt to start with a
       connection to the pmlogger on this TCP/IP
port
. Alternatively, if
pid
is specified, a connection to the pmlogger instance with that
       process id will be attempted on startup."
1180,3,pmlc,"Alternatively, if
pid
is specified, a connection to the pmlogger instance with that
       process id will be attempted on startup. The
-h
option may only
       be used if
-P, -p
port
or a
pid
is also specified. In that case
pmlc
will initially connect to the specified (remote) pmlogger
       instance on
host
rather than the local host."
1180,4,pmlc,"In that case
pmlc
will initially connect to the specified (remote) pmlogger
       instance on
host
rather than the local host. If the connection to
       the specified pmlogger instance cannot be established,
pmlc
will
       start with no connection. These options typically allow the same
       file of
pmlc
commands to be directed to multiple pmlogger
       instances by varying the command line arguments."
1180,5,pmlc,"These options typically allow the same
       file of
pmlc
commands to be directed to multiple pmlogger
       instances by varying the command line arguments. Note that
-P
,
-p
port
,
pid
and
-h
are used only when making an initial connection
       to a pmlogger instance. They are not used as defaults if
       subsequent connections are made interactively (see the
connect
command below)."
1180,6,pmlc,"They are not used as defaults if
       subsequent connections are made interactively (see the
connect
command below). By default,
pmlc
reports the time of day according to the local
       timezone on the system where
pmlc
is run. The
-Z
option changes
       the timezone to
timezone
in the format of the environment variable
TZ
as described in
environ(7)
."
1180,7,pmlc,"The
-Z
option changes
       the timezone to
timezone
in the format of the environment variable
TZ
as described in
environ(7)
. The
-z
option changes the timezone
       to the timezone of the pmlogger instance from which information is
       being obtained. Only one of
-z
or
-Z
may be specified."
1180,8,pmlc,"Only one of
-z
or
-Z
may be specified. If standard input is from a tty,
pmlc
is interactive, with
       prompts. The
-i
flag may be used to force interactive behavior,
       and is typically used in conjunction with
-e
to echo all command
       input on standard output."
1181,0,pmlogbasename,"pmlogbasename
takes
name
(usually the name of one of the physical
       files in a PCP archive) and strips it of any compression suffixes
       then strips it of any PCP archive component suffixes, then reports
       the result (the basename of a PCP archive) on standard output. The compression suffixes known to PCP are:
.xz
,
.lzma
,
.bz2
,
.bz
,
.gz
,
.Z
and
.z
. The PCP archive component suffixes are:
.meta
,
.index
and
."
1181,1,pmlogbasename,"The PCP archive component suffixes are:
.meta
,
.index
and
. <n>
for
       any integer
<n>
. For the most part the stripping is purely textual and is done
       without tests for the existence of any of the associated files,
       although if
name
does not match the pattern of a valid file name
       for a PCP archive then the output is
name
without any stripping."
1181,2,pmlogbasename,"For the most part the stripping is purely textual and is done
       without tests for the existence of any of the associated files,
       although if
name
does not match the pattern of a valid file name
       for a PCP archive then the output is
name
without any stripping. The one exception is when
name
ends with
.N
where
N
is a sequence
       of 1 or more digits, in which case an ambiguity occurs. For
       example consider
name
to be
20241125.05.48
, where this could mean
       the archive basename is really
20241125.05.48
or it could mean
       this refers to volume
48
of the archive basename
20241125.05
."
1181,3,pmlogbasename,"The one exception is when
name
ends with
.N
where
N
is a sequence
       of 1 or more digits, in which case an ambiguity occurs. For
       example consider
name
to be
20241125.05.48
, where this could mean
       the archive basename is really
20241125.05.48
or it could mean
       this refers to volume
48
of the archive basename
20241125.05
. In
       the former case, the file
name
.meta
(or one of the compressed
       versions of this) should exist and
pmlogbasename
probes the
       filesystem to determine if such a file exists."
1182,0,pmlock,"pmlock
attempts to acquire an exclusive lock by creating a zero-
       sized
file
with a mode of 0. The
-i
option changes the behaviour to write
ident
into
file
,
       followed by a newline and the file mode is 0444. ident
is an
       arbitrary string, but by convention it is the process id of the
       locker followed by the name or identification of the locker
       command or script."
1182,1,pmlock,"ident
is an
       arbitrary string, but by convention it is the process id of the
       locker followed by the name or identification of the locker
       command or script. The exit status is 0 for success, 1 for failure. To release the lock, remove
file
with
rm(1)
or
unlink(2)
."
1182,2,pmlock,"The exit status is 0 for success, 1 for failure. To release the lock, remove
file
with
rm(1)
or
unlink(2)
. In the event of a failure, the
-v
option produces an explanatory
       message on
stderr
."
1183,0,pmlogmv,"A Performance Co-Pilot (PCP) archive consists of multiple files as
       created by
pmlogger(1)
. pmlogmv
allows all the files of a single
       PCP archive to be moved or renamed as a group in a single
       operation. Similarly
pmlogcp
copies all the files of single PCP
       archive in a single operation."
1183,1,pmlogmv,"Similarly
pmlogcp
copies all the files of single PCP
       archive in a single operation. The
srcname
argument identifies the target archive, and may be
       either the basename that is common to all files in that archive or
       one of the archive's files. The new archive's basename is
dstname
, except when
dstname
is an
       existing directory, in which case the files are moved or copied
       into
dstname
using the same archive basename as
srcname
."
1183,2,pmlogmv,"The new archive's basename is
dstname
, except when
dstname
is an
       existing directory, in which case the files are moved or copied
       into
dstname
using the same archive basename as
srcname
. Because PCP archives are important records of system activity,
       special care is taken to ensure the integrity of an archive's
       files. For recoverable problems encountered during the execution
       of
pmlogmv
or
pmlogcp
, all the files associated with
srcname
will
       be preserved, and no new files with the
dstname
prefix will be
       created."
1183,3,pmlogmv,"For recoverable problems encountered during the execution
       of
pmlogmv
or
pmlogcp
, all the files associated with
srcname
will
       be preserved, and no new files with the
dstname
prefix will be
       created. ``Recoverable problems'' include signals that can be
       caught (such as SIGHUP, SIGINT, SIGQUIT and SIGTERM), permissions
       issues, new files already existing, file system full events, etc. The implementation of
pmlogmv
tries to use hard links in the file
       system and so follows the semantic restrictions of
ln
(2) which for
       most systems means the directories containing both the
srcname
and
       the
dstname
PCP archive files need to be within the
same
file
       system."
1183,4,pmlogmv,"The implementation of
pmlogmv
tries to use hard links in the file
       system and so follows the semantic restrictions of
ln
(2) which for
       most systems means the directories containing both the
srcname
and
       the
dstname
PCP archive files need to be within the
same
file
       system. When this is not possible,
pmlogmv
falls back to using
cp(1)
to copy
srcname
to
dstname
. pmlogcp
always uses
cp(1)
."
1184,0,pmlogcompress,"pmlogcompress
and
pmlogdecompress
support the compression and
       decompression of the files that make up a Performance Co-Pilot
       (PCP) archive; refer to
LOGARCHIVE(5)
for an explanation of the
       various files that are components of a PCP archive. The
archive
arguments may be either the name of a single file in a
       PCP archive or the basename of a PCP archive, as in the style
       generated by
pmlogbasename(1)
. In the former case,
pmlogcompress
will compress (or
pmlogdecompress
will decompress) just that file,
       but in the latter case
pmlogcompress
will attempt to compress (or
       for
pmlogdecompress
to decompress)
all
the files that are part of
       the associated PCP archive."
1184,1,pmlogcompress,"The
archive
arguments may be either the name of a single file in a
       PCP archive or the basename of a PCP archive, as in the style
       generated by
pmlogbasename(1)
. In the former case,
pmlogcompress
will compress (or
pmlogdecompress
will decompress) just that file,
       but in the latter case
pmlogcompress
will attempt to compress (or
       for
pmlogdecompress
to decompress)
all
the files that are part of
       the associated PCP archive. For decompression the suffix of the name of each file associated
       with
archive
determines the decompression tool to be used."
1185,0,pmlogdump,"pmlogdump
dumps assorted control, metadata, index and state
       information from the files of a Performance Co-Pilot (PCP)
       archive. The archive has the base name
archive
and must have been
       previously created using
pmlogger(1)
. Alternatively
archive
is
       the name of a directory that contains a set of PCP archives than
       could be opened with
pmNewContext(3)
."
1185,1,pmlogdump,"Alternatively
archive
is
       the name of a directory that contains a set of PCP archives than
       could be opened with
pmNewContext(3)
. Historically,
pmlogdump
was known as
pmdumplog
but the latter name
       is not consistent with the other PCP commands that operate on PCP
       archives, so
pmlogdump
is preferred, however
pmdumplog
is
       maintained for backwards compatibility. Normally
pmlogdump
operates on the distributed Performance Metrics
       Name Space (PMNS), however if the
-n
option is specified an
       alternative local PMNS is loaded from the file
pmnsfile
."
1185,2,pmlogdump,"Normally
pmlogdump
operates on the distributed Performance Metrics
       Name Space (PMNS), however if the
-n
option is specified an
       alternative local PMNS is loaded from the file
pmnsfile
. If any
metricname
arguments appear, the report will be restricted
       to information relevant to the named performance metrics. If
metricname
is a non-leaf node in the namespace (see
PMNS(5)
), then
pmlogdump
will recursively descend the archive's namespace and
       report on all leaf nodes."
1185,3,pmlogdump,"If any
metricname
arguments appear, the report will be restricted
       to information relevant to the named performance metrics. If
metricname
is a non-leaf node in the namespace (see
PMNS(5)
), then
pmlogdump
will recursively descend the archive's namespace and
       report on all leaf nodes. Command line options control the specific information to be
       reported."
1186,0,pmlogcheck,"pmlogcheck
prints information about the nature of any invalid data
       which it detects in the files of PCP archives. Each archive has the base name
archive
and must have been
       previously created using
pmlogger(1)
. Alternatively,
archive
can
       be the name of a physical file that forms part of a PCP archive."
1186,1,pmlogcheck,"Each archive has the base name
archive
and must have been
       previously created using
pmlogger(1)
. Alternatively,
archive
can
       be the name of a physical file that forms part of a PCP archive. When multiple
archive
options are present, all of the
       corresponding PCP archives will be checked, however if the
archive
options are file names, then each associated PCP archive will be
       checked at most once."
1187,0,pmlogcompress,"pmlogcompress
and
pmlogdecompress
support the compression and
       decompression of the files that make up a Performance Co-Pilot
       (PCP) archive; refer to
LOGARCHIVE(5)
for an explanation of the
       various files that are components of a PCP archive. The
archive
arguments may be either the name of a single file in a
       PCP archive or the basename of a PCP archive, as in the style
       generated by
pmlogbasename(1)
. In the former case,
pmlogcompress
will compress (or
pmlogdecompress
will decompress) just that file,
       but in the latter case
pmlogcompress
will attempt to compress (or
       for
pmlogdecompress
to decompress)
all
the files that are part of
       the associated PCP archive."
1187,1,pmlogcompress,"The
archive
arguments may be either the name of a single file in a
       PCP archive or the basename of a PCP archive, as in the style
       generated by
pmlogbasename(1)
. In the former case,
pmlogcompress
will compress (or
pmlogdecompress
will decompress) just that file,
       but in the latter case
pmlogcompress
will attempt to compress (or
       for
pmlogdecompress
to decompress)
all
the files that are part of
       the associated PCP archive. For decompression the suffix of the name of each file associated
       with
archive
determines the decompression tool to be used."
1188,0,pmlogconf,"pmlogconf
may be used to create and modify a generic configuration
       file for the PCP archiver,
pmlogger(1)
. If
configfile
does not exist,
pmlogconf
will create a generic
       configuration file with a default set of enabled metrics and
       logging intervals. Once created,
configfile
may be used with the
-c
option to
pmlogger(1)
to select performance metrics and specify logging
       intervals for a PCP archive."
1188,1,pmlogconf,"Once created,
configfile
may be used with the
-c
option to
pmlogger(1)
to select performance metrics and specify logging
       intervals for a PCP archive. If
configfile
does exist,
pmlogconf
will prompt for input from the
       user to enable or disable groups of related performance metrics
       and to control the logging interval for each enabled group. Group selection requires a simple
y
(yes) or
n
(no) response to
       the prompt
Log this group?"
1188,2,pmlogconf,"Group selection requires a simple
y
(yes) or
n
(no) response to
       the prompt
Log this group? . Other responses at this point may be used to select additional
       control functions as follows:
m
Report the names of the metrics in the current group."
1188,3,pmlogconf,"Other responses at this point may be used to select additional
       control functions as follows:
m
Report the names of the metrics in the current group. q
Finish with group selection (quit) and make no further
                 changes to this group or any subsequent group. /
pattern
Make no change to this group but search for a group
                 containing
pattern
in the description of the group or
                 the names of the associated metrics."
1188,4,pmlogconf,"/
pattern
Make no change to this group but search for a group
                 containing
pattern
in the description of the group or
                 the names of the associated metrics. A logging interval is specified by responding to the
Logging
interval? prompt with the keywords
once
or
default
or a valid
pmlogger(1)
interval specification of the form ``
every
N
timeunits
'' or simply ``
N timeunits ''
(the
every
is optional)
       where
N
is an unsigned integer and
timeunits
is one of the
       keywords
msec
,
millisecond
,
sec
,
second
,
min
,
minute
,
hour
or the
       plural form of one of the keywords."
1188,5,pmlogconf,"prompt with the keywords
once
or
default
or a valid
pmlogger(1)
interval specification of the form ``
every
N
timeunits
'' or simply ``
N timeunits ''
(the
every
is optional)
       where
N
is an unsigned integer and
timeunits
is one of the
       keywords
msec
,
millisecond
,
sec
,
second
,
min
,
minute
,
hour
or the
       plural form of one of the keywords. When run from automated logging setup processes, the
-c
option is
       used to indicate that
pmlogconf
is in auto-create mode and no
       interactive dialog takes place. The output
configfile
has an
       additional comment message and timestamp indicating this fact, so
       that it can be identified and subsequently updated using
-c
again."
1188,6,pmlogconf,"The output
configfile
has an
       additional comment message and timestamp indicating this fact, so
       that it can be identified and subsequently updated using
-c
again. This option is not appropriate for interactive use of the tool. The
-q
option suppresses the logging interval dialog and preserves
       the current interval from
configfile
."
1188,7,pmlogconf,"This option is not appropriate for interactive use of the tool. The
-q
option suppresses the logging interval dialog and preserves
       the current interval from
configfile
. More verbose output may be enabled with the
-v
option."
1189,0,pmlogctl,"pmlogctl
may be used to manage
non-primary
instances of the
       Performance Co-Pilot (PCP) archiver
pmlogger(1)
. This would be
       most relevant in a PCP archiver ``farm'' where many
pmlogger(1)
instances would be creating archives of performance data collected
       from
pmcd(1)
on many remote hosts. The
primary
pmlogger(1)
instance is closely linked to the local
pmcd(1)
process and as a consequence shares the same control
       infrastructure, namely
systemd(1)
or the PCP
init(1)
``rc
       scripts''."
1189,1,pmlogctl,"The
primary
pmlogger(1)
instance is closely linked to the local
pmcd(1)
process and as a consequence shares the same control
       infrastructure, namely
systemd(1)
or the PCP
init(1)
``rc
       scripts''. This is why the
primary
pmlogger(1)
instance
cannot
be
       managed with
pmlogctl
. For brevity in the description below, the term ``instance'' means
       a
pmlogger(1)
instance."
1189,2,pmlogctl,"For brevity in the description below, the term ``instance'' means
       a
pmlogger(1)
instance. All instances managed by
pmlogctl
,
pmlogger_check(1)
and
pmlogger_daily(1)
abide by the following rules:

       1. Each instance is fetching performance data from a single
pmcd(1)
(i.e."
1189,3,pmlogctl,"Each instance is fetching performance data from a single
pmcd(1)
(i.e. one host), but each
pmcd(1)
may be providing
          performance data to zero, one or more
pmlogger(1)
processes
          running on one or more hosts. 2."
1189,4,pmlogctl,"2. On the local host, each
pmlogger(1)
instance must be specified
          once in a
pmlogger_check(1)
control file and
pmlogger(1)
creates archives in a unique directory, named in the 4th
          parameter of the associated control file entry (see the
          CONFIGURATION section of
pmlogger_check(1)
). 3."
1189,5,pmlogctl,"3. Each instance belongs to exactly one
class
, optionally named
          using a
$class=... assignment in the associated control file."
1189,6,pmlogctl,"assignment in the associated control file. The special
default
class is reserved for all instances that do
          not have an associated
$class=... assignment."
1189,7,pmlogctl,"assignment. For reporting
          purposes (refer to the
summary
command below), the
primary
pmlogger(1)
instance is automatically assigned to the special
primary
class. Each
pmlogctl
execution manages one or more instances updating the
       associated control files and then running
pmlogger_check(1)
to
       effect the desired change."
1189,8,pmlogctl,"Each
pmlogctl
execution manages one or more instances updating the
       associated control files and then running
pmlogger_check(1)
to
       effect the desired change. The
host
arguments are usually valid host names. For all commands
except
create
and
cond-create
(described below) the
host
arguments
       may also be
egrep
(1) regular expressions that match the
whole
of a
       valid host name, so the pattern used is actually
^
host
$
."
1189,9,pmlogctl,"For all commands
except
create
and
cond-create
(described below) the
host
arguments
       may also be
egrep
(1) regular expressions that match the
whole
of a
       valid host name, so the pattern used is actually
^
host
$
. For
       example
foo.*
(matches all host names beginning with ``foo'') or
.*foo
(matches all host names ending with ``foo'') or
.*[fF][oO][oO].*
(matches all host names containing ``foo'' in
       upper, lower or mixed case). The combination of a
class
from the optional
-c
option (or
default
) and the
host
arguments to each
command
identifies a
target of set
instances to which the
command
operation should be
       applied."
1189,10,pmlogctl,"The combination of a
class
from the optional
-c
option (or
default
) and the
host
arguments to each
command
identifies a
target of set
instances to which the
command
operation should be
       applied. The
-i
option may be used with the
create
or
cond-create
commands
       to override the instance identity that is specified in the ident
       section of the class policy file (see the CLASS POLICY FILE
       section below). Since the identifier must be unique across all
       instances and all classes, it only makes sense to use this option
       when there is a single
host
argument."
1189,11,pmlogctl,"The
-i
option may be used with the
create
or
cond-create
commands
       to override the instance identity that is specified in the ident
       section of the class policy file (see the CLASS POLICY FILE
       section below). Since the identifier must be unique across all
       instances and all classes, it only makes sense to use this option
       when there is a single
host
argument. Given the tasks that
pmlogctl
is undertaking it usually must be
       run as ``root'', the exceptions being the
status
command or when
       the
-N
option is specified."
1190,0,pmlogger_check,"pmlogger_check
and the related
pmlogger_daily(1)
tools along with
       associated control files (see
pmlogger.control(5)
) may be used to
       create a customized regime of administration and management for
       historical archives of performance data within the Performance Co-
       Pilot (see
PCPIntro(1)
) infrastructure. pmlogger_check
may be run at any time of the day and is intended
       to check that a desired set of
pmlogger(1)
processes are running. If not, it (re-)starts any missing logger processes."
1190,1,pmlogger_check,"pmlogger_check
may be run at any time of the day and is intended
       to check that a desired set of
pmlogger(1)
processes are running. If not, it (re-)starts any missing logger processes. By default,
pmlogger_check
also calls
pmlogger_daily(1)
with a
-K
option to
       execute any required archive compression tasks."
1191,0,pmlogextract,"pmlogextract
reads one or more Performance Co-Pilot (PCP) archives
       identified by
input
and creates a merged and/or reduced PCP
       archive in
output
. Each
input
argument is either a name or a
       comma-separated list of names, and each name is the name of one
       file from an archive or the base name of an archive or the name of
       a directory containing one or more archives. The nature of
       merging is controlled by the number of
input
archives, while the
       nature of data reduction is controlled by the command line
       arguments."
1191,1,pmlogextract,"The nature of
       merging is controlled by the number of
input
archives, while the
       nature of data reduction is controlled by the command line
       arguments. The
input
arguments must be archives created by
pmlogger(1)
with performance data collected from the
same
host,
       but usually over different time periods and possibly (although not
       usually) with different performance metrics being logged. If only one
input
is specified, then the default behavior simply
       copies the
input
PCP archive (with possible conversion to a newer
       version of the archive format, see
-V
below), into the
output
PCP
       archive."
1191,2,pmlogextract,"If only one
input
is specified, then the default behavior simply
       copies the
input
PCP archive (with possible conversion to a newer
       version of the archive format, see
-V
below), into the
output
PCP
       archive. When two or more PCP archives are specified as
input
,
       the archives are merged (or concatenated) and written to
output
. In the
output
archive a
<mark>
record may be inserted at a time
       just past the end of each of the
input
archive to indicate a
       possible temporal discontinuity between the end of one
input
archive and the start of the next
input
archive."
1191,3,pmlogextract,"In the
output
archive a
<mark>
record may be inserted at a time
       just past the end of each of the
input
archive to indicate a
       possible temporal discontinuity between the end of one
input
archive and the start of the next
input
archive. See the
MARK
RECORDS
section below for more information. There is no
<mark>
record after the end of the
last
(in temporal order) of the
       records from the
input
archive(s)."
1192,0,pmlogger,"pmlogger
creates the archives of performance metric values that
       may be ``played back'' by other Performance Co-Pilot (see
PCPIntro(1)
) tools. These logs form the basis of the VCR paradigm
       and retrospective performance analysis services common to the PCP
       toolkit. The mandatory argument
archive
is the base name for the physical
       files that constitute an archive."
1192,1,pmlogger,"The mandatory argument
archive
is the base name for the physical
       files that constitute an archive. The
archive
argument may
       contain
strftime(3)
meta-characters, which will be substituted
       prior to creating the archive files. When
pmlogger
is run as a
       service (see
pmlogger_daily(1)
), the standard archive base name
       template is
%Y%m%d.%H.%M
."
1192,2,pmlogger,"When
pmlogger
is run as a
       service (see
pmlogger_daily(1)
), the standard archive base name
       template is
%Y%m%d.%H.%M
. The
-V
option specifies the version for the archive that is
       generated. By default the archive version
$PCP_ARCHIVE_VERSION
(set to 3 in current PCP releases) is used, and the only values
       currently supported for
version
are 2 or 3."
1192,3,pmlogger,"By default the archive version
$PCP_ARCHIVE_VERSION
(set to 3 in current PCP releases) is used, and the only values
       currently supported for
version
are 2 or 3. Unless directed to another host by the
-h
option or when directly
       using PMDAs via the
-o
option,
pmlogger
will contact the
       Performance Metrics Collector Daemon (PMCD) on the local host and
       use that as the source of the metric values to be logged. To support the required flexibility and control over what is
       logged and when,
pmlogger
maintains an independent two level
       logging state for each instance of each performance metric."
1192,4,pmlogger,"To support the required flexibility and control over what is
       logged and when,
pmlogger
maintains an independent two level
       logging state for each instance of each performance metric. At
       the first (mandatory) level, logging is allowed to be
on
(with an
       associated interval between samples), or
off
or
maybe
. In the
       latter case, the second (advisory) level logging is allowed to be
on
(with an associated interval between samples), or
off
."
1192,5,pmlogger,"In the
       latter case, the second (advisory) level logging is allowed to be
on
(with an associated interval between samples), or
off
. The mandatory level allows universal specification that some
       metrics must be logged, or must
not
be logged. The default state
       for all instances of all metrics when
pmlogger
starts is mandatory
       maybe and advisory off."
1192,6,pmlogger,"The default state
       for all instances of all metrics when
pmlogger
starts is mandatory
       maybe and advisory off. Use
pmlc(1)
to interrogate and change the logging state once
pmlogger
is running. If a metric's state is mandatory (on or off) and a request is made
       to change it to mandatory maybe, the new state is mandatory maybe
       and advisory off."
1192,7,pmlogger,"If a metric's state is mandatory (on or off) and a request is made
       to change it to mandatory maybe, the new state is mandatory maybe
       and advisory off. If a metric's state is already advisory (on or
       off) and a request is made to change it to mandatory maybe, the
       current state is retained. It is not possible for
pmlogger
to log specific instances of a
       metric and all instances of the same metric concurrently."
1192,8,pmlogger,"It is not possible for
pmlogger
to log specific instances of a
       metric and all instances of the same metric concurrently. If
       specific instances are being logged and a request to log all
       instances is made, then all instances of the metric will be logged
       according to the new request, superseding any prior logging
       request for the metric. A request to log all instances of a
       metric will supersede any previous request to log all instances."
1192,9,pmlogger,"A request to log all instances of a
       metric will supersede any previous request to log all instances. A request to log specific instances of a metric when all instances
       are already being logged is refused. To do this one must turn off
       logging for all instances of the metric first."
1192,10,pmlogger,"To do this one must turn off
       logging for all instances of the metric first. In each case, the
       validity of the request is checked first; for example a request to
       change a metric's logging state to advisory on when it is
       currently mandatory off is never permitted (it is necessary to
       change the state to mandatory maybe first). Optionally, each system running
pmcd(1)
may also be configured to
       run a ``primary''
pmlogger
instance."
1192,11,pmlogger,"Optionally, each system running
pmcd(1)
may also be configured to
       run a ``primary''
pmlogger
instance. This
pmlogger
instance is
       launched by
$PCP_RC_DIR/pmlogger
, and is affected by the files
$PCP_SYSCONF_DIR/pmlogger/control
,
$PCP_SYSCONF_DIR/pmlogger/control.d/*
, (use
chkconfig
(8),
systemctl(1)
or similar platform-specific commands to activate or
       disable the primary
pmlogger
instance),
$PCP_SYSCONFIG_DIR/pmlogger
(environment variable settings for the
       primary
pmlogger
)
$PCP_SYSCONF_DIR/pmlogger/pmlogger.options
(command line options passed to the primary
pmlogger
) and
$PCP_VAR_DIR/config/pmlogger/config.default
(the default initial
       configuration file for the primary
pmlogger
). The primary
pmlogger
instance is identified by the
-P
option."
1192,12,pmlogger,"The primary
pmlogger
instance is identified by the
-P
option. There may be at most one ``primary''
pmlogger
instance on each
       system. The primary
pmlogger
instance (if any) must be running on
       the same host as the
pmcd(1)
to which it connects (if any), so the
-h
and
-P
options are mutually exclusive."
1192,13,pmlogger,"The primary
pmlogger
instance (if any) must be running on
       the same host as the
pmcd(1)
to which it connects (if any), so the
-h
and
-P
options are mutually exclusive. Logging of some metrics is possible even in the absence of a local
pmcd(1)
, using the ""local context"" mode of operation. This is
       activated using the
-o
option, and causes
pmlogger
to make use of
       local DSO PMDAs instead of communicating with
pmcd(1)
."
1192,14,pmlogger,"This is
       activated using the
-o
option, and causes
pmlogger
to make use of
       local DSO PMDAs instead of communicating with
pmcd(1)
. When
       operating using a local context, the
-K
option may be used to
       control the DSO PMDAs that should be made accessible. The
spec
argument conforms to the syntax described in
pmSpecLocalPMDA(3)
."
1192,15,pmlogger,"The
spec
argument conforms to the syntax described in
pmSpecLocalPMDA(3)
. More than one
-K
option may be used. When launched as a non-primary instance,
pmlogger
will exit
       immediately if the configuration file causes no metric logging to
       be scheduled."
1192,16,pmlogger,"When launched as a non-primary instance,
pmlogger
will exit
       immediately if the configuration file causes no metric logging to
       be scheduled. The
-L
option overrides this behavior, and causes a
       non-primary
pmlogger
instance to ``linger'', presumably pending
       some future dynamic re-configuration and state change via
pmlc(1)
. pmlogger
will also linger without the
-L
option being used if all
       the metrics to be logged are logged as once only metrics."
1192,17,pmlogger,"pmlogger
will also linger without the
-L
option being used if all
       the metrics to be logged are logged as once only metrics. When
       the once only metrics have been logged, a warning message will be
       generated stating that the event queue is empty and no more events
       will be scheduled. By default all diagnostics and errors from
pmlogger
are written to
       the file
pmlogger.log
in the directory where
pmlogger
is launched."
1192,18,pmlogger,"By default all diagnostics and errors from
pmlogger
are written to
       the file
pmlogger.log
in the directory where
pmlogger
is launched. The
-l
option may be used to override the default behavior. If
       the log file cannot be created or is not writable, output is
       written to standard error instead."
1192,19,pmlogger,"If
       the log file cannot be created or is not writable, output is
       written to standard error instead. If the
logfile
for the
-l
option is ""
-
"" (i.e. -l-
) then log messages are written to the
       standard output stream."
1192,20,pmlogger,"-l-
) then log messages are written to the
       standard output stream. This can be particularly useful when
       running
pmlogger
manually, rather than as a service daemon. The
-N
option directs
pmlogger
to notify a service manager,
       typically
systemd(1)
, when it has started and is about to begin
       writing PCP archives."
1192,21,pmlogger,"The
-N
option directs
pmlogger
to notify a service manager,
       typically
systemd(1)
, when it has started and is about to begin
       writing PCP archives. This option would only normally be used
       when
pmlogger
is run as a daemon service under the control of a
       service manager. For more details, see
__pmServerNotifyServiceManagerReady(3)
and
systemd(1)
."
1192,22,pmlogger,"For more details, see
__pmServerNotifyServiceManagerReady(3)
and
systemd(1)
. On
       platforms that do not use a service manager that supports
       notifications, the
-N
option is basically a no-op. If specified, the
-s
option instructs
pmlogger
to terminate after
       a certain size in records, bytes or time units has been
       accumulated."
1192,23,pmlogger,"If specified, the
-s
option instructs
pmlogger
to terminate after
       a certain size in records, bytes or time units has been
       accumulated. If
endsize
is an integer then
endsize
records will
       be written to the archive. If
endsize
is an integer suffixed by
b
or
bytes
then
endsize
bytes of the archive data will be written
       out (note, however, that archive record boundaries will not be
       broken and so this limit may be slightly surpassed)."
1192,24,pmlogger,"If
endsize
is an integer suffixed by
b
or
bytes
then
endsize
bytes of the archive data will be written
       out (note, however, that archive record boundaries will not be
       broken and so this limit may be slightly surpassed). Other viable
       file size units include:
K
,
Kb
,
KiB
,
Kbyte
,
Kilobyte
for kilobytes
       and
M
,
Mb
,
MiB
,
Mbyte
,
Megabyte
for megabytes and
G
,
Gb
,
GiB
,
Gbyte
,
Gigabyte
for gigabytes. These units may be optionally
       suffixed by an
s
and may be of mixed case."
1192,25,pmlogger,"These units may be optionally
       suffixed by an
s
and may be of mixed case. Alternatively
endsize
may be an integer or a floating point number suffixed using a time
       unit as described in
PCPIntro(1)
for the
interval
argument (to the
       standard PCP
-t
command line option). Some examples of different formats:
-s 100
-s 100bytes
-s 100K
-s 100Mb
-s 10Gbyte
-s 10mins
-s 1.5hours
The default is for
pmlogger
to run forever."
1192,26,pmlogger,"Some examples of different formats:
-s 100
-s 100bytes
-s 100K
-s 100Mb
-s 10Gbyte
-s 10mins
-s 1.5hours
The default is for
pmlogger
to run forever. The
-r
option causes the size of the physical record(s) for each
       group of metrics and the expected contribution of the group to the
       size of the PCP archive for one full day of collection to be
       reported in the log file. This information is reported the first
       time each group is successfully written to the archive."
1192,27,pmlogger,"This information is reported the first
       time each group is successfully written to the archive. The
-U
option specifies the user account under which to run
pmlogger
. The default is the current user account for interactive
       use."
1192,28,pmlogger,"The default is the current user account for interactive
       use. When run as a daemon, the unprivileged ""pcp"" account is used
       in current versions of PCP, but in older versions the superuser
       account (""root"") was used by default. The archive is potentially a multi-volume data set, and the
-v
option causes
pmlogger
to start a new volume after a certain size
       in records, bytes, or time units has been accumulated for the
       current volume."
1192,29,pmlogger,"The archive is potentially a multi-volume data set, and the
-v
option causes
pmlogger
to start a new volume after a certain size
       in records, bytes, or time units has been accumulated for the
       current volume. The format of this size specification is
       identical to that of the
-s
option (see above). The default is
       for
pmlogger
to create a single volume archive."
1192,30,pmlogger,"The default is
       for
pmlogger
to create a single volume archive. Additional volume
       switches can also be forced asynchronously by either using
pmlc(1)
or sending
pmlogger
a SIGHUP signal (see below). Note, if a
       scheduled volume switch is in operation due to the
-v
option, then
       its counters will be reset after an asynchronous switch."
1192,31,pmlogger,"Note, if a
       scheduled volume switch is in operation due to the
-v
option, then
       its counters will be reset after an asynchronous switch. Independent of any
-v
option, each volume of an archive is limited
       to no more than 2^31 bytes, so
pmlogger
will automatically create
       a new volume for the archive before this limit is reached. Normally
pmlogger
operates on the distributed Performance Metrics
       Name Space (PMNS), however if the
-n
option is specified an
       alternative local PMNS is loaded from the file
pmnsfile
."
1192,32,pmlogger,"Normally
pmlogger
operates on the distributed Performance Metrics
       Name Space (PMNS), however if the
-n
option is specified an
       alternative local PMNS is loaded from the file
pmnsfile
. Under normal circumstances,
pmlogger
will run forever (except for
       a
-s
option or a termination signal). The
-T
option may be used
       to limit the execution time using the format of time as prescribed
       by
PCPIntro(1)
."
1192,33,pmlogger,"The
-T
option may be used
       to limit the execution time using the format of time as prescribed
       by
PCPIntro(1)
. The time is interpreted within the time zone of
       the PMCD server, unless the
-y
option is given, within which case
       the time zone at this logger host is used. Some examples of different formats:
-T 10mins
-T '@ 11:30'
From this it can be seen that
-T 10mins
and
-s 10mins
perform
       identical actions."
1192,34,pmlogger,"Some examples of different formats:
-T 10mins
-T '@ 11:30'
From this it can be seen that
-T 10mins
and
-s 10mins
perform
       identical actions. Alternatively,
pmlogger
runtime may be limited to the lifetime of
       another process by using the
-p
or
--PID
option to nominate the
       PID of the process of interest. In this case the
pmlogger
will
       exit when the other process no longer exists."
1192,35,pmlogger,"In this case the
pmlogger
will
       exit when the other process no longer exists. When
pmlogger
receives a
SIGHUP
signal, the current volume of the
       archive is closed, and a new volume is opened. This mechanism (or
       the alternative mechanism via
pmlc(1)
) may be used to manage the
       growth of the archive files - once a log volume is closed, that
       file may be archived without ill-effect on the continued operation
       of
pmlogger
."
1192,36,pmlogger,"This mechanism (or
       the alternative mechanism via
pmlc(1)
) may be used to manage the
       growth of the archive files - once a log volume is closed, that
       file may be archived without ill-effect on the continued operation
       of
pmlogger
. See also the
-v
option above. When
pmlogger
receives a
SIGUSR2
signal, the current archive is
       closed, and a new archive is opened."
1192,37,pmlogger,"When
pmlogger
receives a
SIGUSR2
signal, the current archive is
       closed, and a new archive is opened. For this to succeed, the
       original
archive
argument must include
strftime(3)
meta characters
       (e.g. %Y%m%d.%H.%M
), otherwise
pmlogger
will exit because the
       archive files will already exist and
pmlogger
will not over-write
       existing archive files."
1192,38,pmlogger,"%Y%m%d.%H.%M
), otherwise
pmlogger
will exit because the
       archive files will already exist and
pmlogger
will not over-write
       existing archive files. Note that
SIGUSR2
triggers
pmlogger
to
       re-exec itself and re-parse all original arguments. This means
       that any relative time limits placed on it's termination time or
       sampling limit are reset and begin again."
1192,39,pmlogger,"This means
       that any relative time limits placed on it's termination time or
       sampling limit are reset and begin again. This only affects
       relative termination times, not absolute times e.g. -T 5s
is
       affected, but
-T 5pm
is not."
1192,40,pmlogger,"-T 5s
is
       affected, but
-T 5pm
is not. Historically the buffers for the current archive may be flushed to
       disk using the
flush
command of
pmlc(1)
, or by using the
-u
option. The current version of
pmlogger
and the
libpcp
routines
       that underpin
pmlogger
unconditionally use unbuffered writes and a
       single
fwrite(3)
for each logical record written, and so
       ``flushing'' does not force any additional data to be written to
       the file system."
1192,41,pmlogger,"The current version of
pmlogger
and the
libpcp
routines
       that underpin
pmlogger
unconditionally use unbuffered writes and a
       single
fwrite(3)
for each logical record written, and so
       ``flushing'' does not force any additional data to be written to
       the file system. The
-u
option and the
pmlc(1)
flush
command are
       retained for backwards compatibility. When launched with the
-x
option, pmlogger will accept
       asynchronous control requests on the file descriptor
fd
."
1192,42,pmlogger,"When launched with the
-x
option, pmlogger will accept
       asynchronous control requests on the file descriptor
fd
. This
       option is only expected to be used internally by PCP applications
       that support ``live record mode''. The
-m
option allows the string
note
to be appended to the map
       file for this instance of
pmlogger
in the
$PCP_TMP_DIR/pmlogger
directory."
1192,43,pmlogger,"The
-m
option allows the string
note
to be appended to the map
       file for this instance of
pmlogger
in the
$PCP_TMP_DIR/pmlogger
directory. This is currently used internally to document the file
       descriptor (
fd
) when the
-x
option is used, or to indicate that
       this
pmlogger
instance was started under the control of
pmlogger_check(1)
, (
-m pmlogger_check
) or was re-exec'd (see
execvp(3)
) due to a
SIGUSR2
signal being received as described
       above (
-m reexec
). The
-H
option allows the hostname written into the archive label
       to be overridden."
1192,44,pmlogger,"The
-H
option allows the hostname written into the archive label
       to be overridden. This mirrors the
-H
option of
pmcd(1)
, but
       allows it to be specified on the
pmlogger
process. Without this
       option, the value returned from the logged
pmcd(1)
is used."
1192,45,pmlogger,"Without this
       option, the value returned from the logged
pmcd(1)
is used. The
-C
option will cause the configuration file to be parsed and
pmlogger
will then exit without creating an output archive, so
       when
-C
is specified, the
archive
command line argument is not
       required. Any errors in the configuration file are reported."
1192,46,pmlogger,"Any errors in the configuration file are reported. The
-d
or
--directory
option may be used to specify the directory
       where the
archive
should be created. directory
may include
sh
(1)
       metacharacters, like
$(
..."
1192,47,pmlogger,"directory
may include
sh
(1)
       metacharacters, like
$(
... )
or
`
... `
or
$
var
and
pmlogger
will
       expand these to produce a final directory path."
1192,48,pmlogger,"`
or
$
var
and
pmlogger
will
       expand these to produce a final directory path. The resultant
       path must be absolute, not relative. The
-d
option is intended
       primarily for use by
pmlogger_check(1)
and normal users would not
       typically need to use the option, as the directory for
archive
is
       either implied by
archive
if it contains directory components else
       the current directory by default."
1193,0,pmlogger_daily_report,"pmlogger_daily_report
writes daily performance summary reports,
       much like those produced by
sadc
(1) and the
sa2(8)
utility. All of the command line arguments are optional and intended to be
       self explanatory. By default, the reports are not generated, but if the
pcp-zeroconf
package has been installed (there will be files in
$PCP_VAR_DIR/config/pmlogconf/zeroconf
) then the necessary metrics
       will have been included in the default
pmlogger(1)
configuration
       file and the reports will be generated."
1193,1,pmlogger_daily_report,"By default, the reports are not generated, but if the
pcp-zeroconf
package has been installed (there will be files in
$PCP_VAR_DIR/config/pmlogconf/zeroconf
) then the necessary metrics
       will have been included in the default
pmlogger(1)
configuration
       file and the reports will be generated. The reports are generated (by default) soon after midnight, once
pmlogger_daily(1)
has completed the merging of any partial
       archives to generate one archive for yesterday's activity. Each performance summary report is named
sar
XX
(where
XX
is
       yesterdays day-of-the-month)."
1193,2,pmlogger_daily_report,"Each performance summary report is named
sar
XX
(where
XX
is
       yesterdays day-of-the-month). The
outputfile
may be changed with
       the
-f
option. The report will be written to the
$PCP_LOG_DIR/sa
directory by default, but this may be changed with the
-o
option
       to a different
directory
."
1193,3,pmlogger_daily_report,"The report will be written to the
$PCP_LOG_DIR/sa
directory by default, but this may be changed with the
-o
option
       to a different
directory
. Note that there are sufficiently flexible command line options for
pmlogger_daily_report
to be used to read any
archivefile
and write
       the report to any output directory. If the
-a
option is not given, the default input
archivefile
is
$PCP_ARCHIVE_DIR/HOSTNAME/YYYYMMDD
, where
HOSTNAME
defaults to the
       local hostname (unless changed with the
-h
option) and
YYYYMMDD
is
       the base name of yesterdays merged archive, as produced by
pmlogger(1)
and
pmlogger_daily(1)
."
1193,4,pmlogger_daily_report,"If the
-a
option is not given, the default input
archivefile
is
$PCP_ARCHIVE_DIR/HOSTNAME/YYYYMMDD
, where
HOSTNAME
defaults to the
       local hostname (unless changed with the
-h
option) and
YYYYMMDD
is
       the base name of yesterdays merged archive, as produced by
pmlogger(1)
and
pmlogger_daily(1)
. If
archivefile
is a directory,
       then
pmlogger_daily_report
will use all PCP archives found in that
       directory to write the report (this is known as multi-archive
       mode, and may be considerably slower than specifying a single
       archive as the input). The reports themselves are created by the
pmrep(1)
utility using
       its default configuration file, see
pmrep.conf(5)
."
1193,5,pmlogger_daily_report,"The reports themselves are created by the
pmrep(1)
utility using
       its default configuration file, see
pmrep.conf(5)
. The
pmrep(1)
configuration entries used to write the reports is currently
       hardwired into the
pmlogger_daily_report
script. Finally, the input archives must contain sufficient metrics as
       needed by
pmrep(1)
to write the report."
1193,6,pmlogger_daily_report,"Finally, the input archives must contain sufficient metrics as
       needed by
pmrep(1)
to write the report. On platforms that support
       it, the
pcp-zeroconf
package configures PCP logging as required
       for this - hence
pmlogger_daily_report
should be used with the
pmlogger(1)
configuration that is set up by
pcp-zeroconf
. As the
       name suggests,
pcp-zeroconf
requires no additional configuration
       after installation in order to capture the required archives
       needed by
pmlogger_daily_report
."
1194,0,pmlogger_merge,"pmlogger_merge
is a helper script that is used by
pmlogger_daily(1)
when merging all of the Performance Co-Pilot
       (PCP) archives for a single host on a single day into a combined
       PCP archive. pmlogger_merge
is a wrapper script for
pmlogextract(1)
that merges
       all of the archives matching the
input-basename
arguments and
       creates a new archive using
output-name
as the base name for the
       physical files that constitute an archive. The
input-basename
arguments may contain meta characters in the style of
sh
(1)."
1194,1,pmlogger_merge,"pmlogger_merge
is a wrapper script for
pmlogextract(1)
that merges
       all of the archives matching the
input-basename
arguments and
       creates a new archive using
output-name
as the base name for the
       physical files that constitute an archive. The
input-basename
arguments may contain meta characters in the style of
sh
(1). If any of the files that are components of the
input-basename
archives has been compressed then on success
pmlogger_merge
will
       compress
output-name
using
pmlogcompress(1)
."
1195,0,pmlogpaste,"pmlogpaste
takes input text from a file or the command line, and
       writes it as a metric value in a new PCP archive. This metric
       value is timestamped with the current time, and is stored as a
       string type metric. The main purpose of this tool is to take captured output and
       preserve this in a PCP archive."
1195,1,pmlogpaste,"The main purpose of this tool is to take captured output and
       preserve this in a PCP archive. This allows, for example, the
       output of a benchmark run to be stored along with performance
       metrics captured during that run, in a single archive. Archives
       can be merged using the
pmlogextract(1)
utility."
1195,2,pmlogpaste,"This allows, for example, the
       output of a benchmark run to be stored along with performance
       metrics captured during that run, in a single archive. Archives
       can be merged using the
pmlogextract(1)
utility. pmlogpaste
uses the
LOGIMPORT(3)
library interfaces internally,
       which support the creation of archives from external sources of
       performance data."
1196,0,pmlogger_rewrite,"pmlogger_rewrite
is a helper script that is used by
pmlogger_daily(1)
when rewriting Performance Co-Pilot (PCP)
       archives. Rewriting is usually required to accommodate
       evolutionary changes in metadata so old archives can be updated
       and then merged with current archives. pmlogger_rewrite
is a wrapper script for
pmlogrewrite(1)
that will
       potentially rewrite all of the archives matching the
archive
arguments."
1196,1,pmlogger_rewrite,"pmlogger_rewrite
is a wrapper script for
pmlogrewrite(1)
that will
       potentially rewrite all of the archives matching the
archive
arguments. Each
archive
argument may be a PCP archive file name,
       the basename for the files in a PCP archive, or a directory (in
       which case all subordinate PCP archives are found by recursive
       descent). pmlogrewrite
is run with the
-i
option so rewriting is done ``in
       place''."
1196,2,pmlogger_rewrite,"Each
archive
argument may be a PCP archive file name,
       the basename for the files in a PCP archive, or a directory (in
       which case all subordinate PCP archives are found by recursive
       descent). pmlogrewrite
is run with the
-i
option so rewriting is done ``in
       place''. The
-q
option is also used, so if no rewriting is
       required then no changes are made to the archive files."
1197,0,pmlogmv,"A Performance Co-Pilot (PCP) archive consists of multiple files as
       created by
pmlogger(1)
. pmlogmv
allows all the files of a single
       PCP archive to be moved or renamed as a group in a single
       operation. Similarly
pmlogcp
copies all the files of single PCP
       archive in a single operation."
1197,1,pmlogmv,"Similarly
pmlogcp
copies all the files of single PCP
       archive in a single operation. The
srcname
argument identifies the target archive, and may be
       either the basename that is common to all files in that archive or
       one of the archive's files. The new archive's basename is
dstname
, except when
dstname
is an
       existing directory, in which case the files are moved or copied
       into
dstname
using the same archive basename as
srcname
."
1197,2,pmlogmv,"The new archive's basename is
dstname
, except when
dstname
is an
       existing directory, in which case the files are moved or copied
       into
dstname
using the same archive basename as
srcname
. Because PCP archives are important records of system activity,
       special care is taken to ensure the integrity of an archive's
       files. For recoverable problems encountered during the execution
       of
pmlogmv
or
pmlogcp
, all the files associated with
srcname
will
       be preserved, and no new files with the
dstname
prefix will be
       created."
1197,3,pmlogmv,"For recoverable problems encountered during the execution
       of
pmlogmv
or
pmlogcp
, all the files associated with
srcname
will
       be preserved, and no new files with the
dstname
prefix will be
       created. ``Recoverable problems'' include signals that can be
       caught (such as SIGHUP, SIGINT, SIGQUIT and SIGTERM), permissions
       issues, new files already existing, file system full events, etc. The implementation of
pmlogmv
tries to use hard links in the file
       system and so follows the semantic restrictions of
ln
(2) which for
       most systems means the directories containing both the
srcname
and
       the
dstname
PCP archive files need to be within the
same
file
       system."
1197,4,pmlogmv,"The implementation of
pmlogmv
tries to use hard links in the file
       system and so follows the semantic restrictions of
ln
(2) which for
       most systems means the directories containing both the
srcname
and
       the
dstname
PCP archive files need to be within the
same
file
       system. When this is not possible,
pmlogmv
falls back to using
cp(1)
to copy
srcname
to
dstname
. pmlogcp
always uses
cp(1)
."
1198,0,pmloglabel,"pmloglabel
verifies, reports on, and can modify all details of the
       labels in each of the files of a Performance Co-Pilot (PCP)
       archive. The archive has the base name
archive
and must have been
       previously created using
pmlogger(1)
. Each of the files in a PCP archive (metadata, temporal index, and
       one or more data volumes) must contain a valid label at the start,
       else the PCP tools will refuse to open the archive at all."
1198,1,pmloglabel,"Each of the files in a PCP archive (metadata, temporal index, and
       one or more data volumes) must contain a valid label at the start,
       else the PCP tools will refuse to open the archive at all. Thus, the primary function of
pmloglabel
is to be able to repair
       any inconsistent or corrupt label fields, such that the entire
       archive is not lost. It will not check the remainder of the
       archive, but it will give you a fighting chance to recover
       otherwise lost data."
1198,2,pmloglabel,"It will not check the remainder of the
       archive, but it will give you a fighting chance to recover
       otherwise lost data. Together,
pmloglabel
and
pmlogextract
are
       able to produce a valid PCP archive from many forms of corruption. Note that if the temporal index is found to be corrupt, the
       ""*.index"" file can be safely moved aside and the archive will
       still be accessible, however retrievals may take longer without
       the index."
1199,0,pmlogredact,"Performance Co-Pilot (PCP) archives may contain a wealth of
       information collected from across all components of a system. Some of this information may be deemed sensitive outside the
       context of the original collection for analysis of system
       performance. Examples of sensitive information might include user
       names, paths to user home directories (that may imply user names),
       hostnames, IP addresses, MAC addresses, command line arguments,
       process environment variables, etc."
1199,1,pmlogredact,"Examples of sensitive information might include user
       names, paths to user home directories (that may imply user names),
       hostnames, IP addresses, MAC addresses, command line arguments,
       process environment variables, etc. pmlogredact
may be used to remove sensitive information before
       archives are shipped to another organization, or stored in another
       geography, or to meet regulatory or privacy compliance. The
       output archive
outarch
is the redacted version of the input
       archive
inarch
."
1199,2,pmlogredact,"The
       output archive
outarch
is the redacted version of the input
       archive
inarch
. pmlogredact
is a thin wrapper around
pmlogrewrite(1)
, and so the
       configuration files for
pmlogredact
follow the same syntax as the
       configuration files for
pmlogrewrite(1)
. There are a default set of redaction rules in the
$PCP_VAR_DIR/config/pmlogredact/*
files."
1199,3,pmlogredact,"There are a default set of redaction rules in the
$PCP_VAR_DIR/config/pmlogredact/*
files. These rules remove some
       metrics, rewrite the instance domains of some metrics and rewrite
       the values of some metrics. The
-x
(or
--exclude-std
) option may
       be used to
not
use the default set of rules."
1199,4,pmlogredact,"The
-x
(or
--exclude-std
) option may
       be used to
not
use the default set of rules. Additional (or alternative) configuration files may be specified
       with one or more
-c
(or
--config
) options, where each
config
is
       either a file or a directory (implying all the files within that
       directory). The
-v
(or
--verbose
) option adds verbosity (and is passed directâ
       ly to
pmlogrewrite(1)
)."
1199,5,pmlogredact,"The
-v
(or
--verbose
) option adds verbosity (and is passed directâ
       ly to
pmlogrewrite(1)
). The
-? (or
--help)
option displays a usage message and exits."
1200,0,pmlogreduce,"pmlogreduce
reads one set of Performance Co-Pilot (PCP) archives
       identified by
input
and creates a temporally reduced PCP archive
       in
output
. input
is a comma-separated list of names, each of
       which may be the base name of an archive or the name of a
       directory containing one or more archives. The data reduction
       involves statistical and temporal reduction of samples with an
       output sampling interval defined by the
-t
option in the
output
archive (independent of the sampling intervals in the
input
archives), and is further controlled by other command line
       arguments."
1200,1,pmlogreduce,"input
is a comma-separated list of names, each of
       which may be the base name of an archive or the name of a
       directory containing one or more archives. The data reduction
       involves statistical and temporal reduction of samples with an
       output sampling interval defined by the
-t
option in the
output
archive (independent of the sampling intervals in the
input
archives), and is further controlled by other command line
       arguments. For some metrics, temporal data reduction is not going to be
       helpful, so for metrics with types
PM_TYPE_AGGREGATE
or
PM_TYPE_EVENT
, a warning is issued if these metrics are found in
input
and they will be skipped and not appear in the
output
archive."
1201,0,pmlogger_daily,"pmlogger_daily
and the related
pmlogger_check(1)
tools along with
       associated control files (see
pmlogger.control(5)
) may be used to
       create a customized regime of administration and management for
       historical archives of performance data within the Performance Co-
       Pilot (see
PCPIntro(1)
) infrastructure. pmlogger_daily
is intended to be run once per day, preferably in
       the early morning, as soon after midnight as practicable. Its
       task is to aggregate, rotate and perform general housekeeping one
       or more sets of PCP archives."
1201,1,pmlogger_daily,"Its
       task is to aggregate, rotate and perform general housekeeping one
       or more sets of PCP archives. To accommodate the evolution of PMDAs and changes in production
       logging environments,
pmlogger_daily
is integrated with
pmlogrewrite(1)
to allow optional and automatic rewriting of
       archives before merging. If there are global rewriting rules to
       be applied across all archives mentioned in the control file(s),
       then create the directory
$PCP_SYSCONF_DIR/pmlogrewrite
and place
       any
pmlogrewrite(1)
rewriting rules in this directory."
1201,2,pmlogger_daily,"If there are global rewriting rules to
       be applied across all archives mentioned in the control file(s),
       then create the directory
$PCP_SYSCONF_DIR/pmlogrewrite
and place
       any
pmlogrewrite(1)
rewriting rules in this directory. For
       rewriting rules that are specific to only one family of archives,
       use the directory name from the control file(s) - i.e. the
fourth
field - and create a file, or a directory, or a symbolic link
       named
pmlogrewrite
within this directory and place the required
       rewriting rule(s) in the
pmlogrewrite
file or in files within the
pmlogrewrite
subdirectory."
1201,3,pmlogger_daily,"the
fourth
field - and create a file, or a directory, or a symbolic link
       named
pmlogrewrite
within this directory and place the required
       rewriting rule(s) in the
pmlogrewrite
file or in files within the
pmlogrewrite
subdirectory. pmlogger_daily
will choose rewriting
       rules from the archive directory if they exist, else rewriting
       rules from
$PCP_SYSCONF_DIR/pmlogrewrite
if that directory exists,
       else no rewriting is attempted. As an alternate mechanism, if the file
$PCP_LOG_DIR/pmlogger/.NeedRewrite
exists when
pmlogger_daily
starts then this is treated the same as specifying
-R
on the
       command line and
$PCP_LOG_DIR/pmlogger/.NeedRewrite
will be
       removed once all the rewriting has been done."
1202,0,pmlogrewrite,"pmlogrewrite
reads a set of Performance Co-Pilot (PCP) archives
       identified by
inlog
and creates a PCP archive in
outlog
. Under
       normal usage, the
-c
option will be used to nominate a
       configuration file or files that contains specifications (see the
REWRITING RULES SYNTAX
section below) that describe how the data
       and metadata from
inlog
should be transformed to produce
outlog
. The typical uses for
pmlogrewrite
would be to accommodate the
       evolution of Performance Metric Domain Agents (PMDAs) where the
       names, metadata and semantics of metrics and their associated
       instance domains may change over time, e.g."
1202,1,pmlogrewrite,"The typical uses for
pmlogrewrite
would be to accommodate the
       evolution of Performance Metric Domain Agents (PMDAs) where the
       names, metadata and semantics of metrics and their associated
       instance domains may change over time, e.g. promoting the type of
       a metric from a 32-bit to a 64-bit integer, or renaming a group of
       metrics. Refer to the
EXAMPLES
section for some additional use
       cases."
1202,2,pmlogrewrite,"Refer to the
EXAMPLES
section for some additional use
       cases. pmlogrewrite
may also be used to redact sensitive information from
       PCP archives in situations where the archives need to be shipped
       to another organization or to meet privacy policies or legislative
       requirements. See
pmlogredact(1)
for an example use of
pmlogrewrite
in this context."
1202,3,pmlogrewrite,"See
pmlogredact(1)
for an example use of
pmlogrewrite
in this context. pmlogrewrite
is most useful where PMDA changes, or errors in the
       production environment, result in archives that cannot be combined
       with
pmlogextract(1)
. By pre-processing the archives with
pmlogrewrite
the resulting archives may be able to be merged with
pmlogextract(1)
."
1202,4,pmlogrewrite,"By pre-processing the archives with
pmlogrewrite
the resulting archives may be able to be merged with
pmlogextract(1)
. The input
inlog
must be a set of PCP archives created by
pmlogger(1)
, or possibly one of the tools that read and create PCP
       archives, e.g. pmlogextract(1)
and
pmlogreduce(1)
."
1202,5,pmlogrewrite,"pmlogextract(1)
and
pmlogreduce(1)
. inlog
is a
       comma-separated list of names, each of which may be the base name
       of an archive or the name of a directory containing one or more
       archives. If no
-c
option is specified, then the default behavior simply
       creates
outlog
as a copy of
inlog
."
1202,6,pmlogrewrite,"If no
-c
option is specified, then the default behavior simply
       creates
outlog
as a copy of
inlog
. This is a little more
       complicated than
cat(1)
, as each PCP archive is made up of several
       physical files. While
pmlogrewrite
may be used to repair some data consistency
       issues in PCP archives, there is also a class of repair tasks that
       cannot be handled by
pmlogrewrite
and
pmloglabel(1)
may be a
       useful tool in these cases."
1203,0,pmlogsummary,"pmlogsummary
prints statistical information about metrics of
       numeric type contained within the files of a set of Performance
       Co-Pilot (PCP) archives. The default output prints time averages
       for both counter and non-counter metrics. The set of archives is
       identified by
archive
, which is a comma-separated list of names,
       each of which may be the base name of an archive or the name of a
       directory containing one or more archives."
1203,1,pmlogsummary,"The set of archives is
       identified by
archive
, which is a comma-separated list of names,
       each of which may be the base name of an archive or the name of a
       directory containing one or more archives. The archives are
       typically created using
pmlogger(1)
. The metrics of interest are named in the
metricname
arguments."
1203,2,pmlogsummary,"The metrics of interest are named in the
metricname
arguments. If
metricname
is a non-leaf node in the Performance Metrics Name
       Space (
PMNS(5)
), then
pmlogsummary
will recursively descend the
       PMNS and report on all leaf nodes. If no
metricname
argument is
       given, the root of the namespace is used."
1203,3,pmlogsummary,"If
metricname
is a non-leaf node in the Performance Metrics Name
       Space (
PMNS(5)
), then
pmlogsummary
will recursively descend the
       PMNS and report on all leaf nodes. If no
metricname
argument is
       given, the root of the namespace is used. Metrics with counter semantics are converted to rates before being
       evaluated."
1204,0,pcpcompat,nan
1205,0,pmlogsize,"pmlogsize
prints information about the size of the index, metadata
       and data sections of a Performance Co-Pilot (PCP) archive. The
       output is intended to guide improvements in archive encoding
       format for PCP developers and to help trim
pmlogger(1)
configuration files to remove metrics that are bloating the PCP
       archives with low-value data in production environments. The
archive
arguments can be any mixture of the names of the
       physical files of a PCP archive or the basename that is common to
       all the component physical files in a single archive."
1205,1,pmlogsize,"The
archive
arguments can be any mixture of the names of the
       physical files of a PCP archive or the basename that is common to
       all the component physical files in a single archive. In the
       latter case
archive
is replaced by a list of all of the matching
       component file names. Note the semantics is a little different to other PCP tools in
       that
foo.meta
means
just
the file
foo.meta
, not
foo.index
,
foo.meta
,
foo.0
, etc."
1206,0,pmnsadd,"pmnsmerge(1)
performs the same function as
pmnsadd
and is faster,
       more robust and more flexible. It is therefore recommended that
pmnsmerge(1)
be used instead. pmnsadd
adds subtree(s) of new names into a Performance Metrics
       Name Space (PMNS), as used by the components of the Performance
       Co-Pilot (PCP)."
1206,1,pmnsadd,"pmnsadd
adds subtree(s) of new names into a Performance Metrics
       Name Space (PMNS), as used by the components of the Performance
       Co-Pilot (PCP). Normally
pmnsadd
operates on the default Performance Metrics Name
       Space (PMNS), however if the
-n
option is specified an alternative
       namespace is used from the file
namespace
. The default PMNS is found in the file
$PCP_VAR_DIR/pmns/root
unless the environment variable
PMNS_DEFAULT
is set, in which case
       the value is assumed to be the pathname to the file containing the
       default PMNS."
1206,2,pmnsadd,"The default PMNS is found in the file
$PCP_VAR_DIR/pmns/root
unless the environment variable
PMNS_DEFAULT
is set, in which case
       the value is assumed to be the pathname to the file containing the
       default PMNS. The new names are specified in the
file
, arguments and conform to
       the syntax for PMNS specifications, see
PMNS(5)
. There is one
       PMNS subtree in each
file
, and the base PMNS pathname to the
       inserted subtree is identified by the first group named in each
file
, e.g."
1206,3,pmnsadd,"There is one
       PMNS subtree in each
file
, and the base PMNS pathname to the
       inserted subtree is identified by the first group named in each
file
, e.g. if the specifications begin

                 myagent.foo.stuff {
                     mumble    123:45:1
                     fumble    123:45:2
                 }

       then the new names will be added into the PMNS at the non-leaf
       position identified by myagent.foo.stuff, and following all other
       names with the prefix myagent.foo. The new names must be contained within a single subtree of the
       namespace."
1206,4,pmnsadd,"The new names must be contained within a single subtree of the
       namespace. If disjoint subtrees need to be added, these must be
       packaged into separate files and
pmnsadd
used on each, one at a
       time. All of the files defining the PMNS must be located within the
       directory that contains the root of the PMNS, this would typically
       be
$PCP_VAR_DIR/pmns
for the default PMNS, and this would
       typically imply running
pmnsadd
as root."
1206,5,pmnsadd,"All of the files defining the PMNS must be located within the
       directory that contains the root of the PMNS, this would typically
       be
$PCP_VAR_DIR/pmns
for the default PMNS, and this would
       typically imply running
pmnsadd
as root. As a special case, if
file
contains a line that begins root { then
       it is assumed to be a complete PMNS that needs to be merged, so
       none of the subtree extraction and rewriting is performed and
file
is handed directly to
pmnsmerge(1)
. Provided some initial integrity checks are satisfied,
pmnsadd
will
       update the PMNS using
pmnsmerge(1)
- if this fails for any reason,
       the original namespace remains unchanged."
1207,0,pmsleep,"pmpause
sleeps indefinitely, until interrupted by SIGKILL. pmsleep
sleeps for the specified
interval
. The
interval
argument
       follows the syntax described in
PCPIntro(1)
for
-t,
and in the
       simplest form may be an unsigned integer or floating point
       constant (the implied units in this case are seconds)."
1207,1,pmsleep,"The
interval
argument
       follows the syntax described in
PCPIntro(1)
for
-t,
and in the
       simplest form may be an unsigned integer or floating point
       constant (the implied units in this case are seconds). The
-w
option is provided to allow annotation of scripts with
       multiple uses of
pmpause
and/or
pmsleep
to identify a particular
       use in the process's arguments, e.g. as visible to
ps(1)
."
1208,0,pmquery,"pmquery
provides a command-line-option compatible implementation
       of the
xconfirm
and
xmessage
tools, using a look-and-feel that is
       consistent with
pmchart
. Several extensions to the functionality
       of the original tools have been made, in order to improve their
       specific utility for
pmchart
, but wherever possible the original
       semantics remain. pmconfirm
displays a line of text for each
-t
option specified (or
       a file when the
-file
option is used), and a button for each
-b
option specified."
1208,1,pmquery,"pmconfirm
displays a line of text for each
-t
option specified (or
       a file when the
-file
option is used), and a button for each
-b
option specified. When one of the buttons is pressed, the label
       of that button is written to
pmquery's
standard output. This
       provides a means of communication/feedback from within shell
       scripts and a means to display useful information to a user from
       an application."
1208,2,pmquery,"This
       provides a means of communication/feedback from within shell
       scripts and a means to display useful information to a user from
       an application. pmmessage
displays a window containing a message from the command
       line, a file, or standard input. It additionally allows buttons
       to be associated with an exit status, and only optionally will
       write the label of the button to standard output."
1208,3,pmquery,"It additionally allows buttons
       to be associated with an exit status, and only optionally will
       write the label of the button to standard output. pmquery
extends the above tools to additionally support limited
       user input, as free form text. In this
-input
mode, any text
       entered will be output when the default button is pressed."
1208,4,pmquery,"In this
-input
mode, any text
       entered will be output when the default button is pressed. A
       default text can be entered using the same mechanisms as the other
       tools. Command line options are available to specify font style, frame
       style, modality and one of several different icons to be presented
       for tailored visual feedback to the user."
1209,0,pmnscomp,"pmnscomp
compiles a Performance Metrics Name Space (PMNS) in ASCII
       format into a more efficient binary representation. pmLoadNameSpace(3)
is able to load this binary representation
       significantly faster than the equivalent ASCII representation. If
outfile
already exists
pmnscomp
will exit without overwriting
       it."
1209,1,pmnscomp,"If
outfile
already exists
pmnscomp
will exit without overwriting
       it. By convention, the name of the compiled namespace is that of the
       root file of the ASCII namespace, with
.bin
appended. For
       example, the root of the default PMNS is a file named
root
and the
       compiled version of the entire namespace is
root.bin
."
1209,2,pmnscomp,"For
       example, the root of the default PMNS is a file named
root
and the
       compiled version of the entire namespace is
root.bin
. The options are;
-d
By default the PMNS to be compiled is expected to contain at
            most one name for each unique Performance Metric Identifier
            (PMID). The
-d
option relaxes this restriction and allows
            the compilation of a PMNS in which multiple names may be
            associated with a single PMID."
1209,3,pmnscomp,"The
-d
option relaxes this restriction and allows
            the compilation of a PMNS in which multiple names may be
            associated with a single PMID. Duplicate names are useful
            when a particular metric may be logically associated with
            more than one group of related metrics, or when it is desired
            to create abbreviated aliases to name a set of frequently
            used metrics. -f
Force overwriting of an existing
outfile
if it already
            exists."
1209,4,pmnscomp,"-f
Force overwriting of an existing
outfile
if it already
            exists. -n
Normally
pmnscomp
operates on the default PMNS, however if
            the
-n
option is specified an alternative namespace is loaded
            from the file
namespace. -v
By default,
pmnscomp
writes a version
2
compiled namespace."
1209,5,pmnscomp,"-v
By default,
pmnscomp
writes a version
2
compiled namespace. If
version
is
1
then
pmnscomp
will write a version
1
namespace which is similar to version
2
, without the extra
            integrity afforded by checksums. Note that PCP version 2.0
            or later can handle both versions
1
and
2
of the binary PMNS
            format."
1209,6,pmnscomp,"If
version
is
1
then
pmnscomp
will write a version
1
namespace which is similar to version
2
, without the extra
            integrity afforded by checksums. Note that PCP version 2.0
            or later can handle both versions
1
and
2
of the binary PMNS
            format. The default input PMNS is found in the file
$PCP_VAR_DIR/pmns/root
unless the environment variable
PMNS_DEFAULT
is set, in which case
       the value is assumed to be the pathname to the file containing the
       default input PMNS."
1210,0,pmnsmerge,"pmnsmerge
merges multiple instances of a Performance Metrics Name
       Space (PMNS), as used by the components of the Performance Co-
       Pilot (PCP). Each
infile
argument names a file that includes the root of a
       PMNS, of the form

                 root {
                     /* arbitrary stuff */
                 }

       The order in which the
infile
files are processed is determined by
       the presence or absence of embedded control lines of the form

       #define _DATESTAMP
YYYYMMDD
Files without a control line are processed first and in the order
       they appear on the command line. The other files are then
       processed in order of ascending _DATESTAMP."
1210,1,pmnsmerge,"The other files are then
       processed in order of ascending _DATESTAMP. The
-a
option suppresses the argument re-ordering and processes
       all files in the order they appear on the command line. The merging proceeds by matching names in PMNS, only those
new
names in each PMNS are considered, and these are added after any
       existing metrics with the longest possible matching prefix in
       their names."
1210,2,pmnsmerge,"The merging proceeds by matching names in PMNS, only those
new
names in each PMNS are considered, and these are added after any
       existing metrics with the longest possible matching prefix in
       their names. For example, merging these two input PMNS

                 root {                    root {
                                               surprise  1:1:3
                     mine       1:1:1          mine      1:1:1
                     foo                       foo
                                               yawn
                     yours      1:1:2
                 }                         }
                 foo {                     foo {
                     fumble     1:2:1
                                               mumble    1:2:3
                     stumble    1:2:2          stumble   1:2:2
                 }                         }
                                           yawn {
                                               sleepy    1:3:1
                                           }

       Produces the resulting PMNS in
out
. root {
                     mine      1:1:1
                     foo
                     yours     1:1:2
                     surprise  1:1:3
                     yawn
                 }
                 foo {
                     fumble    1:2:1
                     stumble   1:2:2
                     mumble    1:2:3
                 }
                 yawn {
                     sleepy    1:3:1
                 }

       To avoid accidental over-writing of PMNS files,
outfile
is
       expected to not exist when
pmnsmerge
starts."
1210,3,pmnsmerge,"root {
                     mine      1:1:1
                     foo
                     yours     1:1:2
                     surprise  1:1:3
                     yawn
                 }
                 foo {
                     fumble    1:2:1
                     stumble   1:2:2
                     mumble    1:2:3
                 }
                 yawn {
                     sleepy    1:3:1
                 }

       To avoid accidental over-writing of PMNS files,
outfile
is
       expected to not exist when
pmnsmerge
starts. The
-f
option allows
       an existing
outfile
to be unlinked (if possible) and truncated
       before writing starts. Normally duplicate names for the same Performance Metric
       Identifier (PMID) in a PMNS are allowed."
1210,4,pmnsmerge,"Normally duplicate names for the same Performance Metric
       Identifier (PMID) in a PMNS are allowed. The
-d
option is the
       default option and is included for backwards compatibility. The
-x
option reverses the default and
pmnsmerge
will report an error
       and exit with a non-zero status if a duplicate name is found for a
       PMID in any of the
input
PMNS files or in the merged
output
PMNS."
1210,5,pmnsmerge,"The
-x
option reverses the default and
pmnsmerge
will report an error
       and exit with a non-zero status if a duplicate name is found for a
       PMID in any of the
input
PMNS files or in the merged
output
PMNS. The
-v
option produces one line of diagnostic output as each
infile
is processed. Once all of the merging has been completed,
pmnsmerge
will attempt
       to load the resultant namespace using
pmLoadASCIINameSpace(3)
- if
       this fails for any reason,
outfile
will still be created, but
pmnsmerge
will report the problem and exit with non-zero status."
1210,6,pmnsmerge,"Once all of the merging has been completed,
pmnsmerge
will attempt
       to load the resultant namespace using
pmLoadASCIINameSpace(3)
- if
       this fails for any reason,
outfile
will still be created, but
pmnsmerge
will report the problem and exit with non-zero status. Using
pmnsmerge
with a single
input
argument allows that PMNS file
       to be checked. In addition to syntactic checking, specifying
-x
will also enable a check for duplicate names for all PMIDs."
1211,0,pmnsdel,"pmnsdel
removes subtrees of names from a Performance Metrics Name
       Space (PMNS), as used by the components of the Performance Co-
       Pilot (PCP). Normally
pmnsdel
operates on the default Performance Metrics Name
       Space (PMNS), however if the
-n
option is specified an alternative
       namespace is used from the file
namespace
. The default PMNS is found in the file
$PCP_VAR_DIR/pmns/root
unless the environment variable
PMNS_DEFAULT
is set, in which case
       the value is assumed to be the pathname to the file containing the
       default PMNS."
1211,1,pmnsdel,"The default PMNS is found in the file
$PCP_VAR_DIR/pmns/root
unless the environment variable
PMNS_DEFAULT
is set, in which case
       the value is assumed to be the pathname to the file containing the
       default PMNS. The metric names to be deleted are all those for which one of the
metricpath
arguments is a prefix in the PMNS, see
PMNS(5)
. All of the files defining the PMNS must be located within the
       directory that contains the root of the PMNS, and this would
       typically be
$PCP_VAR_DIR/pmns
for the default PMNS, and this
       would typically imply running
pmnsdel
as root."
1211,2,pmnsdel,"All of the files defining the PMNS must be located within the
       directory that contains the root of the PMNS, and this would
       typically be
$PCP_VAR_DIR/pmns
for the default PMNS, and this
       would typically imply running
pmnsdel
as root. Provided some initial integrity checks are satisfied,
pmnsdel
will
       update the necessary PMNS files. Should an error be encountered
       the original namespace is restored."
1211,3,pmnsdel,"Provided some initial integrity checks are satisfied,
pmnsdel
will
       update the necessary PMNS files. Should an error be encountered
       the original namespace is restored. Note that any PMNS files that
       are no longer referenced by the modified namespace will not be
       removed, even though their contents are not part of the new
       namespace."
1212,0,pmpost,"pmpost
will append the text
message
to the end of the Performance
       Co-Pilot (PCP) notice board file (
$PCP_LOG_DIR/NOTICES
) in an
       atomic manner that guards against corruption of the notice board
       file by concurrent invocations of
pmpost
. The PCP notice board is intended to be a persistent store and
       clearing house for important messages relating to the operation of
       the PCP and the notification of performance alerts from
pmie(1)
when other notification options are either unavailable or
       unsuitable. Before being written, messages are prefixed by the current time,
       and when the current day is different to the last time the notice
       board file was written,
pmpost
will prepend the message with the
       full date."
1212,1,pmpost,"Before being written, messages are prefixed by the current time,
       and when the current day is different to the last time the notice
       board file was written,
pmpost
will prepend the message with the
       full date. If the notice board file does not exist,
pmpost
will create it. pmpost
would usually run from long-running PCP daemons executing
       under the (typically unprivileged)
$PCP_USER
and
$PCP_GROUP
accounts."
1212,2,pmpost,"If the notice board file does not exist,
pmpost
will create it. pmpost
would usually run from long-running PCP daemons executing
       under the (typically unprivileged)
$PCP_USER
and
$PCP_GROUP
accounts. The file should be owned and writable by the
$PCP_USER
user, and readable by others."
1213,0,pmprobe,"pmprobe
determines the availability of performance metrics
       exported through the facilities of the Performance Co-Pilot (PCP). The metrics of interest are named in the
metricname
arguments. If
metricname
is a non-leaf node in the Performance Metrics Name
       Space (
PMNS(5)
), then
pmprobe
will recursively descend the PMNS
       and report on all leaf nodes."
1213,1,pmprobe,"If
metricname
is a non-leaf node in the Performance Metrics Name
       Space (
PMNS(5)
), then
pmprobe
will recursively descend the PMNS
       and report on all leaf nodes. If no
metricname
argument is given,
       the root of the namespace is used. This recursive expansion of the PMNS can be inhibited by the
-F
(go faster) option, which reduces the number of roundtrips to
pmcd(1)
when the
metricname
arguments are known to be leaf nodes
       ahead of time."
1213,2,pmprobe,"This recursive expansion of the PMNS can be inhibited by the
-F
(go faster) option, which reduces the number of roundtrips to
pmcd(1)
when the
metricname
arguments are known to be leaf nodes
       ahead of time. The output format is spartan and intended for use in wrapper
       scripts creating configuration files for other PCP tools. By
       default, there is one line of output per metric, with the metric
       name followed by a count of the number of available values."
1213,3,pmprobe,"By
       default, there is one line of output per metric, with the metric
       name followed by a count of the number of available values. Error
       conditions are encoded as a negative value count (as per the
PMAPI(3)
protocols, but may be decoded using
pmerr(1)
) and
       followed by a textual description of the error. Unless directed to another host by the
-h
option,
pmprobe
will
       contact the Performance Metrics Collector Daemon (PMCD) on the
       local host."
1213,4,pmprobe,"Unless directed to another host by the
-h
option,
pmprobe
will
       contact the Performance Metrics Collector Daemon (PMCD) on the
       local host. The
-a
option causes
pmprobe
to use the specified set of archives
       rather than connecting to a PMCD. The
-L
option causes
pmprobe
to use a local context to collect
       metrics from PMDAs on the local host without PMCD."
1213,5,pmprobe,"The
-L
option causes
pmprobe
to use a local context to collect
       metrics from PMDAs on the local host without PMCD. Only some
       metrics are available in this mode. The
-a
,
-h
and
-L
options are mutually exclusive."
1214,0,pmproxy,"pmproxy
acts as a protocol proxy, allowing Performance Co-Pilot
       (PCP) monitoring clients to connect to one or more
pmcd(1)
and/or
       key-value servers (such as
https://valkey.io/
) indirectly. In its default mode of operation
pmproxy
provides the REST API for
       PCP services (see
PMWEBAPI(3)
for details). This includes
       provision of an Open Metrics -
https://openmetrics.io
- text
       interface for PCP metrics at
/metrics
, real-time access to PCP
       metrics through the
/pmapi
interfaces, and access to the fast,
       scalable PCP time series query capabilities offered in conjunction
       with a key-value server (see
pmseries(1)
for details) via the
/query
REST interfaces."
1214,1,pmproxy,"This includes
       provision of an Open Metrics -
https://openmetrics.io
- text
       interface for PCP metrics at
/metrics
, real-time access to PCP
       metrics through the
/pmapi
interfaces, and access to the fast,
       scalable PCP time series query capabilities offered in conjunction
       with a key-value server (see
pmseries(1)
for details) via the
/query
REST interfaces. pmproxy
can be deployed in a firewall domain, or on a cluster
       ``head'' node where the IP (Internet Protocol) address of the
       hosts where
pmcd
and/or a key-value server (such as
https://valkey.io/
) are running may be unknown to the PCP
       monitoring clients, but where the IP address of the host running
pmproxy
is known to these clients. Similarly, the clients may
       have network connectivity only to the host where
pmproxy
is
       running, while there is network connectivity from that host to the
       hosts of interest where
pmcd
and/or a key-value server are
       running."
1214,2,pmproxy,"Similarly, the clients may
       have network connectivity only to the host where
pmproxy
is
       running, while there is network connectivity from that host to the
       hosts of interest where
pmcd
and/or a key-value server are
       running. The behaviour of the PCP monitoring clients is controlled by
       either the
PMPROXY_HOST
environment variable or through the
       extended hostname specification (see
PCPIntro(1)
for details). If
       neither of these mechanisms is used, clients will make their
PMAPI(3)
connections directly to
pmcd
."
1214,3,pmproxy,"The behaviour of the PCP monitoring clients is controlled by
       either the
PMPROXY_HOST
environment variable or through the
       extended hostname specification (see
PCPIntro(1)
for details). If
       neither of these mechanisms is used, clients will make their
PMAPI(3)
connections directly to
pmcd
. If the proxy hostname
       syntax is used or
PMPROXY_HOST
is set, then this should be the
       hostname or IP address of the system where
pmproxy
is running, and
       the clients will connect to
pmcd
or a key-value server indirectly
       through the protocol proxy services of
pmproxy."
1215,0,pmquery,"pmquery
provides a command-line-option compatible implementation
       of the
xconfirm
and
xmessage
tools, using a look-and-feel that is
       consistent with
pmchart
. Several extensions to the functionality
       of the original tools have been made, in order to improve their
       specific utility for
pmchart
, but wherever possible the original
       semantics remain. pmconfirm
displays a line of text for each
-t
option specified (or
       a file when the
-file
option is used), and a button for each
-b
option specified."
1215,1,pmquery,"pmconfirm
displays a line of text for each
-t
option specified (or
       a file when the
-file
option is used), and a button for each
-b
option specified. When one of the buttons is pressed, the label
       of that button is written to
pmquery's
standard output. This
       provides a means of communication/feedback from within shell
       scripts and a means to display useful information to a user from
       an application."
1215,2,pmquery,"This
       provides a means of communication/feedback from within shell
       scripts and a means to display useful information to a user from
       an application. pmmessage
displays a window containing a message from the command
       line, a file, or standard input. It additionally allows buttons
       to be associated with an exit status, and only optionally will
       write the label of the button to standard output."
1215,3,pmquery,"It additionally allows buttons
       to be associated with an exit status, and only optionally will
       write the label of the button to standard output. pmquery
extends the above tools to additionally support limited
       user input, as free form text. In this
-input
mode, any text
       entered will be output when the default button is pressed."
1215,4,pmquery,"In this
-input
mode, any text
       entered will be output when the default button is pressed. A
       default text can be entered using the same mechanisms as the other
       tools. Command line options are available to specify font style, frame
       style, modality and one of several different icons to be presented
       for tailored visual feedback to the user."
1216,0,pmpython,"pmpython
provides a way to run python scripts using a customisable
       python interpreter, rather than embedding the name of a particular
       version of python into each script. This can be useful as it allows version-independent python code to
       be run anywhere. All python modules shipped with PCP support
       versions 2.6 and later (in the python2 series), and 3.3 and later
       (in the python3 release series)."
1216,1,pmpython,"All python modules shipped with PCP support
       versions 2.6 and later (in the python2 series), and 3.3 and later
       (in the python3 release series). Due to python monitoring and collecting scripts being relatively
       simple in PCP (not requiring new modules, language features, etc),
       it has been possible to ensure they work for all of the above
       python versions. However, the name of the python interpreter is not always the
       same, thus, it is common for PCP python scripts to use a âshebangâ
       line that launches the
python
interpreter indirectly as follows:

          #!/usr/bin/env pmpython
env(1)
is used to find the correct path for the
pmpython
executable from the user's
$PATH
."
1216,2,pmpython,"However, the name of the python interpreter is not always the
       same, thus, it is common for PCP python scripts to use a âshebangâ
       line that launches the
python
interpreter indirectly as follows:

          #!/usr/bin/env pmpython
env(1)
is used to find the correct path for the
pmpython
executable from the user's
$PATH
. By default the name of the python interpreter is found from the
       the value of
$PCP_PYTHON_PROG
from the environment (if set) else
       from
/etc/pcp.conf
. The latter is the more typical case where
       this value is based on some heuristics about the platform at the
       time the PCP packages were build and favour the use of
python3
in
       all recent releases of PCP (for those platforms that support it)."
1216,3,pmpython,"The latter is the more typical case where
       this value is based on some heuristics about the platform at the
       time the PCP packages were build and favour the use of
python3
in
       all recent releases of PCP (for those platforms that support it). This allows an appropriate name to be used for the python
       interpreter instead of a hard-coded python version name, while
       still allowing the user to override the python interpreter as
       follows:

          $ PCP_PYTHON_PROG=python3 pmpython --version
          Python 3.4.2
          $ PCP_PYTHON_PROG=python2 pmpython --version
          Python 2.7.9

       This is convenient for shipping identical scripts on multiple
       platforms, and for testing different python versions with the one
       script (e.g. in the case where multiple versions of python are
       installed, PCP_PYTHON_PROG can be set in the local environment to
       override the global setting)."
1216,4,pmpython,"This allows an appropriate name to be used for the python
       interpreter instead of a hard-coded python version name, while
       still allowing the user to override the python interpreter as
       follows:

          $ PCP_PYTHON_PROG=python3 pmpython --version
          Python 3.4.2
          $ PCP_PYTHON_PROG=python2 pmpython --version
          Python 2.7.9

       This is convenient for shipping identical scripts on multiple
       platforms, and for testing different python versions with the one
       script (e.g. in the case where multiple versions of python are
       installed, PCP_PYTHON_PROG can be set in the local environment to
       override the global setting). pmpython
is a replacement for an earlier tool with similar
       function, namely
pcp-python(1)
."
1217,0,pmsearch,"pmsearch
performs full text search queries to find metrics using
       names and help text from metrics, instance domains and instances. It makes use of capabilities of the Performance Co-Pilot (PCP)
pmproxy(1)
service, the Valkey distributed key-value store and
       associated ValkeySearch module. Note that in order to use these services, it is
mandatory
that
pmproxy
is communicating with a Valkey key-value server that has
       the
valkey-search.so
module loaded."
1217,1,pmsearch,"Note that in order to use these services, it is
mandatory
that
pmproxy
is communicating with a Valkey key-value server that has
       the
valkey-search.so
module loaded. When configured to do so,
pmproxy
will then automatically index PCP metric names, instance
       names, metric and instance domain help text into the ValkeySearch
       store, from PCP archives that it discovers locally. Refer to
pmlogger(1)
and
pmlogger_daily(1)
for further details."
1217,2,pmsearch,"Refer to
pmlogger(1)
and
pmlogger_daily(1)
for further details. By default
pmsearch
communicates with a local key-value server
       however the
-h
and
-p
options can be used to specify an alternate
       Valket instance. If this instance is a node of a Valkey cluster,
       all other instances in the cluster will be discovered and used
       automatically."
1218,0,pmrepconf,"pmrepconf
may be used to create and modify a generic configuration
       file for
pmrep(1)
and related utilities in the
pmrep.conf(5)
format. If
configfile
does not exist,
pmrepconf
will create a generic
       configuration file with a set of discovered metrics in a [metrics]
       section. Once created,
configfile
may be used with the
-c
option to
pmrep(1)
and related utilities such as
pcp2elasticsearch
(2) and
pcp2spark
(2)."
1218,1,pmrepconf,"Once created,
configfile
may be used with the
-c
option to
pmrep(1)
and related utilities such as
pcp2elasticsearch
(2) and
pcp2spark
(2). If
configfile
does exist,
pmrepconf
will prompt for input from the
       user to enable or disable groups of related performance metrics. Group selection requires a simple
y
(yes) or
n
(no) response to
       the prompt
Log this group?"
1218,2,pmrepconf,"Group selection requires a simple
y
(yes) or
n
(no) response to
       the prompt
Log this group? . Other responses at this point may be used to select additional
       control functions as follows:
m
Report the names of the metrics in the current group."
1218,3,pmrepconf,"Other responses at this point may be used to select additional
       control functions as follows:
m
Report the names of the metrics in the current group. q
Finish with group selection (quit) and make no further
                 changes to this group or any subsequent group. /
pattern
Make no change to this group but search for a group
                 containing
pattern
in the description of the group or
                 the names of the associated metrics."
1218,4,pmrepconf,"/
pattern
Make no change to this group but search for a group
                 containing
pattern
in the description of the group or
                 the names of the associated metrics. When run from automated setup processes, the
-c
option is used to
       indicate that
pmrepconf
is in auto-create mode and no interactive
       dialog takes place. The output
configfile
has an additional
       comment message and timestamp indicating this fact, so that it can
       be identified and subsequently updated using
-c
again."
1218,5,pmrepconf,"The output
configfile
has an additional
       comment message and timestamp indicating this fact, so that it can
       be identified and subsequently updated using
-c
again. This
       option is not appropriate for interactive use of the tool. More verbose output may be enabled with the
-v
option."
1219,0,pmsignal,"pmsignal
provides a cross-platform event signalling mechanism for
       use with tools from the Performance Co-Pilot toolkit. It can be
       used to send a named
signal
(only HUP, USR1, TERM, and KILL are
       accepted) to one or more processes. The processes are specified directly using PIDs or as program
       names (with either the
-a
or
-p
options)."
1219,1,pmsignal,"The processes are specified directly using PIDs or as program
       names (with either the
-a
or
-p
options). In the
all
case, the
       set of all running processes is searched for a
basename(1)
match
       on
name
. In the
program
case, process identifiers are extracted
       from files in the $PCP_RUN_DIR directory where file names are
       matched on
name
.pid."
1219,2,pmsignal,"In the
program
case, process identifiers are extracted
       from files in the $PCP_RUN_DIR directory where file names are
       matched on
name
.pid. The
-n
option reports the list of process identifiers that would
       have been signalled, but no signals are actually sent. If a
signal
is not specified, then the TERM signal will be sent."
1219,3,pmsignal,"If a
signal
is not specified, then the TERM signal will be sent. The list of supported signals is reported when using the
-l
option. On Linux and UNIX platforms,
pmsignal
is a simple wrapper around
       the
kill(1)
command."
1219,4,pmsignal,"The list of supported signals is reported when using the
-l
option. On Linux and UNIX platforms,
pmsignal
is a simple wrapper around
       the
kill(1)
command. On Windows, the is no direct equivalent to
       this mechanism, and so an alternate mechanism has been implemented
       - this is only honoured by PCP tools, however, not all Windows
       utilities."
1220,0,pmsleep,"pmpause
sleeps indefinitely, until interrupted by SIGKILL. pmsleep
sleeps for the specified
interval
. The
interval
argument
       follows the syntax described in
PCPIntro(1)
for
-t,
and in the
       simplest form may be an unsigned integer or floating point
       constant (the implied units in this case are seconds)."
1220,1,pmsleep,"The
interval
argument
       follows the syntax described in
PCPIntro(1)
for
-t,
and in the
       simplest form may be an unsigned integer or floating point
       constant (the implied units in this case are seconds). The
-w
option is provided to allow annotation of scripts with
       multiple uses of
pmpause
and/or
pmsleep
to identify a particular
       use in the process's arguments, e.g. as visible to
ps(1)
."
1221,0,pmrep,"pmrep
is a customizable performance metrics reporting tool. Any
       available performance metric, live or archived, system and/or
       application, can be selected for reporting using one of the output
       alternatives listed below together with applicable formatting
       options. pmrep
collects selected metric values through the facilities of
       the Performance Co-Pilot (PCP), see
PCPIntro(1)
."
1221,1,pmrep,"pmrep
collects selected metric values through the facilities of
       the Performance Co-Pilot (PCP), see
PCPIntro(1)
. The metrics to
       be reported are specified on the command line, in configuration
       files, or both. Metrics can be automatically converted and scaled
       using the PCP facilities, either by default or by per-metric
       scaling specifications."
1221,2,pmrep,"Metrics can be automatically converted and scaled
       using the PCP facilities, either by default or by per-metric
       scaling specifications. In addition to the existing metrics,
       derived metrics can be defined using the arithmetic expressions
       described in
pmRegisterDerived(3)
. A wide range of metricsets (see below) is included by default,
       providing reports on per-process details, NUMA performance,
       mimicking other tools like
sar(1)
and more, see the
pmrep
configuration files in
$PCP_SYSCONF_DIR/pmrep
(typically
/etc/pcp/pmrep
) for details."
1221,3,pmrep,"A wide range of metricsets (see below) is included by default,
       providing reports on per-process details, NUMA performance,
       mimicking other tools like
sar(1)
and more, see the
pmrep
configuration files in
$PCP_SYSCONF_DIR/pmrep
(typically
/etc/pcp/pmrep
) for details. Tab completion for options, metrics,
       and metricsets is available for bash and zsh. Unless directed to another host by the
-h
option,
pmrep
will
       contact the Performance Metrics Collector Daemon (PMCD, see
pmcd(1)
) on the local host."
1221,4,pmrep,"Unless directed to another host by the
-h
option,
pmrep
will
       contact the Performance Metrics Collector Daemon (PMCD, see
pmcd(1)
) on the local host. The
-a
option causes
pmrep
to use the specified set of archives
       rather than connecting to a PMCD. The
-a
and
-h
options are
       mutually exclusive."
1221,5,pmrep,"The
-a
and
-h
options are
       mutually exclusive. The
-L
option causes
pmrep
to use a local context to collect
       metrics from DSO PMDAs (Performance Metrics Domain Agents,
       ``plugins'') on the local host without PMCD. Only some metrics
       are available in this mode."
1221,6,pmrep,"Only some metrics
       are available in this mode. The
-a
,
-h
, and
-L
options are
       mutually exclusive. The metrics of interest are named in the
metricspec
argument(s)."
1221,7,pmrep,"The metrics of interest are named in the
metricspec
argument(s). If a metricspec specifies a non-leaf node in the Performance
       Metrics Name Space (PMNS), then
pmrep
will recursively descend the
       PMNS and report on all leaf nodes (i.e. metrics) for that
       metricspec."
1221,8,pmrep,"metrics) for that
       metricspec. Use
pminfo(1)
to list all the metrics (PMNS lead
       nodes) and their descriptions. A
metricspec
has three different forms."
1221,9,pmrep,"A
metricspec
has three different forms. First, on the command
       line it can start with a colon (``:'') to indicate a
metricset
to
       be read from
pmrep
configuration files (see
-c
and
pmrep.conf(5)
),
       which may then consist of any number of metrics. Second, a
metricspec
starting with non-colon specifies a PMNS node as
       described above, optionally followed by metric output formatting
       definitions."
1221,10,pmrep,"Second, a
metricspec
starting with non-colon specifies a PMNS node as
       described above, optionally followed by metric output formatting
       definitions. This so-called
compact form
of a metricspec is
       defined as follows:

     metric[,label[,instances[,unit/scale[,type[,width[,precision[,limit]]]]]]]

       A valid PMNS node (
metric
) is mandatory. It may be followed by a
       text
label
used with
stdout
output."
1221,11,pmrep,"It may be followed by a
       text
label
used with
stdout
output. The optional
instances
definition restricts
csv
and
stdout
reporting to the specified
       instances of the metric so non-matching instances will be filtered
       out (see
-i
). An optional
unit/scale
is applicable for dimension-
       compatible, non-string metrics."
1221,12,pmrep,"An optional
unit/scale
is applicable for dimension-
       compatible, non-string metrics. See below for supported
unit/scale
specifications. By default, cumulative counter metrics
       are converted to rates, an optional
type
can be set to
raw
to
       disable this rate conversion."
1221,13,pmrep,"By default, cumulative counter metrics
       are converted to rates, an optional
type
can be set to
raw
to
       disable this rate conversion. For
stdout
output a numeric
width
can be used to set the width of the output column for this metric. Too wide strings in the output will be truncated to fit the
       column."
1221,14,pmrep,"Too wide strings in the output will be truncated to fit the
       column. A metric-specific
precision
can be provided for numeric
       non-integer output values. Lastly, a metric-specific
limit
can be
       set for filtering out numeric values per the limit."
1221,15,pmrep,"Lastly, a metric-specific
limit
can be
       set for filtering out numeric values per the limit. As a special case for metrics that are counters with time units
       (nanoseconds to hours), the
unit/scale
can be used to change the
       default reporting (for example, milliseconds / second) to
       normalize to the range zero to one by setting this to
sec
(see
       also
-y
and
-Y
). The following
metricspec
requests the metric
kernel.all.sysfork
to
       be reported under the text label
forks
, converting to the metric
       default rate count/s in an
8
wide column."
1221,16,pmrep,"The following
metricspec
requests the metric
kernel.all.sysfork
to
       be reported under the text label
forks
, converting to the metric
       default rate count/s in an
8
wide column. Although the
       definitions in this
compact form
are optional, they must always be
       provided in the order specified above, thus the commas. kernel.all.sysfork,forks,,,,8

       The third form of a metricspec,
verbose form
, is described and
       valid only in
pmrep.conf(5)
."
1221,17,pmrep,"kernel.all.sysfork,forks,,,,8

       The third form of a metricspec,
verbose form
, is described and
       valid only in
pmrep.conf(5)
. Derived metrics are specified like regular PMNS leaf node metrics. Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any)."
1221,18,pmrep,"Options via environment values (see
pmGetOptions(3)
) override the
       corresponding built-in default values (if any). Configuration
       file options override the corresponding environment variables (if
       any). Command line options override the corresponding
       configuration file options (if any)."
1222,0,pmseries,"pmseries
displays various types of information about performance
       metrics available through the scalable timeseries facilities of
       the Performance Co-Pilot (PCP) and a distributed key-value data
       store such as
https://valkey/io/
.. By default
pmseries
communicates with a local key-value server
       however the
-h
and
-p
options can be used to specify an alternate
       key-value server. If this instance is a node within a cluster,
       all other instances in the cluster will be discovered and used
       automatically."
1222,1,pmseries,"If this instance is a node within a cluster,
       all other instances in the cluster will be discovered and used
       automatically. pmseries
runs in several different modes - either querying
       timeseries identifiers, metadata or values (already stored in the
       key-value store), or manually loading timeseries. The latter mode
       is generally only used for loading previously collected (inactive)
       archives, since
pmproxy(1)
automatically performs this function
       for ""live"" (actively growing) local
pmlogger(1)
instances, when
       running in its default time series mode."
1222,2,pmseries,"The latter mode
       is generally only used for loading previously collected (inactive)
       archives, since
pmproxy(1)
automatically performs this function
       for ""live"" (actively growing) local
pmlogger(1)
instances, when
       running in its default time series mode. See the
TIMESERIES
LOADING
section below and the
-L
option for further details. Without command line options specifying otherwise,
pmseries
will
       issue a timeseries query to find matching timeseries and values."
1222,3,pmseries,"Without command line options specifying otherwise,
pmseries
will
       issue a timeseries query to find matching timeseries and values. All timeseries are identified using a unique SHA-1 hash which is
       always displayed in a 40-hexdigit human readable form. These
       hashes are formed using the metadata associated with every metric."
1222,4,pmseries,"These
       hashes are formed using the metadata associated with every metric. Importantly, this includes all metric metadata (labels, names,
       descriptors). Metric labels in particular are (as far as
       possible) unique for every machine - on Linux for example the
       labels associated with every metric include the unique
/etc/machine-id
, the hostname, domainname, and other automatically
       generated machine labels, as well as any administrator-defined
       labels from
/etc/pcp/labels
."
1222,5,pmseries,"Metric labels in particular are (as far as
       possible) unique for every machine - on Linux for example the
       labels associated with every metric include the unique
/etc/machine-id
, the hostname, domainname, and other automatically
       generated machine labels, as well as any administrator-defined
       labels from
/etc/pcp/labels
. These labels can be reported with
pminfo(1)
and the
pmcd.labels
metric. See
pmLookupLabels(3)
,
pmLookupInDom(3)
,
pmLookupName(3)
and
pmLookupDesc(3)
for detailed information about metric labels and
       other metric metadata used in each timeseries identifier hash
       calculation."
1222,6,pmseries,"See
pmLookupLabels(3)
,
pmLookupInDom(3)
,
pmLookupName(3)
and
pmLookupDesc(3)
for detailed information about metric labels and
       other metric metadata used in each timeseries identifier hash
       calculation. The timeseries identifiers provide a higher level (and machine
       independent) identifier than the traditional PCP performance
       metric identifiers (pmID), instance domain identifiers (pmInDom)
       and metric names. See
PCPIntro(1)
for more details about these
       traditional identifiers."
1222,7,pmseries,"See
PCPIntro(1)
for more details about these
       traditional identifiers. However,
pmseries
uses timeseries
       identifiers in much the same way that
pminfo(1)
uses the lower
       level indom, metric identifiers and metric names. The default mode of
pmseries
operation (i.e."
1222,8,pmseries,"The default mode of
pmseries
operation (i.e. with no command line
       options) depends on the arguments it is presented. If all non-
       option arguments appear to be timeseries identifiers (in 40 hex
       digit form)
pmseries
will report metadata for these timeseries -
       refer to the
-a
option for details."
1222,9,pmseries,"with no command line
       options) depends on the arguments it is presented. If all non-
       option arguments appear to be timeseries identifiers (in 40 hex
       digit form)
pmseries
will report metadata for these timeseries -
       refer to the
-a
option for details. Otherwise, the parameters
       will be treated as a timeseries query."
1223,0,pmsnap,"pmsnap
is a shell script that is normally run periodically from
crontab(1)
to generate graphic images of
pmchart(1)
performance
       charts. These images can be in any of the supported
pmchart
formats, including
png
,
bmp
, and
jpeg
, and may be incorporated
       into the content offered by the local web server. By default
pmsnap
generates no textual output unless some error or warning
       condition is encountered."
1223,1,pmsnap,"By default
pmsnap
generates no textual output unless some error or warning
       condition is encountered. pmsnap
generates images according to its control file,
$PCP_PMSNAPCONTROL_PATH
(or
dir/control
if the
-C
option is
       specified), and uses archives created by
pmlogger(1)
or PCP
       archive folios created by
pmafm(1)
and
pmlogger_check(1)
. Before
       attempting to configure
pmsnap
, it is strongly recommended that
pmlogger
be configured according to the descriptions in
pmlogger_daily(1)
,
pmlogger_check(1)
and
pmlogger(1)
."
1223,2,pmsnap,"Before
       attempting to configure
pmsnap
, it is strongly recommended that
pmlogger
be configured according to the descriptions in
pmlogger_daily(1)
,
pmlogger_check(1)
and
pmlogger(1)
. Once
pmlogger
has been configured, it is necessary to configure
pmsnap
as follows;

       1. Edit the control file
$PCP_PMSNAPCONTROL_PATH
."
1223,3,pmsnap,"Edit the control file
$PCP_PMSNAPCONTROL_PATH
. The syntax
              of this file is described in the comment at the head of the
              file and an example is supplied for one and twelve hour
              ""Summary"" performance charts for the local host. Suitable
              arguments for
pmchart
are also described in the comment."
1223,4,pmsnap,"Suitable
              arguments for
pmchart
are also described in the comment. The user should consult
pmchart
for further details. Note
              that when
pmsnap
is run, it globally substitutes the string
LOCALHOSTNAME
with the name of the local host in the
              control file."
1223,5,pmsnap,"Note
              that when
pmsnap
is run, it globally substitutes the string
LOCALHOSTNAME
with the name of the local host in the
              control file. 2. Test the configuration by running
$PCP_BINADM_DIR/pmsnap
."
1223,6,pmsnap,"Test the configuration by running
$PCP_BINADM_DIR/pmsnap
. Without any arguments
pmsnap
will process every non-comment
              line in
$PCP_PMSNAPCONTROL_PATH
. The output images will be
              placed in the files named in the first field of each line
              in the control file, with the file format appended if
              necessary."
1223,7,pmsnap,"The output images will be
              placed in the files named in the first field of each line
              in the control file, with the file format appended if
              necessary. If these file names do not start with
/
or
. then they are assumed relative to
dir
, as specified with
              the
-o
option."
1223,8,pmsnap,"then they are assumed relative to
dir
, as specified with
              the
-o
option. The default
dir
is the current directory. Note that if
pmlogger
has only been recently started
              (within about the last 15 minutes), snapshot images may not
              be produced and no error messages will be issued - the
              reason is that
pmchart
can not use very short archives and
              hence, neither can
pmsnap
."
1223,9,pmsnap,"Note that if
pmlogger
has only been recently started
              (within about the last 15 minutes), snapshot images may not
              be produced and no error messages will be issued - the
              reason is that
pmchart
can not use very short archives and
              hence, neither can
pmsnap
. For debugging purposes the
-V
flag should be used. 3."
1223,10,pmsnap,"3. Add an appropriate entry for
pmsnap
in the
root
user's
crontab
. An example is supplied in
$PCP_VAR_DIR/config/pmlogger/crontab
."
1223,11,pmsnap,"An example is supplied in
$PCP_VAR_DIR/config/pmlogger/crontab
. 4. Incorporate the
pmsnap
images into the local WWW content."
1223,12,pmsnap,"Incorporate the
pmsnap
images into the local WWW content. Usually, WWW pages use images that are relative to a
              particular document root, so it is often convenient to use
              the
-o
command line option to specify a sub-directory of
              the local WWW content, and then create a web page in this
              directory that shows the snapshot images with text and
              other content appropriate to the local environment. A sample HTML page, suitable for the Summary snapshot may be found
       in
$PCP_VAR_DIR/config/pmsnap/Summary.html
."
1223,13,pmsnap,"A sample HTML page, suitable for the Summary snapshot may be found
       in
$PCP_VAR_DIR/config/pmsnap/Summary.html
. Although
pmsnap
attempts to flush
stdio(3)
output buffers in the
       relevant
pmlogger
processes before generating snapshots images,
       this may fail for assorted reasons and no error message will be
       given. pmsnap
should not be invoked immediately after
pmlogger_daily
has
       rolled the logs because the new archives will be too short to
       obtain meaningful results."
1223,14,pmsnap,"pmsnap
should not be invoked immediately after
pmlogger_daily
has
       rolled the logs because the new archives will be too short to
       obtain meaningful results. Note however that
pmsnap
will not
       report errors from
pmchart
about not being able to comply with the
-A
option on very short archives. In these cases no error will be
       reported and no output images will be produced."
1224,0,pmsocks,"pmsocks
allows Performance Co-Pilot (PCP) clients running on hosts
       located on the internal side of a TCP/IP firewall to monitor
       remote hosts on the other side of the firewall. This assumes the
       firewall has been configured with a compliant
sockd
daemon and the
       necessary access controls are satisfied. pmsocks
is a thin shell wrapper around the
tsocks
(8) library using
       the
tsocks
(1) utility, which are not included with PCP."
1224,1,pmsocks,"This assumes the
       firewall has been configured with a compliant
sockd
daemon and the
       necessary access controls are satisfied. pmsocks
is a thin shell wrapper around the
tsocks
(8) library using
       the
tsocks
(1) utility, which are not included with PCP. You can
       obtain
tsocks
from
https://tsocks.sourceforge.net/
."
1225,0,pmtrace,"pmtrace
provides a simple command line interface to the trace
       Performance Metrics Domain Agent (PMDA) and the associated
pcp_trace
library.

       The default
pmtrace
behavior is to provide point trace data to the
       trace PMDA, using the
tag
argument as the identifying name
       associated with each trace point.  The
tag
then becomes an
       instance identifier within the set of trace.point metrics."
1226,0,pmstore,"Under certain circumstances, it is useful to be able to modify the
       values of performance metrics, for example to re-initialize
       counters or to assign new values to metrics that act as control
       variables. pmstore
changes the current values for the nominated instances of
       a single performance metric, as identified by
metricname
and the
       list of instance identifiers following the
-i
argument. instances
must be a single argument, with elements of the list separated by
       commas and/or white space."
1226,1,pmstore,"instances
must be a single argument, with elements of the list separated by
       commas and/or white space. By default all instances of
metricname
will be updated. Normally
pmstore
operates on the default Performance Metrics Name
       Space (PMNS), see
PMNS(5)
, however if the
-n
option is specified
       an alternative namespace is loaded from the file
pmnsfile
."
1226,2,pmstore,"Normally
pmstore
operates on the default Performance Metrics Name
       Space (PMNS), see
PMNS(5)
, however if the
-n
option is specified
       an alternative namespace is loaded from the file
pmnsfile
. Unless directed to another host by the
-h
option,
pmstore
will
       interact with the Performance Metric Collector Daemon (PMCD) on
       the local host. The
-L
option causes
pmstore
to use a local context to store to
       metrics from PMDAs on the local host without PMCD."
1226,3,pmstore,"The
-L
option causes
pmstore
to use a local context to store to
       metrics from PMDAs on the local host without PMCD. Only some
       metrics are available in this mode. The
-h
and
-L
options are
       mutually exclusive."
1226,4,pmstore,"The
-h
and
-L
options are
       mutually exclusive. The
-f
option forces the given value to be stored, even if there
       is no current value set. The interpretation of
value
is dependent on the syntax used in its
       specification and the underlying data type of
metricname
, as
       follows."
1226,5,pmstore,"The interpretation of
value
is dependent on the syntax used in its
       specification and the underlying data type of
metricname
, as
       follows. 1. If the metric has an
integer
type, then
value
should be an
           optional leading hyphen, followed either by decimal digits or
           ``0x'' and some hexadecimal digits."
1226,6,pmstore,"If the metric has an
integer
type, then
value
should be an
           optional leading hyphen, followed either by decimal digits or
           ``0x'' and some hexadecimal digits. ``0X'' is also acceptable
           in lieu of ``0x''. See
strtol(3)
and the related routines."
1226,7,pmstore,"See
strtol(3)
and the related routines. 2. If the metric has a
floating point
type, then
value
should be
           either in the form of an integer described above, or a fixed
           point number, or a number in scientific notation."
1226,8,pmstore,"If the metric has a
floating point
type, then
value
should be
           either in the form of an integer described above, or a fixed
           point number, or a number in scientific notation. See
strtod(3)
. 3."
1226,9,pmstore,"3. If the metric has a
string
type, then
value
is interpreted as
           a literal string of ASCII characters. 4."
1226,10,pmstore,"4. If the metric has any other type (i.e. PM_TYPE_EVENT
or
PM_TYPE_AGGREGATE
) then no encoding of
value
from the command
           line makes sense, and the values of these metrics cannot be
           modified with
pmstore
."
1226,11,pmstore,"PM_TYPE_EVENT
or
PM_TYPE_AGGREGATE
) then no encoding of
value
from the command
           line makes sense, and the values of these metrics cannot be
           modified with
pmstore
. The output reports the old value and the new value for each
       updated instance of the requested metric. When using the
-L
option to fetch metrics from a local context,
       the
-K
option may be used to control the DSO PMDAs that should be
       made accessible."
1226,12,pmstore,"When using the
-L
option to fetch metrics from a local context,
       the
-K
option may be used to control the DSO PMDAs that should be
       made accessible. The
spec
argument conforms to the syntax
       described in
pmSpecLocalPMDA(3)
. More than one
-K
option may be
       used."
1226,13,pmstore,"More than one
-K
option may be
       used. Normally
pmstore
will report the old value (as initially retrieved
       using
pmFetch(3)
) and the new value from the command line. The
-F
option forces another
pmFetch(3)
after the
pmStore(3)
and the
       returned value is reported as the new value."
1226,14,pmstore,"The
-F
option forces another
pmFetch(3)
after the
pmStore(3)
and the
       returned value is reported as the new value. This is useful in
       cases where
metricname
is a metric that provides different
       semantics for the store operation, e.g. to increment the current
       value or reset a counter (independent of the
value
from the
       command line)."
1227,0,pmtime,"pmtime
is a graphical user interface for performance monitoring
       applications using the PCP infrastructure and requiring
       interactive time control. pmtime
is not normally invoked directly by users. Rather, it is
       more typical for it to be started by client applications (e.g."
1227,1,pmtime,"Rather, it is
       more typical for it to be started by client applications (e.g. pmchart(1)
,
pmstat(1)
or
pmval(1)
). There are two modes of interacting with a
pmtime
process - live
       host mode, and historical archive mode."
1227,2,pmtime,"There are two modes of interacting with a
pmtime
process - live
       host mode, and historical archive mode. In archive mode the
       window presents time controls suitable for manipulating the
       archive position, allowing full VCR control to move forwards and
       backwards in time at configurable rates and intervals. In live
       mode the
pmtime
window contains the simpler time controls suitable
       for live monitoring."
1227,3,pmtime,"In live
       mode the
pmtime
window contains the simpler time controls suitable
       for live monitoring. Note that the
pmtime
window is only made visible when explicitly
       requested. Multiple client applications can be connected to a
       single
pmtime
server - when the final client application exits,
pmtime
will also exit."
1228,0,pmstat,"pmstat
provides a one line summary of system performance every
interval
unit of time (the default is 5 seconds). pmstat
is
       intended to monitor system performance at the highest level, after
       which other tools may be used to examine subsystems in which
       potential performance problems may be observed in greater detail. pcp-vmstat
is a simple wrapper for use with the
pcp(1)
command,
       providing a more familiar command line format for some users."
1228,1,pmstat,"pcp-vmstat
is a simple wrapper for use with the
pcp(1)
command,
       providing a more familiar command line format for some users. It
       also enables the extended reporting option by default, see the
-x
option below. Multiple hosts may be monitored by supplying more than one host
       with multiple
-h
flags (for live monitoring) or by providing a
       name of the hostlist file, where each line contain one host name,
       with
-H,
or multiple
-a
flags (for retrospective monitoring from
       sets of archives)."
1228,2,pmstat,"Multiple hosts may be monitored by supplying more than one host
       with multiple
-h
flags (for live monitoring) or by providing a
       name of the hostlist file, where each line contain one host name,
       with
-H,
or multiple
-a
flags (for retrospective monitoring from
       sets of archives). By default,
pmstat
fetches metrics by connecting to the
       Performance Metrics Collector Daemon (PMCD) on the local host. If
       the
-L
option is specified, then
pmcd(1)
is bypassed, and metrics
       are fetched from PMDAs on the local host using the stand-alone
PM_CONTEXT_LOCAL
variant of
pmNewContext(3)
."
1228,3,pmstat,"If
       the
-L
option is specified, then
pmcd(1)
is bypassed, and metrics
       are fetched from PMDAs on the local host using the stand-alone
PM_CONTEXT_LOCAL
variant of
pmNewContext(3)
. When the
-h
option
       is specified,
pmstat
connects to the
pmcd(1)
on
host
and fetches
       metrics from there. As mentioned above, multiple hosts may be
       monitored by supplying multiple
-h
flags."
1228,4,pmstat,"As mentioned above, multiple hosts may be
       monitored by supplying multiple
-h
flags. Alternatively, if the
-a
option is used, the metrics are retrieved
       from the Performance Co-Pilot archive files identified by
archive
,
       which is a comma-separated list of names, each of which may be the
       base name of an archive or the name of a directory containing one
       or more archives. Multiple sets of archives may be replayed by
       supplying multiple
-a
flags."
1228,5,pmstat,"Multiple sets of archives may be replayed by
       supplying multiple
-a
flags. When the
-a
flag is used, the
-P
flag may also be used to pause the output after each interval. Stand-alone mode can only connect to the local host, using a set
       of archives implies a host name, and nominating a host precludes
       using an archive, so the options
-L
,
-a
and
-h
are mutually
       exclusive."
1228,6,pmstat,"Stand-alone mode can only connect to the local host, using a set
       of archives implies a host name, and nominating a host precludes
       using an archive, so the options
-L
,
-a
and
-h
are mutually
       exclusive. pmstat
may relinquish its own timing control, and operate under
       the control of a
pmtime(1)
process that uses a GUI dialog to
       provide timing control. In this case, either the
-g
option should
       be used to start
pmstat
as the sole client of a new
pmtime(1)
instance, or
-p
should be used to attach
pmstat
to an existing
pmtime(1)
instance via the IPC channel identified by the
port
argument."
1228,7,pmstat,"pmstat
may relinquish its own timing control, and operate under
       the control of a
pmtime(1)
process that uses a GUI dialog to
       provide timing control. In this case, either the
-g
option should
       be used to start
pmstat
as the sole client of a new
pmtime(1)
instance, or
-p
should be used to attach
pmstat
to an existing
pmtime(1)
instance via the IPC channel identified by the
port
argument. The
-S
,
-T
,
-O
and
-A
options may be used to define a time window
       to restrict the samples retrieved, set an initial origin within
       the time window, or specify a ``natural'' alignment of the sample
       times; refer to
PCPIntro(1)
for a complete description of these
       options."
1229,0,pmview,"pmview
is a generalized 3D performance metrics visualization tool
       for the Performance Co-Pilot (
PCP(1)
). pmview
is the base utility behind performance metrics
       visualization tools such as
dkvis(1)
,
mpvis(1)
,
osvis(1)
and
nfsvis(1)
, It is also used by a range of related tools that are
       specific to optional Performance Domain Agents (PMDA) and/or PCP
       add-on products. pmview
may also be used to construct customized
       3D performance displays."
1229,1,pmview,"pmview
may also be used to construct customized
       3D performance displays. pmview
displays performance metrics as colored blocks and
       cylinders arranged on monochrome base planes. Each object may
       represent a single performance metric, or a stack of several
       performance metrics."
1229,2,pmview,"Each object may
       represent a single performance metric, or a stack of several
       performance metrics. Since the objects are modulated by the value
       of the metric they represent, only numerical metrics may be
       visualized. Objects representing a single metric may be modulated
       in terms of height, color, or height and color."
1229,3,pmview,"Objects representing a single metric may be modulated
       in terms of height, color, or height and color. Objects in a
       stack may only be height modulated, but the stack can be
       normalized to the maximum height. Labels may be added to the
       scene to help identify groups of metrics."
1229,4,pmview,"Labels may be added to the
       scene to help identify groups of metrics. A configuration file (as specified by the
-c
option, or read from
       standard input) is used to specify the position, color, maximum
       value and labels of metrics and metric instances in the scene. The maximum value acts as a normalization factor and is used to
       scale the object height and/or color in proportion to the metric
       values."
1229,5,pmview,"The maximum value acts as a normalization factor and is used to
       scale the object height and/or color in proportion to the metric
       values. Metric values which exceed the associated maximum value
       are displayed as solid white objects. If a metric is unavailable,
       the object will have minimum height and will be colored grey."
1229,6,pmview,"If a metric is unavailable,
       the object will have minimum height and will be colored grey. The full syntax of the scene description language is provided in
pmview(5)
. Normally, the tool operates in ``live'' mode where performance
       metrics are fetched in real-time."
1229,7,pmview,"Normally, the tool operates in ``live'' mode where performance
       metrics are fetched in real-time. The user can view metrics from
       any host running
pmcd(1)
. pmview
can also replay archives of
       performance metrics (see
pmlogger(1)
) and allow the user to
       interactively control the current replay time and rate using the
       VCR paradigm."
1229,8,pmview,"pmview
can also replay archives of
       performance metrics (see
pmlogger(1)
) and allow the user to
       interactively control the current replay time and rate using the
       VCR paradigm. This is particularly useful for retrospective
       comparisons and for postmortem analysis of performance problems
       where a remote system is not accessible or a performance analyst
       is not available on-site. All metrics in the Performance Metrics Name Space (PMNS) with
       numeric value semantics from any number of hosts or archives may
       be visualized."
1229,9,pmview,"This is particularly useful for retrospective
       comparisons and for postmortem analysis of performance problems
       where a remote system is not accessible or a performance analyst
       is not available on-site. All metrics in the Performance Metrics Name Space (PMNS) with
       numeric value semantics from any number of hosts or archives may
       be visualized. pmview
examines the semantics of the metrics and
       where sensible, converts metric values to a rate before scaling."
1230,0,pmval,"pmval
prints current or archived values for the nominated
       performance metric. The metric of interest is named in the
metricname
argument, subject to instance qualification with the
-i
flag as described below. Unless directed to another host by the
-h
option, or to a set of
       archives by the
-a
or
-U
options,
pmval
will contact the
       Performance Metrics Collector Daemon (PMCD) on the local host to
       obtain the required information."
1230,1,pmval,"Unless directed to another host by the
-h
option, or to a set of
       archives by the
-a
or
-U
options,
pmval
will contact the
       Performance Metrics Collector Daemon (PMCD) on the local host to
       obtain the required information. The
metricname
argument may also be given in the metric
       specification syntax, as described in
PCPIntro(1)
, where the
       source, metric and instance may all be included in the
metricname
,
       e.g. thathost:kernel.all.load[""1 minute""]."
1230,2,pmval,"thathost:kernel.all.load[""1 minute""]. When this format is
       used, none of the
-h
or
-a
or
-U
options may be specified. When using the metric specification syntax, the ``hostname''
@
is
       treated specially and causes
pmval
to use a local context to
       collect metrics from PMDAs on the local host without PMCD."
1230,3,pmval,"When using the metric specification syntax, the ``hostname''
@
is
       treated specially and causes
pmval
to use a local context to
       collect metrics from PMDAs on the local host without PMCD. Only
       some metrics are available in this mode. When processing a set of archives,
pmval
may relinquish its own
       timing control, and operate under the control of a a
pmtime(1)
process that uses a GUI dialog to provide timing control."
1230,4,pmval,"When processing a set of archives,
pmval
may relinquish its own
       timing control, and operate under the control of a a
pmtime(1)
process that uses a GUI dialog to provide timing control. In this
       case, either the
-g
option should be used to start
pmval
as the
       sole client of a new
pmtime(1)
instance, or
-p
should be used to
       attach
pmval
to an existing
pmtime(1)
instance via the IPC channel
       identified by the
port
argument. The
-S
,
-T
,
-O
and
-A
options may be used to define a time window
       to restrict the samples retrieved, set an initial origin within
       the time window, or specify a ``natural'' alignment of the sample
       times; refer to
PCPIntro(1)
for a complete description of these
       options."
1230,5,pmval,"The
-S
,
-T
,
-O
and
-A
options may be used to define a time window
       to restrict the samples retrieved, set an initial origin within
       the time window, or specify a ``natural'' alignment of the sample
       times; refer to
PCPIntro(1)
for a complete description of these
       options. The output from
pmval
is directed to standard output. The
       following symbols may occasionally appear, in place of a metric
       value, in
pmval
output:  A question mark symbol (?) indicates that
       a value is no longer available for that metric instance."
1230,6,pmval,"The
       following symbols may occasionally appear, in place of a metric
       value, in
pmval
output:  A question mark symbol (?) indicates that
       a value is no longer available for that metric instance. An
       exclamation mark (!)  indicates that a 64-bit counter wrapped
       during the sample. pmevent
is an alias for
pmval
."
1231,0,pon,"This manual page describes the
pon
,
plog
and
poff
scripts, which
       allow users to control PPP connections. pon
pon
, invoked without arguments, runs the
/etc/ppp/ppp_on_boot
file, if it exists and is executable. Otherwise, a PPP connection
       will be started using configuration from
/etc/ppp/peers/provider
."
1231,1,pon,"Otherwise, a PPP connection
       will be started using configuration from
/etc/ppp/peers/provider
. This is the default behaviour unless an
isp-name
argument is
       given. For instance, to use ISP configuration ""myisp"" run:

              pon myisp
pon
will then use the options file
/etc/ppp/peers/myisp
."
1231,2,pon,"For instance, to use ISP configuration ""myisp"" run:

              pon myisp
pon
will then use the options file
/etc/ppp/peers/myisp
. You can
       pass additional
options
after the ISP name, too. pon
can be used
       to run multiple, simultaneous PPP connections."
1231,3,pon,"pon
can be used
       to run multiple, simultaneous PPP connections. poff
poff
closes a PPP connection. If more than one PPP connection
       exists, the one named in the argument to
poff
will be killed, e.g."
1231,4,pon,"If more than one PPP connection
       exists, the one named in the argument to
poff
will be killed, e.g. poff myprovider2

       will terminate the connection to myprovider2, and leave the PPP
       connections to e.g. ""myprovider1"" or ""myprovider3"" up and running."
1231,5,pon,"""myprovider1"" or ""myprovider3"" up and running. poff
takes the following command line options:
-r
causes the connection to be redialed after it is
                     dropped. -d
toggles the state of pppd's debug option."
1231,6,pon,"-d
toggles the state of pppd's debug option. -c
causes
pppd(8)
to renegotiate compression. -a
stops all running ppp connections."
1231,7,pon,"-a
stops all running ppp connections. If the argument
isp-name
is given it will be ignored. -h
displays help information."
1231,8,pon,"-h
displays help information. -v
prints the version and exits. If no argument is given,
poff
will stop or signal pppd if
              and only if there is exactly one running."
1231,9,pon,"If no argument is given,
poff
will stop or signal pppd if
              and only if there is exactly one running. If more than one
              connection is active, it will exit with an error code of 1. plog
plog
shows you the last few lines of
/var/log/ppp.log
."
1231,10,pon,"plog
plog
shows you the last few lines of
/var/log/ppp.log
. If that
       file doesn't exist, it shows you the last few lines of your
/var/log/syslog
file, but excluding the lines not generated by
       pppd. This script makes use of the
tail(1)
command, so arguments
       that can be passed to
tail(1)
can also be passed to
plog
."
1231,11,pon,"This script makes use of the
tail(1)
command, so arguments
       that can be passed to
tail(1)
can also be passed to
plog
. Note: the
plog
script can only be used by root or another system
       administrator in group ""adm"", due to security reasons. Also, to
       have all pppd-generated information in one logfile, that plog can
       show, you need the following line in your
/etc/syslog.conf
file:

       local2.*       -/var/log/ppp.log"
1232,0,pcpcompat,nan
1233,0,pon,"This manual page describes the
pon
,
plog
and
poff
scripts, which
       allow users to control PPP connections. pon
pon
, invoked without arguments, runs the
/etc/ppp/ppp_on_boot
file, if it exists and is executable. Otherwise, a PPP connection
       will be started using configuration from
/etc/ppp/peers/provider
."
1233,1,pon,"Otherwise, a PPP connection
       will be started using configuration from
/etc/ppp/peers/provider
. This is the default behaviour unless an
isp-name
argument is
       given. For instance, to use ISP configuration ""myisp"" run:

              pon myisp
pon
will then use the options file
/etc/ppp/peers/myisp
."
1233,2,pon,"For instance, to use ISP configuration ""myisp"" run:

              pon myisp
pon
will then use the options file
/etc/ppp/peers/myisp
. You can
       pass additional
options
after the ISP name, too. pon
can be used
       to run multiple, simultaneous PPP connections."
1233,3,pon,"pon
can be used
       to run multiple, simultaneous PPP connections. poff
poff
closes a PPP connection. If more than one PPP connection
       exists, the one named in the argument to
poff
will be killed, e.g."
1233,4,pon,"If more than one PPP connection
       exists, the one named in the argument to
poff
will be killed, e.g. poff myprovider2

       will terminate the connection to myprovider2, and leave the PPP
       connections to e.g. ""myprovider1"" or ""myprovider3"" up and running."
1233,5,pon,"""myprovider1"" or ""myprovider3"" up and running. poff
takes the following command line options:
-r
causes the connection to be redialed after it is
                     dropped. -d
toggles the state of pppd's debug option."
1233,6,pon,"-d
toggles the state of pppd's debug option. -c
causes
pppd(8)
to renegotiate compression. -a
stops all running ppp connections."
1233,7,pon,"-a
stops all running ppp connections. If the argument
isp-name
is given it will be ignored. -h
displays help information."
1233,8,pon,"-h
displays help information. -v
prints the version and exits. If no argument is given,
poff
will stop or signal pppd if
              and only if there is exactly one running."
1233,9,pon,"If no argument is given,
poff
will stop or signal pppd if
              and only if there is exactly one running. If more than one
              connection is active, it will exit with an error code of 1. plog
plog
shows you the last few lines of
/var/log/ppp.log
."
1233,10,pon,"plog
plog
shows you the last few lines of
/var/log/ppp.log
. If that
       file doesn't exist, it shows you the last few lines of your
/var/log/syslog
file, but excluding the lines not generated by
       pppd. This script makes use of the
tail(1)
command, so arguments
       that can be passed to
tail(1)
can also be passed to
plog
."
1233,11,pon,"This script makes use of the
tail(1)
command, so arguments
       that can be passed to
tail(1)
can also be passed to
plog
. Note: the
plog
script can only be used by root or another system
       administrator in group ""adm"", due to security reasons. Also, to
       have all pppd-generated information in one logfile, that plog can
       show, you need the following line in your
/etc/syslog.conf
file:

       local2.*       -/var/log/ppp.log"
1234,0,portablectl,"portablectl
may be used to attach, detach or inspect portable
       service images. It's primarily a command interfacing with
systemd-portabled.service(8)
. Portable service images contain an OS file system tree along with
systemd(1)
unit file information."
1234,1,portablectl,"Portable service images contain an OS file system tree along with
systemd(1)
unit file information. A service image may be
       ""attached"" to the local system. If attached, a set of unit files
       are copied from the image to the host, and extended with
RootDirectory=
or
RootImage=
assignments (in case of service
       units) pointing to the image file or directory, ensuring the
       services will run within the file system context of the image."
1234,2,portablectl,"If attached, a set of unit files
       are copied from the image to the host, and extended with
RootDirectory=
or
RootImage=
assignments (in case of service
       units) pointing to the image file or directory, ensuring the
       services will run within the file system context of the image. Portable service images are an efficient way to bundle multiple
       related services and other units together, and transfer them as a
       whole between systems. When these images are attached to the local
       system, the contained units may run in most ways like regular
       system-provided units, either with full privileges or inside
       strict sandboxing, depending on the selected configuration."
1234,3,portablectl,"When these images are attached to the local
       system, the contained units may run in most ways like regular
       system-provided units, either with full privileges or inside
       strict sandboxing, depending on the selected configuration. For
       more details, see
Portable Services
[1]. Portable service images may be of the following kinds:

       â¢   Directory trees containing an OS, including the top-level
           directories /usr/, /etc/, and so on."
1234,4,portablectl,"Portable service images may be of the following kinds:

       â¢   Directory trees containing an OS, including the top-level
           directories /usr/, /etc/, and so on. â¢   btrfs subvolumes containing OS trees, similar to normal
           directory trees. â¢   Binary ""raw"" disk images containing MBR or GPT partition
           tables and Linux file system partitions."
1234,5,portablectl,"â¢   btrfs subvolumes containing OS trees, similar to normal
           directory trees. â¢   Binary ""raw"" disk images containing MBR or GPT partition
           tables and Linux file system partitions. (These must be
           regular files, with the .raw suffix.)"
1235,0,ppdc,"ppdc
compiles PPDC source files into one or more PPD files.
This
program is deprecated and will be removed in a future release of
CUPS."
1236,0,ppdpo,"ppdpo
extracts UI strings from PPDC source files and updates
       either a GNU gettext or macOS strings format message catalog
       source file for translation.
This program is deprecated and will
be removed in a future release of CUPS."
1237,0,ppdi,"ppdi
imports one or more PPD files into a PPD compiler source
       file.  Multiple languages of the same PPD file are merged into a
       single printer definition to facilitate accurate changes for all
       localizations.
This program is deprecated and will be removed in
a future release of CUPS."
1238,0,ppdhtml,"ppdhtml
reads a driver information file and produces a HTML
       summary page that lists all of the drivers in a file and the
       supported options.
This program is deprecated and will be removed
in a future release of CUPS."
1239,0,ppdmerge,"ppdmerge
merges two or more PPD files into a single, multi-
       language PPD file.
This program is deprecated and will be removed
in a future release of CUPS."
1240,0,pr,"Paginate or columnate FILE(s) for printing. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
1240,1,pr,"Mandatory arguments to long options are mandatory for short
       options too. +FIRST_PAGE[:LAST_PAGE],
--pages
=
FIRST_PAGE[
:LAST_PAGE]
              begin [stop] printing with page FIRST_[LAST_]PAGE
-COLUMN
,
--columns
=
COLUMN
output COLUMN columns and print columns down, unless
-a
is
              used. Balance number of lines in the columns on each page
-a
,
--across
print columns across rather than down, used together with
-COLUMN
-c
,
--show-control-chars
use hat notation (^G) and octal backslash notation
-d
,
--double-space
double space the output
-D
,
--date-format
=
FORMAT
use FORMAT for the header date
-e[CHAR[WIDTH]]
,
--expand-tabs
[=
CHAR[WIDTH]
]
              expand input CHARs (TABs) to tab WIDTH (8)
-F
,
-f
,
--form-feed
use form feeds instead of newlines to separate pages (by a
              3-line page header with
-F
or a 5-line header and trailer
              without
-F
)
-h
,
--header
=
HEADER
use a centered HEADER instead of filename in page header,
-h
"""" prints a blank line, don't use
-h
""""
-i[CHAR[WIDTH]]
,
--output-tabs
[=
CHAR[WIDTH]
]
              replace spaces with CHARs (TABs) to tab WIDTH (8)
-J
,
--join-lines
merge full lines, turns off
-W
line truncation, no column
              alignment,
--sep-string
[=
STRING
] sets separators
-l
,
--length
=
PAGE_LENGTH
set the page length to PAGE_LENGTH (66) lines (default
              number of lines of text 56, and with
-F
63)."
1240,2,pr,"Balance number of lines in the columns on each page
-a
,
--across
print columns across rather than down, used together with
-COLUMN
-c
,
--show-control-chars
use hat notation (^G) and octal backslash notation
-d
,
--double-space
double space the output
-D
,
--date-format
=
FORMAT
use FORMAT for the header date
-e[CHAR[WIDTH]]
,
--expand-tabs
[=
CHAR[WIDTH]
]
              expand input CHARs (TABs) to tab WIDTH (8)
-F
,
-f
,
--form-feed
use form feeds instead of newlines to separate pages (by a
              3-line page header with
-F
or a 5-line header and trailer
              without
-F
)
-h
,
--header
=
HEADER
use a centered HEADER instead of filename in page header,
-h
"""" prints a blank line, don't use
-h
""""
-i[CHAR[WIDTH]]
,
--output-tabs
[=
CHAR[WIDTH]
]
              replace spaces with CHARs (TABs) to tab WIDTH (8)
-J
,
--join-lines
merge full lines, turns off
-W
line truncation, no column
              alignment,
--sep-string
[=
STRING
] sets separators
-l
,
--length
=
PAGE_LENGTH
set the page length to PAGE_LENGTH (66) lines (default
              number of lines of text 56, and with
-F
63). implies
-t
if
              PAGE_LENGTH <= 10
-m
,
--merge
print all files in parallel, one in each column, truncate
              lines, but join lines of full length with
-J
-n[SEP[DIGITS]]
,
--number-lines
[=
SEP[DIGITS]
]
              number lines, use DIGITS (5) digits, then SEP (TAB),
              default counting starts with 1st line of input file
-N
,
--first-line-number
=
NUMBER
start counting with NUMBER at 1st line of first page
              printed (see +FIRST_PAGE)
-o
,
--indent
=
MARGIN
offset each line with MARGIN (zero) spaces, do not affect
-w
or
-W
, MARGIN will be added to PAGE_WIDTH
-r
,
--no-file-warnings
omit warning when a file cannot be opened
-s[CHAR]
,
--separator
[=
CHAR
]
              separate columns by a single character, default for CHAR is
              the <TAB> character without
-w
and 'no char' with
-w
. -s[CHAR]
turns off line truncation of all 3 column options
              (
-COLUMN
|-a
-COLUMN
|-m) except
-w
is set
-S[STRING]
,
--sep-string
[=
STRING
]
              separate columns by STRING, without
-S
: Default separator
              <TAB> with
-J
and <space> otherwise (same as
-S
"" ""), no
              effect on column options
-t
,
--omit-header
omit page headers and trailers; implied if PAGE_LENGTH <=
              10
-T
,
--omit-pagination
omit page headers and trailers, eliminate any pagination by
              form feeds set in input files
-v
,
--show-nonprinting
use octal backslash notation
-w
,
--width
=
PAGE_WIDTH
set page width to PAGE_WIDTH (72) characters for multiple
              text-column output only,
-s[char]
turns off (72)
-W
,
--page-width
=
PAGE_WIDTH
set page width to PAGE_WIDTH (72) characters always,
              truncate lines, except
-J
option is set, no interference
              with
-S
or
-s
--help
display this help and exit
--version
output version information and exit"
1241,0,pr,"The
pr
utility is a printing and pagination filter. If multiple
       input files are specified, each shall be read, formatted, and
       written to standard output. By default, the input shall be
       separated into 66-line pages, each with:

        *  A 5-line header that includes the page number, date, time, and
           the pathname of the file

        *  A 5-line trailer consisting of blank lines

       If standard output is associated with a terminal, diagnostic
       messages shall be deferred until the
pr
utility has completed
       processing."
1241,1,pr,"By default, the input shall be
       separated into 66-line pages, each with:

        *  A 5-line header that includes the page number, date, time, and
           the pathname of the file

        *  A 5-line trailer consisting of blank lines

       If standard output is associated with a terminal, diagnostic
       messages shall be deferred until the
pr
utility has completed
       processing. When options specifying multi-column output are specified, output
       text columns shall be of equal width; input lines that do not fit
       into a text column shall be truncated. By default, text columns
       shall be separated with at least one <blank>."
1242,0,preconv,nan
1243,0,printenv,"Print the values of the specified environment VARIABLE(s). If no
       VARIABLE is specified, print name and value pairs for them all. -0
,
--null
end each output line with NUL, not newline
--help
display this help and exit
--version
output version information and exit

       Your shell may have its own version of printenv, which usually
       supersedes the version described here."
1243,1,printenv,"If no
       VARIABLE is specified, print name and value pairs for them all. -0
,
--null
end each output line with NUL, not newline
--help
display this help and exit
--version
output version information and exit

       Your shell may have its own version of printenv, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports."
1244,0,printf,"Print ARGUMENT(s) according to FORMAT, or execute according to
       OPTION:
--help
display this help and exit
--version
output version information and exit

       FORMAT controls the output as in C printf. Interpreted sequences
       are:

       \""     double quote

       \\     backslash

       \a     alert (BEL)

       \b     backspace

       \c     produce no further output

       \e     escape

       \f     form feed

       \n     new line

       \r     carriage return

       \t     horizontal tab

       \v     vertical tab

       \NNN   byte with octal value NNN (1 to 3 digits)

       \xHH   byte with hexadecimal value HH (1 to 2 digits)

       \uHHHH Unicode (ISO/IEC 10646) character with hex value HHHH (4
              digits)

       \UHHHHHHHH
              Unicode character with hex value HHHHHHHH (8 digits)

       %%     a single %

       %b     ARGUMENT as a string with '\' escapes interpreted, except
              that octal escapes should have a leading 0 like \0NNN

       %q     ARGUMENT is printed in a format that can be reused as shell
              input, escaping non-printable characters with the POSIX $''
              syntax

       and all C format specifications ending with one of diouxXfeEgGcs,
       with ARGUMENTs converted to proper type first. Variable widths
       are handled."
1244,1,printf,"Variable widths
       are handled. Your shell may have its own version of printf, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports."
1245,0,printf,"The
printf
utility shall write formatted operands to the standard
       output. The
argument
operands shall be formatted under control of
       the
format
operand."
1246,0,prs,"The
prs
utility shall write to standard output parts or all of an
       SCCS file in a user-supplied format."
1247,0,prlimit,"Given a process ID and one or more resources,
prlimit
tries to
       retrieve and/or modify the limits. When
command
is given,
prlimit
will run this command with the
       given arguments. The
limits
parameter is composed of a soft and a hard value,
       separated by a colon (:), in order to modify the existing values."
1247,1,prlimit,"The
limits
parameter is composed of a soft and a hard value,
       separated by a colon (:), in order to modify the existing values. If no
limits
are given,
prlimit
will display the current values. If one of the values is not given, then the existing one will be
       used."
1247,2,prlimit,"If one of the values is not given, then the existing one will be
       used. To specify the unlimited or infinity limit (
RLIM_INFINITY
),
       the -1 or 'unlimited' string can be passed. Because of the nature of limits, the soft limit must be lower or
       equal to the high limit (also called the ceiling)."
1247,3,prlimit,"Because of the nature of limits, the soft limit must be lower or
       equal to the high limit (also called the ceiling). To see all
       available resource limits, refer to the
RESOURCE OPTIONS
section. â¢
soft
:
hard
Specify both limits."
1247,4,prlimit,"â¢
soft
:
hard
Specify both limits. â¢
soft
: Specify only the soft limit. â¢   :
hard
Specify only the hard limit."
1247,5,prlimit,"â¢
soft
: Specify only the soft limit. â¢   :
hard
Specify only the hard limit. â¢
value
Specify both limits to the same value."
1248,0,prtstat,"prtstat
prints  the  statistics  of  the specified process.  This
       information comes from the
/proc/
pid
/stat
file."
1249,0,psfgettable,"psfgettable
extracts the embedded Unicode character table from a
       .psf format console font into a human readable ASCII file of the
       format used by
psfaddtable(1)
.  If the font file name is a single
       dash (-), the font is read from standard input."
1250,0,psfaddtable,"psfaddtable
takes a console font in .psf format given by
fontfile
and merges it with the Unicode character table given by
tablefile
to produce a font file with an embedded character table, which is
       written to
outfile
.  An input file name of ""-"" denotes standard
       input, and an output file name of ""-"" denotes standard output.  If
       the
fontfile
already contains an embedded character table, it is
       ignored."
1251,0,ps,"The
ps
utility shall write information about processes, subject to
       having appropriate privileges to obtain information about those
       processes.

       By default,
ps
shall select all processes with the same effective
       user ID as the current user and the same controlling terminal as
       the invoker."
1252,0,psfstriptable,"psfstriptable
reads a .psf format console font from
fontfile
,
       removes the embedded Unicode font table if there is one, and
       writes the result to
outfile
.  An input file name of ""-"" denotes
       standard input, and an output file name of ""-"" denotes standard
       output."
1253,0,ps,"ps
displays information about a selection of the active processes. If you want a repetitive update of the selection and the displayed
       information, use
top
instead. This version of
ps
accepts several kinds of options."
1253,1,ps,"This version of
ps
accepts several kinds of options. â¢   Unix options, which may be grouped and must be preceded by a
           dash. â¢   BSD options, which may be grouped and must not be used with a
           dash."
1253,2,ps,"â¢   BSD options, which may be grouped and must not be used with a
           dash. â¢   GNU long options, which are preceded by two dashes. Options of different types may be freely mixed, but conflicts can
       appear."
1253,3,ps,"Options of different types may be freely mixed, but conflicts can
       appear. There are some synonymous options, which are functionally
       identical, due to the many standards and
ps
implementations that
       this
ps
is compatible with. By default,
ps
selects all processes with the same effective user
       ID (euid=EUID) as the current user and associated with the same
       terminal as the invoker."
1253,4,ps,"By default,
ps
selects all processes with the same effective user
       ID (euid=EUID) as the current user and associated with the same
       terminal as the invoker. It displays the process ID (pid=PID),
       the terminal associated with the process (tname=TTY), the
       cumulated CPU time in [DD-]hh:mm:ss format (time=TIME), and the
       executable name (ucmd=CMD). Output is unsorted by default."
1253,5,ps,"Output is unsorted by default. The use of BSD-style options will add process state (stat=STAT) to
       the default display and show the command args (args=COMMAND)
       instead of the executable name. You can override this with the
PS_FORMAT
environment variable."
1253,6,ps,"You can override this with the
PS_FORMAT
environment variable. The use of BSD-style options will
       also change the process selection to include processes on other
       terminals (TTYs) that are owned by you; alternately, this may be
       described as setting the selection to be the set of all processes
       filtered to exclude processes owned by other users or not on a
       terminal. These effects are not considered when options are
       described as being ""identical"" below, so
-M
will be considered
       identical to
Z
and so on."
1253,7,ps,"These effects are not considered when options are
       described as being ""identical"" below, so
-M
will be considered
       identical to
Z
and so on. Except as described below, process selection options are additive. The default selection is discarded, and then the selected
       processes are added to the set of processes to be displayed."
1253,8,ps,"Except as described below, process selection options are additive. The default selection is discarded, and then the selected
       processes are added to the set of processes to be displayed. A
       process will thus be shown if it meets any of the given selection
       criteria."
1254,0,psfxtable,"psfxtable
handles the embedded Unicode character table for .psf
       format console fonts. It reads a font and possibly a table and
       writes a font and/or a table. psfaddtable(1)
,
psfgettable(1)
and
psfstriptable(1)
are links to it."
1254,1,psfxtable,"psfaddtable(1)
,
psfgettable(1)
and
psfstriptable(1)
are links to it. Each of the filenames
infont
,
outfont
,
intable
, and
outtable
may
       be replaced by a single dash (-), in which case standard input or
       standard output is used. If no
-i
option is given, the font is
       read from standard input."
1254,2,psfxtable,"If no
-i
option is given, the font is
       read from standard input. If no
-it
or
-o
or
-ot
option is given,
       no input table is read or no output font or output table is
       written. By default the output font (if any) will have a Unicode table when
       either the input font has one, or an explicit table (which
       overrides an input font table) has been provided."
1254,3,psfxtable,"By default the output font (if any) will have a Unicode table when
       either the input font has one, or an explicit table (which
       overrides an input font table) has been provided. The option
-nt
causes output of a font without table. When
outfont
is requested
       it will get a psf1 header when infont has a psf1 header and
intable
does not have sequences and a psf2 header otherwise."
1255,0,psktool,"Program  that generates random keys for use with TLS-PSK. The keys
       are stored in hexadecimal format in a key file."
1256,0,pslog,"The
pslog
command reports the current working logs of a process."
1257,0,pstree,"pstree
shows  running processes as a tree. The tree is rooted at
       either
pid
or
init
if
pid
is  omitted. If  a  user  name  is
       specified,  all  process  trees  rooted at processes owned by that
       user are shown."
1257,1,pstree,"If  a  user  name  is
       specified,  all  process  trees  rooted at processes owned by that
       user are shown. pstree
visually merges  identical  branches  by  putting  them  in
       square brackets and prefixing them with the repetition count, e.g. init-+-getty
                |-getty
                |-getty
                `-getty

       becomes

           init---4*[getty]

       Child  threads of a process are found under the parent process and
       are shown with the process name in curly braces, e.g."
1257,2,pstree,"init-+-getty
                |-getty
                |-getty
                `-getty

       becomes

           init---4*[getty]

       Child  threads of a process are found under the parent process and
       are shown with the process name in curly braces, e.g. icecast2---13*[{icecast2}]

       If
pstree
is called as
pstree.x11
then it will prompt the user  at
       the end of the line to press return and will not return until that
       has  happened. This  is  useful  for  when
pstree
is  run in a
       xterminal."
1257,3,pstree,"This  is  useful  for  when
pstree
is  run in a
       xterminal. Certain kernel or mount parameters, such as the
hidepid
option for
       procfs,  will  hide  information  for  some  processes. In  these
       situations
pstree
will  attempt  to  build the tree without this
       information, showing process names as question marks."
1258,0,ptx,"Output a permuted index, including context, of the words in the
       input files. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
1258,1,ptx,"Mandatory arguments to long options are mandatory for short
       options too. -A
,
--auto-reference
output automatically generated references
-G
,
--traditional
behave more like System V 'ptx'
-F
,
--flag-truncation
=
STRING
use STRING for flagging line truncations. The default is
              '/'
-M
,
--macro-name
=
STRING
macro name to use instead of 'xx'
-O
,
--format
=
roff
generate output as roff directives
-R
,
--right-side-refs
put references at right, not counted in
-w
-S
,
--sentence-regexp
=
REGEXP
for end of lines or end of sentences
-T
,
--format
=
tex
generate output as TeX directives
-W
,
--word-regexp
=
REGEXP
use REGEXP to match each keyword
-b
,
--break-file
=
FILE
word break characters in this FILE
-f
,
--ignore-case
fold lower case to upper case for sorting
-g
,
--gap-size
=
NUMBER
gap size in columns between output fields
-i
,
--ignore-file
=
FILE
read ignore word list from FILE
-o
,
--only-file
=
FILE
read only word list from this FILE
-r
,
--references
first field of each line is a reference
-t
,
--typeset-mode
- not implemented -
-w
,
--width
=
NUMBER
output width in columns, reference excluded
--help
display this help and exit
--version
output version information and exit"
1259,0,pwd,"Print the full filename of the current working directory. -L
,
--logical
use PWD from environment, even if it contains symlinks
-P
,
--physical
resolve all symlinks
--help
display this help and exit
--version
output version information and exit

       If no option is specified,
-P
is assumed. Your shell may have its own version of pwd, which usually
       supersedes the version described here."
1259,1,pwd,"-L
,
--logical
use PWD from environment, even if it contains symlinks
-P
,
--physical
resolve all symlinks
--help
display this help and exit
--version
output version information and exit

       If no option is specified,
-P
is assumed. Your shell may have its own version of pwd, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports."
1260,0,pwd,"The
pwd
utility shall write to standard output an absolute
       pathname of the current working directory, which does not contain
       the filenames dot or dot-dot."
1261,0,pwdx,nan
1262,0,pv,"Show the progress of data through a pipeline by giving information
       such as time elapsed, percentage completed (with progress bar),
       current throughput rate, total data transferred, and ETA. Each
FILE
is copied to standard output. With no
FILE
, or when
FILE
is â-â, standard input is read."
1262,1,pv,"Each
FILE
is copied to standard output. With no
FILE
, or when
FILE
is â-â, standard input is read. This is the same behaviour
       as
cat(1)
."
1263,0,qalter,"The attributes of a batch job are altered by a request to the
       batch server that manages the batch job. The
qalter
utility is a
       user-accessible batch client that requests the alteration of the
       attributes of one or more batch jobs. The
qalter
utility shall alter the attributes of those batch jobs,
       and only those batch jobs, for which a batch
job_identifier
is
       presented to the utility."
1263,1,qalter,"The
qalter
utility shall alter the attributes of those batch jobs,
       and only those batch jobs, for which a batch
job_identifier
is
       presented to the utility. The
qalter
utility shall alter the attributes of batch jobs in the
       order in which the batch
job_identifier
s are presented to the
       utility. If the
qalter
utility fails to process a batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any."
1263,2,qalter,"If the
qalter
utility fails to process a batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. For each batch
job_identifier
for which the
qalter
utility
       succeeds, each attribute of the identified batch job shall be
       altered as indicated by all the options presented to the utility. For each identified batch job for which the
qalter
utility fails,
       the utility shall not alter any attribute of the batch job."
1263,3,qalter,"For each identified batch job for which the
qalter
utility fails,
       the utility shall not alter any attribute of the batch job. For each batch job that the
qalter
utility processes, the utility
       shall not modify any attribute other than those required by the
       options and option-arguments presented to the utility. The
qalter
utility shall alter batch jobs by sending a
Modify Job
Request
to the batch server that manages each batch job."
1263,4,qalter,"The
qalter
utility shall alter batch jobs by sending a
Modify Job
Request
to the batch server that manages each batch job. At the
       time the
qalter
utility exits, it shall have modified the batch
       job corresponding to each successfully processed batch
job_identifier
. An attempt to alter the attributes of a batch job
       in the RUNNING state is implementation-defined."
1264,0,qdel,"A batch job is deleted by sending a request to the batch server
       that manages the batch job. A batch job that has been deleted is
       no longer subject to management by batch services. The
qdel
utility is a user-accessible client of batch services
       that requests the deletion of one or more batch jobs."
1264,1,qdel,"The
qdel
utility is a user-accessible client of batch services
       that requests the deletion of one or more batch jobs. The
qdel
utility shall request a batch server to delete those
       batch jobs for which a batch
job_identifier
is presented to the
       utility. The
qdel
utility shall delete batch jobs in the order in which
       their batch
job_identifier
s are presented to the utility."
1264,2,qdel,"The
qdel
utility shall delete batch jobs in the order in which
       their batch
job_identifier
s are presented to the utility. If the
qdel
utility fails to process any batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qdel
utility shall delete each batch job by sending a
Delete
Job Request
to the batch server that manages the batch job."
1264,3,qdel,"If the
qdel
utility fails to process any batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qdel
utility shall delete each batch job by sending a
Delete
Job Request
to the batch server that manages the batch job. The
qdel
utility shall not exit until the batch job corresponding
       to each successfully processed batch
job_identifier
has been
       deleted."
1265,0,qhold,"A hold is placed on a batch job by a request to the batch server
       that manages the batch job. A batch job that has one or more holds
       is not eligible for execution. The
qhold
utility is a user-
       accessible client of batch services that requests one or more
       types of hold to be placed on one or more batch jobs."
1265,1,qhold,"The
qhold
utility is a user-
       accessible client of batch services that requests one or more
       types of hold to be placed on one or more batch jobs. The
qhold
utility shall place holds on those batch jobs for which
       a batch
job_identifier
is presented to the utility. The
qhold
utility shall place holds on batch jobs in the order in
       which their batch
job_identifier
s are presented to the utility."
1265,2,qhold,"The
qhold
utility shall place holds on batch jobs in the order in
       which their batch
job_identifier
s are presented to the utility. If
       the
qhold
utility fails to process any batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qhold
utility shall place holds on each batch job by sending a
Hold Job Request
to the batch server that manages the batch job."
1265,3,qhold,"If
       the
qhold
utility fails to process any batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qhold
utility shall place holds on each batch job by sending a
Hold Job Request
to the batch server that manages the batch job. The
qhold
utility shall not exit until holds have been placed on
       the batch job corresponding to each successfully processed batch
job_identifier
."
1266,0,qmsg,"To send a message to a batch job is to request that a server write
       a message string into one or more output files of the batch job. A
       message is sent to a batch job by a request to the batch server
       that manages the batch job. The
qmsg
utility is a user-accessible
       batch client that requests the sending of messages to one or more
       batch jobs."
1266,1,qmsg,"The
qmsg
utility is a user-accessible
       batch client that requests the sending of messages to one or more
       batch jobs. The
qmsg
utility shall write messages into the files of batch jobs
       by sending a
Job Message Request
to the batch server that manages
       the batch job. The
qmsg
utility shall not directly write the
       message into the files of the batch job."
1266,2,qmsg,"The
qmsg
utility shall not directly write the
       message into the files of the batch job. The
qmsg
utility shall send a
Job Message Request
for those batch
       jobs, and only those batch jobs, for which a batch
job_identifier
is presented to the utility. The
qmsg
utility shall send
Job Message Request
s for batch jobs in
       the order in which their batch
job_identifier
s are presented to
       the utility."
1266,3,qmsg,"The
qmsg
utility shall send
Job Message Request
s for batch jobs in
       the order in which their batch
job_identifier
s are presented to
       the utility. If the
qmsg
utility fails to process any batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qmsg
utility shall not exit before a
Job Message Request
has
       been sent to the server that manages the batch job that
       corresponds to each successfully processed batch
job_identifier
."
1267,0,qmove,"To move a batch job is to remove the batch job from the batch
       queue in which it resides and instantiate the batch job in another
       batch queue. A batch job is moved by a request to the batch
       server that manages the batch job. The
qmove
utility is a user-
       accessible batch client that requests the movement of one or more
       batch jobs."
1267,1,qmove,"The
qmove
utility is a user-
       accessible batch client that requests the movement of one or more
       batch jobs. The
qmove
utility shall move those batch jobs, and only those
       batch jobs, for which a batch
job_identifier
is presented to the
       utility. The
qmove
utility shall move batch jobs in the order in which the
       corresponding batch
job_identifier
s are presented to the utility."
1267,2,qmove,"The
qmove
utility shall move batch jobs in the order in which the
       corresponding batch
job_identifier
s are presented to the utility. If the
qmove
utility fails to process a batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qmove
utility shall move batch jobs by sending a
Move Job
Request
to the batch server that manages each batch job."
1267,3,qmove,"If the
qmove
utility fails to process a batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qmove
utility shall move batch jobs by sending a
Move Job
Request
to the batch server that manages each batch job. The
qmove
utility shall not exit before the batch jobs corresponding to all
       successfully processed batch
job_identifier
s have been moved."
1268,0,qsig,"To signal a batch job is to send a signal to the session leader of
       the batch job. A batch job is signaled by sending a request to the
       batch server that manages the batch job. The
qsig
utility is a
       user-accessible batch client that requests the signaling of a
       batch job."
1268,1,qsig,"The
qsig
utility is a
       user-accessible batch client that requests the signaling of a
       batch job. The
qsig
utility shall signal those batch jobs for which a batch
job_identifier
is presented to the utility. The
qsig
utility shall
       not signal any batch jobs whose batch
job_identifier
s are not
       presented to the utility."
1268,2,qsig,"The
qsig
utility shall
       not signal any batch jobs whose batch
job_identifier
s are not
       presented to the utility. The
qsig
utility shall signal batch jobs in the order in which the
       corresponding batch
job_identifier
s are presented to the utility. If the
qsig
utility fails to process a batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any."
1268,3,qsig,"If the
qsig
utility fails to process a batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qsig
utility shall signal batch jobs by sending a
Signal Job
Request
to the batch server that manages the batch job. For each successfully processed batch
job_identifier
, the
qsig
utility shall have received a completion reply to each
Signal Job
Request
sent to a batch server at the time the utility exits."
1269,0,qrerun,"To rerun a batch job is to terminate the session leader of the
       batch job, delete any associated checkpoint files, and return the
       batch job to the batch queued state. A batch job is rerun by a
       request to the batch server that manages the batch job. The
qrerun
utility is a user-accessible batch client that requests the
       rerunning of one or more batch jobs."
1269,1,qrerun,"The
qrerun
utility is a user-accessible batch client that requests the
       rerunning of one or more batch jobs. The
qrerun
utility shall rerun those batch jobs for which a batch
job_identifier
is presented to the utility. The
qrerun
utility shall rerun batch jobs in the order in which
       their batch
job_identifier
s are presented to the utility."
1269,2,qrerun,"The
qrerun
utility shall rerun batch jobs in the order in which
       their batch
job_identifier
s are presented to the utility. If the
qrerun
utility fails to process any batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qrerun
utility shall rerun batch jobs by sending a
Rerun Job
Request
to the batch server that manages each batch job."
1269,3,qrerun,"If the
qrerun
utility fails to process any batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qrerun
utility shall rerun batch jobs by sending a
Rerun Job
Request
to the batch server that manages each batch job. For each successfully processed batch
job_identifier
, the
qrerun
utility shall have rerun the corresponding batch job at the time
       the utility exits."
1270,0,qrls,"A batch job might have one or more holds, which prevent the batch
       job from executing. A batch job from which all the holds have been
       removed becomes eligible for execution and is said to have been
       released. A batch job hold is removed by sending a request to the
       batch server that manages the batch job."
1270,1,qrls,"A batch job hold is removed by sending a request to the
       batch server that manages the batch job. The
qrls
utility is a
       user-accessible client of batch services that requests holds be
       removed from one or more batch jobs. The
qrls
utility shall remove one or more holds from those batch
       jobs for which a batch
job_identifier
is presented to the utility."
1270,2,qrls,"The
qrls
utility shall remove one or more holds from those batch
       jobs for which a batch
job_identifier
is presented to the utility. The
qrls
utility shall remove holds from batch jobs in the order
       in which their batch
job_identifier
s are presented to the utility. If the
qrls
utility fails to process a batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any."
1270,3,qrls,"If the
qrls
utility fails to process a batch
job_identifier
successfully, the utility shall proceed to process the remaining
       batch
job_identifier
s, if any. The
qrls
utility shall remove holds on each batch job by sending a
Release Job Request
to the batch server that manages the batch
       job. The
qrls
utility shall not exit until the holds have been removed
       from the batch job corresponding to each successfully processed
       batch
job_identifier
."
1271,0,qselect,"To select a set of batch jobs is to return the batch
job_identifier
s for each batch job that meets a list of selection
       criteria. A set of batch jobs is selected by a request to a batch
       server. The
qselect
utility is a user-accessible batch client that
       requests the selection of batch jobs."
1271,1,qselect,"The
qselect
utility is a user-accessible batch client that
       requests the selection of batch jobs. Upon successful completion, the
qselect
utility shall have
       returned a list of zero or more batch
job_identifier
s that meet
       the criteria specified by the options and option-arguments
       presented to the utility. The
qselect
utility shall select batch jobs by sending a
Select
Jobs Request
to a batch server."
1271,2,qselect,"The
qselect
utility shall select batch jobs by sending a
Select
Jobs Request
to a batch server. The
qselect
utility shall not exit
       until the server replies to each request generated. For each option presented to the
qselect
utility, the utility
       shall restrict the set of selected batch jobs as described in the
       OPTIONS section."
1271,3,qselect,"For each option presented to the
qselect
utility, the utility
       shall restrict the set of selected batch jobs as described in the
       OPTIONS section. The
qselect
utility shall not restrict selection of batch jobs
       except by authorization and as required by the options presented
       to the utility. When an option is specified with a mandatory or optional
op
component to the option-argument, then
op
shall specify a relation
       between the value of a certain batch job attribute and the
value
component of the option-argument."
1271,4,qselect,"When an option is specified with a mandatory or optional
op
component to the option-argument, then
op
shall specify a relation
       between the value of a certain batch job attribute and the
value
component of the option-argument. If an
op
is allowable on an
       option, then the description of the option letter indicates the
op
as either mandatory or optional. Acceptable strings for the
op
component, and the relation the string indicates, are shown in the
       following list:

       .eq."
1271,5,qselect,"Acceptable strings for the
op
component, and the relation the string indicates, are shown in the
       following list:

       .eq. The value represented by the attribute of the batch job is
               equal to the value represented by the option-argument. .ge."
1271,6,qselect,".ge. The value represented by the attribute of the batch job is
               greater than or equal to the value represented by the
               option-argument. .gt."
1271,7,qselect,".gt. The value represented by the attribute of the batch job is
               greater than the value represented by the option-argument. .lt."
1271,8,qselect,".lt. The value represented by the attribute of the batch job is
               less than the value represented by the option-argument. .le."
1271,9,qselect,".le. The value represented by the attribute of the batch job is
               less than or equal to the value represented by the option-
               argument. .ne."
1271,10,qselect,"The value represented by the attribute of the batch job is
               less than or equal to the value represented by the option-
               argument. .ne. The value represented by the attribute of the batch job is
               not equal to the value represented by the option-argument."
1272,0,qstat,"The status of a batch job, batch queue, or batch server is
       obtained by a request to the server. The
qstat
utility is a user-
       accessible batch client that requests the status of one or more
       batch jobs, batch queues, or servers, and writes the status
       information to standard output. For each successfully processed batch
job_identifier
, the
qstat
utility shall display information about the corresponding batch
       job."
1272,1,qstat,"For each successfully processed batch
job_identifier
, the
qstat
utility shall display information about the corresponding batch
       job. For each successfully processed destination, the
qstat
utility
       shall display information about the corresponding batch queue. For each successfully processed server name, the
qstat
utility
       shall display information about the corresponding server."
1272,2,qstat,"For each successfully processed server name, the
qstat
utility
       shall display information about the corresponding server. The
qstat
utility shall acquire batch job status information by
       sending a
Job Status Request
to a batch server. The
qstat
utility
       shall acquire batch queue status information by sending a
Queue
Status Request
to a batch server."
1272,3,qstat,"The
qstat
utility shall acquire batch job status information by
       sending a
Job Status Request
to a batch server. The
qstat
utility
       shall acquire batch queue status information by sending a
Queue
Status Request
to a batch server. The
qstat
utility shall acquire
       server status information by sending a
Server Status Request
to a
       batch server."
1273,0,quota,"quota
displays users' disk usage and limits. By default only the
       user quotas are printed. By default space usage and limits are
       shown in kbytes (and are named blocks for historical reasons)."
1273,1,quota,"By default space usage and limits are
       shown in kbytes (and are named blocks for historical reasons). quota
reports the quotas of all the filesystems listed in
/etc/mtab
. For filesystems that are NFS-mounted a call to the
       rpc.rquotad on the server machine is performed to get the
       information."
1274,0,quotasync,"quotasync
flushes file system usage and limits from kernel memory
       to quota files stored in the file system. By default only the user
       quotas are synchronized.

       This tool can be useful if you want to display accurate quotas by
       tools that parse quota files, like
repquota(8)
."
1275,0,qsub,"To submit a script is to create a batch job that executes the
       script. A script is submitted by a request to a batch server. The
qsub
utility is a user-accessible batch client that submits a
       script."
1275,1,qsub,"The
qsub
utility is a user-accessible batch client that submits a
       script. Upon successful completion, the
qsub
utility shall have created a
       batch job that will execute the submitted script. The
qsub
utility shall submit a script by sending a
Queue Job
Request
to a batch server."
1275,2,qsub,"The
qsub
utility shall submit a script by sending a
Queue Job
Request
to a batch server. The
qsub
utility shall place the value of the following
       environment variables in the
Variable_List
attribute of the batch
       job:
HOME
,
LANG
,
LOGNAME
,
PATH
,
MAIL
,
SHELL
, and
TZ
. The name of
       the environment variable shall be the current name prefixed with
       the string PBS_O_."
1275,3,qsub,"The name of
       the environment variable shall be the current name prefixed with
       the string PBS_O_. Note:
If the current value of the
HOME
variable in the
              environment space of the
qsub
utility is
/aa/bb/cc
, then
qsub
shall place
PBS_O_HOME
=
/aa/bb/cc
in the
Variable_List
attribute of the batch job. In addition to the variables described above, the
qsub
utility
       shall add the following variables with the indicated values to the
       variable list:
PBS_O_WORKDIR
The absolute path of the current working directory
                     of the
qsub
utility process."
1275,4,qsub,"Note:
If the current value of the
HOME
variable in the
              environment space of the
qsub
utility is
/aa/bb/cc
, then
qsub
shall place
PBS_O_HOME
=
/aa/bb/cc
in the
Variable_List
attribute of the batch job. In addition to the variables described above, the
qsub
utility
       shall add the following variables with the indicated values to the
       variable list:
PBS_O_WORKDIR
The absolute path of the current working directory
                     of the
qsub
utility process. PBS_O_HOST
The name of the host on which the
qsub
utility is
                     running."
1276,0,ranlib,"ranlib
generates an index to the contents of an archive and stores
       it in the archive. The index lists each symbol defined by a
       member of an archive that is a relocatable object file. You may use
nm -s
or
nm --print-armap
to list this index."
1276,1,ranlib,"You may use
nm -s
or
nm --print-armap
to list this index. An archive with such an index speeds up linking to the library and
       allows routines in the library to call each other without regard
       to their placement in the archive. The GNU
ranlib
program is another form of GNU
ar
; running
ranlib
is completely equivalent to executing
ar -s
."
1277,0,quilt,"Quilt
is a tool to manage large sets of patches by keeping track
       of the changes each patch makes. Patches can be applied,
       unapplied, refreshed, and so forth. The key philosophical concept
       is that your primary working material is patches."
1277,1,quilt,"The key philosophical concept
       is that your primary working material is patches. With
quilt
, all work occurs within a single directory tree. Commands can be invoked from anywhere within the source tree."
1277,2,quilt,"Commands can be invoked from anywhere within the source tree. Like
CVS
,
Subversion
, or
Git
,
quilt
takes commands of the form
       âquilt
command
â. A command can be truncated (abbreviated) as long
       as the specified part of the command is unambiguous."
1277,3,quilt,"A command can be truncated (abbreviated) as long
       as the specified part of the command is unambiguous. If
command
is ambiguously short,
quilt
lists all commands matching that
       prefix and exits. All commands print a brief contextual help
       message and exit if given the â-hâ option."
1277,4,quilt,"All commands print a brief contextual help
       message and exit if given the â-hâ option. Quilt
manages a stack of patches. Patches are applied
       incrementally on top of the base tree plus all preceding patches."
1277,5,quilt,"Patches are applied
       incrementally on top of the base tree plus all preceding patches. They can be pushed onto the stack (âquilt pushâ), and popped off
       the stack (âquilt popâ). Commands are available for querying the
       contents of the stack (âquilt appliedâ, âquilt previousâ, âquilt
       topâ) and the patches that are not applied at a particular moment
       (âquilt nextâ, âquilt unappliedâ)."
1277,6,quilt,"Commands are available for querying the
       contents of the stack (âquilt appliedâ, âquilt previousâ, âquilt
       topâ) and the patches that are not applied at a particular moment
       (âquilt nextâ, âquilt unappliedâ). By default, most commands
       apply to the topmost patch on the stack. Patch files are located in the
patches
subdirectory of the source
       tree (see
Example of working tree
, under
FILES
, below)."
1277,7,quilt,"Patch files are located in the
patches
subdirectory of the source
       tree (see
Example of working tree
, under
FILES
, below). The
QUILT_PATCHES
environment variable overrides this default
       location. When not found in the current directory, that
       subdirectory is searched recursively in the parent directories
       (this is similar to the way
Git
searches for its configuration
       files)."
1277,8,quilt,"When not found in the current directory, that
       subdirectory is searched recursively in the parent directories
       (this is similar to the way
Git
searches for its configuration
       files). The
patches
directory may contain subdirectories. It may
       also be a symbolic link instead of a directory."
1277,9,quilt,"It may
       also be a symbolic link instead of a directory. Quilt
creates and maintains a file called
series
, which defines
       the order in which patches are applied. The
QUILT_SERIES
environment variable overrides this default name."
1277,10,quilt,"The
QUILT_SERIES
environment variable overrides this default name. You can query
       the contents of the series file at any time with âquilt seriesâ. In this file, each patch file name is on a separate line."
1277,11,quilt,"In this file, each patch file name is on a separate line. Patch
       files are identified by path names that are relative to the
patches
directory; patches may be in subdirectories below this
       directory. Lines in the series file that start with a hash
       character (#) are ignored."
1277,12,quilt,"Lines in the series file that start with a hash
       character (#) are ignored. Patch options, such as the strip level
       or whether the patch is reversed, can be added after each patch
       file name. Options are introduced by a space, separated by
       spaces, and follow the syntax of the patch(1) options (e.g.,
       â-p2â)."
1277,13,quilt,"Options are introduced by a space, separated by
       spaces, and follow the syntax of the patch(1) options (e.g.,
       â-p2â). Quilt records patch options automatically when a command
       supporting them is used. Without options, strip level 1 is
       assumed."
1277,14,quilt,"Without options, strip level 1 is
       assumed. You can also add a comment after each patch file name
       and options, introduced by a space followed by a hash character. When
quilt
adds, removes, or renames patches, it automatically
       updates the series file."
1277,15,quilt,"When
quilt
adds, removes, or renames patches, it automatically
       updates the series file. Users of
quilt
can modify series files
       while some patches are applied, as long as the applied patches
       remain in their original order. Unless there are means by which a
       series file can be generated automatically, you should provide it
       along with any set of
quilt
-managed patches you distribute."
1277,16,quilt,"Unless there are means by which a
       series file can be generated automatically, you should provide it
       along with any set of
quilt
-managed patches you distribute. Different series files can be used to assemble patches in
       different ways, corresponding (for example) to different
       development branches. Before a patch is applied, copies of all files the patch modifies
       are saved to the
.pc/
patch-name directory, where
patch-name
is the
       name of the patch (for example,
fix-buffer-overflow.patch
)."
1277,17,quilt,"Before a patch is applied, copies of all files the patch modifies
       are saved to the
.pc/
patch-name directory, where
patch-name
is the
       name of the patch (for example,
fix-buffer-overflow.patch
). The
       patch is added to the list of currently applied patches
       (
.pc/applied-patches
). Later, when a patch is regenerated (âquilt
       refreshâ), the backup copies in
.pc/
patch-name are compared with
       the current versions of the files in the source tree using GNU
diff(1)
."
1277,18,quilt,"Later, when a patch is regenerated (âquilt
       refreshâ), the backup copies in
.pc/
patch-name are compared with
       the current versions of the files in the source tree using GNU
diff(1)
. A similar process occurs when starting a new patch (âquilt newâ);
       the new patch file name is added to the series file. A file to be
       changed by the patch is backed up and opened for editing (âquilt
       editâ)."
1277,19,quilt,"A file to be
       changed by the patch is backed up and opened for editing (âquilt
       editâ). After editing, inspect the impact of your changes (âquilt
       diffâ); the changes stay local to your working tree until you call
       âquilt refreshâ to write them to the patch file. Documentation related to a patch can be put at the beginning of
       its patch file (âquilt headerâ)."
1277,20,quilt,"Documentation related to a patch can be put at the beginning of
       its patch file (âquilt headerâ). Quilt
is careful to preserve all
       text that precedes the actual patch when doing a refresh. (This
       is limited to patches in unified format; see the GNU
Diffutils
manual.)

       The series file is looked up in the
.pc
directory, in the root of
       the source tree, and in the patches directory."
1277,21,quilt,"(This
       is limited to patches in unified format; see the GNU
Diffutils
manual.)

       The series file is looked up in the
.pc
directory, in the root of
       the source tree, and in the patches directory. The first series
       file that is found is used. This may also be a symbolic link, or
       a file with multiple hard links."
1277,22,quilt,"This may also be a symbolic link, or
       a file with multiple hard links. Usually, only one series file is
       used for a set of patches, making the patches subdirectory a
       convenient location. The
.pc
directory cannot be relocated, but it can be a symbolic
       link."
1277,23,quilt,"The
.pc
directory cannot be relocated, but it can be a symbolic
       link. Its subdirectories must not be renamed or restructured. While patches are applied to the source tree, this directory is
       essential for many operations, including popping patches off the
       stack and refreshing them."
1277,24,quilt,"While patches are applied to the source tree, this directory is
       essential for many operations, including popping patches off the
       stack and refreshing them. Files in the
.pc
directory are
       automatically removed when they are no longer needed, so there is
       no need to clean up manually. Quilt commands reference
add
[-P patch] {file} ..."
1277,25,quilt,"Quilt commands reference
add
[-P patch] {file} ... Add one or more files to the topmost or named patch. Files
           must be added to the patch before being modified."
1277,26,quilt,"Files
           must be added to the patch before being modified. Files that
           are modified by patches already applied on top of the
           specified patch cannot be added. -P patch

               Patch to add files to."
1277,27,quilt,"-P patch

               Patch to add files to. annotate
[-P patch] {file}

           Print an annotated listing of the specified file showing which
           patches modify which lines. Only applied patches are included."
1277,28,quilt,"Only applied patches are included. -P patch

               Stop checking for changes at the specified rather than the
               topmost patch. applied
[patch]

           Print a list of applied patches, or all patches up to and
           including the specified patch in the file series."
1277,29,quilt,"applied
[patch]

           Print a list of applied patches, or all patches up to and
           including the specified patch in the file series. delete
[-r] [--backup] [patch|-n]

           Remove the specified or topmost patch from the series file. If the patch is applied, quilt will attempt to remove it
           first."
1277,30,quilt,"If the patch is applied, quilt will attempt to remove it
           first. (Only the topmost patch can be removed right now.)

           -n  Delete the next patch after topmost, rather than the
               specified or topmost patch. -r  Remove the deleted patch file from the patches directory
               as well."
1277,31,quilt,"-r  Remove the deleted patch file from the patches directory
               as well. --backup

               Rename the patch file to patch~ rather than deleting it. Ignored if not used with `-r'."
1277,32,quilt,"Ignored if not used with `-r'. diff
[-p n|-p ab] [-u|-U num|-c|-C num] [--combine patch|-z] [-R]
       [-P patch] [--snapshot] [--diff=utility] [--no-timestamps] [--no-
       index] [--sort] [--color[=always|auto|never]] [file ...]

           Produces a diff of the specified file(s) in the topmost or
           specified patch. If no files are specified, all files that
           are modified are included."
1277,33,quilt,"If no files are specified, all files that
           are modified are included. -p n
               Create a -p n style patch (-p0 or -p1 are supported). -p ab
               Create a -p1 style patch, but use a/file and b/file as the
               original and new filenames instead of the default
               dir.orig/file and dir/file names."
1277,34,quilt,"-p ab
               Create a -p1 style patch, but use a/file and b/file as the
               original and new filenames instead of the default
               dir.orig/file and dir/file names. -u, -U num, -c, -C num

               Create a unified diff (-u, -U) with num lines of context. Create a context diff (-c, -C) with num lines of context."
1277,35,quilt,"Create a context diff (-c, -C) with num lines of context. The number of context lines defaults to 3. --no-timestamps

               Do not include file timestamps in patch headers."
1277,36,quilt,"--no-timestamps

               Do not include file timestamps in patch headers. --no-index

               Do not output Index: lines. -z  Write to standard output the changes that have been made
               relative to the topmost or specified patch."
1277,37,quilt,"-z  Write to standard output the changes that have been made
               relative to the topmost or specified patch. -R  Create a reverse diff. -P patch

               Create a diff for the specified patch."
1277,38,quilt,"-P patch

               Create a diff for the specified patch. (Defaults to the
               topmost patch.)

           --combine patch

               Create a combined diff for all patches between this patch
               and the patch specified with -P. A patch name of `-' is
               equivalent to specifying the first applied patch."
1277,39,quilt,"A patch name of `-' is
               equivalent to specifying the first applied patch. --snapshot

               Diff against snapshot (see `quilt snapshot -h'). --diff=utility

               Use the specified utility for generating the diff."
1277,40,quilt,"--diff=utility

               Use the specified utility for generating the diff. The
               utility is invoked with the original and new file name as
               arguments. --color[=always|auto|never]

               Use syntax coloring (auto activates it only if the output
               is a tty)."
1277,41,quilt,"--color[=always|auto|never]

               Use syntax coloring (auto activates it only if the output
               is a tty). --sort
               Sort files by their name instead of preserving the
               original order. edit
file ..."
1277,42,quilt,"edit
file ... Edit the specified file(s) in $EDITOR after adding it (them)
           to the topmost patch. files
[-v] [-a] [-l] [--combine patch] [patch]

           Print the list of files that the topmost or specified patch
           changes."
1277,43,quilt,"files
[-v] [-a] [-l] [--combine patch] [patch]

           Print the list of files that the topmost or specified patch
           changes. -a  List all files in all applied patches. -l  Add patch name to output."
1277,44,quilt,"-l  Add patch name to output. -v  Verbose, more user friendly output. --combine patch

               Create a listing for all patches between this patch and
               the topmost or specified patch."
1277,45,quilt,"--combine patch

               Create a listing for all patches between this patch and
               the topmost or specified patch. A patch name of `-' is
               equivalent to specifying the first applied patch. fold
[-R] [-q] [-f] [-p strip-level]

           Integrate the patch read from standard input into the topmost
           patch: After making sure that all files modified are part of
           the topmost patch, the patch is applied with the specified
           strip level (which defaults to 1)."
1277,46,quilt,"fold
[-R] [-q] [-f] [-p strip-level]

           Integrate the patch read from standard input into the topmost
           patch: After making sure that all files modified are part of
           the topmost patch, the patch is applied with the specified
           strip level (which defaults to 1). -R  Apply patch in reverse. -q  Quiet operation."
1277,47,quilt,"-q  Quiet operation. -f  Force apply, even if the patch has rejects. Unless in
               quiet mode, apply the patch interactively: the patch
               utility may ask questions."
1277,48,quilt,"Unless in
               quiet mode, apply the patch interactively: the patch
               utility may ask questions. -p strip-level

               The number of pathname components to strip from file names
               when applying patchfile. fork
[new_name]

           Fork the topmost patch."
1277,49,quilt,"fork
[new_name]

           Fork the topmost patch. Forking a patch means creating a
           verbatim copy of it under a new name, and use that new name
           instead of the original one in the current series. This is
           useful when a patch has to be modified, but the original
           version of it should be preserved, e.g."
1277,50,quilt,"This is
           useful when a patch has to be modified, but the original
           version of it should be preserved, e.g. because it is used in
           another series, or for the history. A typical sequence of
           commands would be: fork, edit, refresh."
1277,51,quilt,"A typical sequence of
           commands would be: fork, edit, refresh. If new_name is missing, the name of the forked patch will be
           the current patch name, followed by `-2'. If the patch name
           already ends in a dash-and-number, the number is further
           incremented (e.g., patch.diff, patch-2.diff, patch-3.diff)."
1277,52,quilt,"If the patch name
           already ends in a dash-and-number, the number is further
           incremented (e.g., patch.diff, patch-2.diff, patch-3.diff). graph
[--all] [--reduce] [--lines[=num]] [--edge-labels=files] [-T
       ps] [patch]

           Generate a dot(1) directed graph showing the dependencies
           between applied patches. A patch depends on another patch if
           both touch the same file or, with the --lines option, if their
           modifications overlap."
1277,53,quilt,"A patch depends on another patch if
           both touch the same file or, with the --lines option, if their
           modifications overlap. Unless otherwise specified, the graph
           includes all patches that the topmost patch depends on. When
           a patch name is specified, instead of the topmost patch,
           create a graph for the specified patch."
1277,54,quilt,"When
           a patch name is specified, instead of the topmost patch,
           create a graph for the specified patch. The graph will include
           all other patches that this patch depends on, as well as all
           patches that depend on this patch. --all
               Generate a graph including all applied patches and their
               dependencies."
1277,55,quilt,"--all
               Generate a graph including all applied patches and their
               dependencies. (Unapplied patches are not included.)

           --reduce

               Eliminate transitive edges from the graph. --lines[=num]

               Compute dependencies by looking at the lines the patches
               modify."
1277,56,quilt,"--lines[=num]

               Compute dependencies by looking at the lines the patches
               modify. Unless a different num is specified, two lines of
               context are included. --edge-labels=files

               Label graph edges with the file names that the adjacent
               patches modify."
1277,57,quilt,"--edge-labels=files

               Label graph edges with the file names that the adjacent
               patches modify. -T ps
               Directly produce a PostScript output file. grep
[-h|options] {pattern}

           Grep through the source files, recursively, skipping patches
           and quilt meta-information."
1277,58,quilt,"grep
[-h|options] {pattern}

           Grep through the source files, recursively, skipping patches
           and quilt meta-information. If no filename argument is given,
           the whole source tree is searched. Please see the grep(1)
           manual page for options."
1277,59,quilt,"Please see the grep(1)
           manual page for options. -h  Print this help. The grep -h option can be passed after a
               double-dash (--)."
1277,60,quilt,"The grep -h option can be passed after a
               double-dash (--). Search expressions that start with a
               dash can be passed after a second double-dash (-- --). header
[-a|-r|-e] [--backup] [--strip-diffstat] [--strip-trailing-
       whitespace] [patch]

           Print or change the header of the topmost or specified patch."
1277,61,quilt,"header
[-a|-r|-e] [--backup] [--strip-diffstat] [--strip-trailing-
       whitespace] [patch]

           Print or change the header of the topmost or specified patch. -a, -r, -e

               Append to (-a) or replace (-r) the exiting patch header,
               or edit (-e) the header in $EDITOR. If none of these
               options is given, print the patch header."
1277,62,quilt,"If none of these
               options is given, print the patch header. --strip-diffstat

               Strip diffstat output from the header. --strip-trailing-whitespace

               Strip trailing whitespace at the end of lines of the
               header."
1277,63,quilt,"--strip-trailing-whitespace

               Strip trailing whitespace at the end of lines of the
               header. --backup

               Create a backup copy of the old version of a patch as
               patch~. import
[-p num] [-R] [-P patch] [-f] [-d {o|a|n}] patchfile ..."
1277,64,quilt,"import
[-p num] [-R] [-P patch] [-f] [-d {o|a|n}] patchfile ... Import external patches. The patches will be inserted
           following the current top patch, and must be pushed after
           import to apply them."
1277,65,quilt,"The patches will be inserted
           following the current top patch, and must be pushed after
           import to apply them. -p num

               Number of directory levels to strip when applying
               (default=1)

           -R

               Apply patch in reverse. -P patch

               Patch filename to use inside quilt."
1277,66,quilt,"-P patch

               Patch filename to use inside quilt. This option can only
               be used when importing a single patch. -f  Overwrite/update existing patches."
1277,67,quilt,"-f  Overwrite/update existing patches. -d {o|a|n}

               When overwriting in existing patch, keep the old (o), all
               (a), or new (n) patch header. If both patches include
               headers, this option must be specified."
1277,68,quilt,"If both patches include
               headers, this option must be specified. This option is
               only effective when -f is used. mail
{--mbox file|--send} [-m text] [-M file] [--prefix prefix]
       [--sender ...] [--from ...] [--to ...] [--cc ...] [--bcc ...]
       [--subject ...] [--reply-to message] [--charset ...] [--signature
       file] [first_patch [last_patch]]

           Create mail messages from a specified range of patches, or all
           patches in the series file, and either store them in a mailbox
           file, or send them immediately."
1277,69,quilt,"mail
{--mbox file|--send} [-m text] [-M file] [--prefix prefix]
       [--sender ...] [--from ...] [--to ...] [--cc ...] [--bcc ...]
       [--subject ...] [--reply-to message] [--charset ...] [--signature
       file] [first_patch [last_patch]]

           Create mail messages from a specified range of patches, or all
           patches in the series file, and either store them in a mailbox
           file, or send them immediately. The editor is opened with a
           template for the introduction. Please see
           /usr/local/share/doc/quilt/README.MAIL for details."
1277,70,quilt,"Please see
           /usr/local/share/doc/quilt/README.MAIL for details. When
           specifying a range of patches, a first patch name of `-'
           denotes the first, and a last patch name of `-' denotes the
           last patch in the series. -m text

               Text to use as the text in the introduction."
1277,71,quilt,"-m text

               Text to use as the text in the introduction. When this
               option is used, the editor will not be invoked, and the
               patches will be processed immediately. -M file

               Like the -m option, but read the introduction from file."
1277,72,quilt,"-M file

               Like the -m option, but read the introduction from file. --prefix prefix

               Use an alternate prefix in the bracketed part of the
               subjects generated. Defaults to `patch'."
1277,73,quilt,"Defaults to `patch'. --mbox file

               Store all messages in the specified file in mbox format. The mbox can later be sent using formail, for example."
1277,74,quilt,"The mbox can later be sent using formail, for example. --send

               Send the messages directly. --sender

               The envelope sender address to use."
1277,75,quilt,"--sender

               The envelope sender address to use. The address must be of
               the form `user@domain.name'. No display name is allowed."
1277,76,quilt,"No display name is allowed. --from, --subject

               The values for the From and Subject headers to use. If no
               --from option is given, the value of the --sender option
               is used."
1277,77,quilt,"If no
               --from option is given, the value of the --sender option
               is used. --to, --cc, --bcc

               Append a recipient to the To, Cc, or Bcc header. --charset

               Specify a particular message encoding on systems which
               don't use UTF-8 or ISO-8859-15."
1277,78,quilt,"--charset

               Specify a particular message encoding on systems which
               don't use UTF-8 or ISO-8859-15. This character encoding
               must match the one used in the patches. --signature file

               Append the specified signature to messages (defaults to
               ~/.signature if found; use `-' for no signature)."
1277,79,quilt,"--signature file

               Append the specified signature to messages (defaults to
               ~/.signature if found; use `-' for no signature). --reply-to message

               Add the appropriate headers to reply to the specified
               message. new
[-p n] {patchname}

           Create a new patch with the specified file name, and insert it
           after the topmost patch."
1277,80,quilt,"new
[-p n] {patchname}

           Create a new patch with the specified file name, and insert it
           after the topmost patch. The name can be prefixed with a sub-
           directory name, allowing for grouping related patches
           together. -p n
               Create a -p n style patch (-p0 or -p1 are supported)."
1277,81,quilt,"-p n
               Create a -p n style patch (-p0 or -p1 are supported). Quilt can be used in sub-directories of a source tree. It
               determines the root of a source tree by searching for a
               directory above the current working directory."
1277,82,quilt,"It
               determines the root of a source tree by searching for a
               directory above the current working directory. Create a
               directory in the intended root directory if quilt chooses
               a top-level directory that is too high up in the directory
               tree. next
[patch]

           Print the name of the next patch after the specified or
           topmost patch in the series file."
1277,83,quilt,"next
[patch]

           Print the name of the next patch after the specified or
           topmost patch in the series file. patches
[-v] [--color[=always|auto|never]] {file} [files...]

           Print the list of patches that modify any of the specified
           files. (Uses a heuristic to determine which files are modified
           by unapplied patches."
1277,84,quilt,"(Uses a heuristic to determine which files are modified
           by unapplied patches. Note that this heuristic is much slower
           than scanning applied patches.)

           -v  Verbose, more user friendly output. --color[=always|auto|never]

               Use syntax coloring (auto activates it only if the output
               is a tty)."
1277,85,quilt,"--color[=always|auto|never]

               Use syntax coloring (auto activates it only if the output
               is a tty). pop
[-afRqv] [--refresh] [num|patch]

           Remove patch(es) from the stack of applied patches. Without
           options, the topmost patch is removed."
1277,86,quilt,"Without
           options, the topmost patch is removed. When a number is
           specified, remove the specified number of patches. When a
           patch name is specified, remove patches until the specified
           patch end up on top of the stack."
1277,87,quilt,"When a
           patch name is specified, remove patches until the specified
           patch end up on top of the stack. Patch names may include the
           patches/ prefix, which means that filename completion can be
           used. -a  Remove all applied patches."
1277,88,quilt,"-a  Remove all applied patches. -f  Force remove. The state before the patch(es) were applied
               will be restored from backup files."
1277,89,quilt,"The state before the patch(es) were applied
               will be restored from backup files. -R  Always verify if the patch removes cleanly; don't rely on
               timestamp checks. -q  Quiet operation."
1277,90,quilt,"-q  Quiet operation. -v  Verbose operation. --refresh

               Automatically refresh every patch before it gets
               unapplied."
1277,91,quilt,"--refresh

               Automatically refresh every patch before it gets
               unapplied. previous
[patch]

           Print the name of the previous patch before the specified or
           topmost patch in the series file. push
[-afqvm] [--fuzz=N] [--merge[=merge|diff3]] [--leave-rejects]
       [--color[=always|auto|never]] [--refresh] [num|patch]

           Apply patch(es) from the series file."
1277,92,quilt,"push
[-afqvm] [--fuzz=N] [--merge[=merge|diff3]] [--leave-rejects]
       [--color[=always|auto|never]] [--refresh] [num|patch]

           Apply patch(es) from the series file. Without options, the
           next patch in the series file is applied. When a number is
           specified, apply the specified number of patches."
1277,93,quilt,"When a number is
           specified, apply the specified number of patches. When a
           patch name is specified, apply all patches up to and including
           the specified patch. Patch names may include the patches/
           prefix, which means that filename completion can be used."
1277,94,quilt,"Patch names may include the patches/
           prefix, which means that filename completion can be used. -a  Apply all patches in the series file. -q  Quiet operation."
1277,95,quilt,"-q  Quiet operation. -f  Force apply, even if the patch has rejects. -v  Verbose operation."
1277,96,quilt,"-v  Verbose operation. --fuzz=N

               Set the maximum fuzz factor (default: 2). -m, --merge[=merge|diff3]

               Merge the patch file into the original files (see
               patch(1))."
1277,97,quilt,"-m, --merge[=merge|diff3]

               Merge the patch file into the original files (see
               patch(1)). --leave-rejects

               Leave around the reject files patch produced, even if the
               patch is not actually applied. --color[=always|auto|never]

               Use syntax coloring (auto activates it only if the output
               is a tty)."
1277,98,quilt,"--color[=always|auto|never]

               Use syntax coloring (auto activates it only if the output
               is a tty). --refresh

               Automatically refresh every patch after it was
               successfully applied. refresh
[-p n|-p ab] [-u|-U num|-c|-C num] [-z[new_name]] [-f]
       [--no-timestamps] [--no-index] [--diffstat] [--sort] [--backup]
       [--strip-trailing-whitespace] [patch]

           Refreshes the specified patch, or the topmost patch by
           default."
1277,99,quilt,"refresh
[-p n|-p ab] [-u|-U num|-c|-C num] [-z[new_name]] [-f]
       [--no-timestamps] [--no-index] [--diffstat] [--sort] [--backup]
       [--strip-trailing-whitespace] [patch]

           Refreshes the specified patch, or the topmost patch by
           default. Documentation that comes before the actual patch in
           the patch file is retained. It is possible to refresh patches that are not on top."
1277,100,quilt,"It is possible to refresh patches that are not on top. If any
           patches on top of the patch to refresh modify the same files,
           the script aborts by default. Patches can still be refreshed
           with -f."
1277,101,quilt,"Patches can still be refreshed
           with -f. In that case this script will print a warning for
           each shadowed file, changes by more recent patches will be
           ignored, and only changes in files that have not been modified
           by any more recent patches will end up in the specified patch. -p n
               Create a -p n style patch (-p0 or -p1 supported)."
1277,102,quilt,"-p n
               Create a -p n style patch (-p0 or -p1 supported). -p ab
               Create a -p1 style patch, but use a/file and b/file as the
               original and new filenames instead of the default
               dir.orig/file and dir/file names. -u, -U num, -c, -C num

               Create a unified diff (-u, -U) with num lines of context."
1277,103,quilt,"-u, -U num, -c, -C num

               Create a unified diff (-u, -U) with num lines of context. Create a context diff (-c, -C) with num lines of context. The number of context lines defaults to 3."
1277,104,quilt,"The number of context lines defaults to 3. -z[new_name]

               Create a new patch containing the changes instead of
               refreshing the topmost patch. If no new name is specified,
               `-2' is added to the original patch name, etc."
1277,105,quilt,"If no new name is specified,
               `-2' is added to the original patch name, etc. (See the
               fork command.)

           --no-timestamps

               Do not include file timestamps in patch headers. --no-index

               Do not output Index: lines."
1277,106,quilt,"--no-index

               Do not output Index: lines. --diffstat

               Add a diffstat section to the patch header, or replace the
               existing diffstat section. -f  Enforce refreshing of a patch that is not on top."
1277,107,quilt,"-f  Enforce refreshing of a patch that is not on top. --backup

               Create a backup copy of the old version of a patch as
               patch~. --sort
               Sort files by their name instead of preserving the
               original order."
1277,108,quilt,"--sort
               Sort files by their name instead of preserving the
               original order. --strip-trailing-whitespace

               Strip trailing whitespace at the end of lines. remove
[-P patch] {file} ..."
1277,109,quilt,"remove
[-P patch] {file} ... Remove one or more files from the topmost or named patch. Files that are modified by patches on top of the specified
           patch cannot be removed."
1277,110,quilt,"Files that are modified by patches on top of the specified
           patch cannot be removed. -P patch

               Remove named files from the named patch. rename
[-P patch] new_name

           Rename the topmost or named patch."
1277,111,quilt,"rename
[-P patch] new_name

           Rename the topmost or named patch. -P patch

               Patch to rename. revert
[-P patch] {file} ..."
1277,112,quilt,"revert
[-P patch] {file} ... Revert uncommitted changes to the topmost or named patch for
           the specified file(s): after the revert, 'quilt diff -z' will
           show no differences for those files. Changes to files that are
           modified by patches on top of the specified patch cannot be
           reverted."
1277,113,quilt,"Changes to files that are
           modified by patches on top of the specified patch cannot be
           reverted. -P patch

               Revert changes in the named patch. series
[--color[=always|auto|never]] [-v]

           Print the names of all patches in the series file."
1277,114,quilt,"series
[--color[=always|auto|never]] [-v]

           Print the names of all patches in the series file. --color[=always|auto|never]

               Use syntax coloring (auto activates it only if the output
               is a tty). -v  Verbose, more user friendly output."
1277,115,quilt,"-v  Verbose, more user friendly output. setup
[-d path-prefix] [-v] [--sourcedir dir] [--fuzz=N]
       [--slow|--fast] {specfile|seriesfile}

           Initializes a source tree from an rpm spec file or a quilt
           series file. -d  Optional path prefix for the resulting source tree."
1277,116,quilt,"-d  Optional path prefix for the resulting source tree. --sourcedir

               Directory that contains the package sources. Defaults to
               `.'."
1277,117,quilt,"Defaults to
               `.'. -v  Verbose debug output. --fuzz=N

               Set the maximum fuzz factor (needs rpm 4.6 or later)."
1277,118,quilt,"--fuzz=N

               Set the maximum fuzz factor (needs rpm 4.6 or later). --slow
               Use the original, slow method to process the spec file. In
               this mode, rpmbuild generates a working tree in a
               temporary directory while all its actions are recorded,
               and then everything is replayed from scratch in the target
               directory."
1277,119,quilt,"In
               this mode, rpmbuild generates a working tree in a
               temporary directory while all its actions are recorded,
               and then everything is replayed from scratch in the target
               directory. --fast
               Use the new, faster method to process the spec file. In
               this mode, rpmbuild is told to generate a working tree
               directly in the target directory."
1277,120,quilt,"In
               this mode, rpmbuild is told to generate a working tree
               directly in the target directory. This is the default
               (since quilt version 0.67). The setup command is only guaranteed to work properly on
               spec files where applying all the patches is the last
               thing done in the %prep section."
1277,121,quilt,"The setup command is only guaranteed to work properly on
               spec files where applying all the patches is the last
               thing done in the %prep section. This is a design
               limitation due to the fact that quilt can only operate on
               patches. If other commands in the %prep section modify the
               patched files, they must come first, otherwise you won't
               be able to push the patch series."
1277,122,quilt,"If other commands in the %prep section modify the
               patched files, they must come first, otherwise you won't
               be able to push the patch series. For example, a %prep section where you first unpack a
               tarball, then apply patches, and lastly perform a tree-
               wide string substitution, is not OK. For ""quilt setup"" to
               work, it would have to be changed to unpacking the
               tarball, then performing the tree-wide string
               substitution, and lastly applying the patches."
1277,123,quilt,"For ""quilt setup"" to
               work, it would have to be changed to unpacking the
               tarball, then performing the tree-wide string
               substitution, and lastly applying the patches. snapshot
[-d]

           Take a snapshot of the current working state. After taking
           the snapshot, the tree can be modified in the usual ways,
           including pushing and popping patches."
1277,124,quilt,"After taking
           the snapshot, the tree can be modified in the usual ways,
           including pushing and popping patches. A diff against the
           tree at the moment of the snapshot can be generated with
           `quilt diff --snapshot'. -d  Only remove current snapshot."
1277,125,quilt,"-d  Only remove current snapshot. top
Print the name of the topmost patch on the current stack of
           applied patches. unapplied
[patch]

           Print a list of patches that are not applied, or all patches
           that follow the specified patch in the series file."
1277,126,quilt,"unapplied
[patch]

           Print a list of patches that are not applied, or all patches
           that follow the specified patch in the series file. upgrade
Upgrade the meta-data in a working tree from an old version of
           quilt to the current version. This command is only needed when
           the quilt meta-data format has changed, and the working tree
           still contains old-format meta-data."
1277,127,quilt,"upgrade
Upgrade the meta-data in a working tree from an old version of
           quilt to the current version. This command is only needed when
           the quilt meta-data format has changed, and the working tree
           still contains old-format meta-data. In that case, quilt will
           request to run `quilt upgrade'."
1278,0,rcopy,"Uses sockets over RDMA interface to copy a source file to the
       specified destination."
1279,0,rdma_server,"Uses synchronous librdmam calls to establish an RDMA connections
       between two nodes.  This example is intended to provide a very
       simple coding example of how to use RDMA."
1280,0,rdma_xclient,"Uses synchronous librdmam calls to establish an RDMA connection
       between two nodes.  This example is intended to provide a very
       simple coding example of how to use RDMA."
1281,0,rdma_client,"Uses synchronous librdmam calls to establish an RDMA connection
       between two nodes.  This example is intended to provide a very
       simple coding example of how to use RDMA."
1282,0,rdma_xserver,"Uses the librdmacm to establish various forms of communication and
       exchange data."
1283,0,read,"The
read
utility shall read a single logical line from standard
       input into one or more shell variables. By default, unless the
-r
option is specified, <backslash> shall
       act as an escape character. An unescaped <backslash> shall
       preserve the literal value of the following character, with the
       exception of a <newline>."
1283,1,read,"An unescaped <backslash> shall
       preserve the literal value of the following character, with the
       exception of a <newline>. If a <newline> follows the <backslash>,
       the
read
utility shall interpret this as line continuation. The
       <backslash> and <newline> shall be removed before splitting the
       input into fields."
1283,2,read,"The
       <backslash> and <newline> shall be removed before splitting the
       input into fields. All other unescaped <backslash> characters
       shall be removed after splitting the input into fields. If standard input is a terminal device and the invoking shell is
       interactive,
read
shall prompt for a continuation line when it
       reads an input line ending with a <backslash> <newline>, unless
       the
-r
option is specified."
1283,3,read,"If standard input is a terminal device and the invoking shell is
       interactive,
read
shall prompt for a continuation line when it
       reads an input line ending with a <backslash> <newline>, unless
       the
-r
option is specified. The terminating <newline> (if any) shall be removed from the input
       and the results shall be split into fields as in the shell for the
       results of parameter expansion (see
Section 2.6.5
,
Field
Splitting
); the first field shall be assigned to the first
       variable
var
, the second field to the second variable
var
, and so
       on. If there are fewer fields than there are
var
operands, the
       remaining
var
s shall be set to empty strings."
1283,4,read,"If there are fewer fields than there are
var
operands, the
       remaining
var
s shall be set to empty strings. If there are fewer
var
s than fields, the last
var
shall be set to a value comprising
       the following elements:

        *  The field that corresponds to the last
var
in the normal
           assignment sequence described above

        *  The delimiter(s) that follow the field corresponding to the
           last
var
*  The remaining fields and their delimiters, with trailing
IFS
white space ignored

       The setting of variables specified by the
var
operands shall
       affect the current shell execution environment; see
Section 2.12
,
Shell Execution Environment
. If it is called in a subshell or
       separate utility execution environment, such as one of the
       following:

           (read foo)
           nohup read ..."
1283,5,read,"If it is called in a subshell or
       separate utility execution environment, such as one of the
       following:

           (read foo)
           nohup read ... find . -exec read ..."
1283,6,read,"find . -exec read ... \;

       it shall not affect the shell variables in the caller's
       environment."
1284,0,readlink,"realpath(1)
is a better command for canonicalization
       functionality.

       Print value of a symbolic link or canonical file name
-f
,
--canonicalize
canonicalize by following every symlink in every component
              of the given name recursively; all but the last component
              must exist
-e
,
--canonicalize-existing
canonicalize by following every symlink in every component
              of the given name recursively, all components must exist
-m
,
--canonicalize-missing
canonicalize by following every symlink in every component
              of the given name recursively, without requirements on
              components existence
-n
,
--no-newline
do not output the trailing delimiter
-q
,
--quiet
-s
,
--silent
suppress most error messages (on by default)
-v
,
--verbose
report error messages
-z
,
--zero
end each output line with NUL, not newline
--help
display this help and exit
--version
output version information and exit"
1285,0,readonly,"The variables whose
name
s are specified shall be given the
readonly
attribute. The values of variables with the
readonly
attribute cannot be changed by subsequent assignment, nor can
       those variables be unset by the
unset
utility. If the name of a
       variable is followed by =
word
, then the value of that variable
       shall be set to
word
."
1285,1,readonly,"If the name of a
       variable is followed by =
word
, then the value of that variable
       shall be set to
word
. The
readonly
special built-in shall support the Base Definitions
       volume of POSIX.1â2017,
Section 12.2
,
Utility Syntax Guidelines
. When
-p
is specified,
readonly
writes to the standard output the
       names and values of all read-only variables, in the following
       format:

           ""readonly %s=%s\n"", <
name
>, <
value
>

       if
name
is set, and

           ""readonly %s\n"", <
name
>

       if
name
is unset."
1285,2,readonly,"When
-p
is specified,
readonly
writes to the standard output the
       names and values of all read-only variables, in the following
       format:

           ""readonly %s=%s\n"", <
name
>, <
value
>

       if
name
is set, and

           ""readonly %s\n"", <
name
>

       if
name
is unset. The shell shall format the output, including the proper use of
       quoting, so that it is suitable for reinput to the shell as
       commands that achieve the same value and
readonly
attribute-
       setting results in a shell execution environment in which:

        1. Variables with values at the time they were output do not have
           the
readonly
attribute set."
1285,3,readonly,"Variables with values at the time they were output do not have
           the
readonly
attribute set. 2. Variables that were unset at the time they were output do not
           have a value at the time at which the saved output is reinput
           to the shell."
1285,4,readonly,"2. Variables that were unset at the time they were output do not
           have a value at the time at which the saved output is reinput
           to the shell. When no arguments are given, the results are unspecified."
1286,0,readelf,"readelf
displays information about one or more ELF format object
       files. The options control what particular information to
       display. elffile
..."
1286,1,readelf,"elffile
... are the object files to be examined. 32-bit and 64-bit
       ELF files are supported, as are archives containing ELF files."
1286,2,readelf,"are the object files to be examined. 32-bit and 64-bit
       ELF files are supported, as are archives containing ELF files. This program performs a similar function to
objdump
but it goes
       into more detail and it exists independently of the BFD library,
       so if there is a bug in BFD then readelf will not be affected."
1287,0,rename,"rename
will rename the specified files by replacing the first
       occurrence of
expression
in their name by
replacement
."
1288,0,realpath,"Print the resolved absolute file name; all but the last component
       must exist
-e
,
--canonicalize-existing
all components of the path must exist
-m
,
--canonicalize-missing
no path components need exist or be a directory
-L
,
--logical
resolve '..' components before symlinks
-P
,
--physical
resolve symlinks as encountered (default)
-q
,
--quiet
suppress most error messages
--relative-to
=
DIR
print the resolved path relative to DIR
--relative-base
=
DIR
print absolute paths unless paths below DIR
-s
,
--strip
,
--no-symlinks
don't expand symlinks
-z
,
--zero
end each output line with NUL, not newline
--help
display this help and exit
--version
output version information and exit"
1289,0,recode-sr-latin,"Recode Serbian text from Cyrillic to Latin script. The input text
       is read from standard input. The converted text is output to
       standard output."
1289,1,recode-sr-latin,"The input text
       is read from standard input. The converted text is output to
       standard output. Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit"
1290,0,refer,nan
1291,0,renice,"renice
alters the scheduling priority of one or more running
       processes. The first argument is the
priority
value to be used. The other arguments are interpreted as process IDs (by default),
       process group IDs, user IDs, or user names."
1291,1,renice,"The other arguments are interpreted as process IDs (by default),
       process group IDs, user IDs, or user names. renice
'ing a process
       group causes all processes in the process group to have their
       scheduling priority altered. renice
'ing a user causes all
       processes owned by the user to have their scheduling priority
       altered."
1291,2,renice,"renice
'ing a process
       group causes all processes in the process group to have their
       scheduling priority altered. renice
'ing a user causes all
       processes owned by the user to have their scheduling priority
       altered. If no
-n
,
--priority
or
--relative
option is used, then the
       priority is set as
absolute
."
1292,0,renice,"The
renice
utility shall request that the nice values (see the
       Base Definitions volume of POSIX.1â2017,
Section 3.244
,
Nice
Value
) of one or more running processes be changed. By default,
       the applicable processes are specified by their process IDs. When
       a process group is specified (see
-g
), the request shall apply to
       all processes in the process group."
1292,1,renice,"When
       a process group is specified (see
-g
), the request shall apply to
       all processes in the process group. The nice value shall be bounded in an implementation-defined
       manner. If the requested
increment
would raise or lower the nice
       value of the executed utility beyond implementation-defined
       limits, then the limit whose value was exceeded shall be used."
1292,2,renice,"If the requested
increment
would raise or lower the nice
       value of the executed utility beyond implementation-defined
       limits, then the limit whose value was exceeded shall be used. When a user is
renice
d, the request applies to all processes whose
       saved set-user-ID matches the user ID corresponding to the user. Regardless of which options are supplied or any other factor,
renice
shall not alter the nice values of any process unless the
       user requesting such a change has appropriate privileges to do so
       for the specified process."
1292,3,renice,"Regardless of which options are supplied or any other factor,
renice
shall not alter the nice values of any process unless the
       user requesting such a change has appropriate privileges to do so
       for the specified process. If the user lacks appropriate
       privileges to perform the requested action, the utility shall
       return an error status. The saved set-user-ID of the user's process shall be checked
       instead of its effective user ID when
renice
attempts to determine
       the user ID of the process in order to determine whether the user
       has appropriate privileges."
1293,0,replace,"The
replace
utility program changes strings in place in files or
       on the standard input. Invoke
replace
in one of the following ways:

           shell>
replace
from to
[
from to
] ... --
file_name
[
file_name
] ..."
1293,1,replace,"--
file_name
[
file_name
] ... shell>
replace
from to
[
from to
] ... <
file_name
from
represents a string to look for and
to
represents its
       replacement."
1293,2,replace,"<
file_name
from
represents a string to look for and
to
represents its
       replacement. There can be one or more pairs of strings. Use the
--
option to indicate where the string-replacement list
       ends and the file names begin."
1293,3,replace,"Use the
--
option to indicate where the string-replacement list
       ends and the file names begin. In this case, any file named on the
       command line is modified in place, so you may want to make a copy
       of the original before converting it. replace
prints a message
       indicating which of the input files it actually modifies."
1293,4,replace,"replace
prints a message
       indicating which of the input files it actually modifies. If the
--
option is not given,
replace
reads the standard input
       and writes to the standard output. replace
uses a finite state machine to match longer strings first."
1293,5,replace,"replace
uses a finite state machine to match longer strings first. It can be used to swap strings. For example, the following command
       swaps a and b in the given files, file1 and file2:

           shell>
replace a b b a -- file1 file2 ..."
1293,6,replace,"For example, the following command
       swaps a and b in the given files, file1 and file2:

           shell>
replace a b b a -- file1 file2 ... The
replace
program is used by
msql2mysql
. See
msql2mysql(1)
."
1293,7,replace,"See
msql2mysql(1)
. replace
supports the following options. â¢
-?"
1293,8,replace,"â¢
-? ,
-I
Display a help message and exit. â¢
-#
debug_options
Enable debugging."
1293,9,replace,"â¢
-#
debug_options
Enable debugging. â¢
-s
Silent mode. Print less information what the program does."
1293,10,replace,"Print less information what the program does. â¢
-v
Verbose mode. Print more information about what the program
           does."
1293,11,replace,"â¢
-v
Verbose mode. Print more information about what the program
           does. â¢
-V
Display version information and exit."
1294,0,repo-graph,"repo-graph
is a program that generates a full package dependency
       list from a yum repository and outputs it in dot format."
1295,0,repodiff,"repodiff
is a program which will list differences between two sets
       of repositories.
Note
that by default only source packages are
       compared."
1296,0,repoquery,"repoquery
is a program for querying information from YUM
       repositories similarly to rpm queries."
1297,0,reposync,"reposync
is used to synchronize a remote yum repository to a local
       directory, using yum to retrieve the packages."
1298,0,repoclosure,"repoclosure
is a program that reads package metadata from one or
       more yum repositories, checks all dependencies, and displays a
       list of packages with unresolved dependencies."
1299,0,repotrack,"repotrack
is a program for keeping track of a particular package
       and its dependencies. It will download one or more packages and
       all dependencies."
1300,0,repo-rss,"repo-rss
is a program for generating RSS feeds for one or more Yum
       repositories."
1301,0,repomanage,"repomanage
is a program to manage a directory of RPM packages. It
       displays a list of the newest or oldest packages in a directory
       for easy piping to xargs or similar programs."
1302,0,tset,"tset - initialization
This program initializes terminals. First,
@TSET@
retrieves the current terminal mode settings for
       your terminal. It does this by successively testing

       â¢   the standard error,

       â¢   standard output,

       â¢   standard input and

       â¢   ultimately â/dev/ttyâ

       to obtain terminal settings."
1302,1,tset,"It does this by successively testing

       â¢   the standard error,

       â¢   standard output,

       â¢   standard input and

       â¢   ultimately â/dev/ttyâ

       to obtain terminal settings. Having retrieved these settings,
@TSET@
remembers which file descriptor to use when updating
       settings. Next,
@TSET@
determines the type of terminal that you are using."
1302,2,tset,"Next,
@TSET@
determines the type of terminal that you are using. This determination is done as follows, using the first terminal
       type found. 1."
1302,3,tset,"1. The
terminal
argument specified on the command line. 2."
1302,4,tset,"2. The value of the
TERM
environmental variable. 3."
1302,5,tset,"3. (BSD systems only.) The terminal type associated with the
       standard error output device in the
/etc/ttys
file. (On System-V-
       like UNIXes and systems using that convention,
getty
(1) does this
       job by setting
TERM
according to the type passed to it by
/etc/inittab
.)

       4."
1302,6,tset,"(On System-V-
       like UNIXes and systems using that convention,
getty
(1) does this
       job by setting
TERM
according to the type passed to it by
/etc/inittab
.)

       4. The default terminal type, âunknownâ. If the terminal type was not specified on the command-line, the
-m
option mappings are then applied (see the section
TERMINAL TYPE
MAPPING
for more information)."
1302,7,tset,"If the terminal type was not specified on the command-line, the
-m
option mappings are then applied (see the section
TERMINAL TYPE
MAPPING
for more information). Then, if the terminal type begins
       with a question mark (â?â), the user is prompted for confirmation
       of the terminal type. An empty response confirms the type, or,
       another type can be entered to specify a new type."
1302,8,tset,"An empty response confirms the type, or,
       another type can be entered to specify a new type. Once the
       terminal type has been determined, the terminal description for
       the terminal is retrieved. If no terminal description is found
       for the type, the user is prompted for another terminal type."
1302,9,tset,"If no terminal description is found
       for the type, the user is prompted for another terminal type. Once the terminal description is retrieved,

       â¢   if the â
-w
â option is enabled,
@TSET@
may update the
           terminal's window size. If the window size cannot be obtained from the operating
           system, but the terminal description (or environment, e.g.,
LINES
and
COLUMNS
variables specify this), use this to set the
           operating system's notion of the window size."
1302,10,tset,"If the window size cannot be obtained from the operating
           system, but the terminal description (or environment, e.g.,
LINES
and
COLUMNS
variables specify this), use this to set the
           operating system's notion of the window size. â¢   if the â
-c
â option is enabled, the backspace, interrupt and
           line kill characters (among many other things) are set

       â¢   unless the â
-I
â option is enabled, the terminal and tab
initialization
strings are sent to the standard error output,
           and
@TSET@
waits one second (in case a hardware reset was
           issued). â¢   Finally, if the erase, interrupt and line kill characters have
           changed, or are not set to their default values, their values
           are displayed to the standard error output."
1302,11,tset,"â¢   Finally, if the erase, interrupt and line kill characters have
           changed, or are not set to their default values, their values
           are displayed to the standard error output. reset - reinitialization
When invoked as
@RESET@
,
@TSET@
sets the terminal modes to âsaneâ
       values:

       â¢   sets cooked and echo modes,

       â¢   turns off cbreak and raw modes,

       â¢   turns on newline translation and

       â¢   resets any unset special characters to their default values

       before doing the terminal initialization described above. Also,
       rather than using the terminal
initialization
strings, it uses the
       terminal
reset
strings."
1302,12,tset,"Also,
       rather than using the terminal
initialization
strings, it uses the
       terminal
reset
strings. The
@RESET@
command is useful after a program dies leaving a
       terminal in an abnormal state:

       â¢   you may have to type
<LF>
@RESET@
<LF>
(the line-feed character is normally control-J) to get the
           terminal to work, as carriage-return may no longer work in the
           abnormal state. â¢   Also, the terminal will often not echo the command."
1303,0,tput,"The
@TPUT@
utility uses the
terminfo
database to make the values
       of terminal-dependent capabilities and information available to
       the shell (see
sh
(1)), to initialize or reset the terminal, or
       return the long name of the requested terminal type. The result
       depends upon the capability's type:

          string
@TPUT@
writes the string to the standard output. No
               trailing newline is supplied."
1303,1,tput,"No
               trailing newline is supplied. integer
@TPUT@
writes the decimal value to the standard output,
               with a trailing newline. boolean
@TPUT@
simply sets the exit code (
0
for TRUE if the
               terminal has the capability,
1
for FALSE if it does not),
               and writes nothing to the standard output."
1303,2,tput,"boolean
@TPUT@
simply sets the exit code (
0
for TRUE if the
               terminal has the capability,
1
for FALSE if it does not),
               and writes nothing to the standard output. Before using a value returned on the standard output, the
       application should test the exit code (e.g.,
$? , see
sh
(1)) to be
       sure it is
0
."
1303,3,tput,", see
sh
(1)) to be
       sure it is
0
. (See the
EXIT CODES
and
DIAGNOSTICS
sections.)  For
       a complete list of capabilities and the
capname
associated with
       each, see
terminfo(5)
. Options
-S
allows more than one capability per invocation of
@TPUT@
."
1303,4,tput,"Options
-S
allows more than one capability per invocation of
@TPUT@
. The capabilities must be passed to
@TPUT@
from the standard
              input instead of from the command line (see example). Only
              one
capname
is allowed per line."
1303,5,tput,"Only
              one
capname
is allowed per line. The
-S
option changes the
              meaning of the
0
and
1
boolean and string exit codes (see
              the EXIT CODES section). Because some capabilities may use
string
parameters rather
              than
numbers
,
@TPUT@
uses a table and the presence of
              parameters in its input to decide whether to use
tparm
(3X),
              and how to interpret the parameters."
1303,6,tput,"Because some capabilities may use
string
parameters rather
              than
numbers
,
@TPUT@
uses a table and the presence of
              parameters in its input to decide whether to use
tparm
(3X),
              and how to interpret the parameters. -T
type
indicates the
type
of terminal. Normally this option is
              unnecessary, because the default is taken from the
              environment variable
TERM
."
1303,7,tput,"Normally this option is
              unnecessary, because the default is taken from the
              environment variable
TERM
. If
-T
is specified, then the
              shell variables
LINES
and
COLUMNS
will also be ignored. -V
reports the version of ncurses which was used in this
              program, and exits."
1303,8,tput,"-V
reports the version of ncurses which was used in this
              program, and exits. -x
do not attempt to clear the terminal's scrollback buffer
              using the extended âE3â capability. Commands
A few commands (
init
,
reset
and
longname
) are special; they are
       defined by the
@TPUT@
program."
1303,9,tput,"Commands
A few commands (
init
,
reset
and
longname
) are special; they are
       defined by the
@TPUT@
program. The others are the names of
capabilities
from the terminal database (see
terminfo(5)
for a
       list). Although
init
and
reset
resemble capability names,
@TPUT@
uses several capabilities to perform these special functions."
1303,10,tput,"Although
init
and
reset
resemble capability names,
@TPUT@
uses several capabilities to perform these special functions. capname
indicates the capability from the terminal database. If the capability is a string that takes parameters, the
              arguments following the capability will be used as
              parameters for the string."
1303,11,tput,"If the capability is a string that takes parameters, the
              arguments following the capability will be used as
              parameters for the string. Most parameters are numbers. Only a few terminal
              capabilities require string parameters;
@TPUT@
uses a table
              to decide which to pass as strings."
1303,12,tput,"Only a few terminal
              capabilities require string parameters;
@TPUT@
uses a table
              to decide which to pass as strings. Normally
@TPUT@
uses
tparm
(3X) to perform the substitution. If no parameters
              are given for the capability,
@TPUT@
writes the string
              without performing the substitution."
1303,13,tput,"If no parameters
              are given for the capability,
@TPUT@
writes the string
              without performing the substitution. init
If the terminal database is present and an entry for the
              user's terminal exists (see
-T
type
, above), the following
              will occur:

              (1)  first,
@TPUT@
retrieves the current terminal mode
                   settings for your terminal. It does this by
                   successively testing

                   â¢   the standard error,

                   â¢   standard output,

                   â¢   standard input and

                   â¢   ultimately â/dev/ttyâ

                   to obtain terminal settings."
1303,14,tput,"It does this by
                   successively testing

                   â¢   the standard error,

                   â¢   standard output,

                   â¢   standard input and

                   â¢   ultimately â/dev/ttyâ

                   to obtain terminal settings. Having retrieved these
                   settings,
@TPUT@
remembers which file descriptor to
                   use when updating settings. (2)  if the window size cannot be obtained from the
                   operating system, but the terminal description (or
                   environment, e.g.,
LINES
and
COLUMNS
variables specify
                   this), update the operating system's notion of the
                   window size."
1303,15,tput,"(2)  if the window size cannot be obtained from the
                   operating system, but the terminal description (or
                   environment, e.g.,
LINES
and
COLUMNS
variables specify
                   this), update the operating system's notion of the
                   window size. (3)  the terminal modes will be updated:

                   â¢   any delays (e.g., newline) specified in the entry
                       will be set in the tty driver,

                   â¢   tabs expansion will be turned on or off according
                       to the specification in the entry, and

                   â¢   if tabs are not expanded, standard tabs will be
                       set (every 8 spaces). (4)  if present, the terminal's initialization strings will
                   be output as detailed in the
terminfo(5)
section on
Tabs and Initialization
,

              (5)  output is flushed."
1303,16,tput,"(4)  if present, the terminal's initialization strings will
                   be output as detailed in the
terminfo(5)
section on
Tabs and Initialization
,

              (5)  output is flushed. If an entry does not contain the information needed for any
              of these activities, that activity will silently be
              skipped. reset
This is similar to
init
, with two differences:

              (1)  before any other initialization, the terminal modes
                   will be reset to a âsaneâ state:

                   â¢   set cooked and echo modes,

                   â¢   turn off cbreak and raw modes,

                   â¢   turn on newline translation and

                   â¢   reset any unset special characters to their
                       default values

              (2)  Instead of putting out
initialization
strings, the
                   terminal's
reset
strings will be output if present
                   (
rs1
,
rs2
,
rs3
,
rf
)."
1303,17,tput,"reset
This is similar to
init
, with two differences:

              (1)  before any other initialization, the terminal modes
                   will be reset to a âsaneâ state:

                   â¢   set cooked and echo modes,

                   â¢   turn off cbreak and raw modes,

                   â¢   turn on newline translation and

                   â¢   reset any unset special characters to their
                       default values

              (2)  Instead of putting out
initialization
strings, the
                   terminal's
reset
strings will be output if present
                   (
rs1
,
rs2
,
rs3
,
rf
). If the
reset
strings are not
                   present, but
initialization
strings are, the
initialization
strings will be output. Otherwise,
reset
acts identically to
init
."
1303,18,tput,"Otherwise,
reset
acts identically to
init
. longname
If the terminal database is present and an entry for the
              user's terminal exists (see
-T
type
above), then the long
              name of the terminal will be put out. The long name is the
              last name in the first line of the terminal's description
              in the
terminfo
database [see
term(5)
]."
1303,19,tput,"The long name is the
              last name in the first line of the terminal's description
              in the
terminfo
database [see
term(5)
]. Aliases
@TPUT@
handles the
clear
,
init
and
reset
commands specially: it
       allows for the possibility that it is invoked by a link with those
       names. If
@TPUT@
is invoked by a link named
reset
, this has the same
       effect as
@TPUT@ reset
."
1303,20,tput,"If
@TPUT@
is invoked by a link named
reset
, this has the same
       effect as
@TPUT@ reset
. The
@TSET@
(1) utility also treats a link
       named
reset
specially. Before ncurses 6.1, the two utilities were different from each
       other:

       â¢
@TSET@
utility reset the terminal modes and special characters
           (not done with
@TPUT@
)."
1303,21,tput,"Before ncurses 6.1, the two utilities were different from each
       other:

       â¢
@TSET@
utility reset the terminal modes and special characters
           (not done with
@TPUT@
). â¢   On the other hand,
@TSET@
's repertoire of terminal
           capabilities for resetting the terminal was more limited,
           i.e., only
reset_1string
,
reset_2string
and
reset_file
in
           contrast to the tab-stops and margins which are set by this
           utility. â¢   The
reset
program is usually an alias for
@TSET@
, because of
           this difference with resetting terminal modes and special
           characters."
1303,22,tput,"â¢   The
reset
program is usually an alias for
@TSET@
, because of
           this difference with resetting terminal modes and special
           characters. With the changes made for ncurses 6.1, the
reset
feature of the
       two programs is (mostly) the same. A few differences remain:

       â¢   The
@TSET@
program waits one second when resetting, in case it
           happens to be a hardware terminal."
1303,23,tput,"A few differences remain:

       â¢   The
@TSET@
program waits one second when resetting, in case it
           happens to be a hardware terminal. â¢   The two programs write the terminal initialization strings to
           different streams (i.e., the standard error for
@TSET@
and the
           standard output for
@TPUT@
). Note:
although these programs write to different streams,
           redirecting their output to a file will capture only part of
           their actions."
1303,24,tput,"Note:
although these programs write to different streams,
           redirecting their output to a file will capture only part of
           their actions. The changes to the terminal modes are not
           affected by redirecting the output. If
@TPUT@
is invoked by a link named
init
, this has the same
       effect as
@TPUT@ init
."
1303,25,tput,"If
@TPUT@
is invoked by a link named
init
, this has the same
       effect as
@TPUT@ init
. Again, you are less likely to use that
       link because another program named
init
has a more well-
       established use. Terminal Size
Besides the special commands (e.g.,
clear
), @TPUT@ treats certain
       terminfo capabilities specially:
lines
and
cols
."
1303,26,tput,"Terminal Size
Besides the special commands (e.g.,
clear
), @TPUT@ treats certain
       terminfo capabilities specially:
lines
and
cols
. @TPUT@ calls
setupterm
(3X) to obtain the terminal size:

       â¢   first, it gets the size from the terminal database (which
           generally is not provided for terminal emulators which do not
           have a fixed window size)

       â¢   then it asks the operating system for the terminal's size
           (which generally works, unless connecting via a serial line
           which does not support
NAWS
: negotiations about window size). â¢   finally, it inspects the environment variables
LINES
and
COLUMNS
which may override the terminal size."
1303,27,tput,"@TPUT@ calls
setupterm
(3X) to obtain the terminal size:

       â¢   first, it gets the size from the terminal database (which
           generally is not provided for terminal emulators which do not
           have a fixed window size)

       â¢   then it asks the operating system for the terminal's size
           (which generally works, unless connecting via a serial line
           which does not support
NAWS
: negotiations about window size). â¢   finally, it inspects the environment variables
LINES
and
COLUMNS
which may override the terminal size. If the
-T
option is given @TPUT@ ignores the environment variables
       by calling
use_tioctl(TRUE)
, relying upon the operating system (or
       finally, the terminal database)."
1304,0,resolvectl,"resolvectl
may be used to resolve domain names, IPv4 and IPv6
       addresses, DNS resource records and services with the
systemd-resolved.service(8)
resolver service. By default, the
       specified list of parameters will be resolved as hostnames,
       retrieving their IPv4 and IPv6 addresses. If the parameters
       specified are formatted as IPv4 or IPv6 addresses the reverse
       operation is done, and a hostname is retrieved for the specified
       addresses."
1304,1,resolvectl,"If the parameters
       specified are formatted as IPv4 or IPv6 addresses the reverse
       operation is done, and a hostname is retrieved for the specified
       addresses. The program's output contains information about the protocol used
       for the look-up and on which network interface the data was
       discovered. It also contains information on whether the
       information could be authenticated."
1304,2,resolvectl,"It also contains information on whether the
       information could be authenticated. All data for which local
       DNSSEC validation succeeds is considered authenticated. Moreover,
       all data originating from local, trusted sources is also reported
       authenticated, including resolution of the local host name, the
       ""localhost"" hostname or all data from /etc/hosts."
1305,0,resolveip,"The
resolveip
utility resolves host names to IP addresses and vice
       versa. Invoke
resolveip
like this:

           shell>
resolveip [
options
] {
host_name
|
ip-addr
} ... resolveip
supports the following options."
1305,1,resolveip,"resolveip
supports the following options. â¢
--help
,
--info
,
-? ,
-I
Display a help message and exit."
1305,2,resolveip,",
-I
Display a help message and exit. â¢
--silent
,
-s
Silent mode. Produce less output."
1305,3,resolveip,"â¢
--silent
,
-s
Silent mode. Produce less output. â¢
--version
,
-V
Display version information and exit."
1306,0,resolvectl,"resolvectl
may be used to resolve domain names, IPv4 and IPv6
       addresses, DNS resource records and services with the
systemd-resolved.service(8)
resolver service. By default, the
       specified list of parameters will be resolved as hostnames,
       retrieving their IPv4 and IPv6 addresses. If the parameters
       specified are formatted as IPv4 or IPv6 addresses the reverse
       operation is done, and a hostname is retrieved for the specified
       addresses."
1306,1,resolvectl,"If the parameters
       specified are formatted as IPv4 or IPv6 addresses the reverse
       operation is done, and a hostname is retrieved for the specified
       addresses. The program's output contains information about the protocol used
       for the look-up and on which network interface the data was
       discovered. It also contains information on whether the
       information could be authenticated."
1306,2,resolvectl,"It also contains information on whether the
       information could be authenticated. All data for which local
       DNSSEC validation succeeds is considered authenticated. Moreover,
       all data originating from local, trusted sources is also reported
       authenticated, including resolution of the local host name, the
       ""localhost"" hostname or all data from /etc/hosts."
1307,0,return,"The
return
utility shall cause the shell to stop executing the
       current function or
dot
script. If the shell is not currently
       executing a function or
dot
script, the results are unspecified."
1308,0,resolve_stack_dump,"resolve_stack_dump
resolves a numeric stack dump to symbols. Invoke
resolve_stack_dump
like this:

           shell>
resolve_stack_dump [
options
]
symbols_file
[
numeric_dump_file
]
The symbols file should include the output from the
nm
--numeric-sort mariadbd
command. The numeric dump file should
       contain a numeric stack track from
mariadbd
."
1308,1,resolve_stack_dump,"The numeric dump file should
       contain a numeric stack track from
mariadbd
. If no numeric dump
       file is named on the command line, the stack trace is read from
       the standard input. resolve_stack_dump
supports the following options."
1308,2,resolve_stack_dump,"resolve_stack_dump
supports the following options. â¢
--help
,
-h
Display a help message and exit. â¢
--numeric-dump-file=
file_name
,
-n
file_name
Read the stack trace from the given file."
1308,3,resolve_stack_dump,"â¢
--numeric-dump-file=
file_name
,
-n
file_name
Read the stack trace from the given file. â¢
--symbols-file=
file_name
,
-s
file_name
Use the given symbols file. â¢
--version
,
-V
Display version information and exit."
1309,0,riostream,"Uses the streaming over RDMA protocol (rsocket) to connect and
       exchange data between a client and server application."
1310,0,rm,"This manual page documents the GNU version of
rm
. rm
removes each
       specified file. By default, it does not remove directories."
1310,1,rm,"By default, it does not remove directories. If the
-I
or
--interactive=once
option is given, and there are
       more than three files or the
-r
,
-R
, or
--recursive
are given,
       then
rm
prompts the user for whether to proceed with the entire
       operation. If the response is not affirmative, the entire command
       is aborted."
1310,2,rm,"If the response is not affirmative, the entire command
       is aborted. Otherwise, if a file is unwritable, standard input is a terminal,
       and the
-f
or
--force
option is not given, or the
-i
or
--interactive=always
option is given,
rm
prompts the user for
       whether to remove the file. If the response is not affirmative,
       the file is skipped."
1311,0,rev,"The
rev
utility copies the specified files to standard output,
       reversing the order of characters in every line. If no files are
       specified, standard input is read. This utility is a line-oriented tool and it uses in-memory
       allocated buffer for a whole wide-char line."
1311,1,rev,"If no files are
       specified, standard input is read. This utility is a line-oriented tool and it uses in-memory
       allocated buffer for a whole wide-char line. If the input file is
       huge and without line breaks then allocating the memory for the
       file may be unsuccessful."
1312,0,rm,"The
rm
utility shall remove the directory entry specified by each
file
argument. If either of the files dot or dot-dot are specified as the
       basename portion of an operand (that is, the final pathname
       component) or if an operand resolves to the root directory,
rm
shall write a diagnostic message to standard error and do nothing
       more with such operands. For each
file
the following steps shall be taken:

        1."
1312,1,rm,"For each
file
the following steps shall be taken:

        1. If the
file
does not exist:

            a. If the
-f
option is not specified,
rm
shall write a
               diagnostic message to standard error."
1312,2,rm,"If the
-f
option is not specified,
rm
shall write a
               diagnostic message to standard error. b. Go on to any remaining
files
."
1312,3,rm,"Go on to any remaining
files
. 2. If
file
is of type directory, the following steps shall be
           taken:

            a."
1312,4,rm,"If
file
is of type directory, the following steps shall be
           taken:

            a. If neither the
-R
option nor the
-r
option is specified,
rm
shall write a diagnostic message to standard error, do
               nothing more with
file
, and go on to any remaining files. b."
1312,5,rm,"b. If
file
is an empty directory,
rm
may skip to step 2d. If
               the
-f
option is not specified, and either the permissions
               of
file
do not permit writing and the standard input is a
               terminal or the
-i
option is specified,
rm
shall write a
               prompt to standard error and read a line from the standard
               input."
1312,6,rm,"If
               the
-f
option is not specified, and either the permissions
               of
file
do not permit writing and the standard input is a
               terminal or the
-i
option is specified,
rm
shall write a
               prompt to standard error and read a line from the standard
               input. If the response is not affirmative,
rm
shall do
               nothing more with the current file and go on to any
               remaining files. c."
1312,7,rm,"c. For each entry contained in
file
, other than dot or dot-
               dot, the four steps listed here (1 to 4) shall be taken
               with the entry as if it were a
file
operand. The
rm
utility shall not traverse directories by following
               symbolic links into other parts of the hierarchy, but
               shall remove the links themselves."
1312,8,rm,"The
rm
utility shall not traverse directories by following
               symbolic links into other parts of the hierarchy, but
               shall remove the links themselves. d. If the
-i
option is specified,
rm
shall write a prompt to
               standard error and read a line from the standard input."
1312,9,rm,"If the
-i
option is specified,
rm
shall write a prompt to
               standard error and read a line from the standard input. If
               the response is not affirmative,
rm
shall do nothing more
               with the current file, and go on to any remaining files. 3."
1312,10,rm,"3. If
file
is not of type directory, the
-f
option is not
           specified, and either the permissions of
file
do not permit
           writing and the standard input is a terminal or the
-i
option
           is specified,
rm
shall write a prompt to the standard error
           and read a line from the standard input. If the response is
           not affirmative,
rm
shall do nothing more with the current
           file and go on to any remaining files."
1312,11,rm,"If the response is
           not affirmative,
rm
shall do nothing more with the current
           file and go on to any remaining files. 4. If the current file is a directory,
rm
shall perform actions
           equivalent to the
rmdir
() function defined in the System
           Interfaces volume of POSIX.1â2017 called with a pathname of
           the current file used as the
path
argument."
1312,12,rm,"If the current file is a directory,
rm
shall perform actions
           equivalent to the
rmdir
() function defined in the System
           Interfaces volume of POSIX.1â2017 called with a pathname of
           the current file used as the
path
argument. If the current
           file is not a directory,
rm
shall perform actions equivalent
           to the
unlink
() function defined in the System Interfaces
           volume of POSIX.1â2017 called with a pathname of the current
           file used as the
path
argument. If this fails for any reason,
rm
shall write a diagnostic
           message to standard error, do nothing more with the current
           file, and go on to any remaining files."
1312,13,rm,"If the current
           file is not a directory,
rm
shall perform actions equivalent
           to the
unlink
() function defined in the System Interfaces
           volume of POSIX.1â2017 called with a pathname of the current
           file used as the
path
argument. If this fails for any reason,
rm
shall write a diagnostic
           message to standard error, do nothing more with the current
           file, and go on to any remaining files. The
rm
utility shall be able to descend to arbitrary depths in a
       file hierarchy, and shall not fail due to path length limitations
       (unless an operand specified by the user exceeds system
       limitations)."
1313,0,rmdel,"The
rmdel
utility shall remove the delta specified by the SID from
       each named SCCS file. The delta to be removed shall be the most
       recent delta in its branch in the delta chain of each named SCCS
       file. In addition, the application shall ensure that the SID
       specified is not that of a version being edited for the purpose of
       making a delta; that is, if a
p-file
(see
get(1p)
) exists for the
       named SCCS file, the SID specified shall not appear in any entry
       of the
p-file
."
1313,1,rmdel,"In addition, the application shall ensure that the SID
       specified is not that of a version being edited for the purpose of
       making a delta; that is, if a
p-file
(see
get(1p)
) exists for the
       named SCCS file, the SID specified shall not appear in any entry
       of the
p-file
. Removal of a delta shall be restricted to:

        1. The user who made the delta

        2."
1313,2,rmdel,"The user who made the delta

        2. The owner of the SCCS file

        3. The owner of the directory containing the SCCS file"
1314,0,rmdir,"Remove the DIRECTORY(ies), if they are empty.
--ignore-fail-on-non-empty
ignore each failure to remove a non-empty directory
-p
,
--parents
remove DIRECTORY and its ancestors; e.g., 'rmdir
-p
a/b' is
              similar to 'rmdir a/b a'
-v
,
--verbose
output a diagnostic for every directory processed
--help
display this help and exit
--version
output version information and exit"
1315,0,rmdir,"The
rmdir
utility shall remove the directory entry specified by
       each
dir
operand. For each
dir
operand, the
rmdir
utility shall perform actions
       equivalent to the
rmdir
() function called with the
dir
operand as
       its only argument. Directories shall be processed in the order specified."
1315,1,rmdir,"For each
dir
operand, the
rmdir
utility shall perform actions
       equivalent to the
rmdir
() function called with the
dir
operand as
       its only argument. Directories shall be processed in the order specified. If a
       directory and a subdirectory of that directory are specified in a
       single invocation of the
rmdir
utility, the application shall
       specify the subdirectory before the parent directory so that the
       parent directory will be empty when the
rmdir
utility tries to
       remove it."
1316,0,rping,"Establishes a reliable RDMA connection between two nodes using the
       librdmacm, optionally performs RDMA transfers between the nodes,
       then disconnects."
1317,0,rstream,"Uses the streaming over RDMA protocol (rsocket) to connect and
       exchange data between a client and server application."
1318,0,rrsync,"A user's ssh login can be restricted to only allow the running of
       an rsync transfer in one of two easy ways:

       o      forcing the running of the rrsync script

       o      forcing the running of an rsync daemon-over-ssh command. Both of these setups use a feature of ssh that allows a command to
       be forced to run instead of an interactive shell. However, if the
       user's home shell is bash, please see BASH SECURITY ISSUE for a
       potential issue."
1318,1,rrsync,"However, if the
       user's home shell is bash, please see BASH SECURITY ISSUE for a
       potential issue. To use the rrsync script, edit the user's
~/.ssh/authorized_keys
file and add a prefix like one of the following (followed by a
       space) in front of each ssh-key line that should be restricted:

           command=""rrsync DIR""
           command=""rrsync -ro DIR""
           command=""rrsync -munge -no-del DIR""

       Then, ensure that the rrsync script has your desired option
       restrictions. You may want to copy the script to a local bin dir
       with a unique name if you want to have multiple configurations."
1318,2,rrsync,"You may want to copy the script to a local bin dir
       with a unique name if you want to have multiple configurations. One or more rrsync options can be specified prior to the
DIR
if
       you want to further restrict the transfer. To use an rsync daemon setup, edit the user's
~/.ssh/authorized_keys
file and add a prefix like one of the
       following (followed by a space) in front of each ssh-key line that
       should be restricted:

           command=""rsync --server --daemon .""
           command=""rsync --server --daemon --config=/PATH/TO/rsyncd.conf .""

       Then, ensure that the rsyncd.conf file is created with one or more
       module names with the appropriate path and option restrictions."
1318,3,rrsync,"To use an rsync daemon setup, edit the user's
~/.ssh/authorized_keys
file and add a prefix like one of the
       following (followed by a space) in front of each ssh-key line that
       should be restricted:

           command=""rsync --server --daemon .""
           command=""rsync --server --daemon --config=/PATH/TO/rsyncd.conf .""

       Then, ensure that the rsyncd.conf file is created with one or more
       module names with the appropriate path and option restrictions. If rsync's
--config
option is omitted, it defaults to
~/rsyncd.conf
. See the
rsyncd.conf(5)
manpage for details of how
       to configure an rsync daemon."
1318,4,rrsync,"See the
rsyncd.conf(5)
manpage for details of how
       to configure an rsync daemon. When using rrsync, there can be just one restricted dir per
       authorized key. A daemon setup, on the other hand, allows
       multiple module names inside the config file, each one with its
       own path setting."
1318,5,rrsync,"When using rrsync, there can be just one restricted dir per
       authorized key. A daemon setup, on the other hand, allows
       multiple module names inside the config file, each one with its
       own path setting. The remainder of this manpage is dedicated to using the rrsync
       script."
1319,0,rsync-ssl,"The rsync-ssl script helps you to run an rsync copy to/from an
       rsync daemon that requires ssl connections. The script requires that you specify an rsync-daemon arg in the
       style of either
hostname::
(with 2 colons) or
rsync://hostname/
. The default port used for connecting is 874 (one higher than the
       normal 873) unless overridden in the environment."
1319,1,rsync-ssl,"The script requires that you specify an rsync-daemon arg in the
       style of either
hostname::
(with 2 colons) or
rsync://hostname/
. The default port used for connecting is 874 (one higher than the
       normal 873) unless overridden in the environment. You can specify
       an overriding port via
--port
or by including it in the normal
       spot in the URL format, though both of those require your rsync
       version to be at least 3.2.0."
1320,0,run0,"run0
may be used to temporarily and interactively acquire elevated
       or different privileges. It serves a similar purpose as
sudo(8)
,
       but operates differently in a couple of key areas:

       â¢   No execution or security context credentials are inherited
           from the caller into the invoked commands, as they are invoked
           from a fresh, isolated service forked off by the service
           manager. â¢   Authentication takes place via
polkit
[1], thus isolating the
           authentication prompt from the terminal (if possible)."
1320,1,run0,"â¢   Authentication takes place via
polkit
[1], thus isolating the
           authentication prompt from the terminal (if possible). â¢   An independent pseudo-tty is allocated for the invoked
           command, detaching its lifecycle and isolating it for
           security. â¢   No SetUID/SetGID file access bit functionality is used for the
           implementation."
1320,2,run0,"â¢   No SetUID/SetGID file access bit functionality is used for the
           implementation. Altogether this should provide a safer and more robust alternative
       to the
sudo
mechanism, in particular in OS environments where
       SetUID/SetGID support is not available (for example by setting the
NoNewPrivileges=
variable in
systemd-system.conf(5)
). Any session invoked via
run0
will run through the ""systemd-run0""
       PAM stack."
1320,3,run0,"Any session invoked via
run0
will run through the ""systemd-run0""
       PAM stack. Note that
run0
is implemented as an alternative multi-call
       invocation of
systemd-run(1)
. That is,
run0
is a symbolic link to
systemd-run
executable file, and it behaves as
run0
if it is
       invoked through the symbolic link, otherwise behaves as
systemd-run
."
1321,0,runaspcp,"runaspcp
runs the single argument
command
as the user
$PCP_USER
and group
$PCP_GROUP
(both from
/etc/pcp.conf
). The
command
is run by
sh
(1) by default, else
shell
from the
-s
(or
--shell)
command line argument. Normally
runaspcp
is used from the PCP ``init'' scripts that are
       launched as ``root'' but need to downgrade their privileges when
       running some PCP daemons as the ``pcp'' user."
1321,1,runaspcp,"Normally
runaspcp
is used from the PCP ``init'' scripts that are
       launched as ``root'' but need to downgrade their privileges when
       running some PCP daemons as the ``pcp'' user. The
-? ,
--help
option displays a usage message."
1322,0,runcon,"Run COMMAND with completely-specified CONTEXT, or with current or
       transitioned security context modified by one or more of LEVEL,
       ROLE, TYPE, and USER. If none of
-c
,
-t
,
-u
,
-r
, or
-l
, is specified, the first argument
       is used as the complete context. Any additional arguments after
COMMAND
are interpreted as arguments to the command."
1322,1,runcon,"Any additional arguments after
COMMAND
are interpreted as arguments to the command. Only carefully-chosen contexts are likely to run successfully. Run a program in a different SELinux security context."
1322,2,runcon,"Run a program in a different SELinux security context. With
       neither CONTEXT nor COMMAND, print the current security context. Mandatory arguments to long options are mandatory for short
       options too."
1322,3,runcon,"With
       neither CONTEXT nor COMMAND, print the current security context. Mandatory arguments to long options are mandatory for short
       options too. CONTEXT
              Complete security context
-c
,
--compute
compute process transition context before modifying
-t
,
--type
=
TYPE
type (for same role as parent)
-u
,
--user
=
USER
user identity
-r
,
--role
=
ROLE
role
-l
,
--range
=
RANGE
levelrange
--help
display this help and exit
--version
output version information and exit
Exit status:
125    if the runcon command itself fails

       126    if COMMAND is found but cannot be invoked

       127    if COMMAND cannot be found

       -      the exit status of COMMAND otherwise"
1323,0,runscript,"runscript
is a simple script interpreter that can be called from
       within the minicom communications program to automate tasks like
       logging in to a Unix system or your favorite BBS."
1324,0,rsync,"Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell,
       or to/from a remote rsync daemon. It offers a large number of
       options that control every aspect of its behavior and permit very
       flexible specification of the set of files to be copied."
1324,1,rsync,"It offers a large number of
       options that control every aspect of its behavior and permit very
       flexible specification of the set of files to be copied. It is
       famous for its delta-transfer algorithm, which reduces the amount
       of data sent over the network by sending only the differences
       between the source files and the existing files in the
       destination. Rsync is widely used for backups and mirroring and
       as an improved copy command for everyday use."
1324,2,rsync,"Rsync is widely used for backups and mirroring and
       as an improved copy command for everyday use. Rsync finds files that need to be transferred using a ""quick
       check"" algorithm (by default) that looks for files that have
       changed in size or in last-modified time. Any changes in the
       other preserved attributes (as requested by options) are made on
       the destination file directly when the quick check indicates that
       the file's data does not need to be updated."
1324,3,rsync,"Rsync finds files that need to be transferred using a ""quick
       check"" algorithm (by default) that looks for files that have
       changed in size or in last-modified time. Any changes in the
       other preserved attributes (as requested by options) are made on
       the destination file directly when the quick check indicates that
       the file's data does not need to be updated. Some of the additional features of rsync are:

       o      support for copying links, devices, owners, groups, and
              permissions

       o      exclude and exclude-from options similar to GNU tar

       o      a CVS exclude mode for ignoring the same files that CVS
              would ignore

       o      can use any transparent remote shell, including ssh or rsh

       o      does not require super-user privileges

       o      pipelining of file transfers to minimize latency costs

       o      support for anonymous or authenticated rsync daemons (ideal
              for mirroring)"
1325,0,runuser,"runuser
can be used to run commands with a substitute user and
       group ID. If the option
-u
is not given,
runuser
falls back to
su
-compatible semantics and a shell is executed. The difference
       between the commands
runuser
and
su
is that
runuser
does not ask
       for a password (because it may be executed by the root user only)
       and it uses a different PAM configuration."
1325,1,runuser,"The difference
       between the commands
runuser
and
su
is that
runuser
does not ask
       for a password (because it may be executed by the root user only)
       and it uses a different PAM configuration. The command
runuser
does not have to be installed with set-user-ID permissions. If the PAM session is not required, then the recommended solution
       is to use the
setpriv(1)
command."
1325,2,runuser,"If the PAM session is not required, then the recommended solution
       is to use the
setpriv(1)
command. When called without arguments,
runuser
defaults to running an
       interactive shell as
root
. For backward compatibility,
runuser
defaults to not changing the
       current directory and to setting only the environment variables
HOME
and
SHELL
(plus
USER
and
LOGNAME
if the target
user
is not
       root)."
1325,3,runuser,"For backward compatibility,
runuser
defaults to not changing the
       current directory and to setting only the environment variables
HOME
and
SHELL
(plus
USER
and
LOGNAME
if the target
user
is not
       root). This version of
runuser
uses PAM for session management. Note that
runuser
in all cases use PAM (pam_getenvlist()) to do
       the final environment modification."
1325,4,runuser,"Note that
runuser
in all cases use PAM (pam_getenvlist()) to do
       the final environment modification. Command-line options such as
--login
and
--preserve-environment
affect the environment before
       it is modified by PAM. Since version 2.38
runuser
resets process resource limits
       RLIMIT_NICE, RLIMIT_RTPRIO, RLIMIT_FSIZE, RLIMIT_AS and
       RLIMIT_NOFILE."
1326,0,sact,"The
sact
utility shall inform the user of any impending deltas to
       a named SCCS file by writing a list to standard output. This
       situation occurs when
get
-e
has been executed previously without
       a subsequent execution of
delta
,
unget
, or
sccs
unedit
."
1327,0,sar2pcp,"sar2pcp
is intended to read a binary System Activity Reporting
       (sar) data file as created by
sadc
(1) (
infile
) and translate this
       into a Performance Co-Pilot (PCP) archive with the basename
outfile
. However, if
infile
has the suffix ``.xml'', then it will be
       considered already in XML format and
sar2pcp
will operate directly
       on it. The resultant PCP achive may be used with all the PCP client tools
       to graph subsets of the data using
pmchart(1)
, perform data
       reduction and reporting, filter with the PCP inference engine
pmie(1)
, etc."
1327,1,sar2pcp,"The resultant PCP achive may be used with all the PCP client tools
       to graph subsets of the data using
pmchart(1)
, perform data
       reduction and reporting, filter with the PCP inference engine
pmie(1)
, etc. A series of physical files will be created with the prefix
outfile
. These are
outfile
.0
(the performance data),
outfile
.meta
(the metadata that describes the performance data) and
outfile
.index
(a temporal index to improve efficiency of replay
       operations for the archive)."
1327,2,sar2pcp,"These are
outfile
.0
(the performance data),
outfile
.meta
(the metadata that describes the performance data) and
outfile
.index
(a temporal index to improve efficiency of replay
       operations for the archive). If any of these files exists
       already, then
sar2pcp
will
not
overwrite them and will exit with
       an error message of the form

       _&__pmLogNewFile: ``blah.0'' already exists, not over-written
sar2pcp
is a Perl script that uses the PCP::LogImport Perl wrapper
       around the PCP
libpcp_import
library, and as such could be used as
       an example to develop new tools to import other types of
       performance data and create PCP archives. A Python wrapper module
       is also available."
1328,0,sadf,"The
sadf
command is used for displaying the contents of data files
       created by the
sar(1)
command. But unlike
sar
,
sadf
can write its
       data in many different formats (CSV, XML, etc.)  The default
       format is one that can easily be handled by pattern processing
       commands like
awk
(see option
-p
). The
sadf
command can also be
       used to draw graphs for the various activities collected by
sar
and display them as SVG (Scalable Vector Graphics) graphics in
       your web browser (see option
-g
)."
1328,1,sadf,"The
sadf
command can also be
       used to draw graphs for the various activities collected by
sar
and display them as SVG (Scalable Vector Graphics) graphics in
       your web browser (see option
-g
). The
sadf
command extracts and writes to standard output records
       saved in the
datafile
file. This file must have been created by a
       version of
sar
which is compatible with that of
sadf
."
1328,2,sadf,"This file must have been created by a
       version of
sar
which is compatible with that of
sadf
. If
datafile
is omitted,
sadf
uses the standard system activity daily data
       file. It is also possible to enter
-1
,
-2
etc."
1328,3,sadf,"It is also possible to enter
-1
,
-2
etc. as an argument to
sadf
to display data of that days ago. For example,
-1
will point
       at the standard system activity file of yesterday."
1328,4,sadf,"For example,
-1
will point
       at the standard system activity file of yesterday. The standard system activity daily data file is named
saDD
or
saYYYYMMDD
, where
YYYY
stands for the current year,
MM
for the
       current month and
DD
for the current day. sadf
will look for the
       most recent of
saDD
and
saYYYYMMDD
, and use it."
1328,5,sadf,"sadf
will look for the
       most recent of
saDD
and
saYYYYMMDD
, and use it. By default it is
       located in the
/var/log/sa
directory. Yet it is possible to
       specify an alternate location for it: If
datafile
is a directory
       (instead of a plain file) then it will be considered as the
       directory where the standard system activity daily data file is
       located."
1328,6,sadf,"Yet it is possible to
       specify an alternate location for it: If
datafile
is a directory
       (instead of a plain file) then it will be considered as the
       directory where the standard system activity daily data file is
       located. The
interval
and
count
parameters are used to tell
sadf
to select
count
records at
interval
seconds apart. If the
count
parameter is
       not set, then all the records saved in the data file will be
       displayed."
1328,7,sadf,"If the
count
parameter is
       not set, then all the records saved in the data file will be
       displayed. All the activity flags of
sar
may be entered on the command line
       to indicate which activities are to be reported. Before specifying
       them, put a pair of dashes (
--
) on the command line in order not
       to confuse the flags with those of
sadf."
1328,8,sadf,"All the activity flags of
sar
may be entered on the command line
       to indicate which activities are to be reported. Before specifying
       them, put a pair of dashes (
--
) on the command line in order not
       to confuse the flags with those of
sadf. Not specifying any flags
       selects only CPU activity."
1329,0,scalar,"Scalar is a repository management tool that optimizes Git for use
       in large repositories. Scalar improves performance by configuring
       advanced Git settings, maintaining repositories in the background,
       and helping to reduce data sent across the network. An important Scalar concept is the enlistment: this is the
       top-level directory of the project."
1329,1,scalar,"An important Scalar concept is the enlistment: this is the
       top-level directory of the project. It usually contains the
       subdirectory
src/
which is a Git worktree. This encourages the
       separation between tracked files (inside
src/
) and untracked
       files, such as build artifacts (outside
src/
)."
1329,2,scalar,"This encourages the
       separation between tracked files (inside
src/
) and untracked
       files, such as build artifacts (outside
src/
). When registering an
       existing Git worktree with Scalar whose name is not
src
, the
       enlistment will be identical to the worktree. The
scalar
command implements various subcommands, and different
       options depending on the subcommand."
1329,3,scalar,"The
scalar
command implements various subcommands, and different
       options depending on the subcommand. With the exception of
clone
,
list
and
reconfigure --all
, all subcommands expect to be run in an
       enlistment. The following options can be specified
before
the subcommand:

       -C <directory>
           Before running the subcommand, change the working directory."
1329,4,scalar,"The following options can be specified
before
the subcommand:

       -C <directory>
           Before running the subcommand, change the working directory. This option imitates the same option of
git(1)
. -c <key>=<value>
           For the duration of running the specified subcommand,
           configure this setting."
1329,5,scalar,"This option imitates the same option of
git(1)
. -c <key>=<value>
           For the duration of running the specified subcommand,
           configure this setting. This option imitates the same option
           of
git(1)
."
1330,0,scmp_sys_resolver,"This command resolves both system call names and numbers with
       respect to the given architecture supplied in the optional
ARCH
argument. If the architecture is not supplied on the command line
       then the native architecture is used. If the ""-t"" argument is
       specified along with a system call name, then the system call will
       be translated as necessary for the given architecture."
1330,1,scmp_sys_resolver,"If the ""-t"" argument is
       specified along with a system call name, then the system call will
       be translated as necessary for the given architecture. The ""-t""
       argument has no effect if a system call number is specified. In some combinations of architecture and system call, a negative
       system call number will be displayed."
1330,2,scmp_sys_resolver,"In some combinations of architecture and system call, a negative
       system call number will be displayed. A negative system call
       number indicates that the system call is not defined for the given
       architecture and is treated in a special manner by libseccomp
       depending on the operation. -a
ARCH
The architecture to use for resolving the system call."
1330,3,scmp_sys_resolver,"-a
ARCH
The architecture to use for resolving the system call. Valid
ARCH
values are ""x86"", ""x86_64"", ""x32"", ""arm"",
              ""aarch64"", ""loongarch64"", ""m68k"", ""mips"", ""mipsel"",
              ""mips64"", ""mipsel64"", ""mips64n32"", ""mipsel64n32"", ""parisc"",
              ""parisc64"", ""ppc"", ""ppc64"", ""ppc64le"", ""s390"", ""s390x"",
              ""sheb"" and ""sh"". -t
If necessary, translate the system call name to the proper
              system call number, even if the system call name is
              different, e.g."
1330,4,scmp_sys_resolver,"-t
If necessary, translate the system call name to the proper
              system call number, even if the system call name is
              different, e.g. socket(2) on x86. -h
A simple one-line usage display."
1331,0,sccs,"The
sccs
utility is a front end to the SCCS programs. It also
       includes the capability to run set-user-id to another user to
       provide additional protection. The
sccs
utility shall invoke the specified
command
with the
       specified
options
and
operands
."
1331,1,sccs,"The
sccs
utility shall invoke the specified
command
with the
       specified
options
and
operands
. By default, each of the
operands
shall be modified by prefixing it with the string
""SCCS/s.""
. The
command
can be the name of one of the SCCS utilities in this
       volume of POSIX.1â2017 (
admin
,
delta
,
get
,
prs
,
rmdel
,
sact
,
unget
,
val
, or
what
) or one of the pseudo-utilities listed in the
       EXTENDED DESCRIPTION section."
1332,0,sar,"The
sar
command writes to standard output the contents of selected
       cumulative activity counters in the operating system. The
       accounting system, based on the values in the
count
and
interval
parameters, writes information the specified number of times
       spaced at the specified intervals in seconds. If the
interval
parameter is set to zero, the
sar
command displays the average
       statistics for the time since the system was started."
1332,1,sar,"If the
interval
parameter is set to zero, the
sar
command displays the average
       statistics for the time since the system was started. If the
interval
parameter is specified without the
count
parameter, then
       reports are generated continuously. The collected data can also
       be saved in the file specified by the
-o
filename
flag, in
       addition to being displayed onto the screen."
1332,2,sar,"The collected data can also
       be saved in the file specified by the
-o
filename
flag, in
       addition to being displayed onto the screen. If
filename
is
       omitted,
sar
uses the standard system activity daily data file
       (see below). By default all the data available from the kernel
       are saved in the data file."
1332,3,sar,"By default all the data available from the kernel
       are saved in the data file. The
sar
command extracts and writes to standard output records
       previously saved in a file. This file can be either the one
       specified by the
-f
flag or, by default, the standard system
       activity daily data file."
1332,4,sar,"This file can be either the one
       specified by the
-f
flag or, by default, the standard system
       activity daily data file. It is also possible to enter
-1
,
-2
etc. as an argument to
sar
to display data of that days ago."
1332,5,sar,"as an argument to
sar
to display data of that days ago. For
       example,
-1
will point at the standard system activity file of
       yesterday. Standard system activity daily data files are named
saDD
or
saYYYYMMDD
, where
YYYY
stands for the current year,
MM
for the
       current month and
DD
for the current day."
1332,6,sar,"Standard system activity daily data files are named
saDD
or
saYYYYMMDD
, where
YYYY
stands for the current year,
MM
for the
       current month and
DD
for the current day. They are the default
       files used by
sar
only when no filename has been explicitly
       specified. When used to write data to files (with its option
-o
),
sar
will use
saYYYYMMDD
if option
-D
has also been specified, else
       it will use
saDD
."
1332,7,sar,"When used to write data to files (with its option
-o
),
sar
will use
saYYYYMMDD
if option
-D
has also been specified, else
       it will use
saDD
. When used to display the records previously
       saved in a file,
sar
will look for the most recent of
saDD
and
saYYYYMMDD
, and use it. Standard system activity daily data files are located in the
/var/log/sa
directory by default."
1332,8,sar,"Standard system activity daily data files are located in the
/var/log/sa
directory by default. Yet it is possible to specify an
       alternate location for them: If a directory (instead of a plain
       file) is used with options
-f
or
-o
then it will be considered as
       the directory containing the data files. Without the
-P
flag, the
sar
command reports system-wide (global
       among all processors) statistics, which are calculated as averages
       for values expressed as percentages, and as sums otherwise."
1332,9,sar,"Without the
-P
flag, the
sar
command reports system-wide (global
       among all processors) statistics, which are calculated as averages
       for values expressed as percentages, and as sums otherwise. If the
-P
flag is given, the
sar
command reports activity which relates
       to the specified processor or processors. If
-P ALL
is given, the
sar
command reports statistics for each individual processor and
       global statistics among all processors."
1332,10,sar,"If
-P ALL
is given, the
sar
command reports statistics for each individual processor and
       global statistics among all processors. Offline processors are not
       displayed. You can select information about specific system activities using
       flags."
1332,11,sar,"You can select information about specific system activities using
       flags. Not specifying any flags selects only CPU activity. Specifying the
-A
flag selects all possible activities."
1332,12,sar,"Specifying the
-A
flag selects all possible activities. The default version of the
sar
command (CPU utilization report)
       might be one of the first facilities the user runs to begin system
       activity investigation, because it monitors major system
       resources. If CPU utilization is near 100 percent (user + nice +
       system), the workload sampled is CPU-bound."
1332,13,sar,"If CPU utilization is near 100 percent (user + nice +
       system), the workload sampled is CPU-bound. If multiple samples and multiple reports are desired, it is
       convenient to specify an output file for the
sar
command. Run the
sar
command as a background process."
1332,14,sar,"Run the
sar
command as a background process. The syntax for this is:
sar -o
datafile interval count
>/dev/null 2>&1 &
All data are captured in binary form and saved to a file
       (
datafile
). The data can then be selectively displayed with the
sar
command using the
-f
option."
1332,15,sar,"The data can then be selectively displayed with the
sar
command using the
-f
option. Set the
interval
and
count
parameters to select
count
records at
interval
second intervals. If the
count
parameter is not set, all the records saved in the
       file will be selected."
1332,16,sar,"If the
count
parameter is not set, all the records saved in the
       file will be selected. Collection of data in this manner is
       useful to characterize system usage over a period of time and
       determine peak usage hours. Note: The
sar
command only reports on local activities."
1333,0,scp,"scp
copies files between hosts on a network. scp
uses the SFTP protocol over a
ssh
(1) connection for data
       transfer, and uses the same authentication and provides the same
       security as a login session. scp
will ask for passwords or passphrases if they are needed for
       authentication."
1333,1,scp,"scp
will ask for passwords or passphrases if they are needed for
       authentication. The
source
and
target
may be specified as a local pathname, a
       remote host with optional path in the form [user@]host:[path], or
       a URI in the form scp://[user@]host[:port][/path]. Local file
       names can be made explicit using absolute or relative pathnames to
       avoid
scp
treating file names containing â:â as host specifiers."
1333,2,scp,"Local file
       names can be made explicit using absolute or relative pathnames to
       avoid
scp
treating file names containing â:â as host specifiers. When copying between two remote hosts, if the URI format is used,
       a
port
cannot be specified on the
target
if the
-R
option is used. The options are as follows:
-3
Copies between two remote hosts are transferred through
               the local host."
1333,3,scp,"The options are as follows:
-3
Copies between two remote hosts are transferred through
               the local host. Without this option the data is copied
               directly between the two remote hosts. Note that, when
               using the legacy SCP protocol (via the
-O
flag), this
               option selects batch mode for the second host as
scp
cannot ask for passwords or passphrases for both hosts."
1333,4,scp,"Note that, when
               using the legacy SCP protocol (via the
-O
flag), this
               option selects batch mode for the second host as
scp
cannot ask for passwords or passphrases for both hosts. This mode is the default. -4
Forces
scp
to use IPv4 addresses only."
1333,5,scp,"-4
Forces
scp
to use IPv4 addresses only. -6
Forces
scp
to use IPv6 addresses only. -A
Allows forwarding of
ssh-agent
(1) to the remote system."
1333,6,scp,"-A
Allows forwarding of
ssh-agent
(1) to the remote system. The default is not to forward an authentication agent. -B
Selects batch mode (prevents asking for passwords or
               passphrases)."
1333,7,scp,"-B
Selects batch mode (prevents asking for passwords or
               passphrases). -C
Compression enable. Passes the
-C
flag to
ssh
(1) to
               enable compression."
1333,8,scp,"Passes the
-C
flag to
ssh
(1) to
               enable compression. -c
cipher
Selects the cipher to use for encrypting the data
               transfer. This option is directly passed to
ssh
(1)."
1333,9,scp,"This option is directly passed to
ssh
(1). -D
sftp_server_path
Connect directly to a local SFTP server program rather
               than a remote one via
ssh
(1). This option may be useful
               in debugging the client and server."
1333,10,scp,"This option may be useful
               in debugging the client and server. -F
ssh_config
Specifies an alternative per-user configuration file for
ssh
. This option is directly passed to
ssh
(1)."
1333,11,scp,"This option is directly passed to
ssh
(1). -i
identity_file
Selects the file from which the identity (private key) for
               public key authentication is read. This option is
               directly passed to
ssh
(1)."
1333,12,scp,"This option is
               directly passed to
ssh
(1). -J
destination
Connect to the target host by first making an
scp
connection to the jump host described by
destination
and
               then establishing a TCP forwarding to the ultimate
               destination from there. Multiple jump hops may be
               specified separated by comma characters."
1333,13,scp,"Multiple jump hops may be
               specified separated by comma characters. This is a
               shortcut to specify a
ProxyJump
configuration directive. This option is directly passed to
ssh
(1)."
1333,14,scp,"This option is directly passed to
ssh
(1). -l
limit
Limits the used bandwidth, specified in Kbit/s. -O
Use the legacy SCP protocol for file transfers instead of
               the SFTP protocol."
1333,15,scp,"-O
Use the legacy SCP protocol for file transfers instead of
               the SFTP protocol. Forcing the use of the SCP protocol
               may be necessary for servers that do not implement SFTP,
               for backwards-compatibility for particular filename
               wildcard patterns and for expanding paths with a â~â
               prefix for older SFTP servers. -o
ssh_option
Can be used to pass options to
ssh
in the format used in
ssh_config
(5)."
1333,16,scp,"-o
ssh_option
Can be used to pass options to
ssh
in the format used in
ssh_config
(5). This is useful for specifying options for
               which there is no separate
scp
command-line flag. For
               full details of the options listed below, and their
               possible values, see
ssh_config
(5)."
1333,17,scp,"For
               full details of the options listed below, and their
               possible values, see
ssh_config
(5). AddressFamily
                     BatchMode
                     BindAddress
                     BindInterface
                     CanonicalDomains
                     CanonicalizeFallbackLocal
                     CanonicalizeHostname
                     CanonicalizeMaxDots
                     CanonicalizePermittedCNAMEs
                     CASignatureAlgorithms
                     CertificateFile
                     CheckHostIP
                     Ciphers
                     Compression
                     ConnectionAttempts
                     ConnectTimeout
                     ControlMaster
                     ControlPath
                     ControlPersist
                     GlobalKnownHostsFile
                     GSSAPIAuthentication
                     GSSAPIDelegateCredentials
                     HashKnownHosts
                     Host
                     HostbasedAcceptedAlgorithms
                     HostbasedAuthentication
                     HostKeyAlgorithms
                     HostKeyAlias
                     Hostname
                     IdentitiesOnly
                     IdentityAgent
                     IdentityFile
                     IPQoS
                     KbdInteractiveAuthentication
                     KbdInteractiveDevices
                     KexAlgorithms
                     KnownHostsCommand
                     LogLevel
                     MACs
                     NoHostAuthenticationForLocalhost
                     NumberOfPasswordPrompts
                     PasswordAuthentication
                     PKCS11Provider
                     Port
                     PreferredAuthentications
                     ProxyCommand
                     ProxyJump
                     PubkeyAcceptedAlgorithms
                     PubkeyAuthentication
                     RekeyLimit
                     RequiredRSASize
                     SendEnv
                     ServerAliveInterval
                     ServerAliveCountMax
                     SetEnv
                     StrictHostKeyChecking
                     TCPKeepAlive
                     UpdateHostKeys
                     User
                     UserKnownHostsFile
                     VerifyHostKeyDNS
-P
port
Specifies the port to connect to on the remote host. Note
               that this option is written with a capital âPâ, because
-p
is already reserved for preserving the times and mode bits
               of the file."
1333,18,scp,"Note
               that this option is written with a capital âPâ, because
-p
is already reserved for preserving the times and mode bits
               of the file. -p
Preserves modification times, access times, and file mode
               bits from the source file. -q
Quiet mode: disables the progress meter as well as warning
               and diagnostic messages from
ssh
(1)."
1333,19,scp,"-q
Quiet mode: disables the progress meter as well as warning
               and diagnostic messages from
ssh
(1). -R
Copies between two remote hosts are performed by
               connecting to the origin host and executing
scp
there. This requires that
scp
running on the origin host can
               authenticate to the destination host without requiring a
               password."
1333,20,scp,"This requires that
scp
running on the origin host can
               authenticate to the destination host without requiring a
               password. -r
Recursively copy entire directories. Note that
scp
follows symbolic links encountered in the tree traversal."
1333,21,scp,"Note that
scp
follows symbolic links encountered in the tree traversal. -S
program
Name of
program
to use for the encrypted connection. The
               program must understand
ssh
(1) options."
1333,22,scp,"The
               program must understand
ssh
(1) options. -T
Disable strict filename checking. By default when copying
               files from a remote host to a local directory
scp
checks
               that the received filenames match those requested on the
               command-line to prevent the remote end from sending
               unexpected or unwanted files."
1333,23,scp,"By default when copying
               files from a remote host to a local directory
scp
checks
               that the received filenames match those requested on the
               command-line to prevent the remote end from sending
               unexpected or unwanted files. Because of differences in
               how various operating systems and shells interpret
               filename wildcards, these checks may cause wanted files to
               be rejected. This option disables these checks at the
               expense of fully trusting that the server will not send
               unexpected filenames."
1333,24,scp,"This option disables these checks at the
               expense of fully trusting that the server will not send
               unexpected filenames. -v
Verbose mode. Causes
scp
and
ssh
(1) to print debugging
               messages about their progress."
1333,25,scp,"Causes
scp
and
ssh
(1) to print debugging
               messages about their progress. This is helpful in
               debugging connection, authentication, and configuration
               problems. -X
sftp_option
Specify an option that controls aspects of SFTP protocol
               behaviour."
1333,26,scp,"-X
sftp_option
Specify an option that controls aspects of SFTP protocol
               behaviour. The valid options are:
nrequests
=
value
Controls how many concurrent SFTP read or write
                       requests may be in progress at any point in time
                       during a download or upload. By default 64
                       requests may be active concurrently."
1333,27,scp,"By default 64
                       requests may be active concurrently. buffer
=
value
Controls the maximum buffer size for a single SFTP
                       read/write operation used during download or
                       upload. By default a 32KB buffer is used."
1334,0,scriptlive,"This program re-runs a typescript, using stdin typescript and
       timing information to ensure that input happens in the same rhythm
       as it originally appeared when the script was recorded. The
session is executed
in a newly created pseudoterminal with the
       userâs $SHELL (or defaults to
/bin/bash
). Be careful!"
1334,1,scriptlive,"Be careful! Do not forget that the typescript may contains
       arbitrary commands. It is recommended to use
""scriptreplay
--stream in --log-in typescript""
(or with
--log-io
instead of
--log-in
) to verify the typescript before it is executed by
scriptlive
."
1334,2,scriptlive,"It is recommended to use
""scriptreplay
--stream in --log-in typescript""
(or with
--log-io
instead of
--log-in
) to verify the typescript before it is executed by
scriptlive
. The timing information is what
script(1)
outputs to file specified
       by
--log-timing
. The typescript has to contain stdin information
       and it is what script1 outputs to file specified by
--log-in
or
--log-io
."
1335,0,script,"script
makes a typescript of everything on your terminal session. The terminal data are stored in raw form to the log file and
       information about timing to another (optional) structured log
       file. The timing log file is necessary to replay the session later
       by
scriptreplay(1)
and to store additional information about the
       session."
1335,1,script,"The timing log file is necessary to replay the session later
       by
scriptreplay(1)
and to store additional information about the
       session. Since version 2.35,
script
supports multiple streams and allows
       the logging of input and output to separate files or all the one
       file. This version also supports a new timing file which records
       additional information."
1335,2,script,"This version also supports a new timing file which records
       additional information. The command
scriptreplay --summary
then
       provides all the information. If the argument
file
or option
--log-out
file
is given,
script
saves the dialogue in this
file
."
1335,3,script,"If the argument
file
or option
--log-out
file
is given,
script
saves the dialogue in this
file
. If no filename is given, the
       dialogue is saved in the file
typescript
. Note that logging input using
--log-in
or
--log-io
may record
       security-sensitive information as the log file contains all
       terminal session input (e.g., passwords) independently of the
       terminal echo flag setting."
1336,0,scriptreplay,"This program replays a typescript, using timing information to
       ensure that output happens in the same rhythm as it originally
       appeared when the script was recorded. The replay simply displays the information again; the programs
       that were run when the typescript was being recorded are
not run
again
. Since the same information is simply being displayed,
scriptreplay
is only guaranteed to work properly if run on the
       same type of terminal the typescript was recorded on."
1336,1,scriptreplay,"Since the same information is simply being displayed,
scriptreplay
is only guaranteed to work properly if run on the
       same type of terminal the typescript was recorded on. Otherwise,
       any escape characters in the typescript may be interpreted
       differently by the terminal to which
scriptreplay
is sending its
       output. The timing information is what
script(1)
outputs to file specified
       by
--log-timing
."
1336,2,scriptreplay,"The timing information is what
script(1)
outputs to file specified
       by
--log-timing
. By default, the typescript to display is assumed to be named
typescript
, but other filenames may be specified, as the second
       parameter or with option
--log-out
. If the third parameter or
--divisor
is specified, it is used as a
       speed-up multiplier."
1336,3,scriptreplay,"If the third parameter or
--divisor
is specified, it is used as a
       speed-up multiplier. For example, a speed-up of 2 makes
scriptreplay
go twice as fast, and a speed-down of 0.1 makes it go
       ten times slower than the original session. During the replay, you can interactively speed up, slow down, or
       pause the playback using key bindings."
1337,0,secon,"See a part of a context. The context is taken from a file, pid,
       user input or the context in which
secon
is originally executed. -V
,
--version
shows the current version of secon
-h
,
--help
shows the usage information for secon
-P
,
--prompt
outputs data in a format suitable for a prompt
-C
,
--color
outputs data with the associated ANSI color codes (requires
              -P)
-u
,
--user
show the user of the security context
-r
,
--role
show the role of the security context
-t
,
--type
show the type of the security context
-s
,
--sensitivity
show the sensitivity level of the security context
-c
,
--clearance
show the clearance level of the security context
-m
,
--mls-range
show the sensitivity level and clearance, as a range, of
              the security context
-R
,
--raw
outputs  the sensitivity level and clearance in an
              untranslated format."
1337,1,secon,"-V
,
--version
shows the current version of secon
-h
,
--help
shows the usage information for secon
-P
,
--prompt
outputs data in a format suitable for a prompt
-C
,
--color
outputs data with the associated ANSI color codes (requires
              -P)
-u
,
--user
show the user of the security context
-r
,
--role
show the role of the security context
-t
,
--type
show the type of the security context
-s
,
--sensitivity
show the sensitivity level of the security context
-c
,
--clearance
show the clearance level of the security context
-m
,
--mls-range
show the sensitivity level and clearance, as a range, of
              the security context
-R
,
--raw
outputs  the sensitivity level and clearance in an
              untranslated format. -f
,
--file
gets the context from the specified file FILE
-L
,
--link
gets the context from the specified file FILE (doesn't
              follow symlinks)
-p
,
--pid
gets the context from the specified process PID
--pid-exec
gets the exec context from the specified process PID
--pid-fs
gets the fscreate context from the specified process PID
--pid-key
gets the key context from the specified process PID
--current
,
--self
gets the context from the current process
--current-exec
,
--self-exec
gets the exec context from the current process
--current-fs
,
--self-fs
gets the fscreate context from the current process
--current-key
,
--self-key
gets the key context from the current process
--parent
gets the context from the parent of the current process
--parent-exec
gets the exec context from the parent of the current
              process
--parent-fs
gets the fscreate context from the parent of the current
              process
--parent-key
gets the key context from the parent of the current process

       Additional argument
CONTEXT
may be provided and will be used if no
       options have been specified to make
secon
get its context from
       another source. If that argument is
-
then the context will be
       read from stdin."
1337,2,secon,"If that argument is
-
then the context will be
       read from stdin. If there is no argument,
secon
will try reading a context from
       stdin, if that is not a tty, otherwise
secon
will act as though
--self
had been passed. If none of
--user
,
--role
,
--type
,
--level
or
--mls-range
is
       passed."
1337,3,secon,"If there is no argument,
secon
will try reading a context from
       stdin, if that is not a tty, otherwise
secon
will act as though
--self
had been passed. If none of
--user
,
--role
,
--type
,
--level
or
--mls-range
is
       passed. Then all of them will be output."
1338,0,sdiff,"Side-by-side merge of differences between FILE1 and FILE2. Mandatory arguments to long options are mandatory for short
       options too. -o
,
--output
=
FILE
operate interactively, sending output to FILE
-i
,
--ignore-case
consider upper- and lower-case to be the same
-E
,
--ignore-tab-expansion
ignore changes due to tab expansion
-Z
,
--ignore-trailing-space
ignore white space at line end
-b
,
--ignore-space-change
ignore changes in the amount of white space
-W
,
--ignore-all-space
ignore all white space
-B
,
--ignore-blank-lines
ignore changes whose lines are all blank
-I
,
--ignore-matching-lines
=
RE
ignore changes all whose lines match RE
--strip-trailing-cr
strip trailing carriage return on input
-a
,
--text
treat all files as text
-w
,
--width
=
NUM
output at most NUM (default 130) print columns
-l
,
--left-column
output only the left column of common lines
-s
,
--suppress-common-lines
do not output common lines
-t
,
--expand-tabs
expand tabs to spaces in output
--tabsize
=
NUM
tab stops at every NUM (default 8) print columns
-d
,
--minimal
try hard to find a smaller set of changes
-H
,
--speed-large-files
assume large files, many scattered small changes
--diff-program
=
PROGRAM
use PROGRAM to compare files
--help
display this help and exit
-v
,
--version
output version information and exit

       If a FILE is '-', read standard input."
1338,1,sdiff,"Mandatory arguments to long options are mandatory for short
       options too. -o
,
--output
=
FILE
operate interactively, sending output to FILE
-i
,
--ignore-case
consider upper- and lower-case to be the same
-E
,
--ignore-tab-expansion
ignore changes due to tab expansion
-Z
,
--ignore-trailing-space
ignore white space at line end
-b
,
--ignore-space-change
ignore changes in the amount of white space
-W
,
--ignore-all-space
ignore all white space
-B
,
--ignore-blank-lines
ignore changes whose lines are all blank
-I
,
--ignore-matching-lines
=
RE
ignore changes all whose lines match RE
--strip-trailing-cr
strip trailing carriage return on input
-a
,
--text
treat all files as text
-w
,
--width
=
NUM
output at most NUM (default 130) print columns
-l
,
--left-column
output only the left column of common lines
-s
,
--suppress-common-lines
do not output common lines
-t
,
--expand-tabs
expand tabs to spaces in output
--tabsize
=
NUM
tab stops at every NUM (default 8) print columns
-d
,
--minimal
try hard to find a smaller set of changes
-H
,
--speed-large-files
assume large files, many scattered small changes
--diff-program
=
PROGRAM
use PROGRAM to compare files
--help
display this help and exit
-v
,
--version
output version information and exit

       If a FILE is '-', read standard input. Exit status is 0 if inputs
       are the same, 1 if different, 2 if trouble."
1339,0,sed,"Sed
is a stream editor. A stream editor is used to perform basic
       text transformations on an input stream (a file or input from a
       pipeline). While in some ways similar to an editor which permits
       scripted edits (such as
ed
),
sed
works by making only one pass
       over the input(s), and is consequently more efficient."
1339,1,sed,"While in some ways similar to an editor which permits
       scripted edits (such as
ed
),
sed
works by making only one pass
       over the input(s), and is consequently more efficient. But it is
sed
's ability to filter text in a pipeline which particularly
       distinguishes it from other types of editors. -n
,
--quiet
,
--silent
suppress automatic printing of pattern space
--debug
annotate program execution
-e
script,
--expression
=
script
add the script to the commands to be executed
-f
script-file,
--file
=
script-file
add the contents of script-file to the commands to be
              executed
--follow-symlinks
follow symlinks when processing in place
-i[SUFFIX]
,
--in-place
[=
SUFFIX
]

              edit files in place (makes backup if SUFFIX supplied)
-l
N,
--line-length
=
N
specify the desired line-wrap length for the `l' command
--posix
disable all GNU extensions."
1339,2,sed,"-n
,
--quiet
,
--silent
suppress automatic printing of pattern space
--debug
annotate program execution
-e
script,
--expression
=
script
add the script to the commands to be executed
-f
script-file,
--file
=
script-file
add the contents of script-file to the commands to be
              executed
--follow-symlinks
follow symlinks when processing in place
-i[SUFFIX]
,
--in-place
[=
SUFFIX
]

              edit files in place (makes backup if SUFFIX supplied)
-l
N,
--line-length
=
N
specify the desired line-wrap length for the `l' command
--posix
disable all GNU extensions. -E
,
-r
,
--regexp-extended
use extended regular expressions in the script (for
              portability use POSIX
-E
). -s
,
--separate
consider files as separate rather than as a single,
              continuous long stream."
1339,3,sed,"-s
,
--separate
consider files as separate rather than as a single,
              continuous long stream. --sandbox
operate in sandbox mode (disable e/r/w commands). -u
,
--unbuffered
load minimal amounts of data from the input files and flush
              the output buffers more often
-z
,
--null-data
separate lines by NUL characters
--help
display this help and exit
--version
output version information and exit

       If no
-e
,
--expression
,
-f
, or
--file
option is given, then the
       first non-option argument is taken as the sed script to interpret."
1339,4,sed,"-u
,
--unbuffered
load minimal amounts of data from the input files and flush
              the output buffers more often
-z
,
--null-data
separate lines by NUL characters
--help
display this help and exit
--version
output version information and exit

       If no
-e
,
--expression
,
-f
, or
--file
option is given, then the
       first non-option argument is taken as the sed script to interpret. All remaining arguments are names of input files; if no input
       files are specified, then the standard input is read. GNU sed home page: <
https://www.gnu.org/software/sed/
>."
1339,5,sed,"GNU sed home page: <
https://www.gnu.org/software/sed/
>. General
       help using GNU software: <
https://www.gnu.org/gethelp/
>. E-mail
       bug reports to: <bug-sed@gnu.org>."
1340,0,semind,"semind is the simple to use cscope-like tool based on
       sparse/dissect.  Unlike cscope it runs after pre-processor and
       thus it can't index the code filtered out by ifdef's, but otoh it
       understands how the symbol is used and it can track the usage of
       struct members."
1341,0,sed,"The
sed
utility is a stream editor that shall read one or more
       text files, make editing changes according to a script of editing
       commands, and write the results to standard output. The script
       shall be obtained from either the
script
operand string or a
       combination of the option-arguments from the
-e
script
and
-f
script_file
options."
1342,0,seq,"Print numbers from FIRST to LAST, in steps of INCREMENT. Mandatory arguments to long options are mandatory for short
       options too. -f
,
--format
=
FORMAT
use printf style floating-point FORMAT
-s
,
--separator
=
STRING
use STRING to separate numbers (default: \n)
-w
,
--equal-width
equalize width by padding with leading zeroes
--help
display this help and exit
--version
output version information and exit

       If FIRST or INCREMENT is omitted, it defaults to 1."
1342,1,seq,"-f
,
--format
=
FORMAT
use printf style floating-point FORMAT
-s
,
--separator
=
STRING
use STRING to separate numbers (default: \n)
-w
,
--equal-width
equalize width by padding with leading zeroes
--help
display this help and exit
--version
output version information and exit

       If FIRST or INCREMENT is omitted, it defaults to 1. That is, an
       omitted INCREMENT defaults to 1 even when LAST is smaller than
       FIRST. The sequence of numbers ends when the sum of the current
       number and INCREMENT would become greater than LAST."
1342,2,seq,"The sequence of numbers ends when the sum of the current
       number and INCREMENT would become greater than LAST. FIRST,
       INCREMENT, and LAST are interpreted as floating point values. INCREMENT is usually positive if FIRST is smaller than LAST, and
       INCREMENT is usually negative if FIRST is greater than LAST."
1342,3,seq,"INCREMENT is usually positive if FIRST is smaller than LAST, and
       INCREMENT is usually negative if FIRST is greater than LAST. INCREMENT must not be 0; none of FIRST, INCREMENT and LAST may be
       NaN. FORMAT must be suitable for printing one argument of type
       'double'; it defaults to %.PRECf if FIRST, INCREMENT, and LAST are
       all fixed point decimal numbers with maximum precision PREC, and
       to %g otherwise."
1343,0,screen,"Screen
is a full-screen window manager that multiplexes a physical
       terminal between several processes (typically interactive shells). Each virtual terminal provides the functions of a DEC VT100
       terminal and, in addition, several control functions from the ISO
       6429 (ECMA 48, ANSI X3.64) and ISO 2022 standards (e.g. insert/delete line and support for multiple character sets)."
1343,1,screen,"insert/delete line and support for multiple character sets). There is a scrollback history buffer for each virtual terminal and
       a copy-and-paste mechanism that allows moving text regions between
       windows. When
screen
is called, it creates a single window with a shell in
       it (or the specified command) and then gets out of your way so
       that you can use the program as you normally would."
1343,2,screen,"When
screen
is called, it creates a single window with a shell in
       it (or the specified command) and then gets out of your way so
       that you can use the program as you normally would. Then, at any
       time, you can create new (full-screen) windows with other programs
       in them (including more shells), kill existing windows, view a
       list of windows, turn output logging on and off, copy-and-paste
       text between windows, view the scrollback history, switch between
       windows in whatever manner you wish, etc. All windows run their
       programs completely independent of each other."
1343,3,screen,"All windows run their
       programs completely independent of each other. Programs continue
       to run when their window is currently not visible and even when
       the whole
screen
session is detached from the user's terminal. When a program terminates,
screen
(per default) kills the window
       that contained it."
1343,4,screen,"When a program terminates,
screen
(per default) kills the window
       that contained it. If this window was in the foreground, the
       display switches to the previous window; if none are left,
screen
exits. Shells usually distinguish between running as login-shell
       or sub-shell."
1343,5,screen,"Shells usually distinguish between running as login-shell
       or sub-shell. Screen runs them as sub-shells, unless told
       otherwise (See shell .screenrc command). Everything you type is sent to the program running in the current
       window."
1343,6,screen,"Everything you type is sent to the program running in the current
       window. The only exception to this is the one keystroke that is
       used to initiate a command to the window manager. By default,
       each command begins with a control-a (abbreviated C-a from now
       on), and is followed by one other keystroke."
1343,7,screen,"By default,
       each command begins with a control-a (abbreviated C-a from now
       on), and is followed by one other keystroke. The command
       character and all the key bindings can be fully customized to be
       anything you like, though they are always two characters in
       length. Screen
does not understand the prefix C- to mean control, although
       this notation is used in this manual for readability."
1343,8,screen,"Screen
does not understand the prefix C- to mean control, although
       this notation is used in this manual for readability. Please use
       the caret notation (^A instead of C-a) as arguments to e.g. the
escape
command or the
-e
option."
1343,9,screen,"the
escape
command or the
-e
option. Screen
will also print out
       control characters in caret notation. The standard way to create a new window is to type
C-a c
."
1343,10,screen,"The standard way to create a new window is to type
C-a c
. This
       creates a new window running a shell and switches to that window
       immediately, regardless of the state of the process running in the
       current window. Similarly, you can create a new window with a
       custom command in it by first binding the command to a keystroke
       (in your .screenrc file or at the
C-a :
command line) and then
       using it just like the
C-a c
command."
1343,11,screen,"Similarly, you can create a new window with a
       custom command in it by first binding the command to a keystroke
       (in your .screenrc file or at the
C-a :
command line) and then
       using it just like the
C-a c
command. In addition, new windows
       can be created by running a command like:

              screen emacs prog.c

       from a shell prompt within a previously created window. This will
       not run another copy of
screen
, but will instead supply the
       command name and its arguments to the window manager (specified in
       the $STY environment variable) who will use it to create the new
       window."
1343,12,screen,"This will
       not run another copy of
screen
, but will instead supply the
       command name and its arguments to the window manager (specified in
       the $STY environment variable) who will use it to create the new
       window. The above example would start the emacs editor (editing
       prog.c) and switch to its window. - Note that you cannot transport
       environment variables from the invoking shell to the application
       (emacs in this case), because it is forked from the parent screen
       process, not from the invoking shell."
1343,13,screen,"- Note that you cannot transport
       environment variables from the invoking shell to the application
       (emacs in this case), because it is forked from the parent screen
       process, not from the invoking shell. If /etc/utmp is writable by
screen
, an appropriate record will be
       written to this file for each window, and removed when the window
       is terminated. This is useful for working with talk, script,
       shutdown, rsend, sccs and other similar programs that use the utmp
       file to determine who you are."
1343,14,screen,"This is useful for working with talk, script,
       shutdown, rsend, sccs and other similar programs that use the utmp
       file to determine who you are. As long as
screen
is active on your
       terminal, the terminal's own record is removed from the utmp file. See also C-a L."
1344,0,setleds,"Setleds
reports and changes the led flag settings of a VT (namely
       NumLock, CapsLock and ScrollLock). Without arguments,
setleds
prints the current settings. With arguments, it sets or clears
       the indicated flags (and leaves the others unchanged)."
1344,1,setleds,"With arguments, it sets or clears
       the indicated flags (and leaves the others unchanged). The
       settings before and after the change are reported if the -v flag
       is given. The led flag settings are specific for each VT (and the VT
       corresponding to stdin is used)."
1344,2,setleds,"The led flag settings are specific for each VT (and the VT
       corresponding to stdin is used). By default (or with option -F),
setleds
will only change the VT
       flags (and their setting may be reflected by the keyboard leds). With option -D,
setleds
will change both the VT flags and their
       default settings (so that a subsequent reset will not undo the
       change)."
1344,3,setleds,"With option -D,
setleds
will change both the VT flags and their
       default settings (so that a subsequent reset will not undo the
       change). This might be useful for people who always want to have
       numlock set. With option -L,
setleds
will not touch the VT flags, but only
       change the leds."
1344,4,setleds,"With option -L,
setleds
will not touch the VT flags, but only
       change the leds. From this moment on, the leds will no longer
       reflect the VT flags (but display whatever is put into them). The
       command
setleds -L
(without further arguments) will restore the
       situation in which the leds reflect the VT flags."
1344,5,setleds,"The
       command
setleds -L
(without further arguments) will restore the
       situation in which the leds reflect the VT flags. One might use
setleds
in /etc/rc to define the initial and default
       state of NumLock, e.g. by
            INITTY=/dev/tty[1-8]
            for tty in $INITTY; do
                 setleds -D +num < $tty
            done"
1345,0,setfacl,"This utility sets Access Control Lists (ACLs) of files and
       directories. On the command line, a sequence of commands is
       followed by a sequence of files (which in turn can be followed by
       another sequence of commands, ...). The
-m
and
-x
options expect an ACL on the command line."
1345,1,setfacl,"The
-m
and
-x
options expect an ACL on the command line. Multiple
       ACL entries are separated by comma characters (`,'). The
-M
and
-X
options read an ACL from a file or from standard input."
1345,2,setfacl,"The
-M
and
-X
options read an ACL from a file or from standard input. The ACL
       entry format is described in Section ACL ENTRIES. The
--set
and
--set-file
options set the ACL of a file or a
       directory."
1345,3,setfacl,"The
--set
and
--set-file
options set the ACL of a file or a
       directory. The previous ACL is replaced. ACL entries for this
       operation must include permissions."
1345,4,setfacl,"ACL entries for this
       operation must include permissions. The
-m (--modify)
and
-M (--modify-file)
options modify the ACL of
       a file or directory. ACL entries for this operation must include
       permissions."
1345,5,setfacl,"ACL entries for this operation must include
       permissions. The
-x (--remove)
and
-X (--remove-file)
options remove ACL
       entries. It is not an error to remove an entry which does not
       exist."
1345,6,setfacl,"It is not an error to remove an entry which does not
       exist. Only ACL entries without the
perms
field are accepted as
       parameters, unless POSIXLY_CORRECT is defined. When reading from files using the
-M
and
-X
options, setfacl
       accepts the output getfacl produces."
1345,7,setfacl,"When reading from files using the
-M
and
-X
options, setfacl
       accepts the output getfacl produces. There is at most one ACL
       entry per line. After a Pound sign (`#'), everything up to the end
       of the line is treated as a comment."
1345,8,setfacl,"After a Pound sign (`#'), everything up to the end
       of the line is treated as a comment. If setfacl is used on a file system which does not support ACLs,
       setfacl operates on the file mode permission bits. If the ACL does
       not fit completely in the permission bits, setfacl modifies the
       file mode permission bits to reflect the ACL as closely as
       possible, writes an error message to standard error, and returns
       with an exit status greater than 0."
1345,9,setfacl,"If the ACL does
       not fit completely in the permission bits, setfacl modifies the
       file mode permission bits to reflect the ACL as closely as
       possible, writes an error message to standard error, and returns
       with an exit status greater than 0. PERMISSIONS
The file owner and processes capable of CAP_FOWNER are granted the
       right to modify ACLs of a file. This is analogous to the
       permissions required for accessing the file mode."
1345,10,setfacl,"PERMISSIONS
The file owner and processes capable of CAP_FOWNER are granted the
       right to modify ACLs of a file. This is analogous to the
       permissions required for accessing the file mode. (On current
       Linux systems, root is the only user with the CAP_FOWNER
       capability.)"
1346,0,setfattr,"The
setfattr
command associates a new
value
with an extended
       attribute
name
for each specified file."
1347,0,setmetamode,"Without argument,
setmetamode
prints the current Meta key mode. With argument, it sets the Meta key mode as indicated. The
       setting before and after the change are reported."
1347,1,setmetamode,"The
       setting before and after the change are reported. The Meta key mode is specific for each VT (and the VT
       corresponding to stdin is used). One might use
setmetamode
in
       /etc/rc to define the initial state of the Meta key mode, e.g."
1347,2,setmetamode,"The Meta key mode is specific for each VT (and the VT
       corresponding to stdin is used). One might use
setmetamode
in
       /etc/rc to define the initial state of the Meta key mode, e.g. by

            INITTY=/dev/tty[1-8]
            for tty in $INITTY; do
                 setmetamode escprefix < $tty
            done"
1348,0,setpgid,"setpgid
runs a program in a new process group."
1349,0,set,"If no
option
s or
argument
s are specified,
set
shall write the
       names and values of all shell variables in the collation sequence
       of the current locale. Each
name
shall start on a separate line,
       using the format:

           ""%s=%s\n"", <
name
>, <
value
>

       The
value
string shall be written with appropriate quoting; see
       the description of shell quoting in
Section 2.2
,
Quoting
. The
       output shall be suitable for reinput to the shell, setting or
       resetting, as far as possible, the variables that are currently
       set; read-only variables cannot be reset."
1349,1,set,"The
       output shall be suitable for reinput to the shell, setting or
       resetting, as far as possible, the variables that are currently
       set; read-only variables cannot be reset. When options are specified, they shall set or unset attributes of
       the shell, as described below. When
argument
s are specified, they
       cause positional parameters to be set or unset, as described
       below."
1349,2,set,"When
argument
s are specified, they
       cause positional parameters to be set or unset, as described
       below. Setting or unsetting attributes and positional parameters
       are not necessarily related actions, but they can be combined in a
       single invocation of
set
. The
set
special built-in shall support the Base Definitions volume
       of POSIX.1â2017,
Section 12.2
,
Utility Syntax Guidelines
except
       that options can be specified with either a leading <hyphen-minus>
       (meaning enable the option) or <plus-sign> (meaning disable it)
       unless otherwise specified."
1349,3,set,"The
set
special built-in shall support the Base Definitions volume
       of POSIX.1â2017,
Section 12.2
,
Utility Syntax Guidelines
except
       that options can be specified with either a leading <hyphen-minus>
       (meaning enable the option) or <plus-sign> (meaning disable it)
       unless otherwise specified. Implementations shall support the options in the following list in
       both their <hyphen-minus> and <plus-sign> forms. These options can
       also be specified as options to
sh
."
1349,4,set,"These options can
       also be specified as options to
sh
. -a
When this option is on, the
export
attribute shall be set
             for each variable to which an assignment is performed; see
             the Base Definitions volume of POSIX.1â2017,
Section 4.23
,
Variable Assignment
. If the assignment precedes a utility
             name in a command, the
export
attribute shall not persist in
             the current execution environment after the utility
             completes, with the exception that preceding one of the
             special built-in utilities causes the
export
attribute to
             persist after the built-in has completed."
1349,5,set,"If the assignment precedes a utility
             name in a command, the
export
attribute shall not persist in
             the current execution environment after the utility
             completes, with the exception that preceding one of the
             special built-in utilities causes the
export
attribute to
             persist after the built-in has completed. If the assignment
             does not precede a utility name in the command, or if the
             assignment is a result of the operation of the
getopts
or
read
utilities, the
export
attribute shall persist until the
             variable is unset. -b
This option shall be supported if the implementation
             supports the User Portability Utilities option."
1349,6,set,"-b
This option shall be supported if the implementation
             supports the User Portability Utilities option. It shall
             cause the shell to notify the user asynchronously of
             background job completions. The following message is written
             to standard error:

                 ""[%d]%c %s%s\n"", <
job-number
>, <
current
>, <status>, <job-name>

             where the fields shall be as follows:

             <
current
>   The character
'+'
identifies the job that would
                         be used as a default for the
fg
or
bg
utilities;
                         this job can also be specified using the
job_id
""%+""
or
""%%""
."
1349,7,set,"The following message is written
             to standard error:

                 ""[%d]%c %s%s\n"", <
job-number
>, <
current
>, <status>, <job-name>

             where the fields shall be as follows:

             <
current
>   The character
'+'
identifies the job that would
                         be used as a default for the
fg
or
bg
utilities;
                         this job can also be specified using the
job_id
""%+""
or
""%%""
. The character
'-'
identifies the
                         job that would become the default if the current
                         default job were to exit; this job can also be
                         specified using the
job_id
""%-""
. For other
                         jobs, this field is a <space>."
1349,8,set,"For other
                         jobs, this field is a <space>. At most one job
                         can be identified with
'+'
and at most one job
                         can be identified with
'-'
. If there is any
                         suspended job, then the current job shall be a
                         suspended job."
1349,9,set,"If there is any
                         suspended job, then the current job shall be a
                         suspended job. If there are at least two
                         suspended jobs, then the previous job also shall
                         be a suspended job. <
job-number
>
                         A number that can be used to identify the
                         process group to the
wait
,
fg
,
bg
, and
kill
utilities."
1349,10,set,"<
job-number
>
                         A number that can be used to identify the
                         process group to the
wait
,
fg
,
bg
, and
kill
utilities. Using these utilities, the job can be
                         identified by prefixing the job number with
'%'
. <
status
>    Unspecified."
1349,11,set,"<
status
>    Unspecified. <
job-name
>  Unspecified. When the shell notifies the user a job has been completed,
             it may remove the job's process ID from the list of those
             known in the current shell execution environment; see
Section 2.9.3.1
,
Examples
."
1349,12,set,"When the shell notifies the user a job has been completed,
             it may remove the job's process ID from the list of those
             known in the current shell execution environment; see
Section 2.9.3.1
,
Examples
. Asynchronous notification shall
             not be enabled by default. -C
(Uppercase C.) Prevent existing files from being overwritten
             by the shell's
'>'
redirection operator (see
Section 2.7.2
,
Redirecting Output
); the
"">|""
redirection operator shall
             override this
noclobber
option for an individual file."
1349,13,set,"-C
(Uppercase C.) Prevent existing files from being overwritten
             by the shell's
'>'
redirection operator (see
Section 2.7.2
,
Redirecting Output
); the
"">|""
redirection operator shall
             override this
noclobber
option for an individual file. -e
When this option is on, when any command fails (for any of
             the reasons listed in
Section 2.8.1
,
Consequences of Shell
Errors
or by returning an exit status greater than zero),
             the shell immediately shall exit, as if by executing the
exit
special built-in utility with no arguments, with the
             following exceptions:

              1. The failure of any individual command in a multi-command
                 pipeline shall not cause the shell to exit."
1349,14,set,"The failure of any individual command in a multi-command
                 pipeline shall not cause the shell to exit. Only the
                 failure of the pipeline itself shall be considered. 2."
1349,15,set,"2. The
-e
setting shall be ignored when executing the
                 compound list following the
while
,
until
,
if
, or
elif
reserved word, a pipeline beginning with the
! reserved
                 word, or any command of an AND-OR list other than the
                 last."
1349,16,set,"reserved
                 word, or any command of an AND-OR list other than the
                 last. 3. If the exit status of a compound command other than a
                 subshell command was the result of a failure while
-e
was being ignored, then
-e
shall not apply to this
                 command."
1349,17,set,"If the exit status of a compound command other than a
                 subshell command was the result of a failure while
-e
was being ignored, then
-e
shall not apply to this
                 command. This requirement applies to the shell environment and each
             subshell environment separately. For example, in:

                 set -e; (false; echo one) | cat; echo two

             the
false
command causes the subshell to exit without
             executing
echo one
; however,
echo two
is executed because
             the exit status of the pipeline
(false; echo one) | cat
is
             zero."
1349,18,set,"For example, in:

                 set -e; (false; echo one) | cat; echo two

             the
false
command causes the subshell to exit without
             executing
echo one
; however,
echo two
is executed because
             the exit status of the pipeline
(false; echo one) | cat
is
             zero. -f
The shell shall disable pathname expansion. -h
Locate and remember utilities invoked by functions as those
             functions are defined (the utilities are normally located
             when the function is executed)."
1349,19,set,"-h
Locate and remember utilities invoked by functions as those
             functions are defined (the utilities are normally located
             when the function is executed). -m
This option shall be supported if the implementation
             supports the User Portability Utilities option. All jobs
             shall be run in their own process groups."
1349,20,set,"All jobs
             shall be run in their own process groups. Immediately before
             the shell issues a prompt after completion of the background
             job, a message reporting the exit status of the background
             job shall be written to standard error. If a foreground job
             stops, the shell shall write a message to standard error to
             that effect, formatted as described by the
jobs
utility."
1349,21,set,"If a foreground job
             stops, the shell shall write a message to standard error to
             that effect, formatted as described by the
jobs
utility. In
             addition, if a job changes status other than exiting (for
             example, if it stops for input or output or is stopped by a
             SIGSTOP signal), the shell shall write a similar message
             immediately prior to writing the next prompt. This option is
             enabled by default for interactive shells."
1349,22,set,"This option is
             enabled by default for interactive shells. -n
The shell shall read commands but does not execute them;
             this can be used to check for shell script syntax errors. An
             interactive shell may ignore this option."
1349,23,set,"An
             interactive shell may ignore this option. -o
Write the current settings of the options to standard output
             in an unspecified format. +o
Write the current option settings to standard output in a
             format that is suitable for reinput to the shell as commands
             that achieve the same options settings."
1349,24,set,"+o
Write the current option settings to standard output in a
             format that is suitable for reinput to the shell as commands
             that achieve the same options settings. -o
option
This option is supported if the system supports the User
             Portability Utilities option. It shall set various options,
             many of which shall be equivalent to the single option
             letters."
1349,25,set,"It shall set various options,
             many of which shall be equivalent to the single option
             letters. The following values of
option
shall be supported:
allexport
Equivalent to
-a
. errexit
Equivalent to
-e
."
1349,26,set,"errexit
Equivalent to
-e
. ignoreeof
Prevent an interactive shell from exiting on end-
                       of-file. This setting prevents accidental logouts
                       when <control>âD is entered."
1349,27,set,"This setting prevents accidental logouts
                       when <control>âD is entered. A user shall
                       explicitly
exit
to leave the interactive shell. monitor
Equivalent to
-m
."
1349,28,set,"monitor
Equivalent to
-m
. This option is supported if the
                       system supports the User Portability Utilities
                       option. noclobber
Equivalent to
-C
(uppercase C)."
1349,29,set,"noclobber
Equivalent to
-C
(uppercase C). noglob
Equivalent to
-f
. noexec
Equivalent to
-n
."
1349,30,set,"noexec
Equivalent to
-n
. nolog
Prevent the entry of function definitions into the
                       command history; see
Command History List
. notify
Equivalent to
-b
."
1349,31,set,"notify
Equivalent to
-b
. nounset
Equivalent to
-u
. verbose
Equivalent to
-v
."
1349,32,set,"verbose
Equivalent to
-v
. vi
Allow shell command line editing using the built-
                       in
vi
editor. Enabling
vi
mode shall disable any
                       other command line editing mode provided as an
                       implementation extension."
1349,33,set,"Enabling
vi
mode shall disable any
                       other command line editing mode provided as an
                       implementation extension. It need not be possible to set
vi
mode on for
                       certain block-mode terminals. xtrace
Equivalent to
-x
."
1349,34,set,"xtrace
Equivalent to
-x
. -u
When the shell tries to expand an unset parameter other than
             the
'@'
and
'*'
special parameters, it shall write a message
             to standard error and the expansion shall fail with the
             consequences specified in
Section 2.8.1
,
Consequences of
Shell Errors
. -v
The shell shall write its input to standard error as it is
             read."
1349,35,set,"-v
The shell shall write its input to standard error as it is
             read. -x
The shell shall write to standard error a trace for each
             command after it expands the command and before it executes
             it. It is unspecified whether the command that turns tracing
             off is traced."
1349,36,set,"It is unspecified whether the command that turns tracing
             off is traced. The default for all these options shall be off (unset) unless
       stated otherwise in the description of the option or unless the
       shell was invoked with them on; see
sh
. The remaining arguments shall be assigned in order to the
       positional parameters."
1349,37,set,"The remaining arguments shall be assigned in order to the
       positional parameters. The special parameter
'#'
shall be set to
       reflect the number of positional parameters. All positional
       parameters shall be unset before any new values are assigned."
1349,38,set,"All positional
       parameters shall be unset before any new values are assigned. If the first argument is
'-'
, the results are unspecified. The special argument
""--""
immediately following the
set
command
       name can be used to delimit the arguments if the first argument
       begins with
'+'
or
'-'
, or to prevent inadvertent listing of all
       shell variables when there are no arguments."
1349,39,set,"If the first argument is
'-'
, the results are unspecified. The special argument
""--""
immediately following the
set
command
       name can be used to delimit the arguments if the first argument
       begins with
'+'
or
'-'
, or to prevent inadvertent listing of all
       shell variables when there are no arguments. The command
set
--
without
argument
shall unset all positional parameters and set the
       special parameter
'#'
to zero."
1350,0,setpriv,"Sets or queries various Linux privilege settings that are
       inherited across
execve(2)
.

       In comparison to
su(1)
and
runuser(1)
,
setpriv
neither uses PAM,
       nor does it prompt for a password. It is a simple, non-set-user-ID
       wrapper around
execve(2)
, and can be used to drop privileges in
       the same way as
setuidgid
(8) from
daemontools
,
chpst
(8) from
runit
, or similar tools shipped by other service managers."
1351,0,setsid,"setsid
runs a program in a new session. The command calls
fork(2)
if already a process group leader. Otherwise, it executes a
       program in the current process."
1351,1,setsid,"The command calls
fork(2)
if already a process group leader. Otherwise, it executes a
       program in the current process. This default behavior is possible
       to override by the
--fork
option."
1352,0,sftp,"sftp
is a file transfer program, similar to
ftp
(1), which performs
       all operations over an encrypted
ssh
(1) transport. It may also
       use many features of ssh, such as public key authentication and
       compression. The
destination
may be specified either as [user@]host[:path] or
       as a URI in the form sftp://[user@]host[:port][/path]."
1352,1,sftp,"The
destination
may be specified either as [user@]host[:path] or
       as a URI in the form sftp://[user@]host[:port][/path]. If the
destination
includes a
path
and it is not a directory,
sftp
will retrieve files automatically if a non-interactive
       authentication method is used; otherwise it will do so after
       successful interactive authentication. If no
path
is specified, or if the
path
is a directory,
sftp
will
       log in to the specified
host
and enter interactive command mode,
       changing to the remote directory if one was specified."
1352,2,sftp,"If no
path
is specified, or if the
path
is a directory,
sftp
will
       log in to the specified
host
and enter interactive command mode,
       changing to the remote directory if one was specified. An
       optional trailing slash can be used to force the
path
to be
       interpreted as a directory. Since the destination formats use colon characters to delimit host
       names from path names or port numbers, IPv6 addresses must be
       enclosed in square brackets to avoid ambiguity."
1352,3,sftp,"Since the destination formats use colon characters to delimit host
       names from path names or port numbers, IPv6 addresses must be
       enclosed in square brackets to avoid ambiguity. The options are as follows:
-4
Forces
sftp
to use IPv4 addresses only. -6
Forces
sftp
to use IPv6 addresses only."
1352,4,sftp,"-6
Forces
sftp
to use IPv6 addresses only. -A
Allows forwarding of
ssh-agent
(1) to the remote system. The default is not to forward an authentication agent."
1352,5,sftp,"The default is not to forward an authentication agent. -a
Attempt to continue interrupted transfers rather than
               overwriting existing partial or complete copies of files. If the partial contents differ from those being
               transferred, then the resultant file is likely to be
               corrupt."
1352,6,sftp,"If the partial contents differ from those being
               transferred, then the resultant file is likely to be
               corrupt. -B
buffer_size
Specify the size of the buffer that
sftp
uses when
               transferring files. Larger buffers require fewer round
               trips at the cost of higher memory consumption."
1352,7,sftp,"Larger buffers require fewer round
               trips at the cost of higher memory consumption. The
               default is 32768 bytes. -b
batchfile
Batch mode reads a series of commands from an input
batchfile
instead of
stdin
."
1352,8,sftp,"-b
batchfile
Batch mode reads a series of commands from an input
batchfile
instead of
stdin
. Since it lacks user
               interaction, it should be used in conjunction with non-
               interactive authentication to obviate the need to enter a
               password at connection time (see
sshd
(8) and
ssh-keygen
(1)
               for details). A
batchfile
of â-â may be used to indicate standard input."
1352,9,sftp,"A
batchfile
of â-â may be used to indicate standard input. sftp
will abort if any of the following commands fail:
get
,
put
,
reget
,
reput
,
rename
,
ln
,
rm
,
mkdir
,
chdir
,
ls
,
lchdir
,
copy
,
cp
,
chmod
,
chown
,
chgrp
,
lpwd
,
df
,
symlink
,
               and
lmkdir
. Termination on error can be suppressed on a command by
               command basis by prefixing the command with a â-â
               character (for example,
-rm /tmp/blah*
)."
1352,10,sftp,"Termination on error can be suppressed on a command by
               command basis by prefixing the command with a â-â
               character (for example,
-rm /tmp/blah*
). Echo of the
               command may be suppressed by prefixing the command with a
               â@â character. These two prefixes may be combined in any
               order, for example
-@ls /bsd
."
1352,11,sftp,"These two prefixes may be combined in any
               order, for example
-@ls /bsd
. -C
Enables compression (via ssh's
-C
flag). -c
cipher
Selects the cipher to use for encrypting the data
               transfers."
1352,12,sftp,"-c
cipher
Selects the cipher to use for encrypting the data
               transfers. This option is directly passed to
ssh
(1). -D
sftp_server_command
Connect directly to a local sftp server (rather than via
ssh
(1))."
1352,13,sftp,"-D
sftp_server_command
Connect directly to a local sftp server (rather than via
ssh
(1)). A command and arguments may be specified, for
               example ""/path/sftp-server -el debug3"". This option may
               be useful in debugging the client and server."
1352,14,sftp,"This option may
               be useful in debugging the client and server. -F
ssh_config
Specifies an alternative per-user configuration file for
ssh
(1). This option is directly passed to
ssh
(1)."
1352,15,sftp,"This option is directly passed to
ssh
(1). -f
Requests that files be flushed to disk immediately after
               transfer. When uploading files, this feature is only
               enabled if the server implements the ""fsync@openssh.com""
               extension."
1352,16,sftp,"When uploading files, this feature is only
               enabled if the server implements the ""fsync@openssh.com""
               extension. -i
identity_file
Selects the file from which the identity (private key) for
               public key authentication is read. This option is
               directly passed to
ssh
(1)."
1352,17,sftp,"This option is
               directly passed to
ssh
(1). -J
destination
Connect to the target host by first making an
sftp
connection to the jump host described by
destination
and
               then establishing a TCP forwarding to the ultimate
               destination from there. Multiple jump hops may be
               specified separated by comma characters."
1352,18,sftp,"Multiple jump hops may be
               specified separated by comma characters. This is a
               shortcut to specify a
ProxyJump
configuration directive. This option is directly passed to
ssh
(1)."
1352,19,sftp,"This option is directly passed to
ssh
(1). -l
limit
Limits the used bandwidth, specified in Kbit/s. -N
Disables quiet mode, e.g."
1352,20,sftp,"-N
Disables quiet mode, e.g. to override the implicit quiet
               mode set by the
-b
flag. -o
ssh_option
Can be used to pass options to
ssh
in the format used in
ssh_config
(5)."
1352,21,sftp,"-o
ssh_option
Can be used to pass options to
ssh
in the format used in
ssh_config
(5). This is useful for specifying options for
               which there is no separate
sftp
command-line flag. For
               example, to specify an alternate port use:
sftp -oPort=24
."
1352,22,sftp,"For
               example, to specify an alternate port use:
sftp -oPort=24
. For full details of the options listed below, and their
               possible values, see
ssh_config
(5). AddressFamily
                     BatchMode
                     BindAddress
                     BindInterface
                     CanonicalDomains
                     CanonicalizeFallbackLocal
                     CanonicalizeHostname
                     CanonicalizeMaxDots
                     CanonicalizePermittedCNAMEs
                     CASignatureAlgorithms
                     CertificateFile
                     CheckHostIP
                     Ciphers
                     Compression
                     ConnectionAttempts
                     ConnectTimeout
                     ControlMaster
                     ControlPath
                     ControlPersist
                     GlobalKnownHostsFile
                     GSSAPIAuthentication
                     GSSAPIDelegateCredentials
                     HashKnownHosts
                     Host
                     HostbasedAcceptedAlgorithms
                     HostbasedAuthentication
                     HostKeyAlgorithms
                     HostKeyAlias
                     Hostname
                     IdentitiesOnly
                     IdentityAgent
                     IdentityFile
                     IPQoS
                     KbdInteractiveAuthentication
                     KbdInteractiveDevices
                     KexAlgorithms
                     KnownHostsCommand
                     LogLevel
                     MACs
                     NoHostAuthenticationForLocalhost
                     NumberOfPasswordPrompts
                     PasswordAuthentication
                     PKCS11Provider
                     Port
                     PreferredAuthentications
                     ProxyCommand
                     ProxyJump
                     PubkeyAcceptedAlgorithms
                     PubkeyAuthentication
                     RekeyLimit
                     RequiredRSASize
                     SendEnv
                     ServerAliveInterval
                     ServerAliveCountMax
                     SetEnv
                     StrictHostKeyChecking
                     TCPKeepAlive
                     UpdateHostKeys
                     User
                     UserKnownHostsFile
                     VerifyHostKeyDNS
-P
port
Specifies the port to connect to on the remote host."
1352,23,sftp,"AddressFamily
                     BatchMode
                     BindAddress
                     BindInterface
                     CanonicalDomains
                     CanonicalizeFallbackLocal
                     CanonicalizeHostname
                     CanonicalizeMaxDots
                     CanonicalizePermittedCNAMEs
                     CASignatureAlgorithms
                     CertificateFile
                     CheckHostIP
                     Ciphers
                     Compression
                     ConnectionAttempts
                     ConnectTimeout
                     ControlMaster
                     ControlPath
                     ControlPersist
                     GlobalKnownHostsFile
                     GSSAPIAuthentication
                     GSSAPIDelegateCredentials
                     HashKnownHosts
                     Host
                     HostbasedAcceptedAlgorithms
                     HostbasedAuthentication
                     HostKeyAlgorithms
                     HostKeyAlias
                     Hostname
                     IdentitiesOnly
                     IdentityAgent
                     IdentityFile
                     IPQoS
                     KbdInteractiveAuthentication
                     KbdInteractiveDevices
                     KexAlgorithms
                     KnownHostsCommand
                     LogLevel
                     MACs
                     NoHostAuthenticationForLocalhost
                     NumberOfPasswordPrompts
                     PasswordAuthentication
                     PKCS11Provider
                     Port
                     PreferredAuthentications
                     ProxyCommand
                     ProxyJump
                     PubkeyAcceptedAlgorithms
                     PubkeyAuthentication
                     RekeyLimit
                     RequiredRSASize
                     SendEnv
                     ServerAliveInterval
                     ServerAliveCountMax
                     SetEnv
                     StrictHostKeyChecking
                     TCPKeepAlive
                     UpdateHostKeys
                     User
                     UserKnownHostsFile
                     VerifyHostKeyDNS
-P
port
Specifies the port to connect to on the remote host. -p
Preserves modification times, access times, and modes from
               the original files transferred. -q
Quiet mode: disables the progress meter as well as warning
               and diagnostic messages from
ssh
(1)."
1352,24,sftp,"-q
Quiet mode: disables the progress meter as well as warning
               and diagnostic messages from
ssh
(1). -R
num_requests
Specify how many requests may be outstanding at any one
               time. Increasing this may slightly improve file transfer
               speed but will increase memory usage."
1352,25,sftp,"Increasing this may slightly improve file transfer
               speed but will increase memory usage. The default is 64
               outstanding requests. -r
Recursively copy entire directories when uploading and
               downloading."
1352,26,sftp,"-r
Recursively copy entire directories when uploading and
               downloading. Note that
sftp
does not follow symbolic
               links encountered in the tree traversal. -S
program
Name of the
program
to use for the encrypted connection."
1352,27,sftp,"-S
program
Name of the
program
to use for the encrypted connection. The program must understand
ssh
(1) options. -s
subsystem
|
sftp_server
Specifies the SSH2 subsystem or the path for an sftp
               server on the remote host."
1352,28,sftp,"-s
subsystem
|
sftp_server
Specifies the SSH2 subsystem or the path for an sftp
               server on the remote host. A path is useful when the
               remote
sshd
(8) does not have an sftp subsystem configured. -v
Raise logging level."
1352,29,sftp,"-v
Raise logging level. This option is also passed to ssh. -X
sftp_option
Specify an option that controls aspects of SFTP protocol
               behaviour."
1352,30,sftp,"-X
sftp_option
Specify an option that controls aspects of SFTP protocol
               behaviour. The valid options are:
nrequests
=
value
Controls how many concurrent SFTP read or write
                       requests may be in progress at any point in time
                       during a download or upload. By default 64
                       requests may be active concurrently."
1352,31,sftp,"By default 64
                       requests may be active concurrently. buffer
=
value
Controls the maximum buffer size for a single SFTP
                       read/write operation used during download or
                       upload. By default a 32KB buffer is used."
1353,0,setterm,"setterm
writes to standard output a character string that will
       invoke the specified terminal capabilities. Where possible
terminfo
is consulted to find the string to use. Some options
       however (marked ""virtual consoles only"" below) do not correspond
       to a
terminfo(5)
capability."
1353,1,setterm,"Some options
       however (marked ""virtual consoles only"" below) do not correspond
       to a
terminfo(5)
capability. In this case, if the terminal type is
       ""con"" or ""linux"" the string that invokes the specified
       capabilities on the PC Minix virtual console driver is output. Options that are not implemented by the terminal are ignored."
1354,0,sg,"The
sg
command works similar to
newgrp
but accepts a command. The
       command will be executed with the /bin/sh shell. With most shells
       you may run
sg
from, you need to enclose multi-word commands in
       quotes."
1354,1,sg,"With most shells
       you may run
sg
from, you need to enclose multi-word commands in
       quotes. Another difference between
newgrp
and
sg
is that some
       shells treat
newgrp
specially, replacing themselves with a new
       instance of a shell that
newgrp
creates. This doesn't happen with
sg
, so upon exit from a
sg
command you are returned to your
       previous group ID."
1355,0,sha224sum,"Print or check SHA224 (224-bit) checksums. With no FILE, or when FILE is -, read standard input. -b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in RFC 3874."
1355,1,sha224sum,"-b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in RFC 3874. When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE."
1355,2,sha224sum,"When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE. There is no difference between binary mode and text mode on GNU
       systems."
1356,0,sha256sum,"Print or check SHA256 (256-bit) checksums. With no FILE, or when FILE is -, read standard input. -b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in FIPS-180-2."
1356,1,sha256sum,"-b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in FIPS-180-2. When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE."
1356,2,sha256sum,"When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE. There is no difference between binary mode and text mode on GNU
       systems."
1357,0,sha1sum,"Print or check SHA1 (160-bit) checksums. With no FILE, or when FILE is -, read standard input. -b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in FIPS-180-1."
1357,1,sha1sum,"-b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in FIPS-180-1. When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE."
1357,2,sha1sum,"When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE. There is no difference between binary mode and text mode on GNU
       systems."
1358,0,sha384sum,"Print or check SHA384 (384-bit) checksums. With no FILE, or when FILE is -, read standard input. -b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in FIPS-180-2."
1358,1,sha384sum,"-b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in FIPS-180-2. When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE."
1358,2,sha384sum,"When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE. There is no difference between binary mode and text mode on GNU
       systems."
1359,0,sha512sum,"Print or check SHA512 (512-bit) checksums. With no FILE, or when FILE is -, read standard input. -b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in FIPS-180-2."
1359,1,sha512sum,"-b
,
--binary
read in binary mode
-c
,
--check
read checksums from the FILEs and check them
--tag
create a BSD-style checksum
-t
,
--text
read in text mode (default)
-z
,
--zero
end each output line with NUL, not newline, and disable
              file name escaping
The following five options are useful only when verifying checksums:
--ignore-missing
don't fail or report status for missing files
--quiet
don't print OK for each successfully verified file
--status
don't output anything, status code shows success
--strict
exit non-zero for improperly formatted checksum lines
-w
,
--warn
warn about improperly formatted checksum lines
--help
display this help and exit
--version
output version information and exit

       The sums are computed as described in FIPS-180-2. When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE."
1359,2,sha512sum,"When checking,
       the input should be a former output of this program. The default
       mode is to print a line with: checksum, a space, a character
       indicating input mode ('*' for binary, ' ' for text or where
       binary is insignificant), and name for each FILE. There is no difference between binary mode and text mode on GNU
       systems."
1360,0,sheet2pcp,"sheet2pcp
is intended to read a data spreadsheet (
infile
)
       translate this into a Performance Co-Pilot (PCP) archive with the
       basename
outfile
. The input spreadsheet can be in any of the common formats,
       provided the appropriate Perl modules have been installed (see the
CAVEATS
section below). The spreadsheet must be ``normalized'' so
       that each row contains data for the same time interval, and one of
       the columns contains the date and time for the data in each row."
1360,1,sheet2pcp,"The spreadsheet must be ``normalized'' so
       that each row contains data for the same time interval, and one of
       the columns contains the date and time for the data in each row. The resultant PCP archive may be used with all the PCP client
       tools to graph subsets of the data using
pmchart(1)
, perform data
       reduction and reporting, filter with the PCP inference engine
pmie(1)
, etc. The
mapfile
controls the import process and defines the data
       mapping from the spreadsheet columns onto the PCP data model."
1360,2,sheet2pcp,"The
mapfile
controls the import process and defines the data
       mapping from the spreadsheet columns onto the PCP data model. The
       file is written in XML and conforms to the syntax defined in the
MAPPING CONFIGURATION
section below. A series of physical files will be created with the prefix
outfile
."
1360,3,sheet2pcp,"A series of physical files will be created with the prefix
outfile
. These are
outfile
.0
(the performance data),
outfile
.meta
(the metadata that describes the performance data) and
outfile
.index
(a temporal index to improve efficiency of replay
       operations for the archive). If any of these files exists
       already, then
sheet2pcp
will
not
overwrite them and will exit with
       an error message."
1360,4,sheet2pcp,"If any of these files exists
       already, then
sheet2pcp
will
not
overwrite them and will exit with
       an error message. The
-h
option is an alternate to the
hostname
attribute of the
<sheet>
element in
mapfile
described below. If both are
       specified, the value from
mapfile
is used."
1360,5,sheet2pcp,"If both are
       specified, the value from
mapfile
is used. The
-V
option specifies the version for the output PCP archive. By default the archive version
$PCP_ARCHIVE_VERSION
(set to 3 in
       current PCP releases) is used, and the only values currently
       supported for
version
are 2 or 3."
1360,6,sheet2pcp,"By default the archive version
$PCP_ARCHIVE_VERSION
(set to 3 in
       current PCP releases) is used, and the only values currently
       supported for
version
are 2 or 3. The
-Z
option is an alternate to the
timezone
attribute of the
<sheet>
element in
mapfile
described below. If both are
       specified, the value from
mapfile
is used."
1360,7,sheet2pcp,"The
-Z
option is an alternate to the
timezone
attribute of the
<sheet>
element in
mapfile
described below. If both are
       specified, the value from
mapfile
is used. sheet2pcp
is a Perl script that uses the PCP::LogImport Perl
       wrapper around the PCP
libpcp_import
library, and as such could be
       used as an example to develop new tools to import other types of
       performance data and create PCP archives."
1361,0,sh,"The
sh
utility is a command language interpreter that shall
       execute commands read from a command line string, the standard
       input, or a specified file. The application shall ensure that the
       commands to be executed are expressed in the language described in
Chapter 2
,
Shell Command Language
. Pathname expansion shall not fail due to the size of a file."
1361,1,sh,"The application shall ensure that the
       commands to be executed are expressed in the language described in
Chapter 2
,
Shell Command Language
. Pathname expansion shall not fail due to the size of a file. Shell input and output redirections have an implementation-defined
       offset maximum that is established in the open file description."
1362,0,shift,"The positional parameters shall be shifted. Positional parameter 1
       shall be assigned the value of parameter (1+
n
), parameter 2 shall
       be assigned the value of parameter (2+
n
), and so on. The
       parameters represented by the numbers
""$#""
down to
""$#-n+1""
shall
       be unset, and the parameter
'#'
is updated to reflect the new
       number of positional parameters."
1362,1,shift,"The
       parameters represented by the numbers
""$#""
down to
""$#-n+1""
shall
       be unset, and the parameter
'#'
is updated to reflect the new
       number of positional parameters. The value
n
shall be an unsigned decimal integer less than or
       equal to the value of the special parameter
'#'
. If
n
is not
       given, it shall be assumed to be 1."
1362,2,shift,"The value
n
shall be an unsigned decimal integer less than or
       equal to the value of the special parameter
'#'
. If
n
is not
       given, it shall be assumed to be 1. If
n
is 0, the positional and
       special parameters are not changed."
1363,0,show-changed-rco,"show-changed-rco
gives a compact description of the changes to a
       packages Requires, Conflicts and Obsoletes data from the installed
       (or old) to a specified rpm file."
1364,0,show-installed,"show-installed
gives a compact description of the packages
       installed (or given) making use of the comps groups found in the
       repositories."
1365,0,shuf,"Write a random permutation of the input lines to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
1365,1,shuf,"With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too. -e
,
--echo
treat each ARG as an input line
-i
,
--input-range
=
LO-HI
treat each number LO through HI as an input line
-n
,
--head-count
=
COUNT
output at most COUNT lines
-o
,
--output
=
FILE
write result to FILE instead of standard output
--random-source
=
FILE
get random bytes from FILE
-r
,
--repeat
output lines can be repeated
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit"
1366,0,showkey,"showkey
prints to standard output either the scan codes or the
       keycode or the `ascii' code of each key pressed. In the first two
       modes the program runs until 10 seconds have elapsed since the
       last key press or release event, or until it receives a suitable
       signal, like SIGTERM, from another process. In `ascii' mode the
       program terminates when the user types ^D."
1366,1,showkey,"In `ascii' mode the
       program terminates when the user types ^D. When in scancode dump mode,
showkey
prints in hexadecimal format
       each byte received from the keyboard to the standard output. A new
       line is printed when an interval of about 0.1 seconds occurs
       between the bytes received, or when the internal receive buffer
       fills up."
1366,2,showkey,"A new
       line is printed when an interval of about 0.1 seconds occurs
       between the bytes received, or when the internal receive buffer
       fills up. This can be used to determine roughly, what byte
       sequences the keyboard sends at once on a given key press. The
       scan code dumping mode is primarily intended for debugging the
       keyboard driver or other low level interfaces."
1366,3,showkey,"The
       scan code dumping mode is primarily intended for debugging the
       keyboard driver or other low level interfaces. As such it
       shouldn't be of much interest to the regular end-user. However,
       some modern keyboards have keys or buttons that produce scancodes
       to which the kernel does not associate a keycode, and, after
       finding out what these are, the user can assign keycodes with
setkeycodes(8)
."
1366,4,showkey,"However,
       some modern keyboards have keys or buttons that produce scancodes
       to which the kernel does not associate a keycode, and, after
       finding out what these are, the user can assign keycodes with
setkeycodes(8)
. When in the default keycode dump mode,
showkey
prints to the
       standard output the keycode number or each key pressed or
       released. The kind of the event, press or release, is also
       reported."
1366,5,showkey,"The kind of the event, press or release, is also
       reported. Keycodes are numbers assigned by the kernel to each
       individual physical key. Every key has always only one associated
       keycode number, whether the keyboard sends single or multiple scan
       codes when pressing it."
1366,6,showkey,"Every key has always only one associated
       keycode number, whether the keyboard sends single or multiple scan
       codes when pressing it. Using
showkey
in this mode, you can find
       out what numbers to use in your personalized keymap files. When in `ascii' dump mode,
showkey
prints to the standard output
       the decimal, octal, and hexadecimal value(s) of the key pressed,
       according to he present keymap."
1367,0,shred,"Overwrite the specified FILE(s) repeatedly, in order to make it
       harder for even very expensive hardware probing to recover the
       data. If FILE is -, shred standard output. Mandatory arguments to long options are mandatory for short
       options too."
1367,1,shred,"Mandatory arguments to long options are mandatory for short
       options too. -f
,
--force
change permissions to allow writing if necessary
-n
,
--iterations
=
N
overwrite N times instead of the default (3)
--random-source
=
FILE
get random bytes from FILE
-s
,
--size
=
N
shred this many bytes (suffixes like K, M, G accepted)
-u
deallocate and remove file after overwriting
--remove
[=
HOW
]
              like
-u
but give control on HOW to delete;  See below
-v
,
--verbose
show progress
-x
,
--exact
do not round file sizes up to the next full block;

              this is the default for non-regular files
-z
,
--zero
add a final overwrite with zeros to hide shredding
--help
display this help and exit
--version
output version information and exit

       Delete FILE(s) if
--remove
(
-u
) is specified. The default is not
       to remove the files because it is common to operate on device
       files like
/dev/hda
, and those files usually should not be
       removed."
1367,2,shred,"The default is not
       to remove the files because it is common to operate on device
       files like
/dev/hda
, and those files usually should not be
       removed. The optional HOW parameter indicates how to remove a
       directory entry: 'unlink' => use a standard unlink call. 'wipe'
       => also first obfuscate bytes in the name."
1367,3,shred,"'wipe'
       => also first obfuscate bytes in the name. 'wipesync' => also
       sync each obfuscated byte to the device. The default mode is
       'wipesync', but note it can be expensive."
1367,4,shred,"The default mode is
       'wipesync', but note it can be expensive. CAUTION: shred assumes the file system and hardware overwrite data
       in place. Although this is common, many platforms operate
       otherwise."
1367,5,shred,"Although this is common, many platforms operate
       otherwise. Also, backups and mirrors may contain unremovable
       copies that will let a shredded file be recovered later. See the
       GNU coreutils manual for details."
1368,0,skill,"These tools are obsolete and unportable. The command syntax is
       poorly defined. Consider using the
killall
,
pkill
, and
pgrep
commands instead."
1368,1,skill,"Consider using the
killall
,
pkill
, and
pgrep
commands instead. The default signal for
skill
is TERM. Use
-l
or
-L
to list
       available signals."
1368,2,skill,"Use
-l
or
-L
to list
       available signals. Particularly useful signals include HUP, INT,
       KILL, STOP, CONT, and 0. Alternate signals may be specified in
       three ways:
-9 -SIGKILL -KILL
."
1368,3,skill,"Alternate signals may be specified in
       three ways:
-9 -SIGKILL -KILL
. The default priority for
snice
is +4. Priority numbers range from
       +20 (slowest) to -20 (fastest)."
1368,4,skill,"The default priority for
snice
is +4. Priority numbers range from
       +20 (slowest) to -20 (fastest). Negative priority numbers are
       restricted to administrative users."
1369,0,size,"The GNU
size
utility lists the section sizes and the total size
       for each of the binary files
objfile
on its argument list. By
       default, one line of output is generated for each file or each
       module if the file is an archive. objfile
..."
1369,1,size,"objfile
... are the files to be examined. If none are specified,
       the file ""a.out"" will be used instead."
1370,0,slabtop,"slabtop
displays detailed kernel slab cache information in real
       time.  It displays a listing of the top caches sorted by one of
       the listed sort criteria.  It also displays a statistics header
       filled with slab layer information."
1371,0,sleep,"Pause for NUMBER seconds, where NUMBER is an integer or
       floating-point. SUFFIX may be 's','m','h', or 'd', for seconds,
       minutes, hours, days. With multiple arguments, pause for the sum
       of their values."
1371,1,sleep,"SUFFIX may be 's','m','h', or 'd', for seconds,
       minutes, hours, days. With multiple arguments, pause for the sum
       of their values. --help
display this help and exit
--version
output version information and exit"
1372,0,sleep,"The
sleep
utility shall suspend execution for at least the
       integral number of seconds specified by the
time
operand."
1373,0,smtp,"The
smtp
utility is a Simple Mail Transfer Protocol (SMTP) client
       which can be used to run an SMTP transaction against an SMTP
       server. By default,
smtp
reads the mail content from the standard input,
       establishes an SMTP session, and runs an SMTP transaction for all
       the specified recipients. The content is sent unaltered as mail
       data."
1373,1,smtp,"The content is sent unaltered as mail
       data. The options are as follows:
-a
authfile
Perform a login before sending the message. The username
               and password are read from
authfile
and need to be on the
               first and second line respectively."
1373,2,smtp,"The username
               and password are read from
authfile
and need to be on the
               first and second line respectively. This option requires
               a TLS or STARTTLS
server
. -C
Do not require server certificate to be valid."
1373,3,smtp,"-C
Do not require server certificate to be valid. This flag
               is deprecated. Use â
-T noverify
â instead."
1373,4,smtp,"Use â
-T noverify
â instead. -F
from
Set the return-path (MAIL FROM) for the SMTP transaction. Default to the current username."
1373,5,smtp,"Default to the current username. -H
helo
Define the hostname to advertise (HELO) when establishing
               the SMTP session. -h
Display usage."
1373,6,smtp,"-h
Display usage. -n
Do not actually execute a transaction, just try to
               establish an SMTP session and quit. When this option is
               given, no message is read from the standard input."
1373,7,smtp,"When this option is
               given, no message is read from the standard input. -s
server
Specify the server to connect to and connection
               parameters. The format is
               [
proto
://[
user
:
pass
@]]
host
[:
port
]."
1373,8,smtp,"The format is
               [
proto
://[
user
:
pass
@]]
host
[:
port
]. The following
               protocols are available:

               smtp        Normal SMTP session with opportunistic
                           STARTTLS. smtp+tls    Normal SMTP session with mandatory STARTTLS."
1373,9,smtp,smtp+tls    Normal SMTP session with mandatory STARTTLS. smtp+notls  Plain text SMTP session without TLS. lmtp        LMTP session with opportunistic STARTTLS.
1373,10,smtp,lmtp        LMTP session with opportunistic STARTTLS. lmtp+tls    LMTP session with mandatory STARTTLS. lmtp+notls  Plain text LMTP session without TLS.
1373,11,smtp,lmtp+notls  Plain text LMTP session without TLS. smtps       SMTP session with forced TLS on connection. Defaults to âsmtp://localhost:25â.
1373,12,smtp,"Defaults to âsmtp://localhost:25â. -T
params
Set specific parameters for TLS sessions. The
params
string is a comma or space separated list of options."
1373,13,smtp,"The
params
string is a comma or space separated list of options. The
               available options are:
cafile
=
filename
Use
filename
as root certificates file instead of
                       the system default. ciphers
=
value
Specify the allowed ciphers."
1373,14,smtp,"ciphers
=
value
Specify the allowed ciphers. Refer to
tls_config_set_ciphers
(3) for
value
. nosni
Disable Server Name Indication (SNI)."
1373,15,smtp,"nosni
Disable Server Name Indication (SNI). noverify
Do not require server certificate to be valid. protocols
=
value
Specify the protocols to use."
1373,16,smtp,"protocols
=
value
Specify the protocols to use. Refer to
tls_config_parse_protocols
(3) for
value
. servername
=
value
Use
value
for Server Name Indication (SNI)."
1373,17,smtp,"servername
=
value
Use
value
for Server Name Indication (SNI). Defaults to the specified server hostname. -v
Be more verbose."
1373,18,smtp,"Defaults to the specified server hostname. -v
Be more verbose. This option can be specified multiple
               times."
1374,0,skill,"These tools are obsolete and unportable. The command syntax is
       poorly defined. Consider using the
killall
,
pkill
, and
pgrep
commands instead."
1374,1,skill,"Consider using the
killall
,
pkill
, and
pgrep
commands instead. The default signal for
skill
is TERM. Use
-l
or
-L
to list
       available signals."
1374,2,skill,"Use
-l
or
-L
to list
       available signals. Particularly useful signals include HUP, INT,
       KILL, STOP, CONT, and 0. Alternate signals may be specified in
       three ways:
-9 -SIGKILL -KILL
."
1374,3,skill,"Alternate signals may be specified in
       three ways:
-9 -SIGKILL -KILL
. The default priority for
snice
is +4. Priority numbers range from
       +20 (slowest) to -20 (fastest)."
1374,4,skill,"The default priority for
snice
is +4. Priority numbers range from
       +20 (slowest) to -20 (fastest). Negative priority numbers are
       restricted to administrative users."
1375,0,sort,"Write sorted concatenation of all FILE(s) to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
1375,1,sort,"Mandatory arguments to long options are mandatory for short
       options too. Ordering options:
-b
,
--ignore-leading-blanks
ignore leading blanks
-d
,
--dictionary-order
consider only blanks and alphanumeric characters
-f
,
--ignore-case
fold lower case to upper case characters
-g
,
--general-numeric-sort
compare according to general numerical value
-i
,
--ignore-nonprinting
consider only printable characters
-M
,
--month-sort
compare (unknown) < 'JAN' < ... < 'DEC'
-h
,
--human-numeric-sort
compare human readable numbers (e.g., 2K 1G)
-n
,
--numeric-sort
compare according to string numerical value; see full
              documentation for supported strings
-R
,
--random-sort
shuffle, but group identical keys."
1375,2,sort,"< 'DEC'
-h
,
--human-numeric-sort
compare human readable numbers (e.g., 2K 1G)
-n
,
--numeric-sort
compare according to string numerical value; see full
              documentation for supported strings
-R
,
--random-sort
shuffle, but group identical keys. See
shuf(1)
--random-source
=
FILE
get random bytes from FILE
-r
,
--reverse
reverse the result of comparisons
--sort
=
WORD
sort according to WORD: general-numeric
-g
, human-numeric
-h
, month
-M
, numeric
-n
, random
-R
, version
-V
-V
,
--version-sort
natural sort of (version) numbers within text

       Other options:
--batch-size
=
NMERGE
merge at most NMERGE inputs at once; for more use temp
              files
-c
,
--check
,
--check
=
diagnose-first
check for sorted input; do not sort
-C
,
--check
=
quiet
,
--check
=
silent
like
-c
, but do not report first bad line
--compress-program
=
PROG
compress temporaries with PROG; decompress them with PROG
-d
--debug
annotate the part of the line used to sort, and warn about
              questionable usage to stderr
--files0-from
=
F
read input from the files specified by NUL-terminated names
              in file F; If F is - then read names from standard input
-k
,
--key
=
KEYDEF
sort via a key; KEYDEF gives location and type
-m
,
--merge
merge already sorted files; do not sort
-o
,
--output
=
FILE
write result to FILE instead of standard output
-s
,
--stable
stabilize sort by disabling last-resort comparison
-S
,
--buffer-size
=
SIZE
use SIZE for main memory buffer
-t
,
--field-separator
=
SEP
use SEP instead of non-blank to blank transition
-T
,
--temporary-directory
=
DIR
use DIR for temporaries, not $TMPDIR or
/tmp
; multiple
              options specify multiple directories
--parallel
=
N
change the number of sorts run concurrently to N
-u
,
--unique
with
-c
, check for strict ordering; without
-c
, output only
              the first of an equal run
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit

       KEYDEF is F[.C][OPTS][,F[.C][OPTS]] for start and stop position,
       where F is a field number and C a character position in the field;
       both are origin 1, and the stop position defaults to the line's
       end. If neither
-t
nor
-b
is in effect, characters in a field are
       counted from the beginning of the preceding whitespace."
1375,3,sort,"If neither
-t
nor
-b
is in effect, characters in a field are
       counted from the beginning of the preceding whitespace. OPTS is
       one or more single-letter ordering options [bdfgiMhnRrV], which
       override global ordering options for that key. If no key is
       given, use the entire line as the key."
1375,4,sort,"If no key is
       given, use the entire line as the key. Use
--debug
to diagnose
       incorrect key usage. SIZE may be followed by the following multiplicative suffixes: %
       1% of memory, b 1, K 1024 (default), and so on for M, G, T, P, E,
       Z, Y, R, Q."
1375,5,sort,"SIZE may be followed by the following multiplicative suffixes: %
       1% of memory, b 1, K 1024 (default), and so on for M, G, T, P, E,
       Z, Y, R, Q. *** WARNING *** The locale specified by the environment affects
       sort order. Set LC_ALL=C to get the traditional sort order that
       uses native byte values."
1376,0,sortman,"The
sortman
command sorts manual-page path names in the order that
       they should appear in the manual.

       The chapters and subchapters are first sorted.  Then, within each
       (sub)chapter, the first page is the corresponding
intro
(*) page,
       and the rest are sorted alphabetically (but treating specially
       some special characters)."
1377,0,soelim,nan
1378,0,sparse,"Sparse parses C source and looks for errors, producing warnings on
       standard error. Sparse accepts options controlling the set of warnings to
       generate. To turn on warnings Sparse does not issue by default,
       use the corresponding warning option
-Wsomething
."
1378,1,sparse,"Sparse accepts options controlling the set of warnings to
       generate. To turn on warnings Sparse does not issue by default,
       use the corresponding warning option
-Wsomething
. Sparse issues
       some warnings by default; to turn off those warnings, pass the
       negation of the associated warning option,
-Wno-something
."
1379,0,sort,"The
sort
utility shall perform one of the following functions:

        1. Sort lines of all the named files together and write the
           result to the specified output. 2."
1379,1,sort,"2. Merge lines of all the named (presorted) files together and
           write the result to the specified output. 3."
1379,2,sort,"3. Check that a single input file is correctly presorted. Comparisons shall be based on one or more sort keys extracted from
       each line of input (or, if no sort keys are specified, the entire
       line up to, but not including, the terminating <newline>), and
       shall be performed using the collating sequence of the current
       locale."
1379,3,sort,"Check that a single input file is correctly presorted. Comparisons shall be based on one or more sort keys extracted from
       each line of input (or, if no sort keys are specified, the entire
       line up to, but not including, the terminating <newline>), and
       shall be performed using the collating sequence of the current
       locale. If this collating sequence does not have a total ordering
       of all characters (see the Base Definitions volume of
       POSIX.1â2017,
Section 7.3.2
,
LC_COLLATE
), any lines of input that
       collate equally should be further compared byte-by-byte using the
       collating sequence for the POSIX locale."
1380,0,split,"Output pieces of FILE to PREFIXaa, PREFIXab, ...; default size is
       1000 lines, and default PREFIX is 'x'. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
1380,1,split,"Mandatory arguments to long options are mandatory for short
       options too. -a
,
--suffix-length
=
N
generate suffixes of length N (default 2)
--additional-suffix
=
SUFFIX
append an additional SUFFIX to file names
-b
,
--bytes
=
SIZE
put SIZE bytes per output file
-C
,
--line-bytes
=
SIZE
put at most SIZE bytes of records per output file
-d
use numeric suffixes starting at 0, not alphabetic
--numeric-suffixes
[=
FROM
]
              same as
-d
, but allow setting the start value
-x
use hex suffixes starting at 0, not alphabetic
--hex-suffixes
[=
FROM
]
              same as
-x
, but allow setting the start value
-e
,
--elide-empty-files
do not generate empty output files with '-n'
--filter
=
COMMAND
write to shell COMMAND; file name is $FILE
-l
,
--lines
=
NUMBER
put NUMBER lines/records per output file
-n
,
--number
=
CHUNKS
generate CHUNKS output files; see explanation below
-t
,
--separator
=
SEP
use SEP instead of newline as the record separator; '\0'
              (zero) specifies the NUL character
-u
,
--unbuffered
immediately copy input to output with '-n r/...'
--verbose
print a diagnostic just before each output file is opened
--help
display this help and exit
--version
output version information and exit

       The SIZE argument is an integer and optional unit (example: 10K is
       10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,..."
1380,2,split,"Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,... (powers of 1000). Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on."
1380,3,split,"(powers of 1000). Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on. CHUNKS may be:
N      split into N files based on size of input

       K/N    output Kth of N to stdout

       l/N    split into N files without splitting lines/records

       l/K/N  output Kth of N to stdout without splitting lines/records

       r/N    like 'l' but use round robin distribution

       r/K/N  likewise but only output Kth of N to stdout"
1381,0,split,"The
split
utility shall read an input file and write zero or more
       output files. The default size of each output file shall be 1000
       lines. The size of the output files can be modified by
       specification of the
-b
or
-l
options."
1381,1,split,"The size of the output files can be modified by
       specification of the
-b
or
-l
options. Each output file shall be
       created with a unique suffix. The suffix shall consist of exactly
suffix_length
lowercase letters from the POSIX locale."
1381,2,split,"The suffix shall consist of exactly
suffix_length
lowercase letters from the POSIX locale. The letters
       of the suffix shall be used as if they were a base-26 digit
       system, with the first suffix to be created consisting of all
'a'
characters, the second with a
'b'
replacing the last
'a'
, and so
       on, until a name of all
'z'
characters is created. By default, the
       names of the output files shall be
'x'
, followed by a two-
       character suffix from the character set as described above,
       starting with
""aa""
,
""ab""
,
""ac""
, and so on, and continuing until
       the suffix
""zz""
, for a maximum of 676 files."
1381,3,split,"By default, the
       names of the output files shall be
'x'
, followed by a two-
       character suffix from the character set as described above,
       starting with
""aa""
,
""ab""
,
""ac""
, and so on, and continuing until
       the suffix
""zz""
, for a maximum of 676 files. If the number of files required exceeds the maximum allowed by the
       suffix length provided, such that the last allowable file would be
       larger than the requested size, the
split
utility shall fail after
       creating the last file with a valid suffix;
split
shall not delete
       the files it created with valid suffixes. If the file limit is not
       exceeded, the last file created shall contain the remainder of the
       input file, and may be smaller than the requested size."
1381,4,split,"If the number of files required exceeds the maximum allowed by the
       suffix length provided, such that the last allowable file would be
       larger than the requested size, the
split
utility shall fail after
       creating the last file with a valid suffix;
split
shall not delete
       the files it created with valid suffixes. If the file limit is not
       exceeded, the last file created shall contain the remainder of the
       input file, and may be smaller than the requested size. If the
       input is an empty file, no output file shall be created and this
       shall not be considered to be an error."
1382,0,sprof,"The
sprof
command displays a profiling summary for the shared
       object (shared library) specified as its first command-line
       argument.  The profiling summary is created using previously
       generated profiling data in the (optional) second command-line
       argument.  If the profiling data pathname is omitted, then
sprof
will attempt to deduce it using the soname of the shared object,
       looking for a file with the name
<soname>.profile
in the current
       directory."
1383,0,srptool,"Simple program that emulates the programs in the Stanford SRP
       (Secure Remote Password) libraries using GnuTLS. It is intended
       for use in  places where you don't expect SRP authentication to be
       the used for system users. In  brief,  to use SRP you need to create two files."
1383,1,srptool,"It is intended
       for use in  places where you don't expect SRP authentication to be
       the used for system users. In  brief,  to use SRP you need to create two files. These are the
       password file that holds the users and the verifiers associated
       with  them  and  the configuration file to hold the group
       parameters (called tpasswd.conf)."
1384,0,sqlhist,"The sqlhist(1) will take an SQL like statement to create tracefs
       histograms and synthetic events that can perform various actions
       for various handling of the data. The tracefs file system interfaces with the Linux tracing
       infrastructure that has various dynamic and static events through
       out the kernel. Each of these events can have a ""histogram""
       attached to it, where the fields of the event will define the
       buckets of the histogram."
1384,1,sqlhist,"Each of these events can have a ""histogram""
       attached to it, where the fields of the event will define the
       buckets of the histogram. A synthetic event is a way to attach two separate events and use
       the fields and time stamps of those events to create a new dynamic
       event. This new dynamic event is call a synthetic event."
1384,2,sqlhist,"This new dynamic event is call a synthetic event. The
       fields of each event can have simple calculations done on them
       where, for example, the delta between a field of one event to a
       field of the other event can be taken. This also works for the
       time stamps of the events where the time delta between the two
       events can also be extracted and placed into the synthetic event."
1384,3,sqlhist,"This also works for the
       time stamps of the events where the time delta between the two
       events can also be extracted and placed into the synthetic event. Other actions can be done from the fields of the events. A
       snapshot can be taken of the kernel ring buffer a variable used in
       the synthetic event creating hits a max, or simply changes."
1384,4,sqlhist,"A
       snapshot can be taken of the kernel ring buffer a variable used in
       the synthetic event creating hits a max, or simply changes. The commands to create histograms and synthetic events are complex
       and not easy to remember. sqlhist
is used to convert SQL syntax
       into the commands needed to create the histogram or synthetic
       event."
1384,5,sqlhist,"sqlhist
is used to convert SQL syntax
       into the commands needed to create the histogram or synthetic
       event. The
SQL-select-command
is a SQL string defined by
tracefs_sql(3)
. Note, this must be run as root (or sudo) as interacting with the
       tracefs directory requires root privilege, unless the
-t
option is
       given with a copy of the
tracefs
directory and its events."
1384,6,sqlhist,"The
SQL-select-command
is a SQL string defined by
tracefs_sql(3)
. Note, this must be run as root (or sudo) as interacting with the
       tracefs directory requires root privilege, unless the
-t
option is
       given with a copy of the
tracefs
directory and its events. The
sqlhist
is a simple program where its code actual exists in
       the
tracefs_sql(3)
man page."
1385,0,ssh-agent,"ssh-agent
is a program to hold private keys used for public key
       authentication. Through use of environment variables the agent
       can be located and automatically used for authentication when
       logging in to other machines using
ssh
(1). The options are as follows:
-a
bind_address
Bind the agent to the Unix-domain socket
bind_address
."
1385,1,ssh-agent,"The options are as follows:
-a
bind_address
Bind the agent to the Unix-domain socket
bind_address
. The default is
$TMPDIR/ssh-XXXXXXXXXX/agent.<ppid>
. -c
Generate C-shell commands on stdout."
1385,2,ssh-agent,"-c
Generate C-shell commands on stdout. This is the default
               if SHELL looks like it's a csh style of shell. -D
Foreground mode."
1385,3,ssh-agent,"-D
Foreground mode. When this option is specified,
ssh-agent
will not fork. -d
Debug mode."
1385,4,ssh-agent,"-d
Debug mode. When this option is specified,
ssh-agent
will
               not fork and will write debug information to standard
               error. -E
fingerprint_hash
Specifies the hash algorithm used when displaying key
               fingerprints."
1385,5,ssh-agent,"-E
fingerprint_hash
Specifies the hash algorithm used when displaying key
               fingerprints. Valid options are: âmd5â and âsha256â. The
               default is âsha256â."
1385,6,ssh-agent,"The
               default is âsha256â. -k
Kill the current agent (given by the SSH_AGENT_PID
               environment variable). -O
option
Specify an option when starting
ssh-agent
."
1385,7,ssh-agent,"-O
option
Specify an option when starting
ssh-agent
. Currently two
               options are supported:
allow-remote-pkcs11
and
no-restrict-websafe
. The
allow-remote-pkcs11
option allows clients of a
               forwarded
ssh-agent
to load PKCS#11 or FIDO provider
               libraries."
1385,8,ssh-agent,"The
allow-remote-pkcs11
option allows clients of a
               forwarded
ssh-agent
to load PKCS#11 or FIDO provider
               libraries. By default only local clients may perform this
               operation. Note that signalling that an
ssh-agent
client
               is remote is performed by
ssh
(1), and use of other tools
               to forward access to the agent socket may circumvent this
               restriction."
1385,9,ssh-agent,"Note that signalling that an
ssh-agent
client
               is remote is performed by
ssh
(1), and use of other tools
               to forward access to the agent socket may circumvent this
               restriction. The
no-restrict-websafe
option instructs
ssh-agent
to
               permit signatures using FIDO keys that might be web
               authentication requests. By default,
ssh-agent
refuses
               signature requests for FIDO keys where the key application
               string does not start with âssh:â and when the data to be
               signed does not appear to be a
ssh
(1) user authentication
               request or a
ssh-keygen
(1) signature."
1385,10,ssh-agent,"By default,
ssh-agent
refuses
               signature requests for FIDO keys where the key application
               string does not start with âssh:â and when the data to be
               signed does not appear to be a
ssh
(1) user authentication
               request or a
ssh-keygen
(1) signature. The default
               behaviour prevents forwarded access to a FIDO key from
               also implicitly forwarding the ability to authenticate to
               websites. -P
allowed_providers
Specify a pattern-list of acceptable paths for PKCS#11
               provider and FIDO authenticator middleware shared
               libraries that may be used with the
-S
or
-s
options to
ssh-add
(1)."
1385,11,ssh-agent,"-P
allowed_providers
Specify a pattern-list of acceptable paths for PKCS#11
               provider and FIDO authenticator middleware shared
               libraries that may be used with the
-S
or
-s
options to
ssh-add
(1). Libraries that do not match the pattern list
               will be refused. See PATTERNS in
ssh_config
(5) for a
               description of pattern-list syntax."
1385,12,ssh-agent,"See PATTERNS in
ssh_config
(5) for a
               description of pattern-list syntax. The default list is
               âusr/lib*/*,/usr/local/lib*/*â. -s
Generate Bourne shell commands on stdout."
1385,13,ssh-agent,"-s
Generate Bourne shell commands on stdout. This is the
               default if SHELL does not look like it's a csh style of
               shell. -t
life
Set a default value for the maximum lifetime of identities
               added to the agent."
1385,14,ssh-agent,"-t
life
Set a default value for the maximum lifetime of identities
               added to the agent. The lifetime may be specified in
               seconds or in a time format specified in
sshd_config
(5). A lifetime specified for an identity with
ssh-add
(1)
               overrides this value."
1385,15,ssh-agent,"A lifetime specified for an identity with
ssh-add
(1)
               overrides this value. Without this option the default
               maximum lifetime is forever. command
[
arg ..."
1385,16,ssh-agent,"command
[
arg ... ]
               If a command (and optional arguments) is given, this is
               executed as a subprocess of the agent. The agent exits
               automatically when the command given on the command line
               terminates."
1385,17,ssh-agent,"The agent exits
               automatically when the command given on the command line
               terminates. There are two main ways to get an agent set up. The first is at
       the start of an X session, where all other windows or programs are
       started as children of the
ssh-agent
program."
1385,18,ssh-agent,"The first is at
       the start of an X session, where all other windows or programs are
       started as children of the
ssh-agent
program. The agent starts a
       command under which its environment variables are exported, for
       example
ssh-agent xterm &
. When the command terminates, so does
       the agent."
1385,19,ssh-agent,"When the command terminates, so does
       the agent. The second method is used for a login session. When
ssh-agent
is
       started, it prints the shell commands required to set its
       environment variables, which in turn can be evaluated in the
       calling shell, for example
eval `ssh-agent -s`
."
1385,20,ssh-agent,"When
ssh-agent
is
       started, it prints the shell commands required to set its
       environment variables, which in turn can be evaluated in the
       calling shell, for example
eval `ssh-agent -s`
. In both cases,
ssh
(1) looks at these environment variables and
       uses them to establish a connection to the agent. The agent initially does not have any private keys."
1385,21,ssh-agent,"The agent initially does not have any private keys. Keys are
       added using
ssh-add
(1) or by
ssh
(1) when
AddKeysToAgent
is set in
ssh_config
(5). Multiple identities may be stored in
ssh-agent
concurrently and
ssh
(1) will automatically use them if present."
1385,22,ssh-agent,"Multiple identities may be stored in
ssh-agent
concurrently and
ssh
(1) will automatically use them if present. ssh-add
(1) is also used to remove keys from
ssh-agent
and to query
       the keys that are held in one. Connections to
ssh-agent
may be forwarded from further remote
       hosts using the
-A
option to
ssh
(1) (but see the caveats
       documented therein), avoiding the need for authentication data to
       be stored on other machines."
1385,23,ssh-agent,"ssh-add
(1) is also used to remove keys from
ssh-agent
and to query
       the keys that are held in one. Connections to
ssh-agent
may be forwarded from further remote
       hosts using the
-A
option to
ssh
(1) (but see the caveats
       documented therein), avoiding the need for authentication data to
       be stored on other machines. Authentication passphrases and
       private keys never go over the network: the connection to the
       agent is forwarded over SSH remote connections and the result is
       returned to the requester, allowing the user access to their
       identities anywhere in the network in a secure fashion."
1386,0,ssh-copy-id,"ssh-copy-id
is a script that uses
ssh
(1) to log into a remote
       machine (presumably using a login password, so password
       authentication should be enabled, unless you've done some clever
       use of multiple identities). It assembles a list of one or more
       fingerprints (as described below) and tries to log in with each
       key, to see if any of them are already installed (of course, if
       you are not using
ssh-agent
(1) this may result in you being
       repeatedly prompted for pass-phrases). It then assembles a list
       of those that failed to log in and, using
ssh
(1), enables logins
       with those keys on the remote server."
1386,1,ssh-copy-id,"It then assembles a list
       of those that failed to log in and, using
ssh
(1), enables logins
       with those keys on the remote server. By default it adds the keys
       by appending them to the remote user's
~/.ssh/authorized_keys
(creating the file, and directory, if necessary). It is also
       capable of detecting if the remote system is a NetScreen, and
       using its âset ssh pka-dsa key ...â command instead."
1386,2,ssh-copy-id,"It is also
       capable of detecting if the remote system is a NetScreen, and
       using its âset ssh pka-dsa key ...â command instead. The options are as follows:
-i
[
identity_file
]
               Use only the key(s) contained in
identity_file
(rather
               than looking for identities via
ssh-add
(1) or in the
default_ID_file
). If the filename does not end in
.pub
this is added."
1386,3,ssh-copy-id,"If the filename does not end in
.pub
this is added. If the filename is omitted, the
default_ID_file
is used. Note that this can be used to ensure that the keys copied
               have the comment one prefers and/or extra options applied,
               by ensuring that the key file has these set as preferred
               before the copy is attempted."
1386,4,ssh-copy-id,"Note that this can be used to ensure that the keys copied
               have the comment one prefers and/or extra options applied,
               by ensuring that the key file has these set as preferred
               before the copy is attempted. -f
Forced mode: doesn't check if the keys are present on the
               remote server. This means that it does not need the
               private key."
1386,5,ssh-copy-id,"This means that it does not need the
               private key. Of course, this can result in more than one
               copy of the key being installed on the remote system. -n
do a dry-run."
1386,6,ssh-copy-id,"-n
do a dry-run. Instead of installing keys on the remote
               system simply prints the key(s) that would have been
               installed. -s
SFTP mode: usually the public keys are installed by
               executing commands on the remote side."
1386,7,ssh-copy-id,"-s
SFTP mode: usually the public keys are installed by
               executing commands on the remote side. With this option
               the user's
~/.ssh/authorized_keys
file will be downloaded,
               modified locally and uploaded with sftp. This option is
               useful if the server has restrictions on commands which
               can be used on the remote side."
1386,8,ssh-copy-id,"This option is
               useful if the server has restrictions on commands which
               can be used on the remote side. -t
target_path
the path on the target system where the keys should be
               added (defaults to "".ssh/authorized_keys"")
-p
port
Specifies the port to connect to on the remote host. -F
ssh_config
,
-o
ssh_option
These options are simply passed through untouched (with
               their argument) to ssh/sftp, allowing one to set an
               alternative config file, or other options, respectively."
1386,9,ssh-copy-id,"-F
ssh_config
,
-o
ssh_option
These options are simply passed through untouched (with
               their argument) to ssh/sftp, allowing one to set an
               alternative config file, or other options, respectively. Rather than specifying these as command line options, it
               is often better to use (per-host) settings in
ssh
(1)'s
               configuration file:
ssh_config
(5). -x
This option is for debugging the
ssh-copy-id
script
               itself."
1386,10,ssh-copy-id,"-x
This option is for debugging the
ssh-copy-id
script
               itself. It sets the shell's -x flag, so that you can see
               the commands being run. -h
,
-
?"
1386,11,ssh-copy-id,"-h
,
-
? Print Usage summary

       Default behaviour without
-i
, is to check if âssh-add -Lâ provides
       any output, and if so those keys are used. Note that this results
       in the comment on the key being the filename that was given to
ssh-add
(1) when the key was loaded into your
ssh-agent
(1) rather
       than the comment contained in that file, which is a bit of a
       shame."
1386,12,ssh-copy-id,"Note that this results
       in the comment on the key being the filename that was given to
ssh-add
(1) when the key was loaded into your
ssh-agent
(1) rather
       than the comment contained in that file, which is a bit of a
       shame. Otherwise, if
ssh-add
(1) provides no keys contents of the
default_ID_file
will be used. The
default_ID_file
is the most recent file that matches:
~/.ssh/id*.pub
, (excluding those that match
~/.ssh/*-cert.pub
) so
       if you create a key that is not the one you want
ssh-copy-id
to
       use, just use
touch
(1) on your preferred key's
.pub
file to
       reinstate it as the most recent."
1387,0,ssh-add,"ssh-add
adds private key identities to the authentication agent,
ssh-agent
(1). When run without arguments, it adds the files
~/.ssh/id_rsa
,
~/.ssh/id_ecdsa
,
~/.ssh/id_ecdsa_sk
,
~/.ssh/id_ed25519
and
~/.ssh/id_ed25519_sk
. After loading a
       private key,
ssh-add
will try to load corresponding certificate
       information from the filename obtained by appending
-cert.pub
to
       the name of the private key file."
1387,1,ssh-add,"After loading a
       private key,
ssh-add
will try to load corresponding certificate
       information from the filename obtained by appending
-cert.pub
to
       the name of the private key file. Alternative file names can be
       given on the command line. If any file requires a passphrase,
ssh-add
asks for the passphrase
       from the user."
1387,2,ssh-add,"If any file requires a passphrase,
ssh-add
asks for the passphrase
       from the user. The passphrase is read from the user's tty. ssh-add
retries the last passphrase if multiple identity files are
       given."
1387,3,ssh-add,"ssh-add
retries the last passphrase if multiple identity files are
       given. The authentication agent must be running and the SSH_AUTH_SOCK
       environment variable must contain the name of its socket for
ssh-add
to work. The options are as follows:
-C
When loading keys into or deleting keys from the agent,
               process certificates only and skip plain keys."
1387,4,ssh-add,"The options are as follows:
-C
When loading keys into or deleting keys from the agent,
               process certificates only and skip plain keys. -c
Indicates that added identities should be subject to
               confirmation before being used for authentication. Confirmation is performed by
ssh-askpass
(1)."
1387,5,ssh-add,"Confirmation is performed by
ssh-askpass
(1). Successful
               confirmation is signaled by a zero exit status from
ssh-askpass
(1), rather than text entered into the
               requester. -D
Deletes all identities from the agent."
1387,6,ssh-add,"-D
Deletes all identities from the agent. -d
Instead of adding identities, removes identities from the
               agent. If
ssh-add
has been run without arguments, the
               keys for the default identities and their corresponding
               certificates will be removed."
1387,7,ssh-add,"If
ssh-add
has been run without arguments, the
               keys for the default identities and their corresponding
               certificates will be removed. Otherwise, the argument
               list will be interpreted as a list of paths to public key
               files to specify keys and certificates to be removed from
               the agent. If no public key is found at a given path,
ssh-add
will append
.pub
and retry."
1387,8,ssh-add,"If no public key is found at a given path,
ssh-add
will append
.pub
and retry. If the argument list
               consists of â-â then
ssh-add
will read public keys to be
               removed from standard input. -E
fingerprint_hash
Specifies the hash algorithm used when displaying key
               fingerprints."
1387,9,ssh-add,"-E
fingerprint_hash
Specifies the hash algorithm used when displaying key
               fingerprints. Valid options are: âmd5â and âsha256â. The
               default is âsha256â."
1387,10,ssh-add,"The
               default is âsha256â. -e
pkcs11
Remove keys provided by the PKCS#11 shared library
pkcs11
. -H
hostkey_file
Specifies a known hosts file to look up hostkeys when
               using destination-constrained keys via the
-h
flag."
1387,11,ssh-add,"-H
hostkey_file
Specifies a known hosts file to look up hostkeys when
               using destination-constrained keys via the
-h
flag. This
               option may be specified multiple times to allow multiple
               files to be searched. If no files are specified,
ssh-add
will use the default
ssh_config
(5) known hosts files:
~/.ssh/known_hosts
,
~/.ssh/known_hosts2
,
/etc/ssh/ssh_known_hosts
, and
/etc/ssh/ssh_known_hosts2
."
1387,12,ssh-add,"If no files are specified,
ssh-add
will use the default
ssh_config
(5) known hosts files:
~/.ssh/known_hosts
,
~/.ssh/known_hosts2
,
/etc/ssh/ssh_known_hosts
, and
/etc/ssh/ssh_known_hosts2
. -h
destination_constraint
When adding keys, constrain them to be usable only through
               specific hosts or to specific destinations. Destination constraints of the form â[user@]dest-hostnameâ
               permit use of the key only from the origin host (the one
               running
ssh-agent
(1)) to the listed destination host, with
               optional user name."
1387,13,ssh-add,"Destination constraints of the form â[user@]dest-hostnameâ
               permit use of the key only from the origin host (the one
               running
ssh-agent
(1)) to the listed destination host, with
               optional user name. Constraints of the form âsrc-hostname>[user@]dst-hostnameâ
               allow a key available on a forwarded
ssh-agent
(1) to be
               used through a particular host (as specified by
               âsrc-hostnameâ) to authenticate to a further host,
               specified by âdst-hostnameâ. Multiple destination constraints may be added when loading
               keys."
1387,14,ssh-add,"Multiple destination constraints may be added when loading
               keys. When attempting authentication with a key that has
               destination constraints, the whole connection path,
               including
ssh-agent
(1) forwarding, is tested against those
               constraints and each hop must be permitted for the attempt
               to succeed. For example, if key is forwarded to a remote
               host, âhost-bâ, and is attempting authentication to
               another host, âhost-câ, then the operation will be
               successful only if âhost-bâ was permitted from the origin
               host and the subsequent âhost-b>host-câ hop is also
               permitted by destination constraints."
1387,15,ssh-add,"For example, if key is forwarded to a remote
               host, âhost-bâ, and is attempting authentication to
               another host, âhost-câ, then the operation will be
               successful only if âhost-bâ was permitted from the origin
               host and the subsequent âhost-b>host-câ hop is also
               permitted by destination constraints. Hosts are identified by their host keys, and are looked up
               from known hosts files by
ssh-add
. Wildcards patterns may
               be used for hostnames and certificate host keys are
               supported."
1387,16,ssh-add,"Wildcards patterns may
               be used for hostnames and certificate host keys are
               supported. By default, keys added by
ssh-add
are not
               destination constrained. Destination constraints were added in OpenSSH release 8.9."
1387,17,ssh-add,"Destination constraints were added in OpenSSH release 8.9. Support in both the remote SSH client and server is
               required when using destination-constrained keys over a
               forwarded
ssh-agent
(1) channel. It is also important to note that destination constraints
               can only be enforced by
ssh-agent
(1) when a key is used,
               or when it is forwarded by a
cooperating
ssh
(1)."
1387,18,ssh-add,"It is also important to note that destination constraints
               can only be enforced by
ssh-agent
(1) when a key is used,
               or when it is forwarded by a
cooperating
ssh
(1). Specifically, it does not prevent an attacker with access
               to a remote SSH_AUTH_SOCK from forwarding it again and
               using it on a different host (but only to a permitted
               destination). -K
Load resident keys from a FIDO authenticator."
1387,19,ssh-add,"-K
Load resident keys from a FIDO authenticator. -k
When loading keys into or deleting keys from the agent,
               process plain private keys only and skip certificates. -L
Lists public key parameters of all identities currently
               represented by the agent."
1387,20,ssh-add,"-L
Lists public key parameters of all identities currently
               represented by the agent. -l
Lists fingerprints of all identities currently represented
               by the agent. -q
Be quiet after a successful operation."
1387,21,ssh-add,"-q
Be quiet after a successful operation. -S
provider
Specifies a path to a library that will be used when
               adding FIDO authenticator-hosted keys, overriding the
               default of using the internal USB HID support. -s
pkcs11
Add keys provided by the PKCS#11 shared library
pkcs11
."
1387,22,ssh-add,"-s
pkcs11
Add keys provided by the PKCS#11 shared library
pkcs11
. Certificate files may optionally be listed as command-line
               arguments. If these are present, then they will be loaded
               into the agent using any corresponding private keys loaded
               from the PKCS#11 token."
1387,23,ssh-add,"If these are present, then they will be loaded
               into the agent using any corresponding private keys loaded
               from the PKCS#11 token. -T
pubkey ... Tests whether the private keys that correspond to the
               specified
pubkey
files are usable by performing sign and
               verify operations on each."
1387,24,ssh-add,"Tests whether the private keys that correspond to the
               specified
pubkey
files are usable by performing sign and
               verify operations on each. -t
life
Set a maximum lifetime when adding identities to an agent. The lifetime may be specified in seconds or in a time
               format specified in
sshd_config
(5)."
1387,25,ssh-add,"The lifetime may be specified in seconds or in a time
               format specified in
sshd_config
(5). -v
Verbose mode. Causes
ssh-add
to print debugging messages
               about its progress."
1387,26,ssh-add,"Causes
ssh-add
to print debugging messages
               about its progress. This is helpful in debugging
               problems. Multiple
-v
options increase the verbosity."
1387,27,ssh-add,"Multiple
-v
options increase the verbosity. The maximum is 3. -X
Unlock the agent."
1387,28,ssh-add,"The maximum is 3. -X
Unlock the agent. -x
Lock the agent with a password."
1388,0,ssh-keyscan,"ssh-keyscan
is a utility for gathering the public SSH host keys of
       a number of hosts. It was designed to aid in building and
       verifying
ssh_known_hosts
files, the format of which is documented
       in
sshd
(8). ssh-keyscan
provides a minimal interface suitable for
       use by shell and perl scripts."
1388,1,ssh-keyscan,"ssh-keyscan
provides a minimal interface suitable for
       use by shell and perl scripts. ssh-keyscan
uses non-blocking socket I/O to contact as many hosts
       as possible in parallel, so it is very efficient. The keys from a
       domain of 1,000 hosts can be collected in tens of seconds, even
       when some of those hosts are down or do not run
sshd
(8)."
1388,2,ssh-keyscan,"The keys from a
       domain of 1,000 hosts can be collected in tens of seconds, even
       when some of those hosts are down or do not run
sshd
(8). For
       scanning, one does not need login access to the machines that are
       being scanned, nor does the scanning process involve any
       encryption. Hosts to be scanned may be specified by hostname, address or by
       CIDR network range (e.g."
1388,3,ssh-keyscan,"Hosts to be scanned may be specified by hostname, address or by
       CIDR network range (e.g. 192.168.16/28). If a network range is
       specified, then all addresses in that range will be scanned."
1388,4,ssh-keyscan,"If a network range is
       specified, then all addresses in that range will be scanned. The options are as follows:
-4
Force
ssh-keyscan
to use IPv4 addresses only. -6
Force
ssh-keyscan
to use IPv6 addresses only."
1388,5,ssh-keyscan,"-6
Force
ssh-keyscan
to use IPv6 addresses only. -c
Request certificates from target hosts instead of plain
               keys. -D
Print keys found as SSHFP DNS records."
1388,6,ssh-keyscan,"-D
Print keys found as SSHFP DNS records. The default is to
               print keys in a format usable as a
ssh
(1)
known_hosts
file. -f
file
Read hosts or âaddrlist namelistâ pairs from
file
, one per
               line."
1388,7,ssh-keyscan,"-f
file
Read hosts or âaddrlist namelistâ pairs from
file
, one per
               line. If â-â is supplied instead of a filename,
ssh-keyscan
will read from the standard input. Names read
               from a file must start with an address, hostname or CIDR
               network range to be scanned."
1388,8,ssh-keyscan,"Names read
               from a file must start with an address, hostname or CIDR
               network range to be scanned. Addresses and hostnames may
               optionally be followed by comma-separated name or address
               aliases that will be copied to the output. For example:

               192.168.11.0/24
               10.20.1.1
               happy.example.org
               10.0.0.1,sad.example.org
-H
Hash all hostnames and addresses in the output."
1388,9,ssh-keyscan,"For example:

               192.168.11.0/24
               10.20.1.1
               happy.example.org
               10.0.0.1,sad.example.org
-H
Hash all hostnames and addresses in the output. Hashed
               names may be used normally by
ssh
(1) and
sshd
(8), but they
               do not reveal identifying information should the file's
               contents be disclosed. -O
option
Specify a key/value option."
1388,10,ssh-keyscan,"-O
option
Specify a key/value option. At present, only a single
               option is supported:
hashalg
=
algorithm
Selects a hash algorithm to use when printing
                       SSHFP records using the
-D
flag. Valid algorithms
                       are âsha1â and âsha256â."
1388,11,ssh-keyscan,"Valid algorithms
                       are âsha1â and âsha256â. The default is to print
                       both. -p
port
Connect to
port
on the remote host."
1388,12,ssh-keyscan,"-p
port
Connect to
port
on the remote host. -q
Quiet mode: do not print server host name and banners in
               comments. -T
timeout
Set the timeout for connection attempts."
1388,13,ssh-keyscan,"-T
timeout
Set the timeout for connection attempts. If
timeout
seconds have elapsed since a connection was initiated to a
               host or since the last time anything was read from that
               host, the connection is closed and the host in question
               considered unavailable. The default is 5 seconds."
1388,14,ssh-keyscan,"The default is 5 seconds. -t
type
Specify the type of the key to fetch from the scanned
               hosts. The possible values are âecdsaâ, âed25519â,
               âecdsa-skâ, âed25519-skâ, or ârsaâ."
1388,15,ssh-keyscan,"The possible values are âecdsaâ, âed25519â,
               âecdsa-skâ, âed25519-skâ, or ârsaâ. Multiple values may
               be specified by separating them with commas. The default
               is to fetch all the above key types."
1388,16,ssh-keyscan,"The default
               is to fetch all the above key types. -v
Verbose mode: print debugging messages about progress. If an ssh_known_hosts file is constructed using
ssh-keyscan
without verifying the keys, users will be vulnerable to
man in the
middle
attacks."
1388,17,ssh-keyscan,"-v
Verbose mode: print debugging messages about progress. If an ssh_known_hosts file is constructed using
ssh-keyscan
without verifying the keys, users will be vulnerable to
man in the
middle
attacks. On the other hand, if the security model allows
       such a risk,
ssh-keyscan
can help in the detection of tampered
       keyfiles or man in the middle attacks which have begun after the
       ssh_known_hosts file was created."
1389,0,sshfs,"SSHFS allows you to mount a remote filesystem using SSH (more
       precisely, the SFTP subsystem). Most SSH servers support and
       enable this SFTP access by default, so SSHFS is very simple to use
       - there's nothing to do on the server-side. By default, file permissions are ignored by SSHFS."
1389,1,sshfs,"By default, file permissions are ignored by SSHFS. Any user that
       can access the filesystem will be able to perform any operation
       that the remote server permits - based on the credentials that
       were used to connect to the server. If this is undesired, local
       permission checking can be enabled with
-o default_permissions
."
1389,2,sshfs,"If this is undesired, local
       permission checking can be enabled with
-o default_permissions
. By default, only the mounting user will be able to access the
       filesystem. Access for other users can be enabled by passing
-o
allow_other
."
1389,3,sshfs,"Access for other users can be enabled by passing
-o
allow_other
. In this case you most likely also want to use
-o
default_permissions
. It is recommended to run SSHFS as regular user (not as root)."
1389,4,sshfs,"It is recommended to run SSHFS as regular user (not as root). For
       this to work the mountpoint must be owned by the user. If
       username is omitted SSHFS will use the local username."
1389,5,sshfs,"If
       username is omitted SSHFS will use the local username. If the
       directory is omitted, SSHFS will mount the (remote) home
       directory. If you need to enter a password sshfs will ask for it
       (actually it just runs ssh which ask for the password if needed)."
1390,0,sshfs,"SSHFS allows you to mount a remote filesystem using SSH (more
       precisely, the SFTP subsystem). Most SSH servers support and
       enable this SFTP access by default, so SSHFS is very simple to use
       - there's nothing to do on the server-side. By default, file permissions are ignored by SSHFS."
1390,1,sshfs,"By default, file permissions are ignored by SSHFS. Any user that
       can access the filesystem will be able to perform any operation
       that the remote server permits - based on the credentials that
       were used to connect to the server. If this is undesired, local
       permission checking can be enabled with
-o default_permissions
."
1390,2,sshfs,"If this is undesired, local
       permission checking can be enabled with
-o default_permissions
. By default, only the mounting user will be able to access the
       filesystem. Access for other users can be enabled by passing
-o
allow_other
."
1390,3,sshfs,"Access for other users can be enabled by passing
-o
allow_other
. In this case you most likely also want to use
-o
default_permissions
. It is recommended to run SSHFS as regular user (not as root)."
1390,4,sshfs,"It is recommended to run SSHFS as regular user (not as root). For
       this to work the mountpoint must be owned by the user. If
       username is omitted SSHFS will use the local username."
1390,5,sshfs,"If
       username is omitted SSHFS will use the local username. If the
       directory is omitted, SSHFS will mount the (remote) home
       directory. If you need to enter a password sshfs will ask for it
       (actually it just runs ssh which ask for the password if needed)."
1391,0,ssh-keygen,"ssh-keygen
generates, manages and converts authentication keys for
ssh
(1). ssh-keygen
can create keys for use by SSH protocol
       version 2. The type of key to be generated is specified with the
-t
option."
1391,1,ssh-keygen,"The type of key to be generated is specified with the
-t
option. If invoked without any arguments,
ssh-keygen
will generate an
       Ed25519 key. ssh-keygen
is also used to generate groups for use in Diffie-
       Hellman group exchange (DH-GEX)."
1391,2,ssh-keygen,"ssh-keygen
is also used to generate groups for use in Diffie-
       Hellman group exchange (DH-GEX). See the âMODULI GENERATIONâ
       section for details. Finally,
ssh-keygen
can be used to generate and update Key
       Revocation Lists, and to test whether given keys have been revoked
       by one."
1391,3,ssh-keygen,"Finally,
ssh-keygen
can be used to generate and update Key
       Revocation Lists, and to test whether given keys have been revoked
       by one. See the âKEY REVOCATION LISTSâ section for details. Normally each user wishing to use SSH with public key
       authentication runs this once to create the authentication key in
~/.ssh/id_ecdsa
,
~/.ssh/id_ecdsa_sk
,
~/.ssh/id_ed25519
,
~/.ssh/id_ed25519_sk
or
~/.ssh/id_rsa
."
1391,4,ssh-keygen,"Normally each user wishing to use SSH with public key
       authentication runs this once to create the authentication key in
~/.ssh/id_ecdsa
,
~/.ssh/id_ecdsa_sk
,
~/.ssh/id_ed25519
,
~/.ssh/id_ed25519_sk
or
~/.ssh/id_rsa
. Additionally, the system
       administrator may use this to generate host keys, as seen in
/etc/rc
. Normally this program generates the key and asks for a file in
       which to store the private key."
1391,5,ssh-keygen,"Normally this program generates the key and asks for a file in
       which to store the private key. The public key is stored in a
       file with the same name but â.pubâ appended. The program also
       asks for a passphrase."
1391,6,ssh-keygen,"The program also
       asks for a passphrase. The passphrase may be empty to indicate no
       passphrase (host keys must have an empty passphrase), or it may be
       a string of arbitrary length. A passphrase is similar to a
       password, except it can be a phrase with a series of words,
       punctuation, numbers, whitespace, or any string of characters you
       want."
1391,7,ssh-keygen,"A passphrase is similar to a
       password, except it can be a phrase with a series of words,
       punctuation, numbers, whitespace, or any string of characters you
       want. Good passphrases are 10-30 characters long, are not simple
       sentences or otherwise easily guessable (English prose has only
       1-2 bits of entropy per character, and provides very bad
       passphrases), and contain a mix of upper and lowercase letters,
       numbers, and non-alphanumeric characters. The passphrase can be
       changed later by using the
-p
option."
1391,8,ssh-keygen,"The passphrase can be
       changed later by using the
-p
option. There is no way to recover a lost passphrase. If the passphrase
       is lost or forgotten, a new key must be generated and the
       corresponding public key copied to other machines."
1391,9,ssh-keygen,"If the passphrase
       is lost or forgotten, a new key must be generated and the
       corresponding public key copied to other machines. ssh-keygen
will by default write keys in an OpenSSH-specific
       format. This format is preferred as it offers better protection
       for keys at rest as well as allowing storage of key comments
       within the private key file itself."
1391,10,ssh-keygen,"This format is preferred as it offers better protection
       for keys at rest as well as allowing storage of key comments
       within the private key file itself. The key comment may be useful
       to help identify the key. The comment is initialized to
       âuser@hostâ when the key is created, but can be changed using the
-c
option."
1391,11,ssh-keygen,"The comment is initialized to
       âuser@hostâ when the key is created, but can be changed using the
-c
option. It is still possible for
ssh-keygen
to write the previously-used
       PEM format private keys using the
-m
flag. This may be used when
       generating new keys, and existing new-format keys may be converted
       using this option in conjunction with the
-p
(change passphrase)
       flag."
1391,12,ssh-keygen,"This may be used when
       generating new keys, and existing new-format keys may be converted
       using this option in conjunction with the
-p
(change passphrase)
       flag. After a key is generated,
ssh-keygen
will ask where the keys
       should be placed to be activated. The options are as follows:
-A
Generate host keys of all default key types (rsa, ecdsa,
               and ed25519) if they do not already exist."
1391,13,ssh-keygen,"The options are as follows:
-A
Generate host keys of all default key types (rsa, ecdsa,
               and ed25519) if they do not already exist. The host keys
               are generated with the default key file path, an empty
               passphrase, default bits for the key type, and default
               comment. If
-f
has also been specified, its argument is
               used as a prefix to the default path for the resulting
               host key files."
1391,14,ssh-keygen,"If
-f
has also been specified, its argument is
               used as a prefix to the default path for the resulting
               host key files. This is used by
/etc/rc
to generate new
               host keys. -a
rounds
When saving a private key, this option specifies the
               number of KDF (key derivation function, currently
bcrypt_pbkdf
(3)) rounds used."
1391,15,ssh-keygen,"-a
rounds
When saving a private key, this option specifies the
               number of KDF (key derivation function, currently
bcrypt_pbkdf
(3)) rounds used. Higher numbers result in
               slower passphrase verification and increased resistance to
               brute-force password cracking (should the keys be stolen). The default is 16 rounds."
1391,16,ssh-keygen,"The default is 16 rounds. -B
Show the bubblebabble digest of specified private or
               public key file. -b
bits
Specifies the number of bits in the key to create."
1391,17,ssh-keygen,"-b
bits
Specifies the number of bits in the key to create. For
               RSA keys, the minimum size is 1024 bits and the default is
               3072 bits. Generally, 3072 bits is considered sufficient."
1391,18,ssh-keygen,"Generally, 3072 bits is considered sufficient. For ECDSA keys, the
-b
flag determines the key length by
               selecting from one of three elliptic curve sizes: 256, 384
               or 521 bits. Attempting to use bit lengths other than
               these three values for ECDSA keys will fail."
1391,19,ssh-keygen,"Attempting to use bit lengths other than
               these three values for ECDSA keys will fail. ECDSA-SK,
               Ed25519 and Ed25519-SK keys have a fixed length and the
-b
flag will be ignored. -C
comment
Provides a new comment."
1391,20,ssh-keygen,"-C
comment
Provides a new comment. -c
Requests changing the comment in the private and public
               key files. The program will prompt for the file
               containing the private keys, for the passphrase if the key
               has one, and for the new comment."
1391,21,ssh-keygen,"The program will prompt for the file
               containing the private keys, for the passphrase if the key
               has one, and for the new comment. -D
pkcs11
Download the public keys provided by the PKCS#11 shared
               library
pkcs11
. When used in combination with
-s
, this
               option indicates that a CA key resides in a PKCS#11 token
               (see the âCERTIFICATESâ section for details)."
1391,22,ssh-keygen,"When used in combination with
-s
, this
               option indicates that a CA key resides in a PKCS#11 token
               (see the âCERTIFICATESâ section for details). -E
fingerprint_hash
Specifies the hash algorithm used when displaying key
               fingerprints. Valid options are: âmd5â and âsha256â."
1391,23,ssh-keygen,"Valid options are: âmd5â and âsha256â. The
               default is âsha256â. -e
This option will read a private or public OpenSSH key file
               and print to stdout a public key in one of the formats
               specified by the
-m
option."
1391,24,ssh-keygen,"-e
This option will read a private or public OpenSSH key file
               and print to stdout a public key in one of the formats
               specified by the
-m
option. The default export format is
               âRFC4716â. This option allows exporting OpenSSH keys for
               use by other programs, including several commercial SSH
               implementations."
1391,25,ssh-keygen,"This option allows exporting OpenSSH keys for
               use by other programs, including several commercial SSH
               implementations. -F
hostname
|
[hostname]:port
Search for the specified
hostname
(with optional port
               number) in a
known_hosts
file, listing any occurrences
               found. This option is useful to find hashed host names or
               addresses and may also be used in conjunction with the
-H
option to print found keys in a hashed format."
1391,26,ssh-keygen,"This option is useful to find hashed host names or
               addresses and may also be used in conjunction with the
-H
option to print found keys in a hashed format. -f
filename
Specifies the filename of the key file. -g
Use generic DNS format when printing fingerprint resource
               records using the
-r
command."
1391,27,ssh-keygen,"-g
Use generic DNS format when printing fingerprint resource
               records using the
-r
command. -H
Hash a
known_hosts
file. This replaces all hostnames and
               addresses with hashed representations within the specified
               file; the original content is moved to a file with a .old
               suffix."
1391,28,ssh-keygen,"This replaces all hostnames and
               addresses with hashed representations within the specified
               file; the original content is moved to a file with a .old
               suffix. These hashes may be used normally by
ssh
and
sshd
, but they do not reveal identifying information
               should the file's contents be disclosed. This option will
               not modify existing hashed hostnames and is therefore safe
               to use on files that mix hashed and non-hashed names."
1391,29,ssh-keygen,"This option will
               not modify existing hashed hostnames and is therefore safe
               to use on files that mix hashed and non-hashed names. -h
When signing a key, create a host certificate instead of a
               user certificate. See the âCERTIFICATESâ section for
               details."
1391,30,ssh-keygen,"See the âCERTIFICATESâ section for
               details. -I
certificate_identity
Specify the key identity when signing a public key. See
               the âCERTIFICATESâ section for details."
1391,31,ssh-keygen,"See
               the âCERTIFICATESâ section for details. -i
This option will read an unencrypted private (or public)
               key file in the format specified by the
-m
option and
               print an OpenSSH compatible private (or public) key to
               stdout. This option allows importing keys from other
               software, including several commercial SSH
               implementations."
1391,32,ssh-keygen,"This option allows importing keys from other
               software, including several commercial SSH
               implementations. The default import format is âRFC4716â. -K
Download resident keys from a FIDO authenticator."
1391,33,ssh-keygen,"-K
Download resident keys from a FIDO authenticator. Public
               and private key files will be written to the current
               directory for each downloaded key. If multiple FIDO
               authenticators are attached, keys will be downloaded from
               the first touched authenticator."
1391,34,ssh-keygen,"If multiple FIDO
               authenticators are attached, keys will be downloaded from
               the first touched authenticator. See the âFIDO
               AUTHENTICATORâ section for more information. -k
Generate a KRL file."
1391,35,ssh-keygen,"-k
Generate a KRL file. In this mode,
ssh-keygen
will
               generate a KRL file at the location specified via the
-f
flag that revokes every key or certificate presented on
               the command line. Keys/certificates to be revoked may be
               specified by public key file or using the format described
               in the âKEY REVOCATION LISTSâ section."
1391,36,ssh-keygen,"Keys/certificates to be revoked may be
               specified by public key file or using the format described
               in the âKEY REVOCATION LISTSâ section. -L
Prints the contents of one or more certificates. -l
Show fingerprint of specified public key file."
1391,37,ssh-keygen,"-l
Show fingerprint of specified public key file. ssh-keygen
will try to find the matching public key file and prints
               its fingerprint. If combined with
-v
, a visual ASCII art
               representation of the key is supplied with the
               fingerprint."
1391,38,ssh-keygen,"If combined with
-v
, a visual ASCII art
               representation of the key is supplied with the
               fingerprint. -M generate
Generate candidate Diffie-Hellman Group Exchange (DH-GEX)
               parameters for eventual use by the
               âdiffie-hellman-group-exchange-*â key exchange methods. The numbers generated by this operation must be further
               screened before use."
1391,39,ssh-keygen,"The numbers generated by this operation must be further
               screened before use. See the âMODULI GENERATIONâ section
               for more information. -M screen
Screen candidate parameters for Diffie-Hellman Group
               Exchange."
1391,40,ssh-keygen,"-M screen
Screen candidate parameters for Diffie-Hellman Group
               Exchange. This will accept a list of candidate numbers
               and test that they are safe (Sophie Germain) primes with
               acceptable group generators. The results of this
               operation may be added to the
/etc/moduli
file."
1391,41,ssh-keygen,"The results of this
               operation may be added to the
/etc/moduli
file. See the
               âMODULI GENERATIONâ section for more information. -m
key_format
Specify a key format for key generation, the
-i
(import),
-e
(export) conversion options, and the
-p
change
               passphrase operation."
1391,42,ssh-keygen,"-m
key_format
Specify a key format for key generation, the
-i
(import),
-e
(export) conversion options, and the
-p
change
               passphrase operation. The latter may be used to convert
               between OpenSSH private key and PEM private key formats. The supported key formats are: âRFC4716â (RFC 4716/SSH2
               public or private key), âPKCS8â (PKCS8 public or private
               key) or âPEMâ (PEM public key)."
1391,43,ssh-keygen,"The supported key formats are: âRFC4716â (RFC 4716/SSH2
               public or private key), âPKCS8â (PKCS8 public or private
               key) or âPEMâ (PEM public key). By default OpenSSH will
               write newly-generated private keys in its own format, but
               when converting public keys for export the default format
               is âRFC4716â. Setting a format of âPEMâ when generating
               or updating a supported private key type will cause the
               key to be stored in the legacy PEM private key format."
1391,44,ssh-keygen,"Setting a format of âPEMâ when generating
               or updating a supported private key type will cause the
               key to be stored in the legacy PEM private key format. -N
new_passphrase
Provides the new passphrase. -n
principals
Specify one or more principals (user or host names) to be
               included in a certificate when signing a key."
1391,45,ssh-keygen,"-n
principals
Specify one or more principals (user or host names) to be
               included in a certificate when signing a key. Multiple
               principals may be specified, separated by commas. See the
               âCERTIFICATESâ section for details."
1391,46,ssh-keygen,"See the
               âCERTIFICATESâ section for details. -O
option
Specify a key/value option. These are specific to the
               operation that
ssh-keygen
has been requested to perform."
1391,47,ssh-keygen,"These are specific to the
               operation that
ssh-keygen
has been requested to perform. When signing certificates, one of the options listed in
               the âCERTIFICATESâ section may be specified here. When performing moduli generation or screening, one of the
               options listed in the âMODULI GENERATIONâ section may be
               specified."
1391,48,ssh-keygen,"When performing moduli generation or screening, one of the
               options listed in the âMODULI GENERATIONâ section may be
               specified. When generating FIDO authenticator-backed keys, the
               options listed in the âFIDO AUTHENTICATORâ section may be
               specified. When performing signature-related options using the
-Y
flag, the following options are accepted:
hashalg
=
algorithm
Selects the hash algorithm to use for hashing the
                       message to be signed."
1391,49,ssh-keygen,"When performing signature-related options using the
-Y
flag, the following options are accepted:
hashalg
=
algorithm
Selects the hash algorithm to use for hashing the
                       message to be signed. Valid algorithms are
                       âsha256â and âsha512.â The default is âsha512.â
print-pubkey
Print the full public key to standard output after
                       signature verification. verify-time
=
timestamp
Specifies a time to use when validating signatures
                       instead of the current time."
1391,50,ssh-keygen,"verify-time
=
timestamp
Specifies a time to use when validating signatures
                       instead of the current time. The time may be
                       specified as a date or time in the YYYYMMDD[Z] or
                       in YYYYMMDDHHMM[SS][Z] formats. Dates and times
                       will be interpreted in the current system time
                       zone unless suffixed with a Z character, which
                       causes them to be interpreted in the UTC time
                       zone."
1391,51,ssh-keygen,"Dates and times
                       will be interpreted in the current system time
                       zone unless suffixed with a Z character, which
                       causes them to be interpreted in the UTC time
                       zone. When generating SSHFP DNS records from public keys using
               the
-r
flag, the following options are accepted:
hashalg
=
algorithm
Selects a hash algorithm to use when printing
                       SSHFP records using the
-D
flag. Valid algorithms
                       are âsha1â and âsha256â."
1391,52,ssh-keygen,"Valid algorithms
                       are âsha1â and âsha256â. The default is to print
                       both. The
-O
option may be specified multiple times."
1391,53,ssh-keygen,"The
-O
option may be specified multiple times. -P
passphrase
Provides the (old) passphrase. -p
Requests changing the passphrase of a private key file
               instead of creating a new private key."
1391,54,ssh-keygen,"-p
Requests changing the passphrase of a private key file
               instead of creating a new private key. The program will
               prompt for the file containing the private key, for the
               old passphrase, and twice for the new passphrase. -Q
Test whether keys have been revoked in a KRL."
1391,55,ssh-keygen,"-Q
Test whether keys have been revoked in a KRL. If the
-l
option is also specified then the contents of the KRL will
               be printed. -q
Silence
ssh-keygen
."
1391,56,ssh-keygen,"-q
Silence
ssh-keygen
. -R
hostname
|
[hostname]:port
Removes all keys belonging to the specified
hostname
(with
               optional port number) from a
known_hosts
file. This
               option is useful to delete hashed hosts (see the
-H
option
               above)."
1391,57,ssh-keygen,"This
               option is useful to delete hashed hosts (see the
-H
option
               above). -r
hostname
Print the SSHFP fingerprint resource record named
hostname
for the specified public key file. -s
ca_key
Certify (sign) a public key using the specified CA key."
1391,58,ssh-keygen,"-s
ca_key
Certify (sign) a public key using the specified CA key. See the âCERTIFICATESâ section for details. When generating a KRL,
-s
specifies a path to a CA public
               key file used to revoke certificates directly by key ID or
               serial number."
1391,59,ssh-keygen,"When generating a KRL,
-s
specifies a path to a CA public
               key file used to revoke certificates directly by key ID or
               serial number. See the âKEY REVOCATION LISTSâ section for
               details. -t ecdsa
|
ecdsa-sk
|
ed25519
|
ed25519-sk
|
rsa
Specifies the type of key to create."
1391,60,ssh-keygen,"-t ecdsa
|
ecdsa-sk
|
ed25519
|
ed25519-sk
|
rsa
Specifies the type of key to create. The possible values
               are âecdsaâ, âecdsa-skâ, âed25519 (the default),â
               âed25519-skâ, or ârsaâ. This flag may also be used to specify the desired
               signature type when signing certificates using an RSA CA
               key."
1391,61,ssh-keygen,"This flag may also be used to specify the desired
               signature type when signing certificates using an RSA CA
               key. The available RSA signature variants are âssh-rsaâ
               (SHA1 signatures, not recommended), ârsa-sha2-256â, and
               ârsa-sha2-512â (the default for RSA keys). -U
When used in combination with
-s
or
-Y sign
, this option
               indicates that a CA key resides in a
ssh-agent
(1)."
1391,62,ssh-keygen,"-U
When used in combination with
-s
or
-Y sign
, this option
               indicates that a CA key resides in a
ssh-agent
(1). See
               the âCERTIFICATESâ section for more information. -u
Update a KRL."
1391,63,ssh-keygen,"-u
Update a KRL. When specified with
-k
, keys listed via the
               command line are added to the existing KRL rather than a
               new KRL being created. -V
validity_interval
Specify a validity interval when signing a certificate."
1391,64,ssh-keygen,"-V
validity_interval
Specify a validity interval when signing a certificate. A
               validity interval may consist of a single time, indicating
               that the certificate is valid beginning now and expiring
               at that time, or may consist of two times separated by a
               colon to indicate an explicit time interval. The start time may be specified as:
â¢
The string âalwaysâ to indicate the certificate has no
                   specified start time."
1391,65,ssh-keygen,"The start time may be specified as:
â¢
The string âalwaysâ to indicate the certificate has no
                   specified start time. â¢
A date or time in the system time zone formatted as
                   YYYYMMDD or YYYYMMDDHHMM[SS]. â¢
A date or time in the UTC time zone as YYYYMMDDZ or
                   YYYYMMDDHHMM[SS]Z."
1391,66,ssh-keygen,"â¢
A date or time in the UTC time zone as YYYYMMDDZ or
                   YYYYMMDDHHMM[SS]Z. â¢
A relative time before the current system time
                   consisting of a minus sign followed by an interval in
                   the format described in the TIME FORMATS section of
sshd_config
(5). â¢
A raw seconds since epoch (Jan 1 1970 00:00:00 UTC) as
                   a hexadecimal number beginning with â0xâ."
1391,67,ssh-keygen,"â¢
A raw seconds since epoch (Jan 1 1970 00:00:00 UTC) as
                   a hexadecimal number beginning with â0xâ. The end time may be specified similarly to the start time:
â¢
The string âforeverâ to indicate the certificate has
                   no specified end time. â¢
A date or time in the system time zone formatted as
                   YYYYMMDD or YYYYMMDDHHMM[SS]."
1391,68,ssh-keygen,"â¢
A date or time in the system time zone formatted as
                   YYYYMMDD or YYYYMMDDHHMM[SS]. â¢
A date or time in the UTC time zone as YYYYMMDDZ or
                   YYYYMMDDHHMM[SS]Z. â¢
A relative time after the current system time
                   consisting of a plus sign followed by an interval in
                   the format described in the TIME FORMATS section of
sshd_config
(5)."
1391,69,ssh-keygen,"â¢
A relative time after the current system time
                   consisting of a plus sign followed by an interval in
                   the format described in the TIME FORMATS section of
sshd_config
(5). â¢
A raw seconds since epoch (Jan 1 1970 00:00:00 UTC) as
                   a hexadecimal number beginning with â0xâ. For example:

               +52w1d  Valid from now to 52 weeks and one day from now."
1391,70,ssh-keygen,"For example:

               +52w1d  Valid from now to 52 weeks and one day from now. -4w:+4w
                       Valid from four weeks ago to four weeks from now. 20100101123000:20110101123000
                       Valid from 12:30 PM, January 1st, 2010 to 12:30
                       PM, January 1st, 2011."
1391,71,ssh-keygen,"20100101123000:20110101123000
                       Valid from 12:30 PM, January 1st, 2010 to 12:30
                       PM, January 1st, 2011. 20100101123000Z:20110101123000Z
                       Similar, but interpreted in the UTC time zone
                       rather than the system time zone. -1d:20110101
                       Valid from yesterday to midnight, January 1st,
                       2011."
1391,72,ssh-keygen,"-1d:20110101
                       Valid from yesterday to midnight, January 1st,
                       2011. 0x1:0x2000000000
                       Valid from roughly early 1970 to May 2033. -1m:forever
                       Valid from one minute ago and never expiring."
1391,73,ssh-keygen,"-1m:forever
                       Valid from one minute ago and never expiring. -v
Verbose mode. Causes
ssh-keygen
to print debugging
               messages about its progress."
1391,74,ssh-keygen,"Causes
ssh-keygen
to print debugging
               messages about its progress. This is helpful for
               debugging moduli generation. Multiple
-v
options increase
               the verbosity."
1391,75,ssh-keygen,"Multiple
-v
options increase
               the verbosity. The maximum is 3. -w
provider
Specifies a path to a library that will be used when
               creating FIDO authenticator-hosted keys, overriding the
               default of using the internal USB HID support."
1391,76,ssh-keygen,"-w
provider
Specifies a path to a library that will be used when
               creating FIDO authenticator-hosted keys, overriding the
               default of using the internal USB HID support. -Y find-principals
Find the principal(s) associated with the public key of a
               signature, provided using the
-s
flag in an authorized
               signers file provided using the
-f
flag. The format of
               the allowed signers file is documented in the âALLOWED
               SIGNERSâ section below."
1391,77,ssh-keygen,"The format of
               the allowed signers file is documented in the âALLOWED
               SIGNERSâ section below. If one or more matching
               principals are found, they are returned on standard
               output. -Y match-principals
Find principal matching the principal name provided using
               the
-I
flag in the authorized signers file specified using
               the
-f
flag."
1391,78,ssh-keygen,"-Y match-principals
Find principal matching the principal name provided using
               the
-I
flag in the authorized signers file specified using
               the
-f
flag. If one or more matching principals are
               found, they are returned on standard output. -Y check-novalidate
Checks that a signature generated using
ssh-keygen -Y sign
has a valid structure."
1391,79,ssh-keygen,"-Y check-novalidate
Checks that a signature generated using
ssh-keygen -Y sign
has a valid structure. This does not validate if a
               signature comes from an authorized signer. When testing a
               signature,
ssh-keygen
accepts a message on standard input
               and a signature namespace using
-n
."
1391,80,ssh-keygen,"When testing a
               signature,
ssh-keygen
accepts a message on standard input
               and a signature namespace using
-n
. A file containing the
               corresponding signature must also be supplied using the
-s
flag. Successful testing of the signature is signalled by
ssh-keygen
returning a zero exit status."
1391,81,ssh-keygen,"Successful testing of the signature is signalled by
ssh-keygen
returning a zero exit status. -Y sign
Cryptographically sign a file or some data using an SSH
               key. When signing,
ssh-keygen
accepts zero or more files
               to sign on the command-line - if no files are specified
               then
ssh-keygen
will sign data presented on standard
               input."
1391,82,ssh-keygen,"When signing,
ssh-keygen
accepts zero or more files
               to sign on the command-line - if no files are specified
               then
ssh-keygen
will sign data presented on standard
               input. Signatures are written to the path of the input
               file with â.sigâ appended, or to standard output if the
               message to be signed was read from standard input. The key used for signing is specified using the
-f
option
               and may refer to either a private key, or a public key
               with the private half available via
ssh-agent
(1)."
1391,83,ssh-keygen,"The key used for signing is specified using the
-f
option
               and may refer to either a private key, or a public key
               with the private half available via
ssh-agent
(1). An
               additional signature namespace, used to prevent signature
               confusion across different domains of use (e.g. file
               signing vs email signing) must be provided via the
-n
flag."
1391,84,ssh-keygen,"file
               signing vs email signing) must be provided via the
-n
flag. Namespaces are arbitrary strings, and may include:
               âfileâ for file signing, âemailâ for email signing. For
               custom uses, it is recommended to use names following a
               NAMESPACE@YOUR.DOMAIN pattern to generate unambiguous
               namespaces."
1391,85,ssh-keygen,"For
               custom uses, it is recommended to use names following a
               NAMESPACE@YOUR.DOMAIN pattern to generate unambiguous
               namespaces. -Y verify
Request to verify a signature generated using
ssh-keygen
-Y sign
as described above. When verifying a signature,
ssh-keygen
accepts a message on standard input and a
               signature namespace using
-n
."
1391,86,ssh-keygen,"When verifying a signature,
ssh-keygen
accepts a message on standard input and a
               signature namespace using
-n
. A file containing the
               corresponding signature must also be supplied using the
-s
flag, along with the identity of the signer using
-I
and a
               list of allowed signers via the
-f
flag. The format of
               the allowed signers file is documented in the âALLOWED
               SIGNERSâ section below."
1391,87,ssh-keygen,"The format of
               the allowed signers file is documented in the âALLOWED
               SIGNERSâ section below. A file containing revoked keys
               can be passed using the
-r
flag. The revocation file may
               be a KRL or a one-per-line list of public keys."
1391,88,ssh-keygen,"The revocation file may
               be a KRL or a one-per-line list of public keys. Successful verification by an authorized signer is
               signalled by
ssh-keygen
returning a zero exit status. -y
This option will read a private OpenSSH format file and
               print an OpenSSH public key to stdout."
1391,89,ssh-keygen,"-y
This option will read a private OpenSSH format file and
               print an OpenSSH public key to stdout. -Z
cipher
Specifies the cipher to use for encryption when writing an
               OpenSSH-format private key file. The list of available
               ciphers may be obtained using ""ssh -Q cipher""."
1391,90,ssh-keygen,"The list of available
               ciphers may be obtained using ""ssh -Q cipher"". The
               default is âaes256-ctrâ. -z
serial_number
Specifies a serial number to be embedded in the
               certificate to distinguish this certificate from others
               from the same CA."
1391,91,ssh-keygen,"-z
serial_number
Specifies a serial number to be embedded in the
               certificate to distinguish this certificate from others
               from the same CA. If the
serial_number
is prefixed with a
               â+â character, then the serial number will be incremented
               for each certificate signed on a single command-line. The
               default serial number is zero."
1391,92,ssh-keygen,"If the
serial_number
is prefixed with a
               â+â character, then the serial number will be incremented
               for each certificate signed on a single command-line. The
               default serial number is zero. When generating a KRL, the
-z
flag is used to specify a
               KRL version number."
1392,0,ssh,"ssh
(SSH client) is a program for logging into a remote machine
       and for executing commands on a remote machine. It is intended to
       provide secure encrypted communications between two untrusted
       hosts over an insecure network. X11 connections, arbitrary TCP
       ports and Unix-domain sockets can also be forwarded over the
       secure channel."
1392,1,ssh,"X11 connections, arbitrary TCP
       ports and Unix-domain sockets can also be forwarded over the
       secure channel. ssh
connects and logs into the specified
destination
, which may be
       specified as either [user@]hostname or a URI of the form
       ssh://[user@]hostname[:port]. The user must prove their identity
       to the remote machine using one of several methods (see below)."
1392,2,ssh,"The user must prove their identity
       to the remote machine using one of several methods (see below). If a
command
is specified, it will be executed on the remote host
       instead of a login shell. A complete command line may be
       specified as
command
, or it may have additional arguments."
1392,3,ssh,"A complete command line may be
       specified as
command
, or it may have additional arguments. If
       supplied, the arguments will be appended to the command, separated
       by spaces, before it is sent to the server to be executed. The options are as follows:
-4
Forces
ssh
to use IPv4 addresses only."
1392,4,ssh,"The options are as follows:
-4
Forces
ssh
to use IPv4 addresses only. -6
Forces
ssh
to use IPv6 addresses only. -A
Enables forwarding of connections from an authentication
               agent such as
ssh-agent
(1)."
1392,5,ssh,"-A
Enables forwarding of connections from an authentication
               agent such as
ssh-agent
(1). This can also be specified on
               a per-host basis in a configuration file. Agent forwarding should be enabled with caution."
1392,6,ssh,"Agent forwarding should be enabled with caution. Users
               with the ability to bypass file permissions on the remote
               host (for the agent's Unix-domain socket) can access the
               local agent through the forwarded connection. An attacker
               cannot obtain key material from the agent, however they
               can perform operations on the keys that enable them to
               authenticate using the identities loaded into the agent."
1392,7,ssh,"An attacker
               cannot obtain key material from the agent, however they
               can perform operations on the keys that enable them to
               authenticate using the identities loaded into the agent. A safer alternative may be to use a jump host (see
-J
). -a
Disables forwarding of the authentication agent
               connection."
1392,8,ssh,"-a
Disables forwarding of the authentication agent
               connection. -B
bind_interface
Bind to the address of
bind_interface
before attempting to
               connect to the destination host. This is only useful on
               systems with more than one address."
1392,9,ssh,"This is only useful on
               systems with more than one address. -b
bind_address
Use
bind_address
on the local machine as the source
               address of the connection. Only useful on systems with
               more than one address."
1392,10,ssh,"Only useful on systems with
               more than one address. -C
Requests compression of all data (including stdin, stdout,
               stderr, and data for forwarded X11, TCP and Unix-domain
               connections). The compression algorithm is the same used
               by
gzip
(1)."
1392,11,ssh,"The compression algorithm is the same used
               by
gzip
(1). Compression is desirable on modem lines and
               other slow connections, but will only slow down things on
               fast networks. The default value can be set on a host-by-
               host basis in the configuration files; see the
Compression
option in
ssh_config
(5)."
1392,12,ssh,"The default value can be set on a host-by-
               host basis in the configuration files; see the
Compression
option in
ssh_config
(5). -c
cipher_spec
Selects the cipher specification for encrypting the
               session. cipher_spec
is a comma-separated list of ciphers
               listed in order of preference."
1392,13,ssh,"cipher_spec
is a comma-separated list of ciphers
               listed in order of preference. See the
Ciphers
keyword in
ssh_config
(5) for more information. -D
[
bind_address
:]
port
Specifies a local âdynamicâ application-level port
               forwarding."
1392,14,ssh,"-D
[
bind_address
:]
port
Specifies a local âdynamicâ application-level port
               forwarding. This works by allocating a socket to listen
               to
port
on the local side, optionally bound to the
               specified
bind_address
. Whenever a connection is made to
               this port, the connection is forwarded over the secure
               channel, and the application protocol is then used to
               determine where to connect to from the remote machine."
1392,15,ssh,"Whenever a connection is made to
               this port, the connection is forwarded over the secure
               channel, and the application protocol is then used to
               determine where to connect to from the remote machine. Currently the SOCKS4 and SOCKS5 protocols are supported,
               and
ssh
will act as a SOCKS server. Only root can forward
               privileged ports."
1392,16,ssh,"Only root can forward
               privileged ports. Dynamic port forwardings can also be
               specified in the configuration file. IPv6 addresses can be specified by enclosing the address
               in square brackets."
1392,17,ssh,"IPv6 addresses can be specified by enclosing the address
               in square brackets. Only the superuser can forward
               privileged ports. By default, the local port is bound in
               accordance with the
GatewayPorts
setting."
1392,18,ssh,"By default, the local port is bound in
               accordance with the
GatewayPorts
setting. However, an
               explicit
bind_address
may be used to bind the connection
               to a specific address. The
bind_address
of âlocalhostâ
               indicates that the listening port be bound for local use
               only, while an empty address or â*â indicates that the
               port should be available from all interfaces."
1392,19,ssh,"The
bind_address
of âlocalhostâ
               indicates that the listening port be bound for local use
               only, while an empty address or â*â indicates that the
               port should be available from all interfaces. -E
log_file
Append debug logs to
log_file
instead of standard error. -e
escape_char
Sets the escape character for sessions with a pty
               (default: â~â)."
1392,20,ssh,"-e
escape_char
Sets the escape character for sessions with a pty
               (default: â~â). The escape character is only recognized
               at the beginning of a line. The escape character followed
               by a dot (â.â) closes the connection; followed by control-
               Z suspends the connection; and followed by itself sends
               the escape character once."
1392,21,ssh,"The escape character followed
               by a dot (â.â) closes the connection; followed by control-
               Z suspends the connection; and followed by itself sends
               the escape character once. Setting the character to
               ânoneâ disables any escapes and makes the session fully
               transparent. -F
configfile
Specifies an alternative per-user configuration file."
1392,22,ssh,"-F
configfile
Specifies an alternative per-user configuration file. If
               a configuration file is given on the command line, the
               system-wide configuration file (
/etc/ssh/ssh_config
) will
               be ignored. The default for the per-user configuration
               file is
~/.ssh/config
."
1392,23,ssh,"The default for the per-user configuration
               file is
~/.ssh/config
. If set to ânoneâ, no configuration
               files will be read. -f
Requests
ssh
to go to background just before command
               execution."
1392,24,ssh,"-f
Requests
ssh
to go to background just before command
               execution. This is useful if
ssh
is going to ask for
               passwords or passphrases, but the user wants it in the
               background. This implies
-n
."
1392,25,ssh,"This implies
-n
. The recommended way to
               start X11 programs at a remote site is with something like
ssh -f host xterm
. If the
ExitOnForwardFailure
configuration option is set to
               âyesâ, then a client started with
-f
will wait for all
               remote port forwards to be successfully established before
               placing itself in the background."
1392,26,ssh,"If the
ExitOnForwardFailure
configuration option is set to
               âyesâ, then a client started with
-f
will wait for all
               remote port forwards to be successfully established before
               placing itself in the background. Refer to the
               description of
ForkAfterAuthentication
in
ssh_config
(5)
               for details. -G
Causes
ssh
to print its configuration after evaluating
Host
and
Match
blocks and exit."
1392,27,ssh,"-G
Causes
ssh
to print its configuration after evaluating
Host
and
Match
blocks and exit. -g
Allows remote hosts to connect to local forwarded ports. If used on a multiplexed connection, then this option must
               be specified on the master process."
1392,28,ssh,"If used on a multiplexed connection, then this option must
               be specified on the master process. -I
pkcs11
Specify the PKCS#11 shared library
ssh
should use to
               communicate with a PKCS#11 token providing keys for user
               authentication. -i
identity_file
Selects a file from which the identity (private key) for
               public key authentication is read."
1392,29,ssh,"-i
identity_file
Selects a file from which the identity (private key) for
               public key authentication is read. You can also specify a
               public key file to use the corresponding private key that
               is loaded in
ssh-agent
(1) when the private key file is not
               present locally. The default is
~/.ssh/id_rsa
,
~/.ssh/id_ecdsa
,
~/.ssh/id_ecdsa_sk
,
~/.ssh/id_ed25519
and
~/.ssh/id_ed25519_sk
."
1392,30,ssh,"The default is
~/.ssh/id_rsa
,
~/.ssh/id_ecdsa
,
~/.ssh/id_ecdsa_sk
,
~/.ssh/id_ed25519
and
~/.ssh/id_ed25519_sk
. Identity files may also be
               specified on a per-host basis in the configuration file. It is possible to have multiple
-i
options (and multiple
               identities specified in configuration files)."
1392,31,ssh,"It is possible to have multiple
-i
options (and multiple
               identities specified in configuration files). If no
               certificates have been explicitly specified by the
CertificateFile
directive,
ssh
will also try to load
               certificate information from the filename obtained by
               appending
-cert.pub
to identity filenames. -J
destination
Connect to the target host by first making an
ssh
connection to the jump host described by
destination
and
               then establishing a TCP forwarding to the ultimate
               destination from there."
1392,32,ssh,"-J
destination
Connect to the target host by first making an
ssh
connection to the jump host described by
destination
and
               then establishing a TCP forwarding to the ultimate
               destination from there. Multiple jump hops may be
               specified separated by comma characters. IPv6 addresses
               can be specified by enclosing the address in square
               brackets."
1392,33,ssh,"IPv6 addresses
               can be specified by enclosing the address in square
               brackets. This is a shortcut to specify a
ProxyJump
configuration directive. Note that configuration
               directives supplied on the command-line generally apply to
               the destination host and not any specified jump hosts."
1392,34,ssh,"Note that configuration
               directives supplied on the command-line generally apply to
               the destination host and not any specified jump hosts. Use
~/.ssh/config
to specify configuration for jump hosts. -K
Enables GSSAPI-based authentication and forwarding
               (delegation) of GSSAPI credentials to the server."
1392,35,ssh,"-K
Enables GSSAPI-based authentication and forwarding
               (delegation) of GSSAPI credentials to the server. -k
Disables forwarding (delegation) of GSSAPI credentials to
               the server. -L
[
bind_address
:]
port
:
host
:
hostport
-L
[
bind_address
:]
port
:
remote_socket
-L
local_socket
:
host
:
hostport
-L
local_socket
:
remote_socket
Specifies that connections to the given TCP port or Unix
               socket on the local (client) host are to be forwarded to
               the given host and port, or Unix socket, on the remote
               side."
1392,36,ssh,"-L
[
bind_address
:]
port
:
host
:
hostport
-L
[
bind_address
:]
port
:
remote_socket
-L
local_socket
:
host
:
hostport
-L
local_socket
:
remote_socket
Specifies that connections to the given TCP port or Unix
               socket on the local (client) host are to be forwarded to
               the given host and port, or Unix socket, on the remote
               side. This works by allocating a socket to listen to
               either a TCP
port
on the local side, optionally bound to
               the specified
bind_address
, or to a Unix socket. Whenever
               a connection is made to the local port or socket, the
               connection is forwarded over the secure channel, and a
               connection is made to either
host
port
hostport
, or the
               Unix socket
remote_socket
, from the remote machine."
1392,37,ssh,"Whenever
               a connection is made to the local port or socket, the
               connection is forwarded over the secure channel, and a
               connection is made to either
host
port
hostport
, or the
               Unix socket
remote_socket
, from the remote machine. Port forwardings can also be specified in the
               configuration file. Only the superuser can forward
               privileged ports."
1392,38,ssh,"Only the superuser can forward
               privileged ports. IPv6 addresses can be specified by
               enclosing the address in square brackets. By default, the local port is bound in accordance with the
GatewayPorts
setting."
1392,39,ssh,"By default, the local port is bound in accordance with the
GatewayPorts
setting. However, an explicit
bind_address
may be used to bind the connection to a specific address. The
bind_address
of âlocalhostâ indicates that the
               listening port be bound for local use only, while an empty
               address or â*â indicates that the port should be available
               from all interfaces."
1392,40,ssh,"The
bind_address
of âlocalhostâ indicates that the
               listening port be bound for local use only, while an empty
               address or â*â indicates that the port should be available
               from all interfaces. -l
login_name
Specifies the user to log in as on the remote machine. This also may be specified on a per-host basis in the
               configuration file."
1392,41,ssh,"This also may be specified on a per-host basis in the
               configuration file. -M
Places the
ssh
client into âmasterâ mode for connection
               sharing. Multiple
-M
options places
ssh
into âmasterâ
               mode but with confirmation required using
ssh-askpass
(1)
               before each operation that changes the multiplexing state
               (e.g."
1392,42,ssh,"Multiple
-M
options places
ssh
into âmasterâ
               mode but with confirmation required using
ssh-askpass
(1)
               before each operation that changes the multiplexing state
               (e.g. opening a new session). Refer to the description of
ControlMaster
in
ssh_config
(5) for details."
1392,43,ssh,"Refer to the description of
ControlMaster
in
ssh_config
(5) for details. -m
mac_spec
A comma-separated list of MAC (message authentication
               code) algorithms, specified in order of preference. See
               the
MACs
keyword in
ssh_config
(5) for more information."
1392,44,ssh,"See
               the
MACs
keyword in
ssh_config
(5) for more information. -N
Do not execute a remote command. This is useful for just
               forwarding ports."
1392,45,ssh,"This is useful for just
               forwarding ports. Refer to the description of
SessionType
in
ssh_config
(5) for details. -n
Redirects stdin from
/dev/null
(actually, prevents reading
               from stdin)."
1392,46,ssh,"-n
Redirects stdin from
/dev/null
(actually, prevents reading
               from stdin). This must be used when
ssh
is run in the
               background. A common trick is to use this to run X11
               programs on a remote machine."
1392,47,ssh,"A common trick is to use this to run X11
               programs on a remote machine. For example,
ssh -n
shadows.cs.hut.fi emacs &
will start an emacs on
               shadows.cs.hut.fi, and the X11 connection will be
               automatically forwarded over an encrypted channel. The
ssh
program will be put in the background."
1392,48,ssh,"The
ssh
program will be put in the background. (This does not
               work if
ssh
needs to ask for a password or passphrase; see
               also the
-f
option.)  Refer to the description of
StdinNull
in
ssh_config
(5) for details. -O
ctl_cmd
Control an active connection multiplexing master process."
1392,49,ssh,"-O
ctl_cmd
Control an active connection multiplexing master process. When the
-O
option is specified, the
ctl_cmd
argument is
               interpreted and passed to the master process. Valid
               commands are: âcheckâ (check that the master process is
               running), âforwardâ (request forwardings without command
               execution), âcancelâ (cancel forwardings), âproxyâ
               (connect to a running multiplexing master in proxy mode),
               âexitâ (request the master to exit), and âstopâ (request
               the master to stop accepting further multiplexing
               requests)."
1392,50,ssh,"Valid
               commands are: âcheckâ (check that the master process is
               running), âforwardâ (request forwardings without command
               execution), âcancelâ (cancel forwardings), âproxyâ
               (connect to a running multiplexing master in proxy mode),
               âexitâ (request the master to exit), and âstopâ (request
               the master to stop accepting further multiplexing
               requests). -o
option
Can be used to give options in the format used in the
               configuration file. This is useful for specifying options
               for which there is no separate command-line flag."
1392,51,ssh,"This is useful for specifying options
               for which there is no separate command-line flag. For
               full details of the options listed below, and their
               possible values, see
ssh_config
(5). AddKeysToAgent
                     AddressFamily
                     BatchMode
                     BindAddress
                     CanonicalDomains
                     CanonicalizeFallbackLocal
                     CanonicalizeHostname
                     CanonicalizeMaxDots
                     CanonicalizePermittedCNAMEs
                     CASignatureAlgorithms
                     CertificateFile
                     CheckHostIP
                     Ciphers
                     ClearAllForwardings
                     Compression
                     ConnectionAttempts
                     ConnectTimeout
                     ControlMaster
                     ControlPath
                     ControlPersist
                     DynamicForward
                     EnableEscapeCommandline
                     EscapeChar
                     ExitOnForwardFailure
                     FingerprintHash
                     ForkAfterAuthentication
                     ForwardAgent
                     ForwardX11
                     ForwardX11Timeout
                     ForwardX11Trusted
                     GatewayPorts
                     GlobalKnownHostsFile
                     GSSAPIAuthentication
                     GSSAPIDelegateCredentials
                     HashKnownHosts
                     Host
                     HostbasedAcceptedAlgorithms
                     HostbasedAuthentication
                     HostKeyAlgorithms
                     HostKeyAlias
                     Hostname
                     IdentitiesOnly
                     IdentityAgent
                     IdentityFile
                     IPQoS
                     KbdInteractiveAuthentication
                     KbdInteractiveDevices
                     KexAlgorithms
                     KnownHostsCommand
                     LocalCommand
                     LocalForward
                     LogLevel
                     MACs
                     Match
                     NoHostAuthenticationForLocalhost
                     NumberOfPasswordPrompts
                     PasswordAuthentication
                     PermitLocalCommand
                     PermitRemoteOpen
                     PKCS11Provider
                     Port
                     PreferredAuthentications
                     ProxyCommand
                     ProxyJump
                     ProxyUseFdpass
                     PubkeyAcceptedAlgorithms
                     PubkeyAuthentication
                     RekeyLimit
                     RemoteCommand
                     RemoteForward
                     RequestTTY
                     RequiredRSASize
                     SendEnv
                     ServerAliveInterval
                     ServerAliveCountMax
                     SessionType
                     SetEnv
                     StdinNull
                     StreamLocalBindMask
                     StreamLocalBindUnlink
                     StrictHostKeyChecking
                     TCPKeepAlive
                     Tunnel
                     TunnelDevice
                     UpdateHostKeys
                     User
                     UserKnownHostsFile
                     VerifyHostKeyDNS
                     VisualHostKey
                     XAuthLocation
-P
tag
Specify a tag name that may be used to select
               configuration in
ssh_config
(5)."
1392,52,ssh,"AddKeysToAgent
                     AddressFamily
                     BatchMode
                     BindAddress
                     CanonicalDomains
                     CanonicalizeFallbackLocal
                     CanonicalizeHostname
                     CanonicalizeMaxDots
                     CanonicalizePermittedCNAMEs
                     CASignatureAlgorithms
                     CertificateFile
                     CheckHostIP
                     Ciphers
                     ClearAllForwardings
                     Compression
                     ConnectionAttempts
                     ConnectTimeout
                     ControlMaster
                     ControlPath
                     ControlPersist
                     DynamicForward
                     EnableEscapeCommandline
                     EscapeChar
                     ExitOnForwardFailure
                     FingerprintHash
                     ForkAfterAuthentication
                     ForwardAgent
                     ForwardX11
                     ForwardX11Timeout
                     ForwardX11Trusted
                     GatewayPorts
                     GlobalKnownHostsFile
                     GSSAPIAuthentication
                     GSSAPIDelegateCredentials
                     HashKnownHosts
                     Host
                     HostbasedAcceptedAlgorithms
                     HostbasedAuthentication
                     HostKeyAlgorithms
                     HostKeyAlias
                     Hostname
                     IdentitiesOnly
                     IdentityAgent
                     IdentityFile
                     IPQoS
                     KbdInteractiveAuthentication
                     KbdInteractiveDevices
                     KexAlgorithms
                     KnownHostsCommand
                     LocalCommand
                     LocalForward
                     LogLevel
                     MACs
                     Match
                     NoHostAuthenticationForLocalhost
                     NumberOfPasswordPrompts
                     PasswordAuthentication
                     PermitLocalCommand
                     PermitRemoteOpen
                     PKCS11Provider
                     Port
                     PreferredAuthentications
                     ProxyCommand
                     ProxyJump
                     ProxyUseFdpass
                     PubkeyAcceptedAlgorithms
                     PubkeyAuthentication
                     RekeyLimit
                     RemoteCommand
                     RemoteForward
                     RequestTTY
                     RequiredRSASize
                     SendEnv
                     ServerAliveInterval
                     ServerAliveCountMax
                     SessionType
                     SetEnv
                     StdinNull
                     StreamLocalBindMask
                     StreamLocalBindUnlink
                     StrictHostKeyChecking
                     TCPKeepAlive
                     Tunnel
                     TunnelDevice
                     UpdateHostKeys
                     User
                     UserKnownHostsFile
                     VerifyHostKeyDNS
                     VisualHostKey
                     XAuthLocation
-P
tag
Specify a tag name that may be used to select
               configuration in
ssh_config
(5). Refer to the
Tag
and
Match
keywords in
ssh_config
(5) for more information. -p
port
Port to connect to on the remote host."
1392,53,ssh,"-p
port
Port to connect to on the remote host. This can be
               specified on a per-host basis in the configuration file. -Q
query_option
Queries for the algorithms supported by one of the
               following features:
cipher
(supported symmetric ciphers),
cipher-auth
(supported symmetric ciphers that support
               authenticated encryption),
help
(supported query terms for
               use with the
-Q
flag),
mac
(supported message integrity
               codes),
kex
(key exchange algorithms),
key
(key types),
key-ca-sign
(valid CA signature algorithms for
               certificates),
key-cert
(certificate key types),
key-plain
(non-certificate key types),
key-sig
(all key types and
               signature algorithms),
protocol-version
(supported SSH
               protocol versions), and
sig
(supported signature
               algorithms)."
1392,54,ssh,"-Q
query_option
Queries for the algorithms supported by one of the
               following features:
cipher
(supported symmetric ciphers),
cipher-auth
(supported symmetric ciphers that support
               authenticated encryption),
help
(supported query terms for
               use with the
-Q
flag),
mac
(supported message integrity
               codes),
kex
(key exchange algorithms),
key
(key types),
key-ca-sign
(valid CA signature algorithms for
               certificates),
key-cert
(certificate key types),
key-plain
(non-certificate key types),
key-sig
(all key types and
               signature algorithms),
protocol-version
(supported SSH
               protocol versions), and
sig
(supported signature
               algorithms). Alternatively, any keyword from
ssh_config
(5) or
sshd_config
(5) that takes an algorithm
               list may be used as an alias for the corresponding
               query_option. -q
Quiet mode."
1392,55,ssh,"-q
Quiet mode. Causes most warning and diagnostic messages
               to be suppressed. -R
[
bind_address
:]
port
:
host
:
hostport
-R
[
bind_address
:]
port
:
local_socket
-R
remote_socket
:
host
:
hostport
-R
remote_socket
:
local_socket
-R
[
bind_address
:]
port
Specifies that connections to the given TCP port or Unix
               socket on the remote (server) host are to be forwarded to
               the local side."
1392,56,ssh,"-R
[
bind_address
:]
port
:
host
:
hostport
-R
[
bind_address
:]
port
:
local_socket
-R
remote_socket
:
host
:
hostport
-R
remote_socket
:
local_socket
-R
[
bind_address
:]
port
Specifies that connections to the given TCP port or Unix
               socket on the remote (server) host are to be forwarded to
               the local side. This works by allocating a socket to listen to either a
               TCP
port
or to a Unix socket on the remote side. Whenever
               a connection is made to this port or Unix socket, the
               connection is forwarded over the secure channel, and a
               connection is made from the local machine to either an
               explicit destination specified by
host
port
hostport
, or
local_socket
, or, if no explicit destination was
               specified,
ssh
will act as a SOCKS 4/5 proxy and forward
               connections to the destinations requested by the remote
               SOCKS client."
1392,57,ssh,"Whenever
               a connection is made to this port or Unix socket, the
               connection is forwarded over the secure channel, and a
               connection is made from the local machine to either an
               explicit destination specified by
host
port
hostport
, or
local_socket
, or, if no explicit destination was
               specified,
ssh
will act as a SOCKS 4/5 proxy and forward
               connections to the destinations requested by the remote
               SOCKS client. Port forwardings can also be specified in the
               configuration file. Privileged ports can be forwarded
               only when logging in as root on the remote machine."
1392,58,ssh,"Privileged ports can be forwarded
               only when logging in as root on the remote machine. IPv6
               addresses can be specified by enclosing the address in
               square brackets. By default, TCP listening sockets on the server will be
               bound to the loopback interface only."
1392,59,ssh,"By default, TCP listening sockets on the server will be
               bound to the loopback interface only. This may be
               overridden by specifying a
bind_address
. An empty
bind_address
, or the address â*â, indicates that the
               remote socket should listen on all interfaces."
1392,60,ssh,"An empty
bind_address
, or the address â*â, indicates that the
               remote socket should listen on all interfaces. Specifying
               a remote
bind_address
will only succeed if the server's
GatewayPorts
option is enabled (see
sshd_config
(5)). If the
port
argument is â0â, the listen port will be
               dynamically allocated on the server and reported to the
               client at run time."
1392,61,ssh,"If the
port
argument is â0â, the listen port will be
               dynamically allocated on the server and reported to the
               client at run time. When used together with
-O forward
,
               the allocated port will be printed to the standard output. -S
ctl_path
Specifies the location of a control socket for connection
               sharing, or the string ânoneâ to disable connection
               sharing."
1392,62,ssh,"-S
ctl_path
Specifies the location of a control socket for connection
               sharing, or the string ânoneâ to disable connection
               sharing. Refer to the description of
ControlPath
and
ControlMaster
in
ssh_config
(5) for details. -s
May be used to request invocation of a subsystem on the
               remote system."
1392,63,ssh,"-s
May be used to request invocation of a subsystem on the
               remote system. Subsystems facilitate the use of SSH as a
               secure transport for other applications (e.g. sftp
(1))."
1392,64,ssh,"sftp
(1)). The subsystem is specified as the remote command. Refer
               to the description of
SessionType
in
ssh_config
(5) for
               details."
1392,65,ssh,"Refer
               to the description of
SessionType
in
ssh_config
(5) for
               details. -T
Disable pseudo-terminal allocation. -t
Force pseudo-terminal allocation."
1392,66,ssh,"-t
Force pseudo-terminal allocation. This can be used to
               execute arbitrary screen-based programs on a remote
               machine, which can be very useful, e.g. when implementing
               menu services."
1392,67,ssh,"when implementing
               menu services. Multiple
-t
options force tty allocation,
               even if
ssh
has no local tty. -V
Display the version number and exit."
1392,68,ssh,"-V
Display the version number and exit. -v
Verbose mode. Causes
ssh
to print debugging messages
               about its progress."
1392,69,ssh,"Causes
ssh
to print debugging messages
               about its progress. This is helpful in debugging
               connection, authentication, and configuration problems. Multiple
-v
options increase the verbosity."
1392,70,ssh,"Multiple
-v
options increase the verbosity. The maximum
               is 3. -W
host
:
port
Requests that standard input and output on the client be
               forwarded to
host
on
port
over the secure channel."
1392,71,ssh,"-W
host
:
port
Requests that standard input and output on the client be
               forwarded to
host
on
port
over the secure channel. Implies
-N
,
-T
,
ExitOnForwardFailure
and
ClearAllForwardings
, though these can be overridden in the
               configuration file or using
-o
command line options. -w
local_tun
[:
remote_tun
]
               Requests tunnel device forwarding with the specified
tun
(4) devices between the client (
local_tun
) and the
               server (
remote_tun
)."
1392,72,ssh,"-w
local_tun
[:
remote_tun
]
               Requests tunnel device forwarding with the specified
tun
(4) devices between the client (
local_tun
) and the
               server (
remote_tun
). The devices may be specified by numerical ID or the
               keyword âanyâ, which uses the next available tunnel
               device. If
remote_tun
is not specified, it defaults to
               âanyâ."
1392,73,ssh,"If
remote_tun
is not specified, it defaults to
               âanyâ. See also the
Tunnel
and
TunnelDevice
directives in
ssh_config
(5). If the
Tunnel
directive is unset, it will be set to the
               default tunnel mode, which is âpoint-to-pointâ."
1392,74,ssh,"If the
Tunnel
directive is unset, it will be set to the
               default tunnel mode, which is âpoint-to-pointâ. If a
               different
Tunnel
forwarding mode it desired, then it
               should be specified before
-w
. -X
Enables X11 forwarding."
1392,75,ssh,"-X
Enables X11 forwarding. This can also be specified on a
               per-host basis in a configuration file. X11 forwarding should be enabled with caution."
1392,76,ssh,"X11 forwarding should be enabled with caution. Users with
               the ability to bypass file permissions on the remote host
               (for the user's X authorization database) can access the
               local X11 display through the forwarded connection. An
               attacker may then be able to perform activities such as
               keystroke monitoring."
1392,77,ssh,"An
               attacker may then be able to perform activities such as
               keystroke monitoring. For this reason, X11 forwarding is subjected to X11
               SECURITY extension restrictions by default. Refer to the
ssh -Y
option and the
ForwardX11Trusted
directive in
ssh_config
(5) for more information."
1392,78,ssh,"Refer to the
ssh -Y
option and the
ForwardX11Trusted
directive in
ssh_config
(5) for more information. -x
Disables X11 forwarding. -Y
Enables trusted X11 forwarding."
1392,79,ssh,"-Y
Enables trusted X11 forwarding. Trusted X11 forwardings
               are not subjected to the X11 SECURITY extension controls. -y
Send log information using the
syslog
(3) system module."
1392,80,ssh,"-y
Send log information using the
syslog
(3) system module. By default this information is sent to stderr. ssh
may additionally obtain configuration data from a per-user
       configuration file and a system-wide configuration file."
1392,81,ssh,"By default this information is sent to stderr. ssh
may additionally obtain configuration data from a per-user
       configuration file and a system-wide configuration file. The file
       format and configuration options are described in
ssh_config
(5)."
1393,0,stap-jupyter,"ISystemtap is an interactive jupyter interface for the incremental
       writing and running of Systemtap scripts. The
stap-jupyter-install
program can be used to locally install
       the ISystemtap jupyter kernel, language-server and jupyter-lab
       extension in ~/.systemtap/jupyter. Once installed, the kernel can
       be used with
jupyter-lab
."
1393,1,stap-jupyter,"The
stap-jupyter-install
program can be used to locally install
       the ISystemtap jupyter kernel, language-server and jupyter-lab
       extension in ~/.systemtap/jupyter. Once installed, the kernel can
       be used with
jupyter-lab
. Alternatively the
stap-jupyter-container
program can be used to
       run ISystemtap within a container, preventing the need for any
       local jupyter kernel installation."
1394,0,stap-jupyter,"ISystemtap is an interactive jupyter interface for the incremental
       writing and running of Systemtap scripts. The
stap-jupyter-install
program can be used to locally install
       the ISystemtap jupyter kernel, language-server and jupyter-lab
       extension in ~/.systemtap/jupyter. Once installed, the kernel can
       be used with
jupyter-lab
."
1394,1,stap-jupyter,"The
stap-jupyter-install
program can be used to locally install
       the ISystemtap jupyter kernel, language-server and jupyter-lab
       extension in ~/.systemtap/jupyter. Once installed, the kernel can
       be used with
jupyter-lab
. Alternatively the
stap-jupyter-container
program can be used to
       run ISystemtap within a container, preventing the need for any
       local jupyter kernel installation."
1395,0,stap-report,"The stap-report executable collects system information that is
       useful for debugging systemtap bugs. It is a good idea to include
       such a report in bug reports especially if you send them directly
       to the upstream. stap-report can be run either as a normal user or
       as root."
1395,1,stap-report,"It is a good idea to include
       such a report in bug reports especially if you send them directly
       to the upstream. stap-report can be run either as a normal user or
       as root. The report will be more complete if stap-report is run as
       root."
1396,0,stapref,The reference for the systemtap scripting language.
1397,0,stap-jupyter,"ISystemtap is an interactive jupyter interface for the incremental
       writing and running of Systemtap scripts. The
stap-jupyter-install
program can be used to locally install
       the ISystemtap jupyter kernel, language-server and jupyter-lab
       extension in ~/.systemtap/jupyter. Once installed, the kernel can
       be used with
jupyter-lab
."
1397,1,stap-jupyter,"The
stap-jupyter-install
program can be used to locally install
       the ISystemtap jupyter kernel, language-server and jupyter-lab
       extension in ~/.systemtap/jupyter. Once installed, the kernel can
       be used with
jupyter-lab
. Alternatively the
stap-jupyter-container
program can be used to
       run ISystemtap within a container, preventing the need for any
       local jupyter kernel installation."
1398,0,stapvirt,"The
stapvirt
program can be used to add ports to domains managed
       by libvirt (see <
http://libvirt.org/
>). These ports can then be
       used by
stap
to run scripts inside the domains (see the '--remote'
       option in
stap(1)
for more information). Ports are added to the definition of the domain using the
port-add
command."
1398,1,stapvirt,"Ports are added to the definition of the domain using the
port-add
command. These ports can later be removed using the
port-remove
command. Note that there can only be as many simultaneous
stap
sessions as there are ports."
1398,2,stapvirt,"Note that there can only be as many simultaneous
stap
sessions as there are ports. Starting from libvirt v1.1.1 and QEMU v0.10.0, SystemTap ports can
       be hotplugged and thus do not need to be added first using the
port-add
command. However, you need to ensure that there is a
       virtio-serial controller in place so that hotplugged ports can be
       connected."
1398,3,stapvirt,"However, you need to ensure that there is a
       virtio-serial controller in place so that hotplugged ports can be
       connected. If creating a domain using virt-install, you can do
       this by adding this option:
$
virt-install [...] --controller=virtio-serial

       If the domain has already been created, you can simply do
port-add
followed immediately by
port-remove
, and then power off and
       restart the domain. The port will be removed, but the controller
       will remain."
1399,0,stat,"Display file or file system status. Mandatory arguments to long options are mandatory for short
       options too. -L
,
--dereference
follow links
-f
,
--file-system
display file system status instead of file status
--cached
=
MODE
specify how to use cached attributes; useful on remote file
              systems."
1399,1,stat,"-L
,
--dereference
follow links
-f
,
--file-system
display file system status instead of file status
--cached
=
MODE
specify how to use cached attributes; useful on remote file
              systems. See MODE below
-c  --format
=
FORMAT
use the specified FORMAT instead of the default; output a
              newline after each use of FORMAT
--printf
=
FORMAT
like
--format
, but interpret backslash escapes, and do not
              output a mandatory trailing newline; if you want a newline,
              include \n in FORMAT
-t
,
--terse
print the information in terse form
--help
display this help and exit
--version
output version information and exit

       The MODE argument of
--cached
can be: always, never, or default. 'always' will use cached attributes if available, while 'never'
       will try to synchronize with the latest attributes, and 'default'
       will leave it up to the underlying file system."
1399,2,stat,"'always' will use cached attributes if available, while 'never'
       will try to synchronize with the latest attributes, and 'default'
       will leave it up to the underlying file system. The valid format sequences for files (without
--file-system
):

       %a     permission bits in octal (see '#' and '0' printf flags)

       %A     permission bits and file type in human readable form

       %b     number of blocks allocated (see %B)

       %B     the size in bytes of each block reported by %b

       %C     SELinux security context string

       %d     device number in decimal (st_dev)

       %D     device number in hex (st_dev)

       %Hd    major device number in decimal

       %Ld    minor device number in decimal

       %f     raw mode in hex

       %F     file type

       %g     group ID of owner

       %G     group name of owner

       %h     number of hard links

       %i     inode number

       %m     mount point

       %n     file name

       %N     quoted file name with dereference if symbolic link

       %o     optimal I/O transfer size hint

       %s     total size, in bytes

       %r     device type in decimal (st_rdev)

       %R     device type in hex (st_rdev)

       %Hr    major device type in decimal, for character/block device
              special files

       %Lr    minor device type in decimal, for character/block device
              special files

       %t     major device type in hex, for character/block device
              special files

       %T     minor device type in hex, for character/block device
              special files

       %u     user ID of owner

       %U     user name of owner

       %w     time of file birth, human-readable; - if unknown

       %W     time of file birth, seconds since Epoch; 0 if unknown

       %x     time of last access, human-readable

       %X     time of last access, seconds since Epoch

       %y     time of last data modification, human-readable

       %Y     time of last data modification, seconds since Epoch

       %z     time of last status change, human-readable

       %Z     time of last status change, seconds since Epoch

       Valid format sequences for file systems:

       %a     free blocks available to non-superuser

       %b     total data blocks in file system

       %c     total file nodes in file system

       %d     free file nodes in file system

       %f     free blocks in file system

       %i     file system ID in hex

       %l     maximum length of filenames

       %n     file name

       %s     block size (for faster transfers)

       %S     fundamental block size (for block counts)

       %t     file system type in hex

       %T     file system type in human readable form
--terse is equivalent to the following FORMAT:
%n %s %b %f %u %g %D %i %h %t %T %X %Y %Z %W %o %C
--terse --file-system is equivalent to the following FORMAT:
%n %i %l %t %s %S %b %f %a %c %d

       Your shell may have its own version of stat, which usually
       supersedes the version described here. Please refer to your
       shell's documentation for details about the options it supports."
1400,0,stap-merge,"The stap-merge executable applies when the -b option has been used
       while running a
stap
script.  The -b option will generate files
       per-cpu, based on the timestamp field. Then stap-merge will merge
       and sort through the per-cpu files based on the timestamp field."
1401,0,stg-branch,"Create, clone, switch, rename, or delete StGit-enabled branches. With no arguments, the current branch is printed to stdout. With a single argument, switch to the named branch."
1401,1,stg-branch,"With a single argument, switch to the named branch. StGit supports specifying a branch using the
@{-<n>}
syntax
       supported by git, including
-
as a synonym for
@{-1}
. Thus
stg
branch -
may be used to switch to the last checked-out HEAD."
1401,2,stg-branch,"Thus
stg
branch -
may be used to switch to the last checked-out HEAD. Note
       that
@{-<n>}
refers to the <n>th last HEAD, which is not
       necessarily a local branch. Using an
@{-<n>}
value that refers to
       anything but a local branch will result in an error."
1402,0,stdbuf,"Run COMMAND, with modified buffering operations for its standard
       streams. Mandatory arguments to long options are mandatory for short
       options too. -i
,
--input
=
MODE
adjust standard input stream buffering
-o
,
--output
=
MODE
adjust standard output stream buffering
-e
,
--error
=
MODE
adjust standard error stream buffering
--help
display this help and exit
--version
output version information and exit

       If MODE is 'L' the corresponding stream will be line buffered."
1402,1,stdbuf,"-i
,
--input
=
MODE
adjust standard input stream buffering
-o
,
--output
=
MODE
adjust standard output stream buffering
-e
,
--error
=
MODE
adjust standard error stream buffering
--help
display this help and exit
--version
output version information and exit

       If MODE is 'L' the corresponding stream will be line buffered. This option is invalid with standard input. If MODE is '0' the corresponding stream will be unbuffered."
1402,2,stdbuf,"If MODE is '0' the corresponding stream will be unbuffered. Otherwise MODE is a number which may be followed by one of the
       following: KB 1000, K 1024, MB 1000*1000, M 1024*1024, and so on
       for G,T,P,E,Z,Y,R,Q. Binary prefixes can be used, too: KiB=K,
       MiB=M, and so on."
1402,3,stdbuf,"Binary prefixes can be used, too: KiB=K,
       MiB=M, and so on. In this case the corresponding stream will be
       fully buffered with the buffer size set to MODE bytes. NOTE: If COMMAND adjusts the buffering of its standard streams
       ('tee' does for example) then that will override corresponding
       changes by 'stdbuf'."
1402,4,stdbuf,"NOTE: If COMMAND adjusts the buffering of its standard streams
       ('tee' does for example) then that will override corresponding
       changes by 'stdbuf'. Also some filters (like 'dd' and 'cat' etc.)
       don't use streams for I/O, and are thus unaffected by 'stdbuf'
       settings. Exit status:
125    if the stdbuf command itself fails

       126    if COMMAND is found but cannot be invoked

       127    if COMMAND cannot be found

       -      the exit status of COMMAND otherwise"
1403,0,stap,"The
stap
program is the front-end to the Systemtap tool. It
       accepts probing instructions written in a simple domain-specific
       language, translates those instructions into C code, compiles this
       C code, and loads the resulting module into a running Linux kernel
       or a Dyninst user-space mutator, to perform the requested system
       trace/probe functions. You can supply the script in a named file
       (FILENAME), from standard input (use - instead of FILENAME), or
       from the command line (using -e SCRIPT)."
1403,1,stap,"You can supply the script in a named file
       (FILENAME), from standard input (use - instead of FILENAME), or
       from the command line (using -e SCRIPT). The program runs until
       it is interrupted by the user, or if the script voluntarily
       invokes the
exit()
function, or by sufficient number of soft
       errors. The language, which is described the
SCRIPT LANGUAGE
section
       below, is strictly typed, expressive, declaration free,
       procedural, prototyping-friendly, and inspired by
awk
and
C
."
1403,2,stap,"The language, which is described the
SCRIPT LANGUAGE
section
       below, is strictly typed, expressive, declaration free,
       procedural, prototyping-friendly, and inspired by
awk
and
C
. It
       allows source code points or events in the system to be associated
       with handlers, which are subroutines that are executed
       synchronously. It is somewhat similar conceptually to ""breakpoint
       command lists"" in the
gdb
debugger."
1404,0,stap-prep,"The stap-prep executable prepares the system for systemtap use by
       installing kernel headers, debug symbols and build tools that
       match the currently running kernel or optionally the kernel
       version given by the user. If the debuginfod-find tool is installed and is able to fetch
       debuginfo for a kernel component, it is assumed to remain
       available later. In this case, no debug symbols will be
       downloaded during stap-prep."
1404,1,stap-prep,"In this case, no debug symbols will be
       downloaded during stap-prep. The exact behavior of stap-prep may be customized by the
       distribution maintainers. It might for example only give
       suggestions and not actually install the required packages if that
       is difficult to automate."
1405,0,stg-clean,"Delete the empty patches from the entire series by default, or
       only empty patches from the applied or unapplied patches. A patch
       is considered empty if its tree is the same as its parent."
1406,0,stg-commit,"Finalize one or more patches into the base of the current stack
       and remove them from the series. This is the opposite of
stg-uncommit(1)
. Use this command when a patch is completed and no
       longer needs to be managed with StGit."
1406,1,stg-commit,"Use this command when a patch is completed and no
       longer needs to be managed with StGit. By default, the bottommost patch is committed. If patch names are
       given, the stack is rearranged so that those patches are at the
       bottom, and then they are committed."
1406,2,stg-commit,"If patch names are
       given, the stack is rearranged so that those patches are at the
       bottom, and then they are committed. The -n/--number option specifies the number of applied patches to
       commit (counting from the bottom of the stack). If -a/--all is
       given, all applied patches are committed."
1407,0,stg-completion,"Support completions for bash, fish, and zsh. Also provides
stg
completion list
command for dynamically introspecting StGitâs
       commands and aliases."
1408,0,stg-delete,Delete patches
1409,0,stg-diff,"Show the diff (default) or diffstat between the current working
       copy or a tree-ish object and another tree-ish object (defaulting
       to HEAD). File names can also be given to restrict the diff
       output. The tree-ish object has the format accepted by the
stg-id(1)
command."
1410,0,stg-edit,"Edit a patch. Various aspects of a patch may be edited, including
       the message, author, patch name, or even the patchâs diff. By default, the topmost patch is edited."
1410,1,stg-edit,"By default, the topmost patch is edited. With no options or when
--edit
is specified, the patch details are
       edited interactively. Alternatively, command line options may be
       used to modify the patch non-interactively."
1410,2,stg-edit,"Alternatively, command line options may be
       used to modify the patch non-interactively. The
--diff
option causes the patchâs diff to be appended to the
       patch description when editing interactively. This diff may be
       edited interactively (or just used as a reference when editing the
       patchâs message)."
1410,3,stg-edit,"This diff may be
       edited interactively (or just used as a reference when editing the
       patchâs message). The StGit attempts to apply the modified diff to
       the patchâs parent tree. If the updated diff does not apply, no
       changes are made to the patch and the edited patch is saved to a
       file which may be corrected and then fed-back into
stg edit
--file
."
1411,0,stg-export,"Export a range of patches to a given directory in unified diff
       format. All applied patches are exported by default. Patches are exported to
patches-<branch>
by default."
1411,1,stg-export,"Patches are exported to
patches-<branch>
by default. The
--dir
option may be used to specify a different output directory. The patch file output may be customized via a template file found
       at ""$GIT_DIR/patchexport.tmpl"",
       ""~/.stgit/templates/patchexport.tmpl"", or
       ""$(prefix)/share/stgit/templates""."
1411,2,stg-export,"The
--dir
option may be used to specify a different output directory. The patch file output may be customized via a template file found
       at ""$GIT_DIR/patchexport.tmpl"",
       ""~/.stgit/templates/patchexport.tmpl"", or
       ""$(prefix)/share/stgit/templates"". The following variables are
       supported in the template file:

           %(description)s - patch description
           %(shortdescr)s  - the first line of the patch description
           %(longdescr)s   - the rest of the patch description, after the first line
           %(diffstat)s    - the diff statistics
           %(authname)s    - author name
           %(authemail)s   - author email
           %(authdate)s    - patch creation date (ISO-8601 format)
           %(commname)s    - committer name
           %(commemail)s   - committer email"
1412,0,stg-files,"Show the files modified by a patch. The files of the topmost patch
       are shown by default. Passing the
--stat
option shows the diff
       statistics for the given patch."
1412,1,stg-files,"Passing the
--stat
option shows the diff
       statistics for the given patch. Note that this command does not
       show the files modified in the working tree and not yet included
       in the patch by a
refresh
command. Use the
diff
or
status
commands
       to show these files."
1413,0,stg-float,"Push patches to the top, even if applied. Float one or more patches to be the topmost applied patches. The
       patches to be floated may currently be either applied or
       unapplied."
1413,1,stg-float,"The
       patches to be floated may currently be either applied or
       unapplied. The necessary pop and push operations will be performed
       to float the named patches. Patches not specified will remain
       applied or unapplied as they were prior to the float operation."
1414,0,stg-email,"Format and send patches as email. A typical workflow is to first generate email files for each patch
       along with an optional cover letter using âstg email format
. Then,
after checking the email filesâ contents, sending the emails using
`stg email send
."
1414,1,stg-email,"Then,
after checking the email filesâ contents, sending the emails using
`stg email send
. This workflow may be condensed to one step by
       specifying patch names to
stg email send
instead of email files. The
format
and
send
subcommands are thin wrappers over
git
format-patch
and
git send-email
, respectively."
1414,2,stg-email,"This workflow may be condensed to one step by
       specifying patch names to
stg email send
instead of email files. The
format
and
send
subcommands are thin wrappers over
git
format-patch
and
git send-email
, respectively. Refer to the
git-format-patch(1)
and
git-send-email(1)
manpages for more
       details about configuration and options."
1415,0,stg-fold,"Fold diff file into the current patch. The given GNU diff file (or
       standard input) is applied onto the current patch. With the
--threeway
option, the diff is applied onto the bottom of
       the current patch and a three-way merge is performed with the
       current top."
1415,1,stg-fold,"The given GNU diff file (or
       standard input) is applied onto the current patch. With the
--threeway
option, the diff is applied onto the bottom of
       the current patch and a three-way merge is performed with the
       current top. With the
--base
option, the diff is applied onto the
       specified base and a three-way merge is performed with the current
       top."
1416,0,stg-goto,Go to patch by pushing or popping as necessary
1417,0,stg-id,"Print the hash (object id) of a StGit revision. In addition to standard Git revision specifiers (revspecs),
       patches may be of a stack. If no branch is specified, the current
       branch is used by default."
1417,1,stg-id,"In addition to standard Git revision specifiers (revspecs),
       patches may be of a stack. If no branch is specified, the current
       branch is used by default. The parent of a patch may be specified
       with
[<branch>:]<patch>^
."
1418,0,stg-hide,"Hide patches in the series.

       Hidden patches are no longer shown in the plain
series
output."
1419,0,stg-help,Print this message or the help of the given subcommand(s)
1420,0,stg-import,"Import patches from various sources to the stack. The simplest usage is to import a diff/patch file into the stack
       from a local file. By default, the file name is used as the patch
       name, but this can be overridden with
--name
."
1420,1,stg-import,"By default, the file name is used as the patch
       name, but this can be overridden with
--name
. The patch can either
       be a normal file with the description at the top, or it can have
       standard mail format. The ""Subject"", ""From"", and ""Date"" headers
       will be used for the imported patchâs author details."
1420,2,stg-import,"The ""Subject"", ""From"", and ""Date"" headers
       will be used for the imported patchâs author details. Patches may also be imported from a mail file (-m/--mail), an mbox
       (-M/--mbox), or a series (-S/--series). Furthermore, the -u/--url
       option allows the patches source to be fetched from a url instead
       of from a local file."
1420,3,stg-import,"Furthermore, the -u/--url
       option allows the patches source to be fetched from a url instead
       of from a local file. If a patch does not apply cleanly import is aborted unless
--reject
is specified, in which case it will apply to the work
       tree the parts of the patch that are applicable, leave the
       rejected hunks in corresponding *.rej files, and add an empty
       patch to the stack. The patch description must be separated from the diff with a ""---""
       line."
1421,0,stg-init,"Initialize a StGit stack on a branch. Initializing a branch with a StGit stack commits initial, empty
       stack state for the branch to the repository. Theses stack
       metadata commits are tracked by the
refs/stacks/<branch>
reference."
1421,1,stg-init,"Theses stack
       metadata commits are tracked by the
refs/stacks/<branch>
reference. Updated stack state is committed by each StGit command
       that modifies the stack. StGit users do not have to do anything
       with the
refs/stacks/<branch>
ref directly."
1421,2,stg-init,"StGit users do not have to do anything
       with the
refs/stacks/<branch>
ref directly. Some StGit commands, such as
stg new
and
stg uncommit
, will
       automatically initialize the stack, so it is often not necessary
       to explicitly initialize the stack on a branch. Also, branches
       created with
stg branch --create
are automatically initialized."
1421,3,stg-init,"Also, branches
       created with
stg branch --create
are automatically initialized. The branch must already exist and point to a commit before
       initializing a StGit stack. StGit stack metadata can be deinitialized from a branch using
stg
branch --cleanup
."
1421,4,stg-init,"The branch must already exist and point to a commit before
       initializing a StGit stack. StGit stack metadata can be deinitialized from a branch using
stg
branch --cleanup
. See
stg-branch(1)
for more details."
1422,0,stg-new,"Create a new, empty patch on the current stack. The new patch is
       created on top of the currently applied patches, and is made the
       new top of the stack. Uncommitted changes in the work tree are not
       included in the patch â that is handled by stg-refresh."
1422,1,stg-new,"Uncommitted changes in the work tree are not
       included in the patch â that is handled by stg-refresh. The given patch name must be unique in the stack. If no name is
       given, one is generated from the first line of the patchâs commit
       message."
1422,2,stg-new,"If no name is
       given, one is generated from the first line of the patchâs commit
       message. Patch names follow the rules for Git references with the
       additional constraint that patch names may not contain the
/
character. See
git-check-ref-format(1)
for details."
1422,3,stg-new,"See
git-check-ref-format(1)
for details. Patch names may start with a leading
-
. When specifying such a
       patch name on the command line, the leading
-
may be escaped with
       a single backslash as in
\-patch-name
to disambiguate the patch
       name from command line options."
1422,4,stg-new,"When specifying such a
       patch name on the command line, the leading
-
may be escaped with
       a single backslash as in
\-patch-name
to disambiguate the patch
       name from command line options. An editor will be launched to edit the commit message to be used
       for the patch, unless the
--message
flag already specified one. The
patchdescr.tmpl
template file (if available) is used to
       pre-fill the editor."
1423,0,stg-log,"Show the history of changes to the stack. If one or more patch
       names are given, only the changes affecting those patches are
       shown. The
stg-undo(1)
and
stg-redo(1)
commands may be used to step back
       and forth through historical stack states."
1423,1,stg-log,"The
stg-undo(1)
and
stg-redo(1)
commands may be used to step back
       and forth through historical stack states. The
stg-reset(1)
command may be used to reset the stack directly to a historic
       state. The
--clear
option may be used to delete the stackâs change
       history."
1423,2,stg-log,"The
--clear
option may be used to delete the stackâs change
       history. Undo and redo are unavailable on a stack without change
       history. Clearing the stack state history cannot be undone."
1424,0,stg-name,"Print the patch name of a StGit revision.

       Try to get the name of the patch in the current branch as
       specified by a StGit revision. Revisions can be specified in the
       all the forms accepted by ""stg id"" command."
1425,0,stg-next,"Print the name of the next patch.

       The next patch is the unapplied patch that follows the current,
       topmost patch. An error message will be printed if there are no
       unapplied patches."
1426,0,stg-patches,"Show the applied patches modifying the given paths. Without path
       arguments, the files modified in the working tree are used as the
       paths."
1427,0,stg-pick,"Import one or more patches from another branch or commit object
       into the current series. By default, the imported patchâs name is reused, but may be
       overridden with the
--name
option. A commit object can be reverted
       with the
--revert
option."
1427,1,stg-pick,"A commit object can be reverted
       with the
--revert
option. When using the
--expose
option, the format of the commit message
       is determined by the
stgit.pick.expose-format
configuration
       option. This option is a format string as may be supplied to the
--pretty
option of
git-show(1)
."
1427,2,stg-pick,"When using the
--expose
option, the format of the commit message
       is determined by the
stgit.pick.expose-format
configuration
       option. This option is a format string as may be supplied to the
--pretty
option of
git-show(1)
. The default is
       ""format:%B%n(imported from commit %H)"", which appends the commit
       hash of the picked commit to the patchâs commit message."
1428,0,stg-pull,"Pull the latest changes from a remote repository. The remote repository may be specified on the command line, but
       defaults to branch.<name>.remote from the git configuration, or
       ""origin"" if not configured. This command works by popping all currently applied patches from
       the stack, pulling the changes from the remote repository,
       updating the stack base to the new remote HEAD, and finally
       pushing all formerly applied patches back onto the stack."
1428,1,stg-pull,"This command works by popping all currently applied patches from
       the stack, pulling the changes from the remote repository,
       updating the stack base to the new remote HEAD, and finally
       pushing all formerly applied patches back onto the stack. Merge
       conflicts may occur during the final push step. Those conflicts
       need to be resolved manually."
1428,2,stg-pull,"Merge
       conflicts may occur during the final push step. Those conflicts
       need to be resolved manually. See
git-fetch(1)
for the format of remote repository argument."
1429,0,stg-pop,"Pop (unapply) one or more applied patches. By default, the topmost applied patch is popped. If ranges of patches are specified, pop and push operations are
       performed such that only the patches specified on the command line
       are unapplied at the end of the operation."
1429,1,stg-pop,"By default, the topmost applied patch is popped. If ranges of patches are specified, pop and push operations are
       performed such that only the patches specified on the command line
       are unapplied at the end of the operation. It is possible for some
       of these intermediate push operations to fail due to conflicts if
       patches are popped out of last-pushed first-popped order."
1430,0,stg-prev,"Print the name of the previous patch.

       The previous patch is the applied patch preceding the current,
       topmost patch. An error message will be printed if not enough
       patches are applied."
1431,0,stg-push,"Push one or more unapplied patches from the series onto the stack. By default, the first unapplied patch is pushed. Unapplied patches may be pushed in arbitrary order, but out of
       order pushes may result in merge conflicts."
1431,1,stg-push,"Unapplied patches may be pushed in arbitrary order, but out of
       order pushes may result in merge conflicts. If there are conflicts
       while pushing a patch, the conflicts are written to the work tree
       and the push command halts. Conflicts may then be resolved using
       the normal Git methods, or alternatively the push may be undone
       using
stg-undo(1)
."
1432,0,stg-rebase,"Pop all patches from the current stack, move the stack base to the
       given new base and push the patches back.

       Merge conflicts may arise when patches are being pushed-back onto
       the stack. If this occurs, resolve the conflicts and then continue
       the rebase with the following sequence:

           stg add --update
           stg refresh
           stg goto top-patch

       Or to skip the conflicting patch:

           stg undo --hard
           stg push next-patch..top-patch"
1433,0,stg-refresh,"Include the latest work tree and index changes in the current
       patch. This command generates a new git commit object for the
       patch; the old commit is no longer visible. Refresh will warn if the index is dirty, and require use of either
       the
--index
or
--force
options to override this check."
1433,1,stg-refresh,"Refresh will warn if the index is dirty, and require use of either
       the
--index
or
--force
options to override this check. This is to
       prevent accidental full refresh when only some changes were staged
       using git add interactive mode. You may optionally list one or more files or directories relative
       to the current working directory; if you do, only matching files
       will be updated."
1433,2,stg-refresh,"You may optionally list one or more files or directories relative
       to the current working directory; if you do, only matching files
       will be updated. Behind the scenes, stg refresh first creates a new temporary patch
       with your updates, and then merges that patch into the patch you
       asked to have refreshed. If you asked to refresh a patch other
       than the topmost patch, there can be conflicts; in that case, the
       temporary patch will be left for you to take care of, for example
       with stg squash."
1433,3,stg-refresh,"Behind the scenes, stg refresh first creates a new temporary patch
       with your updates, and then merges that patch into the patch you
       asked to have refreshed. If you asked to refresh a patch other
       than the topmost patch, there can be conflicts; in that case, the
       temporary patch will be left for you to take care of, for example
       with stg squash. The creation of the temporary patch is recorded in a separate
       entry in the patch stack log; this means that one undo step will
       undo the merge between the other patch and the temp patch, and two
       undo steps will additionally get rid of the temp patch."
1434,0,stg-redo,"If the last command was an undo, the patch stack state will be
       reset to its state before the undo. Consecutive redos will undo
       the effects of consecutive invocations of
stg-undo(1)
.

       It is an error to redo if the last stack-modifying command was not
       an undo."
1435,0,stg-repair,"If a branch with a StGit stack is modified with certain git
       commands such as
git-commit(1)
,
git-pull(1)
,
git-merge(1)
, or
git-rebase(1)
, the StGit stack metadata will become inconsistent
       with the branch state. There are a few options for resolving this
       kind of situation:

        1. Use
stg-undo(1)
to undo the effect of the git commands."
1435,1,stg-repair,"Use
stg-undo(1)
to undo the effect of the git commands. Or
           similarly use
stg-reset(1)
to reset the stack/branch to any
           previous stack state. 2."
1435,2,stg-repair,"2. Use
stg repair
. This will repair the StGit stack metadata to
           accommodate the modifications to the branch made by the git
           commands."
1435,3,stg-repair,"This will repair the StGit stack metadata to
           accommodate the modifications to the branch made by the git
           commands. Specifically, it will do the following:

           â¢   If regular git commits were made on top of the stack of
               StGit patches (i.e. by using plain
git commit
),
stg repair
will convert those commits to StGit patches, preserving
               their content."
1435,4,stg-repair,"by using plain
git commit
),
stg repair
will convert those commits to StGit patches, preserving
               their content. â¢   However, merge commits cannot become patches. So if a
               merge was committed on top of the stack,
stg repair
will
               mark all patches below the merge commit as unapplied,
               since they are no longer reachable."
1435,5,stg-repair,"So if a
               merge was committed on top of the stack,
stg repair
will
               mark all patches below the merge commit as unapplied,
               since they are no longer reachable. An alternative when
               this is not the desired behavior is to use
stg undo
to
               first get rid of the offending merge and then run
stg
repair
again. â¢   The applied patches are supposed to be precisely those
               that are reachable from the branch head."
1435,6,stg-repair,"â¢   The applied patches are supposed to be precisely those
               that are reachable from the branch head. If, for example,
git-reset(1)
was used to move the head, some applied
               patches may no longer be reachable and some unapplied
               patches may have become reachable. In this case,
stg
repair
will correct the applied/unapplied state of such
               patches."
1435,7,stg-repair,"In this case,
stg
repair
will correct the applied/unapplied state of such
               patches. stg repair
will repair these inconsistencies reliably, so there
       are valid workflows where git commands are used followed by
stg
repair
. For example, new patches can be created by first making
       commits with a graphical commit tool and then running
stg repair
to convert those commits into patches."
1436,0,stg-rename,"Rename [old-patch] to <new-patch>. If [old-patch] is not given,
       the topmost patch will be renamed."
1437,0,stg-reset,"Reset the patch stack to an earlier state. If no state is
       specified, reset only the changes in the worktree. The state is specified with a commit id from the stack log, which
       may be viewed with
stg-log(1)
."
1437,1,stg-reset,"If no state is
       specified, reset only the changes in the worktree. The state is specified with a commit id from the stack log, which
       may be viewed with
stg-log(1)
. Patch name arguments may optionally
       be provided to limit which patches are reset."
1438,0,stg-show,"Show the commit log and diff corresponding to the given patches.
       The topmost patch is shown by default, or HEAD if no patches are
       applied. The output is similar to
git-show(1)
."
1439,0,stg-series,"Show all the patches in the series, or just those in the given
       range, ordered from bottom to top. The topmost applied patch is prefixed with
>
. All other applied
       patches are prefixed with
+
."
1439,1,stg-series,"All other applied
       patches are prefixed with
+
. Unapplied patches are prefixed with
-
and hidden patches with
! ."
1439,2,stg-series,". The --reverse option may be used to reverse the order in which
       patches are displayed. The reversed order is more stack-like, with
       the base of the stack appearing at the bottom of of the display."
1439,3,stg-series,"The --reverse option may be used to reverse the order in which
       patches are displayed. The reversed order is more stack-like, with
       the base of the stack appearing at the bottom of of the display. Empty patches are prefixed with a
*
when the --empty option is
       used."
1440,0,stg-sink,"Move the specified patches down the stack. If no patch is specified on the command line, the current
       (topmost) patch is sunk. By default, patches are sunk to the
       bottom of the stack, but the
--above
or
--below
(alias
--to
)
       options may be used to place them above or below any applied
       patch."
1440,1,stg-sink,"By default, patches are sunk to the
       bottom of the stack, but the
--above
or
--below
(alias
--to
)
       options may be used to place them above or below any applied
       patch. Internally, sinking involves popping all patches to the bottom (or
       to the target patch if
--above
or
--below
is used), then pushing
       the patches to sink, and then, unless
--nopush
is specified,
       pushing back any other formerly applied patches. Sinking may be useful, for example, to group stable patches at the
       bottom of the stack where they less likely to be impacted by the
       push of another patch, and from where they can be more easily
       committed or pushed to another repository."
1441,0,stg-squash,"Squash two or more patches, creating one patch with their combined
       changes. The squash process, at a high level:

        1. Pop all the given patches, plus any other patches on top of
           them."
1441,1,stg-squash,"Pop all the given patches, plus any other patches on top of
           them. 2. Push the given patches in the order they were given on the
           command line."
1441,2,stg-squash,"Push the given patches in the order they were given on the
           command line. This establishes a tree containing the combined
           changes from the given patches. 3."
1441,3,stg-squash,"3. Replace given patches with a new, squashed patch. 4."
1441,4,stg-squash,"4. Allow the user to interactively edit the commit message of the
           new, squashed patch. 5."
1441,5,stg-squash,"5. Push other patches that were popped in step (1), if any. Conflicts can occur whenever a patch is pushed; this is, in steps
       (2) and (5)."
1441,6,stg-squash,"Push other patches that were popped in step (1), if any. Conflicts can occur whenever a patch is pushed; this is, in steps
       (2) and (5). If conflicts occur, the squash command will halt such
       that the conflicts may be resolved manually."
1442,0,stg-spill,"Spill changes from the topmost patch. Changes are removed from the
       patch, but remain in the index and worktree.

       Spilling a patch may be useful for reselecting the files/hunks to
       be included in the patch."
1443,0,stg-top,"Print the name of the top patch.

       The topmost patch is the currently applied patch. An error message
       will be printed if no patches are applied."
1444,0,stg-sync,"For each of the specified patches, perform a three-way merge with
       the same patch in the specified branch or series. The command can
       be used for keeping patches on several branches in sync. Note that
       the operation may fail for some patches because of conflicts."
1444,1,stg-sync,"The command can
       be used for keeping patches on several branches in sync. Note that
       the operation may fail for some patches because of conflicts. The
       patches in the series must apply cleanly."
1445,0,stg-uncommit,"Convert one or more Git commits from the base of the current stack
       into StGit patches. The original Git commits are not modified; the
       StGit stack extends to incorporate these commits as the bottommost
       applied patches. This is the opposite of
stg-commit(1)
."
1445,1,stg-uncommit,"This is the opposite of
stg-commit(1)
. By default, the number of patches to uncommit is determined by the
       number of patch names provided on the command line. The first
       provided name is used for the first patch to uncommit, i.e."
1445,2,stg-uncommit,"The first
       provided name is used for the first patch to uncommit, i.e. for
       the newest patch. The -n/--number option specifies the number of patches to
       uncommit."
1445,3,stg-uncommit,"The -n/--number option specifies the number of patches to
       uncommit. In this case, at most one patch name may be specified. It is used as prefix to which the patch number is appended."
1445,4,stg-uncommit,"It is used as prefix to which the patch number is appended. If no
       patch names are provided on the command line, StGit automatically
       generates names based on the first lines of the commit messages. The -t/--to option specifies that all commits up to and including
       the given commit should be uncommitted."
1445,5,stg-uncommit,"The -t/--to option specifies that all commits up to and including
       the given commit should be uncommitted. The -x/--exclusive option
       may be used to exclude the ""to"" commit. Only commits with exactly one parent can be uncommitted; in other
       words, merge commits may not be uncommitted."
1446,0,stg-unhide,"Unhide hidden patches in the series.

       Hidden patches are no longer shown in the plain
series
output."
1447,0,stg-undo,"Reset the patch stack to the state before the last operation.
       Consecutive undos will go back to yet older stack states."
1448,0,stg-version,Print version information and exit
1449,0,strace-log-merge,"strace-log-merge
merges the output of
strace -ff -tt[t]
command,
       prepending PID to each line and sorting the result using time
       stamp as a key."
1450,0,strings,"For each
file
given, GNU
strings
prints the printable character
       sequences that are at least 4 characters long (or the number given
       with the options below) and are followed by an unprintable
       character. Depending upon how the strings program was configured it will
       default to either displaying all the printable sequences that it
       can find in each file, or only those sequences that are in
       loadable, initialized data sections. If the file type is
       unrecognizable, or if strings is reading from stdin then it will
       always display all of the printable sequences that it can find."
1450,1,strings,"If the file type is
       unrecognizable, or if strings is reading from stdin then it will
       always display all of the printable sequences that it can find. For backwards compatibility any file that occurs after a
       command-line option of just
-
will also be scanned in full,
       regardless of the presence of any
-d
option. strings
is mainly useful for determining the contents of non-text
       files."
1451,0,stg,"StGit (Stacked Git) is an application that provides a convenient
       way to maintain a
patch stack
on top of a Git branch:

       â¢   The topmost (most recent) commits of a branch are given names. Such a named commit is called a
patch
. â¢   After making changes to the worktree, you can incorporate the
           changes into an existing patch; this is called
refreshing
."
1451,1,stg,"â¢   After making changes to the worktree, you can incorporate the
           changes into an existing patch; this is called
refreshing
. You
           may refresh any patch, not just the topmost one. â¢   You can
pop
a patch: temporarily putting it aside, so that the
           patch below it becomes the topmost patch."
1451,2,stg,"â¢   You can
pop
a patch: temporarily putting it aside, so that the
           patch below it becomes the topmost patch. Later you may
push
it onto the stack again. Pushing and popping can be used to
           reorder patches."
1451,3,stg,"Pushing and popping can be used to
           reorder patches. â¢   You can easily
rebase
your patch stack on top of any other Git
           commit. (The
base
of a patch stack is the most recent Git
           commit that is not an StGit patch.) For example, if you
           started making patches on top of someone elseâs branch, and
           that person publishes an updated branch, you can take all your
           patches and apply them on top of the updated branch."
1451,4,stg,"(The
base
of a patch stack is the most recent Git
           commit that is not an StGit patch.) For example, if you
           started making patches on top of someone elseâs branch, and
           that person publishes an updated branch, you can take all your
           patches and apply them on top of the updated branch. â¢   As you would expect, changing what is below a patch can cause
           that patch to no longer apply cleanly â this can occur when
           you reorder patches, rebase patches, or refresh a non-topmost
           patch. StGit uses Gitâs rename-aware three-way merge
           capability to automatically fix up what it can; if it still
           fails, it lets you manually resolve the conflict just like you
           would resolve a merge conflict in Git."
1451,5,stg,"StGit uses Gitâs rename-aware three-way merge
           capability to automatically fix up what it can; if it still
           fails, it lets you manually resolve the conflict just like you
           would resolve a merge conflict in Git. â¢   The patch stack is just some extra metadata attached to
           regular Git commits, so you can continue to use most Git tools
           along with StGit. Typical uses
Tracking branch
           Tracking changes from a remote branch, while maintaining local
           modifications against that branch, possibly with the intent of
           sending some patches upstream."
1451,6,stg,"Typical uses
Tracking branch
           Tracking changes from a remote branch, while maintaining local
           modifications against that branch, possibly with the intent of
           sending some patches upstream. You can modify your patch stack
           as much as you want, and when your patches are finally
           accepted upstream, the permanent recorded Git history will
           contain just the final sequence of patches, and not the messy
           sequence of edits that produced them. Commands of interest in this workflow are e.g."
1451,7,stg,"Commands of interest in this workflow are e.g. rebase and
           mail. Development branch
           Even if you have no ""upstream"" to send patches to, you can use
           StGit as a convenient way to modify the recent history of a
           Git branch."
1451,8,stg,"Development branch
           Even if you have no ""upstream"" to send patches to, you can use
           StGit as a convenient way to modify the recent history of a
           Git branch. For example, instead of first committing change
A
,
           then change
B
, and then
A2
to fix
A
because it wasnât quite
           right, you could incorporate the fix directly into
A
. This way
           of working results in a much more readable Git history than if
           you had immortalized every misstep you made on your way to the
           right solution."
1451,9,stg,"This way
           of working results in a much more readable Git history than if
           you had immortalized every misstep you made on your way to the
           right solution. Commands of interest in this workflow are e.g. uncommit, which
           can be used to move the patch stack base downwards â i.e.,
           turn Git commits into StGit patches after the fact â and
           commit, its inverse."
1451,10,stg,"uncommit, which
           can be used to move the patch stack base downwards â i.e.,
           turn Git commits into StGit patches after the fact â and
           commit, its inverse. For more information, see the
tutorial
[1]. Specifying patches
Most StGit commands have patch arguments."
1451,11,stg,"Specifying patches
Most StGit commands have patch arguments. Patches in the stack may
       be specified in a variety of ways. A patch in the current branch
       may simply referred to by its name, or, alternatively, be located
       by a relative offset from the topmost patch (e.g."
1451,12,stg,"A patch in the current branch
       may simply referred to by its name, or, alternatively, be located
       by a relative offset from the topmost patch (e.g. +3
), as an
       absolute index into the stack (e.g. 7
), or as an offset from the
       last visible patch (e.g."
1451,13,stg,"7
), or as an offset from the
       last visible patch (e.g. ^1
). Some commands allow you to specify a patch in another branch of
       the repository; this is done by prefixing the patch name with the
       branch name and a colon (e.g."
1451,14,stg,"Some commands allow you to specify a patch in another branch of
       the repository; this is done by prefixing the patch name with the
       branch name and a colon (e.g. otherbranch:thatpatch
). Commands that take multiple patch arguments may be supplied with
       patch ranges of the form
patch1..patchN
as an alternative to
       specifying each patch individually."
1451,15,stg,"Commands that take multiple patch arguments may be supplied with
       patch ranges of the form
patch1..patchN
as an alternative to
       specifying each patch individually. For example,
stg delete p0..p4
would be equivalent to
stg delete p0 p1 p2 p3 p4
. Patch ranges may
       be open on either or both ends."
1451,16,stg,"Patch ranges may
       be open on either or both ends. For example,
stg delete ..p2
would
       delete the first applied patch up to and including patch
p2
. Alternatively,
stg delete p2.."
1451,17,stg,"Alternatively,
stg delete p2.. would delete patch
p2
up to and
       including the topmost applied patch. And
stg delete .."
1451,18,stg,"And
stg delete .. would
       delete all applied patches. The complete syntax for locating patches follows:
<patchname>
, e.g."
1451,19,stg,"The complete syntax for locating patches follows:
<patchname>
, e.g. patch
The name of a patch. @
Refers to the topmost applied patch, or the base of the stack
           if no patches are applied."
1451,20,stg,"@
Refers to the topmost applied patch, or the base of the stack
           if no patches are applied. [<patchname>]~[<n>]
, e.g. ~2
,
patch~
,
patch~3
The <n>th previous patch from the named patch."
1451,21,stg,"~2
,
patch~
,
patch~3
The <n>th previous patch from the named patch. If <patchname>
           is not supplied,
@
is implied. A single
~
represents the first
           previous patch."
1451,22,stg,"A single
~
represents the first
           previous patch. Multiple
~
may be specified, e.g. patch~~~
is
           the same as
patch~3
."
1451,23,stg,"patch~~~
is
           the same as
patch~3
. This is similar to gitâs revision syntax
           where
<rev>~[<n>]
means the <n>th ancestor commit from <rev>
           following first parents. [<patchname>]+[<n>]
, e.g."
1451,24,stg,"[<patchname>]+[<n>]
, e.g. +
,
+3
,
patch+
,
patch+3
The <n>th next patch from the named patch. If <patchname> is
           not supplied,
@
is implied."
1451,25,stg,"If <patchname> is
           not supplied,
@
is implied. A single
+
represents the next
           patch in the series. Multiple
+
may be specified, e.g."
1451,26,stg,"Multiple
+
may be specified, e.g. patch+++
is the same as
patch+3
. -[<n>]
, e.g."
1451,27,stg,"-[<n>]
, e.g. -3
,
-
References the <n>th previously applied patch. This is similar
           to
~<n>
, except it is only valid without a patch name prefix."
1451,28,stg,"This is similar
           to
~<n>
, except it is only valid without a patch name prefix. Note that certain commands with other options taking numeric
           values may require escaping
-
with
\-
, e.g. \-10
."
1451,29,stg,"\-10
. <n>
, e.g. 3
The patch at absolute index <n> in the stack."
1451,30,stg,"3
The patch at absolute index <n> in the stack. This is a
           zero-based index, so
0
refers to the bottommost patch in the
           stack. ^[<n>]
, e.g."
1451,31,stg,"^[<n>]
, e.g. ^
,
^3
The patch at offset <n> from the last visible patch in the
           stack. This is a zero-based offset, so
^0
refers to the last
           visible patch in the stack, which is equivalent to just
^
."
1451,32,stg,"This is a zero-based offset, so
^0
refers to the last
           visible patch in the stack, which is equivalent to just
^
. Negative values of <n> are allowed and refer to hidden patches
           which are after the last visible patch in the stack. {base}+[<n>]
, e.g."
1451,33,stg,"{base}+[<n>]
, e.g. {base}+
,
{base}+3
The patch at offset <n> from the stackâs base commit. Since
           the stack base is not a commit, a positive offset is required."
1451,34,stg,"Since
           the stack base is not a commit, a positive offset is required. Take note that numeric patch locations of the form
<n>
,
-<n>
, and
+<n>
, e.g. 3
,
-3
, or
+3
are also valid patch names."
1451,35,stg,"3
,
-3
, or
+3
are also valid patch names. I.e. it is
       possible (but not recommended) to name a patch, for example, ""-3""."
1451,36,stg,"it is
       possible (but not recommended) to name a patch, for example, ""-3"". In the case where a patch name could also be interpreted as a
       numeric index or offset, the literal patch name will take
       precidence when resolving the patch location. Specifying commits
Some StGit commands take Git commits as arguments."
1451,37,stg,"Specifying commits
Some StGit commands take Git commits as arguments. StGit accepts
       all revision specifications that Git does (see
gitrevisions(7)
);
       and additionally, the patch specifiers from above. The usual Git
       modifiers, including ^, are also allowed; e.g."
1451,38,stg,"The usual Git
       modifiers, including ^, are also allowed; e.g. some-branch:a-patch^^
refers to the grandparent of the commit that
       is patch
a-patch
on branch
some-branch
. If you need to pass a given StGit reference to a Git command,
stg-id(1)
will convert it to a Git commit id for you."
1452,0,strip,"GNU
strip
discards all symbols from object files
objfile
. The
       list of object files may include archives. At least one object
       file must be given."
1452,1,strip,"The
       list of object files may include archives. At least one object
       file must be given. strip
modifies the files named in its argument, rather than
       writing modified copies under different names."
1453,0,strace,"In the simplest case
strace
runs the specified
command
until it
       exits. It intercepts and records the system calls which are
       called by a process and the signals which are received by a
       process. The name of each system call, its arguments and its
       return value are printed on standard error or to the file
       specified with the
-o
option."
1453,1,strace,"The name of each system call, its arguments and its
       return value are printed on standard error or to the file
       specified with the
-o
option. strace
is a useful diagnostic, instructional, and debugging tool. System administrators, diagnosticians and trouble-shooters will
       find it invaluable for solving problems with programs for which
       the source is not readily available since they do not need to be
       recompiled in order to trace them."
1453,2,strace,"System administrators, diagnosticians and trouble-shooters will
       find it invaluable for solving problems with programs for which
       the source is not readily available since they do not need to be
       recompiled in order to trace them. Students, hackers and the
       overly-curious will find that a great deal can be learned about a
       system and its system calls by tracing even ordinary programs. And programmers will find that since system calls and signals are
       events that happen at the user/kernel interface, a close
       examination of this boundary is very useful for bug isolation,
       sanity checking and attempting to capture race conditions."
1453,3,strace,"And programmers will find that since system calls and signals are
       events that happen at the user/kernel interface, a close
       examination of this boundary is very useful for bug isolation,
       sanity checking and attempting to capture race conditions. Each line in the trace contains the system call name, followed by
       its arguments in parentheses and its return value. An example
       from stracing the command ""cat /dev/null"" is:

           open(""/dev/null"", O_RDONLY) = 3

       Errors (typically a return value of -1) have the errno symbol and
       error string appended."
1453,4,strace,"An example
       from stracing the command ""cat /dev/null"" is:

           open(""/dev/null"", O_RDONLY) = 3

       Errors (typically a return value of -1) have the errno symbol and
       error string appended. open(""/foo/bar"", O_RDONLY) = -1 ENOENT (No such file or directory)

       Signals are printed as signal symbol and decoded siginfo
       structure. An excerpt from stracing and interrupting the command
       ""sleep 666"" is:

           sigsuspend([] <unfinished ...>
           --- SIGINT {si_signo=SIGINT, si_code=SI_USER, si_pid=...} ---
           +++ killed by SIGINT +++

       If a system call is being executed and meanwhile another one is
       being called from a different thread/process then
strace
will try
       to preserve the order of those events and mark the ongoing call as
       being
unfinished
."
1453,5,strace,"An excerpt from stracing and interrupting the command
       ""sleep 666"" is:

           sigsuspend([] <unfinished ...>
           --- SIGINT {si_signo=SIGINT, si_code=SI_USER, si_pid=...} ---
           +++ killed by SIGINT +++

       If a system call is being executed and meanwhile another one is
       being called from a different thread/process then
strace
will try
       to preserve the order of those events and mark the ongoing call as
       being
unfinished
. When the call returns it will be marked as
resumed
. [pid 28772] select(4, [3], NULL, NULL, NULL <unfinished ...>
           [pid 28779] clock_gettime(CLOCK_REALTIME, {tv_sec=1130322148, tv_nsec=3977000}) = 0
           [pid 28772] <..."
1453,6,strace,"[pid 28772] select(4, [3], NULL, NULL, NULL <unfinished ...>
           [pid 28779] clock_gettime(CLOCK_REALTIME, {tv_sec=1130322148, tv_nsec=3977000}) = 0
           [pid 28772] <... select resumed> )      = 1 (in [3])

       Interruption of a (restartable) system call by a signal delivery
       is processed differently as kernel terminates the system call and
       also arranges its immediate reexecution after the signal handler
       completes. read(0, 0x7ffff72cf5cf, 1)              = ?"
1453,7,strace,"read(0, 0x7ffff72cf5cf, 1)              = ? ERESTARTSYS (To be restarted)
           --- SIGALRM {si_signo=SIGALRM, si_code=SI_KERNEL} ---
           rt_sigreturn({mask=[]})                 = 0
           read(0, """", 1)                          = 0

       Arguments are printed in symbolic form with passion. This example
       shows the shell performing "">>xyzzy"" output redirection:

           open(""xyzzy"", O_WRONLY|O_APPEND|O_CREAT, 0666) = 3

       Here, the second and the third argument of
open(2)
are decoded by
       breaking down the flag argument into its three bitwise-OR
       constituents and printing the mode value in octal by tradition."
1453,8,strace,"This example
       shows the shell performing "">>xyzzy"" output redirection:

           open(""xyzzy"", O_WRONLY|O_APPEND|O_CREAT, 0666) = 3

       Here, the second and the third argument of
open(2)
are decoded by
       breaking down the flag argument into its three bitwise-OR
       constituents and printing the mode value in octal by tradition. Where the traditional or native usage differs from ANSI or POSIX,
       the latter forms are preferred. In some cases,
strace
output is
       proven to be more readable than the source."
1453,9,strace,"In some cases,
strace
output is
       proven to be more readable than the source. Structure pointers are dereferenced and the members are displayed
       as appropriate. In most cases, arguments are formatted in the
       most C-like fashion possible."
1453,10,strace,"In most cases, arguments are formatted in the
       most C-like fashion possible. For example, the essence of the
       command ""ls -l /dev/null"" is captured as:

           lstat(""/dev/null"", {st_mode=S_IFCHR|0666, st_rdev=makedev(0x1, 0x3), ...}) = 0

       Notice how the 'struct stat' argument is dereferenced and how each
       member is displayed symbolically. In particular, observe how the
st_mode
member is carefully decoded into a bitwise-OR of symbolic
       and numeric values."
1453,11,strace,"In particular, observe how the
st_mode
member is carefully decoded into a bitwise-OR of symbolic
       and numeric values. Also notice in this example that the first
       argument to
lstat(2)
is an input to the system call and the second
       argument is an output. Since output arguments are not modified if
       the system call fails, arguments may not always be dereferenced."
1453,12,strace,"Since output arguments are not modified if
       the system call fails, arguments may not always be dereferenced. For example, retrying the ""ls -l"" example with a non-existent file
       produces the following line:

           lstat(""/foo/bar"", 0xb004) = -1 ENOENT (No such file or directory)

       In this case the porch light is on but nobody is home. Syscalls unknown to
strace
are printed raw, with the unknown
       system call number printed in hexadecimal form and prefixed with
       ""syscall_"":

           syscall_0xbad(0x1, 0x2, 0x3, 0x4, 0x5, 0x6) = -1 ENOSYS (Function not implemented)

       Character pointers are dereferenced and printed as C strings."
1453,13,strace,"Syscalls unknown to
strace
are printed raw, with the unknown
       system call number printed in hexadecimal form and prefixed with
       ""syscall_"":

           syscall_0xbad(0x1, 0x2, 0x3, 0x4, 0x5, 0x6) = -1 ENOSYS (Function not implemented)

       Character pointers are dereferenced and printed as C strings. Non-printing characters in strings are normally represented by
       ordinary C escape codes. Only the first
strsize
(32 by default)
       bytes of strings are printed; longer strings have an ellipsis
       appended following the closing quote."
1453,14,strace,"Only the first
strsize
(32 by default)
       bytes of strings are printed; longer strings have an ellipsis
       appended following the closing quote. Here is a line from ""ls -l""
       where the
getpwuid(3)
library routine is reading the password
       file:

           read(3, ""root::0:0:System Administrator:/""..., 1024) = 422

       While structures are annotated using curly braces, pointers to
       basic types and arrays are printed using square brackets with
       commas separating the elements. Here is an example from the
       command
id(1)
on a system with supplementary group ids:

           getgroups(32, [100, 0]) = 2

       On the other hand, bit-sets are also shown using square brackets,
       but set elements are separated only by a space."
1453,15,strace,"Here is an example from the
       command
id(1)
on a system with supplementary group ids:

           getgroups(32, [100, 0]) = 2

       On the other hand, bit-sets are also shown using square brackets,
       but set elements are separated only by a space. Here is the
       shell, preparing to execute an external command:

           sigprocmask(SIG_BLOCK, [CHLD TTOU], []) = 0

       Here, the second argument is a bit-set of two signals,
SIGCHLD
and
SIGTTOU
. In some cases, the bit-set is so full that printing out
       the unset elements is more valuable."
1453,16,strace,"Here is the
       shell, preparing to execute an external command:

           sigprocmask(SIG_BLOCK, [CHLD TTOU], []) = 0

       Here, the second argument is a bit-set of two signals,
SIGCHLD
and
SIGTTOU
. In some cases, the bit-set is so full that printing out
       the unset elements is more valuable. In that case, the bit-set is
       prefixed by a tilde like this:

           sigprocmask(SIG_UNBLOCK, ~[], NULL) = 0

       Here, the second argument represents the full set of all signals."
1454,0,strings,"The
strings
utility shall look for printable strings in regular
       files and shall write those strings to standard output. A
       printable string is any sequence of four (by default) or more
       printable characters terminated by a <newline> or NUL character. Additional implementation-defined strings may be written; see
localedef
."
1454,1,strings,"A
       printable string is any sequence of four (by default) or more
       printable characters terminated by a <newline> or NUL character. Additional implementation-defined strings may be written; see
localedef
. If the first argument is
'-'
, the results are unspecified."
1455,0,stty,"The
stty
utility shall set or report on terminal I/O
       characteristics for the device that is its standard input. Without
       options or operands specified, it shall report the settings of
       certain characteristics, usually those that differ from
       implementation-defined defaults. Otherwise, it shall modify the
       terminal state according to the specified operands."
1455,1,stty,"Otherwise, it shall modify the
       terminal state according to the specified operands. Detailed
       information about the modes listed in the first five groups below
       are described in the Base Definitions volume of POSIX.1â2017,
Chapter 11
,
General Terminal Interface
. Operands in the
       Combination Modes group (see
Combination Modes
) are implemented
       using operands in the previous groups."
1455,2,stty,"Operands in the
       Combination Modes group (see
Combination Modes
) are implemented
       using operands in the previous groups. Some combinations of
       operands are mutually-exclusive on some terminal types; the
       results of using such combinations are unspecified. Typical implementations of this utility require a communications
       line configured to use the
termios
interface defined in the System
       Interfaces volume of POSIX.1â2017."
1455,3,stty,"Some combinations of
       operands are mutually-exclusive on some terminal types; the
       results of using such combinations are unspecified. Typical implementations of this utility require a communications
       line configured to use the
termios
interface defined in the System
       Interfaces volume of POSIX.1â2017. On systems where none of these
       lines are available, and on lines not currently configured to
       support the
termios
interface, some of the operands need not
       affect terminal characteristics."
1456,0,strip,"A strippable file is defined as a relocatable, object, or
       executable file. On XSI-conformant systems, a strippable file can
       also be an archive of object or relocatable files. The
strip
utility shall remove from strippable files named by the
file
operands any information the implementor deems unnecessary
       for execution of those files."
1456,1,strip,"The
strip
utility shall remove from strippable files named by the
file
operands any information the implementor deems unnecessary
       for execution of those files. The nature of that information is
       unspecified. The effect of
strip
on object and executable files
       shall be similar to the use of the
-s
option to
c99
or
fort77
."
1456,2,strip,"The nature of that information is
       unspecified. The effect of
strip
on object and executable files
       shall be similar to the use of the
-s
option to
c99
or
fort77
. The effect of
strip
on an archive of object files shall be similar
       to the use of the
-s
option to
c99
or
fort77
for each object file
       in the archive."
1457,0,stty,"Print or change terminal characteristics. Mandatory arguments to long options are mandatory for short
       options too. -a
,
--all
print all current settings in human-readable form
-g
,
--save
print all current settings in a stty-readable form
-F
,
--file
=
DEVICE
open and use the specified DEVICE instead of stdin
--help
display this help and exit
--version
output version information and exit

       Optional - before SETTING indicates negation."
1457,1,stty,"-a
,
--all
print all current settings in human-readable form
-g
,
--save
print all current settings in a stty-readable form
-F
,
--file
=
DEVICE
open and use the specified DEVICE instead of stdin
--help
display this help and exit
--version
output version information and exit

       Optional - before SETTING indicates negation. An * marks
       non-POSIX settings. The underlying system defines which settings
       are available."
1457,2,stty,"The underlying system defines which settings
       are available. Special characters:
* discard CHAR
              CHAR will toggle discarding of output

       eof CHAR
              CHAR will send an end of file (terminate the input)

       eol CHAR
              CHAR will end the line

       * eol2 CHAR
              alternate CHAR for ending the line

       erase CHAR
              CHAR will erase the last character typed

       intr CHAR
              CHAR will send an interrupt signal

       kill CHAR
              CHAR will erase the current line

       * lnext CHAR
              CHAR will enter the next character quoted

       quit CHAR
              CHAR will send a quit signal

       * rprnt CHAR
              CHAR will redraw the current line

       start CHAR
              CHAR will restart the output after stopping it

       stop CHAR
              CHAR will stop the output

       susp CHAR
              CHAR will send a terminal stop signal

       * swtch CHAR
              CHAR will switch to a different shell layer

       * werase CHAR
              CHAR will erase the last word typed
Special settings:
N      set the input and output speeds to N bauds

       cols N tell the kernel that the terminal has N columns

       * columns N
              same as cols N

       * [-]drain
              wait for transmission before applying settings (on by
              default)

       ispeed N
              set the input speed to N

       * line N
              use line discipline N

       min N  with
-icanon
, set N characters minimum for a completed read

       ospeed N
              set the output speed to N

       rows N tell the kernel that the terminal has N rows

       size   print the number of rows and columns according to the
              kernel

       speed  print the terminal speed

       time N with
-icanon
, set read timeout of N tenths of a second
Control settings:
[-]clocal
              disable modem control signals

       [-]cread
              allow input to be received

       * [-]crtscts
              enable RTS/CTS handshaking

       csN    set character size to N bits, N in [5..8]

       [-]cstopb
              use two stop bits per character (one with '-')

       [-]hup send a hangup signal when the last process closes the tty

       [-]hupcl
              same as [-]hup

       [-]parenb
              generate parity bit in output and expect parity bit in
              input

       [-]parodd
              set odd parity (or even parity with '-')

       * [-]cmspar
              use ""stick"" (mark/space) parity
Input settings:
[-]brkint
              breaks cause an interrupt signal

       [-]icrnl
              translate carriage return to newline

       [-]ignbrk
              ignore break characters

       [-]igncr
              ignore carriage return

       [-]ignpar
              ignore characters with parity errors

       * [-]imaxbel
              beep and do not flush a full input buffer on a character

       [-]inlcr
              translate newline to carriage return

       [-]inpck
              enable input parity checking

       [-]istrip
              clear high (8th) bit of input characters

       * [-]iutf8
              assume input characters are UTF-8 encoded

       * [-]iuclc
              translate uppercase characters to lowercase

       * [-]ixany
              let any character restart output, not only start character

       [-]ixoff
              enable sending of start/stop characters

       [-]ixon
              enable XON/XOFF flow control

       [-]parmrk
              mark parity errors (with a 255-0-character sequence)

       [-]tandem
              same as [-]ixoff
Output settings:
* bsN  backspace delay style, N in [0..1]

       * crN  carriage return delay style, N in [0..3]

       * ffN  form feed delay style, N in [0..1]

       * nlN  newline delay style, N in [0..1]

       * [-]ocrnl
              translate carriage return to newline

       * [-]ofdel
              use delete characters for fill instead of NUL characters

       * [-]ofill
              use fill (padding) characters instead of timing for delays

       * [-]olcuc
              translate lowercase characters to uppercase

       * [-]onlcr
              translate newline to carriage return-newline

       * [-]onlret
              newline performs a carriage return

       * [-]onocr
              do not print carriage returns in the first column

       [-]opost
              postprocess output

       * tabN horizontal tab delay style, N in [0..3]

       * tabs same as tab0

       *
-tabs
same as tab3

       * vtN  vertical tab delay style, N in [0..1]
Local settings:
[-]crterase
              echo erase characters as backspace-space-backspace

       * crtkill
              kill all line by obeying the echoprt and echoe settings

       *
-crtkill
kill all line by obeying the echoctl and echok settings

       * [-]ctlecho
              echo control characters in hat notation ('^c')

       [-]echo
              echo input characters

       * [-]echoctl
              same as [-]ctlecho

       [-]echoe
              same as [-]crterase

       [-]echok
              echo a newline after a kill character

       * [-]echoke
              same as [-]crtkill

       [-]echonl
              echo newline even if not echoing other characters

       * [-]echoprt
              echo erased characters backward, between '\' and '/'

       * [-]extproc
              enable ""LINEMODE""; useful with high latency links

       * [-]flusho
              discard output

       [-]icanon
              enable special characters: erase, kill, werase, rprnt

       [-]iexten
              enable non-POSIX special characters

       [-]isig
              enable interrupt, quit, and suspend special characters

       [-]noflsh
              disable flushing after interrupt and quit special
              characters

       * [-]prterase
              same as [-]echoprt

       * [-]tostop
              stop background jobs that try to write to the terminal

       * [-]xcase
              with icanon, escape with '\' for uppercase characters
Combination settings:
* [-]LCASE
              same as [-]lcase

       cbreak same as
-icanon
-cbreak
same as icanon

       cooked same as brkint ignpar istrip icrnl ixon opost isig icanon,
              eof and eol characters to their default values
-cooked
same as raw

       crt    same as echoe echoctl echoke

       dec    same as echoe echoctl echoke
-ixany
intr ^c erase 0177 kill
              ^u

       * [-]decctlq
              same as [-]ixany

       ek     erase and kill characters to their default values

       evenp  same as parenb
-parodd
cs7
-evenp
same as
-parenb
cs8

       * [-]lcase
              same as xcase iuclc olcuc

       litout same as
-parenb -istrip -opost
cs8
-litout
same as parenb istrip opost cs7

       nl     same as
-icrnl -onlcr
-nl
same as icrnl
-inlcr -igncr
onlcr
-ocrnl -onlret
oddp   same as parenb parodd cs7
-oddp
same as
-parenb
cs8

       [-]parity
              same as [-]evenp

       pass8  same as
-parenb -istrip
cs8
-pass8
same as parenb istrip cs7

       raw    same as
-ignbrk -brkint -ignpar -parmrk -inpck -istrip
-inlcr -igncr -icrnl -ixon -ixoff -icanon -opost -isig
-iuclc -ixany -imaxbel -xcase
min 1 time 0
-raw
same as cooked

       sane   same as cread
-ignbrk
brkint
-inlcr -igncr
icrnl icanon
              iexten echo echoe echok
-echonl -noflsh -ixoff -iutf8
-iuclc -ixany
imaxbel
-xcase -olcuc -ocrnl
opost
-ofill
onlcr
-onocr -onlret
nl0 cr0 tab0 bs0 vt0 ff0 isig
-tostop
-ofdel -echoprt
echoctl echoke
-extproc -flusho
, all
              special characters to their default values

       Handle the tty line connected to standard input. Without
       arguments, prints baud rate, line discipline, and deviations from
       stty sane."
1457,3,stty,"Special characters:
* discard CHAR
              CHAR will toggle discarding of output

       eof CHAR
              CHAR will send an end of file (terminate the input)

       eol CHAR
              CHAR will end the line

       * eol2 CHAR
              alternate CHAR for ending the line

       erase CHAR
              CHAR will erase the last character typed

       intr CHAR
              CHAR will send an interrupt signal

       kill CHAR
              CHAR will erase the current line

       * lnext CHAR
              CHAR will enter the next character quoted

       quit CHAR
              CHAR will send a quit signal

       * rprnt CHAR
              CHAR will redraw the current line

       start CHAR
              CHAR will restart the output after stopping it

       stop CHAR
              CHAR will stop the output

       susp CHAR
              CHAR will send a terminal stop signal

       * swtch CHAR
              CHAR will switch to a different shell layer

       * werase CHAR
              CHAR will erase the last word typed
Special settings:
N      set the input and output speeds to N bauds

       cols N tell the kernel that the terminal has N columns

       * columns N
              same as cols N

       * [-]drain
              wait for transmission before applying settings (on by
              default)

       ispeed N
              set the input speed to N

       * line N
              use line discipline N

       min N  with
-icanon
, set N characters minimum for a completed read

       ospeed N
              set the output speed to N

       rows N tell the kernel that the terminal has N rows

       size   print the number of rows and columns according to the
              kernel

       speed  print the terminal speed

       time N with
-icanon
, set read timeout of N tenths of a second
Control settings:
[-]clocal
              disable modem control signals

       [-]cread
              allow input to be received

       * [-]crtscts
              enable RTS/CTS handshaking

       csN    set character size to N bits, N in [5..8]

       [-]cstopb
              use two stop bits per character (one with '-')

       [-]hup send a hangup signal when the last process closes the tty

       [-]hupcl
              same as [-]hup

       [-]parenb
              generate parity bit in output and expect parity bit in
              input

       [-]parodd
              set odd parity (or even parity with '-')

       * [-]cmspar
              use ""stick"" (mark/space) parity
Input settings:
[-]brkint
              breaks cause an interrupt signal

       [-]icrnl
              translate carriage return to newline

       [-]ignbrk
              ignore break characters

       [-]igncr
              ignore carriage return

       [-]ignpar
              ignore characters with parity errors

       * [-]imaxbel
              beep and do not flush a full input buffer on a character

       [-]inlcr
              translate newline to carriage return

       [-]inpck
              enable input parity checking

       [-]istrip
              clear high (8th) bit of input characters

       * [-]iutf8
              assume input characters are UTF-8 encoded

       * [-]iuclc
              translate uppercase characters to lowercase

       * [-]ixany
              let any character restart output, not only start character

       [-]ixoff
              enable sending of start/stop characters

       [-]ixon
              enable XON/XOFF flow control

       [-]parmrk
              mark parity errors (with a 255-0-character sequence)

       [-]tandem
              same as [-]ixoff
Output settings:
* bsN  backspace delay style, N in [0..1]

       * crN  carriage return delay style, N in [0..3]

       * ffN  form feed delay style, N in [0..1]

       * nlN  newline delay style, N in [0..1]

       * [-]ocrnl
              translate carriage return to newline

       * [-]ofdel
              use delete characters for fill instead of NUL characters

       * [-]ofill
              use fill (padding) characters instead of timing for delays

       * [-]olcuc
              translate lowercase characters to uppercase

       * [-]onlcr
              translate newline to carriage return-newline

       * [-]onlret
              newline performs a carriage return

       * [-]onocr
              do not print carriage returns in the first column

       [-]opost
              postprocess output

       * tabN horizontal tab delay style, N in [0..3]

       * tabs same as tab0

       *
-tabs
same as tab3

       * vtN  vertical tab delay style, N in [0..1]
Local settings:
[-]crterase
              echo erase characters as backspace-space-backspace

       * crtkill
              kill all line by obeying the echoprt and echoe settings

       *
-crtkill
kill all line by obeying the echoctl and echok settings

       * [-]ctlecho
              echo control characters in hat notation ('^c')

       [-]echo
              echo input characters

       * [-]echoctl
              same as [-]ctlecho

       [-]echoe
              same as [-]crterase

       [-]echok
              echo a newline after a kill character

       * [-]echoke
              same as [-]crtkill

       [-]echonl
              echo newline even if not echoing other characters

       * [-]echoprt
              echo erased characters backward, between '\' and '/'

       * [-]extproc
              enable ""LINEMODE""; useful with high latency links

       * [-]flusho
              discard output

       [-]icanon
              enable special characters: erase, kill, werase, rprnt

       [-]iexten
              enable non-POSIX special characters

       [-]isig
              enable interrupt, quit, and suspend special characters

       [-]noflsh
              disable flushing after interrupt and quit special
              characters

       * [-]prterase
              same as [-]echoprt

       * [-]tostop
              stop background jobs that try to write to the terminal

       * [-]xcase
              with icanon, escape with '\' for uppercase characters
Combination settings:
* [-]LCASE
              same as [-]lcase

       cbreak same as
-icanon
-cbreak
same as icanon

       cooked same as brkint ignpar istrip icrnl ixon opost isig icanon,
              eof and eol characters to their default values
-cooked
same as raw

       crt    same as echoe echoctl echoke

       dec    same as echoe echoctl echoke
-ixany
intr ^c erase 0177 kill
              ^u

       * [-]decctlq
              same as [-]ixany

       ek     erase and kill characters to their default values

       evenp  same as parenb
-parodd
cs7
-evenp
same as
-parenb
cs8

       * [-]lcase
              same as xcase iuclc olcuc

       litout same as
-parenb -istrip -opost
cs8
-litout
same as parenb istrip opost cs7

       nl     same as
-icrnl -onlcr
-nl
same as icrnl
-inlcr -igncr
onlcr
-ocrnl -onlret
oddp   same as parenb parodd cs7
-oddp
same as
-parenb
cs8

       [-]parity
              same as [-]evenp

       pass8  same as
-parenb -istrip
cs8
-pass8
same as parenb istrip cs7

       raw    same as
-ignbrk -brkint -ignpar -parmrk -inpck -istrip
-inlcr -igncr -icrnl -ixon -ixoff -icanon -opost -isig
-iuclc -ixany -imaxbel -xcase
min 1 time 0
-raw
same as cooked

       sane   same as cread
-ignbrk
brkint
-inlcr -igncr
icrnl icanon
              iexten echo echoe echok
-echonl -noflsh -ixoff -iutf8
-iuclc -ixany
imaxbel
-xcase -olcuc -ocrnl
opost
-ofill
onlcr
-onocr -onlret
nl0 cr0 tab0 bs0 vt0 ff0 isig
-tostop
-ofdel -echoprt
echoctl echoke
-extproc -flusho
, all
              special characters to their default values

       Handle the tty line connected to standard input. Without
       arguments, prints baud rate, line discipline, and deviations from
       stty sane. In settings, CHAR is taken literally, or coded as in
       ^c, 0x37, 0177 or 127; special values ^- or undef used to disable
       special characters."
1458,0,su,"su
allows commands to be run with a substitute user and group ID. When called with no
user
specified,
su
defaults to running an
       interactive shell as
root
. When
user
is specified, additional
argument
s can be supplied, in which case they are passed to the
       shell."
1458,1,su,"When
user
is specified, additional
argument
s can be supplied, in which case they are passed to the
       shell. For backward compatibility,
su
defaults to not change the current
       directory and to only set the environment variables
HOME
and
SHELL
(plus
USER
and
LOGNAME
if the target
user
is not root). It is
       recommended to always use the
--login
option (instead of its
       shortcut
-
) to avoid side effects caused by mixing environments."
1458,2,su,"It is
       recommended to always use the
--login
option (instead of its
       shortcut
-
) to avoid side effects caused by mixing environments. This version of
su
uses PAM for authentication, account and
       session management. Some configuration options found in other
su
implementations, such as support for a wheel group, have to be
       configured via PAM."
1458,3,su,"Some configuration options found in other
su
implementations, such as support for a wheel group, have to be
       configured via PAM. su
is mostly designed for unprivileged users, the recommended
       solution for privileged users (e.g., scripts executed by root) is
       to use non-set-user-ID command
runuser(1)
that does not require
       authentication and provides separate PAM configuration. If the PAM
       session is not required at all then the recommended solution is to
       use command
setpriv(1)
."
1458,4,su,"If the PAM
       session is not required at all then the recommended solution is to
       use command
setpriv(1)
. Note that
su
in all cases uses PAM (
pam_getenvlist(3)
) to do the
       final environment modification. Command-line options such as
--login
and
--preserve-environment
affect the environment before
       it is modified by PAM."
1458,5,su,"Note that
su
in all cases uses PAM (
pam_getenvlist(3)
) to do the
       final environment modification. Command-line options such as
--login
and
--preserve-environment
affect the environment before
       it is modified by PAM. Since version 2.38
su
resets process resource limits RLIMIT_NICE,
       RLIMIT_RTPRIO, RLIMIT_FSIZE, RLIMIT_AS and RLIMIT_NOFILE."
1459,0,sync,"Synchronize cached writes to persistent storage

       If one or more files are specified, sync only them, or their
       containing file systems.
-d
,
--data
sync only file data, no unneeded metadata
-f
,
--file-system
sync the file systems that contain the files
--help
display this help and exit
--version
output version information and exit"
1460,0,sum,"Print or check BSD (16-bit) checksums.

       With no FILE, or when FILE is -, read standard input.
-r
use BSD sum algorithm (the default), use 1K blocks
-s
,
--sysv
use System V sum algorithm, use 512 bytes blocks
--help
display this help and exit
--version
output version information and exit"
1461,0,systemd-ac-power,"systemd-ac-power
may be used to check whether the system is
       running on AC power or not. By default, it will simply return
       success (if we can detect that we are running on AC power) or
       failure, with no output. This can be useful for example to debug
ConditionACPower=
(see
systemd.unit(5)
)."
1462,0,systemd-ask-password,"systemd-ask-password
may be used to query a password or passphrase
       interactively from the user, using a question prompt specified on
       the command line. When run from a TTY it will query a password on
       the TTY and print it to standard output. When run with no TTY or
       with
--no-tty
it will use a system-wide or per-user agent-based
       query mechanism, which allows active users to respond via several
       agents, listed below."
1462,1,systemd-ask-password,"When run with no TTY or
       with
--no-tty
it will use a system-wide or per-user agent-based
       query mechanism, which allows active users to respond via several
       agents, listed below. The purpose of this tool is to query system-wide or per-user
       passwords â the former includes passwords possibly not associated
       to a specific user account. Examples include: unlocking encrypted
       hard disks when they are plugged in or at boot, entering an SSL
       certificate passphrase for web and VPN servers."
1462,2,systemd-ask-password,"Examples include: unlocking encrypted
       hard disks when they are plugged in or at boot, entering an SSL
       certificate passphrase for web and VPN servers. Existing system-level agents are:

       â¢   A boot-time password agent asking the user for passwords using
plymouth
(8),

       â¢   A boot-time password agent querying the user directly on the
           console â
systemd-ask-password-console.service(8)
,

       â¢   An agent requesting password input via a
wall(1)
message â
systemd-ask-password-wall.service(8)
,

       â¢   A TTY agent that is temporarily spawned during
systemctl(1)
invocations,

       â¢   A command line agent which can be started temporarily to
           process queued password requests â
systemd-tty-ask-password-agent --query
. Answering system-wide password queries is a privileged operation,
       hence all the agents listed above (except for the last one), run
       as privileged system services."
1462,3,systemd-ask-password,"Answering system-wide password queries is a privileged operation,
       hence all the agents listed above (except for the last one), run
       as privileged system services. The last one also needs elevated
       privileges, so should be run through
run0(1)
or similar. Additional password agents may be implemented according to the
systemd Password Agent Specification
[1]."
1462,4,systemd-ask-password,"Additional password agents may be implemented according to the
systemd Password Agent Specification
[1]. If a password is queried on a TTY, the user may press TAB to hide
       the asterisks normally shown for each character typed. Pressing
       Backspace as first key achieves the same effect."
1463,0,systemd-cgls,"systemd-cgls
recursively shows the contents of the selected Linux
       control group hierarchy in a tree. If arguments are specified,
       shows all member processes of the specified control groups plus
       all their subgroups and their members. The control groups may
       either be specified by their full file paths or are assumed in the
       systemd control group hierarchy."
1463,1,systemd-cgls,"The control groups may
       either be specified by their full file paths or are assumed in the
       systemd control group hierarchy. If no argument is specified and
       the current working directory is beneath the control group mount
       point /sys/fs/cgroup/, shows the contents of the control group the
       working directory refers to. Otherwise, the full systemd control
       group hierarchy is shown."
1463,2,systemd-cgls,"If no argument is specified and
       the current working directory is beneath the control group mount
       point /sys/fs/cgroup/, shows the contents of the control group the
       working directory refers to. Otherwise, the full systemd control
       group hierarchy is shown. By default, empty control groups are not shown."
1464,0,systemctl,"systemctl
may be used to introspect and control the state of the
       ""systemd"" system and service manager. Please refer to
systemd(1)
for an introduction into the basic concepts and functionality this
       tool manages."
1465,0,systemd-cat,"systemd-cat
may be used to connect the standard input and output
       of a process to the journal, or as a filter tool in a shell
       pipeline to pass the output the previous pipeline element
       generates to the journal.

       If no parameter is passed,
systemd-cat
will write everything it
       reads from standard input (stdin) to the journal.

       If parameters are passed, they are executed as command line with
       standard output (stdout) and standard error output (stderr)
       connected to the journal, so that all it writes is stored in the
       journal."
1466,0,systemd-cgtop,"systemd-cgtop
shows the top control groups of the local Linux
       control group hierarchy, ordered by their CPU, memory, or disk I/O
       load. The display is refreshed in regular intervals (by default
       every 1s), similar in style to
top(1)
. If a control group path is
       specified, shows only the services of the specified control group."
1466,1,systemd-cgtop,"If a control group path is
       specified, shows only the services of the specified control group. If
systemd-cgtop
is not connected to a tty, no column headers are
       printed and the default is to only run one iteration. The
--iterations=
argument, if given, is honored."
1466,2,systemd-cgtop,"The
--iterations=
argument, if given, is honored. This mode is
       suitable for scripting. Resource usage is only accounted for control groups with the
       appropriate controllers turned on: ""cpu"" controller for CPU usage,
       ""memory"" controller for memory usage, and ""io"" controller for disk
       I/O consumption."
1466,3,systemd-cgtop,"Resource usage is only accounted for control groups with the
       appropriate controllers turned on: ""cpu"" controller for CPU usage,
       ""memory"" controller for memory usage, and ""io"" controller for disk
       I/O consumption. If resource monitoring for these resources is
       required, it is recommended to add the
CPUAccounting=1
,
MemoryAccounting=1
and
IOAccounting=1
settings in the unit files
       in question. See
systemd.resource-control(5)
for details."
1466,4,systemd-cgtop,"See
systemd.resource-control(5)
for details. The CPU load value can be between 0 and 100 times the number of
       processors the system has. For example, if the system has 8
       processors, the CPU load value is going to be between 0% and 800%."
1466,5,systemd-cgtop,"For example, if the system has 8
       processors, the CPU load value is going to be between 0% and 800%. The number of processors can be found in ""/proc/cpuinfo"". To emphasize: unless ""CPUAccounting=1"", ""MemoryAccounting=1"", and
       ""IOAccounting=1"" are enabled for the services in question, no
       resource accounting will be available for system services and the
       data shown by
systemd-cgtop
will be incomplete."
1467,0,systemd-creds,"systemd-creds
is a tool for listing, showing, encrypting and
       decrypting unit credentials. Credentials are limited-size binary
       or textual objects that may be passed to unit processes. They are
       primarily used for passing cryptographic keys (both public and
       private) or certificates, user account information or identity
       information from the host to services."
1467,1,systemd-creds,"They are
       primarily used for passing cryptographic keys (both public and
       private) or certificates, user account information or identity
       information from the host to services. Credentials are configured in unit files via the
ImportCredential=
,
LoadCredential=
,
SetCredential=
,
LoadCredentialEncrypted=
, and
SetCredentialEncrypted=
settings,
       see
systemd.exec(5)
for details. For further information see
System and Service Credentials
[1]
       documentation."
1468,0,systemd-delta,"systemd-delta
may be used to identify and compare configuration
       files that override other configuration files. Files in /etc/ have
       highest priority, files in /run/ have the second highest priority,
       ..., files in /usr/lib/ have lowest priority. Files in a directory
       with higher priority override files with the same name in
       directories of lower priority."
1468,1,systemd-delta,"Files in a directory
       with higher priority override files with the same name in
       directories of lower priority. In addition, certain configuration
       files can have "".d"" directories which contain ""drop-in"" files with
       configuration snippets which augment the main configuration file. ""Drop-in"" files can be overridden in the same way by placing files
       with the same name in a directory of higher priority (except that,
       in case of ""drop-in"" files, both the ""drop-in"" file name and the
       name of the containing directory, which corresponds to the name of
       the main configuration file, must match)."
1468,2,systemd-delta,"""Drop-in"" files can be overridden in the same way by placing files
       with the same name in a directory of higher priority (except that,
       in case of ""drop-in"" files, both the ""drop-in"" file name and the
       name of the containing directory, which corresponds to the name of
       the main configuration file, must match). For a fuller
       explanation, see
systemd.unit(5)
. The command line argument will be split into a prefix and a
       suffix."
1468,3,systemd-delta,"The command line argument will be split into a prefix and a
       suffix. Either is optional. The prefix must be one of the
       directories containing configuration files (/etc/, /run/,
       /usr/lib/, ...)."
1468,4,systemd-delta,"The prefix must be one of the
       directories containing configuration files (/etc/, /run/,
       /usr/lib/, ...). If it is given, only overriding files contained
       in this directory will be shown. Otherwise, all overriding files
       will be shown."
1468,5,systemd-delta,"Otherwise, all overriding files
       will be shown. The suffix must be a name of a subdirectory
       containing configuration files like tmpfiles.d, sysctl.d or
       systemd/system. If it is given, only configuration files in this
       subdirectory (across all configuration paths) will be analyzed."
1468,6,systemd-delta,"If it is given, only configuration files in this
       subdirectory (across all configuration paths) will be analyzed. Otherwise, all configuration files will be analyzed. If the
       command line argument is not given at all, all configuration files
       will be analyzed."
1468,7,systemd-delta,"Otherwise, all configuration files will be analyzed. If the
       command line argument is not given at all, all configuration files
       will be analyzed. See below for some examples."
1469,0,systemd-analyze,"systemd-analyze
may be used to determine system boot-up
       performance statistics and retrieve other state and tracing
       information from the system and service manager, and to verify the
       correctness of unit files. It is also used to access special
       functions useful for advanced system manager debugging. If no command is passed,
systemd-analyze time
is implied."
1469,1,systemd-analyze,"If no command is passed,
systemd-analyze time
is implied. systemd-analyze time
This command prints the time spent in the kernel before userspace
       has been reached, the time spent in the initrd before normal
       system userspace has been reached, and the time normal system
       userspace took to initialize. Note that these measurements simply
       measure the time passed up to the point where all system services
       have been spawned, but not necessarily until they fully finished
       initialization or the disk is idle."
1469,2,systemd-analyze,"Note that these measurements simply
       measure the time passed up to the point where all system services
       have been spawned, but not necessarily until they fully finished
       initialization or the disk is idle. Example 1. Show how long the boot took
# in a container
           $ systemd-analyze time
           Startup finished in 296ms (userspace)
           multi-user.target reached after 275ms in userspace

           # on a real machine
           $ systemd-analyze time
           Startup finished in 2.584s (kernel) + 19.176s (initrd) + 47.847s (userspace) = 1min 9.608s
           multi-user.target reached after 47.820s in userspace
systemd-analyze blame
This command prints a list of all running units, ordered by the
       time they took to initialize."
1469,3,systemd-analyze,"Show how long the boot took
# in a container
           $ systemd-analyze time
           Startup finished in 296ms (userspace)
           multi-user.target reached after 275ms in userspace

           # on a real machine
           $ systemd-analyze time
           Startup finished in 2.584s (kernel) + 19.176s (initrd) + 47.847s (userspace) = 1min 9.608s
           multi-user.target reached after 47.820s in userspace
systemd-analyze blame
This command prints a list of all running units, ordered by the
       time they took to initialize. This information may be used to
       optimize boot-up times. Note that the output might be misleading
       as the initialization of one service might be slow simply because
       it waits for the initialization of another service to complete."
1469,4,systemd-analyze,"Note that the output might be misleading
       as the initialization of one service might be slow simply because
       it waits for the initialization of another service to complete. Also note:
systemd-analyze blame
does not display results for
       services with
Type=simple
, because systemd considers such services
       to be started immediately, hence no measurement of the
       initialization delays can be done. Also note that this command
       only shows the time units took for starting up, it does not show
       how long unit jobs spent in the execution queue."
1469,5,systemd-analyze,"Also note that this command
       only shows the time units took for starting up, it does not show
       how long unit jobs spent in the execution queue. In particular it
       shows the time units spent in ""activating"" state, which is not
       defined for units such as device units that transition directly
       from ""inactive"" to ""active"". This command hence gives an
       impression of the performance of program code, but cannot
       accurately reflect latency introduced by waiting for hardware and
       similar events."
1469,6,systemd-analyze,"This command hence gives an
       impression of the performance of program code, but cannot
       accurately reflect latency introduced by waiting for hardware and
       similar events. Example 2. Show which units took the most time during boot
$ systemd-analyze blame
                    32.875s pmlogger.service
                    20.905s systemd-networkd-wait-online.service
                    13.299s dev-vda1.device
                    ..."
1469,7,systemd-analyze,"Show which units took the most time during boot
$ systemd-analyze blame
                    32.875s pmlogger.service
                    20.905s systemd-networkd-wait-online.service
                    13.299s dev-vda1.device
                    ... 23ms sysroot.mount
                       11ms initrd-udevadm-cleanup-db.service
                        3ms sys-kernel-config.mount
systemd-analyze critical-chain [
UNIT
...]
       This command prints a tree of the time-critical chain of units
       (for each of the specified
UNIT
s or for the default target
       otherwise). The time after the unit is active or started is
       printed after the ""@"" character."
1469,8,systemd-analyze,"The time after the unit is active or started is
       printed after the ""@"" character. The time the unit takes to start
       is printed after the ""+"" character. Note that the output might be
       misleading as the initialization of services might depend on
       socket activation and because of the parallel execution of units."
1469,9,systemd-analyze,"Note that the output might be
       misleading as the initialization of services might depend on
       socket activation and because of the parallel execution of units. Also, similarly to the
blame
command, this only takes into account
       the time units spent in ""activating"" state, and hence does not
       cover units that never went through an ""activating"" state (such as
       device units that transition directly from ""inactive"" to
       ""active""). Moreover, it does not show information on jobs (and in
       particular not jobs that timed out)."
1469,10,systemd-analyze,"Moreover, it does not show information on jobs (and in
       particular not jobs that timed out). Example 3. systemd-analyze critical-chain
$ systemd-analyze critical-chain
           multi-user.target @47.820s
           ââpmie.service @35.968s +548ms
             ââpmcd.service @33.715s +2.247s
               âânetwork-online.target @33.712s
                 ââsystemd-networkd-wait-online.service @12.804s +20.905s
                   ââsystemd-networkd.service @11.109s +1.690s
                     ââsystemd-udevd.service @9.201s +1.904s
                       ââsystemd-tmpfiles-setup-dev.service @7.306s +1.776s
                         ââkmod-static-nodes.service @6.976s +177ms
                           ââsystemd-journald.socket
                             ââsystem.slice
                               ââ-.slice
systemd-analyze dump [
pattern
...]
       Without any parameter, this command outputs a (usually very long)
       human-readable serialization of the complete service manager
       state."
1469,11,systemd-analyze,"systemd-analyze critical-chain
$ systemd-analyze critical-chain
           multi-user.target @47.820s
           ââpmie.service @35.968s +548ms
             ââpmcd.service @33.715s +2.247s
               âânetwork-online.target @33.712s
                 ââsystemd-networkd-wait-online.service @12.804s +20.905s
                   ââsystemd-networkd.service @11.109s +1.690s
                     ââsystemd-udevd.service @9.201s +1.904s
                       ââsystemd-tmpfiles-setup-dev.service @7.306s +1.776s
                         ââkmod-static-nodes.service @6.976s +177ms
                           ââsystemd-journald.socket
                             ââsystem.slice
                               ââ-.slice
systemd-analyze dump [
pattern
...]
       Without any parameter, this command outputs a (usually very long)
       human-readable serialization of the complete service manager
       state. Optional glob pattern may be specified, causing the output
       to be limited to units whose names match one of the patterns. The
       output format is subject to change without notice and should not
       be parsed by applications."
1469,12,systemd-analyze,"The
       output format is subject to change without notice and should not
       be parsed by applications. This command is rate limited for
       unprivileged users. Example 4."
1469,13,systemd-analyze,"Example 4. Show the internal state of user manager
$ systemd-analyze --user dump
           Timestamp userspace: Thu 2019-03-14 23:28:07 CET
           Timestamp finish: Thu 2019-03-14 23:28:07 CET
           Timestamp generators-start: Thu 2019-03-14 23:28:07 CET
           Timestamp generators-finish: Thu 2019-03-14 23:28:07 CET
           Timestamp units-load-start: Thu 2019-03-14 23:28:07 CET
           Timestamp units-load-finish: Thu 2019-03-14 23:28:07 CET
           -> Unit proc-timer_list.mount:
                   Description: /proc/timer_list
                   ... -> Unit default.target:
                   Description: Main user target
           ..."
1469,14,systemd-analyze,"-> Unit default.target:
                   Description: Main user target
           ... systemd-analyze malloc [
D-Bus service
...]
       This command can be used to request the output of the internal
       memory state (as returned by
malloc_info(3)
) of a D-Bus service. If no service is specified, the query will be sent to
       org.freedesktop.systemd1 (the system or user service manager)."
1469,15,systemd-analyze,"If no service is specified, the query will be sent to
       org.freedesktop.systemd1 (the system or user service manager). The
       output format is not guaranteed to be stable and should not be
       parsed by applications. The service must implement the org.freedesktop.MemoryAllocation1
       interface."
1469,16,systemd-analyze,"The service must implement the org.freedesktop.MemoryAllocation1
       interface. In the systemd suite, it is currently only implemented
       by the manager. systemd-analyze plot
This command prints either an SVG graphic, detailing which system
       services have been started at what time, highlighting the time
       they spent on initialization, or the raw time data in JSON or
       table format."
1469,17,systemd-analyze,"systemd-analyze plot
This command prints either an SVG graphic, detailing which system
       services have been started at what time, highlighting the time
       they spent on initialization, or the raw time data in JSON or
       table format. Example 5. Plot a bootchart
$ systemd-analyze plot >bootup.svg
           $ eog bootup.svg&

       Note that this plot is based on the most recent per-unit timing
       data of loaded units."
1469,18,systemd-analyze,"Plot a bootchart
$ systemd-analyze plot >bootup.svg
           $ eog bootup.svg&

       Note that this plot is based on the most recent per-unit timing
       data of loaded units. This means that if a unit gets started, then
       stopped and then started again the information shown will cover
       the most recent start cycle, not the first one. Thus it is
       recommended to consult this information only shortly after boot,
       so that this distinction does not matter."
1469,19,systemd-analyze,"Thus it is
       recommended to consult this information only shortly after boot,
       so that this distinction does not matter. Moreover, units that are
       not referenced by any other unit through a dependency might be
       unloaded by the service manager once they terminate (and did not
       fail). Such units will not show up in the plot."
1469,20,systemd-analyze,"Such units will not show up in the plot. systemd-analyze dot [
pattern
...]
       This command generates textual dependency graph description in dot
       format for further processing with the GraphViz
dot
(1) tool. Use a
       command line like
systemd-analyze dot | dot -Tsvg >systemd.svg
to
       generate a graphical dependency tree."
1469,21,systemd-analyze,"Use a
       command line like
systemd-analyze dot | dot -Tsvg >systemd.svg
to
       generate a graphical dependency tree. Unless
--order
or
--require
is passed, the generated graph will show both ordering and
       requirement dependencies. Optional pattern globbing style
       specifications (e.g."
1469,22,systemd-analyze,"Optional pattern globbing style
       specifications (e.g. *.target) may be given at the end. A unit
       dependency is included in the graph if any of these patterns match
       either the origin or destination node."
1469,23,systemd-analyze,"A unit
       dependency is included in the graph if any of these patterns match
       either the origin or destination node. Example 6. Plot all dependencies of any unit whose name starts
with ""avahi-daemon""
$ systemd-analyze dot 'avahi-daemon.*' | dot -Tsvg >avahi.svg
           $ eog avahi.svg
Example 7."
1469,24,systemd-analyze,"Plot all dependencies of any unit whose name starts
with ""avahi-daemon""
$ systemd-analyze dot 'avahi-daemon.*' | dot -Tsvg >avahi.svg
           $ eog avahi.svg
Example 7. Plot the dependencies between all known target units
$ systemd-analyze dot --to-pattern='*.target' --from-pattern='*.target' \
                 | dot -Tsvg >targets.svg
           $ eog targets.svg
systemd-analyze unit-paths
This command outputs a list of all directories from which unit
       files, .d overrides, and .wants, .requires symlinks may be loaded. Combine with
--user
to retrieve the list for the user manager
       instance, and
--global
for the global configuration of user
       manager instances."
1469,25,systemd-analyze,"Combine with
--user
to retrieve the list for the user manager
       instance, and
--global
for the global configuration of user
       manager instances. Example 8. Show all paths for generated units
$ systemd-analyze unit-paths | grep '^/run'
           /run/systemd/system.control
           /run/systemd/transient
           /run/systemd/generator.early
           /run/systemd/system
           /run/systemd/system.attached
           /run/systemd/generator
           /run/systemd/generator.late

       Note that this verb prints the list that is compiled into
systemd-analyze
itself, and does not communicate with the running
       manager."
1469,26,systemd-analyze,"Show all paths for generated units
$ systemd-analyze unit-paths | grep '^/run'
           /run/systemd/system.control
           /run/systemd/transient
           /run/systemd/generator.early
           /run/systemd/system
           /run/systemd/system.attached
           /run/systemd/generator
           /run/systemd/generator.late

       Note that this verb prints the list that is compiled into
systemd-analyze
itself, and does not communicate with the running
       manager. Use

           systemctl [--user] [--global] show -p UnitPath --value

       to retrieve the actual list that the manager uses, with any empty
       directories omitted. systemd-analyze exit-status [
STATUS
...]
       This command prints a list of exit statuses along with their
       ""class"", i.e."
1469,27,systemd-analyze,"systemd-analyze exit-status [
STATUS
...]
       This command prints a list of exit statuses along with their
       ""class"", i.e. the source of the definition (one of ""glibc"",
       ""systemd"", ""LSB"", or ""BSD""), see the Process Exit Codes section in
systemd.exec(5)
. If no additional arguments are specified, all
       known statuses are shown."
1469,28,systemd-analyze,"If no additional arguments are specified, all
       known statuses are shown. Otherwise, only the definitions for the
       specified codes are shown. Example 9."
1469,29,systemd-analyze,"Example 9. Show some example exit status names
$ systemd-analyze exit-status 0 1 {63..65}
           NAME    STATUS CLASS
           SUCCESS 0      glibc
           FAILURE 1      glibc
           -       63     -
           USAGE   64     BSD
           DATAERR 65     BSD
systemd-analyze capability [
CAPABILITY
... | {-m | --mask}
MASK
]
       This command prints a list of Linux capabilities along with their
       numeric IDs."
1469,30,systemd-analyze,"| {-m | --mask}
MASK
]
       This command prints a list of Linux capabilities along with their
       numeric IDs. See
capabilities(7)
for details. If no argument is
       specified the full list of capabilities known to the service
       manager and the kernel is shown."
1469,31,systemd-analyze,"If no argument is
       specified the full list of capabilities known to the service
       manager and the kernel is shown. Capabilities defined by the
       kernel but not known to the service manager are shown as
       ""cap_???"". Optionally, if arguments are specified they may refer
       to specific cabilities by name or numeric ID, in which case only
       the indicated capabilities are shown in the table."
1469,32,systemd-analyze,"Optionally, if arguments are specified they may refer
       to specific cabilities by name or numeric ID, in which case only
       the indicated capabilities are shown in the table. Alternatively, if
--mask
is passed, a single numeric argument must
       be specified, which is interpreted as a hexadecimal capability
       mask. In this case, only the capabilities present in the mask are
       shown in the table."
1469,33,systemd-analyze,"In this case, only the capabilities present in the mask are
       shown in the table. This mode is intended to aid in decoding
       capability sets available via various debugging interfaces (e.g. ""/proc/PID/status"")."
1469,34,systemd-analyze,"""/proc/PID/status""). Example 10. Show some example capability names
$ systemd-analyze capability 0 1 {30..32}
           NAME              NUMBER
           cap_chown              0
           cap_dac_override       1
           cap_audit_control     30
           cap_setfcap           31
           cap_mac_override      32
Example 11."
1469,35,systemd-analyze,"Show some example capability names
$ systemd-analyze capability 0 1 {30..32}
           NAME              NUMBER
           cap_chown              0
           cap_dac_override       1
           cap_audit_control     30
           cap_setfcap           31
           cap_mac_override      32
Example 11. Decode a capability mask extracted from /proc
$ systemd-analyze capability -m 0000000000003c00
           NAME                 NUMBER
           cap_net_bind_service     10
           cap_net_broadcast        11
           cap_net_admin            12
           cap_net_raw              13
systemd-analyze condition
CONDITION
... This command will evaluate
Condition*=..."
1469,36,systemd-analyze,"This command will evaluate
Condition*=... and
Assert*=... assignments, and print their values, and the resulting value of
       the combined condition set."
1469,37,systemd-analyze,"assignments, and print their values, and the resulting value of
       the combined condition set. See
systemd.unit(5)
for a list of
       available conditions and asserts. Example 12."
1469,38,systemd-analyze,"Example 12. Evaluate conditions that check kernel versions
$ systemd-analyze condition 'ConditionKernelVersion = ! <4.0' \
                   'ConditionKernelVersion = >=5.1' \
                   'ConditionACPower=|false' \
                   'ConditionArchitecture=|!arm' \
                   'AssertPathExists=/etc/os-release'
           test.service: AssertPathExists=/etc/os-release succeeded."
1469,39,systemd-analyze,"<4.0' \
                   'ConditionKernelVersion = >=5.1' \
                   'ConditionACPower=|false' \
                   'ConditionArchitecture=|!arm' \
                   'AssertPathExists=/etc/os-release'
           test.service: AssertPathExists=/etc/os-release succeeded. Asserts succeeded. test.service: ConditionArchitecture=|!arm succeeded."
1469,40,systemd-analyze,test.service: ConditionArchitecture=|!arm succeeded. test.service: ConditionACPower=|false failed. test.service: ConditionKernelVersion=>=5.1 succeeded.
1469,41,systemd-analyze,test.service: ConditionKernelVersion=>=5.1 succeeded. test.service: ConditionKernelVersion=!<4.0 succeeded. Conditions succeeded.
1469,42,systemd-analyze,"Conditions succeeded. systemd-analyze syscall-filter [
SET
...]
       This command will list system calls contained in the specified
       system call set
SET
, or all known sets if no sets are specified. Argument
SET
must include the ""@"" prefix."
1469,43,systemd-analyze,"Argument
SET
must include the ""@"" prefix. systemd-analyze filesystems [
SET
...]
       This command will list filesystems in the specified filesystem set
SET
, or all known sets if no sets are specified. Argument
SET
must
       include the ""@"" prefix."
1469,44,systemd-analyze,"Argument
SET
must
       include the ""@"" prefix. systemd-analyze calendar
EXPRESSION
... This command will parse and normalize repetitive calendar time
       events, and will calculate when they elapse next."
1469,45,systemd-analyze,"This command will parse and normalize repetitive calendar time
       events, and will calculate when they elapse next. This takes the
       same input as the
OnCalendar=
setting in
systemd.timer(5)
,
       following the syntax described in
systemd.time(7)
. By default,
       only the next time the calendar expression will elapse is shown;
       use
--iterations=
to show the specified number of next times the
       expression elapses."
1469,46,systemd-analyze,"By default,
       only the next time the calendar expression will elapse is shown;
       use
--iterations=
to show the specified number of next times the
       expression elapses. Each time the expression elapses forms a
       timestamp, see the
timestamp
verb below. Example 13."
1469,47,systemd-analyze,"Example 13. Show leap days in the near future
$ systemd-analyze calendar --iterations=5 '*-2-29 0:0:0'
             Original form: *-2-29 0:0:0
           Normalized form: *-02-29 00:00:00
               Next elapse: Sat 2020-02-29 00:00:00 UTC
                  From now: 11 months 15 days left
                  Iter. #2: Thu 2024-02-29 00:00:00 UTC
                  From now: 4 years 11 months left
                  Iter."
1469,48,systemd-analyze,"#2: Thu 2024-02-29 00:00:00 UTC
                  From now: 4 years 11 months left
                  Iter. #3: Tue 2028-02-29 00:00:00 UTC
                  From now: 8 years 11 months left
                  Iter. #4: Sun 2032-02-29 00:00:00 UTC
                  From now: 12 years 11 months left
                  Iter."
1469,49,systemd-analyze,"#4: Sun 2032-02-29 00:00:00 UTC
                  From now: 12 years 11 months left
                  Iter. #5: Fri 2036-02-29 00:00:00 UTC
                  From now: 16 years 11 months left
systemd-analyze timestamp
TIMESTAMP
... This command parses a timestamp (i.e."
1469,50,systemd-analyze,"This command parses a timestamp (i.e. a single point in time) and
       outputs the normalized form and the difference between this
       timestamp and now. The timestamp should adhere to the syntax
       documented in
systemd.time(7)
, section ""PARSING TIMESTAMPS""."
1469,51,systemd-analyze,"The timestamp should adhere to the syntax
       documented in
systemd.time(7)
, section ""PARSING TIMESTAMPS"". Example 14. Show parsing of timestamps
$ systemd-analyze timestamp yesterday now tomorrow
             Original form: yesterday
           Normalized form: Mon 2019-05-20 00:00:00 CEST
                  (in UTC): Sun 2019-05-19 22:00:00 UTC
              UNIX seconds: @15583032000
                  From now: 1 day 9h ago

             Original form: now
           Normalized form: Tue 2019-05-21 09:48:39 CEST
                  (in UTC): Tue 2019-05-21 07:48:39 UTC
              UNIX seconds: @1558424919.659757
                  From now: 43us ago

             Original form: tomorrow
           Normalized form: Wed 2019-05-22 00:00:00 CEST
                  (in UTC): Tue 2019-05-21 22:00:00 UTC
              UNIX seconds: @15584760000
                  From now: 14h left
systemd-analyze timespan
EXPRESSION
..."
1469,52,systemd-analyze,"Show parsing of timestamps
$ systemd-analyze timestamp yesterday now tomorrow
             Original form: yesterday
           Normalized form: Mon 2019-05-20 00:00:00 CEST
                  (in UTC): Sun 2019-05-19 22:00:00 UTC
              UNIX seconds: @15583032000
                  From now: 1 day 9h ago

             Original form: now
           Normalized form: Tue 2019-05-21 09:48:39 CEST
                  (in UTC): Tue 2019-05-21 07:48:39 UTC
              UNIX seconds: @1558424919.659757
                  From now: 43us ago

             Original form: tomorrow
           Normalized form: Wed 2019-05-22 00:00:00 CEST
                  (in UTC): Tue 2019-05-21 22:00:00 UTC
              UNIX seconds: @15584760000
                  From now: 14h left
systemd-analyze timespan
EXPRESSION
... This command parses a time span (i.e. a difference between two
       timestamps) and outputs the normalized form and the equivalent
       value in microseconds."
1469,53,systemd-analyze,"a difference between two
       timestamps) and outputs the normalized form and the equivalent
       value in microseconds. The time span should adhere to the syntax
       documented in
systemd.time(7)
, section ""PARSING TIME SPANS"". Values without units are parsed as seconds."
1469,54,systemd-analyze,"Values without units are parsed as seconds. Example 15. Show parsing of timespans
$ systemd-analyze timespan 1s 300s '1year 0.000001s'
           Original: 1s
                 Î¼s: 1000000
              Human: 1s

           Original: 300s
                 Î¼s: 300000000
              Human: 5min

           Original: 1year 0.000001s
                 Î¼s: 31557600000001
              Human: 1y 1us
systemd-analyze cat-config
NAME
|
PATH
..."
1469,55,systemd-analyze,"Show parsing of timespans
$ systemd-analyze timespan 1s 300s '1year 0.000001s'
           Original: 1s
                 Î¼s: 1000000
              Human: 1s

           Original: 300s
                 Î¼s: 300000000
              Human: 5min

           Original: 1year 0.000001s
                 Î¼s: 31557600000001
              Human: 1y 1us
systemd-analyze cat-config
NAME
|
PATH
... This command is similar to
systemctl cat
, but operates on config
       files. It will copy the contents of a config file and any drop-ins
       to standard output, using the usual systemd set of directories and
       rules for precedence."
1469,56,systemd-analyze,"It will copy the contents of a config file and any drop-ins
       to standard output, using the usual systemd set of directories and
       rules for precedence. Each argument must be either an absolute
       path including the prefix (such as /etc/systemd/logind.conf or
       /usr/lib/systemd/logind.conf), or a name relative to the prefix
       (such as systemd/logind.conf). Example 16."
1469,57,systemd-analyze,"Example 16. Showing logind configuration
$ systemd-analyze cat-config systemd/logind.conf
           # /etc/systemd/logind.conf
           ... [Login]
           NAutoVTs=8
           ..."
1469,58,systemd-analyze,"[Login]
           NAutoVTs=8
           ... # /usr/lib/systemd/logind.conf.d/20-test.conf
           ... some override from another package

           # /etc/systemd/logind.conf.d/50-override.conf
           ..."
1469,59,systemd-analyze,"some override from another package

           # /etc/systemd/logind.conf.d/50-override.conf
           ... some administrator override
systemd-analyze compare-versions
VERSION1
[
OP
]
VERSION2
This command has two distinct modes of operation, depending on
       whether the operator
OP
is specified. In the first mode â when
OP
is not specified â, it will compare
       the two version strings and print either ""
VERSION1
<
VERSION2
"", or
       ""
VERSION1
==
VERSION2
"", or ""
VERSION1
>
VERSION2
"" as appropriate."
1469,60,systemd-analyze,"In the first mode â when
OP
is not specified â, it will compare
       the two version strings and print either ""
VERSION1
<
VERSION2
"", or
       ""
VERSION1
==
VERSION2
"", or ""
VERSION1
>
VERSION2
"" as appropriate. The exit status is
0
if the versions are equal,
11
if the version
       of the right is smaller, and
12
if the version of the left is
       smaller. (This matches the convention used by
rpmdev-vercmp
.)

       In the second mode â when
OP
is specified â it will compare the
       two version strings using the operation
OP
and return
0
(success)
       if they condition is satisfied, and
1
(failure) otherwise."
1469,61,systemd-analyze,"(This matches the convention used by
rpmdev-vercmp
.)

       In the second mode â when
OP
is specified â it will compare the
       two version strings using the operation
OP
and return
0
(success)
       if they condition is satisfied, and
1
(failure) otherwise. OP
may
       be
lt
,
le
,
eq
,
ne
,
ge
,
gt
. In this mode, no output is printed."
1469,62,systemd-analyze,"In this mode, no output is printed. (This matches the convention used by
dpkg(1)
--compare-versions
.)
Example 17. Compare versions of a package
$ systemd-analyze compare-versions systemd-250~rc1.fc36.aarch64 systemd-251.fc36.aarch64
           systemd-250~rc1.fc36.aarch64 < systemd-251.fc36.aarch64
           $ echo $?"
1469,63,systemd-analyze,"Compare versions of a package
$ systemd-analyze compare-versions systemd-250~rc1.fc36.aarch64 systemd-251.fc36.aarch64
           systemd-250~rc1.fc36.aarch64 < systemd-251.fc36.aarch64
           $ echo $? 12

           $ systemd-analyze compare-versions 1 lt 2; echo $? 0
           $ systemd-analyze compare-versions 1 ge 2; echo $?"
1469,64,systemd-analyze,"0
           $ systemd-analyze compare-versions 1 ge 2; echo $? 1
systemd-analyze verify
FILE
... This command will load unit files and print warnings if any errors
       are detected."
1469,65,systemd-analyze,"This command will load unit files and print warnings if any errors
       are detected. Files specified on the command line will be loaded,
       but also any other units referenced by them. A unit's name on disk
       can be overridden by specifying an alias after a colon; see below
       for an example."
1469,66,systemd-analyze,"A unit's name on disk
       can be overridden by specifying an alias after a colon; see below
       for an example. The full unit search path is formed by combining
       the directories for all command line arguments, and the usual unit
       load paths. The variable
$SYSTEMD_UNIT_PATH
is supported, and may
       be used to replace or augment the compiled in set of unit load
       paths; see
systemd.unit(5)
."
1469,67,systemd-analyze,"The variable
$SYSTEMD_UNIT_PATH
is supported, and may
       be used to replace or augment the compiled in set of unit load
       paths; see
systemd.unit(5)
. All units files present in the
       directories containing the command line arguments will be used in
       preference to the other paths. If a template unit without an
       instance name is specified (e.g."
1469,68,systemd-analyze,"If a template unit without an
       instance name is specified (e.g. foo@.service), ""test_instance""
       will be used as the instance name, which can be controlled by
--instance=
option. The following errors are currently detected:

       â¢   unknown sections and directives,

       â¢   missing dependencies which are required to start the given
           unit,

       â¢   man pages listed in
Documentation=
which are not found in the
           system,

       â¢   commands listed in
ExecStart=
and similar which are not found
           in the system or not executable."
1469,69,systemd-analyze,"The following errors are currently detected:

       â¢   unknown sections and directives,

       â¢   missing dependencies which are required to start the given
           unit,

       â¢   man pages listed in
Documentation=
which are not found in the
           system,

       â¢   commands listed in
ExecStart=
and similar which are not found
           in the system or not executable. Example 18. Misspelt directives
$ cat ./user.slice
           [Unit]
           WhatIsThis=11
           Documentation=man:nosuchfile(1)
           Requires=different.service

           [Service]
           Description=x

           $ systemd-analyze verify ./user.slice
           [./user.slice:9] Unknown lvalue 'WhatIsThis' in section 'Unit'
           [./user.slice:13] Unknown section 'Service'."
1469,70,systemd-analyze,"Misspelt directives
$ cat ./user.slice
           [Unit]
           WhatIsThis=11
           Documentation=man:nosuchfile(1)
           Requires=different.service

           [Service]
           Description=x

           $ systemd-analyze verify ./user.slice
           [./user.slice:9] Unknown lvalue 'WhatIsThis' in section 'Unit'
           [./user.slice:13] Unknown section 'Service'. Ignoring. Error: org.freedesktop.systemd1.LoadFailed:
              Unit different.service failed to load:
              No such file or directory."
1469,71,systemd-analyze,"Error: org.freedesktop.systemd1.LoadFailed:
              Unit different.service failed to load:
              No such file or directory. Failed to create user.slice/start: Invalid argument
           user.slice: man nosuchfile(1) command failed with code 16
Example 19. Missing service units
$ tail ./a.socket ./b.socket
           ==> ./a.socket <==
           [Socket]
           ListenStream=100

           ==> ./b.socket <==
           [Socket]
           ListenStream=100
           Accept=yes

           $ systemd-analyze verify ./a.socket ./b.socket
           Service a.service not loaded, a.socket cannot be started."
1469,72,systemd-analyze,"Missing service units
$ tail ./a.socket ./b.socket
           ==> ./a.socket <==
           [Socket]
           ListenStream=100

           ==> ./b.socket <==
           [Socket]
           ListenStream=100
           Accept=yes

           $ systemd-analyze verify ./a.socket ./b.socket
           Service a.service not loaded, a.socket cannot be started. Service b@0.service not loaded, b.socket cannot be started. Example 20."
1469,73,systemd-analyze,"Example 20. Aliasing a unit
$ cat /tmp/source
           [Unit]
           Description=Hostname printer

           [Service]
           Type=simple
           ExecStart=/usr/bin/echo %H
           MysteryKey=true

           $ systemd-analyze verify /tmp/source
           Failed to prepare filename /tmp/source: Invalid argument

           $ systemd-analyze verify /tmp/source:alias.service
           alias.service:7: Unknown key name 'MysteryKey' in section 'Service', ignoring. systemd-analyze security [
UNIT
...]
       This command analyzes the security and sandboxing settings of one
       or more specified service units."
1469,74,systemd-analyze,"systemd-analyze security [
UNIT
...]
       This command analyzes the security and sandboxing settings of one
       or more specified service units. If at least one unit name is
       specified the security settings of the specified service units are
       inspected and a detailed analysis is shown. If no unit name is
       specified, all currently loaded, long-running service units are
       inspected and a terse table with results shown."
1469,75,systemd-analyze,"If no unit name is
       specified, all currently loaded, long-running service units are
       inspected and a terse table with results shown. The command checks
       for various security-related service settings, assigning each a
       numeric ""exposure level"" value, depending on how important a
       setting is. It then calculates an overall exposure level for the
       whole unit, which is an estimation in the range 0.0...10.0
       indicating how exposed a service is security-wise."
1469,76,systemd-analyze,"It then calculates an overall exposure level for the
       whole unit, which is an estimation in the range 0.0...10.0
       indicating how exposed a service is security-wise. High exposure
       levels indicate very little applied sandboxing. Low exposure
       levels indicate tight sandboxing and strongest security
       restrictions."
1469,77,systemd-analyze,"Low exposure
       levels indicate tight sandboxing and strongest security
       restrictions. Note that this only analyzes the per-service
       security features systemd itself implements. This means that any
       additional security mechanisms applied by the service code itself
       are not accounted for."
1469,78,systemd-analyze,"This means that any
       additional security mechanisms applied by the service code itself
       are not accounted for. The exposure level determined this way
       should not be misunderstood: a high exposure level neither means
       that there is no effective sandboxing applied by the service code
       itself, nor that the service is actually vulnerable to remote or
       local attacks. High exposure levels do indicate however that most
       likely the service might benefit from additional settings applied
       to them."
1469,79,systemd-analyze,"High exposure levels do indicate however that most
       likely the service might benefit from additional settings applied
       to them. Please note that many of the security and sandboxing settings
       individually can be circumvented â unless combined with others. For example, if a service retains the privilege to establish or
       undo mount points many of the sandboxing options can be undone by
       the service code itself."
1469,80,systemd-analyze,"For example, if a service retains the privilege to establish or
       undo mount points many of the sandboxing options can be undone by
       the service code itself. Due to that is essential that each
       service uses the most comprehensive and strict sandboxing and
       security settings possible. The tool will take into account some
       of these combinations and relationships between the settings, but
       not all."
1469,81,systemd-analyze,"The tool will take into account some
       of these combinations and relationships between the settings, but
       not all. Also note that the security and sandboxing settings
       analyzed here only apply to the operations executed by the service
       code itself. If a service has access to an IPC system (such as
       D-Bus) it might request operations from other services that are
       not subject to the same restrictions."
1469,82,systemd-analyze,"If a service has access to an IPC system (such as
       D-Bus) it might request operations from other services that are
       not subject to the same restrictions. Any comprehensive security
       and sandboxing analysis is hence incomplete if the IPC access
       policy is not validated too. Example 21."
1469,83,systemd-analyze,"Example 21. Analyze systemd-logind.service
$ systemd-analyze security --no-pager systemd-logind.service
             NAME                DESCRIPTION                              EXPOSURE
           â PrivateNetwork=     Service has access to the host's network      0.5
           â User=/DynamicUser=  Service runs as root user                     0.4
           â DeviceAllow=        Service has no device ACL                     0.2
           â IPAddressDeny=      Service blocks all IP address ranges
           ... â Overall exposure level for systemd-logind.service: 4.1 OK ð
systemd-analyze inspect-elf
FILE
..."
1469,84,systemd-analyze,"â Overall exposure level for systemd-logind.service: 4.1 OK ð
systemd-analyze inspect-elf
FILE
... This command will load the specified files, and if they are ELF
       objects (executables, libraries, core files, etc.) it will parse
       the embedded packaging metadata, if any, and print it in a table
       or json format. See the
Package Metadata for Executable Files
[1]
       document for more information."
1469,85,systemd-analyze,"See the
Package Metadata for Executable Files
[1]
       document for more information. Example 22. Print information about a core file as JSON
$ systemd-analyze inspect-elf --json=pretty \
                   core.fsverity.1000.f77dac5dc161402aa44e15b7dd9dcf97.58561.1637106137000000
           {
                   ""elfType"" : ""coredump"",
                   ""elfArchitecture"" : ""AMD x86-64"",
                   ""/home/bluca/git/fsverity-utils/fsverity"" : {
                           ""type"" : ""deb"",
                           ""name"" : ""fsverity-utils"",
                           ""version"" : ""1.3-1"",
                           ""buildId"" : ""7c895ecd2a271f93e96268f479fdc3c64a2ec4ee""
                   },
                   ""/home/bluca/git/fsverity-utils/libfsverity.so.0"" : {
                           ""type"" : ""deb"",
                           ""name"" : ""fsverity-utils"",
                           ""version"" : ""1.3-1"",
                           ""buildId"" : ""b5e428254abf14237b0ae70ed85fffbb98a78f88""
                   }
           }
systemd-analyze fdstore
UNIT
..."
1469,86,systemd-analyze,"Print information about a core file as JSON
$ systemd-analyze inspect-elf --json=pretty \
                   core.fsverity.1000.f77dac5dc161402aa44e15b7dd9dcf97.58561.1637106137000000
           {
                   ""elfType"" : ""coredump"",
                   ""elfArchitecture"" : ""AMD x86-64"",
                   ""/home/bluca/git/fsverity-utils/fsverity"" : {
                           ""type"" : ""deb"",
                           ""name"" : ""fsverity-utils"",
                           ""version"" : ""1.3-1"",
                           ""buildId"" : ""7c895ecd2a271f93e96268f479fdc3c64a2ec4ee""
                   },
                   ""/home/bluca/git/fsverity-utils/libfsverity.so.0"" : {
                           ""type"" : ""deb"",
                           ""name"" : ""fsverity-utils"",
                           ""version"" : ""1.3-1"",
                           ""buildId"" : ""b5e428254abf14237b0ae70ed85fffbb98a78f88""
                   }
           }
systemd-analyze fdstore
UNIT
... Lists the current contents of the specified service unit's file
       descriptor store. This shows names, inode types, device numbers,
       inode numbers, paths and open modes of the open file descriptors."
1469,87,systemd-analyze,"This shows names, inode types, device numbers,
       inode numbers, paths and open modes of the open file descriptors. The specified units must have
FileDescriptorStoreMax=
enabled, see
systemd.service(5)
for details. Example 23."
1469,88,systemd-analyze,"Example 23. Table output
$ systemd-analyze fdstore systemd-journald.service
           FDNAME TYPE DEVNO   INODE RDEVNO PATH             FLAGS
           stored sock 0:8   4218620 -      socket:[4218620] ro
           stored sock 0:8   4213198 -      socket:[4213198] ro
           stored sock 0:8   4213190 -      socket:[4213190] ro
           ... Note: the ""DEVNO"" column refers to the major/minor numbers of the
       device node backing the file system the file descriptor's inode is
       on."
1469,89,systemd-analyze,"Note: the ""DEVNO"" column refers to the major/minor numbers of the
       device node backing the file system the file descriptor's inode is
       on. The ""RDEVNO"" column refers to the major/minor numbers of the
       device node itself if the file descriptor refers to one. Compare
       with corresponding
.st_dev
and
.st_rdev
fields in
struct stat
(see
stat(2)
for details)."
1469,90,systemd-analyze,"Compare
       with corresponding
.st_dev
and
.st_rdev
fields in
struct stat
(see
stat(2)
for details). The listed inode numbers in the ""INODE""
       column are on the file system indicated by ""DEVNO"". systemd-analyze image-policy
POLICY
..."
1469,91,systemd-analyze,"systemd-analyze image-policy
POLICY
... This command analyzes the specified image policy string, as per
systemd.image-policy(7)
. The policy is normalized and simplified."
1469,92,systemd-analyze,"The policy is normalized and simplified. For each currently defined partition identifier (as per the
Discoverable Partitions Specification
[2]) the effect of the image
       policy string is shown in tabular form. Example 24."
1469,93,systemd-analyze,"Example 24. Example Output
$ systemd-analyze image-policy swap=encrypted:usr=read-only-on+verity:root=encrypted
           Analyzing policy: root=encrypted:usr=verity+read-only-on:swap=encrypted
                  Long form: root=encrypted:usr=verity+read-only-on:swap=encrypted:=unused+absent

           PARTITION       MODE        READ-ONLY GROWFS
           root            encrypted   -         -
           usr             verity      yes       -
           home            ignore      -         -
           srv             ignore      -         -
           esp             ignore      -         -
           xbootldr        ignore      -         -
           swap            encrypted   -         -
           root-verity     ignore      -         -
           usr-verity      unprotected yes       -
           root-verity-sig ignore      -         -
           usr-verity-sig  ignore      -         -
           tmp             ignore      -         -
           var             ignore      -         -
           default         ignore      -         -
systemd-analyze has-tpm2
Reports whether the system is equipped with a usable TPM2 device. If a TPM2 device has been discovered, is supported, and is being
       used by firmware, by the OS kernel drivers and by userspace (i.e."
1469,94,systemd-analyze,"If a TPM2 device has been discovered, is supported, and is being
       used by firmware, by the OS kernel drivers and by userspace (i.e. systemd) this prints ""yes"" and exits with exit status zero. If no
       such device is discovered/supported/used, prints ""no""."
1469,95,systemd-analyze,"If no
       such device is discovered/supported/used, prints ""no"". Otherwise,
       prints ""partial"". In either of these two cases exits with non-zero
       exit status."
1469,96,systemd-analyze,"In either of these two cases exits with non-zero
       exit status. It also shows five lines indicating separately
       whether firmware, drivers, the system, the kernel and libraries
       discovered/support/use TPM2. Currently, required libraries are
       libtss2-esys.so.0, libtss2-rc.so.0, and libtss2-mu.so.0."
1469,97,systemd-analyze,"Currently, required libraries are
       libtss2-esys.so.0, libtss2-rc.so.0, and libtss2-mu.so.0. The
       requirement may be changed in the future release. Note, this checks for TPM 2.0 devices only, and does not consider
       TPM 1.2 at all."
1469,98,systemd-analyze,"Note, this checks for TPM 2.0 devices only, and does not consider
       TPM 1.2 at all. Combine with
--quiet
to suppress the output. Example 25."
1469,99,systemd-analyze,"Example 25. Example Output
yes
           +firmware
           +driver
           +system
           +subsystem
           +libraries
             +libtss2-esys.so.0
             +libtss2-rc.so.0
             +libtss2-mu.so.0

       Added in version 257. systemd-analyze pcrs [
PCR
...]
       This command shows the known TPM2 PCRs along with their
       identifying names and current values."
1469,100,systemd-analyze,"systemd-analyze pcrs [
PCR
...]
       This command shows the known TPM2 PCRs along with their
       identifying names and current values. Example 26. Example Output
$ systemd-analyze pcrs
           NR NAME                SHA256
            0 platform-code       bcd2eb527108bbb1f5528409bcbe310aa9b74f687854cc5857605993f3d9eb11
            1 platform-config     b60622856eb7ce52637b80f30a520e6e87c347daa679f3335f4f1a600681bb01
            2 external-code       1471262403e9a62f9c392941300b4807fbdb6f0bfdd50abfab752732087017dd
            3 external-config     3d458cfe55cc03ea1f443f1562beec8df51c75e14a9fcf9a7234a13f198e7969
            4 boot-loader-code    939f7fa1458e1f7ce968874d908e524fc0debf890383d355e4ce347b7b78a95c
            5 boot-loader-config  864c61c5ea5ecbdb6951e6cb6d9c1f4b4eac79772f7fe13b8bece569d83d3768
            6 -                   3d458cfe55cc03ea1f443f1562beec8df51c75e14a9fcf9a7234a13f198e7969
            7 secure-boot-policy  9c905bd9b9891bfb889b90a54c4b537b889cfa817c4389cc25754823a9443255
            8 -                   0000000000000000000000000000000000000000000000000000000000000000
            9 kernel-initrd       9caa29b128113ef42aa53d421f03437be57211e5ebafc0fa8b5d4514ee37ff0c
           10 ima                 5ea9e3dab53eb6b483b6ec9e3b2c712bea66bca1b155637841216e0094387400
           11 kernel-boot         0000000000000000000000000000000000000000000000000000000000000000
           12 kernel-config       627ffa4b405e911902fe1f1a8b0164693b31acab04f805f15bccfe2209c7eace
           13 sysexts             0000000000000000000000000000000000000000000000000000000000000000
           14 shim-policy         0000000000000000000000000000000000000000000000000000000000000000
           15 system-identity     0000000000000000000000000000000000000000000000000000000000000000
           16 debug               0000000000000000000000000000000000000000000000000000000000000000
           17 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           18 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           19 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           20 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           21 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           22 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           23 application-support 0000000000000000000000000000000000000000000000000000000000000000
systemd-analyze srk [>
FILE
]
       This command reads the Storage Root Key (SRK) from the TPM2
       device, and writes it in marshalled TPM2B_PUBLIC format to stdout."
1469,101,systemd-analyze,"Example Output
$ systemd-analyze pcrs
           NR NAME                SHA256
            0 platform-code       bcd2eb527108bbb1f5528409bcbe310aa9b74f687854cc5857605993f3d9eb11
            1 platform-config     b60622856eb7ce52637b80f30a520e6e87c347daa679f3335f4f1a600681bb01
            2 external-code       1471262403e9a62f9c392941300b4807fbdb6f0bfdd50abfab752732087017dd
            3 external-config     3d458cfe55cc03ea1f443f1562beec8df51c75e14a9fcf9a7234a13f198e7969
            4 boot-loader-code    939f7fa1458e1f7ce968874d908e524fc0debf890383d355e4ce347b7b78a95c
            5 boot-loader-config  864c61c5ea5ecbdb6951e6cb6d9c1f4b4eac79772f7fe13b8bece569d83d3768
            6 -                   3d458cfe55cc03ea1f443f1562beec8df51c75e14a9fcf9a7234a13f198e7969
            7 secure-boot-policy  9c905bd9b9891bfb889b90a54c4b537b889cfa817c4389cc25754823a9443255
            8 -                   0000000000000000000000000000000000000000000000000000000000000000
            9 kernel-initrd       9caa29b128113ef42aa53d421f03437be57211e5ebafc0fa8b5d4514ee37ff0c
           10 ima                 5ea9e3dab53eb6b483b6ec9e3b2c712bea66bca1b155637841216e0094387400
           11 kernel-boot         0000000000000000000000000000000000000000000000000000000000000000
           12 kernel-config       627ffa4b405e911902fe1f1a8b0164693b31acab04f805f15bccfe2209c7eace
           13 sysexts             0000000000000000000000000000000000000000000000000000000000000000
           14 shim-policy         0000000000000000000000000000000000000000000000000000000000000000
           15 system-identity     0000000000000000000000000000000000000000000000000000000000000000
           16 debug               0000000000000000000000000000000000000000000000000000000000000000
           17 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           18 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           19 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           20 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           21 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           22 -                   ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
           23 application-support 0000000000000000000000000000000000000000000000000000000000000000
systemd-analyze srk [>
FILE
]
       This command reads the Storage Root Key (SRK) from the TPM2
       device, and writes it in marshalled TPM2B_PUBLIC format to stdout. The output is non-printable data, so it should be redirected to a
       file or into a pipe. Example 27."
1469,102,systemd-analyze,"Example 27. Save the Storage Root Key to srk.tpm2b_public
systemd-analyze srk >srk.tpm2b_public
systemd-analyze architectures [
NAME
...]
       Lists all known CPU architectures, and which ones are native. The
       listed architecture names are those
ConditionArchitecture=
supports, see
systemd.unit(5)
for details."
1469,103,systemd-analyze,"The
       listed architecture names are those
ConditionArchitecture=
supports, see
systemd.unit(5)
for details. If architecture names
       are specified only those specified are listed. Example 28."
1469,104,systemd-analyze,"Example 28. Table output
$ systemd-analyze architectures
           NAME        SUPPORT
           alpha       foreign
           arc         foreign
           arc-be      foreign
           arm         foreign
           arm64       foreign
           ... sparc       foreign
           sparc64     foreign
           tilegx      foreign
           x86         secondary
           x86-64      native
systemd-analyze smbios11
Shows a list of SMBIOS Type #11 strings passed to the system."
1469,105,systemd-analyze,"sparc       foreign
           sparc64     foreign
           tilegx      foreign
           x86         secondary
           x86-64      native
systemd-analyze smbios11
Shows a list of SMBIOS Type #11 strings passed to the system. Also
       see
smbios-type-11(7)
. Example 29."
1469,106,systemd-analyze,"Example 29. Example output
$ systemd-analyze smbios11
           io.systemd.stub.kernel-cmdline-extra=console=ttyS0
           io.systemd.credential.binary:ssh.ephemeral-authorized_keys-all=c3NoLWVkMjU1MTkgQUFBQUMzTnphQzFsWkRJMU5URTVBQUFBSURGd20xbFp4WlRGclJteG9ZQlozOTYzcE1uYlJCaDMwM1MxVXhLSUM2NmYgbGVubmFydEB6ZXRhCg==
           io.systemd.credential:vmm.notify_socket=vsock-stream:2:254570042

           3 SMBIOS Type #11 strings passed. Added in version 257."
1469,107,systemd-analyze,"Added in version 257. systemd-analyze chid
Shows a list of Computer Hardware IDs (CHIDs) of the local system. These IDs identify the system's computer hardware, based on SMBIOS
       data."
1469,108,systemd-analyze,"These IDs identify the system's computer hardware, based on SMBIOS
       data. See
Using Computer Hardware IDs (CHIDs)
[3] for details about
       CHIDs. Example 30."
1469,109,systemd-analyze,"See
Using Computer Hardware IDs (CHIDs)
[3] for details about
       CHIDs. Example 30. Example output
$ systemd-analyze chid
           TYPE INPUT  CHID
              3 MFPSmp 520537c0-3b59-504f-b062-9682ea236b21
              4 MFPS-- edf05dc8-a53d-5b2c-8023-630bca2a2463
              5 MFP--- ebc6a4d9-ec48-537a-916b-c69fa4fdd814
              6 M--Smp 5ebe4bba-f598-5e90-9ff2-9fd0d3211465
              7 M--S-- 1a3fb835-b42a-5f9c-a38c-eff5bfd5c41d
              8 M-P-mp 2a831dce-8163-5bad-8406-435b8c752dd8
              9 M-P--- 7c21c878-4a75-50f7-9816-21e811588da0
             10 MF--mp 9a003537-bcc5-500e-b10a-8d8892e4fc64
             11 MF---- bb9122bb-8a5c-50d2-a742-a85beb719909
             13 M---mp bfc36935-5032-5987-a0a3-6311f01de33a

           LEGEND: M â sys_vendor (LENOVO) â F â product_family (ThinkPad X1 Carbon Gen 9) â P â product_name (20XW0055GE)
                   S â product_sku (LENOVO_MT_20XW_BU_Think_FM_ThinkPad X1 Carbon Gen 9) â m â board_vendor (LENOVO)
                   p â board_name (20XW0055GE)

       Added in version 258."
1470,0,systemd-detect-virt,"systemd-detect-virt
detects execution in a virtualized
       environment. It identifies the virtualization technology and can
       distinguish full machine virtualization from container
       virtualization. systemd-detect-virt exits with a return value of
       0 (success) if a virtualization technology is detected, and
       non-zero (error) otherwise."
1470,1,systemd-detect-virt,"systemd-detect-virt exits with a return value of
       0 (success) if a virtualization technology is detected, and
       non-zero (error) otherwise. By default, any type of virtualization
       is detected, and the options
--container
and
--vm
can be used to
       limit what types of virtualization are detected. When executed without
--quiet
will print a short identifier for
       the detected virtualization technology."
1470,2,systemd-detect-virt,"When executed without
--quiet
will print a short identifier for
       the detected virtualization technology. The following technologies
       are currently identified:
Table 1. Known virtualization technologies (both VM, i.e."
1470,3,systemd-detect-virt,"Known virtualization technologies (both VM, i.e. full
hardware virtualization, and container, i.e. shared kernel
virtualization)
âââââââââââââ¬âââââââââââââââââ¬âââââââââââââââââââââ
       â
Type
â
ID
â
Product
â
       âââââââââââââ¼âââââââââââââââââ¼âââââââââââââââââââââ¤
       â VM        â
qemu
â QEMU software      â
       â           â                â virtualization,    â
       â           â                â without KVM        â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
kvm
â Linux KVM kernel   â
       â           â                â virtual machine,   â
       â           â                â in combination     â
       â           â                â with QEMU."
1470,4,systemd-detect-virt,"shared kernel
virtualization)
âââââââââââââ¬âââââââââââââââââ¬âââââââââââââââââââââ
       â
Type
â
ID
â
Product
â
       âââââââââââââ¼âââââââââââââââââ¼âââââââââââââââââââââ¤
       â VM        â
qemu
â QEMU software      â
       â           â                â virtualization,    â
       â           â                â without KVM        â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
kvm
â Linux KVM kernel   â
       â           â                â virtual machine,   â
       â           â                â in combination     â
       â           â                â with QEMU. Not     â
       â           â                â used for other     â
       â           â                â virtualizers using â
       â           â                â the KVM            â
       â           â                â interfaces, such   â
       â           â                â as Oracle          â
       â           â                â VirtualBox or      â
       â           â                â Amazon EC2 Nitro,  â
       â           â                â see below. â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
amazon
â Amazon EC2 Nitro   â
       â           â                â using Linux KVM    â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
zvm
â s390 z/VM          â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
vmware
â VMware Workstation â
       â           â                â or Server, and     â
       â           â                â related products   â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
microsoft
â Hyper-V, also      â
       â           â                â known as Viridian  â
       â           â                â or Windows Server  â
       â           â                â Virtualization     â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
oracle
â Oracle VM          â
       â           â                â VirtualBox         â
       â           â                â (historically      â
       â           â                â marketed by        â
       â           â                â innotek and Sun    â
       â           â                â Microsystems), for â
       â           â                â legacy and KVM     â
       â           â                â hypervisor         â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
powervm
â IBM PowerVM        â
       â           â                â hypervisor â comes â
       â           â                â as firmware with   â
       â           â                â some IBM POWER     â
       â           â                â servers            â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
xen
â Xen hypervisor     â
       â           â                â (only domU, not    â
       â           â                â dom0)              â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
bochs
â Bochs Emulator     â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
uml
â User-mode Linux    â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
parallels
â Parallels Desktop, â
       â           â                â Parallels Server   â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
bhyve
â bhyve, FreeBSD     â
       â           â                â hypervisor         â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
qnx
â QNX hypervisor     â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
acrn
â
ACRN hypervisor
[1] â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
apple
â
Apple
â
       â           â                â
virtualization
â
       â           â                â
framework
[2]       â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
sre
â
LMHS SRE
â
       â           â                â
hypervisor
[3]      â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
google
â
Google Compute
â
       â           â                â
Engine
[4]          â
       âââââââââââââ¼âââââââââââââââââ¼âââââââââââââââââââââ¤
       â Container â
openvz
â OpenVZ/Virtuozzo   â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
lxc
â Linux container    â
       â           â                â implementation by  â
       â           â                â LXC                â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
lxc-libvirt
â Linux container    â
       â           â                â implementation by  â
       â           â                â libvirt            â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
systemd-nspawn
â systemd's minimal  â
       â           â                â container          â
       â           â                â implementation,    â
       â           â                â see                â
       â           â                â
systemd-nspawn(1)
â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
docker
â Docker container   â
       â           â                â manager            â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
podman
â
Podman
[5]          â
       â           â                â container manager  â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
rkt
â rkt app container  â
       â           â                â runtime            â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
wsl
â
Windows Subsystem
â
       â           â                â
for Linux
[6]       â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
proot
â
proot
[7] userspace â
       â           â                â chroot/bind mount  â
       â           â                â emulation          â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
pouch
â
Pouch
[8] Container â
       â           â                â Engine             â
       âââââââââââââ´âââââââââââââââââ´âââââââââââââââââââââ

       If multiple virtualization solutions are used, only the
       ""innermost"" is detected and identified."
1470,5,systemd-detect-virt,"â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
amazon
â Amazon EC2 Nitro   â
       â           â                â using Linux KVM    â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
zvm
â s390 z/VM          â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
vmware
â VMware Workstation â
       â           â                â or Server, and     â
       â           â                â related products   â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
microsoft
â Hyper-V, also      â
       â           â                â known as Viridian  â
       â           â                â or Windows Server  â
       â           â                â Virtualization     â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
oracle
â Oracle VM          â
       â           â                â VirtualBox         â
       â           â                â (historically      â
       â           â                â marketed by        â
       â           â                â innotek and Sun    â
       â           â                â Microsystems), for â
       â           â                â legacy and KVM     â
       â           â                â hypervisor         â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
powervm
â IBM PowerVM        â
       â           â                â hypervisor â comes â
       â           â                â as firmware with   â
       â           â                â some IBM POWER     â
       â           â                â servers            â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
xen
â Xen hypervisor     â
       â           â                â (only domU, not    â
       â           â                â dom0)              â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
bochs
â Bochs Emulator     â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
uml
â User-mode Linux    â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
parallels
â Parallels Desktop, â
       â           â                â Parallels Server   â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
bhyve
â bhyve, FreeBSD     â
       â           â                â hypervisor         â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
qnx
â QNX hypervisor     â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
acrn
â
ACRN hypervisor
[1] â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
apple
â
Apple
â
       â           â                â
virtualization
â
       â           â                â
framework
[2]       â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
sre
â
LMHS SRE
â
       â           â                â
hypervisor
[3]      â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
google
â
Google Compute
â
       â           â                â
Engine
[4]          â
       âââââââââââââ¼âââââââââââââââââ¼âââââââââââââââââââââ¤
       â Container â
openvz
â OpenVZ/Virtuozzo   â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
lxc
â Linux container    â
       â           â                â implementation by  â
       â           â                â LXC                â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
lxc-libvirt
â Linux container    â
       â           â                â implementation by  â
       â           â                â libvirt            â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
systemd-nspawn
â systemd's minimal  â
       â           â                â container          â
       â           â                â implementation,    â
       â           â                â see                â
       â           â                â
systemd-nspawn(1)
â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
docker
â Docker container   â
       â           â                â manager            â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
podman
â
Podman
[5]          â
       â           â                â container manager  â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
rkt
â rkt app container  â
       â           â                â runtime            â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
wsl
â
Windows Subsystem
â
       â           â                â
for Linux
[6]       â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
proot
â
proot
[7] userspace â
       â           â                â chroot/bind mount  â
       â           â                â emulation          â
       â           ââââââââââââââââââ¼âââââââââââââââââââââ¤
       â           â
pouch
â
Pouch
[8] Container â
       â           â                â Engine             â
       âââââââââââââ´âââââââââââââââââ´âââââââââââââââââââââ

       If multiple virtualization solutions are used, only the
       ""innermost"" is detected and identified. That means if both machine
       and container virtualization are used in conjunction, only the
       latter will be identified (unless
--vm
is passed). Windows Subsystem for Linux is not a Linux container, but an
       environment for running Linux userspace applications on top of the
       Windows kernel using a Linux-compatible interface."
1470,6,systemd-detect-virt,"Windows Subsystem for Linux is not a Linux container, but an
       environment for running Linux userspace applications on top of the
       Windows kernel using a Linux-compatible interface. WSL is
       categorized as a container for practical purposes. Multiple WSL
       environments share the same kernel and services should generally
       behave like when being run in a container."
1470,7,systemd-detect-virt,"Multiple WSL
       environments share the same kernel and services should generally
       behave like when being run in a container. When executed with
--cvm
, instead of printing the virtualization
       technology, it will display the confidential virtual machine
       technology, if any. The following technologies are currently
       identified:
Table 2."
1470,8,systemd-detect-virt,"When executed with
--cvm
, instead of printing the virtualization
       technology, it will display the confidential virtual machine
       technology, if any. The following technologies are currently
       identified:
Table 2. Known confidential virtualization technologies
ââââââââââ¬âââââââââââ¬âââââââââââââââââââââ
       â
Arch
â
ID
â
Technology
â
       ââââââââââ¼âââââââââââ¼âââââââââââââââââââââ¤
       â x86_64 â
sev
â AMD Secure         â
       â        â          â Encrypted          â
       â        â          â Virtualization     â
       â        ââââââââââââ¼âââââââââââââââââââââ¤
       â        â
sev-es
â AMD Secure         â
       â        â          â Encrypted          â
       â        â          â Virtualization -   â
       â        â          â Encrypted State    â
       â        ââââââââââââ¼âââââââââââââââââââââ¤
       â        â
sev-snp
â AMD Secure         â
       â        â          â Encrypted          â
       â        â          â Virtualization -   â
       â        â          â Secure Nested      â
       â        â          â Paging             â
       â        ââââââââââââ¼âââââââââââââââââââââ¤
       â        â
tdx
â Intel Trust Domain â
       â        â          â Extensions         â
       ââââââââââ¼âââââââââââ¼âââââââââââââââââââââ¤
       â s390x  â
protvirt
â IBM Protected      â
       â        â          â Virtualization     â
       â        â          â (Secure Execution) â
       ââââââââââ¼âââââââââââ¼âââââââââââââââââââââ¤
       â arm64  â
cca
â Arm Confidential   â
       â        â          â Compute            â
       â        â          â Architecture       â
       ââââââââââ´âââââââââââ´âââââââââââââââââââââ"
1471,0,systemd-cryptenroll,"systemd-cryptenroll
is a tool for enrolling hardware security
       tokens and devices into a LUKS2 encrypted volume, which may then
       be used to unlock the volume during boot. Specifically, it
       supports tokens and credentials of the following kind to be
       enrolled:

        1. PKCS#11 security tokens and smartcards that may carry an RSA
           or EC key pair (e.g."
1471,1,systemd-cryptenroll,"PKCS#11 security tokens and smartcards that may carry an RSA
           or EC key pair (e.g. various YubiKeys)

        2. FIDO2 security tokens that implement the ""hmac-secret""
           extension (most FIDO2 keys, including YubiKeys)

        3."
1471,2,systemd-cryptenroll,"FIDO2 security tokens that implement the ""hmac-secret""
           extension (most FIDO2 keys, including YubiKeys)

        3. TPM2 security devices

        4. Regular passphrases

        5."
1471,3,systemd-cryptenroll,"Regular passphrases

        5. Recovery keys. These are similar to regular passphrases,
           however are randomly generated on the computer and thus
           generally have higher entropy than user-chosen passphrases."
1471,4,systemd-cryptenroll,"These are similar to regular passphrases,
           however are randomly generated on the computer and thus
           generally have higher entropy than user-chosen passphrases. Their character set has been designed to ensure they are easy
           to type in, while having high entropy. They may also be
           scanned off screen using QR codes."
1471,5,systemd-cryptenroll,"They may also be
           scanned off screen using QR codes. Recovery keys may be used
           for unlocking LUKS2 volumes wherever passphrases are accepted. They are intended to be used in combination with an enrolled
           hardware security token, as a recovery option when the token
           is lost."
1471,6,systemd-cryptenroll,"They are intended to be used in combination with an enrolled
           hardware security token, as a recovery option when the token
           is lost. In addition, the tool may be used to enumerate currently enrolled
       security tokens and wipe a subset of them. The latter may be
       combined with the enrollment operation of a new security token, in
       order to update or replace enrollments."
1471,7,systemd-cryptenroll,"The latter may be
       combined with the enrollment operation of a new security token, in
       order to update or replace enrollments. The tool supports only LUKS2 volumes, as it stores token
       meta-information in the LUKS2 JSON token area, which is not
       available in other encryption formats. systemd-cryptsetup
operates on the device backing /var/ if no
       device is specified explicitly, and no wipe operation is
       requested."
1471,8,systemd-cryptenroll,"systemd-cryptsetup
operates on the device backing /var/ if no
       device is specified explicitly, and no wipe operation is
       requested. (Note that in the typical case where /var/ is on the
       same file system as the root file system, this hence enrolls a key
       into the backing device of the root file system.)
TPM2 PCRs and policies
PCRs allow binding of the encryption of secrets to specific
       software versions and system state, so that the enrolled key is
       only accessible (may be ""unsealed"") if specific trusted software
       and/or configuration is used. Such bindings may be created with
       the option
--tpm2-pcrs=
described below."
1471,9,systemd-cryptenroll,"Such bindings may be created with
       the option
--tpm2-pcrs=
described below. Secrets may also be bound indirectly: a signed policy for a state
       of some combination of PCR values is provided, and the secret is
       bound to the public part of the key used to sign this policy. This
       means that the owner of a key can generate a sequence of signed
       policies, for specific software versions and system states, and
       the secret can be decrypted as long as the machine state matches
       one of those policies."
1471,10,systemd-cryptenroll,"This
       means that the owner of a key can generate a sequence of signed
       policies, for specific software versions and system states, and
       the secret can be decrypted as long as the machine state matches
       one of those policies. For example, a vendor may provide such a
       policy for each kernel+initrd update, allowing users to encrypt
       secrets so that they can be decrypted when running any
       kernel+initrd signed by the vendor. Such bindings may be created
       with the options
--tpm2-public-key=
,
--tpm2-public-key-pcrs=
,
--tpm2-signature=
described below."
1471,11,systemd-cryptenroll,"Such bindings may be created
       with the options
--tpm2-public-key=
,
--tpm2-public-key-pcrs=
,
--tpm2-signature=
described below. See
Linux TPM PCR Registry
[1] for an authoritative list of PCRs
       and how they are updated. The table below contains a quick
       reference, describing in particular the PCRs modified by systemd."
1471,12,systemd-cryptenroll,"The table below contains a quick
       reference, describing in particular the PCRs modified by systemd. Table 1. Well-known PCR Definitions
âââââââ¬ââââââââââââââââââââââ¬ââââââââââââââââââââââââââââââââ
       â
PCR
â
name
â
Explanation
â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 0   â platform-code       â Core system                   â
       â     â                     â firmware                      â
       â     â                     â executable code;              â
       â     â                     â changes on                    â
       â     â                     â firmware updates              â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 1   â platform-config     â Core system                   â
       â     â                     â firmware data/host            â
       â     â                     â platform                      â
       â     â                     â configuration;                â
       â     â                     â typically contains            â
       â     â                     â serial and model              â
       â     â                     â numbers, changes              â
       â     â                     â on basic                      â
       â     â                     â hardware/CPU/RAM              â
       â     â                     â replacements                  â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 2   â external-code       â Extended or                   â
       â     â                     â pluggable                     â
       â     â                     â executable code;              â
       â     â                     â includes option               â
       â     â                     â ROMs on pluggable             â
       â     â                     â hardware                      â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 3   â external-config     â Extended or                   â
       â     â                     â pluggable firmware            â
       â     â                     â data; includes                â
       â     â                     â information about             â
       â     â                     â pluggable hardware            â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 4   â boot-loader-code    â Boot loader and               â
       â     â                     â additional                    â
       â     â                     â drivers, PE                   â
       â     â                     â binaries invoked              â
       â     â                     â by the boot                   â
       â     â                     â loader; changes on            â
       â     â                     â boot loader                   â
       â     â                     â updates."
1471,13,systemd-cryptenroll,"Well-known PCR Definitions
âââââââ¬ââââââââââââââââââââââ¬ââââââââââââââââââââââââââââââââ
       â
PCR
â
name
â
Explanation
â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 0   â platform-code       â Core system                   â
       â     â                     â firmware                      â
       â     â                     â executable code;              â
       â     â                     â changes on                    â
       â     â                     â firmware updates              â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 1   â platform-config     â Core system                   â
       â     â                     â firmware data/host            â
       â     â                     â platform                      â
       â     â                     â configuration;                â
       â     â                     â typically contains            â
       â     â                     â serial and model              â
       â     â                     â numbers, changes              â
       â     â                     â on basic                      â
       â     â                     â hardware/CPU/RAM              â
       â     â                     â replacements                  â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 2   â external-code       â Extended or                   â
       â     â                     â pluggable                     â
       â     â                     â executable code;              â
       â     â                     â includes option               â
       â     â                     â ROMs on pluggable             â
       â     â                     â hardware                      â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 3   â external-config     â Extended or                   â
       â     â                     â pluggable firmware            â
       â     â                     â data; includes                â
       â     â                     â information about             â
       â     â                     â pluggable hardware            â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 4   â boot-loader-code    â Boot loader and               â
       â     â                     â additional                    â
       â     â                     â drivers, PE                   â
       â     â                     â binaries invoked              â
       â     â                     â by the boot                   â
       â     â                     â loader; changes on            â
       â     â                     â boot loader                   â
       â     â                     â updates. â
       â     â                     â
sd-stub(7)
â
       â     â                     â measures system               â
       â     â                     â extension images              â
       â     â                     â read from the ESP             â
       â     â                     â here too (see                 â
       â     â                     â
systemd-sysext(8)
). â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 5   â boot-loader-config  â GPT/Partition                 â
       â     â                     â table; changes when           â
       â     â                     â the partitions are            â
       â     â                     â added, modified, or           â
       â     â                     â removed                       â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 7   â secure-boot-policy  â Secure Boot state;            â
       â     â                     â changes when UEFI             â
       â     â                     â SecureBoot mode is            â
       â     â                     â enabled/disabled,             â
       â     â                     â or firmware                   â
       â     â                     â certificates (PK,             â
       â     â                     â KEK, db, dbx, ...)            â
       â     â                     â changes."
1471,14,systemd-cryptenroll,"â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 5   â boot-loader-config  â GPT/Partition                 â
       â     â                     â table; changes when           â
       â     â                     â the partitions are            â
       â     â                     â added, modified, or           â
       â     â                     â removed                       â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 7   â secure-boot-policy  â Secure Boot state;            â
       â     â                     â changes when UEFI             â
       â     â                     â SecureBoot mode is            â
       â     â                     â enabled/disabled,             â
       â     â                     â or firmware                   â
       â     â                     â certificates (PK,             â
       â     â                     â KEK, db, dbx, ...)            â
       â     â                     â changes. â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 9   â kernel-initrd       â The Linux kernel              â
       â     â                     â measures all                  â
       â     â                     â initrds it receives           â
       â     â                     â into this PCR. â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 10  â ima                 â The IMA project               â
       â     â                     â measures its                  â
       â     â                     â runtime state into            â
       â     â                     â this PCR."
1471,15,systemd-cryptenroll,"â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 10  â ima                 â The IMA project               â
       â     â                     â measures its                  â
       â     â                     â runtime state into            â
       â     â                     â this PCR. â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 11  â kernel-boot         â
systemd-stub(7)
â
       â     â                     â measures the ELF              â
       â     â                     â kernel image,                 â
       â     â                     â embedded initrd and           â
       â     â                     â other payload of              â
       â     â                     â the PE image it is            â
       â     â                     â placed in into this           â
       â     â                     â PCR. â
       â     â                     â
systemd-pcrphase.service(8)
â
       â     â                     â measures boot phase           â
       â     â                     â strings into this             â
       â     â                     â PCR at various                â
       â     â                     â milestones of the             â
       â     â                     â boot process."
1471,16,systemd-cryptenroll,"â
       â     â                     â
systemd-pcrphase.service(8)
â
       â     â                     â measures boot phase           â
       â     â                     â strings into this             â
       â     â                     â PCR at various                â
       â     â                     â milestones of the             â
       â     â                     â boot process. â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 12  â kernel-config       â
systemd-boot(7)
measures      â
       â     â                     â the kernel command line       â
       â     â                     â into this PCR. â
       â     â                     â
systemd-stub(7)
measures      â
       â     â                     â any manually specified        â
       â     â                     â kernel command line (i.e."
1471,17,systemd-cryptenroll,"â
       â     â                     â
systemd-stub(7)
measures      â
       â     â                     â any manually specified        â
       â     â                     â kernel command line (i.e. a   â
       â     â                     â kernel command line that      â
       â     â                     â overrides the one embedded    â
       â     â                     â in the unified PE image)      â
       â     â                     â and loaded credentials into   â
       â     â                     â this PCR. â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 13  â sysexts             â
systemd-stub(7)
measures      â
       â     â                     â any
systemd-sysext(8)
â
       â     â                     â images it passes to the       â
       â     â                     â booted kernel into this       â
       â     â                     â PCR."
1471,18,systemd-cryptenroll,"â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 13  â sysexts             â
systemd-stub(7)
measures      â
       â     â                     â any
systemd-sysext(8)
â
       â     â                     â images it passes to the       â
       â     â                     â booted kernel into this       â
       â     â                     â PCR. â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 14  â shim-policy         â The shim project measures     â
       â     â                     â its ""MOK"" certificates and    â
       â     â                     â hashes into this PCR. â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 15  â system-identity     â
systemd-cryptsetup(8)
â
       â     â                     â optionally measures the       â
       â     â                     â volume key of activated       â
       â     â                     â LUKS volumes into this PCR."
1471,19,systemd-cryptenroll,"â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 15  â system-identity     â
systemd-cryptsetup(8)
â
       â     â                     â optionally measures the       â
       â     â                     â volume key of activated       â
       â     â                     â LUKS volumes into this PCR. â
       â     â                     â
systemd-pcrmachine.service(8)
â
       â     â                     â measures the
machine-id(5)
â
       â     â                     â into this PCR. â
       â     â                     â
systemd-pcrfs@.service(8)
â
       â     â                     â measures mount points, file   â
       â     â                     â system UUIDs, labels,         â
       â     â                     â partition UUIDs of the root   â
       â     â                     â and /var/ filesystems into    â
       â     â                     â this PCR."
1471,20,systemd-cryptenroll,"â
       â     â                     â
systemd-pcrfs@.service(8)
â
       â     â                     â measures mount points, file   â
       â     â                     â system UUIDs, labels,         â
       â     â                     â partition UUIDs of the root   â
       â     â                     â and /var/ filesystems into    â
       â     â                     â this PCR. â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 16  â debug               â Debug                         â
       âââââââ¼ââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
       â 23  â application-support â Application Support           â
       âââââââ´ââââââââââââââââââââââ´ââââââââââââââââââââââââââââââââ

       In general, encrypted volumes would be bound to some combination
       of PCRs 7, 11, and 14 (if shim/MOK is used). In order to allow
       firmware and OS version updates, it is typically not advisable to
       use PCRs such as 0 and 2, since the program code they cover should
       already be covered indirectly through the certificates measured
       into PCR 7."
1471,21,systemd-cryptenroll,"In order to allow
       firmware and OS version updates, it is typically not advisable to
       use PCRs such as 0 and 2, since the program code they cover should
       already be covered indirectly through the certificates measured
       into PCR 7. Validation through certificates hashes is typically
       preferable over validation through direct measurements as it is
       less brittle in context of OS/firmware updates: the measurements
       will change on every update, but signatures should remain
       unchanged. See the
Linux TPM PCR Registry
[1] for more discussion."
1472,0,systemd-dissect,"systemd-dissect
is a tool for introspecting and interacting with
       file system OS disk images, specifically Discoverable Disk Images
       (DDIs). It supports four different operations:

        1. Show general OS image information, including the image's
os-release(5)
data, machine ID, partition information and
           more."
1472,1,systemd-dissect,"Show general OS image information, including the image's
os-release(5)
data, machine ID, partition information and
           more. 2. Mount an OS image to a local directory."
1472,2,systemd-dissect,"Mount an OS image to a local directory. In this mode it will
           dissect the OS image and mount the included partitions
           according to their designation onto a directory and possibly
           sub-directories. 3."
1472,3,systemd-dissect,"3. Unmount an OS image from a local directory. In this mode it
           will recursively unmount the mounted partitions and remove the
           underlying loop device, including all the partition
           sub-devices."
1472,4,systemd-dissect,"In this mode it
           will recursively unmount the mounted partitions and remove the
           underlying loop device, including all the partition
           sub-devices. 4. Copy files and directories in and out of an OS image."
1472,5,systemd-dissect,"Copy files and directories in and out of an OS image. The tool may operate on three types of OS images:

        1. OS disk images containing a GPT partition table envelope, with
           partitions marked according to the
Discoverable Partitions
Specification
[1]."
1472,6,systemd-dissect,"OS disk images containing a GPT partition table envelope, with
           partitions marked according to the
Discoverable Partitions
Specification
[1]. 2. OS disk images containing just a plain file-system without an
           enveloping partition table."
1472,7,systemd-dissect,"OS disk images containing just a plain file-system without an
           enveloping partition table. (This file system is assumed to be
           the root file system of the OS.)

        3. OS disk images containing a GPT or MBR partition table, with a
           single partition only."
1472,8,systemd-dissect,"OS disk images containing a GPT or MBR partition table, with a
           single partition only. (This partition is assumed to contain
           the root file system of the OS.)

       OS images may use any kind of Linux-supported file systems. In
       addition they may make use of LUKS disk encryption, and contain
       Verity integrity information."
1472,9,systemd-dissect,"In
       addition they may make use of LUKS disk encryption, and contain
       Verity integrity information. Note that qualifying OS images may
       be booted with
systemd-nspawn(1)
's
--image=
switch, and be used as
       root file system for system service using the
RootImage=
unit file
       setting, see
systemd.exec(5)
. Note that the partition table shown when invoked without command
       switch (as listed below) does not necessarily show all partitions
       included in the image, but just the partitions that are understood
       and considered part of an OS disk image."
1472,10,systemd-dissect,"Note that the partition table shown when invoked without command
       switch (as listed below) does not necessarily show all partitions
       included in the image, but just the partitions that are understood
       and considered part of an OS disk image. Specifically, partitions
       of unknown types are ignored, as well as duplicate partitions
       (i.e. more than one per partition type), as are root and /usr/
       partitions of architectures not compatible with the local system."
1472,11,systemd-dissect,"more than one per partition type), as are root and /usr/
       partitions of architectures not compatible with the local system. In other words: this tool will display what it operates with when
       mounting the image. To display the complete list of partitions use
       a tool such as
fdisk(8)
."
1472,12,systemd-dissect,"To display the complete list of partitions use
       a tool such as
fdisk(8)
. The
systemd-dissect
command may be invoked as
mount.ddi
in which
       case it implements the
mount(8)
""external helper"" interface. This
       ensures disk images compatible with
systemd-dissect
can be mounted
       directly by
mount
and
fstab(5)
."
1472,13,systemd-dissect,"This
       ensures disk images compatible with
systemd-dissect
can be mounted
       directly by
mount
and
fstab(5)
. For details see below. In place of the image path a "".v/"" versioned directory may be
       specified, see
systemd.v(7)
for details."
1473,0,systemd-escape,"systemd-escape
may be used to escape strings for inclusion in
       systemd unit names. The command may be used to escape and to undo
       escaping of strings. The command takes any number of strings on the command line, and
       will process them individually, one after another."
1473,1,systemd-escape,"The command takes any number of strings on the command line, and
       will process them individually, one after another. It will output
       them separated by spaces to stdout. By default, this command will escape the strings passed, unless
--unescape
is passed which results in the inverse operation being
       applied."
1473,2,systemd-escape,"By default, this command will escape the strings passed, unless
--unescape
is passed which results in the inverse operation being
       applied. If
--mangle
is given, a special mode of escaping is
       applied instead, which assumes the string is already escaped but
       will escape everything that appears obviously non-escaped. For details on the escaping and unescaping algorithms see the
       relevant section in
systemd.unit(5)
."
1474,0,systemd-firstboot,"The
systemd-firstboot.service
unit is one of the units which are
       used to initialize the machine configuration during ""First Boot"",
       i.e. when the system is freshly installed or after a factory
       reset. The
systemd(1)
manager itself will initialize
machine-id(5)
and preset all units, enabling or disabling them according to the
systemd.preset(5)
settings."
1474,1,systemd-firstboot,"The
systemd(1)
manager itself will initialize
machine-id(5)
and preset all units, enabling or disabling them according to the
systemd.preset(5)
settings. systemd-firstboot.service is started
       later to interactively initialize basic system configuration. It
       is started only if
ConditionFirstBoot=yes
is met, which
       essentially means that /etc/ is unpopulated, see
systemd.unit(5)
for details."
1474,2,systemd-firstboot,"It
       is started only if
ConditionFirstBoot=yes
is met, which
       essentially means that /etc/ is unpopulated, see
systemd.unit(5)
for details. System credentials may be used to inject
       configuration; those settings are not queried interactively. The
systemd-firstboot
command can also be used to
       non-interactively initialize an offline system image."
1474,3,systemd-firstboot,"The
systemd-firstboot
command can also be used to
       non-interactively initialize an offline system image. The following settings may be configured:

       â¢   The machine ID of the system

       â¢   The system locale, more specifically the two locale variables
LANG=
and
LC_MESSAGES
â¢   The system keyboard map

       â¢   The system time zone

       â¢   The system hostname

       â¢   The kernel command line used when installing kernel images

       â¢   The root user's password and shell

       Each of the fields may either be queried interactively by users,
       set non-interactively on the tool's command line, or be copied
       from a host system that is used to set up the system image. If a setting is already initialized, it will not be overwritten
       and the user will not be prompted for the setting."
1474,4,systemd-firstboot,"If a setting is already initialized, it will not be overwritten
       and the user will not be prompted for the setting. Note that this tool operates directly on the file system and does
       not involve any running system services, unlike
localectl(1)
,
timedatectl(1)
or
hostnamectl(1)
. This allows
systemd-firstboot
to
       operate on mounted but not booted disk images and in early boot."
1474,5,systemd-firstboot,"Note that this tool operates directly on the file system and does
       not involve any running system services, unlike
localectl(1)
,
timedatectl(1)
or
hostnamectl(1)
. This allows
systemd-firstboot
to
       operate on mounted but not booted disk images and in early boot. It is not recommended to use
systemd-firstboot
on the running
       system after it has been set up."
1475,0,systemd-keyutil,"systemd-keyutil
can be used to perform various operations on
       private keys and X.509 certificates."
1476,0,systemd-id128,"id128
may be used to conveniently print
sd-id128(3)
UUIDs. What
       identifier is printed depends on the specific verb. With
new
, a new random identifier will be generated."
1476,1,systemd-id128,"With
new
, a new random identifier will be generated. With
machine-id
, the identifier of the current machine will be
       printed. See
machine-id(5)
."
1476,2,systemd-id128,"See
machine-id(5)
. With
boot-id
, the identifier of the current boot will be printed. With
invocation-id
, the identifier of the current service
       invocation will be printed."
1476,3,systemd-id128,"With
invocation-id
, the identifier of the current service
       invocation will be printed. This is available in systemd services. See
systemd.exec(5)
."
1476,4,systemd-id128,"See
systemd.exec(5)
. With
show
, well-known IDs are printed (for now, only GPT partition
       type UUIDs), along with brief identifier strings. When no
       arguments are specified, all known IDs are shown."
1476,5,systemd-id128,"When no
       arguments are specified, all known IDs are shown. When arguments
       are specified, they may be the identifiers or ID values of one or
       more known IDs, which are then printed with their name, or
       arbitrary IDs, which are then printed with a placeholder name. Combine with
--uuid
to list the IDs in UUID style, i.e."
1476,6,systemd-id128,"Combine with
--uuid
to list the IDs in UUID style, i.e. the way
       GPT partition type UUIDs are usually shown. machine-id
,
boot-id
, and
show
may be combined with the
--app-specific=
app-id
switch to generate application-specific IDs."
1476,7,systemd-id128,"machine-id
,
boot-id
, and
show
may be combined with the
--app-specific=
app-id
switch to generate application-specific IDs. See
sd_id128_get_machine(3)
for the discussion when this is
       useful. Support for
show --app-specific=
was added in version 255."
1476,8,systemd-id128,"Support for
show --app-specific=
was added in version 255. var-partition-uuid
prints a UUID which, following the
Discoverable
Partitions Specification
[1], should be used as the GPT partition
       UUID for /var/, being derived from the GPT partition type, keyed
       by the local /etc/machine-id. Added in version 257."
1477,0,systemd-firstboot,"The
systemd-firstboot.service
unit is one of the units which are
       used to initialize the machine configuration during ""First Boot"",
       i.e. when the system is freshly installed or after a factory
       reset. The
systemd(1)
manager itself will initialize
machine-id(5)
and preset all units, enabling or disabling them according to the
systemd.preset(5)
settings."
1477,1,systemd-firstboot,"The
systemd(1)
manager itself will initialize
machine-id(5)
and preset all units, enabling or disabling them according to the
systemd.preset(5)
settings. systemd-firstboot.service is started
       later to interactively initialize basic system configuration. It
       is started only if
ConditionFirstBoot=yes
is met, which
       essentially means that /etc/ is unpopulated, see
systemd.unit(5)
for details."
1477,2,systemd-firstboot,"It
       is started only if
ConditionFirstBoot=yes
is met, which
       essentially means that /etc/ is unpopulated, see
systemd.unit(5)
for details. System credentials may be used to inject
       configuration; those settings are not queried interactively. The
systemd-firstboot
command can also be used to
       non-interactively initialize an offline system image."
1477,3,systemd-firstboot,"The
systemd-firstboot
command can also be used to
       non-interactively initialize an offline system image. The following settings may be configured:

       â¢   The machine ID of the system

       â¢   The system locale, more specifically the two locale variables
LANG=
and
LC_MESSAGES
â¢   The system keyboard map

       â¢   The system time zone

       â¢   The system hostname

       â¢   The kernel command line used when installing kernel images

       â¢   The root user's password and shell

       Each of the fields may either be queried interactively by users,
       set non-interactively on the tool's command line, or be copied
       from a host system that is used to set up the system image. If a setting is already initialized, it will not be overwritten
       and the user will not be prompted for the setting."
1477,4,systemd-firstboot,"If a setting is already initialized, it will not be overwritten
       and the user will not be prompted for the setting. Note that this tool operates directly on the file system and does
       not involve any running system services, unlike
localectl(1)
,
timedatectl(1)
or
hostnamectl(1)
. This allows
systemd-firstboot
to
       operate on mounted but not booted disk images and in early boot."
1477,5,systemd-firstboot,"Note that this tool operates directly on the file system and does
       not involve any running system services, unlike
localectl(1)
,
timedatectl(1)
or
hostnamectl(1)
. This allows
systemd-firstboot
to
       operate on mounted but not booted disk images and in early boot. It is not recommended to use
systemd-firstboot
on the running
       system after it has been set up."
1478,0,systemd-machine-id-setup,"systemd-machine-id-setup
may be used by system installer tools to
       initialize the machine ID stored in /etc/machine-id at install
       time, with a provisioned or randomly generated ID. See
machine-id(5)
for more information about this file. If the tool is invoked without the
--commit
switch,
       /etc/machine-id is initialized with a valid, new machine ID if it
       is missing or empty."
1478,1,systemd-machine-id-setup,"If the tool is invoked without the
--commit
switch,
       /etc/machine-id is initialized with a valid, new machine ID if it
       is missing or empty. The new machine ID will be acquired in the
       following fashion:

        1. If a valid machine ID is stored in /run/machine-id, the
           machine ID is copied and used to initialize the machine ID in
           /etc/machine-id."
1478,2,systemd-machine-id-setup,"If a valid machine ID is stored in /run/machine-id, the
           machine ID is copied and used to initialize the machine ID in
           /etc/machine-id. This step is skipped if
--root=
is specified
           or running in a chroot environment. 2."
1478,3,systemd-machine-id-setup,"2. If a valid D-Bus machine ID is already configured for the
           system, the D-Bus machine ID is copied and used to initialize
           the machine ID in /etc/machine-id. 3."
1478,4,systemd-machine-id-setup,"3. If a valid machine ID is provided through
system.machine_id
credential, the machine ID is copied and used to initialize
           the machine ID in /etc/machine-id. This step is skipped if
--root=
is specified or running in a chroot environment."
1478,5,systemd-machine-id-setup,"This step is skipped if
--root=
is specified or running in a chroot environment. 4. If run inside a KVM virtual machine and a UUID is configured
           (via the
-uuid
option), this UUID is used to initialize the
           machine ID."
1478,6,systemd-machine-id-setup,"If run inside a KVM virtual machine and a UUID is configured
           (via the
-uuid
option), this UUID is used to initialize the
           machine ID. The caller must ensure that the UUID passed is
           sufficiently unique and is different for every booted instance
           of the VM. This step is skipped if
--root=
is specified or
           running in a chroot environment."
1478,7,systemd-machine-id-setup,"This step is skipped if
--root=
is specified or
           running in a chroot environment. 5. Similarly, if run inside a Linux container environment and a
           UUID is configured for the container, this is used to
           initialize the machine ID."
1478,8,systemd-machine-id-setup,"Similarly, if run inside a Linux container environment and a
           UUID is configured for the container, this is used to
           initialize the machine ID. For details, see the documentation
           of the
Container Interface
[1]. This step is skipped if
--root=
is specified or running in a chroot environment."
1478,9,systemd-machine-id-setup,"This step is skipped if
--root=
is specified or running in a chroot environment. 6. Otherwise, a new ID is randomly generated."
1478,10,systemd-machine-id-setup,"Otherwise, a new ID is randomly generated. The
--commit
switch may be used to commit a transient machined ID
       to disk, making it persistent. For details, see below."
1478,11,systemd-machine-id-setup,"The
--commit
switch may be used to commit a transient machined ID
       to disk, making it persistent. For details, see below. Use
systemd-firstboot(1)
to initialize the machine ID on mounted
       (but not booted) system images."
1479,0,systemd-inhibit,"systemd-inhibit
may be used to execute a program with a shutdown,
       sleep, or idle inhibitor lock taken. The lock will be acquired
       before the specified command line is executed and released
       afterwards. Inhibitor locks may be used to block or delay system sleep and
       shutdown requests from the user, as well as automatic idle
       handling of the OS."
1479,1,systemd-inhibit,"Inhibitor locks may be used to block or delay system sleep and
       shutdown requests from the user, as well as automatic idle
       handling of the OS. This is useful to avoid system suspends while
       an optical disc is being recorded, or similar operations that
       should not be interrupted. For more information see
Inhibitor Locks
[1]."
1480,0,systemd-measure,"Note: this command is experimental for now. While it is likely to
       become a regular component of systemd, it might still change in
       behaviour and interface. systemd-measure
is a tool that may be used to pre-calculate and
       sign the expected TPM2 PCR 11 values that should be seen when a
       Linux
Unified Kernel Image (UKI)
[1] based on
systemd-stub(7)
is
       booted up."
1480,1,systemd-measure,"systemd-measure
is a tool that may be used to pre-calculate and
       sign the expected TPM2 PCR 11 values that should be seen when a
       Linux
Unified Kernel Image (UKI)
[1] based on
systemd-stub(7)
is
       booted up. It accepts paths to the ELF kernel image file, initrd
       image file, devicetree file, kernel command line file,
os-release(5)
file, boot splash file, and TPM2 PCR PEM public key
       file that make up the unified kernel image, and determines the PCR
       values expected to be in place after booting the image. Calculation starts with a zero-initialized PCR 11, and is executed
       in a fashion compatible with what systemd-stub does at boot."
1480,2,systemd-measure,"Calculation starts with a zero-initialized PCR 11, and is executed
       in a fashion compatible with what systemd-stub does at boot. The
       result may optionally be signed cryptographically, to allow TPM2
       policies that can only be unlocked if a certain set of kernels is
       booted, for which such a PCR signature can be provided. It usually does not make sense to call this tool directly when
       constructing a UKI."
1480,3,systemd-measure,"The
       result may optionally be signed cryptographically, to allow TPM2
       policies that can only be unlocked if a certain set of kernels is
       booted, for which such a PCR signature can be provided. It usually does not make sense to call this tool directly when
       constructing a UKI. Instead,
ukify(1)
should be used; it will
       invoke
systemd-measure
and take care of embedding the resulting
       measurements into the UKI."
1481,0,systemd-mount,"systemd-mount
may be used to create and start a transient .mount
       or .automount unit of the file system
WHAT
on the mount point
WHERE
. In many ways,
systemd-mount
is similar to the lower-level
mount(8)
command, however instead of executing the mount operation directly
       and immediately,
systemd-mount
schedules it through the service
       manager job queue, so that it may pull in further dependencies
       (such as parent mounts, or a file system checker to execute a
       priori), and may make use of the auto-mounting logic. The command takes either one or two arguments."
1481,1,systemd-mount,"The command takes either one or two arguments. If only one
       argument is specified it should refer to a block device or regular
       file containing a file system (e.g. ""/dev/sdb1"" or
       ""/path/to/disk.img"")."
1481,2,systemd-mount,"""/dev/sdb1"" or
       ""/path/to/disk.img""). The block device or image file is then
       probed for a file system label and other metadata, and is mounted
       to a directory below /run/media/system/ whose name is generated
       from the file system label. In this mode the block device or image
       file must exist at the time of invocation of the command, so that
       it may be probed."
1481,3,systemd-mount,"In this mode the block device or image
       file must exist at the time of invocation of the command, so that
       it may be probed. If the device is found to be a removable block
       device (e.g. a USB stick), an automount point is created instead
       of a regular mount point (i.e."
1481,4,systemd-mount,"a USB stick), an automount point is created instead
       of a regular mount point (i.e. the
--automount=
option is implied,
       see below). If the option
--tmpfs
is specified, then the argument
       is interpreted as the path where the new temporary file system
       shall be mounted."
1481,5,systemd-mount,"If the option
--tmpfs
is specified, then the argument
       is interpreted as the path where the new temporary file system
       shall be mounted. If two arguments are specified, the first indicates the mount
       source (the
WHAT
) and the second indicates the path to mount it on
       (the
WHERE
). In this mode no probing of the source is attempted,
       and a backing device node does not have to exist."
1481,6,systemd-mount,"In this mode no probing of the source is attempted,
       and a backing device node does not have to exist. However, if this
       mode is combined with
--discover
, device node probing for
       additional metadata is enabled, and â much like in the
       single-argument case discussed above â the specified device has to
       exist at the time of invocation of the command. Use the
--list
command to show a terse table of all local, known
       block devices with file systems that may be mounted with this
       command."
1481,7,systemd-mount,"Use the
--list
command to show a terse table of all local, known
       block devices with file systems that may be mounted with this
       command. systemd-umount
can be used to unmount a mount or automount point. It is the same as
systemd-mount --umount
."
1482,0,homectl,"homectl
may be used to create, remove, change or inspect a user's
       home directory. It's primarily a command interfacing with
systemd-homed.service(8)
which manages home directories of users. Home directories managed by systemd-homed.service are
       self-contained, and thus include the user's full metadata record
       in the home's data storage itself, making them easy to migrate
       between machines."
1482,1,homectl,"Home directories managed by systemd-homed.service are
       self-contained, and thus include the user's full metadata record
       in the home's data storage itself, making them easy to migrate
       between machines. In particular, a home directory describes a
       matching user record, and every user record managed by
       systemd-homed.service also implies existence and encapsulation of
       a home directory. The user account and home directory become the
       same concept."
1482,2,homectl,"The user account and home directory become the
       same concept. The following backing storage mechanisms are supported:

       â¢   An individual LUKS2 encrypted loopback file for a user, stored
           in /home/*.home. At login the file system contained in this
           files is mounted, after the LUKS2 encrypted volume has been
           attached."
1482,3,homectl,"At login the file system contained in this
           files is mounted, after the LUKS2 encrypted volume has been
           attached. The user's password is identical to the encryption
           passphrase of the LUKS2 volume. Access to data without
           preceding user authentication is thus not possible, even for
           the system administrator."
1482,4,homectl,"Access to data without
           preceding user authentication is thus not possible, even for
           the system administrator. This storage mechanism provides the
           strongest data security and is thus recommended. â¢   Similar, but the LUKS2 encrypted file system is located on
           regular block device, such as a USB storage stick."
1482,5,homectl,"â¢   Similar, but the LUKS2 encrypted file system is located on
           regular block device, such as a USB storage stick. In this
           mode home directories and all data they include are nicely
           migratable between machines, simply by plugging the USB stick
           into different systems at different times. â¢   An encrypted directory using ""fscrypt"" on file systems that
           support it (at the moment this is primarily ""ext4""), located
           in /home/*.homedir."
1482,6,homectl,"â¢   An encrypted directory using ""fscrypt"" on file systems that
           support it (at the moment this is primarily ""ext4""), located
           in /home/*.homedir. This mechanism also provides encryption,
           but substantially weaker than LUKS2, as most file system
           metadata is unprotected. Moreover it currently does not
           support changing user passwords once the home directory has
           been created."
1482,7,homectl,"Moreover it currently does not
           support changing user passwords once the home directory has
           been created. â¢   A ""btrfs"" subvolume for each user, also located in
           /home/*.homedir. This provides no encryption, but good quota
           support."
1482,8,homectl,"This provides no encryption, but good quota
           support. â¢   A regular directory for each user, also located in
           /home/*.homedir. This provides no encryption, but is a
           suitable fallback available on all machines, even where LUKS2,
           ""fscrypt"" or ""btrfs"" support is not available."
1482,9,homectl,"This provides no encryption, but is a
           suitable fallback available on all machines, even where LUKS2,
           ""fscrypt"" or ""btrfs"" support is not available. â¢   An individual Windows file share (CIFS) for each user. Note that systemd-homed.service and
homectl
will not manage
       ""classic"" UNIX user accounts as created with
useradd(8)
or similar
       tools."
1482,10,homectl,"Note that systemd-homed.service and
homectl
will not manage
       ""classic"" UNIX user accounts as created with
useradd(8)
or similar
       tools. In particular, this functionality is not suitable for
       managing system users (i.e. users with a UID below 1000) but is
       exclusive to regular (""human"") users."
1482,11,homectl,"users with a UID below 1000) but is
       exclusive to regular (""human"") users. Note that users/home directories managed via
systemd-homed.service
do not show up in /etc/passwd and similar files, they are
       synthesized via glibc NSS during runtime. They are thus resolvable
       and may be enumerated via the
getent(1)
tool."
1482,12,homectl,"They are thus resolvable
       and may be enumerated via the
getent(1)
tool. This tool interfaces directly with systemd-homed.service, and may
       execute specific commands on the home directories it manages. Since every home directory managed that way also defines a JSON
       user and group record these home directories may also be inspected
       and enumerated via
userdbctl(1)
."
1482,13,homectl,"Since every home directory managed that way also defines a JSON
       user and group record these home directories may also be inspected
       and enumerated via
userdbctl(1)
. Home directories managed by systemd-homed.service are usually in
       one of two states, or in a transition state between them: when
       ""active"" they are unlocked and mounted, and thus accessible to the
       system and its programs; when ""inactive"" they are not mounted and
       thus not accessible. Activation happens automatically at login of
       the user and usually can only complete after a password (or other
       authentication token) has been supplied."
1482,14,homectl,"Activation happens automatically at login of
       the user and usually can only complete after a password (or other
       authentication token) has been supplied. Deactivation happens
       after the user fully logged out. A home directory remains active
       as long as the user is logged in at least once, i.e."
1482,15,homectl,"A home directory remains active
       as long as the user is logged in at least once, i.e. has at least
       one login session. When the user logs in a second time
       simultaneously the home directory remains active."
1482,16,homectl,"has at least
       one login session. When the user logs in a second time
       simultaneously the home directory remains active. It is
       deactivated only after the last of the user's sessions ends."
1483,0,systemd-notify,"systemd-notify
may be called by service scripts to notify the
       invoking service manager about status changes. It can be used to
       send arbitrary information, encoded in an environment-block-like
       list of strings. Most importantly, it can be used for start-up
       completion notification."
1483,1,systemd-notify,"Most importantly, it can be used for start-up
       completion notification. This is mostly just a wrapper around
sd_notify()
and makes this
       functionality available to shell scripts. For details see
sd_notify(3)
."
1483,2,systemd-notify,"For details see
sd_notify(3)
. The command line may carry a list of environment variables to send
       as part of the status update. Note that systemd will refuse reception of status updates from
       this command unless
NotifyAccess=
is appropriately set for the
       service unit this command is called from."
1483,3,systemd-notify,"Note that systemd will refuse reception of status updates from
       this command unless
NotifyAccess=
is appropriately set for the
       service unit this command is called from. See
systemd.service(5)
for details. Note that
sd_notify()
notifications may be attributed to units
       correctly only if either the sending process is still around at
       the time the service manager processes the message, or if the
       sending process is explicitly runtime-tracked by the service
       manager."
1483,4,systemd-notify,"Note that
sd_notify()
notifications may be attributed to units
       correctly only if either the sending process is still around at
       the time the service manager processes the message, or if the
       sending process is explicitly runtime-tracked by the service
       manager. The latter is the case if the service manager originally
       forked off the process, i.e. on all processes that match
NotifyAccess=
main
or
NotifyAccess=
exec
."
1483,5,systemd-notify,"on all processes that match
NotifyAccess=
main
or
NotifyAccess=
exec
. Conversely, if an
       auxiliary process of the unit sends an
sd_notify()
message and
       immediately exits, the service manager might not be able to
       properly attribute the message to the unit, and thus will ignore
       it, even if
NotifyAccess=
all
is set for it. To address this
systemd-notify
will wait until the notification message has been
       processed by the service manager."
1483,6,systemd-notify,"To address this
systemd-notify
will wait until the notification message has been
       processed by the service manager. When
--no-block
is used, this
       synchronization for reception of notifications is disabled, and
       hence the aforementioned race may occur if the invoking process is
       not the service manager or spawned by the service manager. systemd-notify
will first attempt to invoke
sd_notify()
pretending
       to have the PID of the parent process of
systemd-notify
(i.e."
1483,7,systemd-notify,"systemd-notify
will first attempt to invoke
sd_notify()
pretending
       to have the PID of the parent process of
systemd-notify
(i.e. the
       invoking process). This will only succeed when invoked with
       sufficient privileges."
1483,8,systemd-notify,"This will only succeed when invoked with
       sufficient privileges. On failure, it will then fall back to
       invoking it under its own PID. This behaviour is useful in order
       that when the tool is invoked from a shell script the shell
       process â and not the
systemd-notify
process â appears as sender
       of the message, which in turn is helpful if the shell process is
       the main process of a service, due to the limitations of
NotifyAccess=
all
."
1483,9,systemd-notify,"On failure, it will then fall back to
       invoking it under its own PID. This behaviour is useful in order
       that when the tool is invoked from a shell script the shell
       process â and not the
systemd-notify
process â appears as sender
       of the message, which in turn is helpful if the shell process is
       the main process of a service, due to the limitations of
NotifyAccess=
all
. Use the
--pid=
switch to tweak this behaviour."
1484,0,systemd-sbsign,"systemd-sbsign
can be used to sign PE binaries for EFI Secure
       Boot."
1485,0,systemd-run,"systemd-run
may be used to create and start a transient .service
       or .scope unit and run the specified
COMMAND
in it. It may also be
       used to create and start a transient .path, .socket, or .timer
       unit, that activates a .service unit when elapsing. If a command is run as transient service unit, it will be started
       and managed by the service manager like any other service, and
       thus shows up in the output of
systemctl list-units
like any other
       unit."
1485,1,systemd-run,"If a command is run as transient service unit, it will be started
       and managed by the service manager like any other service, and
       thus shows up in the output of
systemctl list-units
like any other
       unit. It will run in a clean and detached execution environment,
       with the service manager as its parent process. In this mode,
systemd-run
will start the service asynchronously in the
       background and return after the command has begun execution
       (unless
--no-block
,
--wait
,
--pipe
, or
--pty
are specified, see
       below)."
1485,2,systemd-run,"In this mode,
systemd-run
will start the service asynchronously in the
       background and return after the command has begun execution
       (unless
--no-block
,
--wait
,
--pipe
, or
--pty
are specified, see
       below). If a command is run as transient scope unit, it will be executed
       by
systemd-run
itself as parent process and will thus inherit the
       execution environment of the caller. However, the processes of the
       command are managed by the service manager similarly to normal
       services, and will show up in the output of
systemctl list-units
."
1485,3,systemd-run,"However, the processes of the
       command are managed by the service manager similarly to normal
       services, and will show up in the output of
systemctl list-units
. Execution in this case is synchronous, and will return only when
       the command finishes. This mode is enabled via the
--scope
switch
       (see below)."
1485,4,systemd-run,"This mode is enabled via the
--scope
switch
       (see below). If a command is run with path, socket, or timer options such as
--on-calendar=
(see below), a transient path, socket, or timer
       unit is created alongside the service unit for the specified
       command. Only the transient path, socket, or timer unit is started
       immediately, the transient service unit will be triggered by the
       path, socket, or timer unit."
1485,5,systemd-run,"Only the transient path, socket, or timer unit is started
       immediately, the transient service unit will be triggered by the
       path, socket, or timer unit. If the
--unit=
option is specified,
       the
COMMAND
may be omitted. In this case,
systemd-run
creates only
       a .path, .socket, or .timer unit that triggers the specified unit."
1485,6,systemd-run,"In this case,
systemd-run
creates only
       a .path, .socket, or .timer unit that triggers the specified unit. By default, services created with
systemd-run
default to the
simple
type, see the description of
Type=
in
systemd.service(5)
for details. Note that when this type is used, the service manager
       (and thus the
systemd-run
command) considers service start-up
       successful as soon as the
fork()
for the main service process
       succeeded, i.e."
1485,7,systemd-run,"Note that when this type is used, the service manager
       (and thus the
systemd-run
command) considers service start-up
       successful as soon as the
fork()
for the main service process
       succeeded, i.e. before the
execve()
is invoked, and thus even if
       the specified command cannot be started. Consider using the
exec
service type (i.e."
1485,8,systemd-run,"Consider using the
exec
service type (i.e. --property=Type=exec
) to ensure that
systemd-run
returns successfully only if the specified command
       line has been successfully started. After
systemd-run
passes the command to the service manager, the
       manager performs variable expansion."
1485,9,systemd-run,"After
systemd-run
passes the command to the service manager, the
       manager performs variable expansion. This means that dollar
       characters (""$"") which should not be expanded need to be escaped
       as ""$$"". Expansion can also be disabled using
--expand-environment=no
."
1486,0,systemd-path,"systemd-path
may be used to query system and user paths. The tool
       makes many of the paths described in
file-hierarchy(7)
available
       for querying. When invoked without arguments, a list of known paths and their
       current values is shown."
1486,1,systemd-path,"When invoked without arguments, a list of known paths and their
       current values is shown. When at least one argument is passed, the
       path with this name is queried and its value shown. The variables
       whose name begins with ""search-"" do not refer to individual paths,
       but instead to a list of colon-separated search paths, in their
       order of precedence."
1486,2,systemd-path,"The variables
       whose name begins with ""search-"" do not refer to individual paths,
       but instead to a list of colon-separated search paths, in their
       order of precedence. Note that paths which depend on environment variables are computed
       with
systemd-path
's invoked environment, and not the system or
       user manager's environment. As such, the output of
systemd-path
may not reflect the behavior of manager processes."
1487,0,systemd-pty-forward,"systemd-pty-forward
can be used to run a command with a custom
       terminal background color or title."
1488,0,systemd-socket-activate,"systemd-socket-activate
may be used to launch a socket-activated
       service program from the command line for testing purposes. It may
       also be used to launch individual instances of the service program
       per connection. The daemon to launch and its options should be specified after
       options intended for
systemd-socket-activate
."
1488,1,systemd-socket-activate,"The daemon to launch and its options should be specified after
       options intended for
systemd-socket-activate
. If the
--inetd
option is given, the socket file descriptor will be
       used as the standard input and output of the launched process. Otherwise, standard input and output will be inherited, and
       sockets will be passed through file descriptors 3 and higher."
1488,2,systemd-socket-activate,"Otherwise, standard input and output will be inherited, and
       sockets will be passed through file descriptors 3 and higher. Sockets passed through
$LISTEN_FDS
to
systemd-socket-activate
will
       be passed through to the daemon, in the original positions. Other
       sockets specified with
--listen=
will use consecutive descriptors."
1488,3,systemd-socket-activate,"Sockets passed through
$LISTEN_FDS
to
systemd-socket-activate
will
       be passed through to the daemon, in the original positions. Other
       sockets specified with
--listen=
will use consecutive descriptors. By default,
systemd-socket-activate
listens on a stream socket,
       use
--datagram
and
--seqpacket
to listen on datagram or sequential
       packet sockets instead (see below)."
1489,0,systemd-ssh-proxy,"systemd-ssh-proxy
is a small ""proxy"" plugin for the
ssh(1)
tool
       that allows connecting to
AF_UNIX
and
AF_VSOCK
sockets. It
       implements the interface defined by ssh's
ProxyCommand
configuration option. It's supposed to be used with an
ssh_config(5)
configuration fragment like the following:

           Host unix/* vsock/* vsock-mux/*
               ProxyCommand /usr/lib/systemd/systemd-ssh-proxy %h %p
               ProxyUseFdpass yes
               CheckHostIP no

           Host .host
               ProxyCommand /usr/lib/systemd/systemd-ssh-proxy unix/run/ssh-unix-local/socket %p
               ProxyUseFdpass yes
               CheckHostIP no

       A configuration fragment along these lines is by default installed
       into /etc/ssh/ssh_config.d/20-systemd-ssh-proxy.conf."
1489,1,systemd-ssh-proxy,"It's supposed to be used with an
ssh_config(5)
configuration fragment like the following:

           Host unix/* vsock/* vsock-mux/*
               ProxyCommand /usr/lib/systemd/systemd-ssh-proxy %h %p
               ProxyUseFdpass yes
               CheckHostIP no

           Host .host
               ProxyCommand /usr/lib/systemd/systemd-ssh-proxy unix/run/ssh-unix-local/socket %p
               ProxyUseFdpass yes
               CheckHostIP no

       A configuration fragment along these lines is by default installed
       into /etc/ssh/ssh_config.d/20-systemd-ssh-proxy.conf. With this in place, SSH connections to host string ""unix/""
       followed by an absolute
AF_UNIX
file system path to a socket will
       be directed to the specified socket, which must be of type
SOCK_STREAM
. Similar, SSH connections to ""vsock/"" followed by an
AF_VSOCK
CID will result in an SSH connection made to that CID."
1489,2,systemd-ssh-proxy,"Similar, SSH connections to ""vsock/"" followed by an
AF_VSOCK
CID will result in an SSH connection made to that CID. ""vsock-mux/"" followed by an absolute
AF_UNIX
file system path to a
       socket is similar but for cloud-hypervisor/firecracker which do
       not allow direct
AF_VSOCK
communication between the host and
       guests, and provide their own multiplexer over
AF_UNIX
sockets. See
cloud-hypervisor VSOCK support
[1] and
Using the Firecracker
Virtio-vsock Device
[2]."
1489,3,systemd-ssh-proxy,"See
cloud-hypervisor VSOCK support
[1] and
Using the Firecracker
Virtio-vsock Device
[2]. Moreover, connecting to "".host"" will connect to the local host via
       SSH, without involving networking. This tool is supposed to be used together with
systemd-ssh-generator(8)
which when run inside a VM or container
       will bind SSH to suitable addresses."
1489,4,systemd-ssh-proxy,"Moreover, connecting to "".host"" will connect to the local host via
       SSH, without involving networking. This tool is supposed to be used together with
systemd-ssh-generator(8)
which when run inside a VM or container
       will bind SSH to suitable addresses. systemd-ssh-generator
is
       supposed to run in the container or VM guest, and
systemd-ssh-proxy
is run on the host, in order to connect to the
       container or VM guest."
1490,0,systemd-stdio-bridge,"systemd-stdio-bridge
implements a proxy between STDIN/STDOUT and a
       D-Bus bus. It expects to receive an open connection via
       STDIN/STDOUT when started, and will create a new connection to the
       specified bus. It will then forward messages between the two
       connections."
1490,1,systemd-stdio-bridge,"It will then forward messages between the two
       connections. This program is suitable for socket activation: the
       first connection may be a pipe or a socket and must be passed as
       either standard input, or as an open file descriptor according to
       the protocol described in
sd_listen_fds(3)
. The second connection
       will be made by default to the local system bus, but this can be
       influenced by the
--user
,
--system
,
--machine=
, and
--bus-path=
options described below."
1490,2,systemd-stdio-bridge,"This program is suitable for socket activation: the
       first connection may be a pipe or a socket and must be passed as
       either standard input, or as an open file descriptor according to
       the protocol described in
sd_listen_fds(3)
. The second connection
       will be made by default to the local system bus, but this can be
       influenced by the
--user
,
--system
,
--machine=
, and
--bus-path=
options described below. sd-bus(3)
uses
systemd-stdio-bridge
to forward D-Bus connections
       over
ssh(1)
, or to connect to the bus of a different user, see
sd_bus_set_address(3)
."
1491,0,systemd-tty-ask-password-agent,"systemd-tty-ask-password-agent
is a password agent that handles
       password requests of the system, for example for hard disk
       encryption passwords or SSL certificate passwords that need to be
       queried at boot-time or during runtime.
systemd-tty-ask-password-agent
implements the
Password Agents
Specification
[1], and is one of many possible response agents
       which answer to queries formulated with
systemd-ask-password(1)
."
1492,0,systemd-mount,"systemd-mount
may be used to create and start a transient .mount
       or .automount unit of the file system
WHAT
on the mount point
WHERE
. In many ways,
systemd-mount
is similar to the lower-level
mount(8)
command, however instead of executing the mount operation directly
       and immediately,
systemd-mount
schedules it through the service
       manager job queue, so that it may pull in further dependencies
       (such as parent mounts, or a file system checker to execute a
       priori), and may make use of the auto-mounting logic. The command takes either one or two arguments."
1492,1,systemd-mount,"The command takes either one or two arguments. If only one
       argument is specified it should refer to a block device or regular
       file containing a file system (e.g. ""/dev/sdb1"" or
       ""/path/to/disk.img"")."
1492,2,systemd-mount,"""/dev/sdb1"" or
       ""/path/to/disk.img""). The block device or image file is then
       probed for a file system label and other metadata, and is mounted
       to a directory below /run/media/system/ whose name is generated
       from the file system label. In this mode the block device or image
       file must exist at the time of invocation of the command, so that
       it may be probed."
1492,3,systemd-mount,"In this mode the block device or image
       file must exist at the time of invocation of the command, so that
       it may be probed. If the device is found to be a removable block
       device (e.g. a USB stick), an automount point is created instead
       of a regular mount point (i.e."
1492,4,systemd-mount,"a USB stick), an automount point is created instead
       of a regular mount point (i.e. the
--automount=
option is implied,
       see below). If the option
--tmpfs
is specified, then the argument
       is interpreted as the path where the new temporary file system
       shall be mounted."
1492,5,systemd-mount,"If the option
--tmpfs
is specified, then the argument
       is interpreted as the path where the new temporary file system
       shall be mounted. If two arguments are specified, the first indicates the mount
       source (the
WHAT
) and the second indicates the path to mount it on
       (the
WHERE
). In this mode no probing of the source is attempted,
       and a backing device node does not have to exist."
1492,6,systemd-mount,"In this mode no probing of the source is attempted,
       and a backing device node does not have to exist. However, if this
       mode is combined with
--discover
, device node probing for
       additional metadata is enabled, and â much like in the
       single-argument case discussed above â the specified device has to
       exist at the time of invocation of the command. Use the
--list
command to show a terse table of all local, known
       block devices with file systems that may be mounted with this
       command."
1492,7,systemd-mount,"Use the
--list
command to show a terse table of all local, known
       block devices with file systems that may be mounted with this
       command. systemd-umount
can be used to unmount a mount or automount point. It is the same as
systemd-mount --umount
."
1493,0,systemd-nspawn,"systemd-nspawn
may be used to run a command or OS in a lightweight
       namespace container. In many ways it is similar to
chroot(1)
, but
       more powerful since it virtualizes the file system hierarchy, as
       well as the process tree, the various IPC subsystems, and the host
       and domain names. systemd-nspawn
may be invoked on any directory tree containing an
       operating system tree, using the
--directory=
command line option."
1493,1,systemd-nspawn,"systemd-nspawn
may be invoked on any directory tree containing an
       operating system tree, using the
--directory=
command line option. By using the
--machine=
option an OS tree is automatically
       searched for in a couple of locations, most importantly in
       /var/lib/machines/, the suggested directory to place OS container
       images installed on the system. In contrast to
chroot(1)
systemd-nspawn
may be used to boot full
       Linux-based operating systems in a container."
1493,2,systemd-nspawn,"In contrast to
chroot(1)
systemd-nspawn
may be used to boot full
       Linux-based operating systems in a container. systemd-nspawn
limits access to various kernel interfaces in the
       container to read-only, such as /sys/, /proc/sys/, or
       /sys/fs/selinux/. The host's network interfaces and the system
       clock may not be changed from within the container."
1493,3,systemd-nspawn,"The host's network interfaces and the system
       clock may not be changed from within the container. Device nodes
       may not be created. The host system cannot be rebooted and kernel
       modules may not be loaded from within the container."
1493,4,systemd-nspawn,"The host system cannot be rebooted and kernel
       modules may not be loaded from within the container. This sandbox
can easily be circumvented from within the container if user
namespaces are not used
. This means that untrusted code must
       always be run in a user namespace, see the discussion of the
--private-users=
option below."
1493,5,systemd-nspawn,"This means that untrusted code must
       always be run in a user namespace, see the discussion of the
--private-users=
option below. Use a tool like
dnf
(8),
debootstrap
(8), or
pacman
(8) to set up an
       OS directory tree suitable as file system hierarchy for
systemd-nspawn
containers. See the Examples section below for
       details on suitable invocation of these commands."
1493,6,systemd-nspawn,"See the Examples section below for
       details on suitable invocation of these commands. As a safety check
systemd-nspawn
will verify the existence of
       /usr/lib/os-release or /etc/os-release in the container tree
       before booting a container (see
os-release(5)
). It might be
       necessary to add this file to the container tree manually if the
       OS of the container is too old to contain this file
       out-of-the-box."
1493,7,systemd-nspawn,"It might be
       necessary to add this file to the container tree manually if the
       OS of the container is too old to contain this file
       out-of-the-box. systemd-nspawn
may be invoked directly from the interactive
       command line or run as system service in the background. In this
       mode each container instance runs as its own service instance; a
       default template unit file systemd-nspawn@.service is provided to
       make this easy, taking the container name as instance identifier."
1493,8,systemd-nspawn,"In this
       mode each container instance runs as its own service instance; a
       default template unit file systemd-nspawn@.service is provided to
       make this easy, taking the container name as instance identifier. Note that different default options apply when
systemd-nspawn
is
       invoked by the template unit file than interactively on the
       command line. Most importantly the template unit file makes use of
       the
--boot
option which is not the default in case
systemd-nspawn
is invoked from the interactive command line."
1493,9,systemd-nspawn,"Most importantly the template unit file makes use of
       the
--boot
option which is not the default in case
systemd-nspawn
is invoked from the interactive command line. Further differences
       with the defaults are documented along with the various supported
       options below. The
machinectl(1)
tool may be used to execute a number of
       operations on containers."
1493,10,systemd-nspawn,"The
machinectl(1)
tool may be used to execute a number of
       operations on containers. In particular it provides easy-to-use
       commands to run containers as system services using the
       systemd-nspawn@.service template unit file. Along with each container a settings file with the .nspawn suffix
       may exist, containing additional settings to apply when running
       the container."
1493,11,systemd-nspawn,"Along with each container a settings file with the .nspawn suffix
       may exist, containing additional settings to apply when running
       the container. See
systemd.nspawn(5)
for details. Settings files
       override the default options used by the systemd-nspawn@.service
       template unit file, making it usually unnecessary to alter this
       template file directly."
1493,12,systemd-nspawn,"Settings files
       override the default options used by the systemd-nspawn@.service
       template unit file, making it usually unnecessary to alter this
       template file directly. Note that
systemd-nspawn
will mount file systems private to the
       container to /dev/, /run/, and similar. These will not be visible
       outside of the container, and their contents will be lost when the
       container exits."
1493,13,systemd-nspawn,"These will not be visible
       outside of the container, and their contents will be lost when the
       container exits. Note that running two
systemd-nspawn
containers from the same
       directory tree will not make processes in them see each other. The
       PID namespace separation of the two containers is complete and the
       containers will share very few runtime objects except for the
       underlying file system."
1493,14,systemd-nspawn,"The
       PID namespace separation of the two containers is complete and the
       containers will share very few runtime objects except for the
       underlying file system. Rather use
machinectl(1)
's
login
or
shell
commands to request an additional login session in a running
       container. systemd-nspawn
implements the
Container Interface
[1]
       specification."
1493,15,systemd-nspawn,"Rather use
machinectl(1)
's
login
or
shell
commands to request an additional login session in a running
       container. systemd-nspawn
implements the
Container Interface
[1]
       specification. While running, containers invoked with
systemd-nspawn
are
       registered with the
systemd-machined(8)
service that keeps track
       of running containers, and provides programming interfaces to
       interact with them."
1494,0,systemd-vpick,"systemd-vpick
resolves a file system path referencing a "".v/""
       versioned directory to a path to the newest (by version) file
       contained therein. This tool provides a command line interface for
       the
systemd.v(7)
logic. The tool expects a path to a "".v/"" directory as argument (either
       directly, or with a triple underscore pattern as final component)."
1494,1,systemd-vpick,"The tool expects a path to a "".v/"" directory as argument (either
       directly, or with a triple underscore pattern as final component). It then determines the newest file contained in that directory,
       and writes its path to standard output. Unless the triple underscore pattern is passed as last component
       of the path, it is typically necessary to at least specify the
--suffix=
switch to configure the file suffix to look for."
1494,2,systemd-vpick,"Unless the triple underscore pattern is passed as last component
       of the path, it is typically necessary to at least specify the
--suffix=
switch to configure the file suffix to look for. If the specified path does not reference a "".v/"" path (i.e. neither the final component ends in "".v"", nor the penultimate does
       or the final one does contain a triple underscore) its specified
       path is written unmodified to standard output."
1495,0,tabs,"The
@TABS@
program clears and sets tab-stops on the terminal. This uses the terminfo
clear_all_tabs
and
set_tab
capabilities. If either is absent,
@TABS@
is unable to clear/set tab-stops."
1495,1,tabs,"If either is absent,
@TABS@
is unable to clear/set tab-stops. The
       terminal should be configured to use hard tabs, e.g.,

           stty tab0

       Like
@CLEAR@
(1),
@TABS@
writes to the standard output. You can
       redirect the standard output to a file (which prevents
@TABS@
from
       actually changing the tabstops), and later
cat
the file to the
       screen, setting tabstops at that point."
1495,2,tabs,"You can
       redirect the standard output to a file (which prevents
@TABS@
from
       actually changing the tabstops), and later
cat
the file to the
       screen, setting tabstops at that point. These are hardware tabs, which cannot be queried rapidly by
       applications running in the terminal, if at all. Curses and other
       full-screen applications may use hardware tabs in optimizing their
       output to the terminal."
1495,3,tabs,"Curses and other
       full-screen applications may use hardware tabs in optimizing their
       output to the terminal. If the hardware tabstops differ from the
       information in the terminal database, the result is unpredictable. Before running curses programs, you should either reset tab-stops
       to the standard interval

           tabs -8

       or use the
@RESET@
program, since the normal initialization
       sequences do not ensure that tab-stops are reset."
1496,0,systemd-vmspawn,"systemd-vmspawn
may be used to start a virtual machine from an OS
       image. In many ways it is similar to
systemd-nspawn(1)
, but
       launches a full virtual machine instead of using namespaces. File descriptors for /dev/kvm and /dev/vhost-vsock can be passed
       to
systemd-vmspawn
via systemd's native socket passing interface
       (see
sd_listen_fds(3)
for details about the precise protocol used
       and the order in which the file descriptors are passed), these
       file descriptors must be passed with the names ""kvm"" and
       ""vhost-vsock"" respectively."
1496,1,systemd-vmspawn,"In many ways it is similar to
systemd-nspawn(1)
, but
       launches a full virtual machine instead of using namespaces. File descriptors for /dev/kvm and /dev/vhost-vsock can be passed
       to
systemd-vmspawn
via systemd's native socket passing interface
       (see
sd_listen_fds(3)
for details about the precise protocol used
       and the order in which the file descriptors are passed), these
       file descriptors must be passed with the names ""kvm"" and
       ""vhost-vsock"" respectively. Note: on Ubuntu/Debian derivatives
systemd-vmspawn
requires the
       user to be in the ""kvm"" group to use the VSOCK options."
1497,0,tabs,"The
@TABS@
program clears and sets tab-stops on the terminal. This uses the terminfo
clear_all_tabs
and
set_tab
capabilities. If either is absent,
@TABS@
is unable to clear/set tab-stops."
1497,1,tabs,"If either is absent,
@TABS@
is unable to clear/set tab-stops. The
       terminal should be configured to use hard tabs, e.g.,

           stty tab0

       Like
@CLEAR@
(1),
@TABS@
writes to the standard output. You can
       redirect the standard output to a file (which prevents
@TABS@
from
       actually changing the tabstops), and later
cat
the file to the
       screen, setting tabstops at that point."
1497,2,tabs,"You can
       redirect the standard output to a file (which prevents
@TABS@
from
       actually changing the tabstops), and later
cat
the file to the
       screen, setting tabstops at that point. These are hardware tabs, which cannot be queried rapidly by
       applications running in the terminal, if at all. Curses and other
       full-screen applications may use hardware tabs in optimizing their
       output to the terminal."
1497,3,tabs,"Curses and other
       full-screen applications may use hardware tabs in optimizing their
       output to the terminal. If the hardware tabstops differ from the
       information in the terminal database, the result is unpredictable. Before running curses programs, you should either reset tab-stops
       to the standard interval

           tabs -8

       or use the
@RESET@
program, since the normal initialization
       sequences do not ensure that tab-stops are reset."
1498,0,tac,"Write each FILE to standard output, last line first. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
1498,1,tac,"With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too. -b
,
--before
attach the separator before instead of after
-r
,
--regex
interpret the separator as a regular expression
-s
,
--separator
=
STRING
use STRING as the separator instead of newline
--help
display this help and exit
--version
output version information and exit"
1499,0,tabs,"The
tabs
utility shall display a series of characters that first
       clears the hardware terminal tab settings and then initializes the
       tab stops at the specified positions and optionally adjusts the
       margin. The phrase ``tab-stop position
N
'' shall be taken to mean that,
       from the start of a line of output, tabbing to position
N
shall
       cause the next character output to be in the (
N
+1)th column
       position on that line. The maximum number of tab stops allowed is
       terminal-dependent."
1499,1,tabs,"The maximum number of tab stops allowed is
       terminal-dependent. It need not be possible to implement
tabs
on certain terminals. If
       the terminal type obtained from the
TERM
environment variable or
-T
option represents such a terminal, an appropriate diagnostic
       message shall be written to standard error and
tabs
shall exit
       with a status greater than zero."
1500,0,tail,"Print the last 10 lines of each FILE to standard output. With
       more than one FILE, precede each with a header giving the file
       name. With no FILE, or when FILE is -, read standard input."
1500,1,tail,"With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too. -c
,
--bytes
=
[
+]NUM
              output the last NUM bytes; or use
-c
+NUM to output
              starting with byte NUM of each file
-f
,
--follow[=
{name|descriptor}]
              output appended data as the file grows;

              an absent option argument means 'descriptor'
-F
same as
--follow
=
name
--retry
-n
,
--lines
=
[
+]NUM
              output the last NUM lines, instead of the last 10; or use
-n
+NUM to skip NUM-1 lines at the start
--max-unchanged-stats
=
N
with
--follow
=
name
, reopen a FILE which has not

              changed size after N (default 5) iterations to see if it
              has been unlinked or renamed (this is the usual case of
              rotated log files); with inotify, this option is rarely
              useful
--pid
=
PID
with
-f
, terminate after process ID, PID dies; can be
              repeated to watch multiple processes
-q
,
--quiet
,
--silent
never output headers giving file names
--retry
keep trying to open a file if it is inaccessible
-s
,
--sleep-interval
=
N
with
-f
, sleep for approximately N seconds (default 1.0)
              between iterations; with inotify and
--pid
=
P
, check process
              P at least once every N seconds
-v
,
--verbose
always output headers giving file names
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit

       NUM may have a multiplier suffix: b 512, kB 1000, K 1024, MB
       1000*1000, M 1024*1024, GB 1000*1000*1000, G 1024*1024*1024, and
       so on for T, P, E, Z, Y, R, Q."
1500,2,tail,"-c
,
--bytes
=
[
+]NUM
              output the last NUM bytes; or use
-c
+NUM to output
              starting with byte NUM of each file
-f
,
--follow[=
{name|descriptor}]
              output appended data as the file grows;

              an absent option argument means 'descriptor'
-F
same as
--follow
=
name
--retry
-n
,
--lines
=
[
+]NUM
              output the last NUM lines, instead of the last 10; or use
-n
+NUM to skip NUM-1 lines at the start
--max-unchanged-stats
=
N
with
--follow
=
name
, reopen a FILE which has not

              changed size after N (default 5) iterations to see if it
              has been unlinked or renamed (this is the usual case of
              rotated log files); with inotify, this option is rarely
              useful
--pid
=
PID
with
-f
, terminate after process ID, PID dies; can be
              repeated to watch multiple processes
-q
,
--quiet
,
--silent
never output headers giving file names
--retry
keep trying to open a file if it is inaccessible
-s
,
--sleep-interval
=
N
with
-f
, sleep for approximately N seconds (default 1.0)
              between iterations; with inotify and
--pid
=
P
, check process
              P at least once every N seconds
-v
,
--verbose
always output headers giving file names
-z
,
--zero-terminated
line delimiter is NUL, not newline
--help
display this help and exit
--version
output version information and exit

       NUM may have a multiplier suffix: b 512, kB 1000, K 1024, MB
       1000*1000, M 1024*1024, GB 1000*1000*1000, G 1024*1024*1024, and
       so on for T, P, E, Z, Y, R, Q. Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on. With
--follow
(
-f
), tail defaults to following the file
       descriptor, which means that even if a tail'ed file is renamed,
       tail will continue to track its end."
1500,3,tail,"With
--follow
(
-f
), tail defaults to following the file
       descriptor, which means that even if a tail'ed file is renamed,
       tail will continue to track its end. This default behavior is not
       desirable when you really want to track the actual name of the
       file, not the file descriptor (e.g., log rotation). Use
--follow
=
name
in that case."
1500,4,tail,"This default behavior is not
       desirable when you really want to track the actual name of the
       file, not the file descriptor (e.g., log rotation). Use
--follow
=
name
in that case. That causes tail to track the named
       file in a way that accommodates renaming, removal and creation."
1501,0,tail,"The
tail
utility shall copy its input file to the standard output
       beginning at a designated place. Copying shall begin at the point in the file indicated by the
-c
number
or
-n
number
options. The option-argument
number
shall be
       counted in units of lines or bytes, according to the options
-n
and
-c
."
1501,1,tail,"The option-argument
number
shall be
       counted in units of lines or bytes, according to the options
-n
and
-c
. Both line and byte counts start from 1. Tails relative to the end of the file may be saved in an internal
       buffer, and thus may be limited in length."
1501,2,tail,"Both line and byte counts start from 1. Tails relative to the end of the file may be saved in an internal
       buffer, and thus may be limited in length. Such a buffer, if any,
       shall be no smaller than {LINE_MAX}*10 bytes."
1502,0,talk,"The
talk
utility is a two-way, screen-oriented communication
       program. When first invoked,
talk
shall send a message similar to:

           Message from <
unspecified string
>
           talk: connection requested by
your_address
talk: respond with: talk
your_address
to the specified
address
. At this point, the recipient of the
       message can reply by typing:

           talk
your_address
Once communication is established, the two parties can type
       simultaneously, with their output displayed in separate regions of
       the screen."
1502,1,talk,"At this point, the recipient of the
       message can reply by typing:

           talk
your_address
Once communication is established, the two parties can type
       simultaneously, with their output displayed in separate regions of
       the screen. Characters shall be processed as follows:

        *  Typing the <alert> character shall alert the recipient's
           terminal. *  Typing <control>âL shall cause the sender's screen regions to
           be refreshed."
1502,2,talk,"*  Typing <control>âL shall cause the sender's screen regions to
           be refreshed. *  Typing the erase and kill characters shall affect the sender's
           terminal in the manner described by the
termios
interface in
           the Base Definitions volume of POSIX.1â2017,
Chapter 11
,
General Terminal Interface
. *  Typing the interrupt or end-of-file characters shall terminate
           the local
talk
utility."
1502,3,talk,"*  Typing the interrupt or end-of-file characters shall terminate
           the local
talk
utility. Once the
talk
session has been
           terminated on one side, the other side of the
talk
session
           shall be notified that the
talk
session has been terminated
           and shall be able to do nothing except exit. *  Typing characters from
LC_CTYPE
classifications
print
or
space
shall cause those characters to be sent to the recipient's
           terminal."
1502,4,talk,"*  Typing characters from
LC_CTYPE
classifications
print
or
space
shall cause those characters to be sent to the recipient's
           terminal. *  When and only when the
stty
iexten
local mode is enabled, the
           existence and processing of additional special control
           characters and multi-byte or single-byte functions shall be
           implementation-defined. *  Typing other non-printable characters shall cause
           implementation-defined sequences of printable characters to be
           sent to the recipient's terminal."
1502,5,talk,"*  Typing other non-printable characters shall cause
           implementation-defined sequences of printable characters to be
           sent to the recipient's terminal. Permission to be a recipient of a
talk
message can be denied or
       granted by use of the
mesg
utility. However, a user's privilege
       may further constrain the domain of accessibility of other users'
       terminals."
1502,6,talk,"However, a user's privilege
       may further constrain the domain of accessibility of other users'
       terminals. The
talk
utility shall fail when the user lacks
       appropriate privileges to perform the requested action. Certain block-mode terminals do not have all the capabilities
       necessary to support the simultaneous exchange of messages
       required for
talk
."
1502,7,talk,"The
talk
utility shall fail when the user lacks
       appropriate privileges to perform the requested action. Certain block-mode terminals do not have all the capabilities
       necessary to support the simultaneous exchange of messages
       required for
talk
. When this type of exchange cannot be supported
       on such terminals, the implementation may support an exchange with
       reduced levels of simultaneous interaction or it may report an
       error describing the terminal-related deficiency."
1503,0,systemd,"systemd is a system and service manager for Linux operating
       systems. When run as first process on boot (as PID 1), it acts as
       init system that brings up and maintains userspace services. Separate instances are started for logged-in users to start their
       services."
1503,1,systemd,"Separate instances are started for logged-in users to start their
       services. systemd
is usually not invoked directly by the user, but is
       installed as the /sbin/init symlink and started during early boot. The user manager instances are started automatically through the
user@.service(5)
service."
1503,2,systemd,"The user manager instances are started automatically through the
user@.service(5)
service. For compatibility with SysV, if the binary is called as
init
and
       is not the first process on the machine (PID is not 1), it will
       execute
telinit
and pass all command line arguments unmodified. That means
init
and
telinit
are mostly equivalent when invoked
       from normal login sessions."
1503,3,systemd,"That means
init
and
telinit
are mostly equivalent when invoked
       from normal login sessions. See
telinit(8)
for more information. When run as a system instance, systemd interprets the
       configuration file system.conf and the files in system.conf.d
       directories; when run as a user instance, systemd interprets the
       configuration file user.conf and the files in user.conf.d
       directories."
1503,4,systemd,"When run as a system instance, systemd interprets the
       configuration file system.conf and the files in system.conf.d
       directories; when run as a user instance, systemd interprets the
       configuration file user.conf and the files in user.conf.d
       directories. See
systemd-system.conf(5)
for more information. systemd
contains native implementations of various tasks that need
       to be executed as part of the boot process."
1503,5,systemd,"systemd
contains native implementations of various tasks that need
       to be executed as part of the boot process. For example, it sets
       the hostname or configures the loopback network device. It also
       sets up and mounts various API file systems, such as /sys/,
       /proc/, and /dev/."
1503,6,systemd,"It also
       sets up and mounts various API file systems, such as /sys/,
       /proc/, and /dev/. systemd
will also reset the system clock during early boot if it
       appears to be set incorrectly. See ""System clock epoch"" section
       below."
1503,7,systemd,"See ""System clock epoch"" section
       below. Note that some but not all interfaces provided by systemd are
       covered by the
Interface Portability and Stability Promise
[1]. The D-Bus API of
systemd
is described in
org.freedesktop.systemd1(5)
and
org.freedesktop.LogControl1(5)
."
1503,8,systemd,"Note that some but not all interfaces provided by systemd are
       covered by the
Interface Portability and Stability Promise
[1]. The D-Bus API of
systemd
is described in
org.freedesktop.systemd1(5)
and
org.freedesktop.LogControl1(5)
. Systems which invoke systemd in a container or initrd environment
       should implement the
Container Interface
[2] or
initrd Interface
[3]
       specifications, respectively."
1504,0,tapestat,"The
tapestat
command is used for monitoring the activity of tape
       drives connected to a system. The first report generated by the
tapestat
command provides
       statistics concerning the time since the system was booted, unless
       the
-y
option is used, when this first report is omitted. Each
       subsequent report covers the time since the previous report."
1504,1,tapestat,"Each
       subsequent report covers the time since the previous report. The
interval
parameter specifies the amount of time in seconds
       between each report. The
count
parameter can be specified in
       conjunction with the
interval
parameter."
1504,2,tapestat,"The
count
parameter can be specified in
       conjunction with the
interval
parameter. If the
count
parameter is
       specified, the value of
count
determines the number of reports
       generated at
interval
seconds apart. If the
interval
parameter is
       specified without the
count
parameter, the
tapestat
command
       generates reports continuously."
1505,0,taskset,"The
taskset
command is used to set or retrieve the CPU affinity of
       a running process given its
pid
, or to launch a new
command
with a
       given CPU affinity. CPU affinity is a scheduler property that
       ""bonds"" a process to a given set of CPUs on the system. The Linux
       scheduler will honor the given CPU affinity and the process will
       not run on any other CPUs."
1505,1,taskset,"The Linux
       scheduler will honor the given CPU affinity and the process will
       not run on any other CPUs. Note that the Linux scheduler also
       supports natural CPU affinity: the scheduler attempts to keep
       processes on the same CPU as long as practical for performance
       reasons. Therefore, forcing a specific CPU affinity is useful only
       in certain applications."
1505,2,taskset,"Therefore, forcing a specific CPU affinity is useful only
       in certain applications. The affinity of some processes like
       kernel per-CPU threads cannot be set. The CPU affinity is represented as a bitmask, with the lowest
       order bit corresponding to the first logical CPU and the highest
       order bit corresponding to the last logical CPU."
1505,3,taskset,"The CPU affinity is represented as a bitmask, with the lowest
       order bit corresponding to the first logical CPU and the highest
       order bit corresponding to the last logical CPU. Not all CPUs may
       exist on a given system but a mask may specify more CPUs than are
       present. A retrieved mask will reflect only the bits that
       correspond to CPUs physically on the system."
1505,4,taskset,"A retrieved mask will reflect only the bits that
       correspond to CPUs physically on the system. If an invalid mask is
       given (i.e., one that corresponds to no valid CPUs on the current
       system) an error is returned. The masks may be specified in
       hexadecimal (with or without a leading ""0x""), or as a CPU list
       with the
--cpu-list
option."
1505,5,taskset,"The masks may be specified in
       hexadecimal (with or without a leading ""0x""), or as a CPU list
       with the
--cpu-list
option. For example,
0x00000001
is processor #0,
0x00000003
is processors #0 and #1,
FFFFFFFF
is processors #0 through #31,
0x32
is processors #1, #4, and #5,
--cpu-list 0-2,6
is processors #0, #1, #2, and #6. --cpu-list 0-10:2
is processors #0, #2, #4, #6, #8 and #10."
1505,6,taskset,"--cpu-list 0-10:2
is processors #0, #2, #4, #6, #8 and #10. The suffix "":N""
           specifies stride in the range, for example 0-10:3 is
           interpreted as 0,3,6,9 list. When
taskset
returns, it is guaranteed that the given program has
       been scheduled to a legal CPU."
1506,0,tee,"Copy standard input to each FILE, and also to standard output. -a
,
--append
append to the given FILEs, do not overwrite
-i
,
--ignore-interrupts
ignore interrupt signals
-p
operate in a more appropriate MODE with pipes
--output-error
[=
MODE
]
              set behavior on write error. See MODE below
--help
display this help and exit
--version
output version information and exit
MODE determines behavior with write errors on the outputs:
warn   diagnose errors writing to any output

       warn-nopipe
              diagnose errors writing to any output not a pipe

       exit   exit on error writing to any output

       exit-nopipe
              exit on error writing to any output not a pipe

       The default MODE for the
-p
option is 'warn-nopipe'."
1506,1,tee,"See MODE below
--help
display this help and exit
--version
output version information and exit
MODE determines behavior with write errors on the outputs:
warn   diagnose errors writing to any output

       warn-nopipe
              diagnose errors writing to any output not a pipe

       exit   exit on error writing to any output

       exit-nopipe
              exit on error writing to any output not a pipe

       The default MODE for the
-p
option is 'warn-nopipe'. With
       ""nopipe"" MODEs, exit immediately if all outputs become broken
       pipes. The default operation when
--output-error
is not
       specified, is to exit immediately on error writing to a pipe, and
       diagnose errors writing to non pipe outputs."
1507,0,telnet-probe,"telnet-probe
allows the
pmdashping(1)
daemons to establish
       connections to arbitrary local and remote service-providing
       daemons so that response time and service availability information
       can be obtained. The required
host
and
port
number arguments have the same meaning
       as their
telnet
(1) equivalents. The
-c
option causes
telnet-probe
to perform a
connect(2)
only."
1507,1,telnet-probe,"The
-c
option causes
telnet-probe
to perform a
connect(2)
only. This skips the
read(2)
and
write(2)
exercise that would otherwise
       be done after connecting (see below). Once the telnet connection has been established,
telnet-probe
reads from
stdin
until end-of-file, and writes all the input data
       to the telnet connection."
1507,2,telnet-probe,"Once the telnet connection has been established,
telnet-probe
reads from
stdin
until end-of-file, and writes all the input data
       to the telnet connection. Next,
telnet-probe
will read from the
       telnet connection until end-of-file, discarding whatever data it
       receives. Then
telnet-probe
exits."
1507,3,telnet-probe,"Then
telnet-probe
exits. To operate successfully, the input passed via
telnet-probe
to the
       remote service must be sufficient to cause the remote service to
       close the connection when the last line of input has been
       processed, e.g. ending with ``quit'' when probing SMTP on port 25."
1507,4,telnet-probe,"To operate successfully, the input passed via
telnet-probe
to the
       remote service must be sufficient to cause the remote service to
       close the connection when the last line of input has been
       processed, e.g. ending with ``quit'' when probing SMTP on port 25. By default
telnet-probe
will not produce any output, unless there
       is an error in which case a diagnostic message can be displayed
       (in verbose mode only) and the exit status will be non-zero
       indicating a failure."
1508,0,tee,"The
tee
utility shall copy standard input to standard output,
       making a copy in zero or more files. The
tee
utility shall not
       buffer output.

       If the
-a
option is not specified, output files shall be written
       (see
Section 1.1.1.4
,
File Read
,
Write
,
and Creation
."
1509,0,test,"Exit with the status determined by EXPRESSION. --help
display this help and exit
--version
output version information and exit

       An omitted EXPRESSION defaults to false. Otherwise, EXPRESSION is
       true or false and sets exit status."
1509,1,test,"Otherwise, EXPRESSION is
       true or false and sets exit status. It is one of:

       ( EXPRESSION )
              EXPRESSION is true

       ! EXPRESSION
              EXPRESSION is false

       EXPRESSION1
-a
EXPRESSION2
              both EXPRESSION1 and EXPRESSION2 are true

       EXPRESSION1
-o
EXPRESSION2
              either EXPRESSION1 or EXPRESSION2 is true
-n
STRING
              the length of STRING is nonzero

       STRING equivalent to
-n
STRING
-z
STRING
              the length of STRING is zero

       STRING1 = STRING2
              the strings are equal

       STRING1 != STRING2
              the strings are not equal

       STRING1 > STRING2
              STRING1 is greater than STRING2 in the current locale

       STRING1 < STRING2
              STRING1 is less than STRING2 in the current locale

       INTEGER1
-eq
INTEGER2
              INTEGER1 is equal to INTEGER2

       INTEGER1
-ge
INTEGER2
              INTEGER1 is greater than or equal to INTEGER2

       INTEGER1
-gt
INTEGER2
              INTEGER1 is greater than INTEGER2

       INTEGER1
-le
INTEGER2
              INTEGER1 is less than or equal to INTEGER2

       INTEGER1
-lt
INTEGER2
              INTEGER1 is less than INTEGER2

       INTEGER1
-ne
INTEGER2
              INTEGER1 is not equal to INTEGER2

       FILE1
-ef
FILE2
              FILE1 and FILE2 have the same device and inode numbers

       FILE1
-nt
FILE2
              FILE1 is newer (modification date) than FILE2

       FILE1
-ot
FILE2
              FILE1 is older than FILE2
-b
FILE
              FILE exists and is block special
-c
FILE
              FILE exists and is character special
-d
FILE
              FILE exists and is a directory
-e
FILE
              FILE exists
-f
FILE
              FILE exists and is a regular file
-g
FILE
              FILE exists and is set-group-ID
-G
FILE
              FILE exists and is owned by the effective group ID
-h
FILE
              FILE exists and is a symbolic link (same as
-L
)
-k
FILE
              FILE exists and has its sticky bit set
-L
FILE
              FILE exists and is a symbolic link (same as
-h
)
-N
FILE
              FILE exists and has been modified since it was last read
-O
FILE
              FILE exists and is owned by the effective user ID
-p
FILE
              FILE exists and is a named pipe
-r
FILE
              FILE exists and the user has read access
-s
FILE
              FILE exists and has a size greater than zero
-S
FILE
              FILE exists and is a socket
-t
FD  file descriptor FD is opened on a terminal
-u
FILE
              FILE exists and its set-user-ID bit is set
-w
FILE
              FILE exists and the user has write access
-x
FILE
              FILE exists and the user has execute (or search) access

       Except for
-h
and
-L
, all FILE-related tests dereference symbolic
       links."
1509,2,test,"EXPRESSION
              EXPRESSION is false

       EXPRESSION1
-a
EXPRESSION2
              both EXPRESSION1 and EXPRESSION2 are true

       EXPRESSION1
-o
EXPRESSION2
              either EXPRESSION1 or EXPRESSION2 is true
-n
STRING
              the length of STRING is nonzero

       STRING equivalent to
-n
STRING
-z
STRING
              the length of STRING is zero

       STRING1 = STRING2
              the strings are equal

       STRING1 != STRING2
              the strings are not equal

       STRING1 > STRING2
              STRING1 is greater than STRING2 in the current locale

       STRING1 < STRING2
              STRING1 is less than STRING2 in the current locale

       INTEGER1
-eq
INTEGER2
              INTEGER1 is equal to INTEGER2

       INTEGER1
-ge
INTEGER2
              INTEGER1 is greater than or equal to INTEGER2

       INTEGER1
-gt
INTEGER2
              INTEGER1 is greater than INTEGER2

       INTEGER1
-le
INTEGER2
              INTEGER1 is less than or equal to INTEGER2

       INTEGER1
-lt
INTEGER2
              INTEGER1 is less than INTEGER2

       INTEGER1
-ne
INTEGER2
              INTEGER1 is not equal to INTEGER2

       FILE1
-ef
FILE2
              FILE1 and FILE2 have the same device and inode numbers

       FILE1
-nt
FILE2
              FILE1 is newer (modification date) than FILE2

       FILE1
-ot
FILE2
              FILE1 is older than FILE2
-b
FILE
              FILE exists and is block special
-c
FILE
              FILE exists and is character special
-d
FILE
              FILE exists and is a directory
-e
FILE
              FILE exists
-f
FILE
              FILE exists and is a regular file
-g
FILE
              FILE exists and is set-group-ID
-G
FILE
              FILE exists and is owned by the effective group ID
-h
FILE
              FILE exists and is a symbolic link (same as
-L
)
-k
FILE
              FILE exists and has its sticky bit set
-L
FILE
              FILE exists and is a symbolic link (same as
-h
)
-N
FILE
              FILE exists and has been modified since it was last read
-O
FILE
              FILE exists and is owned by the effective user ID
-p
FILE
              FILE exists and is a named pipe
-r
FILE
              FILE exists and the user has read access
-s
FILE
              FILE exists and has a size greater than zero
-S
FILE
              FILE exists and is a socket
-t
FD  file descriptor FD is opened on a terminal
-u
FILE
              FILE exists and its set-user-ID bit is set
-w
FILE
              FILE exists and the user has write access
-x
FILE
              FILE exists and the user has execute (or search) access

       Except for
-h
and
-L
, all FILE-related tests dereference symbolic
       links. Beware that parentheses need to be escaped (e.g., by
       backslashes) for shells. INTEGER may also be
-l
STRING, which
       evaluates to the length of STRING."
1509,3,test,"INTEGER may also be
-l
STRING, which
       evaluates to the length of STRING. Binary
-a
and
-o
are ambiguous. Use 'test EXPR1 && test EXPR2' or
       'test EXPR1 || test EXPR2' instead."
1509,4,test,"Use 'test EXPR1 && test EXPR2' or
       'test EXPR1 || test EXPR2' instead. '[' honors
--help
and
--version
, but 'test' treats them as
       STRINGs. Your shell may have its own version of test and/or [, which
       usually supersedes the version described here."
1509,5,test,"'[' honors
--help
and
--version
, but 'test' treats them as
       STRINGs. Your shell may have its own version of test and/or [, which
       usually supersedes the version described here. Please refer to
       your shell's documentation for details about the options it
       supports."
1510,0,tbl,nan
1511,0,tar,"GNU
tar
is an archiving program designed to store multiple files
       in a single file (an
archive
), and to manipulate such archives. The archive can be either a regular file or a device (e.g., a tape
       drive, hence the name of the program, which stands for
t
ape
ar
chiver), which can be located either on the local or on a remote
       machine. Option styles
Options to GNU
tar
can be given in three different styles."
1511,1,tar,"Option styles
Options to GNU
tar
can be given in three different styles. In
traditional style
, the first argument is a cluster of option
       letters and all subsequent arguments supply arguments to those
       options that require them. The arguments are read in the same
       order as the option letters."
1511,2,tar,"The arguments are read in the same
       order as the option letters. Any command line words that remain
       after all options have been processed are treated as non-option
       arguments: file or archive member names. For example, the
c
option requires creating the archive, the
v
option requests the verbose operation, and the
f
option takes an
       argument that sets the name of the archive to operate upon."
1511,3,tar,"For example, the
c
option requires creating the archive, the
v
option requests the verbose operation, and the
f
option takes an
       argument that sets the name of the archive to operate upon. The
       following command, written in the traditional style, instructs tar
       to store all files from the directory
/etc
into the archive file
etc.tar
, verbosely listing the files being archived:

       tar cfv etc.tar /etc

       In
UNIX
or
short-option style
, each option letter is prefixed with
       a single dash, as in other command line utilities. If an option
       takes an argument, the argument follows it, either as a separate
       command line word, or immediately following the option."
1511,4,tar,"If an option
       takes an argument, the argument follows it, either as a separate
       command line word, or immediately following the option. However,
       if the option takes an
optional
argument, the argument must follow
       the option letter without any intervening whitespace, as in
-g/tmp/snar.db
. Any number of options not taking arguments can be clustered
       together after a single dash, e.g."
1511,5,tar,"Any number of options not taking arguments can be clustered
       together after a single dash, e.g. -vkp
. An option that takes an
       argument (whether mandatory or optional) can appear at the end of
       such a cluster, e.g."
1511,6,tar,"An option that takes an
       argument (whether mandatory or optional) can appear at the end of
       such a cluster, e.g. -vkpf a.tar
. The example command above written in the
short-option style
could
       look like:

       tar -cvf etc.tar /etc
       or
       tar -c -v -f etc.tar /etc

       In
GNU
or
long-option style
, each option begins with two dashes
       and has a meaningful name, consisting of lower-case letters and
       dashes."
1511,7,tar,"The example command above written in the
short-option style
could
       look like:

       tar -cvf etc.tar /etc
       or
       tar -c -v -f etc.tar /etc

       In
GNU
or
long-option style
, each option begins with two dashes
       and has a meaningful name, consisting of lower-case letters and
       dashes. When used, the long option can be abbreviated to its
       initial letters, provided that this does not create ambiguity. Arguments to long options are supplied either as a separate
       command line word, immediately following the option, or separated
       from the option by an equals sign with no intervening whitespace."
1511,8,tar,"Arguments to long options are supplied either as a separate
       command line word, immediately following the option, or separated
       from the option by an equals sign with no intervening whitespace. Optional arguments must always use the latter method. Here are several ways of writing the example command in this
       style:

       tar --create --file etc.tar --verbose /etc
       or (abbreviating some options):
       tar --cre --file=etc.tar --verb /etc

       The options in all three styles can be intermixed, although doing
       so with old options is not encouraged."
1511,9,tar,"Here are several ways of writing the example command in this
       style:

       tar --create --file etc.tar --verbose /etc
       or (abbreviating some options):
       tar --cre --file=etc.tar --verb /etc

       The options in all three styles can be intermixed, although doing
       so with old options is not encouraged. Operation mode
The options listed in the table below tell GNU
tar
what operation
       it is to perform. Exactly one of them must be given."
1511,10,tar,"Exactly one of them must be given. The meaning
       of non-option arguments depends on the operation mode requested. -A
,
--catenate
,
--concatenate
Append archives to the end of another archive."
1511,11,tar,"-A
,
--catenate
,
--concatenate
Append archives to the end of another archive. The
              arguments are treated as the names of archives to append. All archives must be of the same format as the archive they
              are appended to, otherwise the resulting archive might be
              unusable with non-GNU implementations of
tar
."
1511,12,tar,"All archives must be of the same format as the archive they
              are appended to, otherwise the resulting archive might be
              unusable with non-GNU implementations of
tar
. Notice also
              that when more than one archive is given, the members from
              archives other than the first one will be accessible in the
              resulting archive only when using the
-i
(
--ignore-zeros
)
              option. Compressed archives cannot be concatenated."
1511,13,tar,"Compressed archives cannot be concatenated. -c
,
--create
Create a new archive. Arguments supply the names of the
              files to be archived."
1511,14,tar,"Arguments supply the names of the
              files to be archived. Directories are archived
              recursively, unless the
--no-recursion
option is given. -d
,
--diff
,
--compare
Find differences between archive and file system."
1511,15,tar,"-d
,
--diff
,
--compare
Find differences between archive and file system. The
              arguments are optional and specify archive members to
              compare. If not given, the current working directory is
              assumed."
1511,16,tar,"If not given, the current working directory is
              assumed. --delete
Delete from the archive. The arguments supply names of the
              archive members to be removed."
1511,17,tar,"The arguments supply names of the
              archive members to be removed. At least one argument must
              be given. This option does not operate on compressed archives."
1511,18,tar,"This option does not operate on compressed archives. There
              is no short option equivalent. -r
,
--append
Append files to the end of an archive."
1511,19,tar,"-r
,
--append
Append files to the end of an archive. Arguments have the
              same meaning as for
-c
(
--create
). -t
,
--list
List the contents of an archive."
1511,20,tar,"-t
,
--list
List the contents of an archive. Arguments are optional. When given, they specify the names of the members to list."
1511,21,tar,"When given, they specify the names of the members to list. --test-label
Test the archive volume label and exit. When used without
              arguments, it prints the volume label (if any) and exits
              with status
0
."
1511,22,tar,"When used without
              arguments, it prints the volume label (if any) and exits
              with status
0
. When one or more command line arguments are
              given. tar
compares the volume label with each argument."
1511,23,tar,"tar
compares the volume label with each argument. It exits with code
0
if a match is found, and with code
1
otherwise. No output is displayed, unless used together
              with the
-v
(
--verbose
) option."
1511,24,tar,"No output is displayed, unless used together
              with the
-v
(
--verbose
) option. There is no short option equivalent for this option. -u
,
--update
Append files which are newer than the corresponding copy in
              the archive."
1511,25,tar,"-u
,
--update
Append files which are newer than the corresponding copy in
              the archive. Arguments have the same meaning as with the
-c
and
-r
options. Notice, that newer files don't replace
              their old archive copies, but instead are appended to the
              end of archive."
1511,26,tar,"Notice, that newer files don't replace
              their old archive copies, but instead are appended to the
              end of archive. The resulting archive can thus contain
              several members of the same name, corresponding to various
              versions of the same file. -x
,
--extract
,
--get
Extract files from an archive."
1511,27,tar,"-x
,
--extract
,
--get
Extract files from an archive. Arguments are optional. When given, they specify names of the archive members to be
              extracted."
1511,28,tar,"When given, they specify names of the archive members to be
              extracted. --show-defaults
Show built-in defaults for various
tar
options and exit. -?"
1511,29,tar,"-? ,
--help
Display a short option summary and exit. --usage
Display a list of available options and exit."
1511,30,tar,",
--help
Display a short option summary and exit. --usage
Display a list of available options and exit. --version
Print program version and copyright information and exit."
1512,0,tcpdump,"tcpdump
prints  out a description of the contents of packets on a
       network  interface  that  match  the   Boolean
expression
(see
pcap-filter
(@MAN_MISC_INFO@)   for  the
expression
syntax);  the
       description is preceded by a time stamp, printed, by  default,  as
       hours, minutes, seconds, and fractions of a second since midnight. It  can  also be run with the
-w
flag, which causes it to save the
       packet data to a file for later analysis, and/or with the
-r
flag,
       which causes it to read from a saved packet file  rather  than  to
       read  packets  from  a network interface. It can also be run with
       the
-V
flag, which causes it to read a list of saved packet files."
1512,1,tcpdump,"It can also be run with
       the
-V
flag, which causes it to read a list of saved packet files. In all cases, only packets that match
expression
will be processed
       by
tcpdump
. tcpdump
will, if not run with  the
-c
flag,  continue  capturing
       packets until it is interrupted by a
SIGINT
signal (generated, for
       example,  by typing your interrupt character, typically control-C)
       or  a
SIGTERM
signal  (typically  generated  with  the
kill(1)
command);  if  run with the
-c
flag, it will capture packets until
       it is interrupted by a
SIGINT
or
SIGTERM
signal or  the  specified
       number of packets have been processed."
1512,2,tcpdump,"tcpdump
will, if not run with  the
-c
flag,  continue  capturing
       packets until it is interrupted by a
SIGINT
signal (generated, for
       example,  by typing your interrupt character, typically control-C)
       or  a
SIGTERM
signal  (typically  generated  with  the
kill(1)
command);  if  run with the
-c
flag, it will capture packets until
       it is interrupted by a
SIGINT
or
SIGTERM
signal or  the  specified
       number of packets have been processed. When
tcpdump
finishes capturing packets, it will report counts of:

              packets  ``captured''  (this  is the number of packets that
tcpdump
has received and processed);

              packets ``received by filter'' (the meaning of this depends
              on the OS on which you're running
tcpdump
, and possibly  on
              the  way  the OS was configured - if a filter was specified
              on the  command  line,  on  some  OSes  it  counts  packets
              regardless  of  whether  they  were  matched  by the filter
              expression and, even if they were  matched  by  the  filter
              expression,  regardless  of  whether
tcpdump
has read and
              processed them yet, on other OSes it  counts  only  packets
              that  were  matched  by the filter expression regardless of
              whether
tcpdump
has read and processed  them  yet,  and  on
              other  OSes it counts only packets that were matched by the
              filter expression and were processed by
tcpdump
);

              packets ``dropped  by  kernel''  (this  is  the  number  of
              packets  that  were dropped, due to a lack of buffer space,
              by the packet capture mechanism in the OS on which
tcpdump
is   running,   if  the  OS  reports  that  information  to
              applications; if not, it will be reported as 0). On platforms that support the
SIGINFO
signal, such  as  most  BSDs
       (including  macOS), it will report those counts when it receives a
SIGINFO
signal (generated, for example, by typing your  ``status''
       character,  typically  control-T, although on some platforms, such
       as macOS, the ``status'' character is not set by default,  so  you
       must  set  it  with
stty(1)
in order to use it) and will continue
       capturing packets."
1512,3,tcpdump,"On platforms that support the
SIGINFO
signal, such  as  most  BSDs
       (including  macOS), it will report those counts when it receives a
SIGINFO
signal (generated, for example, by typing your  ``status''
       character,  typically  control-T, although on some platforms, such
       as macOS, the ``status'' character is not set by default,  so  you
       must  set  it  with
stty(1)
in order to use it) and will continue
       capturing packets. On platforms that do not  support  the
SIGINFO
signal, the same can be achieved by using the
SIGUSR1
signal. Using  the
SIGUSR2
signal  along  with the
-w
flag will forcibly
       flush the packet buffer into the output file."
1512,4,tcpdump,"Using  the
SIGUSR2
signal  along  with the
-w
flag will forcibly
       flush the packet buffer into the output file. Reading packets from a network interface may require that you have
       special privileges; see the
pcap
(3PCAP)  man  page  for  details. Reading a saved packet file doesn't require special privileges."
1513,0,tfmtodit,nan
1514,0,test,"The
test
utility shall evaluate the
expression
and indicate the
       result of the evaluation by its exit status. An exit status of
       zero indicates that the expression evaluated as true and an exit
       status of 1 indicates that the expression evaluated as false. In the second form of the utility, where the utility name used is
[
rather than
test
, the application shall ensure that the closing
       square bracket is a separate argument."
1514,1,test,"In the second form of the utility, where the utility name used is
[
rather than
test
, the application shall ensure that the closing
       square bracket is a separate argument. The
test
and
[
utilities
       may be implemented as a single linked utility which examines the
       basename of the zeroth command line argument to determine whether
       to behave as the
test
or
[
variant. Applications using the
exec
()
       family of functions to execute these utilities shall ensure that
       the argument passed in
arg0
or
argv
[0] is
'['
when executing the
[
utility and has a basename of
""test""
when executing the
test
utility."
1515,0,time,"The
time
command runs the specified program
command
with the given
       arguments. When
command
finishes,
time
writes a message to
       standard error giving timing statistics about this program run. These statistics consist of (i) the elapsed real time between
       invocation and termination, (ii) the user CPU time (the sum of the
tms_utime
and
tms_cutime
values in a
struct tms
as returned by
times(2)
), and (iii) the system CPU time (the sum of the
tms_stime
and
tms_cstime
values in a
struct tms
as returned by
times(2)
)."
1515,1,time,"These statistics consist of (i) the elapsed real time between
       invocation and termination, (ii) the user CPU time (the sum of the
tms_utime
and
tms_cutime
values in a
struct tms
as returned by
times(2)
), and (iii) the system CPU time (the sum of the
tms_stime
and
tms_cstime
values in a
struct tms
as returned by
times(2)
). Note: some shells (e.g.,
bash(1)
) have a built-in
time
command
       that provides similar information on the usage of time and
       possibly other resources. To access the real command, you may
       need to specify its pathname (something like
/usr/bin/time
)."
1516,0,time,"The
time
utility shall invoke the utility named by the
utility
operand with arguments supplied as the
argument
operands and write
       a message to standard error that lists timing statistics for the
       utility. The message shall include the following information:

        *  The elapsed (real) time between invocation of
utility
and its
           termination. *  The User CPU time, equivalent to the sum of the
tms_utime
and
tms_cutime
fields returned by the
times
() function defined in
           the System Interfaces volume of POSIX.1â2017 for the process
           in which
utility
is executed."
1516,1,time,"*  The User CPU time, equivalent to the sum of the
tms_utime
and
tms_cutime
fields returned by the
times
() function defined in
           the System Interfaces volume of POSIX.1â2017 for the process
           in which
utility
is executed. *  The System CPU time, equivalent to the sum of the
tms_stime
and
tms_cstime
fields returned by the
times
() function for the
           process in which
utility
is executed. The precision of the timing shall be no less than the granularity
       defined for the size of the clock tick unit on the system, but the
       results shall be reported in terms of standard time units (for
       example, 0.02 seconds, 00:00:00.02, 1m33.75s, 365.21 seconds), not
       numbers of clock ticks."
1516,2,time,"The precision of the timing shall be no less than the granularity
       defined for the size of the clock tick unit on the system, but the
       results shall be reported in terms of standard time units (for
       example, 0.02 seconds, 00:00:00.02, 1m33.75s, 365.21 seconds), not
       numbers of clock ticks. When
time
is used as part of a pipeline, the times reported are
       unspecified, except when it is the sole command within a grouping
       command (see
Section 2.9.4.1
,
Grouping Commands
) in that pipeline. For example, the commands on the left are unspecified; those on
       the right report on utilities
a
and
c
, respectively:

           time a | b | c    { time a; } | b | c
           a | b | time c    a | b | (time c)"
1517,0,tload,"tload
prints a graph of the current system load average to the
       specified
tty
(or the tty of the
tload
process if none is
       specified)."
1518,0,timedatectl,"timedatectl
may be used to query and change the system clock and
       its settings, and enable or disable time synchronization services.

       Use
systemd-firstboot(1)
to initialize the system time zone for
       mounted (but not booted) system images.
timedatectl
may be used to show the current status of time
       synchronization services, for example
systemd-timesyncd.service(8)
."
1519,0,tpmtool,Program that allows handling cryptographic data from the TPM chip.
1520,0,times,"The
times
utility shall write the accumulated user and system
       times for the shell and for all of its child processes, in the
       following POSIX locale format:

           ""%dm%fs %dm%fs\n%dm%fs %dm%fs\n"", <
shell user minutes
>,
               <
shell user seconds
>, <
shell system minutes
>,
               <
shell system seconds
>, <
children user minutes
>,
               <
children user seconds
>, <
children system minutes
>,
               <
children system seconds
>

       The four pairs of times shall correspond to the members of the
<sys/times.h>
tms
structure (defined in the Base Definitions
       volume of POSIX.1â2017,
Chapter 13
,
Headers
) as returned by
times
():
tms_utime
,
tms_stime
,
tms_cutime
, and
tms_cstime
,
       respectively."
1521,0,timeout,"Start COMMAND, and kill it if still running after DURATION. Mandatory arguments to long options are mandatory for short
       options too. -f
,
--foreground
when not running timeout directly from a shell prompt,

              allow COMMAND to read from the TTY and get TTY signals; in
              this mode, children of COMMAND will not be timed out
-k
,
--kill-after
=
DURATION
also send a KILL signal if COMMAND is still running

              this long after the initial signal was sent
-p
,
--preserve-status
exit with the same status as COMMAND,

              even when the command times out
-s
,
--signal
=
SIGNAL
specify the signal to be sent on timeout;

              SIGNAL may be a name like 'HUP' or a number; see 'kill
-l
'
              for a list of signals
-v
,
--verbose
diagnose to stderr any signal sent upon timeout
--help
display this help and exit
--version
output version information and exit

       DURATION is a floating point number with an optional suffix: 's'
       for seconds (the default), 'm' for minutes, 'h' for hours or 'd'
       for days."
1521,1,timeout,"-f
,
--foreground
when not running timeout directly from a shell prompt,

              allow COMMAND to read from the TTY and get TTY signals; in
              this mode, children of COMMAND will not be timed out
-k
,
--kill-after
=
DURATION
also send a KILL signal if COMMAND is still running

              this long after the initial signal was sent
-p
,
--preserve-status
exit with the same status as COMMAND,

              even when the command times out
-s
,
--signal
=
SIGNAL
specify the signal to be sent on timeout;

              SIGNAL may be a name like 'HUP' or a number; see 'kill
-l
'
              for a list of signals
-v
,
--verbose
diagnose to stderr any signal sent upon timeout
--help
display this help and exit
--version
output version information and exit

       DURATION is a floating point number with an optional suffix: 's'
       for seconds (the default), 'm' for minutes, 'h' for hours or 'd'
       for days. A duration of 0 disables the associated timeout. Upon timeout, send the TERM signal to COMMAND, if no other SIGNAL
       specified."
1521,2,timeout,"Upon timeout, send the TERM signal to COMMAND, if no other SIGNAL
       specified. The TERM signal kills any process that does not block
       or catch that signal. It may be necessary to use the KILL signal,
       since this signal can't be caught."
1521,3,timeout,"The TERM signal kills any process that does not block
       or catch that signal. It may be necessary to use the KILL signal,
       since this signal can't be caught. Exit status:
124    if COMMAND times out, and
--preserve-status
is not
              specified

       125    if the timeout command itself fails

       126    if COMMAND is found but cannot be invoked

       127    if COMMAND cannot be found

       137    if COMMAND (or timeout itself) is sent the KILL (9) signal
              (128+9)

       -      the exit status of COMMAND otherwise"
1522,0,touch,"Update the access and modification times of each FILE to the
       current time. A FILE argument that does not exist is created empty, unless
-c
or
-h
is supplied. A FILE argument string of - is handled specially and causes touch
       to change the times of the file associated with standard output."
1522,1,touch,"A FILE argument string of - is handled specially and causes touch
       to change the times of the file associated with standard output. Mandatory arguments to long options are mandatory for short
       options too. -a
change only the access time
-c
,
--no-create
do not create any files
-d
,
--date
=
STRING
parse STRING and use it instead of current time
-f
(ignored)
-h
,
--no-dereference
affect each symbolic link instead of any referenced file
              (useful only on systems that can change the timestamps of a
              symlink)
-m
change only the modification time
-r
,
--reference
=
FILE
use this file's times instead of current time
-t
[[CC]YY]MMDDhhmm[.ss]
              use specified time instead of current time, with a
              date-time format that differs from
-d
's
--time
=
WORD
specify which time to change: access time (
-a
): 'access',
              'atime', 'use'; modification time (
-m
): 'modify', 'mtime'
--help
display this help and exit
--version
output version information and exit"
1523,0,touch,"The
touch
utility shall change the last data modification
       timestamps, the last data access timestamps, or both. The time used can be specified by the
-t
time
option-argument, the
       corresponding
time
fields of the file referenced by the
-r
ref_file
option-argument, or the
-d
date_time
option-argument, as
       specified in the following sections. If none of these are
       specified,
touch
shall use the current time."
1523,1,touch,"If none of these are
       specified,
touch
shall use the current time. For each
file
operand,
touch
shall perform actions equivalent to
       the following functions defined in the System Interfaces volume of
       POSIX.1â2017:

        1. If
file
does not exist:

            a."
1523,2,touch,"If
file
does not exist:

            a. The
creat
() function is called with the following
               arguments:

               --  The
file
operand is used as the
path
argument. --  The value of the bitwise-inclusive OR of S_IRUSR,
                   S_IWUSR, S_IRGRP, S_IWGRP, S_IROTH, and S_IWOTH is
                   used as the
mode
argument."
1523,3,touch,"--  The value of the bitwise-inclusive OR of S_IRUSR,
                   S_IWUSR, S_IRGRP, S_IWGRP, S_IROTH, and S_IWOTH is
                   used as the
mode
argument. b. The
futimens
() function is called with the following
               arguments:

               --  The file descriptor opened in step 1a."
1523,4,touch,"The
futimens
() function is called with the following
               arguments:

               --  The file descriptor opened in step 1a. --  The access time and the modification time, set as
                   described in the OPTIONS section, are used as the
                   first and second elements of the
times
array argument,
                   respectively. 2."
1523,5,touch,"2. If
file
exists, the
utimensat
() function is called with the
           following arguments:

            a. The AT_FDCWD special value is used as the
fd
argument."
1523,6,touch,"The AT_FDCWD special value is used as the
fd
argument. b. The
file
operand is used as the
path
argument."
1523,7,touch,"The
file
operand is used as the
path
argument. c. The access time and the modification time, set as
               described in the OPTIONS section, are used as the first
               and second elements of the
times
array argument,
               respectively."
1523,8,touch,"The access time and the modification time, set as
               described in the OPTIONS section, are used as the first
               and second elements of the
times
array argument,
               respectively. d. The
flag
argument is set to zero."
1524,0,tput,"The
@TPUT@
utility uses the
terminfo
database to make the values
       of terminal-dependent capabilities and information available to
       the shell (see
sh
(1)), to initialize or reset the terminal, or
       return the long name of the requested terminal type. The result
       depends upon the capability's type:

          string
@TPUT@
writes the string to the standard output. No
               trailing newline is supplied."
1524,1,tput,"No
               trailing newline is supplied. integer
@TPUT@
writes the decimal value to the standard output,
               with a trailing newline. boolean
@TPUT@
simply sets the exit code (
0
for TRUE if the
               terminal has the capability,
1
for FALSE if it does not),
               and writes nothing to the standard output."
1524,2,tput,"boolean
@TPUT@
simply sets the exit code (
0
for TRUE if the
               terminal has the capability,
1
for FALSE if it does not),
               and writes nothing to the standard output. Before using a value returned on the standard output, the
       application should test the exit code (e.g.,
$? , see
sh
(1)) to be
       sure it is
0
."
1524,3,tput,", see
sh
(1)) to be
       sure it is
0
. (See the
EXIT CODES
and
DIAGNOSTICS
sections.)  For
       a complete list of capabilities and the
capname
associated with
       each, see
terminfo(5)
. Options
-S
allows more than one capability per invocation of
@TPUT@
."
1524,4,tput,"Options
-S
allows more than one capability per invocation of
@TPUT@
. The capabilities must be passed to
@TPUT@
from the standard
              input instead of from the command line (see example). Only
              one
capname
is allowed per line."
1524,5,tput,"Only
              one
capname
is allowed per line. The
-S
option changes the
              meaning of the
0
and
1
boolean and string exit codes (see
              the EXIT CODES section). Because some capabilities may use
string
parameters rather
              than
numbers
,
@TPUT@
uses a table and the presence of
              parameters in its input to decide whether to use
tparm
(3X),
              and how to interpret the parameters."
1524,6,tput,"Because some capabilities may use
string
parameters rather
              than
numbers
,
@TPUT@
uses a table and the presence of
              parameters in its input to decide whether to use
tparm
(3X),
              and how to interpret the parameters. -T
type
indicates the
type
of terminal. Normally this option is
              unnecessary, because the default is taken from the
              environment variable
TERM
."
1524,7,tput,"Normally this option is
              unnecessary, because the default is taken from the
              environment variable
TERM
. If
-T
is specified, then the
              shell variables
LINES
and
COLUMNS
will also be ignored. -V
reports the version of ncurses which was used in this
              program, and exits."
1524,8,tput,"-V
reports the version of ncurses which was used in this
              program, and exits. -x
do not attempt to clear the terminal's scrollback buffer
              using the extended âE3â capability. Commands
A few commands (
init
,
reset
and
longname
) are special; they are
       defined by the
@TPUT@
program."
1524,9,tput,"Commands
A few commands (
init
,
reset
and
longname
) are special; they are
       defined by the
@TPUT@
program. The others are the names of
capabilities
from the terminal database (see
terminfo(5)
for a
       list). Although
init
and
reset
resemble capability names,
@TPUT@
uses several capabilities to perform these special functions."
1524,10,tput,"Although
init
and
reset
resemble capability names,
@TPUT@
uses several capabilities to perform these special functions. capname
indicates the capability from the terminal database. If the capability is a string that takes parameters, the
              arguments following the capability will be used as
              parameters for the string."
1524,11,tput,"If the capability is a string that takes parameters, the
              arguments following the capability will be used as
              parameters for the string. Most parameters are numbers. Only a few terminal
              capabilities require string parameters;
@TPUT@
uses a table
              to decide which to pass as strings."
1524,12,tput,"Only a few terminal
              capabilities require string parameters;
@TPUT@
uses a table
              to decide which to pass as strings. Normally
@TPUT@
uses
tparm
(3X) to perform the substitution. If no parameters
              are given for the capability,
@TPUT@
writes the string
              without performing the substitution."
1524,13,tput,"If no parameters
              are given for the capability,
@TPUT@
writes the string
              without performing the substitution. init
If the terminal database is present and an entry for the
              user's terminal exists (see
-T
type
, above), the following
              will occur:

              (1)  first,
@TPUT@
retrieves the current terminal mode
                   settings for your terminal. It does this by
                   successively testing

                   â¢   the standard error,

                   â¢   standard output,

                   â¢   standard input and

                   â¢   ultimately â/dev/ttyâ

                   to obtain terminal settings."
1524,14,tput,"It does this by
                   successively testing

                   â¢   the standard error,

                   â¢   standard output,

                   â¢   standard input and

                   â¢   ultimately â/dev/ttyâ

                   to obtain terminal settings. Having retrieved these
                   settings,
@TPUT@
remembers which file descriptor to
                   use when updating settings. (2)  if the window size cannot be obtained from the
                   operating system, but the terminal description (or
                   environment, e.g.,
LINES
and
COLUMNS
variables specify
                   this), update the operating system's notion of the
                   window size."
1524,15,tput,"(2)  if the window size cannot be obtained from the
                   operating system, but the terminal description (or
                   environment, e.g.,
LINES
and
COLUMNS
variables specify
                   this), update the operating system's notion of the
                   window size. (3)  the terminal modes will be updated:

                   â¢   any delays (e.g., newline) specified in the entry
                       will be set in the tty driver,

                   â¢   tabs expansion will be turned on or off according
                       to the specification in the entry, and

                   â¢   if tabs are not expanded, standard tabs will be
                       set (every 8 spaces). (4)  if present, the terminal's initialization strings will
                   be output as detailed in the
terminfo(5)
section on
Tabs and Initialization
,

              (5)  output is flushed."
1524,16,tput,"(4)  if present, the terminal's initialization strings will
                   be output as detailed in the
terminfo(5)
section on
Tabs and Initialization
,

              (5)  output is flushed. If an entry does not contain the information needed for any
              of these activities, that activity will silently be
              skipped. reset
This is similar to
init
, with two differences:

              (1)  before any other initialization, the terminal modes
                   will be reset to a âsaneâ state:

                   â¢   set cooked and echo modes,

                   â¢   turn off cbreak and raw modes,

                   â¢   turn on newline translation and

                   â¢   reset any unset special characters to their
                       default values

              (2)  Instead of putting out
initialization
strings, the
                   terminal's
reset
strings will be output if present
                   (
rs1
,
rs2
,
rs3
,
rf
)."
1524,17,tput,"reset
This is similar to
init
, with two differences:

              (1)  before any other initialization, the terminal modes
                   will be reset to a âsaneâ state:

                   â¢   set cooked and echo modes,

                   â¢   turn off cbreak and raw modes,

                   â¢   turn on newline translation and

                   â¢   reset any unset special characters to their
                       default values

              (2)  Instead of putting out
initialization
strings, the
                   terminal's
reset
strings will be output if present
                   (
rs1
,
rs2
,
rs3
,
rf
). If the
reset
strings are not
                   present, but
initialization
strings are, the
initialization
strings will be output. Otherwise,
reset
acts identically to
init
."
1524,18,tput,"Otherwise,
reset
acts identically to
init
. longname
If the terminal database is present and an entry for the
              user's terminal exists (see
-T
type
above), then the long
              name of the terminal will be put out. The long name is the
              last name in the first line of the terminal's description
              in the
terminfo
database [see
term(5)
]."
1524,19,tput,"The long name is the
              last name in the first line of the terminal's description
              in the
terminfo
database [see
term(5)
]. Aliases
@TPUT@
handles the
clear
,
init
and
reset
commands specially: it
       allows for the possibility that it is invoked by a link with those
       names. If
@TPUT@
is invoked by a link named
reset
, this has the same
       effect as
@TPUT@ reset
."
1524,20,tput,"If
@TPUT@
is invoked by a link named
reset
, this has the same
       effect as
@TPUT@ reset
. The
@TSET@
(1) utility also treats a link
       named
reset
specially. Before ncurses 6.1, the two utilities were different from each
       other:

       â¢
@TSET@
utility reset the terminal modes and special characters
           (not done with
@TPUT@
)."
1524,21,tput,"Before ncurses 6.1, the two utilities were different from each
       other:

       â¢
@TSET@
utility reset the terminal modes and special characters
           (not done with
@TPUT@
). â¢   On the other hand,
@TSET@
's repertoire of terminal
           capabilities for resetting the terminal was more limited,
           i.e., only
reset_1string
,
reset_2string
and
reset_file
in
           contrast to the tab-stops and margins which are set by this
           utility. â¢   The
reset
program is usually an alias for
@TSET@
, because of
           this difference with resetting terminal modes and special
           characters."
1524,22,tput,"â¢   The
reset
program is usually an alias for
@TSET@
, because of
           this difference with resetting terminal modes and special
           characters. With the changes made for ncurses 6.1, the
reset
feature of the
       two programs is (mostly) the same. A few differences remain:

       â¢   The
@TSET@
program waits one second when resetting, in case it
           happens to be a hardware terminal."
1524,23,tput,"A few differences remain:

       â¢   The
@TSET@
program waits one second when resetting, in case it
           happens to be a hardware terminal. â¢   The two programs write the terminal initialization strings to
           different streams (i.e., the standard error for
@TSET@
and the
           standard output for
@TPUT@
). Note:
although these programs write to different streams,
           redirecting their output to a file will capture only part of
           their actions."
1524,24,tput,"Note:
although these programs write to different streams,
           redirecting their output to a file will capture only part of
           their actions. The changes to the terminal modes are not
           affected by redirecting the output. If
@TPUT@
is invoked by a link named
init
, this has the same
       effect as
@TPUT@ init
."
1524,25,tput,"If
@TPUT@
is invoked by a link named
init
, this has the same
       effect as
@TPUT@ init
. Again, you are less likely to use that
       link because another program named
init
has a more well-
       established use. Terminal Size
Besides the special commands (e.g.,
clear
), @TPUT@ treats certain
       terminfo capabilities specially:
lines
and
cols
."
1524,26,tput,"Terminal Size
Besides the special commands (e.g.,
clear
), @TPUT@ treats certain
       terminfo capabilities specially:
lines
and
cols
. @TPUT@ calls
setupterm
(3X) to obtain the terminal size:

       â¢   first, it gets the size from the terminal database (which
           generally is not provided for terminal emulators which do not
           have a fixed window size)

       â¢   then it asks the operating system for the terminal's size
           (which generally works, unless connecting via a serial line
           which does not support
NAWS
: negotiations about window size). â¢   finally, it inspects the environment variables
LINES
and
COLUMNS
which may override the terminal size."
1524,27,tput,"@TPUT@ calls
setupterm
(3X) to obtain the terminal size:

       â¢   first, it gets the size from the terminal database (which
           generally is not provided for terminal emulators which do not
           have a fixed window size)

       â¢   then it asks the operating system for the terminal's size
           (which generally works, unless connecting via a serial line
           which does not support
NAWS
: negotiations about window size). â¢   finally, it inspects the environment variables
LINES
and
COLUMNS
which may override the terminal size. If the
-T
option is given @TPUT@ ignores the environment variables
       by calling
use_tioctl(TRUE)
, relying upon the operating system (or
       finally, the terminal database)."
1525,0,top,"The
top
program provides a dynamic real-time view of a running
       system. It can display
system
summary information as well as a
       list of
processes
or
threads
currently being managed by the Linux
       kernel. The types of system summary information shown and the
       types, order and size of information displayed for processes are
       all user configurable and that configuration can be made
       persistent across restarts."
1525,1,top,"The types of system summary information shown and the
       types, order and size of information displayed for processes are
       all user configurable and that configuration can be made
       persistent across restarts. The program provides a limited interactive interface for process
       manipulation as well as a much more extensive interface for
       personal configuration  --  encompassing every aspect of its
       operation. And while
top
is referred to throughout this document,
       you are free to name the program anything you wish."
1525,2,top,"The program provides a limited interactive interface for process
       manipulation as well as a much more extensive interface for
       personal configuration  --  encompassing every aspect of its
       operation. And while
top
is referred to throughout this document,
       you are free to name the program anything you wish. That new
       name, possibly an alias, will then be reflected on top's display
       and used when reading and writing a configuration file."
1526,0,tmux,"tmux
is a terminal multiplexer: it enables a number of terminals
       to be created, accessed, and controlled from a single screen. tmux
may be detached from a screen and continue running in the
       background, then later reattached. When
tmux
is started, it creates a new
session
with a single
window
and displays it on screen."
1526,1,tmux,"When
tmux
is started, it creates a new
session
with a single
window
and displays it on screen. A status line at the bottom of
       the screen shows information on the current session and is used to
       enter interactive commands. A session is a single collection of
pseudo terminals
under the
       management of
tmux
."
1526,2,tmux,"A session is a single collection of
pseudo terminals
under the
       management of
tmux
. Each session has one or more windows linked
       to it. A window occupies the entire screen and may be split into
       rectangular panes, each of which is a separate pseudo terminal
       (the
pty
(4) manual page documents the technical details of pseudo
       terminals)."
1526,3,tmux,"A window occupies the entire screen and may be split into
       rectangular panes, each of which is a separate pseudo terminal
       (the
pty
(4) manual page documents the technical details of pseudo
       terminals). Any number of
tmux
instances may connect to the same
       session, and any number of windows may be present in the same
       session. Once all sessions are killed,
tmux
exits."
1526,4,tmux,"Once all sessions are killed,
tmux
exits. Each session is persistent and will survive accidental
       disconnection (such as
ssh
(1) connection timeout) or intentional
       detaching (with the âC-b dâ key strokes). tmux
may be reattached
       using:
$ tmux attach
In
tmux
, a session is displayed on screen by a
client
and all
       sessions are managed by a single
server
."
1526,5,tmux,"tmux
may be reattached
       using:
$ tmux attach
In
tmux
, a session is displayed on screen by a
client
and all
       sessions are managed by a single
server
. The server and each
       client are separate processes which communicate through a socket
       in
/tmp
. The options are as follows:
-2
Force
tmux
to assume the terminal supports 256
                     colours."
1526,6,tmux,"The options are as follows:
-2
Force
tmux
to assume the terminal supports 256
                     colours. This is equivalent to
-T
256
. -C
Start in control mode (see the âCONTROL MODEâ
                     section)."
1526,7,tmux,"-C
Start in control mode (see the âCONTROL MODEâ
                     section). Given twice (
-CC
) disables echo. -c
shell-command
Execute
shell-command
using the default shell."
1526,8,tmux,"-c
shell-command
Execute
shell-command
using the default shell. If
                     necessary, the
tmux
server will be started to
                     retrieve the
default-shell
option. This option is
                     for compatibility with
sh
(1) when
tmux
is used as a
                     login shell."
1526,9,tmux,"This option is
                     for compatibility with
sh
(1) when
tmux
is used as a
                     login shell. -D
Do not start the
tmux
server as a daemon. This also
                     turns the
exit-empty
option off."
1526,10,tmux,"This also
                     turns the
exit-empty
option off. With
-D
,
command
may not be specified. -f
file
Specify an alternative configuration file."
1526,11,tmux,"-f
file
Specify an alternative configuration file. By
                     default,
tmux
loads the system configuration file
                     from
@SYSCONFDIR@/tmux.conf
, if present, then looks
                     for a user configuration file at
~/.tmux.conf
or
$XDG_CONFIG_HOME/tmux/tmux.conf
. The configuration file is a set of
tmux
commands
                     which are executed in sequence when the server is
                     first started."
1526,12,tmux,"The configuration file is a set of
tmux
commands
                     which are executed in sequence when the server is
                     first started. tmux
loads configuration files once
                     when the server process has started. The
source-file
command may be used to load a file
                     later."
1526,13,tmux,"The
source-file
command may be used to load a file
                     later. tmux
shows any error messages from commands in
                     configuration files in the first session created,
                     and continues to process the rest of the
                     configuration file. -L
socket-name
tmux
stores the server socket in a directory under
                     TMUX_TMPDIR or
/tmp
if it is unset."
1526,14,tmux,"-L
socket-name
tmux
stores the server socket in a directory under
                     TMUX_TMPDIR or
/tmp
if it is unset. The default
                     socket is named
default
. This option allows a
                     different socket name to be specified, allowing
                     several independent
tmux
servers to be run."
1526,15,tmux,"This option allows a
                     different socket name to be specified, allowing
                     several independent
tmux
servers to be run. Unlike
-S
a full path is not necessary: the sockets are all
                     created in a directory
tmux-UID
under the directory
                     given by TMUX_TMPDIR or in
/tmp
. The
tmux-UID
directory is created by
tmux
and must not be world
                     readable, writable or executable."
1526,16,tmux,"The
tmux-UID
directory is created by
tmux
and must not be world
                     readable, writable or executable. If the socket is accidentally removed, the SIGUSR1
                     signal may be sent to the
tmux
server process to
                     recreate it (note that this will fail if any parent
                     directories are missing). -l
Behave as a login shell."
1526,17,tmux,"-l
Behave as a login shell. This flag currently has no
                     effect and is for compatibility with other shells
                     when using tmux as a login shell. -N
Do not start the server even if the command would
                     normally do so (for example
new-session
or
start-server
)."
1526,18,tmux,"-N
Do not start the server even if the command would
                     normally do so (for example
new-session
or
start-server
). -S
socket-path
Specify a full alternative path to the server
                     socket. If
-S
is specified, the default socket
                     directory is not used and any
-L
flag is ignored."
1526,19,tmux,"If
-S
is specified, the default socket
                     directory is not used and any
-L
flag is ignored. -T
features
Set terminal features for the client. This is a
                     comma-separated list of features."
1526,20,tmux,"This is a
                     comma-separated list of features. See the
terminal-features
option. -u
Write UTF-8 output to the terminal even if the first
                     environment variable of LC_ALL, LC_CTYPE, or LANG
                     that is set does not contain ""UTF-8"" or ""UTF8""."
1526,21,tmux,"-u
Write UTF-8 output to the terminal even if the first
                     environment variable of LC_ALL, LC_CTYPE, or LANG
                     that is set does not contain ""UTF-8"" or ""UTF8"". -V
Report the
tmux
version. -v
Request verbose logging."
1526,22,tmux,"-v
Request verbose logging. Log messages will be saved
                     into
tmux-client-PID.log
and
tmux-server-PID.log
files in the current directory, where
PID
is the PID
                     of the server or client process. If
-v
is specified
                     twice, an additional
tmux-out-PID.log
file is
                     generated with a copy of everything
tmux
writes to
                     the terminal."
1526,23,tmux,"If
-v
is specified
                     twice, an additional
tmux-out-PID.log
file is
                     generated with a copy of everything
tmux
writes to
                     the terminal. The SIGUSR2 signal may be sent to the
tmux
server
                     process to toggle logging between on (as if
-v
was
                     given) and off. command
[
flags
]
                     This specifies one of a set of commands used to
                     control
tmux
, as described in the following
                     sections."
1526,24,tmux,"The SIGUSR2 signal may be sent to the
tmux
server
                     process to toggle logging between on (as if
-v
was
                     given) and off. command
[
flags
]
                     This specifies one of a set of commands used to
                     control
tmux
, as described in the following
                     sections. If no commands are specified, the
new-session
command is assumed."
1527,0,tput,"The
@TPUT@
utility uses the
terminfo
database to make the values
       of terminal-dependent capabilities and information available to
       the shell (see
sh
(1)), to initialize or reset the terminal, or
       return the long name of the requested terminal type. The result
       depends upon the capability's type:

          string
@TPUT@
writes the string to the standard output. No
               trailing newline is supplied."
1527,1,tput,"No
               trailing newline is supplied. integer
@TPUT@
writes the decimal value to the standard output,
               with a trailing newline. boolean
@TPUT@
simply sets the exit code (
0
for TRUE if the
               terminal has the capability,
1
for FALSE if it does not),
               and writes nothing to the standard output."
1527,2,tput,"boolean
@TPUT@
simply sets the exit code (
0
for TRUE if the
               terminal has the capability,
1
for FALSE if it does not),
               and writes nothing to the standard output. Before using a value returned on the standard output, the
       application should test the exit code (e.g.,
$? , see
sh
(1)) to be
       sure it is
0
."
1527,3,tput,", see
sh
(1)) to be
       sure it is
0
. (See the
EXIT CODES
and
DIAGNOSTICS
sections.)  For
       a complete list of capabilities and the
capname
associated with
       each, see
terminfo(5)
. Options
-S
allows more than one capability per invocation of
@TPUT@
."
1527,4,tput,"Options
-S
allows more than one capability per invocation of
@TPUT@
. The capabilities must be passed to
@TPUT@
from the standard
              input instead of from the command line (see example). Only
              one
capname
is allowed per line."
1527,5,tput,"Only
              one
capname
is allowed per line. The
-S
option changes the
              meaning of the
0
and
1
boolean and string exit codes (see
              the EXIT CODES section). Because some capabilities may use
string
parameters rather
              than
numbers
,
@TPUT@
uses a table and the presence of
              parameters in its input to decide whether to use
tparm
(3X),
              and how to interpret the parameters."
1527,6,tput,"Because some capabilities may use
string
parameters rather
              than
numbers
,
@TPUT@
uses a table and the presence of
              parameters in its input to decide whether to use
tparm
(3X),
              and how to interpret the parameters. -T
type
indicates the
type
of terminal. Normally this option is
              unnecessary, because the default is taken from the
              environment variable
TERM
."
1527,7,tput,"Normally this option is
              unnecessary, because the default is taken from the
              environment variable
TERM
. If
-T
is specified, then the
              shell variables
LINES
and
COLUMNS
will also be ignored. -V
reports the version of ncurses which was used in this
              program, and exits."
1527,8,tput,"-V
reports the version of ncurses which was used in this
              program, and exits. -x
do not attempt to clear the terminal's scrollback buffer
              using the extended âE3â capability. Commands
A few commands (
init
,
reset
and
longname
) are special; they are
       defined by the
@TPUT@
program."
1527,9,tput,"Commands
A few commands (
init
,
reset
and
longname
) are special; they are
       defined by the
@TPUT@
program. The others are the names of
capabilities
from the terminal database (see
terminfo(5)
for a
       list). Although
init
and
reset
resemble capability names,
@TPUT@
uses several capabilities to perform these special functions."
1527,10,tput,"Although
init
and
reset
resemble capability names,
@TPUT@
uses several capabilities to perform these special functions. capname
indicates the capability from the terminal database. If the capability is a string that takes parameters, the
              arguments following the capability will be used as
              parameters for the string."
1527,11,tput,"If the capability is a string that takes parameters, the
              arguments following the capability will be used as
              parameters for the string. Most parameters are numbers. Only a few terminal
              capabilities require string parameters;
@TPUT@
uses a table
              to decide which to pass as strings."
1527,12,tput,"Only a few terminal
              capabilities require string parameters;
@TPUT@
uses a table
              to decide which to pass as strings. Normally
@TPUT@
uses
tparm
(3X) to perform the substitution. If no parameters
              are given for the capability,
@TPUT@
writes the string
              without performing the substitution."
1527,13,tput,"If no parameters
              are given for the capability,
@TPUT@
writes the string
              without performing the substitution. init
If the terminal database is present and an entry for the
              user's terminal exists (see
-T
type
, above), the following
              will occur:

              (1)  first,
@TPUT@
retrieves the current terminal mode
                   settings for your terminal. It does this by
                   successively testing

                   â¢   the standard error,

                   â¢   standard output,

                   â¢   standard input and

                   â¢   ultimately â/dev/ttyâ

                   to obtain terminal settings."
1527,14,tput,"It does this by
                   successively testing

                   â¢   the standard error,

                   â¢   standard output,

                   â¢   standard input and

                   â¢   ultimately â/dev/ttyâ

                   to obtain terminal settings. Having retrieved these
                   settings,
@TPUT@
remembers which file descriptor to
                   use when updating settings. (2)  if the window size cannot be obtained from the
                   operating system, but the terminal description (or
                   environment, e.g.,
LINES
and
COLUMNS
variables specify
                   this), update the operating system's notion of the
                   window size."
1527,15,tput,"(2)  if the window size cannot be obtained from the
                   operating system, but the terminal description (or
                   environment, e.g.,
LINES
and
COLUMNS
variables specify
                   this), update the operating system's notion of the
                   window size. (3)  the terminal modes will be updated:

                   â¢   any delays (e.g., newline) specified in the entry
                       will be set in the tty driver,

                   â¢   tabs expansion will be turned on or off according
                       to the specification in the entry, and

                   â¢   if tabs are not expanded, standard tabs will be
                       set (every 8 spaces). (4)  if present, the terminal's initialization strings will
                   be output as detailed in the
terminfo(5)
section on
Tabs and Initialization
,

              (5)  output is flushed."
1527,16,tput,"(4)  if present, the terminal's initialization strings will
                   be output as detailed in the
terminfo(5)
section on
Tabs and Initialization
,

              (5)  output is flushed. If an entry does not contain the information needed for any
              of these activities, that activity will silently be
              skipped. reset
This is similar to
init
, with two differences:

              (1)  before any other initialization, the terminal modes
                   will be reset to a âsaneâ state:

                   â¢   set cooked and echo modes,

                   â¢   turn off cbreak and raw modes,

                   â¢   turn on newline translation and

                   â¢   reset any unset special characters to their
                       default values

              (2)  Instead of putting out
initialization
strings, the
                   terminal's
reset
strings will be output if present
                   (
rs1
,
rs2
,
rs3
,
rf
)."
1527,17,tput,"reset
This is similar to
init
, with two differences:

              (1)  before any other initialization, the terminal modes
                   will be reset to a âsaneâ state:

                   â¢   set cooked and echo modes,

                   â¢   turn off cbreak and raw modes,

                   â¢   turn on newline translation and

                   â¢   reset any unset special characters to their
                       default values

              (2)  Instead of putting out
initialization
strings, the
                   terminal's
reset
strings will be output if present
                   (
rs1
,
rs2
,
rs3
,
rf
). If the
reset
strings are not
                   present, but
initialization
strings are, the
initialization
strings will be output. Otherwise,
reset
acts identically to
init
."
1527,18,tput,"Otherwise,
reset
acts identically to
init
. longname
If the terminal database is present and an entry for the
              user's terminal exists (see
-T
type
above), then the long
              name of the terminal will be put out. The long name is the
              last name in the first line of the terminal's description
              in the
terminfo
database [see
term(5)
]."
1527,19,tput,"The long name is the
              last name in the first line of the terminal's description
              in the
terminfo
database [see
term(5)
]. Aliases
@TPUT@
handles the
clear
,
init
and
reset
commands specially: it
       allows for the possibility that it is invoked by a link with those
       names. If
@TPUT@
is invoked by a link named
reset
, this has the same
       effect as
@TPUT@ reset
."
1527,20,tput,"If
@TPUT@
is invoked by a link named
reset
, this has the same
       effect as
@TPUT@ reset
. The
@TSET@
(1) utility also treats a link
       named
reset
specially. Before ncurses 6.1, the two utilities were different from each
       other:

       â¢
@TSET@
utility reset the terminal modes and special characters
           (not done with
@TPUT@
)."
1527,21,tput,"Before ncurses 6.1, the two utilities were different from each
       other:

       â¢
@TSET@
utility reset the terminal modes and special characters
           (not done with
@TPUT@
). â¢   On the other hand,
@TSET@
's repertoire of terminal
           capabilities for resetting the terminal was more limited,
           i.e., only
reset_1string
,
reset_2string
and
reset_file
in
           contrast to the tab-stops and margins which are set by this
           utility. â¢   The
reset
program is usually an alias for
@TSET@
, because of
           this difference with resetting terminal modes and special
           characters."
1527,22,tput,"â¢   The
reset
program is usually an alias for
@TSET@
, because of
           this difference with resetting terminal modes and special
           characters. With the changes made for ncurses 6.1, the
reset
feature of the
       two programs is (mostly) the same. A few differences remain:

       â¢   The
@TSET@
program waits one second when resetting, in case it
           happens to be a hardware terminal."
1527,23,tput,"A few differences remain:

       â¢   The
@TSET@
program waits one second when resetting, in case it
           happens to be a hardware terminal. â¢   The two programs write the terminal initialization strings to
           different streams (i.e., the standard error for
@TSET@
and the
           standard output for
@TPUT@
). Note:
although these programs write to different streams,
           redirecting their output to a file will capture only part of
           their actions."
1527,24,tput,"Note:
although these programs write to different streams,
           redirecting their output to a file will capture only part of
           their actions. The changes to the terminal modes are not
           affected by redirecting the output. If
@TPUT@
is invoked by a link named
init
, this has the same
       effect as
@TPUT@ init
."
1527,25,tput,"If
@TPUT@
is invoked by a link named
init
, this has the same
       effect as
@TPUT@ init
. Again, you are less likely to use that
       link because another program named
init
has a more well-
       established use. Terminal Size
Besides the special commands (e.g.,
clear
), @TPUT@ treats certain
       terminfo capabilities specially:
lines
and
cols
."
1527,26,tput,"Terminal Size
Besides the special commands (e.g.,
clear
), @TPUT@ treats certain
       terminfo capabilities specially:
lines
and
cols
. @TPUT@ calls
setupterm
(3X) to obtain the terminal size:

       â¢   first, it gets the size from the terminal database (which
           generally is not provided for terminal emulators which do not
           have a fixed window size)

       â¢   then it asks the operating system for the terminal's size
           (which generally works, unless connecting via a serial line
           which does not support
NAWS
: negotiations about window size). â¢   finally, it inspects the environment variables
LINES
and
COLUMNS
which may override the terminal size."
1527,27,tput,"@TPUT@ calls
setupterm
(3X) to obtain the terminal size:

       â¢   first, it gets the size from the terminal database (which
           generally is not provided for terminal emulators which do not
           have a fixed window size)

       â¢   then it asks the operating system for the terminal's size
           (which generally works, unless connecting via a serial line
           which does not support
NAWS
: negotiations about window size). â¢   finally, it inspects the environment variables
LINES
and
COLUMNS
which may override the terminal size. If the
-T
option is given @TPUT@ ignores the environment variables
       by calling
use_tioctl(TRUE)
, relying upon the operating system (or
       finally, the terminal database)."
1528,0,tput,"The
tput
utility shall display terminal-dependent information. The
       manner in which this information is retrieved is unspecified. The
       information displayed shall clear the terminal screen, initialize
       the user's terminal, or reset the user's terminal, depending on
       the operand given."
1528,1,tput,"The
       manner in which this information is retrieved is unspecified. The
       information displayed shall clear the terminal screen, initialize
       the user's terminal, or reset the user's terminal, depending on
       the operand given. The exact consequences of displaying this
       information are unspecified."
1529,0,tr,"The
tr
utility shall copy the standard input to the standard
       output with substitution or deletion of selected characters. The
       options specified and the
string1
and
string2
operands shall
       control translations that occur while copying characters and
       single-character collating elements."
1530,0,tr,"Translate, squeeze, and/or delete characters from standard input,
       writing to standard output. STRING1 and STRING2 specify arrays of
       characters ARRAY1 and ARRAY2 that control the action. -c
,
-C
,
--complement
use the complement of ARRAY1
-d
,
--delete
delete characters in ARRAY1, do not translate
-s
,
--squeeze-repeats
replace each sequence of a repeated character that is
              listed in the last specified ARRAY, with a single
              occurrence of that character
-t
,
--truncate-set1
first truncate ARRAY1 to length of ARRAY2
--help
display this help and exit
--version
output version information and exit

       ARRAYs are specified as strings of characters."
1530,1,tr,"-c
,
-C
,
--complement
use the complement of ARRAY1
-d
,
--delete
delete characters in ARRAY1, do not translate
-s
,
--squeeze-repeats
replace each sequence of a repeated character that is
              listed in the last specified ARRAY, with a single
              occurrence of that character
-t
,
--truncate-set1
first truncate ARRAY1 to length of ARRAY2
--help
display this help and exit
--version
output version information and exit

       ARRAYs are specified as strings of characters. Most represent
       themselves. Interpreted sequences are:

       \NNN   character with octal value NNN (1 to 3 octal digits)

       \\     backslash

       \a     audible BEL

       \b     backspace

       \f     form feed

       \n     new line

       \r     return

       \t     horizontal tab

       \v     vertical tab

       CHAR1-CHAR2
              all characters from CHAR1 to CHAR2 in ascending order

       [CHAR*]
              in ARRAY2, copies of CHAR until length of ARRAY1

       [CHAR*REPEAT]
              REPEAT copies of CHAR, REPEAT octal if starting with 0

       [:alnum:]
              all letters and digits

       [:alpha:]
              all letters

       [:blank:]
              all horizontal whitespace

       [:cntrl:]
              all control characters

       [:digit:]
              all digits

       [:graph:]
              all printable characters, not including space

       [:lower:]
              all lower case letters

       [:print:]
              all printable characters, including space

       [:punct:]
              all punctuation characters

       [:space:]
              all horizontal or vertical whitespace

       [:upper:]
              all upper case letters

       [:xdigit:]
              all hexadecimal digits

       [=CHAR=]
              all characters which are equivalent to CHAR

       Translation occurs if
-d
is not given and both STRING1 and STRING2
       appear."
1530,2,tr,"Interpreted sequences are:

       \NNN   character with octal value NNN (1 to 3 octal digits)

       \\     backslash

       \a     audible BEL

       \b     backspace

       \f     form feed

       \n     new line

       \r     return

       \t     horizontal tab

       \v     vertical tab

       CHAR1-CHAR2
              all characters from CHAR1 to CHAR2 in ascending order

       [CHAR*]
              in ARRAY2, copies of CHAR until length of ARRAY1

       [CHAR*REPEAT]
              REPEAT copies of CHAR, REPEAT octal if starting with 0

       [:alnum:]
              all letters and digits

       [:alpha:]
              all letters

       [:blank:]
              all horizontal whitespace

       [:cntrl:]
              all control characters

       [:digit:]
              all digits

       [:graph:]
              all printable characters, not including space

       [:lower:]
              all lower case letters

       [:print:]
              all printable characters, including space

       [:punct:]
              all punctuation characters

       [:space:]
              all horizontal or vertical whitespace

       [:upper:]
              all upper case letters

       [:xdigit:]
              all hexadecimal digits

       [=CHAR=]
              all characters which are equivalent to CHAR

       Translation occurs if
-d
is not given and both STRING1 and STRING2
       appear. -t
is only significant when translating. ARRAY2 is
       extended to length of ARRAY1 by repeating its last character as
       necessary."
1530,3,tr,"ARRAY2 is
       extended to length of ARRAY1 by repeating its last character as
       necessary. Excess characters of ARRAY2 are ignored. Character
       classes expand in unspecified order; while translating, [:lower:]
       and [:upper:] may be used in pairs to specify case conversion."
1530,4,tr,"Excess characters of ARRAY2 are ignored. Character
       classes expand in unspecified order; while translating, [:lower:]
       and [:upper:] may be used in pairs to specify case conversion. Squeezing occurs after translation or deletion."
1531,0,trace-cmd-agent,"The trace-cmd(1) agent listens over a vsocket (for virtual
       machines) or a TCP port for connections to control the tracing of
       the machine. The agent will then start tracing on the local
       machine and pass the data to the controlling connection."
1532,0,trace-cmd-attach,"The trace-cmd(1) attach is used to take a trace.dat file created
       on a guest and attach it to a trace.dat file that was created on
       the host. In most cases, trace-cmd-agent(1) can be used to
       automate this, but if for some reason, the agent isnât
       appropriate, it may be required to start trace-cmd recording on
       the guest with trace-cmd-record(1). If the host recording is
       activated at the same time, one can use trace-cmd attach(1) to
       connect the guest and host files as if they were created by the
       trace-cmd agent."
1532,1,trace-cmd-attach,"If the host recording is
       activated at the same time, one can use trace-cmd attach(1) to
       connect the guest and host files as if they were created by the
       trace-cmd agent. host-trace-file
The trace.dat file created by the host. Must have kvm_exit and
           kvm_entry events, and use the ""tsc2nsec"" clock."
1532,2,trace-cmd-attach,"Must have kvm_exit and
           kvm_entry events, and use the ""tsc2nsec"" clock. guest-trace-file
The trace.dat file created by the guest. Must use the
           ""x86-tsc"" clock."
1532,3,trace-cmd-attach,"Must use the
           ""x86-tsc"" clock. For now, this is only supported on x86, it
           may support other achitectures later. guest-pid
The process ID of the host thread that represents the guests
           threads."
1532,4,trace-cmd-attach,"guest-pid
The process ID of the host thread that represents the guests
           threads. Each process ID that represents all of the guest
           vCPUs should be listed. Note, you can add more than just the
           threads that represent the guest vCPUs, as the tool will
           search the
host-trace-file
for kvm_exit and kvm_entry events
           to match these PIDs with the vCPUs that they represent."
1533,0,trace-cmd-check-events,"The trace-cmd(1) check-events parses format strings for all the
       events on the local system. It returns whether all the format
       strings can be parsed correctly. It will load plugins unless
       specified otherwise."
1533,1,trace-cmd-check-events,"It will load plugins unless
       specified otherwise. This is useful to check for any trace event format strings which
       may contain some internal kernel function references which cannot
       be decoded outside of the kernel. This may mean that either the
       unparsed format strings of the trace events need to be changed or
       that a plugin needs to be created to parse them."
1534,0,trace-cmd-clear,"The
trace-cmd(1) clear
clears the content of the Ftrace ring
       buffer."
1535,0,trace-cmd-convert,"The trace-cmd(1) convert command converts trace file. It reads the
       input file and copies the data into an output file. The output
       file may be in different format, depending on the command line
       arguments."
1535,1,trace-cmd-convert,"It reads the
       input file and copies the data into an output file. The output
       file may be in different format, depending on the command line
       arguments. The default output is in version 7 and compressed (if
       compiled with compression support)."
1536,0,trace-cmd-dump,"The trace-cmd(1) dump command will display the meta data from a
       trace file created by trace-cmd record."
1537,0,trace-cmd-extract,"The trace-cmd(1) extract is usually used after
trace-cmd-start(1)
and
trace-cmd-stop(1)
. It can be used after the Ftrace tracer has
       been started manually through the Ftrace pseudo file system. The extract command creates a trace.dat file that can be used by
trace-cmd-report(1)
to read from."
1537,1,trace-cmd-extract,"It can be used after the Ftrace tracer has
       been started manually through the Ftrace pseudo file system. The extract command creates a trace.dat file that can be used by
trace-cmd-report(1)
to read from. It reads the kernel internal
       ring buffer to produce the trace.dat file."
1538,0,trace-cmd-listen,"The trace-cmd(1) listen sets up a port to listen to waiting for
       connections from other hosts that run
trace-cmd-record(1)
with the
-N
option. When a connection is made, and the remote host sends
       data, it will create a file called
trace.HOST:PORT.dat
. Where HOST
       is the name of the remote host, and PORT is the port that the
       remote host used to connect with."
1539,0,trace-cmd-list,"The trace-cmd(1) list displays the available plugins, events or
       Ftrace options that are configured on the current machine. If no
       option is given, then it lists all plugins, event systems, events
       and Ftrace options to standard output."
1540,0,trace-cmd-hist,"The trace-cmd(1) hist displays a histogram form from the trace.dat
       file. Instead of showing the events as they were ordered, it
       creates a histogram that can be displayed per task or for all
       tasks where the most common events appear first. It uses the
       function tracer and call stacks that it finds to try to put
       together a call graph of the events."
1541,0,trace-cmd-options,"The trace-cmd(1) options command will examine all the trace-cmd
       plugins that are used by
trace-cmd report(1)
and list them."
1542,0,trace-cmd-mem,"The trace-cmd(1) mem requires a trace-cmd record that enabled the
       following events:

           kmalloc
           kmalloc_node
           kfree
           kmem_cache_alloc
           kmem_cache_alloc_node
           kmem_cache_alloc_free

       It then reads the amount requested and the ammount freed as well
       as the functions that called the allocation. It then reports the
       final amount of bytes requested and allocated, along with the
       total amount allocated and requested, as well as the max
       allocation and requested during the run. It reports the amount of
       wasted bytes (allocated - requested) that was not freed, as well
       as the max wasted amount during the run."
1542,1,trace-cmd-mem,"It reports the amount of
       wasted bytes (allocated - requested) that was not freed, as well
       as the max wasted amount during the run. The list is sorted by
       descending order of wasted bytes after the run. Function                Waste   Alloc   req             TotAlloc     TotReq             MaxAlloc     MaxReq     MaxWaste
                   --------                -----   -----   ---             --------     ------             --------     ------     --------
             rb_allocate_cpu_buffer        768     2304    1536                2304       1536                 2304       1536     768
                    alloc_pipe_info        400     1152    752                 1152        752                 1152        752     400
                     instance_mkdir        252     544     292                  544        292                  544        292     252
                          __d_alloc        215     1086560 1086345          1087208    1086993              1086560    1086345     215
                     get_empty_filp        72      2304    2232                4864       4712                 4864       4712     152
                           mm_alloc        40      960     920                  960        920                  960        920     40
                      prepare_creds        32      192     160                 1728       1440                 1728       1440     288
               tracing_buffers_open        8       32      24                    32         24                   32         24     8
                             do_brk        0       0       0                    368        368                  368        368     0
           journal_add_journal_head        0       6048    6048                6048       6048                 6048       6048     0
                      journal_start        0       0       0                   1224       1224                   48         48     0
                __rb_allocate_pages        0       3289856 3289856          3289856    3289856              3289856    3289856     0
                     anon_vma_alloc        0       0       0                    936        936                  864        864     0
                                                                   [...]"
1543,0,trace-cmd-profile,"The trace-cmd(1) profile will start tracing just like
       trace-cmd-record(1), with the
--profile
option, except that it
       does not write to a file, but instead, it will read the events as
       they happen and will update the accounting of the events. When the
       trace is finished, it will report the results just like
       trace-cmd-report(1) would do with its
--profile
option. In other
       words, the profile command does the work of trace-cmd record
       --profile, and trace-cmd report --profile without having to record
       the data to disk, in between."
1543,1,trace-cmd-profile,"In other
       words, the profile command does the work of trace-cmd record
       --profile, and trace-cmd report --profile without having to record
       the data to disk, in between. The advantage of using the profile command is that the profiling
       can be done over a long period of time where recording all events
       would take up too much disk space. This will enable several events as well as the function graph
       tracer with a depth of one (if the kernel supports it)."
1543,2,trace-cmd-profile,"This will enable several events as well as the function graph
       tracer with a depth of one (if the kernel supports it). This is to
       show where tasks enter and exit the kernel and how long they were
       in the kernel. To disable calling function graph, use the
-p
option to enable
       another tracer."
1543,3,trace-cmd-profile,"To disable calling function graph, use the
-p
option to enable
       another tracer. To not enable any tracer, use
-p nop
. All timings are currently in nanoseconds."
1544,0,trace-cmd-reset,"The trace-cmd(1) reset command turns off all tracing of Ftrace. This will bring back the performance of the system before tracing
       was enabled. This is necessary since
trace-cmd-record(1)
,
trace-cmd-stop(1)
and
trace-cmd-extract(1)
do not disable the
       tracer, event after the data has been pulled from the buffers."
1544,1,trace-cmd-reset,"This is necessary since
trace-cmd-record(1)
,
trace-cmd-stop(1)
and
trace-cmd-extract(1)
do not disable the
       tracer, event after the data has been pulled from the buffers. The
       rational is that the user may want to manually enable the tracer
       with the Ftrace pseudo file system, or examine other parts of
       Ftrace to see what trace-cmd did. After the reset command happens,
       the data in the ring buffer, and the options that were used are
       all lost."
1545,0,trace-cmd-report,"The trace-cmd(1) report command will output a human readable
       report of a trace created by trace-cmd record."
1546,0,trace-cmd-record,"The trace-cmd(1) record command will set up the Ftrace Linux
       kernel tracer to record the specified plugins or events that
       happen while the
command
executes. If no command is given, then it
       will record until the user hits Ctrl-C. The record command of trace-cmd will set up the Ftrace tracer to
       start tracing the various events or plugins that are given on the
       command line."
1546,1,trace-cmd-record,"The record command of trace-cmd will set up the Ftrace tracer to
       start tracing the various events or plugins that are given on the
       command line. It will then create a number of tracing processes
       (one per CPU) that will start recording from the kernel ring
       buffer straight into temporary files. When the command is complete
       (or Ctrl-C is hit) all the files will be combined into a trace.dat
       file that can later be read (see trace-cmd-report(1))."
1547,0,trace-cmd-restore,"The trace-cmd(1) restore command will restore a crashed
       trace-cmd-record(1) file. If for some reason a trace-cmd record
       fails, it will leave a the per-cpu data files and not create the
       final trace.dat file. The trace-cmd restore will append the files
       to create a working trace.dat file that can be read with
       trace-cmd-report(1)."
1547,1,trace-cmd-restore,"The trace-cmd restore will append the files
       to create a working trace.dat file that can be read with
       trace-cmd-report(1). When trace-cmd record runs, it spawns off a process per CPU and
       writes to a per cpu file usually called
trace.dat.cpuX
, where X
       represents the CPU number that it is tracing. If the -o option was
       used in the trace-cmd record, then the CPU data files will have
       that name instead of the
trace.dat
name."
1547,2,trace-cmd-restore,"If the -o option was
       used in the trace-cmd record, then the CPU data files will have
       that name instead of the
trace.dat
name. If a unexpected crash
       occurs before the tracing is finished, then the per CPU files will
       still exist but there will not be any trace.dat file to read from. trace-cmd restore will allow you to create a trace.dat file with
       the existing data files."
1548,0,trace-cmd-set,"The trace-cmd(1) set command will set a configuration parameter of
       the Ftrace Linux kernel tracer. The specified
command
will be run
       after the ftrace state is set. The configured ftrace state can be
       restored to default using the trace-cmd-reset(1) command."
1549,0,trace-cmd-show,"The trace-cmd(1) show displays the contents of one of the Ftrace
       Linux kernel tracing files: trace, snapshot, or trace_pipe. It is
       basically the equivalent of doing:

           cat /sys/kernel/debug/tracing/trace"
1550,0,trace-cmd-snapshot,"The trace-cmd(1) snapshot controls or displays the Ftrace Linux
       kernel snapshot feature (if the kernel supports it). This is
       useful to ""freeze"" an instance of a live trace but without
       stopping the trace.

            trace-cmd start -p function
            trace-cmd snapshot -s
            trace-cmd snapshot
           [ dumps the content of buffer at 'trace-cmd snapshot -s' ]
            trace-cmd snapshot -s
            trace-cmd snapshot
           [ dumps the new content of the buffer at the last -s operation ]"
1551,0,trace-cmd-split,"The trace-cmd(1) split is used to break up a trace.dat into small
       files. The
start-time
specifies where the new file will start at. Using
trace-cmd-report(1)
and copying the time stamp given at a
       particular event, can be used as input for either
start-time
or
end-time
."
1551,1,trace-cmd-split,"Using
trace-cmd-report(1)
and copying the time stamp given at a
       particular event, can be used as input for either
start-time
or
end-time
. The split will stop creating files when it reaches an
       event after
end-time
. If only the end-time is needed, use 0.0 as
       the start-time."
1551,2,trace-cmd-split,"If only the end-time is needed, use 0.0 as
       the start-time. If start-time is left out, then the split will start at the
       beginning of the file. If end-time is left out, then split will
       continue to the end unless it meets one of the requirements
       specified by the options."
1552,0,trace-cmd-sqlhist,"The trace-cmd sqlhist(1) will take an SQL like statement to create
       tracefs histograms and synthetic events that can perform various
       actions for various handling of the data. The tracefs file system interfaces with the Linux tracing
       infrastructure that has various dynamic and static events through
       out the kernel. Each of these events can have a ""histogram""
       attached to it, where the fields of the event will define the
       buckets of the histogram."
1552,1,trace-cmd-sqlhist,"Each of these events can have a ""histogram""
       attached to it, where the fields of the event will define the
       buckets of the histogram. A synthetic event is a way to attach two separate events and use
       the fields and time stamps of those events to create a new dynamic
       event. This new dynamic event is call a synthetic event."
1552,2,trace-cmd-sqlhist,"This new dynamic event is call a synthetic event. The
       fields of each event can have simple calculations done on them
       where, for example, the delta between a field of one event to a
       field of the other event can be taken. This also works for the
       time stamps of the events where the time delta between the two
       events can also be extracted and placed into the synthetic event."
1552,3,trace-cmd-sqlhist,"This also works for the
       time stamps of the events where the time delta between the two
       events can also be extracted and placed into the synthetic event. Other actions can be done from the fields of the events. A
       snapshot can be taken of the kernel ring buffer a variable used in
       the synthetic event creating hits a max, or simply changes."
1552,4,trace-cmd-sqlhist,"A
       snapshot can be taken of the kernel ring buffer a variable used in
       the synthetic event creating hits a max, or simply changes. The commands to create histograms and synthetic events are complex
       and not easy to remember. trace-cmd sqlhist
is used to convert SQL
       syntax into the commands needed to create the histogram or
       synthetic event."
1552,5,trace-cmd-sqlhist,"trace-cmd sqlhist
is used to convert SQL
       syntax into the commands needed to create the histogram or
       synthetic event. The
SQL-select-command
is a SQL string defined by
tracefs_sqlhist
(3). Note, this must be run as root (or sudo) as interacting with the
       tracefs directory requires root privilege, unless the
-t
option is
       given with a copy of the
tracefs
directory and its events."
1553,0,trace-cmd-stack,"The trace-cmd(1) stack enables the Ftrace stack tracer within the
       kernel. The stack tracer enables the function tracer and at each
       function call within the kernel, the stack is checked. When a new
       maximum usage stack is discovered, it is recorded."
1553,1,trace-cmd-stack,"When a new
       maximum usage stack is discovered, it is recorded. When no option is used, the current stack is displayed. To enable the stack tracer, use the option
--start
, and to disable
       the stack tracer, use the option
--stop
."
1553,2,trace-cmd-stack,"To enable the stack tracer, use the option
--start
, and to disable
       the stack tracer, use the option
--stop
. The output will be the
       maximum stack found since the start was enabled. Use
--reset
to reset the stack counter to zero."
1553,3,trace-cmd-stack,"Use
--reset
to reset the stack counter to zero. User
--verbose
[=
level
] to set the log level. Supported log levels
       are ""none"", ""critical"", ""error"", ""warning"", ""info"", ""debug"", ""all""
       or their identifiers ""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6""."
1553,4,trace-cmd-stack,"Supported log levels
       are ""none"", ""critical"", ""error"", ""warning"", ""info"", ""debug"", ""all""
       or their identifiers ""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6"". Setting
       the log level to specific value enables all logs from that and all
       previous levels. The level will default to ""info"" if one is not
       specified."
1554,0,trace-cmd-start,"The trace-cmd(1) start enables all the Ftrace tracing the same way
       trace-cmd-record(1) does. The difference is that it does not run
       threads to create a trace.dat file. This is useful just to enable
       Ftrace and you are only interested in the trace after some event
       has occurred and the trace is stopped."
1554,1,trace-cmd-start,"The difference is that it does not run
       threads to create a trace.dat file. This is useful just to enable
       Ftrace and you are only interested in the trace after some event
       has occurred and the trace is stopped. Then the trace can be read
       straight from the Ftrace pseudo file system or can be extracted
       with trace-cmd-extract(1)."
1555,0,trace-cmd-stat,"The trace-cmd(1) stat displays the various status of the tracing
       (ftrace) system. The status that it shows is:
Instances:
List all configured ftrace instances. Tracer:
if one of the tracers (like function_graph) is active."
1555,1,trace-cmd-stat,"Tracer:
if one of the tracers (like function_graph) is active. Otherwise nothing is displayed. Events:
Lists the events that are enable."
1555,2,trace-cmd-stat,"Events:
Lists the events that are enable. Event filters:
Shows any filters that are set for any events
Function filters:
Shows any filters for the function tracers
Graph functions:
Shows any functions that the function graph
       tracer should graph
Buffers:
Shows the trace buffer size if they have been expanded. By default, tracing buffers are in a compressed format until they
       are used."
1555,3,trace-cmd-stat,"By default, tracing buffers are in a compressed format until they
       are used. If they are compressed, the buffer display will not be
       shown. Trace clock:
If the tracing clock is anything other than the
       default ""local"" it will be displayed."
1555,4,trace-cmd-stat,"Trace clock:
If the tracing clock is anything other than the
       default ""local"" it will be displayed. Trace CPU mask:
If not all available CPUs are in the tracing CPU
       mask, then the tracing CPU mask will be displayed. Trace max latency:
Shows the value of the trace max latency if it
       is other than zero."
1555,5,trace-cmd-stat,"Trace max latency:
Shows the value of the trace max latency if it
       is other than zero. Kprobes:
Shows any kprobes that are defined for tracing. Uprobes:
Shows any uprobes that are defined for tracing."
1555,6,trace-cmd-stat,"Kprobes:
Shows any kprobes that are defined for tracing. Uprobes:
Shows any uprobes that are defined for tracing. Error log:
Dump the content of ftrace error_log file."
1556,0,trace-cmd-stop,"The trace-cmd(1) stop is a complement to
trace-cmd-start(1)
. This
       will disable Ftrace from writing to the ring buffer. This does not
       stop the overhead that the tracing may incur."
1556,1,trace-cmd-stop,"This does not
       stop the overhead that the tracing may incur. Only the updating of
       the ring buffer is disabled, the Ftrace tracing may still be
       inducing overhead. After stopping the trace, the
trace-cmd-extract(1)
may strip out
       the data from the ring buffer and create a trace.dat file."
1556,2,trace-cmd-stop,"After stopping the trace, the
trace-cmd-extract(1)
may strip out
       the data from the ring buffer and create a trace.dat file. The
       Ftrace pseudo file system may also be examined. To disable the tracing completely to remove the overhead it
       causes, use
trace-cmd-reset(1)
."
1556,3,trace-cmd-stop,"The
       Ftrace pseudo file system may also be examined. To disable the tracing completely to remove the overhead it
       causes, use
trace-cmd-reset(1)
. But after a reset is performed,
       the data that has been recorded is lost."
1557,0,trace-cmd-stream,"The trace-cmd(1) stream will start tracing just like
       trace-cmd-record(1), except it will not record to a file and
       instead it will read the binary buffer as it is happening, convert
       it to a human readable format and write it to stdout. This is basically the same as trace-cmd-start(1) and then doing a
       trace-cmd-show(1) with the
-p
option. trace-cmd-stream is not as
       efficient as reading from the pipe file as most of the stream work
       is done in userspace."
1557,1,trace-cmd-stream,"This is basically the same as trace-cmd-start(1) and then doing a
       trace-cmd-show(1) with the
-p
option. trace-cmd-stream is not as
       efficient as reading from the pipe file as most of the stream work
       is done in userspace. This is useful if it is needed to do the
       work mostly in userspace instead of the kernel, and stream also
       helps to debug trace-cmd-profile(1) which uses the stream code to
       perform the live data analysis for the profile."
1558,0,true,"The
true
utility shall return with exit code zero."
1559,0,trace-cmd,"The trace-cmd(1) command interacts with the Ftrace tracer that is
       built inside the Linux kernel. It interfaces with the Ftrace
       specific files found in the debugfs file system under the tracing
       directory. A
COMMAND
must be specified to tell trace-cmd what to
       do."
1560,0,trap,"If the first operand is an unsigned decimal integer, the shell
       shall treat all operands as conditions, and shall reset each
       condition to the default value. Otherwise, if there are operands,
       the first is treated as an action and the remaining as conditions. If
action
is
'-'
, the shell shall reset each
condition
to the
       default value."
1560,1,trap,"If
action
is
'-'
, the shell shall reset each
condition
to the
       default value. If
action
is null (
""""
), the shell shall ignore each
       specified
condition
if it arises. Otherwise, the argument
action
shall be read and executed by the shell when one of the
       corresponding conditions arises."
1560,2,trap,"Otherwise, the argument
action
shall be read and executed by the shell when one of the
       corresponding conditions arises. The action of
trap
shall override
       a previous action (either default action or one explicitly set). The value of
""$?""
after the
trap
action completes shall be the
       value it had before
trap
was invoked."
1560,3,trap,"The value of
""$?""
after the
trap
action completes shall be the
       value it had before
trap
was invoked. The condition can be EXIT, 0 (equivalent to EXIT), or a signal
       specified using a symbolic name, without the SIG prefix, as listed
       in the tables of signal names in the
<signal.h>
header defined in
       the Base Definitions volume of POSIX.1â2017,
Chapter 13
,
Headers
;
       for example, HUP, INT, QUIT, TERM. Implementations may permit
       names with the SIG prefix or ignore case in signal names as an
       extension."
1560,4,trap,"Implementations may permit
       names with the SIG prefix or ignore case in signal names as an
       extension. Setting a trap for SIGKILL or SIGSTOP produces
       undefined results. The environment in which the shell executes a
trap
on EXIT shall
       be identical to the environment immediately after the last command
       executed before the
trap
on EXIT was taken."
1560,5,trap,"The environment in which the shell executes a
trap
on EXIT shall
       be identical to the environment immediately after the last command
       executed before the
trap
on EXIT was taken. Each time
trap
is invoked, the
action
argument shall be processed
       in a manner equivalent to:

           eval
action
Signals that were ignored on entry to a non-interactive shell
       cannot be trapped or reset, although no error need be reported
       when attempting to do so. An interactive shell may reset or catch
       signals ignored on entry."
1560,6,trap,"An interactive shell may reset or catch
       signals ignored on entry. Traps shall remain in place for a given
       shell until explicitly changed with another
trap
command. When a subshell is entered, traps that are not being ignored shall
       be set to the default actions, except in the case of a command
       substitution containing only a single
trap
command, when the traps
       need not be altered."
1560,7,trap,"When a subshell is entered, traps that are not being ignored shall
       be set to the default actions, except in the case of a command
       substitution containing only a single
trap
command, when the traps
       need not be altered. Implementations may check for this case using
       only lexical analysis; for example, if
`trap`
and
$( trap -- )
do
       not alter the traps in the subshell, cases such as assigning
var=trap
and then using
$($var)
may still alter them. This does
       not imply that the
trap
command cannot be used within the subshell
       to set new traps."
1560,8,trap,"This does
       not imply that the
trap
command cannot be used within the subshell
       to set new traps. The
trap
command with no operands shall write to standard output a
       list of commands associated with each condition. If the command is
       executed in a subshell, the implementation does not perform the
       optional check described above for a command substitution
       containing only a single
trap
command, and no
trap
commands with
       operands have been executed since entry to the subshell, the list
       shall contain the commands that were associated with each
       condition immediately before the subshell environment was entered."
1560,9,trap,"If the command is
       executed in a subshell, the implementation does not perform the
       optional check described above for a command substitution
       containing only a single
trap
command, and no
trap
commands with
       operands have been executed since entry to the subshell, the list
       shall contain the commands that were associated with each
       condition immediately before the subshell environment was entered. Otherwise, the list shall contain the commands currently
       associated with each condition. The format shall be:

           ""trap -- %s %s ...\n"", <
action
>, <
condition
> ..."
1560,10,trap,"The format shall be:

           ""trap -- %s %s ...\n"", <
action
>, <
condition
> ... The shell shall format the output, including the proper use of
       quoting, so that it is suitable for reinput to the shell as
       commands that achieve the same trapping results. For example:

           save_traps=$(trap)
           ..."
1560,11,trap,"The shell shall format the output, including the proper use of
       quoting, so that it is suitable for reinput to the shell as
       commands that achieve the same trapping results. For example:

           save_traps=$(trap)
           ... eval ""$save_traps""

       XSI-conformant systems also allow numeric signal numbers for the
       conditions corresponding to the following signal names:

       1     SIGHUP

       2     SIGINT

       3     SIGQUIT

       6     SIGABRT

       9     SIGKILL

       14    SIGALRM

       15    SIGTERM

       The
trap
special built-in shall conform to the Base Definitions
       volume of POSIX.1â2017,
Section 12.2
,
Utility Syntax Guidelines
."
1561,0,truncate,"Shrink or extend the size of each FILE to the specified size

       A FILE argument that does not exist is created. If a FILE is larger than the specified size, the extra data is
       lost. If a FILE is shorter, it is extended and the sparse
       extended part (hole) reads as zero bytes."
1561,1,truncate,"If a FILE is shorter, it is extended and the sparse
       extended part (hole) reads as zero bytes. Mandatory arguments to long options are mandatory for short
       options too. -c
,
--no-create
do not create any files
-o
,
--io-blocks
treat SIZE as number of IO blocks instead of bytes
-r
,
--reference
=
RFILE
base size on RFILE
-s
,
--size
=
SIZE
set or adjust the file size by SIZE bytes
--help
display this help and exit
--version
output version information and exit

       The SIZE argument is an integer and optional unit (example: 10K is
       10*1024)."
1561,2,truncate,"-c
,
--no-create
do not create any files
-o
,
--io-blocks
treat SIZE as number of IO blocks instead of bytes
-r
,
--reference
=
RFILE
base size on RFILE
-s
,
--size
=
SIZE
set or adjust the file size by SIZE bytes
--help
display this help and exit
--version
output version information and exit

       The SIZE argument is an integer and optional unit (example: 10K is
       10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,... (powers of 1000)."
1561,3,truncate,"(powers of 1000). Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on. SIZE may also be prefixed by one of the following modifying
       characters: '+' extend by, '-' reduce by, '<' at most, '>' at
       least, '/' round down to multiple of, '%' round up to multiple of."
1562,0,true,"Exit with a status code indicating success.
--help
display this help and exit
--version
output version information and exit

       Your shell may have its own version of true, which usually
       supersedes the version described here.  Please refer to your
       shell's documentation for details about the options it supports."
1563,0,troff,nan
1564,0,tset,"tset - initialization
This program initializes terminals. First,
@TSET@
retrieves the current terminal mode settings for
       your terminal. It does this by successively testing

       â¢   the standard error,

       â¢   standard output,

       â¢   standard input and

       â¢   ultimately â/dev/ttyâ

       to obtain terminal settings."
1564,1,tset,"It does this by successively testing

       â¢   the standard error,

       â¢   standard output,

       â¢   standard input and

       â¢   ultimately â/dev/ttyâ

       to obtain terminal settings. Having retrieved these settings,
@TSET@
remembers which file descriptor to use when updating
       settings. Next,
@TSET@
determines the type of terminal that you are using."
1564,2,tset,"Next,
@TSET@
determines the type of terminal that you are using. This determination is done as follows, using the first terminal
       type found. 1."
1564,3,tset,"1. The
terminal
argument specified on the command line. 2."
1564,4,tset,"2. The value of the
TERM
environmental variable. 3."
1564,5,tset,"3. (BSD systems only.) The terminal type associated with the
       standard error output device in the
/etc/ttys
file. (On System-V-
       like UNIXes and systems using that convention,
getty
(1) does this
       job by setting
TERM
according to the type passed to it by
/etc/inittab
.)

       4."
1564,6,tset,"(On System-V-
       like UNIXes and systems using that convention,
getty
(1) does this
       job by setting
TERM
according to the type passed to it by
/etc/inittab
.)

       4. The default terminal type, âunknownâ. If the terminal type was not specified on the command-line, the
-m
option mappings are then applied (see the section
TERMINAL TYPE
MAPPING
for more information)."
1564,7,tset,"If the terminal type was not specified on the command-line, the
-m
option mappings are then applied (see the section
TERMINAL TYPE
MAPPING
for more information). Then, if the terminal type begins
       with a question mark (â?â), the user is prompted for confirmation
       of the terminal type. An empty response confirms the type, or,
       another type can be entered to specify a new type."
1564,8,tset,"An empty response confirms the type, or,
       another type can be entered to specify a new type. Once the
       terminal type has been determined, the terminal description for
       the terminal is retrieved. If no terminal description is found
       for the type, the user is prompted for another terminal type."
1564,9,tset,"If no terminal description is found
       for the type, the user is prompted for another terminal type. Once the terminal description is retrieved,

       â¢   if the â
-w
â option is enabled,
@TSET@
may update the
           terminal's window size. If the window size cannot be obtained from the operating
           system, but the terminal description (or environment, e.g.,
LINES
and
COLUMNS
variables specify this), use this to set the
           operating system's notion of the window size."
1564,10,tset,"If the window size cannot be obtained from the operating
           system, but the terminal description (or environment, e.g.,
LINES
and
COLUMNS
variables specify this), use this to set the
           operating system's notion of the window size. â¢   if the â
-c
â option is enabled, the backspace, interrupt and
           line kill characters (among many other things) are set

       â¢   unless the â
-I
â option is enabled, the terminal and tab
initialization
strings are sent to the standard error output,
           and
@TSET@
waits one second (in case a hardware reset was
           issued). â¢   Finally, if the erase, interrupt and line kill characters have
           changed, or are not set to their default values, their values
           are displayed to the standard error output."
1564,11,tset,"â¢   Finally, if the erase, interrupt and line kill characters have
           changed, or are not set to their default values, their values
           are displayed to the standard error output. reset - reinitialization
When invoked as
@RESET@
,
@TSET@
sets the terminal modes to âsaneâ
       values:

       â¢   sets cooked and echo modes,

       â¢   turns off cbreak and raw modes,

       â¢   turns on newline translation and

       â¢   resets any unset special characters to their default values

       before doing the terminal initialization described above. Also,
       rather than using the terminal
initialization
strings, it uses the
       terminal
reset
strings."
1564,12,tset,"Also,
       rather than using the terminal
initialization
strings, it uses the
       terminal
reset
strings. The
@RESET@
command is useful after a program dies leaving a
       terminal in an abnormal state:

       â¢   you may have to type
<LF>
@RESET@
<LF>
(the line-feed character is normally control-J) to get the
           terminal to work, as carriage-return may no longer work in the
           abnormal state. â¢   Also, the terminal will often not echo the command."
1565,0,tset,"tset - initialization
This program initializes terminals. First,
@TSET@
retrieves the current terminal mode settings for
       your terminal. It does this by successively testing

       â¢   the standard error,

       â¢   standard output,

       â¢   standard input and

       â¢   ultimately â/dev/ttyâ

       to obtain terminal settings."
1565,1,tset,"It does this by successively testing

       â¢   the standard error,

       â¢   standard output,

       â¢   standard input and

       â¢   ultimately â/dev/ttyâ

       to obtain terminal settings. Having retrieved these settings,
@TSET@
remembers which file descriptor to use when updating
       settings. Next,
@TSET@
determines the type of terminal that you are using."
1565,2,tset,"Next,
@TSET@
determines the type of terminal that you are using. This determination is done as follows, using the first terminal
       type found. 1."
1565,3,tset,"1. The
terminal
argument specified on the command line. 2."
1565,4,tset,"2. The value of the
TERM
environmental variable. 3."
1565,5,tset,"3. (BSD systems only.) The terminal type associated with the
       standard error output device in the
/etc/ttys
file. (On System-V-
       like UNIXes and systems using that convention,
getty
(1) does this
       job by setting
TERM
according to the type passed to it by
/etc/inittab
.)

       4."
1565,6,tset,"(On System-V-
       like UNIXes and systems using that convention,
getty
(1) does this
       job by setting
TERM
according to the type passed to it by
/etc/inittab
.)

       4. The default terminal type, âunknownâ. If the terminal type was not specified on the command-line, the
-m
option mappings are then applied (see the section
TERMINAL TYPE
MAPPING
for more information)."
1565,7,tset,"If the terminal type was not specified on the command-line, the
-m
option mappings are then applied (see the section
TERMINAL TYPE
MAPPING
for more information). Then, if the terminal type begins
       with a question mark (â?â), the user is prompted for confirmation
       of the terminal type. An empty response confirms the type, or,
       another type can be entered to specify a new type."
1565,8,tset,"An empty response confirms the type, or,
       another type can be entered to specify a new type. Once the
       terminal type has been determined, the terminal description for
       the terminal is retrieved. If no terminal description is found
       for the type, the user is prompted for another terminal type."
1565,9,tset,"If no terminal description is found
       for the type, the user is prompted for another terminal type. Once the terminal description is retrieved,

       â¢   if the â
-w
â option is enabled,
@TSET@
may update the
           terminal's window size. If the window size cannot be obtained from the operating
           system, but the terminal description (or environment, e.g.,
LINES
and
COLUMNS
variables specify this), use this to set the
           operating system's notion of the window size."
1565,10,tset,"If the window size cannot be obtained from the operating
           system, but the terminal description (or environment, e.g.,
LINES
and
COLUMNS
variables specify this), use this to set the
           operating system's notion of the window size. â¢   if the â
-c
â option is enabled, the backspace, interrupt and
           line kill characters (among many other things) are set

       â¢   unless the â
-I
â option is enabled, the terminal and tab
initialization
strings are sent to the standard error output,
           and
@TSET@
waits one second (in case a hardware reset was
           issued). â¢   Finally, if the erase, interrupt and line kill characters have
           changed, or are not set to their default values, their values
           are displayed to the standard error output."
1565,11,tset,"â¢   Finally, if the erase, interrupt and line kill characters have
           changed, or are not set to their default values, their values
           are displayed to the standard error output. reset - reinitialization
When invoked as
@RESET@
,
@TSET@
sets the terminal modes to âsaneâ
       values:

       â¢   sets cooked and echo modes,

       â¢   turns off cbreak and raw modes,

       â¢   turns on newline translation and

       â¢   resets any unset special characters to their default values

       before doing the terminal initialization described above. Also,
       rather than using the terminal
initialization
strings, it uses the
       terminal
reset
strings."
1565,12,tset,"Also,
       rather than using the terminal
initialization
strings, it uses the
       terminal
reset
strings. The
@RESET@
command is useful after a program dies leaving a
       terminal in an abnormal state:

       â¢   you may have to type
<LF>
@RESET@
<LF>
(the line-feed character is normally control-J) to get the
           terminal to work, as carriage-return may no longer work in the
           abnormal state. â¢   Also, the terminal will often not echo the command."
1566,0,tsort,"Write totally ordered list consistent with the partial ordering in
       FILE.

       With no FILE, or when FILE is -, read standard input.
--help
display this help and exit
--version
output version information and exit"
1567,0,tsort,"The
tsort
utility shall write to standard output a totally ordered
       list of items consistent with a partial ordering of items
       contained in the input. The application shall ensure that the input consists of pairs of
       items (non-empty strings) separated by <blank> characters. Pairs
       of different items indicate ordering."
1567,1,tsort,"The application shall ensure that the input consists of pairs of
       items (non-empty strings) separated by <blank> characters. Pairs
       of different items indicate ordering. Pairs of identical items
       indicate presence, but not ordering."
1568,0,tty,"Print the file name of the terminal connected to standard input.
-s
,
--silent
,
--quiet
print nothing, only return an exit status
--help
display this help and exit
--version
output version information and exit"
1569,0,type,"The
type
utility shall indicate how each argument would be
       interpreted if used as a command name."
1570,0,ucmatose,"Establishes a set of reliable RDMA connections between two nodes
       using the librdmacm, optionally transfers data between the nodes,
       then disconnects."
1571,0,tty,"The
tty
utility shall write to the standard output the name of the
       terminal that is open as standard input. The name that is used
       shall be equivalent to the string that would be returned by the
ttyname
() function defined in the System Interfaces volume of
       POSIX.1â2017."
1572,0,uclampset,"uclampset
sets or retrieves the utilization clamping attributes of
       an existing
PID
, or runs
command
with the given attributes. Utilization clamping is a new feature added in v5.3. It gives a
       hint to the scheduler about the allowed range of utilization the
       task should be operating at."
1572,1,uclampset,"It gives a
       hint to the scheduler about the allowed range of utilization the
       task should be operating at. The utilization of the task affects frequency selection and task
       placement. Only schedutil cpufreq governor understands handling
       util clamp hints at the time of writing."
1572,2,uclampset,"Only schedutil cpufreq governor understands handling
       util clamp hints at the time of writing. Consult your kernel docs
       for further info about other cpufreq governors support. If youâre running on asymmetric heterogeneous system like Armâs
       big.LITTLE."
1572,3,uclampset,"If youâre running on asymmetric heterogeneous system like Armâs
       big.LITTLE. Utilization clamping can help bias task placement. If
       the task is boosted such that
util_min
value is higher than the
       little cores' capacity, then the scheduler will do its best to
       place it on a big core."
1572,4,uclampset,"If
       the task is boosted such that
util_min
value is higher than the
       little cores' capacity, then the scheduler will do its best to
       place it on a big core. Similarly, if
util_max
is smaller than or equal the capacity of
       the little cores, then the scheduler can still choose to place it
       there even if the actual utilization of the task is at max. Setting a taskâs
uclamp_min
to a none zero value will effectively
       boost the task as when it runs itâll always start from this
       utilization value."
1572,5,uclampset,"Setting a taskâs
uclamp_min
to a none zero value will effectively
       boost the task as when it runs itâll always start from this
       utilization value. By setting a taskâs
uclamp_max
below 1024, this will effectively
       cap the task as when it runs itâll never be able to go above this
       utilization value. The full utilization range is: [0:1024]."
1572,6,uclampset,"The full utilization range is: [0:1024]. The special value -1 is
       used to reset to systemâs default. Consult latest kernel documentation for more details:
https://kernel.org/doc/html/latest/scheduler/sched-util-clamp.html"
1573,0,pmdatxmon,"pmdatxmon
is an example Performance Metrics Domain Agent (PMDA)
       which exports a small number of performance metrics from a
       simulated transaction monitor. The txmon PMDA is shipped as both binary and source code and is
       designed to be an aid for PMDA developers; the txmon PMDA
       demonstrates how performance data can be exported from an
       application (in this case
txrecord
) to the PCP infrastructure via
       a shared memory segment. As a matter of convenience,
pmdatxmon
creates (and destroys on exit) the shared memory segment."
1573,1,pmdatxmon,"As a matter of convenience,
pmdatxmon
creates (and destroys on exit) the shared memory segment. The
tx_type
arguments are arbitrary unique tags used to identify
       different transaction types. The
txrecord
application simulates the processing of one or more
       transactions identified by
tx_type
and with an observed service
       time of
servtime ."
1573,2,pmdatxmon,"The
txrecord
application simulates the processing of one or more
       transactions identified by
tx_type
and with an observed service
       time of
servtime . With the
-l
option,
txrecord
displays the current summary of the
       transaction activity from the shared memory segment. genload
is a shell and
awk
(1) script that acts as a front-end to
txrecord
to generate a constant load of simulated transaction
       activity."
1573,3,pmdatxmon,"genload
is a shell and
awk
(1) script that acts as a front-end to
txrecord
to generate a constant load of simulated transaction
       activity. A brief description of the
pmdatxmon
command line options follows:
-d
It is absolutely crucial that the performance metrics
domain
number specified here is unique and consistent. That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts."
1573,4,pmdatxmon,"That is,
domain
should be different for every PMDA on the one host,
            and the same
domain
number should be used for the same PMDA
            on all hosts. -l
Location of the log file. By default, a log file named
txmon.log
is written in the current directory of
pmcd(1)
when
pmdatxmon
is started, i.e."
1573,5,pmdatxmon,"By default, a log file named
txmon.log
is written in the current directory of
pmcd(1)
when
pmdatxmon
is started, i.e. $PCP_LOG_DIR/pmcd
. If the log
            file cannot be created or is not writable, output is written
            to the standard error instead."
1573,6,pmdatxmon,"If the log
            file cannot be created or is not writable, output is written
            to the standard error instead. -U
User account under which to run the agent. The default is
            the unprivileged ""pcp"" account in current versions of PCP,
            but in older versions the superuser account (""root"") was used
            by default."
1574,0,uconv,"uconv
converts, or transcodes, each given
file
(or its standard
       input if no
file
is specified) from one
encoding
to another. The
       transcoding is done using Unicode as a pivot encoding (i.e. the
       data are first transcoded from their original encoding to Unicode,
       and then from Unicode to the destination encoding)."
1574,1,uconv,"the
       data are first transcoded from their original encoding to Unicode,
       and then from Unicode to the destination encoding). If an
encoding
is not specified or is
-
, the default encoding is
       used. Thus, calling
uconv
with no
encoding
provides an easy way to
       validate and sanitize data files for further consumption by tools
       requiring data in the default encoding."
1574,2,uconv,"Thus, calling
uconv
with no
encoding
provides an easy way to
       validate and sanitize data files for further consumption by tools
       requiring data in the default encoding. When calling
uconv
, it is possible to specify callbacks that are
       used to handle invalid characters in the input, or characters that
       cannot be transcoded to the destination encoding. Some encodings,
       for example, offer a default substitution character that can be
       used to represent the occurrence of such characters in the input."
1574,3,uconv,"Some encodings,
       for example, offer a default substitution character that can be
       used to represent the occurrence of such characters in the input. Other callbacks offer a useful visual representation of the
       invalid data. uconv
can also run the specified
transliteration
on the transcoded
       data, in which case transliteration will happen as an intermediate
       step, after the data have been transcoded to Unicode."
1574,4,uconv,"uconv
can also run the specified
transliteration
on the transcoded
       data, in which case transliteration will happen as an intermediate
       step, after the data have been transcoded to Unicode. The
transliteration
can be either a list of semicolon-separated
       transliterator names, or an arbitrarily complex set of rules in
       the ICU transliteration rules format. For transcoding purposes,
uconv
options are compatible with those
       of
iconv(1)
, making it easy to replace it in scripts."
1574,5,uconv,"For transcoding purposes,
uconv
options are compatible with those
       of
iconv(1)
, making it easy to replace it in scripts. It is not
       necessarily the case, however, that the encoding names used by
uconv
and ICU are the same as the ones used by
iconv(1)
. Also,
       options that provide informational data, such as the
-l
,
--list
one offered by some
iconv(1)
variants such as GNU's, produce data
       in a slightly different and easier to parse format."
1575,0,udpong,"Uses unreliable datagram streaming over RDMA protocol (rsocket) to
       connect and exchange data between a client and server application."
1576,0,udfinfo,"udfinfo
shows various information about a UDF filesystem stored
       either on the block device or in the disk file image. The output
       from the
udfinfo
is suitable for parsing by external applications
       or scripts."
1577,0,udaddy,"Establishes a set of unreliable RDMA datagram communication paths
       between two nodes using the librdmacm, optionally transfers
       datagrams between the nodes, then tears down the communication."
1578,0,ukify,"ukify
is a tool whose primary purpose is to combine components
       (usually a kernel, an initrd, and a UEFI boot stub) to create a
Unified Kernel Image (UKI)
[1] â a PE binary that can be executed
       by the firmware to start the embedded linux kernel. See
systemd-stub(7)
for details about the stub."
1579,0,ul,"ul
reads the named files (or standard input if none are given) and
       translates occurrences of underscores to the sequence which
       indicates underlining for the terminal in use, as specified by the
       environment variable
TERM
. The
terminfo
database is read to
       determine the appropriate sequences for underlining. If the
       terminal is incapable of underlining but is capable of a standout
       mode, then that is used instead."
1579,1,ul,"If the
       terminal is incapable of underlining but is capable of a standout
       mode, then that is used instead. If the terminal can overstrike,
       or handles underlining automatically,
ul
degenerates to
cat(1)
. If
       the terminal cannot underline, underlining is ignored."
1580,0,uname,"Print certain system information.  With no OPTION, same as
-s
.
-a
,
--all
print all information, in the following order, except omit
-p
and
-i
if unknown:
-s
,
--kernel-name
print the kernel name
-n
,
--nodename
print the network node hostname
-r
,
--kernel-release
print the kernel release
-v
,
--kernel-version
print the kernel version
-m
,
--machine
print the machine hardware name
-p
,
--processor
print the processor type (non-portable)
-i
,
--hardware-platform
print the hardware platform (non-portable)
-o
,
--operating-system
print the operating system
--help
display this help and exit
--version
output version information and exit"
1581,0,umask,"The
umask
utility shall set the file mode creation mask of the
       current shell execution environment (see
Section 2.12
,
Shell
Execution Environment
) to the value specified by the
mask
operand. This mask shall affect the initial value of the file permission
       bits of subsequently created files. If
umask
is called in a
       subshell or separate utility execution environment, such as one of
       the following:

           (umask 002)
           nohup umask ..."
1581,1,umask,"If
umask
is called in a
       subshell or separate utility execution environment, such as one of
       the following:

           (umask 002)
           nohup umask ... find . -exec umask ..."
1581,2,umask,"-exec umask ... \;

       it shall not affect the file mode creation mask of the caller's
       environment. If the
mask
operand is not specified, the
umask
utility shall
       write to standard output the value of the file mode creation mask
       of the invoking process."
1582,0,ulimit,"The
ulimit
utility shall set or report the file-size writing limit
       imposed on files written by the shell and its child processes
       (files of any size may be read). Only a process with appropriate
       privileges can increase the limit."
1583,0,unalias,"The
unalias
utility shall remove the definition for each alias
       name specified. See
Section 2.3.1
,
Alias Substitution
.  The
       aliases shall be removed from the current shell execution
       environment; see
Section 2.12
,
Shell Execution Environment
."
1584,0,uname,"By default, the
uname
utility shall write the operating system
       name to standard output. When options are specified, symbols
       representing one or more system characteristics shall be written
       to the standard output. The format and contents of the symbols are
       implementation-defined."
1584,1,uname,"When options are specified, symbols
       representing one or more system characteristics shall be written
       to the standard output. The format and contents of the symbols are
       implementation-defined. On systems conforming to the System
       Interfaces volume of POSIX.1â2017, the symbols written shall be
       those supported by the
uname
() function as defined in the System
       Interfaces volume of POSIX.1â2017."
1585,0,unexpand,"Convert blanks in each FILE to tabs, writing to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short
       options too."
1585,1,unexpand,"Mandatory arguments to long options are mandatory for short
       options too. -a
,
--all
convert all blanks, instead of just initial blanks
--first-only
convert only leading sequences of blanks (overrides
-a
)
-t
,
--tabs
=
N
have tabs N characters apart instead of 8 (enables
-a
)
-t
,
--tabs
=
LIST
use comma separated list of tab positions. The last
              specified position can be prefixed with '/' to specify a
              tab size to use after the last explicitly specified tab
              stop."
1585,2,unexpand,"-a
,
--all
convert all blanks, instead of just initial blanks
--first-only
convert only leading sequences of blanks (overrides
-a
)
-t
,
--tabs
=
N
have tabs N characters apart instead of 8 (enables
-a
)
-t
,
--tabs
=
LIST
use comma separated list of tab positions. The last
              specified position can be prefixed with '/' to specify a
              tab size to use after the last explicitly specified tab
              stop. Also a prefix of '+' can be used to align remaining
              tab stops relative to the last specified tab stop instead
              of the first column
--help
display this help and exit
--version
output version information and exit"
1586,0,uncompress,"The
uncompress
utility shall restore files to their original state
       after they have been compressed using the
compress
utility. If no
       files are specified, the standard input shall be uncompressed to
       the standard output. If the invoking process has appropriate
       privileges, the ownership, modes, access time, and modification
       time of the original file shall be preserved."
1586,1,uncompress,"If the invoking process has appropriate
       privileges, the ownership, modes, access time, and modification
       time of the original file shall be preserved. This utility shall support the uncompressing of any files produced
       by the
compress
utility on the same implementation. For files
       produced by
compress
on other systems,
uncompress
supports 9 to
       14-bit compression (see
compress(1p)
,
-b
); it is implementation-
       defined whether values of
-b
greater than 14 are supported."
1587,0,unget,"The
unget
utility shall reverse the effect of a
get
-e
done prior
       to creating the intended new delta."
1588,0,unicode_start,"The
unicode_start
command will put the keyboard and console into
       Unicode (UTF-8) mode. For the keyboard this means that one can attach 16-bit U+xxxx
       values to keyboard keys using
loadkeys(1)
, and have these appear
       as UTF-8 input to user programs. Also, that one can type
       hexadecimal Alt-xxxx using the numeric keypad, and again produce
       UTF-8."
1588,1,unicode_start,"Also, that one can type
       hexadecimal Alt-xxxx using the numeric keypad, and again produce
       UTF-8. For the console this means that the kernel expects UTF-8 output
       from user programs, and displays the output accordingly. The parameter
font
is a font that is loaded."
1588,2,unicode_start,"The parameter
font
is a font that is loaded. It should have a
       built-in Unicode map, or, if it hasn't, such a map can be given
       explicitly as second parameter. When no font was specified, the
       current font is kept."
1589,0,unexpand,"The
unexpand
utility shall copy files or standard input to
       standard output, converting <blank> characters at the beginning of
       each line into the maximum number of <tab> characters followed by
       the minimum number of <space> characters needed to fill the same
       column positions originally filled by the translated <blank>
       characters. By default, tabstops shall be set at every eighth
       column position. Each <backspace> shall be copied to the output,
       and shall cause the column position count for tab calculations to
       be decremented; the count shall never be decremented to a value
       less than one."
1590,0,unicode_stop,"The
unicode_stop
command will more-or-less undo the effect of
unicode_start
.  It puts the keyboard in ASCII (XLATE) mode, and
       clears the console UTF-8 mode."
1591,0,unlink,"Call the unlink function to remove the specified FILE.
--help
display this help and exit
--version
output version information and exit"
1592,0,uniq,"Filter adjacent matching lines from INPUT (or standard input),
       writing to OUTPUT (or standard output). With no options, matching lines are merged to the first
       occurrence. Mandatory arguments to long options are mandatory for short
       options too."
1592,1,uniq,"Mandatory arguments to long options are mandatory for short
       options too. -c
,
--count
prefix lines by the number of occurrences
-d
,
--repeated
only print duplicate lines, one for each group
-D
print all duplicate lines
--all-repeated
[=
METHOD
]
              like
-D
, but allow separating groups with an empty line;
              METHOD={none(default),prepend,separate}
-f
,
--skip-fields
=
N
avoid comparing the first N fields
--group
[=
METHOD
]
              show all items, separating groups with an empty line;
              METHOD={separate(default),prepend,append,both}
-i
,
--ignore-case
ignore differences in case when comparing
-s
,
--skip-chars
=
N
avoid comparing the first N characters
-u
,
--unique
only print unique lines
-z
,
--zero-terminated
line delimiter is NUL, not newline
-w
,
--check-chars
=
N
compare no more than N characters in lines
--help
display this help and exit
--version
output version information and exit

       A field is a run of blanks (usually spaces and/or TABs), then
       non-blank characters. Fields are skipped before chars."
1592,2,uniq,"Fields are skipped before chars. 'uniq' does not detect repeated lines unless they are adjacent. You may want to sort the input first, or use 'sort
-u
' without
       'uniq'."
1593,0,uniq,"The
uniq
utility shall read an input file comparing adjacent
       lines, and write one copy of each input line on the output. The
       second and succeeding copies of repeated adjacent input lines
       shall not be written. The trailing <newline> of each line in the
       input shall be ignored when doing comparisons."
1593,1,uniq,"The
       second and succeeding copies of repeated adjacent input lines
       shall not be written. The trailing <newline> of each line in the
       input shall be ignored when doing comparisons. Repeated lines in the input shall not be detected if they are not
       adjacent."
1594,0,unlink,"The
unlink
utility shall perform the function call:

           unlink(
file
);

       A user may need appropriate privileges to invoke the
unlink
utility."
1595,0,unset,"Each variable or function specified by
name
shall be unset. If
-v
is specified,
name
refers to a variable name and the shell
       shall unset it and remove it from the environment. Read-only
       variables cannot be unset."
1595,1,unset,"Read-only
       variables cannot be unset. If
-f
is specified,
name
refers to a function and the shell shall
       unset the function definition. If neither
-f
nor
-v
is specified,
name
refers to a variable; if a
       variable by that name does not exist, it is unspecified whether a
       function by that name, if any, shall be unset."
1595,2,unset,"If neither
-f
nor
-v
is specified,
name
refers to a variable; if a
       variable by that name does not exist, it is unspecified whether a
       function by that name, if any, shall be unset. Unsetting a variable or function that was not previously set shall
       not be considered an error and does not cause the shell to abort. The
unset
special built-in shall support the Base Definitions
       volume of POSIX.1â2017,
Section 12.2
,
Utility Syntax Guidelines
."
1595,3,unset,"The
unset
special built-in shall support the Base Definitions
       volume of POSIX.1â2017,
Section 12.2
,
Utility Syntax Guidelines
. Note that:

           VARIABLE=

       is not equivalent to an
unset
of
VARIABLE
; in the example,
VARIABLE
is set to
""""
. Also, the variables that can be
unset
should not be misinterpreted to include the special parameters
       (see
Section 2.5.2
,
Special Parameters
)."
1596,0,updatectl,"updatectl
may be used to check for and install system updates
       managed by
systemd-sysupdated.service(8)
."
1597,0,unsetfiles,"This program removes the SELinux file security contexts of files.
       It can help cleaning extended file attributes after disabling
       SELinux.
unsetfiles
will only work on SELinux disabled systems, since
       removing file security contexts is not supported by SELinux."
1598,0,unshare,"The
unshare
command creates new namespaces (as specified by the
       command-line options described below) and then executes the
       specified
program
. If
program
is not given, then ""${SHELL}"" is run
       (default:
/bin/sh
). By default, a new namespace persists only as long as it has member
       processes."
1598,1,unshare,"By default, a new namespace persists only as long as it has member
       processes. A new namespace can be made persistent even when it has
       no member processes by bind mounting /proc/
pid
/ns/
type
files to a
       filesystem path. A namespace that has been made persistent in this
       way can subsequently be entered with
nsenter(1)
even after the
program
terminates (except PID namespaces where a permanently
       running init process is required)."
1598,2,unshare,"A namespace that has been made persistent in this
       way can subsequently be entered with
nsenter(1)
even after the
program
terminates (except PID namespaces where a permanently
       running init process is required). Once a persistent namespace is
       no longer needed, it can be unpersisted by using
umount(8)
to
       remove the bind mount. See the
EXAMPLES
section for more details."
1598,3,unshare,"See the
EXAMPLES
section for more details. unshare
since util-linux version 2.36 uses
/proc/[pid]/ns/pid_for_children
and
/proc/[pid]/ns/time_for_children
files for persistent PID and TIME
       namespaces. This change requires Linux kernel 4.17 or newer."
1598,4,unshare,"This change requires Linux kernel 4.17 or newer. The following types of namespaces can be created with
unshare
:
mount namespace
Mounting and unmounting filesystems will not affect the rest
           of the system, except for filesystems which are explicitly
           marked as shared (with
mount --make-shared
; see
/proc/self/mountinfo
or
findmnt -o+PROPAGATION
for the
shared
flags). For further details, see
mount_namespaces(7)
."
1598,5,unshare,"For further details, see
mount_namespaces(7)
. unshare
since util-linux version 2.27 automatically sets
           propagation to
private
in a new mount namespace to make sure
           that the new namespace is really unshared. Itâs possible to
           disable this feature with option
--propagation unchanged
."
1598,6,unshare,"Itâs possible to
           disable this feature with option
--propagation unchanged
. Note
           that
private
is the kernel default. UTS namespace
Setting hostname or domainname will not affect the rest of the
           system."
1598,7,unshare,"UTS namespace
Setting hostname or domainname will not affect the rest of the
           system. For further details, see
uts_namespaces(7)
. IPC namespace
The process will have an independent namespace for POSIX
           message queues as well as System V message queues, semaphore
           sets and shared memory segments."
1598,8,unshare,"IPC namespace
The process will have an independent namespace for POSIX
           message queues as well as System V message queues, semaphore
           sets and shared memory segments. For further details, see
ipc_namespaces(7)
. network namespace
The process will have independent IPv4 and IPv6 stacks, IP
           routing tables, firewall rules, the
/proc/net
and
/sys/class/net
directory trees, sockets, etc."
1598,9,unshare,"network namespace
The process will have independent IPv4 and IPv6 stacks, IP
           routing tables, firewall rules, the
/proc/net
and
/sys/class/net
directory trees, sockets, etc. For further
           details, see
network_namespaces(7)
. PID namespace
Children will have a distinct set of PID-to-process mappings
           from their parent."
1598,10,unshare,"PID namespace
Children will have a distinct set of PID-to-process mappings
           from their parent. For further details, see
pid_namespaces(7)
. cgroup namespace
The process will have a virtualized view of
/proc/self/cgroup
,
           and new cgroup mounts will be rooted at the namespace cgroup
           root."
1598,11,unshare,"cgroup namespace
The process will have a virtualized view of
/proc/self/cgroup
,
           and new cgroup mounts will be rooted at the namespace cgroup
           root. For further details, see
cgroup_namespaces(7)
. user namespace
The process will have a distinct set of UIDs, GIDs and
           capabilities."
1598,12,unshare,"user namespace
The process will have a distinct set of UIDs, GIDs and
           capabilities. For further details, see
user_namespaces(7)
. time namespace
The process can have a distinct view of
CLOCK_MONOTONIC
and/or
CLOCK_BOOTTIME
which can be changed using
/proc/self/timens_offsets
."
1598,13,unshare,"For further details, see
user_namespaces(7)
. time namespace
The process can have a distinct view of
CLOCK_MONOTONIC
and/or
CLOCK_BOOTTIME
which can be changed using
/proc/self/timens_offsets
. For further details, see
time_namespaces(7)
."
1599,0,update-alternatives,"update-alternatives
creates, removes, maintains and displays
       information about the symbolic links comprising the alternatives
       system. It is possible for several programs fulfilling the same or similar
       functions to be installed on a single system at the same time. For example, many systems have several text editors installed at
       once."
1599,1,update-alternatives,"For example, many systems have several text editors installed at
       once. This gives choice to the users of a system, allowing each
       to use a different editor, if desired, but makes it difficult for
       a program to make a good choice for an editor to invoke if the
       user has not specified a particular preference. The alternatives system aims to solve this problem."
1599,2,update-alternatives,"The alternatives system aims to solve this problem. A generic
       name in the filesystem is shared by all files providing
       interchangeable functionality. The alternatives system and the
       system administrator together determine which actual file is
       referenced by this generic name."
1599,3,update-alternatives,"The alternatives system and the
       system administrator together determine which actual file is
       referenced by this generic name. For example, if the text editors
ed
(1) and
nvi
(1) are both installed on the system, the
       alternatives system will cause the generic name
/usr/bin/editor
to
       refer to
/usr/bin/nvi
by default. The system administrator can
       override this and cause it to refer to
/usr/bin/ed
instead, and
       the alternatives system will not alter this setting until
       explicitly requested to do so."
1599,4,update-alternatives,"The system administrator can
       override this and cause it to refer to
/usr/bin/ed
instead, and
       the alternatives system will not alter this setting until
       explicitly requested to do so. The generic name is not a direct symbolic link to the selected
       alternative. Instead, it is a symbolic link to a name in the
alternatives directory
, which in turn is a symbolic link to the
       actual file referenced."
1599,5,update-alternatives,"Instead, it is a symbolic link to a name in the
alternatives directory
, which in turn is a symbolic link to the
       actual file referenced. This is done so that the system
       administrator's changes can be confined within the
/usr/local/etc
directory: the FHS (q.v.) gives reasons why this is a Good Thing. When each package providing a file with a particular functionality
       is installed, changed or removed,
update-alternatives
is called to
       update information about that file in the alternatives system."
1599,6,update-alternatives,"When each package providing a file with a particular functionality
       is installed, changed or removed,
update-alternatives
is called to
       update information about that file in the alternatives system. update-alternatives
is usually called from the following Debian
       package maintainer scripts,
postinst
(configure) to install the
       alternative and from
prerm
and
postrm
(remove) to remove the
       alternative. Note
: In most (if not all) cases no other maintainer
       script actions should call
update-alternatives
, in particular
       neither of
upgrade
nor
disappear
, as any other such action can
       lose the manual state of an alternative, or make the alternative
       temporarily flip-flop, or completely switch when several of them
       have the same priority."
1599,7,update-alternatives,"Note
: In most (if not all) cases no other maintainer
       script actions should call
update-alternatives
, in particular
       neither of
upgrade
nor
disappear
, as any other such action can
       lose the manual state of an alternative, or make the alternative
       temporarily flip-flop, or completely switch when several of them
       have the same priority. It is often useful for a number of alternatives to be
       synchronized, so that they are changed as a group; for example,
       when several versions of the
vi
(1) editor are installed, the
       manual page referenced by
/usr/share/man/man1/vi.1
should
       correspond to the executable referenced by
/usr/bin/vi
. update-alternatives
handles this by means of
master
and
slave
links; when the master is changed, any associated slaves are
       changed too."
1599,8,update-alternatives,"update-alternatives
handles this by means of
master
and
slave
links; when the master is changed, any associated slaves are
       changed too. A master link and its associated slaves make up a
link group
. Each link group is, at any given time, in one of two modes:
       automatic or manual."
1599,9,update-alternatives,"Each link group is, at any given time, in one of two modes:
       automatic or manual. When a group is in automatic mode, the
       alternatives system will automatically decide, as packages are
       installed and removed, whether and how to update the links. In
       manual mode, the alternatives system will retain the choice of the
       administrator and avoid changing the links (except when something
       is broken)."
1599,10,update-alternatives,"In
       manual mode, the alternatives system will retain the choice of the
       administrator and avoid changing the links (except when something
       is broken). Link groups are in automatic mode when they are first introduced
       to the system. If the system administrator makes changes to the
       system's automatic settings, this will be noticed the next time
update-alternatives
is run on the changed link's group, and the
       group will automatically be switched to manual mode."
1599,11,update-alternatives,"If the system administrator makes changes to the
       system's automatic settings, this will be noticed the next time
update-alternatives
is run on the changed link's group, and the
       group will automatically be switched to manual mode. Each alternative has a
priority
associated with it. When a link
       group is in automatic mode, the alternatives pointed to by members
       of the group will be those which have the highest priority."
1599,12,update-alternatives,"When a link
       group is in automatic mode, the alternatives pointed to by members
       of the group will be those which have the highest priority. When using the
--config
option,
update-alternatives
will list all
       of the choices for the link group of which given
name
is the
       master alternative name. The current choice is marked with a â*â."
1599,13,update-alternatives,"The current choice is marked with a â*â. You will then be prompted for your choice regarding this link
       group. Depending on the choice made, the link group might no
       longer be in
auto
mode."
1599,14,update-alternatives,"Depending on the choice made, the link group might no
       longer be in
auto
mode. You will need to use the
--auto
option in
       order to return to the automatic mode (or you can rerun
--config
and select the entry marked as automatic). If you want to configure non-interactively you can use the
--set
option instead (see below)."
1599,15,update-alternatives,"If you want to configure non-interactively you can use the
--set
option instead (see below). Different packages providing the same file need to do so
cooperatively
. In other words, the usage of
update-alternatives
is
mandatory
for all involved packages in such case."
1599,16,update-alternatives,"Different packages providing the same file need to do so
cooperatively
. In other words, the usage of
update-alternatives
is
mandatory
for all involved packages in such case. It is not
       possible to override some file in a package that does not employ
       the
update-alternatives
mechanism."
1600,0,updatedb,"This manual page documents the GNU version of
updatedb
, which
       updates file name databases used by GNU
locate
. The file name
       databases contain lists of files that were in particular directory
       trees when the databases were last updated. The file name of the
       default database is determined when
locate
and
updatedb
are
       configured and installed."
1600,1,updatedb,"The file name of the
       default database is determined when
locate
and
updatedb
are
       configured and installed. The frequency with which the databases
       are updated and the directories for which they contain entries
       depend on how often
updatedb
is run, and with which arguments. In networked environments, it often makes sense to build a
       database at the root of each filesystem, containing the entries
       for that filesystem."
1600,2,updatedb,"In networked environments, it often makes sense to build a
       database at the root of each filesystem, containing the entries
       for that filesystem. updatedb
is then run for each filesystem on
       the fileserver where that filesystem is on a local disk, to
       prevent thrashing the network. Users can select which databases
locate
searches using an environment variable or command line
       option; see
locate(1)
."
1600,3,updatedb,"Users can select which databases
locate
searches using an environment variable or command line
       option; see
locate(1)
. Databases cannot be concatenated together. The
LOCATE02
database format was introduced in GNU findutils
       version 4.0 in order to allow machines with different byte
       orderings to share the databases."
1600,4,updatedb,"Databases cannot be concatenated together. The
LOCATE02
database format was introduced in GNU findutils
       version 4.0 in order to allow machines with different byte
       orderings to share the databases. GNU
locate
can read both the
       old and
LOCATE02
database formats, though support for the old
       pre-4.0 database format will be removed shortly."
1601,0,uptime,"uptime
gives a one line display of the following information. The
       current time, how long the system has been running, how many users
       are currently logged on, and the system load averages for the past
       1, 5, and 15 minutes. This is the same information contained in the header line
       displayed by
w(1)
."
1601,1,uptime,"This is the same information contained in the header line
       displayed by
w(1)
. System load averages is the average number of processes that are
       either in a runnable or uninterruptable state. A process in a
       runnable state is either using the CPU or waiting to use the CPU."
1601,2,uptime,"A process in a
       runnable state is either using the CPU or waiting to use the CPU. A process in uninterruptable state is waiting for some I/O access,
       eg waiting for disk. The averages are taken over the three time
       intervals."
1601,3,uptime,"A process in uninterruptable state is waiting for some I/O access,
       eg waiting for disk. The averages are taken over the three time
       intervals. Load averages are not normalized for the number of
       CPUs in a system, so a load average of 1 means a single CPU system
       is loaded all the time while on a 4 CPU system it means it was
       idle 75% of the time."
1602,0,usb-devices,"usb-devices
is a shell script that can be used to display details
       of USB buses in the system and the devices connected to them. The output of the script is similar to the
usb/devices
file
       available either under
/proc/bus
(if usbfs is mounted), or under
/sys/kernel/debug
(if debugfs is mounted there). The script is
       primarily intended to be used if the file is not available."
1602,1,usb-devices,"The script is
       primarily intended to be used if the file is not available. In contrast to the
usb/devices
file, this script only lists
active
interfaces (those marked with a ""*"" in the
usb/devices
file) and
       their endpoints. Be advised that there can be differences in the way information is
       sorted, as well as in the format of the output."
1603,0,usbreset,"usbreset
is a utility that performs resets on USB devices. It is
       particularly useful situations where a USB device is unresponsive
       or exhibits erratic behavior.  The USB
device
to be reset can be
       specified in one of three formats:
PPPP:VVVV
Reset by product and vendor IDs
BBB/DDD
Reset by bus and device number
Product
Reset by product name

       When run without any arguments,
usbreset
provides usage
       information and a list of connected USB devices, including their
       product and vendor IDs, bus and device numbers, and product names."
1604,0,userdbctl,"userdbctl
may be used to inspect user and groups (as well as group
       memberships) of the system. This client utility inquires
       user/group information provided by various system services, both
       operating on JSON user/group records (as defined by the
JSON User
Records
[1] and
JSON Group Records
[2] definitions), and classic
       UNIX NSS/glibc user and group records. This tool is primarily a
       client to the
User/Group Record Lookup API via Varlink
[3], and may
       also pick up drop-in JSON user and group records from
       /etc/userdb/, /run/userdb/, /run/host/userdb/, /usr/lib/userdb/."
1605,0,users,"Output who is currently logged in according to FILE. If FILE is
       not specified, use
/var/run/utmp
. /var/log/wtmp
as FILE is
       common."
1605,1,users,"If FILE is
       not specified, use
/var/run/utmp
. /var/log/wtmp
as FILE is
       common. --help
display this help and exit
--version
output version information and exit"
1606,0,utmpdump,"utmpdump
is a simple program to dump UTMP and WTMP files in raw
       format, so they can be examined.
utmpdump
reads from stdin unless
       a
filename
is passed."
1607,0,uucp,"The
uucp
utility shall copy files named by the
source-file
argument to the
destination-file
argument. The files named can be
       on local or remote systems. The
uucp
utility cannot guarantee support for all character
       encodings in all circumstances."
1607,1,uucp,"The
uucp
utility cannot guarantee support for all character
       encodings in all circumstances. For example, transmission data may
       be restricted to 7 bits by the underlying network, 8-bit data and
       filenames need not be portable to non-internationalized systems,
       and so on. Under these circumstances, it is recommended that only
       characters defined in the ISO/IEC 646:1991 standard International
       Reference Version (equivalent to ASCII) 7-bit range of characters
       be used, and that only characters defined in the portable filename
       character set be used for naming files."
1607,2,uucp,"Under these circumstances, it is recommended that only
       characters defined in the ISO/IEC 646:1991 standard International
       Reference Version (equivalent to ASCII) 7-bit range of characters
       be used, and that only characters defined in the portable filename
       character set be used for naming files. The protocol for transfer
       of files is unspecified by POSIX.1â2008. Typical implementations of this utility require a communications
       line configured to use the Base Definitions volume of
       POSIX.1â2017,
Chapter 11
,
General Terminal Interface
, but other
       communications means may be used."
1607,3,uucp,"The protocol for transfer
       of files is unspecified by POSIX.1â2008. Typical implementations of this utility require a communications
       line configured to use the Base Definitions volume of
       POSIX.1â2017,
Chapter 11
,
General Terminal Interface
, but other
       communications means may be used. On systems where there are no
       available communications means (either temporarily or
       permanently), this utility shall write an error message describing
       the problem and exit with a non-zero exit status."
1608,0,uuidgen,"The
uuidgen
program creates (and prints) a new universally unique
       identifier (UUID) using the
libuuid
(3) library. The new UUID can
       reasonably be considered unique among all UUIDs created on the
       local system, and among UUIDs created on other systems in the past
       and in the future. There are three types of UUIDs which
uuidgen
can generate:
       time-based UUIDs, random-based UUIDs, and hash-based UUIDs."
1608,1,uuidgen,"There are three types of UUIDs which
uuidgen
can generate:
       time-based UUIDs, random-based UUIDs, and hash-based UUIDs. By
       default
uuidgen
will generate a random-based UUID if a
       high-quality random number generator is present. Otherwise, it
       will choose a time-based UUID."
1608,2,uuidgen,"Otherwise, it
       will choose a time-based UUID. It is possible to force the
       generation of one of these first two UUID types by using the
--random
or
--time
options. The third type of UUID is generated with the
--md5
or
--sha1
options, followed by
--namespace
namespace
and
--name
name
."
1608,3,uuidgen,"The third type of UUID is generated with the
--md5
or
--sha1
options, followed by
--namespace
namespace
and
--name
name
. The
namespace
may either be a well-known UUID, or else an alias to one
       of the well-known UUIDs defined in RFC 4122, that is
@dns
,
@url
,
@oid
, or
@x500
. The
name
is an arbitrary string value."
1608,4,uuidgen,"The
name
is an arbitrary string value. The
       generated UUID is the digest of the concatenation of the namespace
       UUID and the name value, hashed with the MD5 or SHA1 algorithms. It is, therefore, a predictable value which may be useful when
       UUIDs are being used as handles or nonces for more complex values
       or values which shouldnât be disclosed directly."
1608,5,uuidgen,"The
       generated UUID is the digest of the concatenation of the namespace
       UUID and the name value, hashed with the MD5 or SHA1 algorithms. It is, therefore, a predictable value which may be useful when
       UUIDs are being used as handles or nonces for more complex values
       or values which shouldnât be disclosed directly. See the RFC for
       more information."
1609,0,uudecode,"The
uudecode
utility shall read a file, or standard input if no
       file is specified, that includes data created by the
uuencode
utility. The
uudecode
utility shall scan the input file, searching
       for data compatible with one of the formats specified in
uuencode
,
       and attempt to create or overwrite the file described by the data
       (or overridden by the
-o
option). The pathname shall be contained
       in the data or specified by the
-o
option."
1609,1,uudecode,"The pathname shall be contained
       in the data or specified by the
-o
option. The file access
       permission bits and contents for the file to be produced shall be
       contained in that data. The mode bits of the created file (other
       than standard output) shall be set from the file access permission
       bits contained in the data; that is, other attributes of the mode,
       including the file mode creation mask (see
umask
), shall not
       affect the file being produced."
1609,2,uudecode,"The mode bits of the created file (other
       than standard output) shall be set from the file access permission
       bits contained in the data; that is, other attributes of the mode,
       including the file mode creation mask (see
umask
), shall not
       affect the file being produced. If either of the
op
characters
'+'
and
'-'
(see
chmod
) are specified in symbolic mode, the initial
       mode on which those operations are based is unspecified. If the pathname of the file resolves to an existing file and the
       user does not have write permission on that file,
uudecode
shall
       terminate with an error."
1609,3,uudecode,"If the pathname of the file resolves to an existing file and the
       user does not have write permission on that file,
uudecode
shall
       terminate with an error. If the pathname of the file resolves to
       an existing file and the user has write permission on that file,
       the existing file shall be overwritten and, if possible, the mode
       bits of the file (other than standard output) shall be set as
       described above; if the mode bits cannot be set,
uudecode
shall
       not treat this as an error. If the input data was produced by
uuencode
on a system with a
       different number of bits per byte than on the target system, the
       results of
uudecode
are unspecified."
1610,0,uustat,"The
uustat
utility shall display the status of, or cancel,
       previously specified
uucp
requests, or provide general status on
uucp
connections to other systems. When no options are given,
uustat
shall write to standard output
       the status of all
uucp
requests issued by the current user. Typical implementations of this utility require a communications
       line configured to use the Base Definitions volume of
       POSIX.1â2017,
Chapter 11
,
General Terminal Interface
, but other
       communications means may be used."
1610,1,uustat,"When no options are given,
uustat
shall write to standard output
       the status of all
uucp
requests issued by the current user. Typical implementations of this utility require a communications
       line configured to use the Base Definitions volume of
       POSIX.1â2017,
Chapter 11
,
General Terminal Interface
, but other
       communications means may be used. On systems where there are no
       available communications means (either temporarily or
       permanently), this utility shall write an error message describing
       the problem and exit with a non-zero exit status."
1611,0,uuidparse,"This command will parse unique identifier inputs from either
       command line arguments or standard input. The inputs are
       white-space separated."
1612,0,uux,"The
uux
utility shall gather zero or more files from various
       systems, execute a shell pipeline (see
Section 2.9
,
Shell
Commands
) on a specified system, and then send the standard output
       of the command to a file on a specified system. Only the first
       command of a pipeline can have a
system-name
! prefix."
1612,1,uux,"prefix. All other
       commands in the pipeline shall be executed on the system of the
       first command. The following restrictions are applicable to the shell pipeline
       processed by
uux
:

        *  In gathering files from different systems, pathname expansion
           shall not be performed by
uux
."
1612,2,uux,"The following restrictions are applicable to the shell pipeline
       processed by
uux
:

        *  In gathering files from different systems, pathname expansion
           shall not be performed by
uux
. Thus, a request such as:

               uux ""c99 remsys!~/*.c""

           would attempt to copy the file named literally
*.c
to the
           local system. *  The redirection operators
"">>""
,
""<<""
,
"">|""
, and
"">&""
shall not
           be accepted."
1612,3,uux,"*  The redirection operators
"">>""
,
""<<""
,
"">|""
, and
"">&""
shall not
           be accepted. Any use of these redirection operators shall
           cause this utility to write an error message describing the
           problem and exit with a non-zero exit status. *  The reserved word
!"
1612,4,uux,"*  The reserved word
! cannot be used at the head of the
           pipeline to modify the exit status. (See the
command-string
operand description below.)

        *  Alias substitution shall not be performed."
1612,5,uux,"(See the
command-string
operand description below.)

        *  Alias substitution shall not be performed. A filename can be specified as for
uucp
; it can be an absolute
       pathname, a pathname preceded by ~
name
(which is replaced by the
       corresponding login directory), a pathname specified as ~/
dest
(
dest
is prefixed by the public directory called
PUBDIR
; the
       actual location of
PUBDIR
is implementation-defined), or a simple
       filename (which is prefixed by
uux
with the current directory). See
uucp(1p)
for the details."
1612,6,uux,"See
uucp(1p)
for the details. The execution of commands on remote systems shall take place in an
       execution directory known to the
uucp
system. All files required
       for the execution shall be put into this directory unless they
       already reside on that machine."
1612,7,uux,"All files required
       for the execution shall be put into this directory unless they
       already reside on that machine. Therefore, the application shall
       ensure that non-local filenames (without path or machine
       reference) are unique within the
uux
request. The
uux
utility shall attempt to get all files to the execution
       system."
1612,8,uux,"The
uux
utility shall attempt to get all files to the execution
       system. For files that are output files, the application shall
       ensure that the filename is escaped using parentheses. The remote system shall notify the user by mail if the requested
       command on the remote system was disallowed or the files were not
       accessible."
1612,9,uux,"The remote system shall notify the user by mail if the requested
       command on the remote system was disallowed or the files were not
       accessible. This notification can be turned off by the
-n
option. Typical implementations of this utility require a communications
       line configured to use the Base Definitions volume of
       POSIX.1â2017,
Chapter 11
,
General Terminal Interface
, but other
       communications means may be used."
1612,10,uux,"Typical implementations of this utility require a communications
       line configured to use the Base Definitions volume of
       POSIX.1â2017,
Chapter 11
,
General Terminal Interface
, but other
       communications means may be used. On systems where there are no
       available communications means (either temporarily or
       permanently), this utility shall write an error message describing
       the problem and exit with a non-zero exit status. The
uux
utility cannot guarantee support for all character
       encodings in all circumstances."
1612,11,uux,"The
uux
utility cannot guarantee support for all character
       encodings in all circumstances. For example, transmission data may
       be restricted to 7 bits by the underlying network, 8-bit data and
       filenames need not be portable to non-internationalized systems,
       and so on. Under these circumstances, it is recommended that only
       characters defined in the ISO/IEC 646:1991 standard International
       Reference Version (equivalent to ASCII) 7-bit range of characters
       be used and that only characters defined in the portable filename
       character set be used for naming files."
1613,0,uuencode,"The
uuencode
utility shall write an encoded version of the named
       input file, or standard input if no
file
is specified, to standard
       output. The output shall be encoded using one of the algorithms
       described in the STDOUT section and shall include the file access
       permission bits (in
chmod
octal or symbolic notation) of the input
       file and the
decode_pathname
, for re-creation of the file on
       another system that conforms to this volume of POSIX.1â2017."
1614,0,val,"The
val
utility shall determine whether the specified
file
is an
       SCCS file meeting the characteristics specified by the options."
1615,0,valgrind-di-server,"valgrind-di-server
accepts (multiple) connections from
valgrind
processes that use the
--debuginfo-server
option on the specified port and serves
       (compressed) debuginfo files (in chunks) from the current working
       directory."
1616,0,valgrind-listener,"valgrind-listener
accepts (multiple) connections from
valgrind
processes that use the
--log-socket
option on the specified port
       and copies the commentary it is sent to stdout."
1617,0,vdir,"List information about the FILEs (the current directory by
       default). Sort entries alphabetically if none of
-cftuvSUX
nor
--sort
is specified. Mandatory arguments to long options are mandatory for short
       options too."
1617,1,vdir,"Mandatory arguments to long options are mandatory for short
       options too. -a
,
--all
do not ignore entries starting with . -A
,
--almost-all
do not list implied ."
1617,2,vdir,"-A
,
--almost-all
do not list implied . and .. --author
with
-l
, print the author of each file
-b
,
--escape
print C-style escapes for nongraphic characters
--block-size
=
SIZE
with
-l
, scale sizes by SIZE when printing them; e.g.,
              '--block-size=M'; see SIZE format below
-B
,
--ignore-backups
do not list implied entries ending with ~
-c
with
-lt
: sort by, and show, ctime (time of last change of
              file status information); with
-l
: show ctime and sort by
              name; otherwise: sort by ctime, newest first
-C
list entries by columns
--color
[=
WHEN
]
              color the output WHEN; more info below
-d
,
--directory
list directories themselves, not their contents
-D
,
--dired
generate output designed for Emacs' dired mode
-f
same as
-a -U
-F
,
--classify
[=
WHEN
]
              append indicator (one of */=>@|) to entries WHEN
--file-type
likewise, except do not append '*'
--format
=
WORD
across
-x
, commas
-m
, horizontal
-x
, long
-l
, single-column
-1
, verbose
-l
, vertical
-C
--full-time
like
-l --time-style
=
full-iso
-g
like
-l
, but do not list owner
--group-directories-first
group directories before files
-G
,
--no-group
in a long listing, don't print group names
-h
,
--human-readable
with
-l
and
-s
, print sizes like 1K 234M 2G etc."
1617,3,vdir,"--author
with
-l
, print the author of each file
-b
,
--escape
print C-style escapes for nongraphic characters
--block-size
=
SIZE
with
-l
, scale sizes by SIZE when printing them; e.g.,
              '--block-size=M'; see SIZE format below
-B
,
--ignore-backups
do not list implied entries ending with ~
-c
with
-lt
: sort by, and show, ctime (time of last change of
              file status information); with
-l
: show ctime and sort by
              name; otherwise: sort by ctime, newest first
-C
list entries by columns
--color
[=
WHEN
]
              color the output WHEN; more info below
-d
,
--directory
list directories themselves, not their contents
-D
,
--dired
generate output designed for Emacs' dired mode
-f
same as
-a -U
-F
,
--classify
[=
WHEN
]
              append indicator (one of */=>@|) to entries WHEN
--file-type
likewise, except do not append '*'
--format
=
WORD
across
-x
, commas
-m
, horizontal
-x
, long
-l
, single-column
-1
, verbose
-l
, vertical
-C
--full-time
like
-l --time-style
=
full-iso
-g
like
-l
, but do not list owner
--group-directories-first
group directories before files
-G
,
--no-group
in a long listing, don't print group names
-h
,
--human-readable
with
-l
and
-s
, print sizes like 1K 234M 2G etc. --si
likewise, but use powers of 1000 not 1024
-H
,
--dereference-command-line
follow symbolic links listed on the command line
--dereference-command-line-symlink-to-dir
follow each command line symbolic link that points to a
              directory
--hide
=
PATTERN
do not list implied entries matching shell PATTERN
              (overridden by
-a
or
-A
)
--hyperlink
[=
WHEN
]
              hyperlink file names WHEN
--indicator-style
=
WORD
append indicator with style WORD to entry names: none
              (default), slash (
-p
), file-type (
--file-type
), classify
              (
-F
)
-i
,
--inode
print the index number of each file
-I
,
--ignore
=
PATTERN
do not list implied entries matching shell PATTERN
-k
,
--kibibytes
default to 1024-byte blocks for file system usage; used
              only with
-s
and per directory totals
-l
use a long listing format
-L
,
--dereference
when showing file information for a symbolic link, show
              information for the file the link references rather than
              for the link itself
-m
fill width with a comma separated list of entries
-n
,
--numeric-uid-gid
like
-l
, but list numeric user and group IDs
-N
,
--literal
print entry names without quoting
-o
like
-l
, but do not list group information
-p
,
--indicator-style
=
slash
append / indicator to directories
-q
,
--hide-control-chars
print ? instead of nongraphic characters
--show-control-chars
show nongraphic characters as-is (the default, unless
              program is 'ls' and output is a terminal)
-Q
,
--quote-name
enclose entry names in double quotes
--quoting-style
=
WORD
use quoting style WORD for entry names: literal, locale,
              shell, shell-always, shell-escape, shell-escape-always, c,
              escape (overrides QUOTING_STYLE environment variable)
-r
,
--reverse
reverse order while sorting
-R
,
--recursive
list subdirectories recursively
-s
,
--size
print the allocated size of each file, in blocks
-S
sort by file size, largest first
--sort
=
WORD
change default 'name' sort to WORD: none (
-U
), size (
-S
),
              time (
-t
), version (
-v
), extension (
-X
), name, width
--time
=
WORD
select which timestamp used to display or sort; access time
              (
-u
): atime, access, use; metadata change time (
-c
): ctime,
              status; modified time (default): mtime, modification; birth
              time: birth, creation;

              with
-l
, WORD determines which time to show; with
--sort
=
time
, sort by WORD (newest first)
--time-style
=
TIME_STYLE
time/date format with
-l
; see TIME_STYLE below
-t
sort by time, newest first; see
--time
-T
,
--tabsize
=
COLS
assume tab stops at each COLS instead of 8
-u
with
-lt
: sort by, and show, access time; with
-l
: show
              access time and sort by name; otherwise: sort by access
              time, newest first
-U
do not sort directory entries
-v
natural sort of (version) numbers within text
-w
,
--width
=
COLS
set output width to COLS."
1617,4,vdir,"instead of nongraphic characters
--show-control-chars
show nongraphic characters as-is (the default, unless
              program is 'ls' and output is a terminal)
-Q
,
--quote-name
enclose entry names in double quotes
--quoting-style
=
WORD
use quoting style WORD for entry names: literal, locale,
              shell, shell-always, shell-escape, shell-escape-always, c,
              escape (overrides QUOTING_STYLE environment variable)
-r
,
--reverse
reverse order while sorting
-R
,
--recursive
list subdirectories recursively
-s
,
--size
print the allocated size of each file, in blocks
-S
sort by file size, largest first
--sort
=
WORD
change default 'name' sort to WORD: none (
-U
), size (
-S
),
              time (
-t
), version (
-v
), extension (
-X
), name, width
--time
=
WORD
select which timestamp used to display or sort; access time
              (
-u
): atime, access, use; metadata change time (
-c
): ctime,
              status; modified time (default): mtime, modification; birth
              time: birth, creation;

              with
-l
, WORD determines which time to show; with
--sort
=
time
, sort by WORD (newest first)
--time-style
=
TIME_STYLE
time/date format with
-l
; see TIME_STYLE below
-t
sort by time, newest first; see
--time
-T
,
--tabsize
=
COLS
assume tab stops at each COLS instead of 8
-u
with
-lt
: sort by, and show, access time; with
-l
: show
              access time and sort by name; otherwise: sort by access
              time, newest first
-U
do not sort directory entries
-v
natural sort of (version) numbers within text
-w
,
--width
=
COLS
set output width to COLS. 0 means no limit
-x
list entries by lines instead of by columns
-X
sort alphabetically by entry extension
-Z
,
--context
print any security context of each file
--zero
end each output line with NUL, not newline
-1
list one file per line
--help
display this help and exit
--version
output version information and exit

       The SIZE argument is an integer and optional unit (example: 10K is
       10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,..."
1617,5,vdir,"Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or
       KB,MB,... (powers of 1000). Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on."
1617,6,vdir,"Binary prefixes can be used, too:
       KiB=K, MiB=M, and so on. The TIME_STYLE argument can be full-iso, long-iso, iso, locale, or
       +FORMAT. FORMAT is interpreted like in
date(1)
."
1617,7,vdir,"FORMAT is interpreted like in
date(1)
. If FORMAT is
       FORMAT1<newline>FORMAT2, then FORMAT1 applies to non-recent files
       and FORMAT2 to recent files. TIME_STYLE prefixed with 'posix-'
       takes effect only outside the POSIX locale."
1617,8,vdir,"TIME_STYLE prefixed with 'posix-'
       takes effect only outside the POSIX locale. Also the TIME_STYLE
       environment variable sets the default style to use. The WHEN argument defaults to 'always' and can also be 'auto' or
       'never'."
1617,9,vdir,"The WHEN argument defaults to 'always' and can also be 'auto' or
       'never'. Using color to distinguish file types is disabled both by default
       and with
--color
=
never
. With
--color
=
auto
, ls emits color codes
       only when standard output is connected to a terminal."
1617,10,vdir,"With
--color
=
auto
, ls emits color codes
       only when standard output is connected to a terminal. The
       LS_COLORS environment variable can change the settings. Use the
dircolors(1)
command to set it."
1617,11,vdir,"The
       LS_COLORS environment variable can change the settings. Use the
dircolors(1)
command to set it. Exit status:
0      if OK,

       1      if minor problems (e.g., cannot access subdirectory),

       2      if serious trouble (e.g., cannot access command-line
              argument)."
1618,0,varlinkctl,"varlinkctl
may be used to introspect and invoke
Varlink
[1]
       services. Services are referenced by one of the following:

       â¢   A Varlink service reference starting with the ""unix:"" string,
           followed by an absolute
AF_UNIX
socket path, or by ""@"" and an
           arbitrary string (the latter for referencing sockets in the
           abstract namespace). In this case, a stream socket connection
           is made to the specified socket."
1618,1,varlinkctl,"In this case, a stream socket connection
           is made to the specified socket. â¢   A Varlink service reference starting with the ""exec:"" string,
           followed by an absolute path of a binary to execute. In this
           case, the specified process is forked off locally, with a
           connected stream socket passed in."
1618,2,varlinkctl,"In this
           case, the specified process is forked off locally, with a
           connected stream socket passed in. â¢   A Varlink service reference starting with the ""ssh-unix:""
           string, followed by an SSH host specification, followed by
           "":"", followed by an absolute
AF_UNIX
socket path. (This
           requires OpenSSH 9.4 or newer on the server side, and abstract
           namespace sockets are not supported.)

       â¢   A Varlink service reference starting with the ""ssh-exec:""
           string, followed by an SSH host specification, followed by
           "":"", followed by a command line."
1618,3,varlinkctl,"(This
           requires OpenSSH 9.4 or newer on the server side, and abstract
           namespace sockets are not supported.)

       â¢   A Varlink service reference starting with the ""ssh-exec:""
           string, followed by an SSH host specification, followed by
           "":"", followed by a command line. In this case, the command is
           invoked and the Varlink protocol is spoken on the standard
           input and output of the invoked command. For convenience, these two simpler (redundant) service address
       syntaxes are also supported:

       â¢   A file system path to an
AF_UNIX
socket, either absolute (i.e."
1618,4,varlinkctl,"For convenience, these two simpler (redundant) service address
       syntaxes are also supported:

       â¢   A file system path to an
AF_UNIX
socket, either absolute (i.e. begins with ""/"") or relative (in which case it must begin with
           ""./""). â¢   A file system path to an executable, either absolute or
           relative (as above, must begin with ""/"" or ""./"",
           respectively)."
1619,0,vgdb,"vgdb
(""Valgrind to GDB"") is used as an intermediary between
       Valgrind and GDB or a shell. It has three usage modes:

        1. As a standalone utility, it is used from a shell command line
           to send monitor commands to a process running under Valgrind."
1619,1,vgdb,"As a standalone utility, it is used from a shell command line
           to send monitor commands to a process running under Valgrind. For this usage, the vgdb OPTION(s) must be followed by the
           monitor command to send. To send more than one command,
           separate them with the
-c
option."
1619,2,vgdb,"To send more than one command,
           separate them with the
-c
option. 2. In combination with GDB ""target remote |"" command, it is used
           as the relay application between GDB and the Valgrind
           gdbserver."
1619,3,vgdb,"In combination with GDB ""target remote |"" command, it is used
           as the relay application between GDB and the Valgrind
           gdbserver. For this usage, only OPTION(s) can be given, but no
           COMMAND can be given. 3."
1619,4,vgdb,"3. In the
--multi
mode, vgdb uses the extended remote protocol to
           communicate with GDB. This allows you to view output from both
           valgrind and GDB in the GDB session."
1619,5,vgdb,"This allows you to view output from both
           valgrind and GDB in the GDB session. This is accomplished via
           the ""target extended-remote | vgdb --multi"". In this mode you
           no longer need to start valgrind yourself."
1619,6,vgdb,"In this mode you
           no longer need to start valgrind yourself. vgdb will start up
           valgrind when gdb tells it to run a new program. For this
           usage, the vgdb OPTIONS(s) can also include
--valgrind
and
--vargs
to describe how valgrind should be started."
1620,0,verifytree,"verifytree
is a program that verifies whether a local yum
       repository is consistent."
1621,0,verify_blkparse,"Verifies an output file from blkparse. All it does is check if the
       events in the file are correctly time ordered. If an entry is
       found that isn't ordered, it's dumped to stdout."
1622,0,vlock,"vlock
is a program to lock one or more sessions on the Linux
       console. This is especially useful for Linux machines which have
       multiple users with access to the console. One user may lock his
       or her session(s) while still allowing other users to use the
       system on other virtual consoles."
1622,1,vlock,"One user may lock his
       or her session(s) while still allowing other users to use the
       system on other virtual consoles. If desired, the entire console
       may be locked and virtual console switching disabled. By default, only the current VC (virtual console) is locked."
1622,2,vlock,"By default, only the current VC (virtual console) is locked. With
       the
-a,-all
option all VCs are locked. The locked VCs cannot be
       unlocked without the invoker's password."
1622,3,vlock,"The locked VCs cannot be
       unlocked without the invoker's password. And, for the paranoid,
       vlock makes it a trying experience for those attempting to guess
       the password, so unauthorized access to session(s) is highly
       unlikely. Please note that it is entirely possible to completely lock
       yourself out of the console with the
-a,--all
option if you cannot
       remember your password!"
1622,4,vlock,"Please note that it is entirely possible to completely lock
       yourself out of the console with the
-a,--all
option if you cannot
       remember your password! Unless you are able to kill vlock by
       logging in remotely via a serial terminal or network, a hard reset
       is the only method of ``unlocking'' the display. vlock
works for console sessions primarily."
1622,5,vlock,"Unless you are able to kill vlock by
       logging in remotely via a serial terminal or network, a hard reset
       is the only method of ``unlocking'' the display. vlock
works for console sessions primarily. However, there is
       support for trying to lock non-console sessions as well, but that
       support has not been well tested."
1623,0,w,"w
displays information about the users currently on the machine,
       and their processes. The header shows, in this order, the current
       time, how long the system has been running, how many users are
       currently logged on, and the system load averages for the past 1,
       5, and 15 minutes. The following entries are displayed for each user: login name, the
       tty name, the remote host, login time, idle time, JCPU, PCPU, and
       the command line of their current process."
1623,1,w,"The following entries are displayed for each user: login name, the
       tty name, the remote host, login time, idle time, JCPU, PCPU, and
       the command line of their current process. The JCPU time is the time used by all processes attached to the
       tty. It does not include past background jobs, but does include
       currently running background jobs."
1623,2,w,"The JCPU time is the time used by all processes attached to the
       tty. It does not include past background jobs, but does include
       currently running background jobs. The PCPU time is the time used by the current process, named in
       the ""what"" field."
1624,0,vi,"This utility shall be provided on systems that both support the
       User Portability Utilities option and define the POSIX2_CHAR_TERM
       symbol. On other systems it is optional. The
vi
(visual) utility is a screen-oriented text editor."
1624,1,vi,"The
vi
(visual) utility is a screen-oriented text editor. Only the
       open and visual modes of the editor are described in POSIX.1â2008;
       see the line editor
ex
for additional editing capabilities used in
vi
. The user can switch back and forth between
vi
and
ex
and
       execute
ex
commands from within
vi
."
1624,2,vi,"The user can switch back and forth between
vi
and
ex
and
       execute
ex
commands from within
vi
. This reference page uses the term
edit buffer
to describe the
       current working text. No specific implementation is implied by
       this term."
1624,3,vi,"No specific implementation is implied by
       this term. All editing changes are performed on the edit buffer,
       and no changes to it shall affect any file until an editor command
       writes the file. When using
vi
, the terminal screen acts as a window into the
       editing buffer."
1624,4,vi,"When using
vi
, the terminal screen acts as a window into the
       editing buffer. Changes made to the editing buffer shall be
       reflected in the screen display; the position of the cursor on the
       screen shall indicate the position within the editing buffer. Certain terminals do not have all the capabilities necessary to
       support the complete
vi
definition."
1624,5,vi,"Certain terminals do not have all the capabilities necessary to
       support the complete
vi
definition. When these commands cannot be
       supported on such terminals, this condition shall not produce an
       error message such as ``not an editor command'' or report a syntax
       error. The implementation may either accept the commands and
       produce results on the screen that are the result of an
       unsuccessful attempt to meet the requirements of this volume of
       POSIX.1â2017 or report an error describing the terminal-related
       deficiency."
1625,0,valgrind,"Valgrind
is a flexible program for debugging and profiling Linux
       executables. It consists of a core, which provides a synthetic CPU
       in software, and a series of debugging and profiling tools. The
       architecture is modular, so that new tools can be created easily
       and without disturbing the existing structure."
1625,1,valgrind,"The
       architecture is modular, so that new tools can be created easily
       and without disturbing the existing structure. Some of the options described below work with all Valgrind tools,
       and some only work with a few or one. The section MEMCHECK OPTIONS
       and those below it describe tool-specific options."
1625,2,valgrind,"The section MEMCHECK OPTIONS
       and those below it describe tool-specific options. This manual page covers only basic usage and options. For more
       comprehensive information, please see the HTML documentation on
       your system: $INSTALL/share/doc/valgrind/html/index.html, or
       online:
http://www.valgrind.org/docs/manual/index.html
."
1626,0,waitpid,"waitpid
is a simple command to wait for arbitrary non-child
       processes.

       It exits after all processes whose PIDs have been passed as
       arguments have exited."
1627,0,wait,"When an asynchronous list (see
Section 2.9.3.1
,
Examples
) is
       started by the shell, the process ID of the last command in each
       element of the asynchronous list shall become known in the current
       shell execution environment; see
Section 2.12
,
Shell Execution
Environment
. If the
wait
utility is invoked with no operands, it shall wait
       until all process IDs known to the invoking shell have terminated
       and exit with a zero exit status. If one or more
pid
operands are specified that represent known
       process IDs, the
wait
utility shall wait until all of them have
       terminated."
1627,1,wait,"If one or more
pid
operands are specified that represent known
       process IDs, the
wait
utility shall wait until all of them have
       terminated. If one or more
pid
operands are specified that
       represent unknown process IDs,
wait
shall treat them as if they
       were known process IDs that exited with exit status 127. The exit
       status returned by the
wait
utility shall be the exit status of
       the process requested by the last
pid
operand."
1627,2,wait,"If one or more
pid
operands are specified that
       represent unknown process IDs,
wait
shall treat them as if they
       were known process IDs that exited with exit status 127. The exit
       status returned by the
wait
utility shall be the exit status of
       the process requested by the last
pid
operand. The known process IDs are applicable only for invocations of
wait
in the current shell execution environment."
1628,0,watch,"watch
runs
command
repeatedly, displaying its output and errors
       (the first screenful). This allows you to watch the program output
       change over time. By default,
command
is run every 2 seconds and
watch
will run until interrupted."
1628,1,watch,"This allows you to watch the program output
       change over time. By default,
command
is run every 2 seconds and
watch
will run until interrupted. A header informs of the start
       and running time of
command
as well as its exit code."
1629,0,wall,"wall
displays a
message
, or the contents of a
file
, or otherwise
       its standard input, on the terminals of all currently logged in
       users. The command will wrap lines that are longer than 79
       characters. Short lines are whitespace padded to have 79
       characters."
1629,1,wall,"Short lines are whitespace padded to have 79
       characters. The command will always put a carriage return and new
       line at the end of each line. Only the superuser can write on the terminals of users who have
       chosen to deny messages or are using a program which automatically
       denies messages."
1629,2,wall,"The command will always put a carriage return and new
       line at the end of each line. Only the superuser can write on the terminals of users who have
       chosen to deny messages or are using a program which automatically
       denies messages. Reading from a
file
is refused when the invoker is not superuser
       and the program is set-user-ID or set-group-ID."
1630,0,wc,"Print newline, word, and byte counts for each FILE, and a total
       line if more than one FILE is specified. A word is a nonempty
       sequence of non white space delimited by white space characters or
       by start or end of input. With no FILE, or when FILE is -, read standard input."
1630,1,wc,"With no FILE, or when FILE is -, read standard input. The options below may be used to select which counts are printed,
       always in the following order: newline, word, character, byte,
       maximum line length. -c
,
--bytes
print the byte counts
-m
,
--chars
print the character counts
-l
,
--lines
print the newline counts
--files0-from
=
F
read input from the files specified by NUL-terminated names
              in file F; If F is - then read names from standard input
-L
,
--max-line-length
print the maximum display width
-w
,
--words
print the word counts
--total
=
WHEN
when to print a line with total counts; WHEN can be: auto,
              always, only, never
--help
display this help and exit
--version
output version information and exit"
1631,0,wc,"The
wc
utility shall read one or more input files and, by default,
       write the number of <newline> characters, words, and bytes
       contained in each input file to the standard output.

       The utility also shall write a total count for all named files, if
       more than one input file is specified.

       The
wc
utility shall consider a
word
to be a non-zero-length
       string of characters delimited by white space."
1632,0,weblogvis,"weblogvis
displays Web server activity as extracted from the Web
       server access logs by the Performance Co-Pilot (PCP) agent
pmdaweblog(1)
. The display is modulated by the values of the
       performance metrics retrieved from the target
host
which is
       running
pmcd(1)
and the
pmdaweblog(1)
Performance Metrics Domain
       Agent (
PMDA(3)
), or from the PCP archive log identified by
archive
. The display is updated every
interval
seconds (default 2
       seconds)."
1632,1,weblogvis,"The display is updated every
interval
seconds (default 2
       seconds). The default display mode shows the request rate classified by
       request response size, for all Web server logs being monitored by
pmdaweblog(1)
. The top of the display includes the idle time and
       the total request rate of each Web server."
1632,2,weblogvis,"The top of the display includes the idle time and
       the total request rate of each Web server. The list of servers
       can be restricted by specifying
server
names. The possible
servers
are listed in the
pmdaweblog(1)
configuration file."
1632,3,weblogvis,"The possible
servers
are listed in the
pmdaweblog(1)
configuration file. weblogvis
uses
pmview(1)
, and so the user interface follows that
       described for
pmview(1)
, which in turn displays the scene within
       an Inventor examiner viewer. weblogvis
passes most command line options to
pmview(1)
."
1632,4,weblogvis,"weblogvis
uses
pmview(1)
, and so the user interface follows that
       described for
pmview(1)
, which in turn displays the scene within
       an Inventor examiner viewer. weblogvis
passes most command line options to
pmview(1)
. Therefore, the command line options
-A
,
-a
,
-C
,
-h
,
-n
,
-O
,
-p
,
-S
,
-t
,
-T
,
-x
,
-Z
and
-z
, and the user interface are described in
       the
pmview(1)
man page."
1633,0,webpingvis,"webpingvis
displays a summary of Web server response-time
       statistics collected from the Performance Co-Pilot (PCP)
       infrastructure. The display is modulated by the values of
       performance metrics retrieved from the target
host
(which is
       running
pmcd(1)
and the
pmdawebping
(1) Performance Metrics Domain
       Agent) or from the PCP archive log identified by
archive
. The
       display is updated every
interval
seconds (default 2 seconds)."
1633,1,webpingvis,"The
       display is updated every
interval
seconds (default 2 seconds). As in all
pmview(1)
scenes, when the mouse is moved over one of
       the bars, the current value and metric information for that bar
       will be shown in the text box near the top of the display. The
       height of the bars is proportional to the performance metric
       values relative to the maximum, as controlled by size of the URLs
       being fetched by
pmdawebping
(1), and the
-m
option (see below)."
1633,2,webpingvis,"The
       height of the bars is proportional to the performance metric
       values relative to the maximum, as controlled by size of the URLs
       being fetched by
pmdawebping
(1), and the
-m
option (see below). The bars in the
webpingvis
scene represent the following
       information:
Size
The green bars indicate the relative sizes of the results
           returned for each URL in the
pmdawebping
workload. Response
For each URL in the
pmdawebping
workload, the components of
           the Web server response-time (connect, head and body) and the
           total response-time is displayed."
1633,3,webpingvis,"Response
For each URL in the
pmdawebping
workload, the components of
           the Web server response-time (connect, head and body) and the
           total response-time is displayed. To the right, the component and total times are summed over
           all URLs in the
pmdawebping
workload. Errors
The four red error bars indicate the number of socket, HTTP,
           HTML or other errors that occurred in the last iteration of
           the
pmdawebping
workload."
1633,4,webpingvis,"Errors
The four red error bars indicate the number of socket, HTTP,
           HTML or other errors that occurred in the last iteration of
           the
pmdawebping
workload. Any of these errors will terminate
           the request for a URL. webpingvis
uses
pmview(1)
, and so the user interface follows that
       described for
pmview(1)
, which in turn displays the scene within
       an Inventor examiner viewer."
1633,5,webpingvis,"webpingvis
uses
pmview(1)
, and so the user interface follows that
       described for
pmview(1)
, which in turn displays the scene within
       an Inventor examiner viewer. For generic control of the viewer,
       see
ivview
(1). webpingvis
passes most command line options to
pmview(1)
."
1633,6,webpingvis,"webpingvis
passes most command line options to
pmview(1)
. Therefore, the command line options
-A
,
-a
,
-C
,
-h
,
-n
,
-O
,
-p
,
-S
,
-t
,
-T
,
-x
,
-Z
and
-z
, and the user interface are described in
       the
pmview(1)
man page. Options specific to
webpingvis
are:
-i
The URL names are not included as labels in the scene by
              default."
1633,7,webpingvis,"Options specific to
webpingvis
are:
-i
The URL names are not included as labels in the scene by
              default. The
-i
option forces them to be included. -m
max
Change the normalization factor for the response-time bars."
1633,8,webpingvis,"-m
max
Change the normalization factor for the response-time bars. The value for
max
is in units of milliseconds, and should
              be the expected maximum value for the total response-time
              aggregated over all URLs in the
pmdawebping
workload. The
              default value is 1000 milliseconds."
1633,9,webpingvis,"The
              default value is 1000 milliseconds. -V
The derived configuration file for
pmview(1)
is written on
              standard output. This may be saved and used directly with
pmview(1)
if the user wishes to customize the display, or
              modify some of the normalization parameters."
1634,0,webvis,"webvis
displays an overview of system level Web server performance
       statistics collected from the Performance Co-Pilot (PCP)
       infrastructure. The display is modulated by the values of the
       performance metrics retrieved from the target
host
(which is
       running
pmcd(1)
and the
pmdaweblog(1)
Performance Metrics Domain
       Agent) or from the PCP archive log identified by
archive
. The
       display is updated every
interval
seconds (default 2 seconds)."
1634,1,webvis,"The
       display is updated every
interval
seconds (default 2 seconds). As in all
pmview(1)
scenes, when the mouse is moved over one of
       the bars, the current value and metric information for that bar
       will be shown in the text box near the top of the display. The height of the web request and network activity bars is
       proportional to the performance metric values relative to the
       maximum expected activity, as controlled by the
-m
and
-r
options
       (see below)."
1634,2,webvis,"The height of the web request and network activity bars is
       proportional to the performance metric values relative to the
       maximum expected activity, as controlled by the
-m
and
-r
options
       (see below). Similarly the
-b
and
-i
options control the scaling
       for disk activity bars. The bars in the
webvis
scene represent the following information;
Requests by Size
At the front of the scene, the ""Requests by Size"" row of bars
           shows the rate of requests for different size requests (the
           histograms are defined by the following byte counts: 0, 3
           Kbytes, 10 Kbytes, 30 Kbytes, 100 Kbytes, 300 Kbytes, 1 Mbyte,
           3 Mbytes and larger than 3 Mbytes)."
1634,3,webvis,"The bars in the
webvis
scene represent the following information;
Requests by Size
At the front of the scene, the ""Requests by Size"" row of bars
           shows the rate of requests for different size requests (the
           histograms are defined by the following byte counts: 0, 3
           Kbytes, 10 Kbytes, 30 Kbytes, 100 Kbytes, 300 Kbytes, 1 Mbyte,
           3 Mbytes and larger than 3 Mbytes). Notice that the size
           divisions are not evenly distributed. The ""size"" is the data
           portion of the response to each Web server request."
1634,4,webvis,"The ""size"" is the data
           portion of the response to each Web server request. These
           rates are aggregated across all monitored Web servers. Requests by Type
This row of bars shows the request rate for each type of HTTP
           request (get, post, head and other), aggregated across all
           monitored Web servers."
1634,5,webvis,"Requests by Type
This row of bars shows the request rate for each type of HTTP
           request (get, post, head and other), aggregated across all
           monitored Web servers. For a detailed display showing the
           break down of requests
per Web server
, see
weblogvis(1)
. Network
For every network interface there are two stacked bars."
1634,6,webvis,"Network
For every network interface there are two stacked bars. One
           of the bars shows the input traffic while the other bar shows
           the output traffic. The stacks are composed of the number of
           errors (red), the number of drops (orange) and the number of
           packets (green)."
1634,7,webvis,"The stacks are composed of the number of
           errors (red), the number of drops (orange) and the number of
           packets (green). In general, if there are any ""dropped input
           packets"" then the corresponding network interface is
           saturated, or there are insufficient network resources
           available in the kernel to adequately service the input
           request load. If this is the case then the
Alarm Conditions
rows (see below) may provide more detail into the source of
           the problem."
1634,8,webvis,"If this is the case then the
Alarm Conditions
rows (see below) may provide more detail into the source of
           the problem. Alarm Conditions
The red row of bars shows an assortment of TCP error
           conditions (aggregated for all network interfaces), the orange
           bars show critical kernel buffer allocation problems, and the
           yellow bar shows severe paging conditions. If any of these
           bars have a non-zero height then the system being monitored
           may require kernel parameter tuning, software reconfiguration
           or more hardware resources."
1634,9,webvis,"If any of these
           bars have a non-zero height then the system being monitored
           may require kernel parameter tuning, software reconfiguration
           or more hardware resources. The performance metrics behind
           the bars are:
network.tcp.drops
- rate of dropped connections
network.tcp.conndrops
- rate of embryonic connections dropped
network.tcp.timeoutdrop
- rate of connections dropped by rexmit timeout
network.tcp.rcvbadsum
- rate of packets discarded for bad checksums
network.tcp.rexmttimeo
- rate of retransmit timeouts
network.tcp.sndrexmitpack
- rate of data packets retransmitted
swap.pagesout
- page swap out rate (indicating insufficient memory)
network.mbuf.failed
- rate of incidents where the kernel failed to find
                  mbuf space
network.mbuf.waited
- rate of incidents where the kernel waited to find
                  mbuf space
CPU
This column shows CPU utilization, aggregated over all CPUs. (CPU idle time is not included in the column)."
1634,10,webvis,"(CPU idle time is not included in the column). Disk
There are two cylinders showing disk metrics. The first
           cylinder shows the rate of read (yellow) and write (violet)
           operations, aggregated over all disk spindles."
1634,11,webvis,"The first
           cylinder shows the rate of read (yellow) and write (violet)
           operations, aggregated over all disk spindles. The second
           cylinder shows the average (over all disks) percentage of time
           for which a disk is busy or active. This metric is not
           available in PCP1.x versions, therefore if
webvis
is being
           used to monitor a host running PCP1.x this cylinder will not
           be displayed."
1634,12,webvis,"This metric is not
           available in PCP1.x versions, therefore if
webvis
is being
           used to monitor a host running PCP1.x this cylinder will not
           be displayed. To adjust the scaling of these objects, refer to the
-b
and
-i
options described below. Mem
There are two bars showing memory metrics."
1634,13,webvis,"Mem
There are two bars showing memory metrics. The first bar
           shows utilized memory, with different colors representing
           different types of utilization (kernel, user, etc), while the
           second bar shows the amount of free memory. If
webvis
is
           being used to monitor a host running PCP1.x then only the bar
           showing free memory will be displayed."
1634,14,webvis,"If
webvis
is
           being used to monitor a host running PCP1.x then only the bar
           showing free memory will be displayed. If any optional
interface
arguments are specified in the command
       line, then just the network interfaces matching the
interface
arguments will appear in the
Network
section. By default,
all
interfaces will be used."
1634,15,webvis,"By default,
all
interfaces will be used. The
interface
arguments are used as
       patterns for
egrep
(1) matching against the interface names, so
ec
would select all external Ethernet interfaces for a Challenge S. webvis
uses
pmview(1)
, and so the user interface follows that
       described for
pmview(1)
, which in turn displays the scene within
       an Inventor examiner viewer."
1634,16,webvis,"webvis
uses
pmview(1)
, and so the user interface follows that
       described for
pmview(1)
, which in turn displays the scene within
       an Inventor examiner viewer. webvis
passes most command line options to
pmview(1)
. Therefore,
       the command line options
-A
,
-a
,
-C
,
-h
,
-n
,
-O
,
-p
,
-S
,
-t
,
-T
,
-x
,
-Z
and
-z
, and the user interface are described in the
pmview(1)
man page."
1634,17,webvis,"Therefore,
       the command line options
-A
,
-a
,
-C
,
-h
,
-n
,
-O
,
-p
,
-S
,
-t
,
-T
,
-x
,
-Z
and
-z
, and the user interface are described in the
pmview(1)
man page. Options specific to
webvis
are:
-b
maxbusy
Controls the maximum (normalization) value for the average
              percentage of the time active over all disks. The default
              value is 30% active."
1634,18,webvis,"The default
              value is 30% active. -i
maxio
Controls the maximum (normalization) value for the sume of
              the aggregate disk read and disk write rates. The default
              value is 100 I/Os per second."
1634,19,webvis,"The default
              value is 100 I/Os per second. -m
max
Controls the maximum (normalization) value for the packet
              input and packet output rates. The default value is 750
              packets/second."
1634,20,webvis,"The default value is 750
              packets/second. -r
maxreq
Controls the maximum Web request rate. The default is 5%
              of the maximum packet rate (i.e."
1634,21,webvis,"The default is 5%
              of the maximum packet rate (i.e. 38 requests/second by
              default). The maximum Web error rate is fixed at 20% of
              the maximum Web request rate (i.e."
1634,22,webvis,"The maximum Web error rate is fixed at 20% of
              the maximum Web request rate (i.e. 7 errors/second by
              default). -V
The derived configuration file for
pmview(1)
is written on
              standard output."
1634,23,webvis,"7 errors/second by
              default). -V
The derived configuration file for
pmview(1)
is written on
              standard output. This may be saved and used directly with
pmview
if the user wishes to customize the display, or
              modify some of the normalization parameters."
1635,0,wget,"GNU Wget is a free utility for non-interactive download of files
       from the Web. It supports HTTP, HTTPS, and FTP protocols, as well
       as retrieval through HTTP proxies. Wget is non-interactive, meaning that it can work in the
       background, while the user is not logged on."
1635,1,wget,"Wget is non-interactive, meaning that it can work in the
       background, while the user is not logged on. This allows you to
       start a retrieval and disconnect from the system, letting Wget
       finish the work. By contrast, most of the Web browsers require
       constant user's presence, which can be a great hindrance when
       transferring a lot of data."
1635,2,wget,"By contrast, most of the Web browsers require
       constant user's presence, which can be a great hindrance when
       transferring a lot of data. Wget can follow links in HTML, XHTML, and CSS pages, to create
       local versions of remote web sites, fully recreating the directory
       structure of the original site. This is sometimes referred to as
       ""recursive downloading.""  While doing that, Wget respects the
       Robot Exclusion Standard (
/robots.txt
)."
1635,3,wget,"This is sometimes referred to as
       ""recursive downloading.""  While doing that, Wget respects the
       Robot Exclusion Standard (
/robots.txt
). Wget can be instructed to
       convert the links in downloaded files to point at the local files,
       for offline viewing. Wget has been designed for robustness over slow or unstable
       network connections; if a download fails due to a network problem,
       it will keep retrying until the whole file has been retrieved."
1635,4,wget,"Wget can be instructed to
       convert the links in downloaded files to point at the local files,
       for offline viewing. Wget has been designed for robustness over slow or unstable
       network connections; if a download fails due to a network problem,
       it will keep retrying until the whole file has been retrieved. If
       the server supports regetting, it will instruct the server to
       continue the download from where it left off."
1636,0,what,"The
what
utility shall search the given files for all occurrences
       of the pattern that
get
(see
get(1p)
) substitutes for the %
Z
%
       keyword (
""@(#)""
) and shall write to standard output what follows
       until the first occurrence of one of the following:

           ""   >   newline   \   NUL"
1637,0,whereis,"whereis
locates the binary, source and manual files for the
       specified command names. The supplied names are
first stripped of
leading pathname components
. Prefixes of
s."
1637,1,whereis,"Prefixes of
s. resulting from use of
       source code control are also dealt with. whereis
then attempts to
       locate the desired program in the standard Linux places, and in
       the places specified by
$PATH
and
$MANPATH
."
1637,2,whereis,"whereis
then attempts to
       locate the desired program in the standard Linux places, and in
       the places specified by
$PATH
and
$MANPATH
. The search restrictions (options
-b
,
-m
and
-s
) are cumulative and
       apply to the subsequent
name
patterns on the command line. Any new
       search restriction resets the search mask."
1637,3,whereis,"Any new
       search restriction resets the search mask. For example,
whereis -bm ls tr -m gcc
searches for ""ls"" and ""tr"" binaries and man pages, and for ""gcc""
       man pages only. The options
-B
,
-M
and
-S
reset search paths for the subsequent
name
patterns."
1637,4,whereis,"For example,
whereis -bm ls tr -m gcc
searches for ""ls"" and ""tr"" binaries and man pages, and for ""gcc""
       man pages only. The options
-B
,
-M
and
-S
reset search paths for the subsequent
name
patterns. For example,
whereis -m ls -M /usr/share/man/man1 -f cal
searches for ""
ls
"" man pages in all default paths, but for ""cal"" in
       the
/usr/share/man/man1
directory only."
1638,0,whatis,"Each manual page has a short description available within it. whatis
searches the manual page names and displays the manual page
       descriptions of any
name
matched. name
may contain wildcards (
-w
) or be a regular expression (
-r
)."
1638,1,whatis,"name
may contain wildcards (
-w
) or be a regular expression (
-r
). Using these options, it may be necessary to quote the
name
or
       escape (\) the special characters to stop the shell from
       interpreting them. index
databases are used during the search, and are updated by the
mandb
program."
1638,2,whatis,"index
databases are used during the search, and are updated by the
mandb
program. Depending on your installation, this may be run by
       a periodic cron job, or may need to be run manually after new
       manual pages have been installed. To produce an old style text
whatis
database from the relative
index
database, issue the
       command:
whatis -M
manpath
-w '*' | sort >
manpath/whatis
where
manpath
is a manual page hierarchy such as
/usr/man
."
1639,0,who,"The
who
utility shall list various pieces of information about
       accessible users. The domain of accessibility is implementation-
       defined.

       Based on the options given,
who
can also list the user's name,
       terminal line, login time, elapsed time since activity occurred on
       the line, and the process ID of the command interpreter for each
       current system user."
1640,0,who,"Print information about users who are currently logged in. -a
,
--all
same as
-b -d --login -p -r -t -T -u
-b
,
--boot
time of last system boot
-d
,
--dead
print dead processes
-H
,
--heading
print line of column headings
-l
,
--login
print system login processes
--lookup
attempt to canonicalize hostnames via DNS
-m
only hostname and user associated with stdin
-p
,
--process
print active processes spawned by init
-q
,
--count
all login names and number of users logged on
-r
,
--runlevel
print current runlevel
-s
,
--short
print only name, line, and time (default)
-t
,
--time
print last system clock change
-T
,
-w
,
--mesg
add user's message status as +, - or ? -u
,
--users
list users logged in
--message
same as
-T
--writable
same as
-T
--help
display this help and exit
--version
output version information and exit

       If FILE is not specified, use
/var/run/utmp
."
1640,1,who,"-u
,
--users
list users logged in
--message
same as
-T
--writable
same as
-T
--help
display this help and exit
--version
output version information and exit

       If FILE is not specified, use
/var/run/utmp
. /var/log/wtmp
as
       FILE is common. If ARG1 ARG2 given,
-m
presumed: 'am i' or 'mom
       likes' are usual."
1641,0,whoami,"Print the user name associated with the current effective user ID.
       Same as id
-un
.
--help
display this help and exit
--version
output version information and exit"
1642,0,wget,"GNU Wget is a free utility for non-interactive download of files
       from the Web. It supports HTTP, HTTPS, and FTP protocols, as well
       as retrieval through HTTP proxies. Wget is non-interactive, meaning that it can work in the
       background, while the user is not logged on."
1642,1,wget,"Wget is non-interactive, meaning that it can work in the
       background, while the user is not logged on. This allows you to
       start a retrieval and disconnect from the system, letting Wget
       finish the work. By contrast, most of the Web browsers require
       constant user's presence, which can be a great hindrance when
       transferring a lot of data."
1642,2,wget,"By contrast, most of the Web browsers require
       constant user's presence, which can be a great hindrance when
       transferring a lot of data. Wget can follow links in HTML, XHTML, and CSS pages, to create
       local versions of remote web sites, fully recreating the directory
       structure of the original site. This is sometimes referred to as
       ""recursive downloading.""  While doing that, Wget respects the
       Robot Exclusion Standard (
/robots.txt
)."
1642,3,wget,"This is sometimes referred to as
       ""recursive downloading.""  While doing that, Wget respects the
       Robot Exclusion Standard (
/robots.txt
). Wget can be instructed to
       convert the links in downloaded files to point at the local files,
       for offline viewing. Wget has been designed for robustness over slow or unstable
       network connections; if a download fails due to a network problem,
       it will keep retrying until the whole file has been retrieved."
1642,4,wget,"Wget can be instructed to
       convert the links in downloaded files to point at the local files,
       for offline viewing. Wget has been designed for robustness over slow or unstable
       network connections; if a download fails due to a network problem,
       it will keep retrying until the whole file has been retrieved. If
       the server supports regetting, it will instruct the server to
       continue the download from where it left off."
1643,0,windmc,"windmc
reads message definitions from an input file (.mc) and
       translate them into a set of output files. The output files may
       be of four kinds:

       ""h"" A C header file containing the message definitions. ""rc""
           A resource file compilable by the
windres
tool."
1643,1,windmc,"""rc""
           A resource file compilable by the
windres
tool. ""bin""
           One or more binary files containing the resource data for a
           specific message language. ""dbg""
           A C include file that maps message id's to their symbolic
           name."
1643,2,windmc,"""dbg""
           A C include file that maps message id's to their symbolic
           name. The exact description of these different formats is available in
       documentation from Microsoft. When
windmc
converts from the ""mc"" format to the ""bin"" format,
       ""rc"", ""h"", and optional ""dbg"" it is acting like the Windows
       Message Compiler."
1644,0,windres,"windres
reads resources from an input file and copies them into an
       output file. Either file may be in one of three formats:

       ""rc""
           A text format read by the Resource Compiler. ""res""
           A binary format generated by the Resource Compiler."
1644,1,windres,"""res""
           A binary format generated by the Resource Compiler. ""coff""
           A COFF object or executable. The exact description of these different formats is available in
       documentation from Microsoft."
1644,2,windres,"The exact description of these different formats is available in
       documentation from Microsoft. When
windres
converts from the ""rc"" format to the ""res"" format, it
       is acting like the Windows Resource Compiler. When
windres
converts from the ""res"" format to the ""coff"" format, it is acting
       like the Windows ""CVTRES"" program."
1644,3,windres,"When
windres
converts from the ""res"" format to the ""coff"" format, it is acting
       like the Windows ""CVTRES"" program. When
windres
generates an ""rc"" file, the output is similar but not
       identical to the format expected for the input. When an input
       ""rc"" file refers to an external filename, an output ""rc"" file will
       instead include the file contents."
1644,4,windres,"When an input
       ""rc"" file refers to an external filename, an output ""rc"" file will
       instead include the file contents. If the input or output format is not specified,
windres
will guess
       based on the file name, or, for the input file, the file contents. A file with an extension of
.rc
will be treated as an ""rc"" file, a
       file with an extension of
.res
will be treated as a ""res"" file,
       and a file with an extension of
.o
or
.exe
will be treated as a
       ""coff"" file."
1644,5,windres,"A file with an extension of
.rc
will be treated as an ""rc"" file, a
       file with an extension of
.res
will be treated as a ""res"" file,
       and a file with an extension of
.o
or
.exe
will be treated as a
       ""coff"" file. If no output file is specified,
windres
will print the resources
       in ""rc"" format to standard output. The normal use is for you to write an ""rc"" file, use
windres
to
       convert it to a COFF object file, and then link the COFF file into
       your application."
1644,6,windres,"If no output file is specified,
windres
will print the resources
       in ""rc"" format to standard output. The normal use is for you to write an ""rc"" file, use
windres
to
       convert it to a COFF object file, and then link the COFF file into
       your application. This will make the resources described in the
       ""rc"" file available to Windows."
1645,0,write,"The
write
utility shall read lines from the standard input and
       write them to the terminal of the specified user. When first
       invoked, it shall write the message:
Message from
sender-login-id
(
sending-terminal
)
[
date
]
... to
user_name
."
1645,1,write,"to
user_name
. When it has successfully completed the connection,
       the sender's terminal shall be alerted twice to indicate that what
       the sender is typing is being written to the recipient's terminal. If the recipient wants to reply, this can be accomplished by
       typing:

           write
sender-login-id
[
sending-terminal
]
upon receipt of the initial message."
1645,2,write,"If the recipient wants to reply, this can be accomplished by
       typing:

           write
sender-login-id
[
sending-terminal
]
upon receipt of the initial message. Whenever a line of input as
       delimited by an NL, EOF, or EOL special character (see the Base
       Definitions volume of POSIX.1â2017,
Chapter 11
,
General Terminal
Interface
) is accumulated while in canonical input mode, the
       accumulated data shall be written on the other user's terminal. Characters shall be processed as follows:

        *  Typing <alert> shall write the <alert> character to the
           recipient's terminal."
1645,3,write,"Characters shall be processed as follows:

        *  Typing <alert> shall write the <alert> character to the
           recipient's terminal. *  Typing the erase and kill characters shall affect the sender's
           terminal in the manner described by the
termios
interface in
           the Base Definitions volume of POSIX.1â2017,
Chapter 11
,
General Terminal Interface
. *  Typing the interrupt or end-of-file characters shall cause
write
to write an appropriate message (
""EOT\n""
in the POSIX
           locale) to the recipient's terminal and exit."
1645,4,write,"*  Typing the interrupt or end-of-file characters shall cause
write
to write an appropriate message (
""EOT\n""
in the POSIX
           locale) to the recipient's terminal and exit. *  Typing characters from
LC_CTYPE
classifications
print
or
space
shall cause those characters to be sent to the recipient's
           terminal. *  When and only when the
stty
iexten
local mode is enabled, the
           existence and processing of additional special control
           characters and multi-byte or single-byte functions is
           implementation-defined."
1645,5,write,"*  When and only when the
stty
iexten
local mode is enabled, the
           existence and processing of additional special control
           characters and multi-byte or single-byte functions is
           implementation-defined. *  Typing other non-printable characters shall cause
           implementation-defined sequences of printable characters to be
           written to the recipient's terminal. To write to a user who is logged in more than once, the
terminal
argument can be used to indicate which terminal to write to;
       otherwise, the recipient's terminal is selected in an
       implementation-defined manner and an informational message is
       written to the sender's standard output, indicating which terminal
       was chosen."
1645,6,write,"To write to a user who is logged in more than once, the
terminal
argument can be used to indicate which terminal to write to;
       otherwise, the recipient's terminal is selected in an
       implementation-defined manner and an informational message is
       written to the sender's standard output, indicating which terminal
       was chosen. Permission to be a recipient of a
write
message can be denied or
       granted by use of the
mesg
utility. However, a user's privilege
       may further constrain the domain of accessibility of other users'
       terminals."
1645,7,write,"Permission to be a recipient of a
write
message can be denied or
       granted by use of the
mesg
utility. However, a user's privilege
       may further constrain the domain of accessibility of other users'
       terminals. The
write
utility shall fail when the user lacks
       appropriate privileges to perform the requested action."
1646,0,wrudf,"wrudf
provides an interactive shell with operations on existing
       UDF filesystem: cp, rm, mkdir, rmdir, ls, cd.
COMMANDS
cp
copy
rm
remove
mkdir
make directory
rmdir
remove directory
lsc
list files (Compact disc version)
lsh
list files (Hard disc version)
cdc
change working directory (Compact disc)
cdh
change working directory (Hard disc)
quit
quit
wrudf
exit
quit
wrudf"
1647,0,wsrep_sst_backup,"Use: See source code of script.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
1648,0,wsrep_sst_common,"Use: Common command line parser to be sourced by other SST
       scripts.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
1649,0,wsrep_sst_mariabackup,"Use: mariabackup-based state snapshot transfer.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
1650,0,wsrep_sst_mysqldump,"Use: mysqldump-based state snapshot transfer.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
1651,0,wsrep_sst_rsync,"Use: rsync-based state snapshot transfer.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
1652,0,wsrep_sst_rsync_wan,"Use: rsync_wan-based state snapshot transfer.

       For more information, please refer to the MariaDB Knowledge Base,
       available online at
https://mariadb.com/kb/"
1653,0,xargs,"This manual page documents the GNU version of
xargs
. xargs
reads
       items from the standard input, delimited by blanks (which can be
       protected with double or single quotes or a backslash) or newâ
       lines, and executes the
command
(default is
echo
) one or more
       times with any
initial-arguments
followed by items read from stanâ
       dard input. Blank lines on the standard input are ignored."
1653,1,xargs,"Blank lines on the standard input are ignored. The command line for
command
is built up until it reaches a sysâ
       tem-defined limit (unless the
-n
and
-L
options are used). The
       specified
command
will be invoked as many times as necessary to
       use up the list of input items."
1653,2,xargs,"The
       specified
command
will be invoked as many times as necessary to
       use up the list of input items. In general, there will be many
       fewer invocations of
command
than there were items in the input. This will normally have significant performance benefits."
1653,3,xargs,"This will normally have significant performance benefits. Some
       commands can usefully be executed in parallel too; see the
-P
opâ
       tion. Because Unix filenames can contain blanks and newlines, this deâ
       fault behaviour is often problematic; filenames containing blanks
       and/or newlines are incorrectly processed by
xargs
."
1653,4,xargs,"Because Unix filenames can contain blanks and newlines, this deâ
       fault behaviour is often problematic; filenames containing blanks
       and/or newlines are incorrectly processed by
xargs
. In these sitâ
       uations it is better to use the
-0
option, which prevents such
       problems. When using this option you will need to ensure that the
       program which produces the input for
xargs
also uses a null charâ
       acter as a separator."
1653,5,xargs,"When using this option you will need to ensure that the
       program which produces the input for
xargs
also uses a null charâ
       acter as a separator. If that program is GNU
find
for example,
       the
-print0
option does this for you. If any invocation of the command exits with a status of 255,
xargs
will stop immediately without reading any further input."
1653,6,xargs,"If that program is GNU
find
for example,
       the
-print0
option does this for you. If any invocation of the command exits with a status of 255,
xargs
will stop immediately without reading any further input. An error
       message is issued on stderr when this happens."
1654,0,xargs,"The
xargs
utility shall construct a command line consisting of the
utility
and
argument
operands specified followed by as many
       arguments read in sequence from standard input as fit in length
       and number constraints specified by the options. The
xargs
utility
       shall then invoke the constructed command line and wait for its
       completion. This sequence shall be repeated until one of the
       following occurs:

        *  An end-of-file condition is detected on standard input."
1654,1,xargs,"This sequence shall be repeated until one of the
       following occurs:

        *  An end-of-file condition is detected on standard input. *  An argument consisting of just the logical end-of-file string
           (see the
-E
eofstr
option) is found on standard input after
           double-quote processing, <apostrophe> processing, and
           <backslash>-escape processing (see next paragraph). All
           arguments up to but not including the argument consisting of
           just the logical end-of-file string shall be used as arguments
           in constructed command lines."
1654,2,xargs,"All
           arguments up to but not including the argument consisting of
           just the logical end-of-file string shall be used as arguments
           in constructed command lines. *  An invocation of a constructed command line returns an exit
           status of 255. The application shall ensure that arguments in the standard input
       are separated by unquoted <blank> characters, unescaped <blank>
       characters, or <newline> characters."
1654,3,xargs,"The application shall ensure that arguments in the standard input
       are separated by unquoted <blank> characters, unescaped <blank>
       characters, or <newline> characters. A string of zero or more non-
       double-quote (
'""'
) characters and non-<newline> characters can be
       quoted by enclosing them in double-quotes. A string of zero or
       more non-<apostrophe> (
'\''
) characters and non-<newline>
       characters can be quoted by enclosing them in <apostrophe>
       characters."
1654,4,xargs,"A string of zero or
       more non-<apostrophe> (
'\''
) characters and non-<newline>
       characters can be quoted by enclosing them in <apostrophe>
       characters. Any unquoted character can be escaped by preceding it
       with a <backslash>. The utility named by
utility
shall be
       executed one or more times until the end-of-file is reached or the
       logical end-of file string is found."
1654,5,xargs,"The utility named by
utility
shall be
       executed one or more times until the end-of-file is reached or the
       logical end-of file string is found. The results are unspecified
       if the utility named by
utility
attempts to read from its standard
       input. The generated command line length shall be the sum of the size in
       bytes of the utility name and each argument treated as strings,
       including a null byte terminator for each of these strings."
1654,6,xargs,"The generated command line length shall be the sum of the size in
       bytes of the utility name and each argument treated as strings,
       including a null byte terminator for each of these strings. The
xargs
utility shall limit the command line length such that when
       the command line is invoked, the combined argument and environment
       lists (see the
exec
family of functions in the System Interfaces
       volume of POSIX.1â2017) shall not exceed {ARG_MAX}-2048 bytes. Within this constraint, if neither the
-n
nor the
-s
option is
       specified, the default command line length shall be at least
       {LINE_MAX}."
1655,0,xminicom,"Xminicom
is a script wrapper around
minicom.
It tries to find a
       color capable xterm or rxvt on your system, and then runs minicom
       with the -c (color) flag in a terminal session."
1656,0,xgettext,"Extract translatable strings from given input files. Mandatory arguments to long options are mandatory for short
       options too. Similarly for optional arguments."
1656,1,xgettext,"Similarly for optional arguments. Input file location:
INPUTFILE ... input files
-f
,
--files-from
=
FILE
get list of input files from FILE
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read."
1656,2,xgettext,"input files
-f
,
--files-from
=
FILE
get list of input files from FILE
-D
,
--directory
=
DIRECTORY
add DIRECTORY to list for input files search

       If input file is -, standard input is read. Output file location:
-d
,
--default-domain
=
NAME
use NAME.po for output (instead of messages.po)
-o
,
--output
=
FILE
write output to specified file
-p
,
--output-dir
=
DIR
output files will be placed in directory DIR

       If output file is -, output is written to standard output. Choice of input file language:
-L
,
--language
=
NAME
recognise the specified language (C, C++, ObjectiveC, PO,
              Shell, Python, Lisp, EmacsLisp, librep, Scheme, Guile,
              Smalltalk, Java, JavaProperties, C#, awk, YCP, Tcl, Perl,
              PHP, Ruby, GCC-source, NXStringTable, RST, RSJ, Glade, Lua,
              JavaScript, Vala, Desktop)
-C
,
--c
++
              shorthand for
--language
=
C
++

       By default the language is guessed depending on the input file
       name extension."
1656,3,xgettext,"Choice of input file language:
-L
,
--language
=
NAME
recognise the specified language (C, C++, ObjectiveC, PO,
              Shell, Python, Lisp, EmacsLisp, librep, Scheme, Guile,
              Smalltalk, Java, JavaProperties, C#, awk, YCP, Tcl, Perl,
              PHP, Ruby, GCC-source, NXStringTable, RST, RSJ, Glade, Lua,
              JavaScript, Vala, Desktop)
-C
,
--c
++
              shorthand for
--language
=
C
++

       By default the language is guessed depending on the input file
       name extension. Input file interpretation:
--from-code
=
NAME
encoding of input files (except for Python, Tcl, Glade)

       By default the input files are assumed to be in ASCII. Operation mode:
-j
,
--join-existing
join messages with existing file
-x
,
--exclude-file
=
FILE
.po
              entries from FILE.po are not extracted
-cTAG
,
--add-comments
=
TAG
place comment blocks starting with TAG and preceding
              keyword lines in output file
-c
,
--add-comments
place all comment blocks preceding keyword lines in output
              file
--check
=
NAME
perform syntax check on messages (ellipsis-unicode,
              space-ellipsis,

              quote-unicode, bullet-unicode)
--sentence-end
=
TYPE
type describing the end of sentence (single-space, which is
              the default,

              or double-space)
Language specific options:
-a
,
--extract-all
extract all strings (only languages C, C++, ObjectiveC,
              Shell, Python, Lisp, EmacsLisp, librep, Scheme, Java, C#,
              awk, Tcl, Perl, PHP, GCC-source, Glade, Lua, JavaScript,
              Vala)
-kWORD
,
--keyword
=
WORD
look for WORD as an additional keyword
-k
,
--keyword
do not to use default keywords (only languages C, C++,
              ObjectiveC, Shell, Python, Lisp, EmacsLisp, librep, Scheme,
              Java, C#, awk, Tcl, Perl, PHP, GCC-source, Glade, Lua,
              JavaScript, Vala, Desktop)
--flag
=
WORD
:ARG:FLAG
              additional flag for strings inside the argument number ARG
              of keyword WORD

       (only languages C, C++, ObjectiveC, Shell,
              Python, Lisp, EmacsLisp, librep, Scheme, Java, C#, awk,
              YCP, Tcl, Perl, PHP, GCC-source, Lua, JavaScript, Vala)
--tag
=
WORD
:FORMAT
              defines the behaviour of tagged template literals with tag
              WORD

              (only language JavaScript)
-T
,
--trigraphs
understand ANSI C trigraphs for input (deprecated; only
              languages C, C++, ObjectiveC)
--its
=
FILE
apply ITS rules from FILE (only XML based languages)
--qt
recognize Qt format strings (only language C++)
--kde
recognize KDE 4 format strings (only language C++)
--boost
recognize Boost format strings (only language C++)
--debug
more detailed formatstring recognition result
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN."
1656,4,xgettext,"Operation mode:
-j
,
--join-existing
join messages with existing file
-x
,
--exclude-file
=
FILE
.po
              entries from FILE.po are not extracted
-cTAG
,
--add-comments
=
TAG
place comment blocks starting with TAG and preceding
              keyword lines in output file
-c
,
--add-comments
place all comment blocks preceding keyword lines in output
              file
--check
=
NAME
perform syntax check on messages (ellipsis-unicode,
              space-ellipsis,

              quote-unicode, bullet-unicode)
--sentence-end
=
TYPE
type describing the end of sentence (single-space, which is
              the default,

              or double-space)
Language specific options:
-a
,
--extract-all
extract all strings (only languages C, C++, ObjectiveC,
              Shell, Python, Lisp, EmacsLisp, librep, Scheme, Java, C#,
              awk, Tcl, Perl, PHP, GCC-source, Glade, Lua, JavaScript,
              Vala)
-kWORD
,
--keyword
=
WORD
look for WORD as an additional keyword
-k
,
--keyword
do not to use default keywords (only languages C, C++,
              ObjectiveC, Shell, Python, Lisp, EmacsLisp, librep, Scheme,
              Java, C#, awk, Tcl, Perl, PHP, GCC-source, Glade, Lua,
              JavaScript, Vala, Desktop)
--flag
=
WORD
:ARG:FLAG
              additional flag for strings inside the argument number ARG
              of keyword WORD

       (only languages C, C++, ObjectiveC, Shell,
              Python, Lisp, EmacsLisp, librep, Scheme, Java, C#, awk,
              YCP, Tcl, Perl, PHP, GCC-source, Lua, JavaScript, Vala)
--tag
=
WORD
:FORMAT
              defines the behaviour of tagged template literals with tag
              WORD

              (only language JavaScript)
-T
,
--trigraphs
understand ANSI C trigraphs for input (deprecated; only
              languages C, C++, ObjectiveC)
--its
=
FILE
apply ITS rules from FILE (only XML based languages)
--qt
recognize Qt format strings (only language C++)
--kde
recognize KDE 4 format strings (only language C++)
--boost
recognize Boost format strings (only language C++)
--debug
more detailed formatstring recognition result
Output details:
--color
use colors and other text attributes always
--color
=
WHEN
use colors and other text attributes if WHEN. WHEN may be
              'always', 'never', 'auto', or 'html'. --style
=
STYLEFILE
specify CSS style rule file for
--color
-e
,
--no-escape
do not use C escapes in output (default)
-E
,
--escape
use C escapes in output, no extended chars
--force-po
write PO file even if empty
-i
,
--indent
write the .po file using indented style
--no-location
do not write '#: filename:line' lines
-n
,
--add-location
generate '#: filename:line' lines (default)
--strict
write out strict Uniforum conforming .po file
--properties-output
write out a Java .properties file
--stringtable-output
write out a NeXTstep/GNUstep .strings file
--itstool
write out itstool comments
-w
,
--width
=
NUMBER
set output page width
--no-wrap
do not break long message lines, longer than the output
              page width, into several lines
-s
,
--sort-output
generate sorted output (deprecated)
-F
,
--sort-by-file
sort output by file location
--omit-header
don't write header with 'msgid """"' entry
--copyright-holder
=
STRING
set copyright holder in output
--foreign-user
omit FSF copyright in output for foreign user
--package-name
=
PACKAGE
set package name in output
--package-version
=
VERSION
set package version in output
--msgid-bugs-address
=
EMAIL
@ADDRESS
              set report address for msgid bugs
-m[STRING]
,
--msgstr-prefix
[=
STRING
]
              use STRING or """" as prefix for msgstr values
-M[STRING]
,
--msgstr-suffix
[=
STRING
]
              use STRING or """" as suffix for msgstr values
Informative output:
-h
,
--help
display this help and exit
-V
,
--version
output version information and exit
-v
,
--verbose
increase verbosity level"
1657,0,xtotroff,nan
1658,0,hostname,"Hostname
is the program that is used to either set or display the
       current host, domain or node name of the system. These names are
       used by many of the networking programs to identify the machine. The domain name is also used by NIS/YP."
1658,1,hostname,"The domain name is also used by NIS/YP. GET NAME
When called without any arguments, the program displays the
       current names:
hostname
will print the name of the system as returned by the
gethostname(2)
function. domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function."
1658,2,hostname,"domainname, nisdomainname, ypdomainname
will print the name of the
       system as returned by the
getdomainname(2)
function. This is also
       known as the YP/NIS domain name of the system. nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function."
1658,3,hostname,"nodename
will print the DECnet node name of the system as returned
       by the
getnodename
(2) function. dnsdomainname
will print the domain part of the FQDN (Fully
       Qualified Domain Name). The complete FQDN of the system is
       returned with
hostname --fqdn
."
1658,4,hostname,"The complete FQDN of the system is
       returned with
hostname --fqdn
. SET NAME
When called with one argument or with the
--file
option, the
       commands set the host name, the NIS/YP domain name or the node
       name. Note, that only the super-user can change the names."
1658,5,hostname,"Note, that only the super-user can change the names. It is not possible to set the FQDN or the DNS domain name with the
dnsdomainname
command (see
THE FQDN
below). The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g."
1658,6,hostname,"The host name is usually set once at system startup by reading the
       contents of a file which contains the host name, e.g. /etc/hostname
). THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command."
1658,7,hostname,"THE FQDN
You can't change the FQDN (as returned by
hostname --fqdn
) or the
       DNS domain name (as returned by
dnsdomainname
) with this command. The FQDN of the system is the name that the
resolver(3)
returns
       for the host name. Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name."
1658,8,hostname,"Technically: The FQDN is the canonical name returned by
gethostbyname2
(2) when resolving the result of the
gethostname(2)
name. The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it."
1658,9,hostname,"The DNS domain name is the part after the first dot. Therefore it depends on the configuration (usually in
/etc/host.conf
) how you can change it. If
hosts
is the first
       lookup method, you can change the FQDN in
/etc/hosts
."
1659,0,yes,"Repeatedly output a line with all specified STRING(s), or 'y'.
--help
display this help and exit
--version
output version information and exit"
1660,0,yum-builddep,"yum-builddep
is a program which installs the RPMs needed to build
       the specified package. The source RPM for the specified package
       must be available in a Yum repository (which will be automatically
       enabled, if it is disabled) or it can be a local source RPM or a
       spec file. Note, that only the BuildRequires information within the SRPM
       header information is used to determine build dependencies."
1660,1,yum-builddep,"The source RPM for the specified package
       must be available in a Yum repository (which will be automatically
       enabled, if it is disabled) or it can be a local source RPM or a
       spec file. Note, that only the BuildRequires information within the SRPM
       header information is used to determine build dependencies. This
       will specifically omit any dependencies that are required only for
       specific architectures."
1661,0,yacc,"The
yacc
utility shall read a description of a context-free
       grammar in
grammar
and write C source code, conforming to the
       ISO C standard, to a code file, and optionally header information
       into a header file, in the current directory. The generated source
       code shall not depend on any undefined, unspecified, or
       implementation-defined behavior, except in cases where it is
       copied directly from the supplied grammar, or in cases that are
       documented by the implementation. The C code shall define a
       function and related routines and macros for an automaton that
       executes a parsing algorithm meeting the requirements in
Algorithms
."
1661,1,yacc,"The C code shall define a
       function and related routines and macros for an automaton that
       executes a parsing algorithm meeting the requirements in
Algorithms
. The form and meaning of the grammar are described in the EXTENDED
       DESCRIPTION section. The C source code and header file shall be produced in a form
       suitable as input for the C compiler (see
c99(1p)
)."
1662,0,yum-changelog,"yum-changelog(1)
is a Yum plugin for viewing package changelogs
       before/after updating.  yum will invoke
yum-changelog(1)
plugin if
       the
--changelog
option or the
changelog
command is used with yum."
1663,0,yum-config-manager,"yum-config-manager
is a program that can manage main yum
       configuration options, toggle which repositories are enabled or
       disabled, and add new repositories. Unless --add-repo is used, the program will output the current
       configuration of the selected sections, and optionally save it
       back to the corresponding files. By default, if no positional arguments are specified, the program
       will select the [main] section and each enabled repository."
1663,1,yum-config-manager,"By default, if no positional arguments are specified, the program
       will select the [main] section and each enabled repository. You
       can override this by specifying your own list of sections as
       arguments (these may also include disabled repositories). A
       section can either be main or a repoid."
1664,0,yum-aliases,"]8;;https://github.com/rpm-software-management/dnf/\
DNF
]8;;\ is the next upcoming major version of ]8;;http://yum.baseurl.org/\
YUM
]8;;\, a package manager
       for RPM-based Linux distributions. It roughly maintains CLI
       compatibility with YUM and defines a strict API for extensions and
       plugins. Plugins can modify or extend features of DNF or provide additional
       CLI commands on top of those mentioned below."
1664,1,yum-aliases,"Plugins can modify or extend features of DNF or provide additional
       CLI commands on top of those mentioned below. If you know the name
       of such a command (including commands mentioned below), you may
       find/install the package which provides it using the appropriate
       virtual provide in the form of
dnf-command(<alias>)
, where
<alias>
is the name of the command; e.g. dnf install
'dnf-command(versionlock)'
installs a
versionlock
plugin."
1664,2,yum-aliases,"dnf install
'dnf-command(versionlock)'
installs a
versionlock
plugin. This
       approach also applies to specifying dependencies of packages that
       require a particular DNF command. Return values:

       â¢
0
: Operation was successful."
1664,3,yum-aliases,"Return values:

       â¢
0
: Operation was successful. â¢
1
: An error occurred, which was handled by dnf. â¢
3
: An unknown unhandled error occurred during operation."
1664,4,yum-aliases,"â¢
3
: An unknown unhandled error occurred during operation. â¢
100
: See
check-update
â¢
200
: There was a problem with acquiring or releasing of locks. Available commands:

       â¢
alias
â¢
autoremove
â¢
check
â¢
check-update
â¢
clean
â¢
deplist
â¢
distro-sync
â¢
downgrade
â¢
group
â¢
help
â¢
history
â¢
info
â¢
install
â¢
list
â¢
makecache
â¢
mark
â¢
module
â¢
provides
â¢
reinstall
â¢
remove
â¢
repoinfo
â¢
repolist
â¢
repoquery
â¢
repository-packages
â¢
search
â¢
shell
â¢
swap
â¢
updateinfo
â¢
upgrade
â¢
upgrade-minimal
Additional information:

       â¢
Options
â¢
Specifying Packages
â¢
Specifying Provides
â¢
Specifying File Provides
â¢
Specifying Groups
â¢
Specifying Transactions
â¢
Metadata Synchronization
â¢
Configuration Files Replacement Policy
â¢
Files
â¢
See Also"
1665,0,yum-debug-dump,"yum-debug-dump
is a program which creates a gzipped file
       containing a lot of information useful to developers trying to
       debug a problem. By default it will output a file to the current working directory
       named yum_debug_dump-<hostname>-<time>.txt.gz. This file contains
       no private information but does contain a complete list of all
       packages you have installed, all packages available in any
       repository, important configuration and system information."
1665,1,yum-debug-dump,"This file contains
       no private information but does contain a complete list of all
       packages you have installed, all packages available in any
       repository, important configuration and system information. You
       can view this file using the 'zless' command. You can use the coresponding program
yum-debug-restore
to act on
       this file and restore a set of packages (much like dump/restore)."
1666,0,yum-debug-restore,"yum-debug-restore
is a program which takes a gzipped file created
       by
yum-debug-dump
and acts on the information about installed
       packages contained within."
1667,0,yum-filter-data,"This plugin extends
yum
with some options, currently just for
       ""update"" and ""list update"" type commands, to allow filters to be
       placed on which packages should be used based on the data in those
       packages. Note that due to some of the data being unknown, and
       thus could possibly match, all unknown data is treated as a match."
1668,0,yum-groups-manager,"yum-groups-manager
is used to create or edit a group metadata file
       for a yum repository. This is often much easier than
       writing/editing the XML by hand.  The
yum-groups-manager
can load
       an entire file of groups metadata and either create a new group or
       edit an existing group and then write all of the groups metadata
       back out."
1669,0,yum-fs-snapshot,"yum-fs-snapshot(1)
is a Yum plugin for taking snapshots of your
       filesystems before running a yum transaction. By default it will
       take a snapshot of any filesystem that can be snapshotted, which
       currently is limited to BTRFS filesystems. However, all
       filesystems built on LVM logical volumes may be snapshotted at the
       block level using LVM snapshots."
1669,1,yum-fs-snapshot,"However, all
       filesystems built on LVM logical volumes may be snapshotted at the
       block level using LVM snapshots. LVM snapshot support is provided
       for the purpose of system rollback. As such LVM snapshots will
       only be created if the kernel supports the ""snapshot-merge"" DM
       target."
1670,0,yum-list-data,"This plugin extends
yum
for some commands that give aggregate
       package data based on lists of packages

       added yum
command
s are:
        * list-vendors
        * info-vendors
        * list-rpm-groups
        * info-rpm-groups
        * list-packagers
        * info-packagers
        * list-licenses
        * info-licenses
        * list-arches
        * info-arches
        * list-committers
        * info-committers
        * list-buildhosts
        * info-buildhosts
        * list-baseurls
        * info-baseurls
        * list-package-sizes
        * info-package-sizes
        * list-archive-sizes
        * info-archive-sizes
        * list-installed-sizes
        * info-installed-sizes
        * list-groups
        * info-groups

       all of which take the same arguments as the list and info yum
       commands. The difference between the list and info varieties is
       that the info versions lists all the packages under each
       aggregation. list-vendors
,
info-vendors
Is used to list the aggregate of the vendor attribute on
              the packages, examples are ""Fedora Project"" and ""Red Hat,
              Inc.""."
1670,1,yum-list-data,"list-vendors
,
info-vendors
Is used to list the aggregate of the vendor attribute on
              the packages, examples are ""Fedora Project"" and ""Red Hat,
              Inc."". list-rpm-groups
,
info-rpm-groups
Is used to list the aggregate of the group attribute on the
              packages, examples are ""Applications/System"",
              ""Development/Tools"" and ""System Environment/Base""
list-packagers
,
info-packagers
Is used to list the aggregate of the packager attribute on
              the packages, examples are ""Fedora Project"" and ""Red Hat,
              Inc."". list-licenses
,
info-licenses
Is used to list the aggregate of the license attribute on
              the packages, examples are ""GPL"" and ""MIT""
list-arches
,
info-arches
Is used to list the aggregate of the arch attribute on the
              packages, examples are ""i386"" and ""x86_64""
list-committers
,
info-committers
Is used to list the aggregate of the committer attribute on
              the packages, this is taken from the most recent changelog
              entry of the package."
1670,2,yum-list-data,"list-licenses
,
info-licenses
Is used to list the aggregate of the license attribute on
              the packages, examples are ""GPL"" and ""MIT""
list-arches
,
info-arches
Is used to list the aggregate of the arch attribute on the
              packages, examples are ""i386"" and ""x86_64""
list-committers
,
info-committers
Is used to list the aggregate of the committer attribute on
              the packages, this is taken from the most recent changelog
              entry of the package. list-buildhosts
,
info-buildhosts
Is used to list the aggregate of the buildhost attribute on
              the packages, examples are ""mybuilder.example.com"" and
              ""xenbuilder1.fedora.redhat.com""
list-baseurls
,
info-baseurls
Is used to list the aggregate of the url attribute on the
              packages after discarding the path of the URL, examples are
              ""http://yum.baseurl.org/"" and ""http://www.and.org/""
list-package-sizes
,
info-package-sizes
Is used to list the aggregate of specified ranges the
              packagesize attribute on the packages, examples are ""[
              1B -  10KB ]"" and ""[ 750KB -   1MB ]"". list-archive-sizes
,
info-archive-sizes
Is used to list the aggregate of specified ranges the
              archivesize attribute on the packages, examples are ""[
              1B -  10KB ]"" and ""[ 750KB -   1MB ]""."
1670,3,yum-list-data,"list-archive-sizes
,
info-archive-sizes
Is used to list the aggregate of specified ranges the
              archivesize attribute on the packages, examples are ""[
              1B -  10KB ]"" and ""[ 750KB -   1MB ]"". list-installed-sizes
,
info-installed-sizes
Is used to list the aggregate of specified ranges the
              installedsize attribute on the packages, examples are ""[
              1B -  10KB ]"" and ""[ 750KB -   1MB ]"". list-groups
,
info-groups
Is used to list the aggregate of the yum groups that the
              packages are in, examples are in ""yum grouplist""."
1670,4,yum-list-data,"list-groups
,
info-groups
Is used to list the aggregate of the yum groups that the
              packages are in, examples are in ""yum grouplist"". Note that
              in yum groups a package can be in more than one group at a
              time. It is worth noting that some of the above data can be ""unknown"",
       to yum, at which point a separate aggregation called ""-- Unknown
       --"" is listed."
1671,0,yum-ovl,"Opening a file on OverlayFS in read-only mode causes the file from
       lower layer to be opened, then later on, if the same file is
       opened
       in write mode, a copy-up into the upper    layer    takes
       place,
       resulting into a
new
file being opened.
       Since yum(8) needs to open the
RPMdb
first read-only, and then
       also with write access, we need to copy-up the files beforehand to
       make sure that the access is consistent."
1672,0,yum-torrent,"yum-torrent
extends the behaviour of yum by downloading then
       seeding packages via BitTorrent.  Once installed and configured,
       the plugin works transparently."
1673,0,yum-utils,"yum-utils
is a collection of tools and programs for managing yum
       repositories, installing debug packages, source packages, extended
       information from repositories and administration."
1674,0,yum-verify,"This plugin extends
yum
with some commands that give verification
       information on the installed system, much like rpm -V. You can
       change how the verification is done and which files it applies to. In case any mismatches are found, the exit status is set to 1."
1674,1,yum-verify,"In case any mismatches are found, the exit status is set to 1. added yum
command
s are:
        * verify
        * verify-rpm
        * verify-all

       all of which take the same arguments as the list yum command. You
       can only verify packages that are installed on the system."
1674,2,yum-verify,"You
       can only verify packages that are installed on the system. verify
Is the generic verification command, and is intended to
              give the most useful output. It removes all false matches
              due to multilib and ignores changes to configuration files
              by default."
1674,3,yum-verify,"It removes all false matches
              due to multilib and ignores changes to configuration files
              by default. verify-rpm
Does the same checks as rpm -V. verify-all
Is used to list all the differences, including some that
              rpm itself will ignore."
1675,0,yum-versionlock,"yum-versionlock(1)
is a Yum plugin that takes a set of
       name/versions for packages and excludes all other versions of
       those packages (including optionally following obsoletes). This
       allows you to protect packages from being updated by newer
       versions. The plugin provides a command ""versionlock"" which allows you to
       view and edit the list of locked packages easily."
1675,1,yum-versionlock,"The plugin provides a command ""versionlock"" which allows you to
       view and edit the list of locked packages easily. yum versionlock add <package-wildcard>... Add a versionlock for all of the packages in the rpmdb
              matching the given wildcards."
1675,2,yum-versionlock,"Add a versionlock for all of the packages in the rpmdb
              matching the given wildcards. yum versionlock exclude <package-wildcard>... Opposite; disallow currently available versions of the
              packages matching the given wildcards."
1675,3,yum-versionlock,"Opposite; disallow currently available versions of the
              packages matching the given wildcards. yum versionlock list
List the current versionlock entries. yum versionlock status
List any available updates that are currently blocked by
              versionlock."
1675,4,yum-versionlock,"yum versionlock status
List any available updates that are currently blocked by
              versionlock. That is, for each entry in the lock list,
              print the newest package available in the repos unless it
              is the particular locked/excluded version. yum versionlock delete <entry-wildcard>..."
1675,5,yum-versionlock,"yum versionlock delete <entry-wildcard>... Remove any matching versionlock entries. yum versionlock clear
Remove all versionlock entries."
1676,0,yumdownloader,"yumdownloader
is a program for downloading RPMs from Yum
       repositories."
1677,0,zcat,"The
zcat
utility shall write to standard output the uncompressed
       form of files that have been compressed using the
compress
utility. It is the equivalent of
uncompress
-c
.  Input files are
       not affected."
1678,0,zenmap,"Zenmap is a multi-platform graphical Nmap frontend and results
       viewer. Zenmap aims to make Nmap easy for beginners to use while
       giving experienced Nmap users advanced features. Frequently used
       scans can be saved as profiles to make them easy to run
       repeatedly."
1678,1,zenmap,"Frequently used
       scans can be saved as profiles to make them easy to run
       repeatedly. A command creator allows interactive creation of Nmap
       command lines. Scan results can be saved and viewed later."
1678,2,zenmap,"Scan results can be saved and viewed later. Saved
       scan results can be compared with one another to see how they
       differ. The results of recent scans are stored in a searchable
       database."
1678,3,zenmap,"The results of recent scans are stored in a searchable
       database. This man page only describes the few Zenmap command-line options
       and some critical notes. A much more detailed Zenmap User's Guide
       is available at
https://nmap.org/book/zenmap.html
."
1678,4,zenmap,"This man page only describes the few Zenmap command-line options
       and some critical notes. A much more detailed Zenmap User's Guide
       is available at
https://nmap.org/book/zenmap.html
. Other
       documentation and information is available from the Zenmap web
       page at
https://nmap.org/zenmap/
."
1679,0,zsoelim,"zsoelim
parses
file
arguments, or if none are specified, its
       standard input for lines of the form:
.so
<
filename
>

       These requests are replaced by the contents of the
filename
specified. If the request cannot be met,
zsoelim
looks for
filename.ext
where
.ext
can be one of
.gz
,
.Z
or
.z
. Other
       extension types may be supported depending upon compile time
       options."
1679,1,zsoelim,"Other
       extension types may be supported depending upon compile time
       options. If the request can be met by a compressed file, this
       file is decompressed using an appropriate decompressor and its
       output is used to satisfy the request. Traditionally,
soelim
programs were used to allow roff
       preprocessors to be able to preprocess the files referred to by
       the requests."
1679,2,zsoelim,"If the request can be met by a compressed file, this
       file is decompressed using an appropriate decompressor and its
       output is used to satisfy the request. Traditionally,
soelim
programs were used to allow roff
       preprocessors to be able to preprocess the files referred to by
       the requests. This particular version was written to circumvent
       problems created by support for compressed manual pages."
